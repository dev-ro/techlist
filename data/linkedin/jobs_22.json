[
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Oakland, CA",
        "job_id": 3945302730,
        "company": "Enexus Global Inc.",
        "title": "Sr MS SQL DATABASE ENGINEER - Oakland, CA(hybrid)",
        "created_on": 1720636141.8005307,
        "description": "Role : Senior SQL Database Developer Location : Oakland, CA(hybrid) Contract type : W2/1099 only Experience : 8+ years Responsibilities Design, develop and optimize large, complex DB schemas, SQL scripts and objects to meet application functionality and performance requirements. Working cohesively with stakeholders including data, design, product, and executive teams and assisting them with data-related technical issues. Working closely with application developers and business teams at all levels to assist with data-related technical issues and help ensure the successful designing and delivering data driven solutions. Implement processes and procedures for the development and release of products/projects that facilitate high quality and rapid deployment Provide solutions to promote data integrity in enterprise systems. Participate in code reviews to validate effectiveness and quality of code. Liaise with Developers to improve applications and establish best practices Publish documentation and collaborative information using internal tools. Requirements Expertise in Database Architecture in an environment that handles large volume of data, excess of 500 million of new data records every day. Strong analytical and organizational skills. This job involves analyzing existing databases and the client's needs to develop effective data driven solutions. Demonstrate expertise in performance tuning including both query and server optimization utilizing SQL tools and/or 3rd party solutions. Strong knowledge and experience in data modeling, database design, optimization for performance, SQL, stored procedures. Expertise in understanding complex business needs, analyzing, designing, and developing solutions. Hands-on development experience in SQL Server 2016 or above using SSIS and SSRS. Experience in troubleshooting and resolving data related issues. Excellent oral and written communication skills. Expertise in performance tuning especially tuning complex queries, procedure, and indexing strategies. Monitor and perform tuning on complex ETL jobs using meta-data/variables/parameters. Performance tuning experience using 3rd party tools. Audit/compliance experience in highly regulated environment. Experience using JIRA and Confluence as part of development life cycle. Experience with Business Intelligence tools such as Tableau, SSRS, Power BI. Familiar with Continual Improvement processes. Familiar with Git. Experience 8 years + relational database and SQL experience Creativity, curiosity, initiative, and self-management are key attributes candidate embodies. Solid experience (4 years +) in coding complex SQL queries and stored procedures. The ability to explain the details of performance tuning internals of the database. Strong understanding of database development methodologies (Source Control, Continual improvement, Release Management, Agile and Scrum) Experience with Continuous Integration Tools (Jenkins, TeamCity, Bamboo) and Test-Driven Development (TDD) a big plus Experience with Red Gate Tools a plus (SQL Source Control, SQL Compare, SQL Data Compare, DLM). Healthcare domain knowledge a big plus. Education BS or equivalent in engineering or related technical area Master's degree preferred",
        "url": "https://www.linkedin.com/jobs/view/3945302730"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3964452929,
        "company": "DoorDash",
        "title": "Staff Software Engineer, Data Engineering",
        "created_on": 1720636145.9043918,
        "description": "About the Team Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. Team serves as the foundation for decision-making at DoorDash. About the Role DoorDash is looking for a Staff Software Engineer,Data to be a technical lead and help architect and scale our data reliability, data infrastructure, automation and tools to meet growing business needs. You're excited about this opportunity because you will… Own critical data systems that support multiple products/teams Develop, implement and enforce best practices for data infrastructure and automation Design, develop and implement large scale, high volume, high performance data models and pipelines for Data Lake and Data Warehouse Improve the reliability and scalability of our Ingestion, data processing, ETLs, Reporting tools and data ecosystem services Manage a portfolio of data products that deliver high-quality, trustworthy data Help onboard and support other engineers as they join the team We're excited about you because… 8+ years of professional experience as a hands-on engineer and technical leader leading multiple projects 6+ years experience working in data platform and data engineering or a similar role Proficiency in programming languages such as Python/Kotlin/Scala 4+ years of experience in ETL orchestration and workflow management tools like Airflow Expert in database fundamentals, SQL, data reliability practices and distributed computing 4+ years of experience with the Distributed data/similar ecosystem (Spark, Presto) and streaming technologies such as Kafka/Flink/Spark Streaming Excellent communication skills and experience working with technical and non-technical teams and knowledge of reporting tools Comfortable working in fast paced environment, self starter and self organizing Ability to think strategically, analyze and interpret market and consumer information You must be located near one of our engineering hubs indicated above Compensation The location-specific base salary range for this position is listed below. Compensation in other geographies may vary. Actual compensation within the pay range will be decided based on factors including, but not limited to, skills, prior relevant experience, and specific work location. For roles that are available to be filled remotely, base salary is localized according to employee work location. Please discuss your intended work location with your recruiter for more information. DoorDash cares about you and your overall well-being, and that's why we offer a comprehensive benefits package, for full-time employees, that includes healthcare benefits, a 401(k) plan including an employer match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid time off, paid parental leave, and several paid holidays, among others. In addition to base salary, the compensation package for this role also includes opportunities for equity grants. We use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on June 20, 2024. Please see the independent bias audit report covering our use of Covey here. California Pay Range: $201,900—$302,900 USD Washington Pay Range: $201,900—$302,900 USD About DoorDash At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more. Our Commitment to Diversity and Inclusion We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel. Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on \"protected categories,\" we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination. Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation. If you need any accommodations, please inform your recruiting contact upon initial connection.",
        "url": "https://www.linkedin.com/jobs/view/3964452929"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3647560521,
        "company": "Ponto",
        "title": "Backend Software Engineer",
        "created_on": 1720636147.6638644,
        "description": "Ponto is building the financial infrastructure to power the next generation of wallets, banks, and financial services by integrating local economies into the global financial system. Our mission is to power and provide access to the best financial experiences anywhere in the world, enabling the vast population of unbanked individuals across the globe to participate in the global economy. We're looking for backend software engineers with a passion for building reliable and scalable systems that power great products. Our team is diverse, empathetic, and mission-driven. Our ideal teammate is one who shares our drive to effect positive change, with a willingness to jump into any aspect of our system and our work. Although experience in fintech, blockchain, or crypto is valuable, you don't need to have any experience in these areas to join us! Expected compensation range 185K-250K. In Your Role At Ponto, You Will Design and build highly available, resilient, and performant production systems that power financial services for a large number of end-users. Security will be at the forefront of how you design and operate these systems. Design and implement data collection and manipulation pipelines. Design well-abstracted and documented APIs for our customers and partners. Rigorously develop and implement automated testing to cover the full gamut of functionality in our systems, including unit tests, integration tests, and end-to-end tests. Setup and manage CI/CD pipelines and other developer tooling to increase your team's engineering velocity. Learn your way around public cloud providers and their numerous service offerings. Work with a diverse, talented, and kind group of people with many different roles in performing all of the above. Qualifications Hands-on experience with distributed systems such as Spark, Kafka, or Cassandra, but no experience with a specific technology is required. Strong coding skills in any object-oriented language. We believe languages can be learned and are far more interested in your general engineering abilities. An inclusive, collaborative, and respectful attitude, along with great critical thinking and problem solving abilities. 8+ years of relevant experience We Offer Best-in-class benefits package Meaningful and significant equity in a fast-growing startup Flexible vacation policy, with an annual minimum Parental Leave Relocation support Generous wellness package that includes gym memberships In office, we pay for meals for our employees so you can focus on work A world-class environment in which to learn and do your best work",
        "url": "https://www.linkedin.com/jobs/view/3647560521"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3956072618,
        "company": "Ursus, Inc.",
        "title": "Python Data Engineer - Content Operations",
        "created_on": 1720636149.3159242,
        "description": "JOB TITLE: Python Data Engineer - Content Operations LOCATION: San Francisco, CA - HYBRID PAY RANGE: $46-$56/hr DURATION: 2 months (special project) COMPANY: Our client a Fortune 500 Software Organization is seeking a Python Data Engineer - Content Operations to bring onto the team. DUTIES: We are seeking an enthusiastic and inquisitive Data Engineer who is passionate about data and proficient in programming with Python. This role involves working on diverse projects that include processing, analyzing, and interpreting large datasets within the context of global financial markets. Responsibilities: Extract, transform, join, and load data from one or multiple systems to other systems, repositories, or tools supporting internal projects associated with the operational management of customer-ready help content. Build, format, and publish aggregated data sets containing customer-facing help content and associated attributes. Design and develop data pipelines to ingest, transform, and load unstructured and structured data from various sources. Document all programming tasks and data sets for future reference and troubleshooting. Leverage Large Language Models (LLMs) to automate specific content-related tasks. Enhance productivity for content authoring processes and teams by integrating tooling, including AI-based tooling. Skills: 1 to 3 years of relevant experience Python coding: Write clean, efficient, and maintainable code as standalone scripts in Python to implement data solutions and algorithms tailored to project requirements. Experience and knowledge should include: Data typing and data structures Calling RESTful and GraphQL web service APIs Querying or populating both No-SQL and SQL databases Utilizing cloud storage and platforms such as AWS or Azure Proficiency with Git, artifactory, and modern developer tooling for creating and managing code in a large enterprise. Demonstrated ability to perform exploratory data analysis to uncover insights and patterns within help content-related datasets and utilize statistical methods. Experience with prompt engineering for LLMs. Some experience with standard use of basic features of cloud platforms like Azure or AWS Proven ability to be self-driven and work relatively independently Experience as a user of Photoshop or other Creative Cloud products is a plus Specific experience working with digital content management systems or tools would be ideal Experience with a framework for AI applications is also a plus Education: Bachelor's degree or higher in Science, Computer Science, Data Science, or a related field, with substantial coursework in Computer Science. IND123",
        "url": "https://www.linkedin.com/jobs/view/3956072618"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3710141427,
        "company": "Kaedim",
        "title": "Software Engineer",
        "created_on": 1720636152.7509198,
        "description": "Kaedim is a cutting-edge AI technology company specializing in developing Machine Learning algorithms for transforming 2D images into digital 3D models. Our primary focus is serving game developers, offering big speedups in their 3D asset production pipelines. For Working With Us You Must be eager to be involved with both AI and product dev. Must have done this before, or be willing to learn fast. Must be customer driven. We think customers first and so should you. Must be driven to go above and beyond. Must be able to explain and communicate clearly. Must be able to work autonomously. Must want to work hard. Must be a strong communicator, capable of justifying decisions, proposing new ideas and explaining solutions to the rest of the team Responsibilities Collaborate with cross-functional teams to design, develop and deploy web applications that meet customer needs and exceed expectations. Write clean, modular, and maintainable code using the ReactJS, TailwindCSS, and NodeJS frameworks. Manage AWS cloud infrastructure and services, including EC2, S3, and RDS, and implement best practices. Design and manage MySQL databases, ensuring efficient and effective data storage and retrieval. Conduct unit testing and end-to-end testing using Cypress and Jest to ensure application stability and reliability. Develop and maintain REST APIs to support application functionality and integrations. Understand and incorporate customer feedback into design and development decisions, ensuring a high level of customer satisfaction. Communicate complex ideas and technical concepts clearly and concisely to cross-functional teams and stakeholders. Work independently to manage projects, meet deadlines, and achieve business goals. Stay up-to-date with emerging trends and technologies in web development. Qualifications Strong experience with React and Tailwind CSS for frontend development. Solid experience with NodeJS and Express for backend development. Solid experience with Python. Strong knowledge of MySQL and database design. Experience with unit testing and end-to-end testing using Cypress and Jest. Experience in REST API design and development using modern web development frameworks. Strong debugging skills and the ability to troubleshoot complex issues across the tech stack. Excellent collaboration and communication skills, including the ability to work in a fast-paced environment with cross-functional teams and manage multiple projects simultaneously. Nice to haves Familiarity with WebGL and three.js for 3D graphics programming and rendering. Experience with containerization using Docker for application deployment and management. Experience with AWS-SDK for cloud computing, including experience with AWS services such as EC2, S3, and RDS. Experience with 3D modelling would be a big plus.",
        "url": "https://www.linkedin.com/jobs/view/3710141427"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Campbell, CA",
        "job_id": 3923096566,
        "company": "Telos Health",
        "title": "Software Engineer II – Realtime Embedded Systems",
        "created_on": 1720636154.4068706,
        "description": "Job Title: Software Engineer II - Realtime Embedded Systems Why Telos Health? At Telos Health we are developing novel robotic-assisted technologies and interventional capabilities that will forever change the disparate outcomes of ischemic stroke – a disease that impacts close to a million people a year in the U.S., and 10 million worldwide. Not only is Telos changing the way stroke is treated, but also bringing this treatment to the greater population who is currently without. We are actively building a team who is focused on developing novel solutions for this complex disease – a disease in which one in four adults will face in their lifetime. What You’ll Do: We are looking for a talented and experienced Software Engineer to design and implement embedded software for the Telos robotic platform. As one of the key founding members of the software team, you will contribute to the design and development of the infrastructure software. You’ll work closely with a cross-functional team to implement and test software solutions based on clinical and user requirements. What You’ll Bring: BS in Engineering with a focus in software, controls, or robotics and 2+ years of working experience or an MS or an Advanced degree; or equivalent combination of education and work experience. 2+ years of embedded software development experience Proficiency with C/C++ and Python Experience with real-time operating systems (QNX, ThreadX, or similar) Experience with hardware/software integration Excellent communication and documentation skills Desired Knowledge Experience developing software for robotics Experience developing software for safety-critical applications Software development of microcontrollers Experience working in an Agile development environment Employee Benefits include a stake in our collective success with stock options, competitive salaries, a 401k plan, health benefits, generous PTO, and a parental leave program. Join Us! Salary Range: $120,000 - 140,000 annually Please note that the salary information is a general guideline only. Imperative Care considers factors such as scope and responsibilities of the position, candidate's work experience, education/training, key skills, and internal equity, as well as location, market and business considerations when extending an offer. As part of our total rewards package, Imperative Care offers comprehensive benefits including a 401k plan, health benefits, generous PTO, a parental leave program and emotional health resources. Powered by JazzHR YV2xa29bS0",
        "url": "https://www.linkedin.com/jobs/view/3923096566"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Garden Grove, CA",
        "job_id": 3962952547,
        "company": "EV.Careers",
        "title": "Software Engineer, Data Applications",
        "created_on": 1720636156.0611286,
        "description": "Job Overview The data applications software engineer will be pivotal in designing, developing, and maintaining data analysis and integration solutions to draw insights from vehicle data. This role demands a strong background in software engineering, data science, and a passion for sustainable technology. The ideal candidate will work closely with cross-functional teams to develop applications which support engineering analysis, vehicle reliability and service operations, and support our mission to deliver the best experience for customers. What You’ll Do Database Infrastructure Development: Design and implement ETL processes and data storage to integrate data from different sources and combine to facilitate data analysis, metric development and visualization. Application Development: Collaborate with cross-functional engineers to create data applications including data-based correlation of simulation models, verification of control algorithm performance, vehicle performance and reliability analysis, event-tracking and other value-added applications for the development and continuous improvement of our technology. Performance Optimization: Monitor and optimize the performance of data applications. Identify and resolve performance bottlenecks. Documentation & Testing: Create and maintain detailed documentation of data applications, ensuring clarity and accessibility. Develop and execute comprehensive testing plans to guarantee the reliability and accuracy of integrated data. Troubleshooting & Support: Provide ongoing support and troubleshooting for data applications Work with stakeholders to resolve data-related problems promptly and effectively. Who You Are Bachelor’s degree in Computer Science, Information Technology, or a related field. Master’s degree preferred. Minimum of 3-5 years of experience in software engineering with a focus on data science and information systems. Strong fluency in Python and data analysis packages such as pandas, numpy, SciPy, and similar Experience with data analysis computational frameworks such as Apache Spark, Hadoop Experience with ETL processes and data warehousing solutions. Familiarity with cloud platforms (e.g., AWS, Azure, Google Cloud) and their data integration services. Experience with containerization: docker, kubernetes, Understanding of IoT data processing data analysis challenges. Familiarity with machine learning packages such as PyTorch and TensorFlow a plus Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Ability to work independently and manage multiple tasks in a fast-paced environment.",
        "url": "https://www.linkedin.com/jobs/view/3962952547"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Pleasanton, CA",
        "job_id": 3894422189,
        "company": "10x Genomics",
        "title": "Software Engineer III",
        "created_on": 1720636157.7396474,
        "description": "10x Genomics creates powerful scientific tools that enable key biological discoveries and drive exponential progress in the study of human health. Our talented team has a distinguished record of creating innovative instruments, reagents, and software that analyze biological systems at a resolution that matches the complexity of biology. Scientists have used our tools to discover the mechanisms behind Alzheimer's disease, cystic fibrosis, autism, stem cell differentiation, COVID-19, and more. You are a full stack engineer who will be working on Web applications, incorporating the latest software development techniques with the cutting edge of biology. Current projects include everything from e-commerce to data visualization. If you are the kind of person who is an avid fan of technology in all fields, not just your own, and want to apply your talent alongside a diverse team of experts every day, join us at 10x Genomics. What You Will Be Doing Developing well-tested applications based on the latest tech. Contributing to internal tools that increase the robustness of 10x software. Helping standardize approaches across projects. Collaborating with design and product. Minimum Requirements Bachelor's degree in computer science, engineering, math, or scientific discipline and 2 years of software development experience; OR 4 years of professional experience building software Preferred Skills And Experience Significant experience with frontend (eg. Typescript, React, Next). Significant experience with backend (eg. Node, GraphQL, Postgres, Go). Experience testing and deploying applications to the Web. A background in biology is not required, but curiosity and scientific interest is. Below is the U.S. base pay range for this full-time position. The actual base pay will depend on several factors unique to each candidate, including one’s skills, qualifications, experience, and location. At 10x, base pay is also just one component of the Company’s total compensation package. This role is also eligible for 10x’s equity grants, its comprehensive health and retirement benefit programs, and its annual bonus program or sales incentive program. Your 10x recruiter can share more about the specific base pay range for your preferred location, as well as the Company’s total compensation package, during the hiring process. Pay Range $130,815—$208,000 USD About 10x Genomics At 10x Genomics, accelerating our understanding of biology is more than a mission for us. It is a commitment. This is the century of biology, and the breakthroughs we make now have the potential to change the world. We enable scientists to advance their research, allowing them to address scientific questions they did not even know they could ask. Our tools have enabled fundamental discoveries across biology including cancer, immunology, and neuroscience. Our teams are empowered and encouraged to follow their passions, pursue new ideas, and perform at their best in an inclusive and dynamic environment. We know that behind every scientific breakthrough, there is a deep infrastructure of talented people driving the life sciences industry and making it possible for scientists and clinicians to make new strides. We are dedicated to finding the very best person for every aspect of our work because the innovations and discoveries that we enable together will lead to better technologies, better treatments, and a better future. Find out how you can make a 10x difference. Individuals seeking employment at 10x Genomics are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation, or any other characteristic protected by applicable law. 10x does not accept unsolicited applicants submitted by third-party recruiters or agencies. Any resume or application submitted to 10x without a vendor agreement in place will be considered unsolicited and property of 10x, and 10x will not pay a placement fee.",
        "url": "https://www.linkedin.com/jobs/view/3894422189"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Oakland, CA",
        "job_id": 3949994564,
        "company": "SiriusXM",
        "title": "Senior Data Engineer, Data Ingestion",
        "created_on": 1720636159.485125,
        "description": "Who We Are SiriusXM and its brands (Pandora, SiriusXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners -- in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories, and music they love wherever they are. This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day. SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment, and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics, and monetization. The Company’s advertising sales organization, which operates as SiriusXM Media, leverages its scale, cross-platform sales organization, and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through SiriusXM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers. How You’ll Make An Impact In this role you will be a member of a team responsible for designing and developing a data ecosystem to promote an environment of data democratization and utilization across SiriusXM and Pandora. This role will report to a Director of Data Engineering. What You’ll Do Build cloud-based data pipeline frameworks and operations to power business intelligence. Build and improve workflow orchestration tooling to support efficient data pipelines. E.g. airflow plugins, systems integration, deployments. Implement data governance through proper structure, access controls, and safeguards Build command line tools that improve user experience and encourage best practices in the cloud. Build monitoring dashboards for stakeholders to better understand the health, performance, and cost of the platform. Write documentation to encourage adoption of platform tools and support users in their use. Strengthen corporate best practices around data engineering software development processes. What You’ll Need 5+ years’ experience developing data ETL pipelines and data tools in Scala and/or Python. BS/MS or above in Computer Science or relevant experience Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Sqoop. Experience with streaming technologies - Kafka, Kafka Connect, KStreams, KSQL, Beam, Flink, Spark. Experience developing SQL applications of significant complexity Experience with cloud computing - Google Cloud Platform, Amazon Web Services. Experience developing for Linux-based deployment platforms, developing scalable, multithreaded server-side software for deployment. Experience developing service-oriented architectures / orchestration. Experience with API design/development – RPC, REST, JSON. Experience with unit and integration testing frameworks. Experience with CI/CD, build and deployment technologies such as Jenkins. Experience with Data Visualization or Data Notebook tools (i.e Zeppelin, Tableau, etc.). Experience working in a Cloud Environment (AWS, GCP, etc.). Experience developing and deploying machine learning algorithms. Experience developing with additional languages - R, Scala. Experience with workflow tools – Airflow/Composer/Luigi. Experience with data serialization system - Avro, Protobuf. Good public speaking and presentation skills. Interpersonal skills and ability to interact and work with staff at all levels. Excellent written and verbal communication skills. Ability to work independently and in a team environment. Ability to pay attention to details and be organized. Ability to project professionalism over the phone and in person. Ability to handle multiple tasks in a fast-paced environment. Commitment to “internal client” and customer service principles. Willingness to take initiative and to follow through on projects. Creative writing ability. Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment. Must have legal right to work in the U.S. At SiriusXM, we carefully consider a wide range of factors when determining compensation, including your background and experience. These considerations can cause your compensation to vary. We expect the base salary for this position to be in the range of $128,000 to $170,000 and will depend on your skills, qualifications, and experience. Additionally, this role might be eligible for discretionary short-term and long-term incentives. We encourage all interested candidates to apply. Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws. The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice. R-2024-05-101",
        "url": "https://www.linkedin.com/jobs/view/3949994564"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3910303407,
        "company": "Bunkerhill Health",
        "title": "Software Engineer - Backend",
        "created_on": 1720636161.0814445,
        "description": "About The Role We are seeking a talented and enthusiastic Backend Software Engineer to join our team. As a Backend Software Engineer, you will work closely with our team to develop, test, and maintain software solutions that meet our clients' needs, and play a pivotal role in ensuring seamless integration and deployment of our cutting-edge solutions for our clients. Responsibilities: Collaborate with team members to understand project requirements and translate them into technical specifications. Develop high-quality, maintainable code following best practices and coding standards. Participate in code reviews to ensure code quality and share knowledge with team members. Assist in troubleshooting, debugging, and resolving software issues. Stay updated on emerging technologies and contribute ideas to improve our software development processes. Requirements: 3+ years of full-time experience in software engineering in a dynamic, fast-paced environment. Bachelor's or post graduate degree in Computer Science, Software Engineering, or a related field. Proficiency in Python. Familiarity with common frameworks (Django, celery) is a plus. Familiarity with version control systems (e.g., Git). Excellent problem-solving and analytical skills. Good communication and teamwork abilities. Benefits Competitive salary and equity package Comprehensive health, dental, and vision benefits Hybrid work schedule (3 days in office) Professional development opportunities Dynamic and inclusive work culture with a focus on innovation and collaboration",
        "url": "https://www.linkedin.com/jobs/view/3910303407"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3926330564,
        "company": "Cardless",
        "title": "Senior Software Engineer - Backend",
        "created_on": 1720636162.6813655,
        "description": "At Cardless, we’re building a credit card and loyalty platform that consumer businesses use to engage their customers. We’ve launched 9 credit cards, including for the largest mall operator in the U.S. and the largest airline in South America. We help businesses bring imaginative card programs to life, and have pioneered technology to embed credit card features natively into their products. We value curiosity, humility, and intensity — we move fast and take ownership. This is a place where a motivated, resourceful individual can have an enormous impact on our trajectory. We're headquartered in San Francisco, and have raised about $60M in equity funding from top venture capital firms and angels. ——— Role Cardless is looking for an experienced backend engineer to join our exceptional team! Powering digital-first and consumer-friendly credit cards is no easy task! Behind the scenes, we need to integrate with a number of third-party services (like card networks, payment processors, and credit bureaus), solve tricky distributed systems problems (like eventual consistency and idempotent workflows), and balance a number of needs (like security, reliability, performance, time-to-market, and compliance). We achieve much of that today through a microservice architecture built primarily with Java, gRPC, and AWS tools like DynamoDB, EKS (hosted Kubernetes), and API Gateway. We also use services like Datadog (observability), LaunchDarkly (feature flags & experimentation), and VeryGoodSecurity (tokenization) to achieve a lot with a little. We have an exciting Product and Platform roadmap for 2024 and are seeking Backend Engineers with diverse backgrounds & complementary skillsets who are passionate about building quality systems & services and achieving real-world impact. You may be a generalist who's excited to work in many domains, or you may prefer to go deep in a few (e.g. helping us build an extensible rules engine or a highly reliable ledger). Besides writing & reviewing code, you'll plan work, write tech specs & review design docs, lead projects, collaborate across disciplines (e.g. with PM, design, compliance & partnerships), and mentor other engineers. Requirements Research has shown that women & underrepresented minorities read lists of requirements and consider themselves unqualified if they don't meet every single one. This list represents what we're ideally looking for, but we encourage you to apply even if you don't meet everything 100%. Everyone has unique strengths & weaknesses, and we hire for strength & potential, not lack of weakness. Experience designing backend services & systems and scaling them in production. This is more important to us than a specific # of years of experience, but we expect most engineers to need at least 3-5 years in the industry to gain this experience Experience leading projects, planning work, collaborating cross-functionally, and mentoring other engineers. A high-functioning, collaborative, and supportive environment is important to us, and you'll play an important role in fostering that Broad, high-level expertise across a modern application stack (covering e.g. databases, infrastructure, CI/CD, APIs, client apps, queueing, etc.) Deep, low-level expertise in one or more backend domains (e.g. databases, scaling, or distributed systems), in the technology/platform of your choice Passion for both your craft (building things right) and achieving real-world impact (building the right things for our business & customers) Benefits We're headquartered in San Francisco, CA, with a beautiful office in the Mission District. We're proud to offer our team excellent benefits: 💸 Meaningful Start-up equity 🏥 100% health, vision & dental primary coverage ➕ 75% health, vision & dental dependent coverage 🍱 Catered lunches 🚎 $250/month Commuter benefit 👶 Parental leave ✈️ Team building events & happy hours 🌴 Flexible PTO with a minimum of 15 days off per year 🖥️ Apple equipment 💸 401k plan ——— Cardless employees are required to be fully vaccinated and boosted against COVID-19, and to provide proof of vaccination prior to their first day. Cardless is an equal opportunity employer, and we value a diverse and inclusive workplace. We do not discriminate on the basis of race, national origin, ethnicity, gender, gender identity, sexual orientation, protected veteran status, disability, age, or any other applicable legally protected characteristics. Actual compensation is influenced by a wide array of factors including but not limited to skills, experience, and specific work location.",
        "url": "https://www.linkedin.com/jobs/view/3926330564"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3948737922,
        "company": "Google",
        "title": "Software Engineer III, Machine Learning, Google Workspace",
        "created_on": 1720636164.4670134,
        "description": "Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning and/or natural language processing. Preferred qualifications: Master's degree or PhD in Computer Science or related technical fields. 2 years of experience with performance, large scale systems data analysis, visualization tools, and/or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About the job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.The web is what you make of it and our team is helping the world make more of the web. From open-source pros to user-experience extraordinaires, we develop products that help users connect, communicate and collaborate with others. Our consumer products and cloud platforms are giving millions of users at homes, businesses, universities and nonprofits around the world the tools that shape their web experience -- and changing the way they think about computing. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3948737922"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3940840645,
        "company": "CloudKitchens",
        "title": "Software Engineer, Cloudkitchens - Mountain View",
        "created_on": 1720636166.161355,
        "description": "Who We Are CloudKitchens helps restaurateurs around the world succeed in online food delivery - our goal is to make food more affordable, higher quality and convenient for everyone. We take underutilized properties and transform them into smart kitchens so they can better serve restaurateurs, customers and the neighborhoods they’re in. Every time we launch a new facility we create jobs in that neighborhood, and we’re proud to provide a wide range of cuisines and options for healthy food at an affordable price. We're changing the game for restaurateurs whether they’re entrepreneurs opening their first restaurant all the way through to your favorite global quick-service restaurant chains. Who You Are: A passionate software engineer with at least 4 years of experience in backend development, preferably using Go or Java. A problem-solver who thrives in tackling diverse technical challenges and demonstrates a clear track record of growth and learning. A take-charge individual who exhibits ownership and takes pride in writing clean, maintainable, and fun code. What You'll Do: Build & evolve scalable, reliable distributed systems to solve key business challenges. Own & improve the core infrastructure (message bus, sharding service etc.) that powers the business-critical applications. Simplify infrastructure with abstractions for developing robust multi-region active-active software. Actively participate in contributing to the team's open-source efforts. Bonus Points: Expertise in Go development is a major plus. Experience building distributed applications is highly valued. Familiarity with PSQL, CockroachDB, Kubernetes (k8s), and the software development lifecycle (SDLC) is a significant advantage. Why join us Growing market: You’ll be focused on an $80 billion market that’s projected to reach at least $500 billion by 2030 in the US alone. Changing the restaurant industry: You’ll be part of a team that helps restaurants succeed in online food delivery. Collaborative environment: You will receive support and guidance from experienced colleagues and managers, helping you to learn, grow and achieve your goals, and you’ll work closely with other teams to ensure our customer’s success. What Else You Need To Know This role is based in our Mountain View office. We believe that people do their best work when they are together. As a company, we’re in the marketplace of ideas and innovation. When you’re constantly innovating, changing how an industry works, inventing new products and processes - and we are doing all these things - we believe we’re better as a team in-person. That’s why all of our teams (except for our field-based roles) are now working from one of our office locations 5 days a week Looking forward to sharing more about a Career of Substance at Cloudkitchens! Ready to join us as we serve those who serve others?",
        "url": "https://www.linkedin.com/jobs/view/3940840645"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3927944044,
        "company": "Varo Bank",
        "title": "Sr. Software Engineer, Backend",
        "created_on": 1720636167.7383447,
        "description": "Varo is an entirely new kind of bank. All digital, mission-driven, FDIC insured and designed for the way our customers live their lives. A bank for all of us. The Backend Engineering Team at Varo Bank is small but is growing rapidly. The Backend engineering team is responsible for building and maintaining engineering solutions that power Varo’s core banking, lending, authentication, risk, offers, and marketplaces to achieve our goal to disrupt the banking industry and build products that help improve the financial well-being of our customers. You will get to work with new technology stacks, be part of a great and diverse workplace, and improve the financial lives of others. In our Engineering team, we value personal growth, initiative and ownership, innovation, collaboration, and the importance of thinking like an engineer while building customer-first products. What you'll be doing: Partner with the engineering team to help design, build and evolve the lending infrastructure for a bank for all of us Design and build scalable distributed solutions that our customers can build their lives around Work cross-functionally with various engineering and product teams to build the next-generation lending platform Work projects from ideation to creation with a customer-first mindset Participate in code reviews to main code quality and distribute knowledge Work on large projects from ideation to delivery Be involved in the technical strategy and with a drive to improve products, infrastructure, processes, or organizations Write well-designed, well-tested, readable, and maintainable code You’ll bring the following required skills and experiences: 3+ years of industry experience in software development, preferably JAVA Understanding of microservices and event-driven programming Experience in building public and internal APIs Experience in strong consistency in a distributed environment, transactional databases, and caching systems Understanding of the software security practices Experience with unit and integration testing Experience with scalable, distributed systems with a test-first approach A basic understanding of financial systems (banking, lending, payments) will catch our attention You love making complicated things, simple Knowledge of databases, caching, consistency, etc We recognize not everyone will have all of these requirements. If you meet most of the criteria above and you’re excited about the opportunity and willing to learn, we’d love to hear from you! About Varo Varo launched in 2017 with the vision to bring the best of fintech into the regulated banking system. We’re a new kind of bank – all-digital, mission-driven, FDIC-insured, and designed around the modern American consumer. As the first consumer fintech to be granted a national bank charter in 2020, we make financial inclusion and opportunity for all a reality by empowering everyone with the products, insights, and support they need to get ahead. Through our core product offerings and suite of customer-first features, we aim to address a broad range of consumer needs while profitably serving underserved communities that have been historically excluded from the traditional financial system. We are growing quickly in our hub locations of San Francisco, Salt Lake City, and Charlotte along with colleagues located across the country. We have been recognized among Fast Company’s Most Innovative Companies, Forbes’ Fintech 50, and earned the No. 7 spot on Inc. 5000’s list of fastest-growing companies across the country. Varo. A bank for all of us. Our Core Values - Customers First - Take Ownership - Respect - Stay Curious - Make it Better Learn more about Varo by following us: Facebook - https://www.facebook.com/varomoney Instagram - www.instagram.com/varobank LinkedIn - https://www.linkedin.com/company/varobank Twitter - https://twitter.com/varobank Engineering Blog - https://medium.com/engineering-varo SoundCloud - https://soundcloud.com/varobank Varo is an equal opportunity employer. Varo embraces diversity and we are committed to building teams that represent a variety of backgrounds, perspectives, and skills. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. Beware of fraudulent job postings! Varo will never ask for payment to process documents, refer you to a third party to process applications or visas, or ask you to pay costs. Never send money to anyone suggesting they can provide work with Varo.  If you suspect you have received a phony offer, please e-mail careers@varomoney.com with the pertinent information and contact information. CCPA Notice at Collection for California Employees and Applicants: https://varomoney.box.com/s/q7eockvma9nd2b0utwryruh4ze6gf8eg For cash compensation, we set standard ranges for all US-based roles based on function, level, and geographic location, benchmarked against similar-stage growth companies. Per applicable law, the salary range for this role is $150,000 - $190,000. Final offer amounts are determined by multiple factors as well as candidate experience and expertise and may vary from the identified range.",
        "url": "https://www.linkedin.com/jobs/view/3927944044"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Diego, CA",
        "job_id": 3910235235,
        "company": "Brain Corp",
        "title": "Senior Data Engineer",
        "created_on": 1720636169.4618852,
        "description": "Brain Corp is a San Diego, California, USA-based AI company creating transformative core technology for the robotics industry. Our purpose is to create autonomous technology that helps the real world work better. Brain's robotic and AI solutions help retailers ensure that the right product is on the right shelf at the right price, in a clean environment. Through the BrainOS® Robotics Platform, which powers the largest global fleet of the Autonomous Mobile Robots (AMRs) in operation in commercial public spaces, Brain Corp delivers insightful and efficient automated solutions in both commercial floor cleaning and inventory management, empowering organizations and their employees to achieve more. Brain Corp currently powers more than 30,000 AMRs, representing the largest fleet of its kind in the world. Brain Corp is funded by the SoftBank Vision Fund, Clearbridge, and Qualcomm Ventures. Position Summary As a member of our Software Engineering team, the Senior Data Engineer will lead the development of data-centric products that enhance our innovative BrainOS platform. This individual will be responsible for designing, constructing, and maintaining the systems and infrastructure to facilitate efficient collection, storage, and analysis of large sets of data. The Senior Data Engineer will have a strong foundation in computer science or software engineering, supplemented but significant experience in data storage and processing technologies. Exceptional problem-solving abilities, effective communication skills, and a proven capability to collaborate effectively within a team are crucial to excel in this role. Essential Job Functions Development of Data Pipelines: Design, develop, and maintain robust data pipelines to collect, process, and store large volumes of data. Data Architecture and Design: Design and implement complex data models. Optimize data storage and retrieval processes to support data analytics and business intelligence (BI) applications. Optimize Performance and Scalability: Enhance the efficiency and and scalability of data pipelines and storage systems by identifying bottlenecks, implementing partitioning and sharding, and configuring cluster resources. Collaborate and Support: Collaborate with data analysts, data scientists, and other business teams to support data-related technical issues and support their data infrastructure needs. Mentor Junior Engineers: Offer guidance and mentorship to junior data engineers, oversee code reviews, and monitor performance. Quality Assurance and Documentation: Ensure data integrity and compliance with quality standards. Documenting the data engineering processes, systems, and their interactions. Data Security: Champion robust security measures leveraging encryption and access controls capable of passing regular compliance auditing. Assist in other duties and projects as assigned. Education And/or Work Experience Requirements BS or MS in Computer Science or applicable engineering discipline. 5-10 years of proven software development experience, with at least 3-5 of those years specifically focused on data engineering. Proven track record of successful project completion that leverages data to drive business decisions. Required Knowledge, Skills, Abilities, And Other Characteristics Strong proficiency in SQL as well as one or more programming languages such as Python, Go, or Typescript. Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in data modeling and understanding of complex data structures, along with a solid grasp of database design principles. Familiar with data warehousing and storage systems such as BigQuery, Firestore, Redshift, Snowflake, MySQL, PostgreSQL. Familiar with data pipeline and ETL development frameworks such as Apache Beam, DBT, Google Dataflow, Pub/Sub. Understanding of data security best practices and experience with technologies such as encryption and data masking. Excellent communication skills. Things That Make a Difference Experience with machine learning models and data science methodologies. Experience with Google Cloud and their data ecosystem. Familiarity with BI tools (e.g., Tableau, Power BI) and data framework (e.g., Hadoop, Spark). Experience with infrastructure as code (eg. Terraform, Pulumi), and containerization and orchestration tools (eg. Docker, Kubernetes). Physical Demands The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Essential functions may require maintaining the physical condition necessary for sitting, walking or standing for periods of time; operating a computer and keyboard; use of hands to finger and grasp; talk and hear at normal room levels; visual acuity to determine the accuracy, neatness, and thoroughness of the work assigned or to make general observations of facilities or structures; push or pull up to 20 pounds. Work Environment The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. The noise level in the work environment is usually quiet to moderate. Employees are exposed to the typical office environment with computers, printers and telephones. Salary Range The anticipated salary range for candidates who will work in San Diego, California is $133,565 to $161,684. The final salary offered to a successful candidate will be dependent on several factors that may include but are not limited to the type and length of experience within the job, type and length of experience within the industry, education, etc. Brain Corp is a multi-state employer and this salary range may not reflect positions that work in other states. In addition to base pay, our competitive total rewards package consists of: A discretionary annual target bonus Stock options 401(k) plan with match (no waiting period and immediate vesting) Comprehensive suite of insurance benefits for employees (and their families) to include a variety of medical plan options (including an HSA with employer contribution), dental, vision, life and disability insurance, Employee Assistance Program (EAP), Legal/Identity support plans, pet insurance. Access to Flexible Spending Accounts (Medical and Dependent Care) Generous paid time off including flexible vacation, Paid Sick Leave, time off for volunteering in the community, 10 paid company holidays, and a winter company shutdown Additional Perks Include Daily on-site lunch available in the San Diego office On-campus gym including pool and tennis courts in the San Diego office Opportunities to connect with colleagues including monthly game nights, hikes, wellness challenges, and community events Internal continuous learning events Opportunities to share your own interests and hobbies with the Company",
        "url": "https://www.linkedin.com/jobs/view/3910235235"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3952973700,
        "company": "Faire",
        "title": "Staff Data Engineer",
        "created_on": 1720636171.2546723,
        "description": "About Faire Faire is an online wholesale marketplace built on the belief that the future is local — independent retailers around the globe are doing more revenue than Walmart and Amazon combined. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants. By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We’re looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours. About The Role Do you want to use data to help drive the direction of Faire's product features that impact small and medium businesses (SMB)? If yes, we want to talk to you. We're looking for a leader in our Core Data Infrastructure team to work closely with Product and Strategy Analysts, Data Scientists, and Software Engineers to support product launches and roadmaps by building the data models and related pipelines that inform and drive insights. In this role, you'll see a direct link between your work, company growth, and user satisfaction. You'll work with A tier players, work with one of the richest data sets in the world, use cutting-edge technology, and see your efforts affect products and SMBs regularly. Job Description & What You Will Do The ideal candidate will have strong analytics engineering, an understanding of data infrastructure and data architecture skills, a proven track record of leading and scaling analytics engineering / business-initiatie teams, strong operational skills to drive efficiency and speed, strong project management leadership, and a strong vision to lead the team. Develop and execute a strategic vision for the Core Data Infrastructure platform (BI and Data Warehousing) at the product pillar and enterprise levels. Optimize processes for operational excellence in project management and system reliability. Lead a scalable BI and Data Warehousing team, fostering collaboration with cross-functional teams. Oversee data warehouse plans, aligning them with strategic goals for various product pillars. Drive the design and deployment of new data models and pipelines to enhance data infrastructure. Ensure and promote data quality standards for accurate and reliable insights. Embrace emerging technologies with enthusiasm. Direct the delivery of impactful dashboards and data visualizations. Define and manage SLAs for data sets and processes in production, ensuring performance benchmarks are met Minimum qualification Over 5+ years of Business Intelligence (BI) and Data Warehousing expertise. Proven track record in scaling and overseeing teams of 4+ individuals. Demonstrated communication and leadership skills, with a history of initiating and steering successful projects. Hands-on development experience in at least one object-oriented language, Python or Java. Expert SQL proficiency with proven competencies in designing well-architected data models, optimizing query performance, and documenting code. Experience and strong knowledge of data warehousing concepts, big data technologies, and analytics platforms. Experience implementing and/or owning enterprise BI tooling (Looker, Tableau, or similar visualization/dashboarding tool). Experience working with DBT or similar analytics workflow tools, as well as airflow and git workflows Project management experience. Holds a BA/BS degree in Computer Science, Math, Physics, or a related technical field. Salary Range San Francisco*: the pay range for this role is $209,500 to $288,000 per year. This role will also be eligible for equity and benefits. Actual base pay will be determined based on permissible factors such as transferable skills, work experience, market demands, and primary work location. The base pay range provided is subject to change and may be modified in the future. Faire’s flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that’s mainly in the office, remotely, or a mix of both. Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option. Applications for this position will be accepted for a minimum of 30 days from the posting date. Why you’ll love working at Faire We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is taking part in the founding process. We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners. We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy. We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality. Faire was founded in 2017 by a team of early product and engineering leads from Square. We’re backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog. Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression. Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form (https://bit.ly/faire-form)",
        "url": "https://www.linkedin.com/jobs/view/3952973700"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3925338147,
        "company": "Amazon",
        "title": "Senior Data Engineer, Alexa Devices",
        "created_on": 1720636173.3261564,
        "description": "Description The Alexa Echo Device Team is looking for a talented, highly motivated Data Engineer to join our Business Intelligence team. Alexa is the groundbreaking cloud-based intelligent agent that powers Echo and other devices designed around your voice. We provide actionable business insights that inform future products and services that will power the next generation of Echo and Alexa devices. As a Senior Data Engineer, you will work in one of the world's largest and most complex data warehouse environments. You will work closely with Product Management, Software Development, Data Science, and other Data Engineering teams to develop scalable and innovative analytical solutions, process and store terabytes of low latency structured and unstructured data, and enable the Echo Device team to build successful, data driven strategies. You will be responsible for designing and implementing an analytical environment using third-party and in-house tools and using Python, Scala, or Java to automate the ETL, analytics, and data quality platform from the ground up. You will design and implement complex data models, model metadata, build reports and dashboards, and own data presentation and dashboarding tools for the end users of our data products and systems. You will work with leading edge technologies like Redshift, EMR, Hadoop/Hive/Pig, and more. You will write scalable, highly tuned SQL queries running over billions of rows of data and will develop learning and training programs to drive adoption of data driven decision making across the Echo and Alexa organization. You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to implement efficient and scalable ETL solutions. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to replicate data from production systems into the BI data store. Key job responsibilities Work with the product and development teams within Alexa org to understand the product vision and requirements. Work with Product Managers, BI engineers and Software Engineers to design, implement and support high quality data products. Partner with other teams across Alexa to ingest relevant datasets into the Alexa Devices BI data-warehouse. Collaborate with other data engineers within the team to build a data platform that is self-service and possesses key capabilities like data discovery, data lineage, proactive data monitoring and security/compliance monitoring. Leverage and manage AWS services like Bedrock, Sagemaker, S3, Redshift, Athena, Kinesis, Lambda, Data Lake etc.. Conduct workshops and lunch-n-learn sessions to educate customers on product capabilities. Basic Qualifications 5+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Experience with SQL Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS Experience mentoring team members on best practices Preferred Qualifications Experience with big data technologies such as: Hadoop, Hive, Spark, EMR Experience operating large data warehouses Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $139,100/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon.com Services LLC Job ID: A2642703",
        "url": "https://www.linkedin.com/jobs/view/3925338147"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 2961690008,
        "company": "Databricks",
        "title": "Senior Software Engineer - Database Engine Internals",
        "created_on": 1720636175.0800073,
        "description": "P-97 Our mission at Databricks is to radically simplify the whole data lifecycle from ingestion to ETL, BI, and all the way up to ML/AI with a unified platform. To achieve this goal, we believe the data warehouse architecture as we know it today will be replaced by a new architectural pattern, Lakehouse (CIDR 2021 paper), open platforms that unify data warehousing and advanced analytics. The new architecture will help address several major challenges, including data staleness, reliability, total cost of ownership, data lock-in, and limited use-case support. A critical part of realizing this vision is the next generation (decoupled) query engine and structured storage system that can outperform specialized data warehouses in relational query performance, yet retain the expressiveness and of general purpose systems such as Spark™ to support diverse workloads ranging from ETL to data science. As Part Of This Team, You Will Be Working In One Or More Of The Following Areas To Design And Implement These Next Gen Systems That Leapfrog State-of-the-art Query compilation and optimization Distributed query execution and scheduling Vectorized execution engine Data security Resource management Transaction coordination Efficient storage structures (encodings, indexes) Automatic physical data optimization What We Look For A passion for database systems, storage systems, distributed systems, language design, or performance optimization Experience working towards a multi-year vision with incremental deliverables Motivated by delivering customer value and impact 5+ years of experience working in a related system (preferred) Optional: PhD in databases or distributed systems Benefits Comprehensive health coverage including medical, dental, and vision 401(k) Plan Equity awards Flexible time off Paid parental leave Family Planning Gym reimbursement Annual personal development fund Work headphones reimbursement Employee Assistance Program (EAP) Business travel accident insurance Mental wellness resources Pay Range Transparency Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here. Local Pay Range $166,000—$225,000 USD About Databricks Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. Compliance If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.",
        "url": "https://www.linkedin.com/jobs/view/2961690008"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3926347343,
        "company": "CentML",
        "title": "Software Engineer - Platform",
        "created_on": 1720636176.7580314,
        "description": "About Us We believe AI will fundamentally transform how people live and work. CentML's mission is to massively reduce the cost of developing and deploying ML models so we can enable anyone to harness the power of AI and everyone to benefit from its potential. Our founding team is made up of experts in AI, compilers, and ML hardware and has led efforts at companies like Amazon, Google, Microsoft Research, Nvidia, Intel, Qualcomm, and IBM. Our co-founder and CEO, Gennady Pekhimenko, is a world-renowned expert in ML systems who holds multiple academic and industry research awards from Google, Amazon, Facebook, and VMware. Overview: We are seeking highly motivated and skilled systems engineers to join our team to help in developing the CentML platform that offers a cost effective infrastructure for serving and training large scale machine learning models. As a systems engineer, you will play a crucial role in building a unified solution that brings our innovative in-house technologies such as Hidet compiler, DeepView, and other ML optimizations into a single, cohesive platform. Your expertise will drive the scalability, performance, and reliability of the platform, enabling our customers to seamlessly access and utilize a comprehensive suite of ML services that we offer. Responsibilities: Taking part in the design and development of the CentML platform Designing and building solutions for scheduling large scale ML training and inference workloads on GPU clusters over multiple CSPs Communicate with our product teams and define use cases, and develop methodology & benchmarks to evaluate different approaches Qualifications: Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Graduate degree with research experience is a plus Experience building large scale systems from scratch. Prior experience in container-based deployment systems like Kubernetes is a big plus Strong coding skills (in at least one of Python and C++) Solid fundamentals in other computer science and computer engineering topics: algorithms and data structures, operating systems, computer architecture, etc Benefits & Perks An open and inclusive culture and work environment Fully stocked kitchen at the office Full health and dental benefits Parental Leave top-up for 6 months Continuous education budget Generous vacation - we're not saying unlimited, but if you need extra time to recharge, just ask At CentML, we celebrate our differences and value cultivating an inclusive environment for all. We welcome applications of all kinds and are committed to providing an equal opportunity process.",
        "url": "https://www.linkedin.com/jobs/view/3926347343"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3953609739,
        "company": "Google",
        "title": "Software Engineer III, Infrastructure, Google Cloud Compute Infrastructure",
        "created_on": 1720636178.5929525,
        "description": "Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. 2 years of experience with developing large-scale infrastructure, distributed systems or networks, or experience with compute technologies, storage or hardware architecture. Preferred qualifications: Master's degree or PhD in Computer Science or related technical fields. 2 years of experience with performance, large scale systems data analysis, visualization tools, and/or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About the job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3953609739"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Santa Clara, CA",
        "job_id": 3960513183,
        "company": "Palo Alto Networks",
        "title": "Sr Software Engineer (URL Filtering)",
        "created_on": 1720636180.3587584,
        "description": "Our Mission At Palo Alto Networks® everything starts and ends with our mission: Being the cybersecurity partner of choice, protecting our digital way of life. Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are. Our Approach to Work We lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your wellbeing support to your growth and development, and beyond! At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together! Job Description Your Career As a member of the Advanced URL Filtering (Internet Security) Infrastructure and Data Science Team, you will work closely with data scientists, security researchers, and other engineers on implementing different projects to detect and defend against various emerging threats in the areas of Web Security. You will build big data and distributed systems that use machine learning and deep learning models to analyze and categorize an enormous amount of URLs. You will be a key person in transforming ideas into products which are part of the next generation security platform. The Internet Security Research Team is responsible for innovating new security techniques. Your Impact Build and maintain threat research systems for both customer-facing products and internal infrastructures Work closely with team members and Product Managers to collect product requirements, create design drafts, and develop functional specifications Implement solutions by adhering software development guidelines and best practices Work with SREs on production release/deployment and monitoring Qualifications Your Experience Creative thinker and team player, with good communication skills and desire to make differences Proficient in one or more programming languages such as Golang, Python, Java, or Scala Ability to design, implement, and deploy backend services and data pipelines -conduct regression and integration tests Proficient in cloud platforms (GCP, AWS, Azure) and container-based development (Docker, Kubernetes) Proficient in Linux OS and shell scripting Proficient in database systems such as MongoDB, MySQL, or similar Experience with Big data, distributed systems, and ETL pipelines such as Spark Have basic knowledge of Machine Learning and Web Content Classification Basic knowledge of Front-End and Javascript is a plus Hands-on and humble attitude, self-directed and passion in cybersecurity BS/MS Majored in Computer Science or Computer Engineering -BS with 3+ years industrial experience or equivalent military experience required Additional Information The Team We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment. Our Commitment We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together. We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com . Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics. All your information will be kept confidential according to EEO guidelines. The compensation offered for this position will depend on your degree or progress toward degree , qualifications, experience, and work location. For candidates who receive an offer, the starting rate is expected to be $175,000/yr for the specific role.",
        "url": "https://www.linkedin.com/jobs/view/3960513183"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco Bay Area",
        "job_id": 3961905453,
        "company": "Rippling",
        "title": "Staff Data Engineer",
        "created_on": 1720636182.061229,
        "description": "About The Role We are looking for an experienced data engineer to join our fast-growing data engineering team. As one of the senior-most members of the team, you will be leading the design and development of data pipelines and services to enable data-driven decision-making, and power BI, ML, experimentation, and user-facing features. You are expected to work closely with stakeholders across a variety of orgs, such as Data Science, Marketing, Bizops, RevOps, Finance, and adjacent data teams to drive projects forward and support the professional development of junior team members. Here’s an idea of some of the initiatives you could be working on: Building custom data pipelines using Airflow and AWS resources Setting up high-velocity data streaming consumers Regionalizing our data infrastructure and services Building out a data masking and suppression system for handling sensitive data What You'll Do Architect, build, and scale our data pipelines for ingesting data from internal databases and systems, and third-party tools into our warehouse Help build out our data lake and real-time infrastructure and tooling on AWS Support analytics, data science, machine learning, and business operations functions Monitor and maintain pipelines and infrastructure to uphold internal SLAs Qualifications 8+ years of experience in data and software engineering Expertise in writing complex data transforms in SQL and Python Knowledge of data warehousing concepts around building custom ETL integrations, and building data infrastructure (SCD, CDC, Snapshots, indexing, partitioning) Knowledge of Data Security and Governance (nice to have) Experience in analytics, dimensional modeling, and ETL optimization preferred BS/BA in a technical field such as Computer Science or Mathematics preferred Additional Information Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com Rippling highly values having employees working in-office to foster a collaborative work environment and company culture. For office-based employees (employees who live within a 40 mile radius of a Rippling office), Rippling considers working in the office, at least three days a week under current policy, to be an essential function of the employee's role. This role will receive a competitive salary + benefits + equity. The salary for US-based employees will be aligned with one of the ranges below based on location; see which tier applies to your location here .",
        "url": "https://www.linkedin.com/jobs/view/3961905453"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco Bay Area",
        "job_id": 3957614216,
        "company": "Fathom",
        "title": "Software Engineer (Backend/Data)",
        "created_on": 1720636186.2004619,
        "description": "Fathom is on a mission to use AI to understand and structure the world’s medical data, starting by making sense of the terabytes of clinician notes contained within the electronic health records of the world’s largest health systems. Our deep learning engine automates the translation of patient records into the billing codes used for healthcare provider reimbursement, a process today that costs hospitals in the US $15B+ annually and tens of billions more in errors and denied claims. We are a venture-backed company that completed a Series B round of financing for $46M in late 2022. We are looking for an Software Engineer (Backend/Data) to work on data products that drive the core of our business. We want to work with teammates based in the San Francisco Bay area, who are excited about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration. If you’d like to become a backend expert who can unify data, and build systems that scale for both operations and organization, then Fathom is your next big opportunity! Your role and responsibilities will include: Developing data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs Building performant and expressive interfaces to the data Creating infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning We are looking for a teammate with: 2+ years of software engineering experience in a company/production setting Relevant experience developing backend, integrations, data pipelining, infrastructure, etc. projects in a production setting Problem solving skills and first principles thinking Strong computer science principles including: algorithms, data structures, logic, etc. Hands-on backend coding and/or systems design using best practices in a company setting Effective communication and exceptional collaboration skills Bonus points if you have: Proficiency in coding with python or another modern backend language Expertise with wrangling healthcare data and/or HIPAA Experience with managing large-scale data labelling and acquisition Compensation: Salary: $100,000 USD - $175,000 USD Company Equity Benefits: PTO and Uncapped Sick Days Medical/Dental/Vision Coverage 401k Matching $1,500 USD Home Office Budget Virtual and Local Office (San Francisco, New York City and Toronto) Team Building Events Annual Company Off-site",
        "url": "https://www.linkedin.com/jobs/view/3957614216"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3908050669,
        "company": "Enexus Global Inc.",
        "title": "Senior Data Engineer - W2 / 1099 only",
        "created_on": 1720636187.8119226,
        "description": "Role - Senior Data Engineer Location - Sunnyvale, CA (hybrid) Contract Type - W2/1099 only Minimum Experience - 11+ Years Responsibilities Develop and enhance data-processing, orchestration, monitoring, and more by leveraging popular open-source software, AWS, and GitLab automation. Collaborate with product and technology teams to design and validate the capabilities of the data platform Identify, design, and implement process improvements: automating manual processes, optimizing for usability, re-designing for greater scalability Provide technical support and usage guidance to the users of our platform's services. Drive the creation and refinement of metrics, monitoring, and alerting mechanisms to give us the visibility we need into our production services. Qualifications Experience building and optimizing data pipelines in a distributed environment Experience supporting and working with cross-functional teams Proficiency working in Linux environment 8+ years of advanced working knowledge of SQL, Python, and PySpark 5+ years of experience with using a broad range of AWS technologies Experience using tools such as: Git/Bitbucket, Jenkins/CodeBuild, CodePipeline Experience with platform monitoring and alerts tools",
        "url": "https://www.linkedin.com/jobs/view/3908050669"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3970217404,
        "company": "Meritence",
        "title": "Backend Engineer, SQL",
        "created_on": 1720636189.470901,
        "description": "Coactive is looking for a Backend Engineer in San Jose, CA About Coactive: Coactive makes it easy to search, filter, and analyze visual content. As visual data increasingly captures our content consumption, product purchases, and work, it represents 80% of internet traffic. However, visual content often poses challenges due to its complexity. Coactive brings structure to unstructured visual data, enabling data teams to unlock its value in minutes for use cases such as content understanding, moderation, search, and analytics. Founded by experts from leading organizations like Google, Meta, Pinterest, eBay, and Lyft, Coactive leverages decades of experience in high-performance deep learning and data-centric AI. Our mission is to democratize machine learning systems, making them accessible without requiring a PhD. Join one of Forbes' top 50 AI companies, backed by investors like Andreesen Horowitz and Bessemer Ventures. This is an exceptional opportunity to be part of a category-defining team pushing the boundaries of AI. Position: Backend Engineer As a Backend Engineer at Coactive, you will build highly reliable full-stack applications using foundational AI models. Your role involves designing and developing services to advance data pipelines for video, audio, and image data. You will architect data models for optimal storage and retrieval, supporting high throughput and low latency queries. Collaboration across departments with engineers, product, and research teams will be key to solving complex, high-scale problems. You will work with both structured and unstructured data sources, building performant functionality on top of them. Additionally, you will gain exposure to AI/ML and all parts of the codebase through team discussions. Your expertise will shape our engineering best practices and contribute to our company culture as we grow. What You’ll Do: Build highly reliable full-stack applications that use foundational AI models. Design and develop services to advance data pipelines ingesting video, audio, and image data. Design and architect intricate data models for optimal storage and retrieval to support high throughput, low latency queries. Work with both structured and unstructured data sources, building performant functionality on top of them. Collaborate across departments with engineers, product, and research teams to solve complex high-scale problems. Gain exposure to AI/ML and all parts of the codebase through collaborative team discussions. Shape engineering best practices and company culture as we grow. Requirements: 8+ years of professional experience in web development, microservices architecture, and SQL development. Deep knowledge of database internals, query planning, and optimizations. Proficiency in the design of algorithms, data structures, design patterns, and deploying scalable microservices. Experience with one or more general-purpose programming languages, including Python, Go, or Java (we use Python). Experience working with NoSQL databases (e.g., MongoDB, ElasticSearch) and relational databases (e.g., Postgres). Strong data ingestion fundamentals and meaningful contribution in the area of streaming pipelines and handling high volumes of data. Strong testing ethos and knowledge of best practices, including code quality, accessibility, performance, and security. Preferred Skills: Exposure to big data frameworks like Spark, Kafka. What You Can Expect From Us: Location: San Jose, California (hybrid, with three days in office). Estimated annual base salary: $180,000-$220,000.* Market-leading equity grants. 100% medical, dental, & vision coverage for you. Partial coverage for dependents' medical, dental, & vision. Unlimited PTO. Social events including book clubs, happy hours, hiking, board game nights, and Mario Kart. A supportive work environment focused on personal and professional development. *Actual pay depends on an individual candidate’s professional background, experience, skills, and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.",
        "url": "https://www.linkedin.com/jobs/view/3970217404"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "El Segundo, CA",
        "job_id": 3943672713,
        "company": "Eleven Recruiting",
        "title": "Software Engineer - (Project)",
        "created_on": 1720636191.0541356,
        "description": "Our client, a global investment firm, is seeking a Software Engineer to join their team. Your responsibilities will include developing new features, fixing bugs, creating tools, and ensuring various tools', applications', and platforms' stability. If you have a passion for financial technology, strong technical skills, and a background in investment management, this role is perfect for you. Responsibilities: Design, develop, and implement software applications using Python and/or C# .NET. Write clean, maintainable, and efficient code. Collaborate with cross-functional teams to define, design, and ship new features. Ensure the performance, quality, and responsiveness of applications. Identify and correct bottlenecks and fix bugs. Help maintain code quality, organization, and automatization. Participate in code reviews and contribute to team and organizational improvements. Qualifications: Bachelor's degree in Computer Science, Engineering, or a related field, or equivalent work experience. Minimum 4 years of development experience in a professional environment. Strong proficiency in Python and/or C# .NET . Experience with SQL and database design principles. Familiarity with Azure cloud services and development in an Azure environment. Knowledge of Snowflake and Kubernetes is a plus. Preferred Skills: Experience with Agile development methodologies. Understanding of the full software development life cycle. Excellent problem-solving and communication skills. Ability to work independently and as part of a team. Location: El Segundo, CA Seniority Level: Mid-Senior Level Employment Type: Contract Job Function: Information Technology Salary: $65/ HR - $80/HR",
        "url": "https://www.linkedin.com/jobs/view/3943672713"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Diego, CA",
        "job_id": 3915049285,
        "company": "Amazon",
        "title": "Jr. Software Development Engineer - San Diego, Jr. Developer Program",
        "created_on": 1720636192.846066,
        "description": "Description Amazon is looking for a highly-motivated Jr. Software Development Engineer (SDE)! Jr. SDEs write real software and collaborate with experienced software engineers who provide guidance and opportunities for ownership on projects that matter to our customers. As a year-round intern, Jr. SDEs become fully integrated into their teams and regularly contribute to impactful deliverables. Your design and code will contribute to solving some of Amazon's most complex technical challenges. The Jr. SDE role is part of Amazon's Jr Developer Program - a year-round internship opportunity that offers a symbiotic relationship between work and school. Jrs. receive 1:1 mentoring throughout their time in the program, receiving guidance and insight from a full-time Amazonian on their team. Because of the internship's extended tenure, our Jrs. become immersed in an Amazon team and gain real-life technical experience. Flexible part-time schedules during the school year and full-time employment over the summer creates an environment where students can succeed in both their work and their education. San Diego has a growing population of Jrs, allowing for deep connections with fellow students engaged in similar roles. Upon successful completion of the Jr. Developer Program, the opportunity for full-time employment may be available at an Amazon corporate site. Role Highlights Part-time work during the school year (16 hours/week) Full-time work during the summer (40 hours/week) 1:1 mentoring with an experienced Software Engineer Effective performance management and integrated opportunities for growth We are open to hiring candidates to work out of one of the following locations: San Diego, CA, USA Basic Qualifications Currently enrolled in an accredited college or university Bachelor's or Master's degree program. Majoring in Computer Science, Software Engineering, or related STEM field. Graduating between June 2026 and June 2027. Ability to work year-round until graduation (part-time during the school year and full-time during the summer). Living within commutable distance to San Diego, CA and able to work in-person year-round. Programming experience with at least one modern language such as Java, Python, or C++ including object-oriented design. Preferred Qualifications Previous technical internship(s), if applicable. Ability to effectively articulate technical challenges and solutions. Adept at handling ambiguous or undefined problems as well as ability to think abstractly. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $15/hr in our lowest geographic market up to $75.63/hr in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon.com Services LLC Job ID: A2630256",
        "url": "https://www.linkedin.com/jobs/view/3915049285"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3911892522,
        "company": "Unreal Staffing, Inc",
        "title": "Software Engineer",
        "created_on": 1720636194.3798614,
        "description": "About the Role: We're seeking a talented software engineer to join our early team, specializing in .NET integrations with Windows APIs and Unity development. In this role, you'll play a crucial part in prototyping, designing, and architecting features, libraries, and infrastructure for immersive 3D avatar experiences. Collaboration with fellow engineers and designers, process improvement, and fostering a vibrant team culture are also key aspects of this role. Requirements Requirements: Unity and .NET Expertise: Proficiency in Unity and .NET is essential for building our core Unity experience and integrating it with Windows APIs. Experience in architecting services related to the pipeline is a plus Software Engineering Principles: Familiarity with software engineering principles and best practices is essential. You should possess a solid understanding of modern application architecture and have a portfolio showcasing your own projects Remote Work Culture: Strong written communication skills are paramount due to our fully remote setup. You should be able to effectively communicate ideas, proposals, and decisions online and in-person Bonus Points: Familiarity with or interest in related disciplines such as AR, AI, and consumer software would be advantageous What You'll Do: Prototype, design, and architect features, libraries, and infrastructure for interactive 3D avatar experiences Collaborate with other engineers and designers to improve processes and contribute to a great team culture Benefits Competitive Compensation: A competitive salary and benefits package commensurate with your experience and skills Remote Work Flexibility: Enjoy the flexibility of fully remote work, allowing you to work from anywhere while maintaining a healthy work-life balance Professional Growth: Join a small, dynamic team working on a rapidly expanding product with promising signs of product-market fit, offering ample opportunities for professional growth and advancement Health and Wellness Benefits: Full medical, dental, and vision health coverage, along with a monthly stipend for mental and physical health 401(k) Plan: Secure your financial future with our 401(k) plan Paid Time Off: Unlimited vacation, 7 company holidays including election day, and 1 personal volunteer day per year Collaborative Culture: Join a team that values collaboration, innovation, and continuous learning, with a fun-filled work environment that encourages personal and professional development If you're passionate about pushing the boundaries of interactive experiences and thrive in a collaborative, remote environment, we'd love to hear from you!",
        "url": "https://www.linkedin.com/jobs/view/3911892522"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Fremont, CA",
        "job_id": 3890921023,
        "company": "First Soft Solutions LLC",
        "title": "Sr. Azure Data Engineer",
        "created_on": 1720636195.5815225,
        "description": "We are actively hiring for Sr. Azure Data Engineer C2C Long term Looking for Senior candidates minimum 10+ years of experience. Must Have Enterprise Data modeling / Design Azure SQL Data Warehouse (Synapse) Azure synapse serverless pool T-SQL ( Hands on experience , writing quires , building stored procs, performance optimization , etc..) ADF / Any Enterprise ETL Tool ADLS / any cloud storage Should be able to understand the requirements and convert them into technical specifications , also able to work independently with minimal or no supervision.",
        "url": "https://www.linkedin.com/jobs/view/3890921023"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3919462950,
        "company": "Asana",
        "title": "Software Engineer, LLM Frameworks and Tools",
        "created_on": 1720636197.1555216,
        "description": "With AI, the world is changing. 92% of employees want to use AI to enhance some part of their jobs. At Asana, this means that it isn’t just an exciting technology, but a seismic shift for our business – we deeply believe in its power to help teams work together more effectively, and we’re committed to building safe and ethical solutions to do so. Within the AI Org at Asana, the LLM Frameworks and Tooling Team is responsible for supporting and scaling Large Language Model (LLM) development across all of Asana. We are a team with a broad charter that serves multiple customers – we manage the infrastructure that powers all LLM-based user features at Asana, build the code-level abstractions that enable Asana engineers to use that infrastructure easily, and innovate on tools that allow Asana engineers and product leaders to develop, test, observe, and evaluate new AI features safely, quickly, and with high quality. This role is based in our San Francisco office with an office-centric hybrid schedule. The standard in-office days are Monday, Tuesday, and Thursday. Most Asanas have the option to work from home on Wednesdays. Working from home on Fridays depends on the type of work you do and the teams with which you partner. If you're interviewing for this role, your recruiter will share more about the in-office requirements. What You’ll Achieve Build scalable infrastructure that balance Asana’s costs, values and brand responsibly Simplify AI feature development by creating seamless code-level interfaces with LLMs Create an ecosystem of in-house and third-party tools to enable rapid testing and evaluation of LLM prompts Define and benchmark performance for large-scale Retrieval Augmented Generation (RAG) systems. Analyze problems, consider alternative solutions/trade-offs, and make key technical implementation decisions to help guide the vision of AI development at Asana. Solve scalability challenges to create a best-in-class engineering experience. Support design reviews, communicate constraints, and help engineers make the right trade-offs to develop high-quality code. Evangelize good code, solid engineering and operational excellence. About You 3 to 5 years of experience building software solutions for internal teams and performance optimization work Has worked directly with internal customers to develop a strong understanding of customer needs, and are equally comfortable using the tools they use Good judgment in mitigating risks and building reliable, scalable, and performant systems Excellent communication skills; can effectively explain the “why” behind your decision-making Others around you learn about new technology from your contributions Passionate about creating a superlative user experience for our engineers and PMs Excited to work in an environment where you and your teammates empower one another to become the best versions of yourselves At Asana, we're committed to building teams that include a variety of backgrounds, perspectives, and skills, as this is critical to helping us achieve our mission. If you're interested in this role and don't meet every listed requirement, we still encourage you to apply. What We’ll Offer Our comprehensive compensation package plays a big part in how we recognize you for the impact you have on our path to achieving our mission. We believe that compensation should be reflective of the value you create relative to the market value of your role. To ensure pay is fair and not impacted by biases, we're committed to looking at market value which is why we check ourselves and conduct a yearly pay equity audit. For this role, the estimated base salary range is between $171,000 - $209,000. The actual base salary will vary based on various factors, including market and individual qualifications objectively assessed during the interview process. The listed range above is a guideline, and the base salary range for this role may be modified. In addition to base salary, your compensation package may include additional components such as equity, sales incentive pay (for most sales roles), and benefits. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role. We strive to provide equitable and competitive benefits packages that support our employees worldwide and include: Mental health, wellness & fitness benefits Career coaching & support Inclusive family building benefits Long-term savings or retirement plans In-office culinary options to cater to your dietary preferences These are just some of the benefits we offer, and benefits may vary based on role, country, and local regulations. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role. About Us Asana helps teams orchestrate their work, from small projects to strategic initiatives. Millions of teams around the world rely on Asana to achieve their most important goals, faster. Asana has been named a Top 10 Best Workplace for 5 years in a row, is Fortune's #1 Best Workplace in the Bay Area, and one of Glassdoor’s and Inc.’s Best Places to Work. After spending more than a year physically distanced, Team Asana is safely and mindfully returning to in-person collaboration, incorporating flexibility that adds hybrid elements to our office-centric culture . With 11+ offices all over the world, we are always looking for individuals who care about building technology that drives positive change in the world and a culture where everyone feels that they belong. We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We provide equal employment opportunities to all applicants without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by law. We also comply with the San Francisco Fair Chance Ordinance and similar laws in other locations.",
        "url": "https://www.linkedin.com/jobs/view/3919462950"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3951202928,
        "company": "Walmart",
        "title": "Software Engineer III",
        "created_on": 1720636198.8081484,
        "description": "Position Summary... What you'll do... Develop, maintain and support highly scalable services that serve billions of ad requests About The Team Walmart's Advertising Technology group enables the connection between supplier brands and retail shoppers at unprecedented scale. We are a highly motivated group of engineers and data scientists, working in an agile group to solve sophisticated and high impact problems. We serve billions of ad requests every month with our high-performance ad servers. We build smart data systems that ingest, model, analyze and optimize the massive flow of data from online and store user activity and transactions. We use cutting edge machine learning, data mining and optimization algorithms on this data. Above all, we are laser focused on delivering experiences that our customers and advertisers love. This role is part of our Sponsored Search Ad Server engineering team for Backend Services and will build the next generation omni-advertising platforms to deliver performance and value at scale. What You'll Do Develop clean, organized code Develop unit tests and perform integration testing Provide on-call production support for business critical services Build and maintain services that can handle millions of requests per day to support advertising on Walmart.com and its subsidiaries Work with tech leads and cross functional teams to implement technical solutions for business requirements What You'll Bring Bachelor's or Master's degree in Computer Science (or related field) and 2+ years of experience as a developer 2+ years of experience working on backend services. Experience object-oriented programming language like Java Experience in RDBMS and/or NoSQL Excellent coding and debugging skills Experience designing and implementing REST API web services Experience in Apache Hadoop, Map-reduce, Apache Spark, and in messaging Systems as Kafka Excellent analytical-reasoning and problem-solving skills Excellent communication, timeliness, and a desire to write clean, organized code The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process. About Walmart Global Tech Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail. Who We Are Join Walmart and your work could help approximately 220 million global customers live better every week. Yes, we are the Fortune #1 company. But you'll quickly find we're a company who wants you to feel comfortable bringing your whole self to work. Our mission spreads far beyond the walls of our stores. Here at the world's leading retailer, you can make career defining accomplishments, learn new skills, gain experience from virtually every industry and leverage your expertise to innovate at scale, impact millions and reimagine the future of retail. Discover why we are a world leader in technology, diversity and inclusion, sustainability and community involvement. careers.walmart.com. Benefits & Perks Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Future Ways of Working Our company's success can be attributed to our employees. While technology has allowed us to be effective while working remotely, there is no substitute for being in the office together; it helps to shape our culture, collaborate, innovate, build relationships, and move more quickly. We strive to provide flexibility in order to promote a healthy work-life balance but recognize that in-person interactions are important to our culture and shared success. We'll meet in person on a regular and purposeful basis. Equal Opportunity Employer Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas, and opinions - while being inclusive of all people. At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more. ‎ ‎ ‎ You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. ‎ For information about PTO, see https://one.walmart.com/notices . ‎ ‎ Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart. ‎ Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. ‎ For Information About Benefits And Eligibility, See One.Walmart . ‎ The annual salary range for this position is $117,000.00-$234,000.00 ‎ Additional Compensation Includes Annual Or Quarterly Performance Bonuses. ‎ Additional Compensation For Certain Positions May Also Include ‎ ‎ Stock ‎ ‎ Minimum Qualifications... Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. Option 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 2 years' experience in software engineering or related area.Option 2: 4 years' experience in software engineering or related area. Preferred Qualifications... Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. Customer Service, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart's accessibility standards and guidelines for supporting an inclusive culture. Masters: Computer Science Primary Location... 680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America",
        "url": "https://www.linkedin.com/jobs/view/3951202928"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Pleasanton, CA",
        "job_id": 3849825159,
        "company": "Dwebtech Consulting Inc.",
        "title": "DevOps Engineer",
        "created_on": 1720636200.389403,
        "description": "Position: DevOps Engineer Work Location; Pleasanton, CA or Sanjose, CA (Hybrid) Type:Contract Key Skills: Strong Kubernetes, Terraform Scripting, Data processing – Automation, AWS, AKS, Jenkins etc.. Job Description As the DevOps Engineer, you will play a crucial role in automating the infrastructure, setting up CI/CD pipelines for accelerated software delivery with reduced errors. You will work directly with the supply chain software development team and closely work with software teams in other groups to build common deployment architecture. The team is responsible for building data platform and systems integration either using iPaaS platform or through microservices to support the entire Global Supply Chain. The FE applications are written in ReactJS and deployed as micro frontend & BE services are in Java, Python, Go. The DevOps engineer will collaborate with developers to build robust pipelines for code deployment all the way to production and help with early issue detection and rapid Responsibilities Design, implement, and manage CI/CD pipelines for automated build, test, and deployment processes. Provision, configure, and maintain infrastructure, including servers, networks, and cloud services. Implement and manage containerization technologies (e.g., Docker) and orchestration platforms (e.g., Kubernetes). Monitor system performance, application metrics, and logs using monitoring tools like Grafana, Loki, CloudWatch to ensure the reliability, performance, and security of the data platform. Work closely with security team to Implement security best practices and compliance measures throughout the software development lifecycle. Design and implement backup and disaster recovery solutions for data stored on AWS using services like Amazon S3 versioning, Amazon S3 Cross-Region Replication, Amazon RDS automated backups, Amazon Redshift snapshots, and other data backup and recovery mechanisms. Automate the provisioning and configuration of AWS services such as Amazon EC2 instances, Amazon RDS databases, Amazon Redshift data warehouses, Amazon EMR clusters, and other relevant services using infrastructure-as-code (IaC) tools like Terraform or AWS CloudFormation. Collaborate with development teams to optimize application performance and scalability. Document system configurations, procedures, and best practices to facilitate knowledge sharing and transfer within the team. Qualifications Proven experience as a DevOps Engineer in Software Development organization, 8+ years of hands-on experience of AWS services, k8s (Kubernetes), Docker, CI/CD. 3+ years of experience automating the infrastructure using Terraform (or CloudFormation) on AWS. Experience with Cloud infrastructure management, monitoring, logging & fine tuning, Bachelor’s degree in Computer Science, Engineering or related field 5+ years of hands-on experience with various AWS services relevant to microservices, microfrontend, data management and analytics, including but not limited to Amazon S3, Amazon RDS, Amazon Redshift, Amazon EMR, Serverless, Amazon EKS, Rancher, EC2, IAM. 8+ years of hands-on experience with containerization technologies (e.g., Docker) and container orchestration platforms (e.g., Kubernetes, Rancher). 8+ years of hands-on experience in designing and implementing CI/CD pipelines, version control systems (e.g., Gitlab), and automation tools (e.g., ArgoCD, Jenkins). Knowledge of data governance principles and practices, with experience in managing data quality, lineage, metadata, and compliance using tools like AWS. 3+ years of hands-on in infrastructure-as-code (IaC) tools like Terraform or AWS CloudFormation for provisioning and managing AWS resources in a repeatable and automated manner. Experience in hybrid and multi-cloud development. 5+ years of Working experience with Data platform, Microservices, and Micro frontend technology. Excellent communication and interpersonal skills to effectively collaborate with cross-functional teams.",
        "url": "https://www.linkedin.com/jobs/view/3849825159"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Carlos, CA",
        "job_id": 3559569361,
        "company": "Linbar Solutions Inc. (LSi)",
        "title": "Data Security Engineer",
        "created_on": 1720636202.143419,
        "description": "If you have interest in this position please send resume in word with contact number. Data Security Engineer Salary DOE, stock options, relocation assistance and great perks/benefits. Location: San Carlos, CA No sponsorships. Please answer questions at bottom Job Description Company is looking for a detail-oriented Data Security Engineer who will work at the cutting edge of encryption and data security to ensure that our data is secure and compliant. You will work collaboratively with our engineering and data science teams to protect the security of our product and infrastructure. You will also build and install tools that identify and classify our data. Reporting directly to the Head of Information Security, you will help execute on PCI compliance-related tasks and projects. If you are excited about using the latest tools to manage data exposure risk for one of the most innovative data science models in the fintech industry, this may be the right opportunity for you! Here’s More About What You’ll Be Doing Take ownership of building, managing and monitoring Upstart’s encryption service, adequate access service, and data security controls for external auditors Working closely with engineering and data science teams to safeguard our products Building, refining, and maintaining a company-wide data dictionary, helping us drive and understand sensitive/non-sensitive elements Reporting on sensitive data and its usage in the company Working with the Director of Information Security to map PCI compliance to our infrastructure Requirements: 3+ years of experience in a data security role within a technology or financial services organization Experience managing security controls and driving security policies over Amazon S3 Experience with data classification tools, SQL, and databases (e.g. Postgres, MySQL, Redshift) Strong written and verbal communication Ability to collaborate cross-functionally and communicate effectively with highly technical teams Certifications such as Data privacy certification (e.g. CIPP) will strengthen consideration Job Type: Full-time Application Questions You have requested that Indeed ask candidates the following questions: How many years of data security role experience do you have? How many years of security controls and driving security policies at amazon S3 experience do you have? How many years of SQL, Postgres, MySQL, Redshift experience do you have? How many years of technology or financial field experience do you have? Do you have the following license or certification: Data privacy certification (e.g. CIPP)? Barbara Ensminger Linbar Solutions VP Operations Please Contact Me With Any Questions (w) 423-877-0920 (c) 423-322-3604 Email barbensminger@linbarsolutions.com Visit our careers website to view our current opportunities http://linbarsolutions.catsone.com/careers",
        "url": "https://www.linkedin.com/jobs/view/3559569361"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Redwood City, CA",
        "job_id": 3905004401,
        "company": "Zilliz",
        "title": "Staff Software Engineer, Database Systems",
        "created_on": 1720636203.7487938,
        "description": "About Zilliz Zilliz is a fast-growing startup developing the industry's leading vector database company for enterprise-grade AI. Founded by the engineers behind Milvus, the world's most popular open-source vector database, the company builds next-generation database technologies to help organizations quickly create AI applications. On a mission to democratize AI, Zilliz is committed to simplifying data management for AI applications and making vector databases accessible to every organization. What you will do: Develop distributed database systems using Zilliz's innovative data science platforms. Create request plans, develop new systems, and perform prototype verification and testing. Design and write core architecture code. Provide creative solutions to technical issues that arise during the product development process. Take ownership of product performance and stability. Research emerging technology to optimize the performance of underlying distributed platforms. Manage the Milvus open-source community and broaden Zilliz's reach worldwide. What we are looking for: 4+ years of experience in developing database systems Active contributor to one or more infrastructure software such as Snowflake, CockroachDB, Oracle RDBMS, Google BigQuery, Spanner, Redshift, Aurora, Cosmos DB, MySQL, PostgreSQL, Hudi, Delta Lake, Iceberg, Ray, Spark, Flink, Kafka, Redis, ElasticSearch, etc. Bachelor's degree or above in computer science, software engineering, or other relevant disciplines. Willing to adapt to a fast-changing environment (i.e. the different stages of a startup company) Benefits: Competitive compensation (cash + equity) Regular bonus and equity refresh opportunities Medical, dental, and vision insurance Paid time off, including vacation, sick leave, and global reset/wellbeing days Generous 401(k) and regional retirement plans Zilliz is committed to building an inclusive and diverse workforce. We are an Equal Opportunity Employer and welcome people from all backgrounds, experiences, abilities, and perspectives. All qualified applicants will receive consideration for employment regardless of race, color, national origin, religion, sexual orientation, gender, gender identity, age, physical disability, or length of time spent unemployed.",
        "url": "https://www.linkedin.com/jobs/view/3905004401"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Palo Alto, CA",
        "job_id": 3967495840,
        "company": "EV.Careers",
        "title": "Internship, Software Engineer, Integration (Fall 2024)",
        "created_on": 1720636205.2328289,
        "description": "What To Expect Tesla is a leader in innovative technology, pioneering advancements in autonomous vehicles and humanoid robotics. Our cutting-edge AI platform powers some of the most advanced systems globally, including Autopilot for vehicles and humanoid robots. As an Integration Engineer Intern within our Autonomy teams, you will play a crucial role in advancing our AI platform's integration with vehicles and humanoid robotics. You'll be at the forefront of developing and implementing features that leverage the power of Tesla AI, ensuring seamless functionality across various platforms. Your responsibilities will encompass software development, integration, optimization, and collaboration across multiple functions to achieve our goals. In addition, the team plays a key role in developing safety and reliability specifications for driverless vehicle operation. You would be designing fail-safe mechanisms and redundant architectures to mitigate risks and minimize downtime in autonomous driving scenarios. The team contributes to the development and deployment of new features on both vehicles and robotics platforms. Join us in shaping the future of mobility and robotics technology. What You'll Do Write, debug, and maintain robust C/C++ software for the Autopilot and humanoid robot software stackIntegrate Autopilot features and controls with user interfaces and other vehicle systemsDevelop and iterate on new features through simulation, validation, and fleet data analysisOptimize feature effectiveness while minimizing power consumptionProvide performance data and constructive feedback to hardware design and manufacturing teams to continuously improve processes and system capabilitiesBring up Autonomy features on new vehicle and compute platforms What You'll Bring Practical experience programming in C/C++ software, including modern C/C++ (C++14/17/20), multithreading, and Python. Experience with Cuda/OpenCL is a plusExperience with embedded systems software design conceptsFamiliarity with Computer Vision, Machine Learning, and related software conceptsExperience with automotive communication standards such as CAN, Ethernet, TCP/IPProficiency in developing software on a Linux host, with experience in embedded Linux targets (cross-compilation, etc.) considered a plusExcellent problem-solving, critical thinking, and communication skills Benefits Compensation and Benefits As a full-time Tesla Intern, you will be eligible for: Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction Family-building, fertility, adoption and surrogacy benefits Dental (including orthodontic coverage) and vision plans. Both have an option with a $0 payroll contribution Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Medical Plan with HSA Healthcare and Dependent Care Flexible Spending Accounts (FSA) LGBTQ+ care concierge services 401(k), Employee Stock Purchase Plans, and other financial benefits Company Paid Basic Life, AD&D, and short-term disability insurance Employee Assistance Program Sick time after 90 days of employment and Paid Holidays Back-up childcare and parenting support resources Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance Commuter benefits Employee discounts and perks program Expected Compensation $100,000.0 - $150,000.0/annual salary + benefits Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment. , Tesla",
        "url": "https://www.linkedin.com/jobs/view/3967495840"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Foster City, CA",
        "job_id": 3945668424,
        "company": "Visa",
        "title": "Staff Data Engineer",
        "created_on": 1720636206.9761338,
        "description": "Company Description Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid. Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa. Job Description Visa Technology & Operations LLC, a Visa Inc. company, needs a Staff Data Engineer (multiple openings) in Foster City, CA to Design and implement large-scale data and analytical platform services leveraging database, open source, and cloud technologies. Understand business requirements and data assets andleverage appropriate MPP query processing technologies to solve the business use case. Establish metrics and analytics for monitoring and understanding of the user experiences andoperational status of the data store and analytical platform. Identify platform challenges and design for resilience improvements and implement measures for resilience, self-healing, and recoverability of the platform. Perform troubleshooting, analysis, and performance tuning for customers using the data warehouse, SQL engine, and data analytical platforms. Perform root cause analysis, including implementation of hardened measures that avoid and/or mitigate impact to users in case of similar or related issues. Build self-service capabilities in the platform to help users provision, use and analyse data in a self-served manner. Build analytical platform services like Data Mart Builder as a Service, Graph and Spatial Analytics as a Service, Cloud SQL Warehouse and others which provide analytical capabilities over large data sets to users in Visa. Actively participate in all phases of software development lifecycle: analysis, technical design, planning, development, testing/CICD, release, post production/escalation support. Apply the appropriate software engineering patterns to build highly scalable, available and resilient multi-tenant Platforms that can host large scale and highly critical applications. Take ownership of Platform and drive it to the next level of effectiveness to support current and long-term requirements. Builds strong commitment within the team to support the appropriate team priorities. Position reports to the Foster City, California office and may allow for partial telecommuting. Qualifications Basic Qualifications: Employer will accept a Bachelor's degree in Computer Science, Engineering or related field and 10 years of progressive, post-baccalaureate experience in the job offered or in a related occupation. Position requires experience in the following: Query Performance Tuning and Optimization Linux and Windows Operating Systems Linux Shell Scripting DB2 LUW Database Implementation DB2 Database Partitioning Feature on Linux IBM Data Server Manager and IBM Database Management Console Additional Information Worksite: Foster City, CA This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Travel Requirements: This position does not require travel. Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers. Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code. U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is $215,197.00 USD to $231,400.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for an annual bonus and equity. Visa has a comprehensive benefits package for which this position is eligible that includes Medical, Dental, Vision, 401(k), Employee Stock Purchase Program, FSA/HSA, Life Insurance, Paid Time off and Wellness Programs.",
        "url": "https://www.linkedin.com/jobs/view/3945668424"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3951590313,
        "company": "Google",
        "title": "Software Engineer III, Machine Learning, Core",
        "created_on": 1720636208.6618507,
        "description": "Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning or natural language processing. Preferred qualifications: Master's degree or PhD in Computer Science or related technical field. 2 years of experience with performance, large scale systems data analysis, visualization tools, or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About The Job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions. The Core team builds the technical foundation behind Google’s flagship products. We are owners and advocates for the underlying design elements, developer platforms, product components, and infrastructure at Google. These are the essential building blocks for excellent, safe, and coherent experiences for our users and drive the pace of innovation for every developer. We look across Google’s products to build central solutions, break down technical barriers and strengthen existing systems. As the Core team, we have a mandate and a unique opportunity to impact important technical decisions across the company. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3951590313"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3711896457,
        "company": "TensorOpera AI",
        "title": "Back-end and Data Platform Software Engineer",
        "created_on": 1720636210.3063984,
        "description": "Responsibilities Participate in the development of machine learning platform and open source communities Responsible for the foundational research and product development, and continuously improve the R&D efficiency Responsible for feature development, algorithm optimization of the platform, improving user experience and usability through cutting-edge or mature technologies Participate in or lead design reviews with peers and stakeholders to decide amongst available technologies Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency) Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback Minimum Qualifications Bachelor’s degree or equivalent practical experience in computer science or related areas. 2 years of experience with software development in one or more programming languages (Python, Java, JavaScript, C/C++), or 1 year of experience with an advanced degree 2 years of experience with data structures or algorithms in either an academic or industry setting Good communication and writing skills in English environment Preferred Qualifications Proficient in Java, familiar with Linux, Spring, Mybatis, Spring Cloud, MySQL, common NoSQL systems and distributed architecture Familiar with the application of Kubernetes, Docker, DevOPS and other cloud native (Cloud Native) technologies, experience in medium and large-scale back-end application development is preferred, and experience in machine learning platform development is preferred Familiar with underlying middleware and distributed technologies (such as RPC framework, cache, message system, etc.) Familiar with the use/principle/tuning of common big data frameworks is preferred, such as Flume/Kafka/Hadoop/Hbase/Spark/Storm/ELK/ETL/kafka/Hive, etc. About The Job FedML, Inc. (https:/fedml.ai) empowers our clients to build & scale any machine learning or artificial intelligence models anywhere. That includes the latest foundation models as well as more traditional ML models. Our products cover both training, serving with a low-code UI MLOPs & LLMOps platform. We also offer a Federated Machine Learning solution for cross-silo training for data privacy sensitive applications. Our earliest products power federated machine learning missions for clients in several industries, where data privacy, low latency serving, and low cost of data storage are important to the client. Our easy-to-use FedML MLOps solution enables data science and machine learning engineering to work seamlessly together to deploy & manage their model to production machines. Our federated learning and serving solutions support siloed edge devices, smartphones, and IoT. Our next generation of solutions includes geo-distributed machine learning and serving that continues our tradition of delivering easy-to-use, simple, low-cost, and enterprise grade MLOPs solutions. Our MLOps and evolving LLMOps platform will always empower experimentation, observability, evaluation, governance, and collaboration for our clients’ AI & ML training and serving needs, as well as other general computing needs. FedML supports vertical solutions across a broad range of industries (healthcare, finance, insurance, automotive, advertising, smart cities, IoT etc,) and applications (computer vision, natural language processing, data mining, and time-series forecasting). Its core technology is backed by more than 3 years of cutting-edge research of its co-founders who are recognized leaders in the federated machine learning community. FedML's researchers and software engineers and product teams are busy developing the next-generation FedML platform for machine learning and artificial intelligence and we're looking to grow our team with skilled professionals who bring fresh ideas from all areas, including machine learning and its applications, computer vision, natural language processing, large-scale system design, distributed/cloud computing/systems, MLOps, security/privacy, mobile/IoT systems, and networking. We’re an early stage startup, hence you will work on projects which are critical to our customers' and our business needs. If you love to learn, and love to convert ideas into real and scalable machine learning infrastructure products and applications, FedML may be a great place for you. Location Our HQ is in Sunnyvale California. Preference is for someone local who can be at our office regularly. Hybrid is ok. How To Apply If you are interested, please apply via the link.",
        "url": "https://www.linkedin.com/jobs/view/3711896457"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3958006522,
        "company": "Ever",
        "title": "Software Engineer - Backend",
        "created_on": 1720636212.0539362,
        "description": "About Ever: Ever is a fast-moving, venture-backed marketplace and technology business, building the next industry-defining company in the electric mobility and household electrification space. Our mission is to help consumers and businesses toward a clean energy future. We are starting by building the best possible experience for buying and selling electric vehicles. Our retail and marketplace platform (evercars.com) was launched in late 2023, and our early momentum has been very strong. As a small but strong early-stage team, we are looking to onboard world-class engineers, product designers, and operators to key roles in our core team. You'll work closely with the founders and the rest of our team, taking strong ownership of key initiatives and building the leading marketplace and operations products that help us fulfill our mission. What You'll Do: You'll work alongside the CTO and engineering team to build a generational EV platform to serve consumers on their journey from EV's to broader electrification initiatives. Work directly with the founders, users, and customers to create positive product feedback loops and define engineering roadmaps. Design and develop scalable architecture patterns Lead, grow, and build our team with an engineering first culture. Qualifications & Fit: 3+ years of relevant software engineering experience in a fast paced environment Passion for EVs, climate, & unsolved challenges in the shift towards electric mobility Experience leading technically challenging projects and working with stakeholders across multiple domains Technical skills: 3+ years of experience delivering, scaling, and owning highly successful and innovative products Familiarity with technologies in our backend stack: (Go, Node, MySQL, DynamoDB) Experience with real-world system design challenges, large scale applications, and data pipelines Benefits: Competitive salary and equity Unlimited PTO Health, dental, and vision Ever is an equal opportunity employer. We encourage applicants from all backgrounds and experiences to apply.",
        "url": "https://www.linkedin.com/jobs/view/3958006522"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3912060994,
        "company": "Unreal Staffing, Inc",
        "title": "Front End Software Engineer",
        "created_on": 1720636213.704069,
        "description": "Mission We're dedicated to advancing AI with a focus on privacy, personalization, and real-world applications. Our engineering ethos centers on innovation and ownership, empowering Fortune 500 companies to embrace cutting-edge AI solutions. If you're driven to push boundaries and make an immediate impact, join us on our mission to shape the future of AI. Requirements Responsibilities Design and develop highly efficient, responsive, and visually stunning user interfaces using ReactJS and Typescript Collaborate closely with the design team to seamlessly integrate visual elements into our applications, ensuring a cohesive user experience Leverage Tailwind CSS to elevate the styling and layout of our web applications, focusing on both aesthetics and functionality Iterate quickly and deliver Minimum Viable Products (MVPs) with a strong emphasis on speed and quality Coordinate with backend developers to integrate frontend components with server-side logic, ensuring seamless functionality Identify and address performance bottlenecks to optimize application speed and responsiveness Expectations Demonstrated proficiency in front-end development, with 3-5 years of professional experience working with ReactJS and Typescript Strong skills in utilizing Tailwind CSS for crafting modern and visually appealing user interfaces Portfolio showcasing previous projects and accomplishments, highlighting your expertise in web development Solid understanding of web development best practices and emerging trends Experience with version control systems like Git and comfortable with collaborative development workflows Benefits Competitive salary package commensurate with experience Comprehensive health, dental, and vision insurance plans 401(k) retirement savings plan with company matching Flexible remote work options Generous paid time off and company holidays Professional development stipend for continued learning and growth opportunities Vibrant company culture with regular team-building events and activities",
        "url": "https://www.linkedin.com/jobs/view/3912060994"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Culver City, CA",
        "job_id": 3931651602,
        "company": "Prime Video & Amazon MGM Studios",
        "title": "Sr Data Engineer, Partner Experience",
        "created_on": 1720636215.394851,
        "description": "Description Prime Video offers customers a vast collection of movies, series, and sports—all available to watch on hundreds of compatible devices. U.S. Prime members can also subscribe to 100+ channels including Max, discovery+, Paramount+ with SHOWTIME, BET+, MGM+, ViX+, PBS KIDS, NBA League Pass, MLB.TV, and STARZ with no extra apps to download, and no cable required. Partner experience (PX) organization obsess over partners with a focus on delivering world-class partner tools to enable them to launch, grow and scale their businesses across PV’s business lines. PX organization build various products to enable partners to 1) onboard and make their selection available to customers globally; 2) manage selection across PV business lines 3) acquire, engage, retain customers through self-service marketing, merchandising, promotion tools. By providing partners with best-in-class self-service capabilities throughout their engagement with Amazon, we power the flywheel through increased partner satisfaction and expanded the breadth of selection available to Amazon customers. PXBI (Partner Experience BI team) fulfills data needs for Partner Experience (PX) organization to provide big data to power reporting functions across five crucial partner-facing products, meeting reporting contractual obligations and powering Prime Video partners with performance data for measurement to grow their business in Prime Video; also build data pipelines to enable data to measurement effectiveness of organization’s product deliveries and facilitate data-driven decision-making within PX organization. Key job responsibilities We are seeking a talented Sr. Data Engineer to enhance overall PXBI core data infrastructure by implementing AWS services to build the data pipelines, enhancing data accuracy, reducing data latency, increasing data service stability, and ensuring compliance with Amazon-wide data compliance regulations, Furthermore, the Sr Data engineer partner with SDE team to build Slate analytics product – a new generation of reporting and analytics product to replace the existing VC reporting system and PVD reporting system. We will design and implement data lake to provide robust, scalable data infrastructure to deliver intra-day data to power slate analytics product. As a Sr. Data Engineer in the team, you will work on very large data sets in one of the world's largest and most complex data lake and data warehouse environments. You will design, build and maintain the robust data infrastructures to process large volumes of data (big data) from various sources. This includes writing clean, maintainable code that adheres to best practices, being familiar with AWS data processing services, possessing broad knowledge of when to utilize different types of data, and understanding data security and compliance standards to ensure alignment with company policies and regulations. A day in the life Write the design document to propose the solutions to resolve challenging data processing and data handling. Meet with your peers to discuss the solutions. Review your design doc with product managers, senior management, Sr SDE to communicate your thought and gather their feedback. Build up data infrastructure and data pipelines by using AWS services. Productionalize your solutions into products which will be used by WW Prime Video partners. About The Team We are a centralized data team to support partner experience organization. We process big data by using advance AWS services. We work closely with PM, TPM, SDE, collaborate with other data teams outside of partner experience organization to deliver products for Prime Video partners. We are open to hiring candidates to work out of one of the following locations: Culver City, CA, USA | Seattle, WA, USA Basic Qualifications 5+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Experience with SQL Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS Preferred Qualifications Experience with big data technologies such as: Hadoop, Hive, Spark, EMR Experience operating large data warehouses Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $139,100/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon.com Services LLC Job ID: A2652779",
        "url": "https://www.linkedin.com/jobs/view/3931651602"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "West Sacramento, CA",
        "job_id": 3878694756,
        "company": "Linbar Solutions Inc. (LSi)",
        "title": "Data Modeler/Data Engineer",
        "created_on": 1720636217.0910277,
        "description": "If you have interest in this position please send resume in word with contact number, C2C rate, location and requisition # # 2 Title: Data Modeler/Data Engineer (#11839726) Position Type: Contract Job Location: Remote Duration: One Year Openings: 1 Interview Type: Phone/Web with a possible In Person Job Order Recruiter Name and Email Address: Barb Ensminger –barbensminger@linbarsolutions.com Description Data Engineer Senior associate role 1 year of assignment confirmed 3-5 Years Of Experienced, Preferred Responsible for developing quality software applications. Understands and documents global, regional, and local business processes for a specific business area (e.g., finance, supply chain). Knowledgeable of, configures and/or develops systems to support initial implementations and subsequent process optimization efforts. Works with IT team members to maintain solutions and ensure systems meet the needs of the global organization in terms of functionality and quality. Provides support to business associates on systems use as needed. Undergraduate Degree (e.g., BA, BS) preferred in computer science, information technology or a related discipline. Additional Skills Software development and architecture Experienced in architecting platform-as-a-service solutions Experienced in cloud based platforms (Google Cloud, AWS, Azure) Experienced in integrating cloud based platform capabilities into a custom developed platform-as-a service solution Experienced in API calls to external software packages Experienced in machine learning, artificial intelligence and neural network architecture and development Understanding of the full software development lifecycle (SDLC) Understanding of different software development methodologies including Agile, JAD and Extreme Programming Requirements gathering and definition High-level and detail design of end-to-end analytic solutions (data acquisition, data integration, data modeling, data quality, master data management, metadata management, testing) Development of code assets including leading code reviews Developing comprehensive test plans Performing unit and system testing to validate analytic procedures against expected results Understanding of relational databases and SQL; NoSQL database models, XML and other database models; development languages, such as Python and Spark Leading the conversion / integration of algorithms and other data science output into the production framework Additional Information 100% remote work (prefer candidates in the Washington Metro and California Bay Area) Probability of up to 25% of domestic travel Barbara Ensminger Linbar Solutions VP Operations Please Contact Me With Any Questions (w) 423-877-0920 (c) 423-322-3604 Email barbensminger@linbarsolutions.com Visit our careers website to view our current opportunities http://linbarsolutions.catsone.com/careers",
        "url": "https://www.linkedin.com/jobs/view/3878694756"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Diego, CA",
        "job_id": 3966744217,
        "company": "Qualcomm",
        "title": "Data Platform Sr. Engineer - Autonomous Driving",
        "created_on": 1720636220.300566,
        "description": "Company Qualcomm Technologies, Inc. Job Area Engineering Group, Engineering Group > ADAS R&D Software General Summary Qualcomm is hiring multiple software engineers to help architect and build its next generation data processing platform to support Autonomous Driving R&D efforts. Our goal is to design and build a highly scalable, efficient, and modular data platform. This platform will be used by engineers to run re-simulation pipelines, machine learning workloads, perform in-depth data analysis/analytics, visualize results, and more. Excellent communication and planning skills are critical in this role as we'll be working with internal teams and external partners. Minimum Qualifications Bachelor's degree in Computer Science, Electrical Engineering, Robotics, or related field and 2+ years Software Engineering or related work experience. OR Master's degree in Computer Science, Electrical Engineering, Robotics, or related field and 1+ year Software Engineering or related work experience. OR PhD in Computer Science, Electrical Engineering, Robotics, or related field. Preferred Qualifications 4-7 years of relevant experience in a software development role (or equivalent) Backend development experience with a focus on data management, distributed systems, ML/AI, and high performance compute applications Familiarity using a programming language such as Python, Go, C/C++, Java, or Scala Hands-on experience using managed services from one or more of the major cloud vendors: AWS, GCP, Azure Understanding of RDBMS, NoSQL DB technologies, and data warehousing solutions and tradeoffs Experience building RESTful web APIs and services Experience building user interfaces. Proficiency with common software engineering tools, CI/CD, and version control systems such as git, GitLab CI/CD, Jenkins, Python virtual environments, etc. Industry experience designing and implementing a SaaS system in a cloud environment. Industry experience designing and implementing scalable solutions used for Autonomous Driving R&D applications Experience managing, deploying, and maintaining large-scale infrastructure on the cloud for \"Big Data\" applications Experience using infrastructure and configuration management Experience in UI/UX Strong interpersonal skills and demonstrated ability to work with multi-functional teams Excellent communication skills Principal Duties And Responsibilities Applies knowledge and experience of ADAS Software to design, develop, and optimize software for embedded technology blocks that directly enable autonomous and self-driving vehicles. Develops and enhances technologies for camera perception; high precision localization; radar and lidar perception; precise sensor synchronization and calibration; sensor driver; multi-sensor fusion; estimation and tracking of static and dynamic objects in the environment; behavior prediction of agents; planning of autonomous vehicle decisions, trajectory and speed; and/or autonomous vehicle control. Develops and verifies code for a component and validates ADAS software against specifications; collaborates with test team. Designs and develops software development kits (SDK) to enable customer proof of concepts. Writes detailed technical documentation, descriptions, specifications, and/or feature descriptions for projects to guide users and/or customers to use or implement output. Level Of Responsibility Works independently with minimal supervision. Decision-making may affect work beyond immediate work group. Requires verbal and written communication skills to convey information. May require basic negotiation, influence, tact, etc. Has a moderate amount of influence over key organizational decisions. Tasks require multiple steps which can be performed in various orders; some planning, problem-solving, and prioritization must occur to complete the tasks effectively. Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail myhr.support@qualcomm.com or call Qualcomm's toll-free number found here . Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. To all Staffing and Recruiting Agencies : Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. EEO Employer: Qualcomm is an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or any other protected classification. Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. Pay Range $114,500.00 - $171,500.00 The above pay scale reflects the broad, minimum to maximum, pay scale for this job code for the location for which it has been posted. Even more importantly, please note that salary is only one component of total compensation at Qualcomm. We also offer a competitive annual discretionary bonus program and opportunity for annual RSU grants (employees on sales-incentive plans are not eligible for our annual bonus). In addition, our highly competitive benefits package is designed to support your success at work, at home, and at play. Your recruiter will be happy to discuss all that Qualcomm has to offer! If you would like more information about this role, please contact Qualcomm Careers. 3063579",
        "url": "https://www.linkedin.com/jobs/view/3966744217"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3941962840,
        "company": "Sprig",
        "title": "Backend Engineer",
        "created_on": 1720636221.9590616,
        "description": "About Sprig Sprig is a user insights platform backed by top-tier investors, including Andreessen Horowitz, Accel, and First Round Capital. Our suite of products enable our customers to combine traditional analytics with qualitative product data so they can build an exceptional product experience for their users. Leading tech companies like Notion, Square, Dropbox and Figma use Sprig to build best-in-class, customer centric products. Most recently, we've partnered with Calendly and TripAdvisor and continue to see exceptional growth and diversity within our customer base. At Sprig, we pride ourselves on being a people-first company, where your contributions truly matter and are valued. We were recently awarded by Fortune as top 50 best places to work in the US, and top 50 Places to Work in the Bay Area by Built In. Come join our mission of building products users love and have a real impact on Sprig's future. More about our mission, values, and why it's a great time to join us can be found here. About This Role We're looking for a talented Backend Engineer to join our Data Team. The Data Team at Sprig is responsible for the backend architecture, data ingestion, processing and storage systems, as well as playing a critical role in ensuring our platform's reliability, scalability, and performance. You will work closely with cross-functional teams to design, build, and maintain features and the infrastructure that powers our innovative product research solutions. Ultimately, your work will have a direct impact on the success of our customers by providing reliable, scalable, and insightful research tools, so they can build customer-centric products that resonate with their users. This role is based in San Francisco or New York City with 2-3 days working in the office. Your Impact Enabling customer insights via implementing and optimizing features that power our event-based targeting systems. Collaborating with product managers, AI engineers, and product engineers, you will facilitate the integration of backend systems with other components of the platform. Staying ahead of the latest technologies and integrating them into our systems will keep Sprig at the cutting edge of product research solutions. Your proactive approach to innovation will ensure our platform remains competitive and capable of meeting future challenges. Driving data integrity and security by managing and maintaining databases. This is crucial for maintaining the trust of our clients and ensuring the accuracy of the insights generated by our platform. Enhancing platform scalability and performance by designing and developing robust backend systems. Your Strengths 2+ years of software engineer experience with focus on platform, backend system, data infrastructure, or distributed computing. Experience with some of the technologies we use, e.g., Redis, Kubernetes, Postgres, ClickHouse, Kafka, gRPC, REST, WebSocket, and S3. Write high quality production code using Node.js or Golang. Excellent written and verbal communication skills. Quick learner and good team player. Experience with low latency high volume data stores and platforms is a big plus. Benefits & Perks Competitive Salary Competitive Employee Equity 401K Program Medical, Dental, and Vision Benefits FSA/HSA Benefit $150/month Commuter Benefit Additional Wellbeing Benefits Flexible Paid Time Off Paid Parental Leave Professional Development Stipend Hybrid Office Policy Lunch available 5x a week in SF and NYC Dinner available 2x a week in SF Company Sponsored Social Events Our Commitment to Diversity and Inclusion We prioritize diversity within our team and value different perspectives, educational backgrounds, and life experiences. We encourage people from underrepresented backgrounds to apply. We're \"Great Place to Work\" Certified! Check out our profile. Employee Pay Disclosure The base salary range for this full-time position is $140,000 - $170,000 + Equity + Benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all locations (San Francisco, CA; New York, NY). Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your Recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in postings reflect the base salary only, and do not include equity or benefits. ***Please beware of scammers who are posing as Sprig and Sprig team members. Our recruiters use @sprig.com email addresses exclusively. We do not conduct interviews via text or instant message, and we do not ask candidates to purchase equipment through us or solicit money from you. If you have been contacted by someone claiming to be from a different domain about a job offer, please report it as potential job fraud to law enforcement and contact us here.***",
        "url": "https://www.linkedin.com/jobs/view/3941962840"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3961091765,
        "company": "Patch",
        "title": "Software Engineer",
        "created_on": 1720636223.9288528,
        "description": "About Patch A livable future depends on climate solutions — and those solutions need funding to scale. There is a financial mechanism powerful enough to help drive climate solutions to gigatonne-scale and beyond carbon credits. Patch is the platform for accelerating climate solutions with integrity. Patch technology enables organizations to manage, sell, and buy carbon credits with efficiency, transparency, and rigor. Through Patch, companies gain access to the broadest network of high-integrity carbon credits. Carbon credit suppliers use Patch to enhance operational efficiency and precision and modernize their buyer experiences. That allows companies to achieve their climate goals, project developers to scale their solutions, and ultimately helps rebalance the planet. About Position: We're looking for exceptional engineers to design, build, launch, and manage Patch’s novel platform primitives and API products. Nothing like Patch has ever been built before. There is no playbook detailing how features or products should be built. This role offers product-minded engineers the ability to take control of the roadmap and chart a course toward making the greatest impact. We currently use Ruby on Rails, Postgres, and Typescript on AWS. What You'll Do: Design and deploy highly available and resilient platform primitives, APIs, and features. Architect scalable, product-oriented systems able to handle billions of API requests annually. Work through problems with your team, roll up your sleeves, form an opinion, and advocate for engineering-specific roadmap items. Strategize and collaborate with other Patch teammates to provide the best product possible to our users. Who You Are: You have at least 4 years of software engineering experience You have experience in or are willing and able to learn Ruby on Rails You are eager to contribute to Patch’s carbon removal mission You have a passion for collaboration and a history of establishing great relationships with design and product management teams across time zones. You are curious about constantly learning new things in a fast-paced startup environment. You have a commitment to technical excellence, raising the bar, and delivering results. You are an excellent oral and written communicator. You are willing and able to work from the Hayes Valley office in San Francisco, California a few days a week. Why Patch: Work with the most talented team in climate tech Competitive compensation and meaningful equity Monthly wellness stipend for mental and physical health Time-off as-needed vacation policy Generous parental leave policy Commitment to Diversity: Patch is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant, candidate, or employee on the basis of race, color, religion, creed, national origin or ancestry, sex, gender, gender identity, gender expression, sexual orientation, age, physical or mental disability, medical condition, marital/domestic partner status, military or veteran status, genetic information or any other legally-recognized protected basis under federal, state or local laws, regulations or ordinances. If you are extended an offer, that offer may be contingent upon your successful completion of a background check, which will be conducted in accordance with applicable laws. We may obtain one or more background screening reports about you, solely for employment purposes. Compensation Range: $148K - $160K",
        "url": "https://www.linkedin.com/jobs/view/3961091765"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Carlos, CA",
        "job_id": 3936381539,
        "company": "Beacon AI",
        "title": "Front End / Web Application - Software Engineer (Multiple Seniority Levels)",
        "created_on": 1720636227.974958,
        "description": "Front End / Web Application Developer - Software Engineer (Multiple Seniority Levels) SAN CARLOS, CA (HYBRID) | ENGINEERING – FRONT END / WEB APPLICATION | FULL TIME About Beacon AI Beacon AI is developing AI pilot assistant technology to transform aviation, flight safety, operational efficiency, and pilot capabilities. We are on a mission to leverage the power of artificial intelligence and advanced data analytics to revolutionize the aviation industry. Join us to be at the cutting edge of technological innovation for the second century of aviation. Role Overview We are seeking a self-motivated and talented Front-End Web Developer who can bring a unique blend of skills to our team as we build innovative front-end interfaces that interact with our advanced flight safety system in flight. In this role, you'll have the opportunity to play an active role in building a critical application to our overall platform that allows users away from aircraft to interact with the data and make meaning from flights. You will not only impact how the application performs, but also how it looks by working closely with our product and UX/UI design teams to bridge the gap between design and technical implementation. Key Responsibilities Feature Development: Build new features and improve existing functionality for a web application built in React Data Handling: Handle data from multiple sources, both live and archived System Design: Design systems to efficiently handle large amounts of data and build efficient high-refresh-rate components Collaboration: Collaborate with teammates throughout the stack for design and implementation decisions Third-Party Libraries: Work with popular third-party libraries to enhance functionality UX/UI Collaboration: Partner with a UX/UI designer to ensure the implementation of a user interface that is consistent, intuitive, and user-friendly React Development: Use React to extend the functionality of our web application Media Tools: Use a variety of streaming and media tools to provide a feature-rich experience User Interface: Develop new, user-focused interface features ensuring technical viability for speed and scalability Documentation: Develop front-end documentation to catalog relevant solutions in our technology stack Data Streams: Work with data streams and collaborate with the rest of our engineers to develop the best solutions for live-streaming and playback features Testing: Write and maintain robust test coverage to ensure the application functions as expected Reusable Code: Build reusable code and libraries for future use What Will Make You Successful React Expertise: Strong expertise in React Web Markup: Proficiency with HTML5 and CSS3 Front-End Technologies: At least 4 years of experience with front-end technologies and an excellent understanding of Javascript and ES6 CSS Pre-Processing: Familiarity with CSS pre-processing platforms like SCSS, SASS, or LESS Asynchronous Requests: Good understanding of asynchronous request handling, partial page updates, AJAX, and GraphQL technologies Streaming Proficiency: Proficiency with video and data streaming Bonus Points Passion for Aviation: Passion for aviation and improving air-travel efficiency and safety Geo-Mapping Tools: Experience with online geo-mapping tools such as MapBox or Cesium TypeScript: Familiarity with TypeScript Why Join Us: At Beacon AI, you will be at the forefront of revolutionizing the aviation industry. As a key player in our innovative team, you will have the unique opportunity to create groundbreaking technology that enhances flight safety and operational efficiency. We are driven by a passion for cutting-edge solutions, and we want you to bring your creative energy and technical expertise to help shape the future of aviation. By joining Beacon AI, you will: Make a Real Impact: Your work will directly contribute to saving lives and transforming how pilots interact with their aircraft Innovate: Collaborate with a team of brilliant minds who are as passionate about technology and aviation as you are Grow with Us: As a fast-growing startup, we offer ample opportunities for personal and professional growth, allowing you to expand your skills and take on increasing responsibilities Be Valued: We foster a supportive and inclusive environment where your ideas and contributions are highly valued Stay Ahead of the Curve: Work with the latest technologies and stay at the cutting edge of industry trends and innovations Enjoy Flexibility: Benefit from a hybrid work model that promotes a healthy work-life balance, ensuring you stay energized and motivated Benefits Comprehensive Healthcare Coverage: Enjoy peace of mind with our generous health, vision, and dental benefits, with 75% of costs covered by the company for the employee Paid Time Off: Recharge and relax with 3 weeks of paid vacation, in addition to 14 company-paid holidays each year Connectivity Stipend: Stay connected with our cell phone benefit, ensuring you have the tools you need to excel in your role Health and Wellness Allowance: Use this towards a gym membership or subscription to a meditation app, empowering you to prioritize self-care and maintain a healthy lifestyle Financial Planning: Prepare for the future with our 401(k) program. While we currently do not offer matching, we are committed to enhancing this benefit in the future Powered by JazzHR DRsccoTfcI",
        "url": "https://www.linkedin.com/jobs/view/3936381539"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3592056736,
        "company": "TikTok",
        "title": "Senior Data Engineer, Data Application",
        "created_on": 1720636229.7282271,
        "description": "Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. Join us. TikTok's immersive experience, global presence, and high engagement makes it the ideal marketing destination for business, big and small, to showcase their unique brand identity, connect with their consumers, and build strong lasting relationships over time. The Ads Data Team builds and manages the petabyte scale data infrastructure, batch/realtime pipelines and services to support Tiktok's global Ads business. We are committed to building a robust data foundation and scalable data applications, unblocking the full potential of advertising data to optimize advertiser experience, boost business growth, empower strategy execution. We are looking for passionate Data Engineers that have strong problem solving skills to join forces with talented cross functional partners (business operation, data science, engineering and product management) to solve some of the most interesting data challenges with efficiency and quality. In this role, you will contribute to the company's core business across innovative advertising products, campaign management and measurement solutions. You will see a direct impact from your day-to-day work to customer satisfaction and company growth. Responsibilities: 1. Work closely with Product Managers, Data Scientists/Analysts, and Software/Machine Learning Engineers and other stakeholders to understand data requirements and deliver data solutions that meet business needs. 2. Evaluate, implement and maintain data infrastructure tools and technologies to support efficient data processing, storage and query. 3. Design, build and optimize scalable data pipelines to ingest, process and transform large volumes of data. 4. Design and implement robust data models and visualization to support complex analytical queries and reporting requirements. 5. Ensure the data integrity, accuracy and consistency of data by implementing data quality checks, validation processes and monitoring mechanisms. 6. Continously optimize data pipelines, queries and processes to improve performance, reduce latency and enhance scalability. 7. Provide rapid response to SLA oncall support to business critical data pipelines. 8. Create and maintain good documentation for data assets and promote best practices for data governance within the data user community. 9. Coordinate project management and define business domain data development roadmap 10. Influence product and cross-functional teams to identify data opportunities to drive bigger impact. 11. Mentor junior team members by giving actionable feedback to improve their performance. Qualifications Qualifications: 1. Bachelor's degree in Computer Science, Engineering, or a related field. 2. Proven 5 years' experience as a Data Engineer or similar role in supporting data-centric business. 3. Strong knowledge of SQL and experience working with relational and non-relational databases. 4. Proficiency in programming languages such as Python, Java, Go etc. 5. Solid understanding of data modeling and data warehousing concepts, data integration and ETL/ELT techniques. 6. Effective communication skills and ability to collaborate effectively with cross-functional teams. 7. Excellent problem-solving skills, attention to detail, and ability to thrive in a fast-paced environment. Preferred Qualifications: 1. Experience with big data technologies(e.g. Apache Hadoop, Spark, Kafka, Flink) and working with terabyte to petabyte scale data. 2. Experience with cloud data warehouses(eg. Snowflake, Databricks, BigQuery) and modern business intelligence/data stack. 3. Experience with data governance, data privacy and compliance. 4. Experience in the advertising, e-commerce or gaming industry. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2 Job Information: 【For Pay Transparency】Compensation Description (annually) The base salary range for this position in the selected city is $187040 - $280000 annually. ​ Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units. ​ Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: ​ We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. ​ Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. ​ We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice. ​",
        "url": "https://www.linkedin.com/jobs/view/3592056736"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3860726584,
        "company": "Padlet",
        "title": "Software Engineer – Backend",
        "created_on": 1720636233.778492,
        "description": "Padlet is building software for a good education. A good education is one that inspires curiosity, creativity, and community. Our software enables that through visual content creation and collaboration in millions of classrooms worldwide. We are looking for Backend Engineers to deliver on our promise. Cloud makes it possible for any human to have access to supercomputers. We need you to program these supercomputers to improve the lives of a billion people. Responsibilities Building new features. E.g. building our public API so our users can extend Padlet. Improving backend performance. E.g. making network calls faster and more reliable. Making the backend more cost efficient. E.g. reducing the CPU and memory requirements of services. Improving how we work. E.g. improving our internationalization tooling we use to translate our app into 40+ languages. Qualifications At some point in your life, someone has told you: “you write good code.” You know how to copy-paste code from Stack Overflow. Bonus: you have a good sense of humor. About Padlet Vision: Every child in the world will grow up with Mickey Mouse and Padlet. Product: We are making the default way of collecting and sharing thoughts on the Internet. People love the product. Impact: We have over 50 million active users making Padlet one of the most used apps on the planet. Our goal is to be THE the most used app on the planet. Money: We are venture backed AND profitable. We are built to last one hundred years. Badassery: We are 36 people (plus a baby crane that we've adopted but it doesn't really do much). That's over a million active users per employee. Some badass people work here. Tech stack Backend: Ruby (Rails), Typescript, Elixir (Phoenix), and Python. Storage: Postgres, Redis, Elasticsearch, Firestore, and Snowflake. Web: VueJS, Tailwind. Mobile apps: React Native (with Swift and Java where necessary.) Joys of engineering at Padlet We have very few meetings. We value keeping you in flow. A lot of people use Padlet. We have to solve interesting concurrency problems. Our users are in over 200 countries, using all kinds of devices and connections, and speaking over 40 languages. We have to solve interesting internationalization problems. We process a lot of data real fast. We have to solve interesting scale problems. We try to solve problems creatively instead of just throwing money at them. We are engineers! We thrive in constraints, not in the absence of them. We ship often. We value beautiful code. Sorrows of engineering at Padlet We grew pretty fast last year and our processes are still catching up. E.g. we don't have 100% code coverage yet. Our deployment process isn't as painless as it could be. This sometimes leads to spending time on things that aren't the most fun. We’re working on it! Our project management process could be better. This sometimes leads to re-speccing in the middle of development, getting in the way of programming flow. We’re working on it! Some people you‘d be working with Josh Hewitt: insists that wallabies and kangaroos are different animals, artificially inflating the biodiversity of his homeland. Is excellent at surgically improving an existing, complicated system. Colin Teahan: lives for one-liners. E.g: Colleague: “Wouldn’t it be funny if Iron Man were anemic?” Teahan: “It would be IRONIC.” Single-handedly wrote early versions of our iOS and Android apps. The office Our office is in the middle of Presidio, a beautiful national park. We’re 5 minutes from the beach, a walk we take often. The WiFi works outdoors. You can work sitting in a lawn overlooking the Golden Gate Bridge. The office itself is designed to be a space for all your interests and hobbies. We have a meditation room, game room, library, podcasting studio, art studio, kids room, and full makerspace with 3d printers, presses, laser cutters, sewing machines, and more. Benefits Top tier medical, dental, and vision insurance for you and your family. One Medical and Cue memberships for you and your family. 401(k) with matching. Commuter benefits. FSA. Good stock options. Catered lunches and dinners. 20 vacation days. Plus sickness and bereavement days for when life happens. All the gadgetry you need, including a new phone every year. Special time to join Because we're small, there's a lot of energy. And because we have tremendous traction, your first commit touches millions. This combination is rare and quite satisfying.",
        "url": "https://www.linkedin.com/jobs/view/3860726584"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Mateo, CA",
        "job_id": 3765974078,
        "company": "Verkada",
        "title": "Backend Software Engineer - University Graduate 2024",
        "created_on": 1720636235.5765834,
        "description": "Who We Are Verkada is the largest cloud-based B2B physical security platform company in the world. Only Verkada offers six product lines — video security cameras, access control, environmental sensors, alarms, workplace and intercoms — integrated with a single cloud-based software platform. Designed with simplicity and scalability in mind, Verkada gives organizations the real-time insight to know what could impact the safety and comfort of people throughout their physical environment, while empowering them to take immediate action to minimize security risks, workplace frustrations and costly inefficiencies. Founded in 2016 with more than $460M in funding raised to date, Verkada has expanded rapidly with 16 offices across three continents, 1,900+ full-time employees and 25,000+ customers across 70+ countries. Overview We are looking for software engineers who thrive in a high growth environment working alongside teammates to launch products and features that will be utilized by customers across the globe. As part of the Software Engineering team, you’ll have ownership of one or more projects on various product or platform facing teams. You will work across the full software stack and collaborate cross functionally to build the latest iterations of Verkada’s flagship software, enabling our best-in-class security systems. Responsibilities Build scalable distributed systems capable of handling high traffic from 100s of thousands of devices deployed around the world. Work with high concurrency key-value storage systems (Redis, DynamoDB) Work with Postgres relational databases Work with logging and message passing technologies like Kafka and SQS Deploy services via Terraform and Kubernetes Develop large scale systems to interact with and configure products remotely. Define and improve low-latency, high-throughput, high-reliability microservice architectures. Design and develop features incorporating cutting edge computer vision Design clean APIs and implement them using Python and/or Go. Requirements BS/MS in Computer Science or similar technical field of study Internship experience developing and launching products Working knowledge of Python and/or Go Comfortable working in an agile team software development environment Familiarity with REST APIs, ability to read python server code a plus Pay Disclosure At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate’s skills and experience, as well as market demands and internal parity. This estimate can vary based on the factors described above, so the actual starting annual base salary may be above or below this range. This estimate is also just one component of Verkada’s total rewards package. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of Restricted Stock Units (RSUs). Estimated Annual Pay Range $120,000—$280,000 USD Verkada Is An Equal Opportunity Employer As an equal opportunity employer, Verkada is committed to providing employment opportunities to all individuals. All applicants for positions at Verkada will be treated without regard to race, color, ethnicity, religion, sex, gender, gender identity and expression, sexual orientation, national origin, disability, age, marital status, veteran status, pregnancy, or any other basis prohibited by applicable law. Your application will be handled in accordance with our Candidate Privacy Policy.",
        "url": "https://www.linkedin.com/jobs/view/3765974078"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3950305279,
        "company": "Sigma Computing",
        "title": "Senior Analytics Engineer, GTM",
        "created_on": 1720636237.1661623,
        "description": "About the Role We are building out our Data Platform team at Sigma, with a relentless focus on developing data models that fuel trusted insights across the company. As a Senior Analytics Engineer, you will be responsible for building, documenting, and educating our internal customers on how to best use our data products in Sigma. You will also be challenged to advocate for the vision and direction of our product through the lens of how a data team wants to work with a best-in-class BI tool. If you’re passionate about analytics engineering and the future of analytics, let’s chat! What You Will Be Doing Architect and manage our production data models in Snowflake and how they are consumed in Sigma, including writing documentation and generating data tests. (Tech we use: Fivetran, dbt, Snowflake, Sigma, Hightouch, Metaplane) Give power to the people. People are our strongest asset and we need you to work with team members from across the company to get them the data they need to support the business Build and maintain corporate reporting assets across respective GTM / Operations domains (e.g., Finance, Customer Success) Work cross functionally to accomplish all of the above! You’ll work across Product, Engineering, Sales, Marketing, Partnerships, and with users of all skills and levels Qualifications We Need Strong knowledge of data modeling and warehouse optimizations ( bonus points for any public facing repos or bodies of work you can point us to !). Detail oriented. Our data models are production systems and we need someone meticulous to maintain them! Strong communication and collaboration skills. You’ll be working with many stakeholders across the company, so we need someone who’s comfortable communicating with the whole company as their audience. In addition, you’ll be supporting other teammates by reviewing their work, providing coverage where needed, and supporting initiatives to grow our team Must have a builder mindset. Innate desire to document, templatize, automate and define a process around everything you do that is repeatable and set up for scale Ability to thrive in ambiguous environments and get stuff done. We move fast and iterate quickly, and we want you to feel empowered to do exactly that Experience building reports and managing stakeholder relationships, particularly in Marketing, Finance or Sales Visualization experience (Sigma highly preferred)—you will use Sigma every day! 4+ years of relevant experience working in a data role Qualifications We Want (also, skills you’ll learn!) A drive to continuously learn (and share those learnings) about the evolving data ecosystem Advanced knowledge of dbt, python, and SQL ( bonus points for Snowflake specifically ) Startup experience Experience training and enabling internal teams on best practices within BI tools Additional Job Details The base salary range for this position is $140k - $165k annually. Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work at Sigma Computing. This role is eligible for stock options, as well as a comprehensive benefits package. About Us Sigma is the only cloud analytics and business intelligence tool empowering business teams to break free from the confines of the dashboard, explore data for themselves, and make better, faster decisions. The award-winning software was built to capitalize on the performance power of cloud data warehouses to combine data sources and analyze billions of rows of data instantly via an intuitive, spreadsheet-like interface – no coding required. Since launching with its unique interface, Sigma Computing has added features such as collaboration tools and embedded analytics capabilities. The most recent product launch included a set of AI tools such as forecasting capabilities, an AI copilot and a notebook interface for users who prefer a code-first environment. Sigma announced its $200M in Series D financing in May 2024, to continue transforming BI through its innovations in AI infrastructure, data application development, enterprise-wide collaboration, and business user adoption. Spark Capital and Avenir Growth Capital co-led the Series D funding round, with additional participation from a group of past investors including Snowflake Ventures and Sutter Hill Ventures.The Series D funding, raised at a valuation 60% higher than the company’s Series C round three years ago, promises to further accelerate Sigma’s growth. Come join us! Benefits For Our Full-Time Employees Equity Generous health benefits Flexible time off policy. Take the time off you need! Paid bonding time for all new parents Traditional and Roth 401k Commuter and FSA benefits Lunch Program Dog friendly office Sigma Computing is an equal opportunity employer. We are committed to building a smart and strong team regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We look forward to learning how your experience can enable all of us to grow . Note: We have an in-office work environment in both our SF & NYC office.",
        "url": "https://www.linkedin.com/jobs/view/3950305279"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3625986796,
        "company": "Agave",
        "title": "Software Engineer",
        "created_on": 1720636238.804156,
        "description": "tl;dr : we're looking for a world-class engineer who loves simplifying complex systems, unifying fragmented data, and building high-scale backend systems. Learn more about us here (link). Why Join Us Opportunity: you have the chance to be an early, pivotal member of a fast-growing YC startup modernizing one of the world's largest industries (construction). Team: you'll work with a world-class founding team that's experienced, intense, and ambitious. We've worked together for 10 years, first at a startup that Amazon acquired, then at Amazon, and now at Agave. You'll learn a ton while having outsized ownership. Timing: you're joining at a key inflection point. We're proven (we've grown revenue 4x year over year, have 65+ customers) but also early. This means you have lower risk but also huge upside. Requirements Back-end/full-stack engineer, ideally with 1-4 years experience (we're open to exceptional college grads with strong intern/co-op experience). Familiarity with cloud infrastructure (e.g. AWS). Self-motivated, high ownership, low ego; desire to work on a fast-paced, intense, fun team. Excited to be our next hire; passion for building a world-class engineering culture. Pumped to work in-person with us in SF 5 days/week. No need to have: prior experience with our tech stack or at B2B SaaS/API company Interesting Technical Challenges Unification: we’re unifying dozens-to-hundreds of fragmented systems under a single standard that we define. Our unification covers data objects, data models, authentication, account-linking UX, and features like filters and pagination. When designing any new feature, we have to do it in a scalable way. For example, when adding filters, we have to research each system we support (and plan to support) and create a generic, system-agnostic solution. On-prem: we’re connecting with many types of on-prem systems (SQL-based, DLL-based, API-based), many built 20-40 years ago. We provide tremendous value to customers allowing them to interface with these systems in a secure, fast, reliable way, as if they’re modern, cloud-based products. We need to support real-time communication and webhooks when they don’t exist (e.g., using web-sockets). Scale & speed: we’re handling millions of API requests per day, and growing daily. For our products that we power with our own API (e.g. Analytics), we need to store and retrieve large amounts of data in an efficient way, building elegant caching layers to reduce latency. We ship code daily and iterate quickly based on actual feedback from paying customers (they share tons!). Operational excellence: we’re creating a reliable API layer on top of many old systems that don’t have APIs. It’s like building a skyscraper on quicksand, enforced by SLAs. We need to innovate in expanding the depth and breadth of our integrations while simultaneously increasing our development velocity. We need to be very creative in how to continually test our code and integrations, creating scalable testing frameworks that can catch edge cases and bugs across 1k+ endpoints. Mix of back-end and front-end: we’re building front-end apps that dog-food our own APIs (e.g. Sync, Analytics). This helps us build world-class APIs because we suffer any pain present in our API. We’re building both the lego blocks and the higher-level lego models: we see what kinds of APIs our SaaS customers want, then also look at the kinds of API niceties we want for our own applications (like a caching layer, advanced filtering) and implement a combination of the two. Variety: without knowing, you might assume adding a new integration is low-ambiguity and routine. But each integration we launch is special, completely different and posing unique challenges. This requires researching that system and its nuances in great depth before building on top of it. It’s part engineering, part archeology. Tech Stack Backend: PHP Laravel...why? We have extensive experience using PHP to scale Alexa's NLP to 100M users. From YC: https://youtu.be/rP7bpYsfa6Q?t=992 Good HN post: https://news.ycombinator.com/item?id=35896954 Frontend: TypeScript, React Infra: Redis, Postgres, AWS - CDK, EC2 Benefits Healthcare: we cover 90% of your healthcare costs with several plan options. 401k: we match 100% of your contributions, up to 4% of annual salary. Relocation: sizable relocation bonus for folks currently located outside of the Bay Area. Gym: on-site gym with Peloton, squat rack, Tempo, Yoga setup, and more. Visa: we sponsor Visas (H1B, TN, etc.) for candidates who are a good fit!",
        "url": "https://www.linkedin.com/jobs/view/3625986796"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3942359139,
        "company": "Harness",
        "title": "Senior/Staff Software Engineer - Data Platform",
        "created_on": 1720636240.427069,
        "description": "Harness is a high-growth company that is disrupting the software delivery market. Our mission is to enable the 30 million software developers in the world to deliver code to their users reliably, efficiently, securely and quickly, increasing customers’ pace of innovation while improving the developer experience. We offer solutions for every step of the software delivery lifecycle to build, test, secure, deploy and manage reliability, feature flags and cloud costs. The Harness Software Delivery Platform includes modules for CI, CD, Cloud Cost Management, Feature Flags, Service Reliability Management, Security Testing Orchestration, Chaos Engineering, Software Engineering Insights and continues to expand at an incredibly fast pace. Harness is led by technologist and entrepreneur Jyoti Bansal, who founded AppDynamics and sold it to Cisco for $3.7B. We’re backed with $425M in venture financing from top-tier VC and strategic firms, including J.P. Morgan, Capital One Ventures, Citi Ventures, ServiceNow, Splunk Ventures, Norwest Venture Partners, Adage Capital Partners, Balyasny Asset Management, Gaingels, Harmonic Growth Partners, Menlo Ventures, IVP, Unusual Ventures, GV (formerly Google Ventures), Alkeon Capital, Battery Ventures, Sorenson Capital, Thomvest Ventures and Silicon Valley Bank. Position Summary We are seeking a talented and experienced data engineer to join our team. The ideal candidate will be responsible for designing, developing, and maintaining our data pipelines and infrastructure. They will work closely with cross-functional teams to understand data requirements, implement solutions, and ensure data quality and reliability. The data engineer will also be involved in optimizing data processes and supporting data analytics initiatives. About The Role Design, build, and maintain scalable data pipelines and infrastructure to support data ingestion, processing, and storage. Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and develop solutions to meet business needs. Implement data quality checks and ensure data integrity and reliability throughout the data lifecycle. Optimize and tune data pipelines for performance and efficiency. Troubleshoot and debug data-related issues, and provide timely resolution. Stay updated with the latest technologies and best practices in data engineering and apply them to improve existing systems. Document data architecture, processes, and workflows. Provide support and guidance to junior members of the team. About You Bachelor's degree in Computer Science, Engineering, or related field. Master's degree preferred. 3+ yrs of proven experience as a data engineer or similar role, with a strong background in data warehousing, ETL/ELT processes, and data modeling. Proficiency in programming languages such as Python, Java, or Scala. Experience with big data technologies such as BigQuery, Spark, Kafka, DBT, SQLMesh etc. Hands-on experience with cloud platforms such as AWS, Azure, or Google Cloud. Strong SQL skills and experience working with relational and NoSQL databases. Familiarity with data visualization tools such as Tableau, Power BI, or Looker. Excellent problem-solving and analytical skills. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Preferred Experience Experience with containerization and orchestration tools such as Docker and Kubernetes. Knowledge of machine learning techniques and frameworks. Experience with DevOps practices and tools for CI/CD. Work Location Mountain View, CA - Hybrid (3 days / week onsite) What you will have at Harness Competitive salary Comprehensive healthcare benefits Flexible Spending Account (FSA) Flexible work schedule Employee Assistance Program (EAP) Flexible Time Off and Parental Leave Monthly, quarterly, and annual social and team building events Monthly internet reimbursement Pay transparency $145,000—$185,000 USD Harness In The News Harness Grabs a $150m Line of Credit Welcome Split! Harness Snags $230 Series D - $3.7B Valuation Harness Recognized in Inc.'s Best Workplace Awards 2022 Harness on LinkedIn: America's Great Companies to Work For -- And What You Can Learn From #6 - Glassdoor Best Places to Work 2021 list #17 on Forbes Top 50 Cloud Companies to Work For #47 on LinkedIn’ Top 50 Companies to Work For #2 on Quartz 2021 list best places to work for remote workers 2021 Career Launching Companies List All qualified applicants will receive consideration for employment without regard to race, color, religion, sex or national origin.",
        "url": "https://www.linkedin.com/jobs/view/3942359139"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3915647798,
        "company": "OpenAI",
        "title": "Software Engineer, Engineering Acceleration",
        "created_on": 1720636246.3198295,
        "description": "About The Team The Applied AI team safely brings OpenAI's technology to the world. We released ChatGPT, Plugins, DALL·E, and the APIs for GPT-4, GPT-3, embeddings, and fine-tuning. We also operate inference infrastructure at scale. There's a lot more on the immediate horizon. We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth. We serve end-users directly through ChatGPT, and serve developers through our APIs, which power product features that were never before possible. About The Role The Engineering Acceleration team designs, builds and maintains the foundational systems that engineers use to build ChatGPT and the API. This is a fast-growing team and you will get a chance to own and define the strategy, vision, and plan for how to accelerate engineering. In This Role, You Will Drive the design, development, and implementation of tools, systems, and processes that accelerate engineering velocity, reduce manual effort, and increase the quality of output. Use our latest AI tools to re-think how we can be the most productive team in the industry. Work closely with various teams within OpenAI to understand their workflows, challenges, and needs, and ensure the tools and systems built by the Engineering Acceleration team address these requirements. Bring new features and research capabilities to the world by partnering with product engineers to lay the necessary technical foundations. Guide and advise product engineering teams on best practices for ensuring observable, scalable systems. Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group think. Like all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed. You Might Thrive In This Role If You Have 5+ years of experience in engineering, including 3+ years of experience in infrastructure building tooling for developers. Have experience-driven empathy for the tools, frustrations, and processes that slow engineering teams down and lead to toil or burnout. Care deeply about diversity, equity, and inclusion, and have a track record of building inclusive teams. Have a voracious and intrinsic desire to learn and fill in missing skills—and an equally strong talent for sharing learnings clearly and concisely with others. Are comfortable with ambiguity and rapidly changing conditions. You view changes as an opportunity to add structure and order when necessary. As technical context: at the heart of our infrastructure is a large-scale deployment of GPU nodes running in dozens of Kubernetes clusters across regions. Some core technologies we build with include Terraform, Buildkite, Postgres, Cosmos DB, Kafka, Python, and FastAPI. This role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employee About OpenAI OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity. We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status. For US Based Candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records. We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link. OpenAI Global Applicant Privacy Policy At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.",
        "url": "https://www.linkedin.com/jobs/view/3915647798"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3960503919,
        "company": "LinkedIn",
        "title": "Senior Software Engineer, Multi-Language Infrastructure",
        "created_on": 1720636247.9494357,
        "description": "LinkedIn is the world’s largest professional network, built to help members of all backgrounds and experiences achieve more in their careers. Our vision is to create economic opportunity for every member of the global workforce. Every day our members use our products to make connections, discover opportunities, build skills and gain insights. We believe amazing things happen when we work together in an environment where everyone feels a true sense of belonging, and that what matters most in a candidate is having the skills needed to succeed. It inspires us to invest in our talent and support career growth. Join us to challenge yourself with work that matters. This role will be based in Mountain View, CA. At LinkedIn, we trust each other to do our best work where it works best for us and our teams. This role offers a hybrid work option, meaning you can both work from home and commute to a LinkedIn office, depending on what’s best for you and when it is important for your team to be together. As part of our world-class software engineering team, you will be charged with building the next-generation infrastructure and platforms for LinkedIn, including but not limited to: an application and service delivery platform, massively scalable data storage and replication systems, cutting-edge search platform, best-in-class AI platform, experimentation platform, privacy and compliance platform, and service and language infrastructure. You will work and learn among the best, putting to use your passion for  distributed technologies and algorithms, API design and systems-design, and your passion for writing code that performs at an extreme scale. LinkedIn has already pioneered well-known open-source infrastructure projects like Apache Kafka, Pinot, Azkaban, Samza, Venice, Datahub, Feather etc. We also work with industry standard open source infrastructure products like Kubernetes, gRPC and GraphQL - come join our infrastructure teams and share the knowledge with a broader community while making a real impact within our company. Responsibilities: - You will design, build and operate one of the infrastructure platforms that power all of Linkedin’s core applications. - You will participate in design and code reviews to maintain our high development standards. - You will partner with peers, leads and internal customers to define scope, prioritize and build impactful features at a high velocity. - You will mentor other engineers and will help build a fast-growing team. - You will work closely with the open-source community to participate and influence cutting edge open-source projects. Basic Qualifications: - BA/BS Degree in Computer Science or related technical discipline, or related practical experience. - 2+ years of industry experience in software design, development, and algorithm related solutions. - 2+ years experience programming in object-oriented languages such as Python, Go, and/or Rust - Hands on experience developing distributed systems, large-scale systems, databases and/or Backend APIs Preferred Qualifications: - BS and 5+ years of relevant work experience, MS and 4+ years of relevant work experience, or PhD and 2+ years of relevant work experience - Experience in architecting, building, and running large-scale distributed systems - Experience with industry, opensource, and/or academic research in technologies such as GraphQL, gRPC, Envoy Proxy, Kubernetes - Experience with interoperability with C++ and/or Rust, including Foreign Function Interface (FFI). - Hands-on experience with SideCar architecture - Experience with open-source project management and governance - Experience in building a language platform - Experience in improving the developer experience and enabling innovation. Suggested Skills: - Distributed Systems - Python - Go - Rust You will Benefit from our Culture: We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels LinkedIn is committed to fair and equitable compensation practices. The pay range for this role is $128,000 to $210,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor. The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For more information, visit https://careers.linkedin.com/benefits. Equal Opportunity Statement LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information. LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful. If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation. Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to: -Documents in alternate formats or read aloud to you -Having interviews in an accessible location -Being accompanied by a service dog -Having a sign language interpreter present for the interview A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response. LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information. Pay Transparency Policy Statement As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency. Global Data Privacy Notice for Job Candidates This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",
        "url": "https://www.linkedin.com/jobs/view/3960503919"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Milpitas, CA",
        "job_id": 3830430650,
        "company": "Zivahh LLC",
        "title": "Data Center Infrastructure Deployment Engineer",
        "created_on": 1720636249.8019857,
        "description": "Experience: 7- 10 years Location: Santa Clara, Milpitas- CA Job Type: 12 month Contract (Contract to Hire) Job Responsibilities Execute space & power, cabling, and infrastructure requirements to support present and future edge network needs in the region. Design and plan critical electrical/mechanical infrastructure for new Data Center sites. Collaborate with Engineering team to design floor plans for edge/pop sites and allocate space for network functions. Implement engineering design packages for edge/pop sites according to ENS standards. Proactively contribute to evolving documentation, automation, and processes. Understand current and future POP infrastructure needs and contribute to retrospective project reviews. Ensure adherence to process standards and oversee the site acceptance process for new POP sites. Minimum Qualifications 6-8 years of experience as an electrical engineer. Proficiency in AutoCAD/AutoDesk tools, with experience in BIM 360/Blue Beam preferred. Knowledge of infrastructure architecture principles, including space lineup, airflow, and cooling. Familiarity with Telecom Central Offices, Data Centers, Collocations, and Remote Hut environments, with expertise in power infrastructure engineering. Understanding of optical network design and installation, especially in service provider or enterprise networks. Experience working in POPs, carrier hotels, data centers, and Central Office environments. Technical knowledge of regional Data Center electrical and cooling configurations, including IEC, NEMA standards, AC/DC power, and power redundancy scenarios. Must-Have Qualifications Bachelor's degree in Electrical/Electronics Engineering or equivalent. Experience overseeing Global POP/CLS Infrastructure projects. Must-Have Skills Knowledge of Telecom Central Offices, Data Center, Collocations, and Remote Hut environments, including power infrastructure engineering. Outstanding proficiency with AutoCAD/AutoDesk tools, with experience in BIM 360/Blue Beam preferred. Knowledge of infrastructure architecture principles, such as space lineup, airflow, and cooling.",
        "url": "https://www.linkedin.com/jobs/view/3830430650"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3959912913,
        "company": "LinkedIn",
        "title": "Sr. Staff Software Engineer, Developer Platforms and Experience",
        "created_on": 1720636251.5807226,
        "description": "LinkedIn is the world’s largest professional network, built to create economic opportunity for every member of the global workforce. Our products help people make powerful connections, discover exciting opportunities, build necessary skills, and gain valuable insights every day. We’re also committed to providing transformational opportunities for our own employees by investing in their growth. We aspire to create a culture that’s built on trust, care, inclusion, and fun – where everyone can succeed. Join us to transform the way the world works. At LinkedIn, we trust each other to do our best work where it works best for us and our teams. This role offers both hybrid and remote work options. This means you can work from home and commute to a LinkedIn office, depending on what's best for you and when it is important for your team to be together, or you can work remotely from most locations within the country listed for this role. The team is part of the Developer Platforms and Experience organization with the mission to empower LinkedIn engineers to ship high quality features with confidence and high velocity. We provide infrastructure, tooling and experiences to accelerate development with world-class automations, including generative AI, code generation, and code transformation, across various stages of the development lifecycle and various technology stacks. We partner with organizations and engineering teams across the company to build the right strategy and investments that boost engineering productivity and product quality. As a Sr. Staff Software Engineer, you will be part of the leadership team responsible for shaping the company-wide vision for automating software maintenance tasks, in partnership with engineering leaders across the company. You will be driving investments based anywhere from industry best practices to innovative new technologies, addressing unique LinkedIn challenges and the ever-evolving technical landscape. The responsibilities include anything from building large scale automation infrastructure to automation frameworks, intelligent diagnostics and analytics, or user experiences, all with the goal of keeping your fellow engineers productive and effective in shipping high quality products. Responsibilities: •\tShape and execute on the engineering automation strategy by leading multiple initiatives across the company. •\tOwn and drive the technical roadmap and architecture for key automation infrastructure and processes. •\tDesign and build high performance large scale systems to automate development tasks across the LinkedIn engineering ecosystem. •\tIdentify and design metrics to ensure the safety of automations and maintain developer trust. •\tBuild innovative solutions with the application of AI&ML technologies to provide intelligent productivity enhancements. •\tOwn, manage and extend services and infrastructure, constantly improving and adding new features, while driving operational excellence. •\tPromote and drive best practices and industry standards across the company. •\tPartner with engineers across the company to guide, influence and iterate on their automation strategies and build best in class engineering productivity solutions. •\tLead and mentor the next generation of engineering leaders by building a culture of craftsmanship and innovation. Basic Qualifications: •\tBA/BS Degree in Computer Science or related technical discipline, or related practical experience. •\t5+ years of experience in software design, development, and algorithm related solutions •\t5+ years of experience in programming languages such as Python, Java, C/C++, C# •\t2+ years of experience in an architect or technical leadership position Preferred Qualifications: •\tBS and 10+ years of relevant work experience, MS and 8+ years of relevant work experience, or PhD and 6+ years of relevant work experience. •\tExperience architecting and launching large complex projects. •\tPassion for developer experience and productivity, and familiarity with current trends and best practices. •\tExperience with developer toolchains such as build systems, CI/CD pipelines, common deployment models and infrastructure. •\tExperience with large-scale distributed systems and client-server architectures. •\tExperience with strategic planning, executing on a long term roadmap, team development and scaling processes to support business growth. •\tExperience leading by influence, formulating and driving technical strategies across various organizations. Suggested Skills: •\tTechnical Leadership •\tBackend development •\tDeveloper Productivity •\tPlatform design and architecture •\tCode transformation tools and/or AI code models You will Benefit from our Culture: We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels. LinkedIn is committed to fair and equitable compensation practices. The pay range for this role is $171,000 to $280,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor. The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For more information, visit https://careers.linkedin.com/benefits. Equal Opportunity Statement LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information. LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful. If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation. Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to: -Documents in alternate formats or read aloud to you -Having interviews in an accessible location -Being accompanied by a service dog -Having a sign language interpreter present for the interview A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response. LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information. Pay Transparency Policy Statement As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency. Global Data Privacy Notice for Job Candidates This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",
        "url": "https://www.linkedin.com/jobs/view/3959912913"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3967709369,
        "company": "San Francisco Health Plan",
        "title": "Senior Software Engineer",
        "created_on": 1720636253.3042638,
        "description": "Are you ready to play a vital role in ensuring equitable access to quality health care to the diverse San Francisco communities? San Francisco Health Plan (SFHP) has that opportunity for you. As a Senior Software Engineer at SFHP, you will be part of a creative, innovative, and mission-driven software engineering team which plays a central role in building and delivering system integrations, applications, and automated processes. The team strives to excel in satisfying SFHP core mission of providing quality healthcare to our members, empowering providers with access to member eligibility info, efficient and accurate claims processing and implementing various CA Healthcare initiatives that improve healthcare outcomes of SF communities. You will be working closely with other engineering teams, business system analysts, quality assurance engineers to design, build, test and maintain such software applications. You will be applying common SDLC process methodologies (e.g., AGILE, SCRUM, Waterfall) and leverage Microsoft’s suite of technology platforms (i.e., .Net Framework, SQL Server, ASP.NET, MVC, Web API 2, WCF, LINQ and Azure DevOps) to develop, maintain, deliver software processes, web applications, REST APIs, that meets business needs. You will also be involved in designing and architecting solutions that conform to best industry practices and SFHP standards for developing highly optimized, well-organized, scalable and reusable software. You will also be reviewing business requirements documents, user stories and functional specifications; author technical specification documents; review, clarify and understands business needs to provide the most efficient and optimal application to support business function and most of all, serves as a SME for the common codebase. Please note that while SFHP supports a hybrid work environment, this role will be required to be onsite and in-office a minimum of 4 days per month. This is a hybrid position, based in our Downtown San Francisco office. Salary Range: $126,000 - $141,000/year What You Will Do Create and finalize technical specifications documents in response to approved business requirements. Design, develop, test and deploy multi-tiered applications and batch processes. Create and execute unit test plans based on system and validation requirements. Troubleshoot, optimize, and tune applications. Document all work-product, per SFHP’s best practices and standards. Maintain existing code and fix defects whenever needed. Ensure that all software is delivered on time as per project commitments. Ensure smooth functioning of our development, QA, and production environments. Collaborate with Business Systems Analysts on business requirements review Conduct data analysis; identify issues; recommend and implement solutions. Create ad-hoc and automated reporting solutions as needed Perform other related duties and special projects as assigned. Foster an environment that solicits and enlists diverse and inclusive perspectives and approaches to better serve our staff, our members and our providers. What You Will Bring Bachelor’s degree in Computer Science or equivalent experience. 7+ Years of Software engineering experience in a variety of programming languages. 7+ Years of BizTalk and .NET developer experience using Visual Studio. 7+ Years of advanced SQL Server experience. 7+ Years of proven ability in application development. 3+ years delivering on large scale, high-visibility software development projects. 2+ Years mentoring junior members of software development teams. Worked on the complete SDLC from analysis of requirements to software deployment of at least 4 large projects (at least 2 of the projects must be as a Senior Engineer). Experience working directly with business partners and Product Managers. Knowledge of Health Care industry systems including claims processing systems, Member Eligibility processing, Provider Management and Care Management Systems, Health Care Payment, Billing & Accounting Systems. Expert knowledge of .NET Framework, ASP.NET, ASP.NET MVC, Web API (current supported version), C#, JSON, JQuery, Bootstrap. Expert Knowledge of Visual Studio 2015 & 2019, and Azure DevOps. Expert Knowledge of SQL Server 2017development (complex SQL, store procedures, functions), SSIS packages and SSRS reports. What We Offer A competitive and robust compensation package, including: Health benefits Medical: You’ll have a choice of medical plans, including options from Kaiser and Blue Shield of California. Employee-only coverage in the HMO plans is currently available at no cost and dependent coverage is heavily subsidized by SFHP. Dental: You’ll have a choice of a basic dental plan or an enhanced dental plan which includes orthodontic coverage. Vision: Employee vision care coverage is available through Vision Service Plan (VSP). Retirement – Employer-matched CalPERS Pension and 401(a) plans, 457 Plan Time off – 23 days of Paid Time Off (PTO) and 13 paid holidays Professional development: Opportunities for tuition reimbursement, professional license/membership. An opportunity to work in a vibrant atmosphere with the most amazingly talented people who are shaping the future of healthcare! The chance to make a difference in the lives of many San Francisco residents! San Francisco Health Plan is proud to be an equal opportunity employer. We are committed to a work environment that supports and respects all individuals and in which our processes are applied without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, marital status, age, disability, national or ethnic origin, military service status, citizenship, or other protected characteristics. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. San Francisco Health Plan is an E-Verify participating employer.",
        "url": "https://www.linkedin.com/jobs/view/3967709369"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3930464911,
        "company": "Fathom",
        "title": "Senior Software Engineer (Backend/Data)",
        "created_on": 1720636255.0404546,
        "description": "Fathom is on a mission to use AI to understand and structure the world's medical data, starting by making sense of the terabytes of clinician notes contained within the electronic health records of the world's largest health systems. Our deep learning engine automates the translation of patient records into the billing codes used for healthcare provider reimbursement, a process today that costs hospitals in the US $15B+ annually and tens of billions more in errors and denied claims. We are a venture-backed company that completed a Series B round of financing for $46M in late 2022. We are looking for a Senior Software Engineer (Backend/Data) to work on data products that drive the core of our business. We want to work with teammates in the Bay area, who are excited about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration. If you are a backend expert able to unify data, and build systems that scale from both an operational and an organizational perspective, Fathom is an opportunity worth exploring! Your role and responsibilities will include: Developing data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs Building performant and expressive interfaces to the data Creating infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning We are looking for a teammate with: 5+ years of software engineering experience in a company/production setting Knowledge of algorithms, data structures and systems design Experience building data pipelines from disparate sources Hands-on experience building and scaling up compute clusters A solid understanding of databases and large-scale data processing frameworks like Hadoop or Spark and the ability to evaluate which tools to use on the job A unique combination of creative and analytic skills apt of designing a system capable of pulling together, training, and testing dozens of data sources under a unified ontology Bonus points if you have: Know-how of developing systems to do or support machine learning, including experience working with NLP toolkits like Stanford CoreNLP, OpenNLP, and/or Python's NLTK Expertise with wrangling healthcare data and/or HIPAA Experience with managing large-scale data labelling and acquisition, through tools such as through Amazon Turk or DeepDive Compensation: Salary: $175,000 USD - $220,000 USD Company Equity Benefits: PTO and Uncapped Sick Days Medical/Dental/Vision Coverage 401k Matching $1,500 USD Home Office Budget Virtual and Local Office (San Francisco, New York City and Toronto) Team Building Events Annual Company Off-site",
        "url": "https://www.linkedin.com/jobs/view/3930464911"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3952778497,
        "company": "SoFi",
        "title": "Senior Software Engineer, Cloud Efficiency",
        "created_on": 1720636256.6249514,
        "description": "Employee Applicant Privacy Notice Who we are: Shape a brighter financial future with us. Together with our members, we’re changing the way people think about and interact with personal finance. We’re a next-generation financial services company and national bank using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. Join us to invest in yourself, your career, and the financial world. The Role: We are seeking a highly skilled and experienced Senior Software Engineer to join our Platform Cloud Efficiency team that enhances performance, scalability, and cost-effectiveness of our cloud-based systems. You will have the opportunity to directly impact the direction and architecture of our cloud and best practices that are used across all of SoFi engineering. If you are a seasoned Software Engineer with a passion for building software and a strong background in cloud technologies, we invite you to apply for this exciting opportunity. What You’ll Do: Collaborate with cross-functional teams to design and implement scalable and efficient cloud solutions. Development of software solutions to enhance cloud efficiency, including automation scripts. Tooling, and infrastructure as code (IaC). Identify opportunities for automation and process improvement to enhance cloud efficiency. Collaborate with cloud and software engineers to integrate solutions seamlessly into cloud environments. Implement monitoring and analytic solutions to track key cloud efficiency metrics. Analyze data to identify areas for improvement and provide insights to drive optimization strategies. Work closely with cross-functional teams to understand the requirements and design software that is intuitive, efficient, scalable and reliable. Conduct code reviews and provide constructive feedback to other team members. What You’ll Need: Bachelor's or Master's degree in Computer Science, Software Engineering, or a related technical field. 5+ years software development experience. Deep expertise in cloud platforms including AWS, and cloud native technologies. Strong programming fundamentals (Java/Kotlin, Python, Go). Strong understanding of software design principles, microservice architecture and best practices. Experience with infrastructure as code (IaC) tools and practices. Experience with container orchestration (e.g. Docker, Kubernetes), Networking and service meshes (e.g. Istio). Experience with workflows (e.g. Temporal, Apache Airflow, Cadence). Experience with streaming and messaging systems (e.g. Kafka, Kinesis), is a plus. Compensation And Benefits The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location. To view all of our comprehensive and competitive benefits, visit our Benefits at SoFi page! SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law. The Company hires the best qualified candidate for the job, without regard to protected characteristics. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. New York applicants: Notice of Employee Rights SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com. Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time. Internal Employees If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.",
        "url": "https://www.linkedin.com/jobs/view/3952778497"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Santa Clara, CA",
        "job_id": 3849704348,
        "company": "Tech Firefly",
        "title": "Senior Software Engineer",
        "created_on": 1720636258.1891491,
        "description": "Summary: The Project Manager is an Information Technology (IT) position and will direct, oversee, monitor, and report to our client. The Project Manager will collaborate with project stakeholders and implement the project work plan to achieve project objectives. The Project Manager will lead daily Agile Scrum standup meetings and help identify and resolve project team issues. The ideal candidate will have a strong background in computer science, experience with software development, Quality Automation and Data reporting background , and a passion for building innovative products. Responsibilities: Working closely with the stakeholders to prioritize goals on the Engineer, Data and QA Automation roadmaps, understanding ROI to the client with mindful of partnerships with: Financial capital Political capital Public visibility Strategic alignment Proactively communicating status updates, blockers, etc. to stakeholders in different streams awaiting delivery Managing TaskFlow backlogs and sprints for Engineers, Data and QA teams Writing documentation for new processes, scripts, workflows, integrations and more Scope the timelines for each project and maintain the timeframes, Story point estimates and status reports Coordinating project team members and developing schedules and individual responsibilities Implementing IT strategies that deliver projects on schedule and within budget by using project management tools to track project performance and schedule adherence Publishing Eng, Data and QA team's accomplishments as a newsletter with the entire leadership group. Scheduling/Attending partner meetings to help scope Engineer and Data custom work Serving as the first POC for the stakeholders when Script/Dash/Integration not WAI. Requirements Bachelor's degree in computer science or related field 7+ years of experience in software engineering, and Data reporting Preferred any experience with Python or Java or Data reporting or BI tool. Excellent communication and teamwork skills Strong presentation skills are mandatory Benefits Subsidized Medical, Dental and Vision Life Insurance 401k Employee Assistance Programs",
        "url": "https://www.linkedin.com/jobs/view/3849704348"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3934994363,
        "company": "Ciitizen",
        "title": "Senior Analytics Engineer",
        "created_on": 1720636262.5494888,
        "description": "Who We Are At Ciitizen, we have a singular mission: to improve the lives of the 350 million+ people suffering from rare and complex conditions. We empower patients with seamless access and control over their health data that they can share across our multi-sided platform with caregivers, providers and researchers to illuminate better treatment and support options, while bringing therapies to patients faster. We support thousands of patients, work with a rapidly growing network of patient advocacy organizations, and innovate with leading biopharma organizations to accelerate therapies, always ensuring patients remain at the center. We are a team of builders, advocates, family caregivers and researchers who have had first-hand experience across the spectrum of rare and complex diseases. Led by a seasoned founding team with a history of successful exits in healthcare and consumer startups, and supported by top-tier investors, we are a close-knit, mission-driven group seeking exceptional talents to join us. We are a hybrid team based out of the San Francisco Bay Area. The Role We are in search of a seasoned Analytics Engineer to enhance and re-architect our end-to-end analytics infrastructure. Our goal is to consolidate and streamline our data architecture and tooling, which currently includes marketing and CRM applications such as Wordpress, HubSpot, and Salesforce, as well as customer and internal facing react applications, and an underlying LLM data platform used to extract clinical insights from medical records. We currently leverage a combination of Segment, Amplitude and analytics/reports native to vendor platforms (like Salesforce) to support analytics in parts of the business at differing levels of maturity. In this role, you will streamline our analytics strategy and implementation by driving the data architecture, tooling decisions and best practices. You will build a nimble and easily usable analytics infrastructure to support product insights, business metrics and a granular view of our end to end funnel, as well as insight into clinical data of our patient population ensuring compliance with HIPAA and other applicable privacy standards. Your role will encompass ownership of the full lifecycle of this work, from initial design to deployment. You will collaborate with internal teams to ensure that the system aligns with our operational needs and drives efficiency and insights across the organization. We are keen to bring on a full-time team member and are also open to independent contractors or contract-to-hire for this role. Key Responsibilities Architect and implement a scalable and efficient end-to-end tracking and analytics system across our platform. Conduct thorough analysis to understand and document data requirements. Provide recommendations on best technologies and tooling for data processing and analytics . Data Integration: Seamlessly integrate data from our proprietary data platform, HubSpot, Salesforce, and other key business tools, ensuring data integrity and fluidity. Data Processing: Design and implement automated, reliable, scalable and efficient data processing pipelines for analytics; Ensure data integrity, data quality and optimize data processing workflows. Data Modeling: Design and implement physical and logical data models for different analytical use cases. Data Analytics: Work with stakeholders to build data products that provide insight into our data, leveraging appropriate visualization, BI, data sciences tools. Compliance with privacy regulations: Strictly adhere to HIPAA and other applicable privacy regulations, especially critical due to the involvement of medical records and collection of health and health-relevant information from users via web and product interactions. Qualifications Advanced degree in Computer Science, Engineering, or related field. 5+ years experience in Data Engineering and/or Analytics Engineering roles (particularly building end to end tracking) Demonstrated ability in data modeling, warehousing, and pipeline development. Hands-on experience with ETL/ELT tools and technologies (e.g. DBT, FiveTran, Glue…) Previous experience designing, architecting and implementing end-to-end analytics systems Proficient in SQL/NoSQL databases, Big Data technologies, and cloud platforms. Familiarity with analytics tools and technologies including Segment and Amplitude, amongst others (e.g. Looker, Tableau,...) Experience working in fast-paced, start-up environments Expertise in Python, Java, Scala, or similar programming languages. Excellent problem-solving, analytical, and consulting skills. Strong communication skills, with the ability to liaise effectively with various stakeholders. How To Apply If you are a passionate about rearchitecting end-to-end analytics infrastructure and excited about shaping the future of healthcare and making a meaningful impact on the rare disease community, we invite you to submit your resume, and an optional cover letter detailing your relevant experience and why you are a great fit for this role. Ciitizen is an equal opportunity employer, and we welcome candidates from all backgrounds to apply.",
        "url": "https://www.linkedin.com/jobs/view/3934994363"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3787335474,
        "company": "Lever Middleware Test Company 2",
        "title": "Back-End Software Engineer",
        "created_on": 1720636264.114277,
        "description": "Lever builds software for teams to source, interview, and hire top talent. Our team strives to set a new bar for enterprise software with modern, well-designed, real-time apps. We participated in Y Combinator in summer 2012, and since then have raised $33 million. This year, we're doubling the team in size, and we're looking forward to supporting more great companies like Netflix, Eventbrite, and Lyft. Under the hood, we're a technology company with a powerful open-source web framework: DerbyJS. It is the first and only open-source MVC framework that syncs all data via an Operational Transformation backend, using the same algorithm that powers Google Docs. DerbyJS is also uniquely optimized to render everything on the server as well as the client. Assembling a top notch team is the #1 challenge forward-looking companies know they must solve. At Lever, we’re building next-generation collaboration software that helps companies to bring more transparency, participation, and engagement to their hiring. As a Software Engineer, you’ll help us build out our core product by developing high-impact, user-facing features. In our growing engineering organization, you’ll be a driver for positive change to Lever’s engineering culture, processes and technology. You will be a strong voice in product planning, drive the implementation and release of major features, and be a champion of best practices for writing well-tested, well-organized code. You’ll become familiar with all parts of our stack—including our open source web framework, DerbyJS. You will exercise judgment in making tradeoffs between design and feasibility. You’ll engineer your features to be scalable and resilient in a complex, single-page application. We believe that user-centric design ultimately leads to the best products, so we listen closely to our users, both external and internal. As an engineer on our close-knit, cross-functional team, you’ll be an active voice in shaping our product. Lever is constantly rolling out high-demand features and tackling ever greater challenges of scale. You’ll join a team where everyone—including you—is knowledgeable about development patterns and cares about the product development process. We are an incredibly supportive team–we love to pitch in when problems arise and give great peer feedback to help each other grow. We are passionate about lots of things – browser performance, code reviews, debugging, continuous integration, creating a great hiring experience, and pandas – and we love sharing those passions with each other. Our Technology Lever is built on our own modern web framework based on NodeJS called DerbyJS. ShareDB–an open-source implementation of operational transform–enables us to sync data real-time. Learn more about the power of OT from our CTO Nate's conference talk about Operational Transform! For our data layer and search, we use MongoDB, Redis, and Elasticsearch. For deployment, we use the combined forces of npm, AWS, Jenkins, and Docker. Within 3 months, you’ll… Build, launch, and support your first big feature Master DerbyJS development patterns Participate in support engineering and on-call rotations to help diagnose and resolve production problems and customer issues. Write internal documentation for your features and systems Lever builds software for teams to source, interview, and hire top talent. Our team strives to set a new bar for enterprise software with modern, well-designed, real-time apps. We participated in Y Combinator in summer 2012, and since then have raised $33 million. This year, we're doubling the team in size, and we're looking forward to supporting more great companies like Netflix, Eventbrite, and Shopify. Under the hood, we're a technology company with a powerful open-source web framework: DerbyJS. It is the first and only open-source MVC framework that syncs all data via an Operational Transformation backend, using the same algorithm that powers Google Docs. DerbyJS is also uniquely optimized to render everything on the server as well as the client. Lever is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse workforce. A look into life at Lever! Lever is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse workforce.",
        "url": "https://www.linkedin.com/jobs/view/3787335474"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3917183347,
        "company": "Zip",
        "title": "Software Engineer, Product (Early Career)",
        "created_on": 1720636265.674677,
        "description": "Zip is tackling the $50B+TAM space to transform the way businesses manage spend. Our co-founders started Zip (YC S2020) because they saw the challenges companies had using outdated 20 year old software to manage hundreds of millions of dollars in spend every year. We invented the world’s leading Intake-to-Procure solution to bring a consumer grade user experience to B2B purchasing. And, we’re just getting started. We're a fast growing team that helped scale category-defining companies like Airbnb, Facebook, Salesforce, Apple, Quora, Pinterest, and Square. With $180 million in funding from YC Continuity (Y Combinator), CRV and Tiger Global, we're valued at $1.5 billion in just 3 years. In today's economic climate, the value we offer our customers is more critical than ever and our business is accelerating. We're growing quickly and need your help! Your Role As a Software Engineer you will be responsible for building Zip’s core products and architecture. You will ship features that will be immediately used by our customers, and will work with a tight-knit team that values open communication and cross-functional collaboration. We move quickly to solve a wide range of complex technical and product challenges. While we are an experienced team that can provide constant guidance and mentorship, we value engineers who can autonomously scope and solve difficult technical challenges. You Will Design and build highly reliable and resilient products and features. Work closely with cross functional product and customer-facing teams to understand requirements and ship thoughtful solutions. Write high-quality, extensible, and maintainable code. Design and build scalable frontend applications and components. Design and build APIs to drive existing and new features for a web-based application. Qualifications 1-3 years of software engineering experience. BS or higher, in Computer Science or related technical field involving coding (e.g. physics or math) Experience with web application and API development in production environments. At Zip, our stack includes Python, Javascript, React, and GraphQL. Experience with industry standard build, test, deploy tools. At Zip, our stack includes Kubernetes, Spinnaker, Jenkins, Kibana, Prometheus, and Grafana. Ability and interest to quickly learn new frameworks, architecture patterns, and programming languages as needed Experience working at a small company with diverse responsibilities is a bonus, but not required. Experience working with API connections with external systems like Jira, ServiceNow, Slack, etc is a bonus, but not required. The salary range for this role is $140,000 - $170,000. The salary for this position is determined based on a variety of job-related factors that may include location, relevant experience, education, or particular skills and expertise. Perks & Benefits At Zip, we’re committed to providing our employees with everything they need to do their best work. 📈 Start-up equity 🦷 Full health, vision & dental coverage 🍽️ Catered lunches & dinners for SF employees 🚍 Commuter benefit 🚠 Team building events & happy hours 🌴 Flexible PTO 💻 Apple equipment plus home office budget 💸 401k plan We're looking to hire Zipsters and that means hiring people who take ownership, communicate openly, have an underdog mindset, and are excited to increase the pace of innovation for every business in the world. We encourage all candidates to apply even if your experience doesn't exactly match up to our job description. We are committed to building a diverse and inclusive workspace where everyone (regardless of age, religion, ethnicity, gender, sexual orientation, and more) feels like they belong. We look forward to hearing from you!",
        "url": "https://www.linkedin.com/jobs/view/3917183347"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Diego, CA",
        "job_id": 3970539014,
        "company": "Auria Space",
        "title": "Digital Engineer (Software Engineer)",
        "created_on": 1720636267.2118216,
        "description": "Auria is looking for a full-time Digital Engineer (Software Engineer) to join our team in San Diego, CA! This is a contingent position pending on contract award. The Department of the Navy (DON), Naval Information Warfare Systems Command (NAVWAR) is acquiring support services for the development of networks, infrastructure, data architecture, tools and. The effort is to connect sensors and generally improve networking and data capabilities. Critical is the development of networks, infrastructure, data architecture, and tools and analytics that support the operational and developmental environment that will enable sustained maritime dominance for years to come. Salary Range: $95,000 - $145,000 Responsibilities: The Candidate shall identify risks associated with the development of enterprise architectures to address system of system cybersecurity designs, maximizing common and inheritable security controls in support of a defense in depth strategy through the utilization of digital engineering methods (e.g. model based systems engineering) for efforts in the RDT&E phase of the acquisition life cycle The Candidate shall screen all electronic deliverables or electronically provided information for malicious code using DoD approved anti-virus software prior to delivery to the Government The Candidate shall utilize appropriate controls (firewalls, password protection, encryption, digital certificates, etc.) at all times to protect contract related information processed, stored or transmitted on computers/servers to ensure confidentiality, integrity, availability, authentication, and non-repudiation The Candidate shall ensure provisions are in place to safeguard all aspects of information operations pertaining to this contract in compliance The Candidate shall ensure Data-at-Rest is required on all portable electronic devices including storage of all types. Encryption and digital signing of communications is required for authentication and non-repudiation Requirements: Bachelor Degree in a quantitative field, such as Electrical Engineering, Computer Engineering, Computer Science, Information Technology, or Information Systems. Additional years of experience and certifications may be considered in lieu of a formal 4 year degree 3+ years of experience in software engineering Experience with applying programming concepts in a professional or academic setting Experience with applying modern software development methodologies (e.g. Agile, DEVOPS/SEVSECOPS) in a professional or academic setting Security+ Certification or equivalent Secret Clearance Preferred: Master Degree of Science in a quantitative field, such as Electrical Engineering, Computer Engineering, Computer Science, Information Technology, or Information Systems 3+ years of experience in software engineering Experience and certifications in a wide range of software languages Agile Developer certification or Certified Scrum Developer certification Top Secret Clearance About Auria Auria is a provider of solutions and software in support of complex Space, National Security, and Cyber missions of federal, international, and commercial customers. Headquartered in Colorado Springs, CO and with operations in Boulder, CO, Washington, DC, Huntsville, AL, Albuquerque, NM, Ogden, UT, and San Diego, CA, our success is built on the excellence of diverse teams advancing innovative systems and operational software to strengthen our customers’ superiority in Space. With a distinguished track record and a spirit of relentless pursuit, we set the pace for progress and execute every mission with the utmost precision. When you join Auria as a full-time employee, you get many benefits which include: Generous PTO package with yearly tenure increases Flex time policy providing you the flexibility needed 11 Company-Paid Holidays per year Up to 4% match on 401(k) employee contributions, employer and employee contributions immediately vested Tuition and Certification Fee Assistance Low-cost medical plans that include company-sponsored HSA No-cost life insurance Employee Assistance Program (EAP) And much more! Auria is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, marital status, national origin, age, veteran status, disability, or any other protected class.",
        "url": "https://www.linkedin.com/jobs/view/3970539014"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3839795257,
        "company": "Lynx Analytics",
        "title": "Senior Data Engineer (Onsite)",
        "created_on": 1720636269.527099,
        "description": "COMPANY OVERVIEW Lynx Analytics was founded in 2010 by a group of INSEAD students and professors with a strong research background in graph analytics. Several of our founders since then became professors and faculty directors of analytics centers at leading US universities. Our founding purpose? To apply graph theory to simplify and solve complex, real-world business problems. Our mission has evolved over the years, and we currently offer a range of cutting edge data analytics and AI solutions to help companies transform their operations and optimise their commercial performance. Back then, graph theory was mostly the purview of social networking sites. We wanted to expand this technology and help companies leverage their communities to unlock greater growth. Lynx has offices in Singapore, US, Hong Kong, Hungary, and operations in several other countries such as Canada, Germany, Indonesia. We work with some of the world's largest companies and are constantly looking to expand our knowledge base and geographical footprint. Lynx Analytics' technology is deployed with various Clients internationally and has significant growth potential. We have a diverse and inclusive global team comprising Professors, PhDs, MSc's, and MBAs from Ivy Leagues, INSEAD and NUS with a broad spectrum of experience in start-ups and blue-chip companies (Google, Databricks, ZS, Abbvie, Amgen, Vodafone, Morgan Stanley, Palantir, Katana Graph to name but a few). It is the combination of our industry insight and experience, scalable proprietary technology, and highly qualified people that drives our compelling value proposition. We are looking for ambitious, innovative, empathetic and relentless team players to explore the career opportunities that we offer as we continue to scale our operations. KEY RESPONSIBILITIES As a Senior Data Engineer, your responsibility is to implement and deploy data analysis pipelines at various clients of Lynx Analytics. In this role, you will Understand the business problems we solve for our client. This role involves frequent communication with our client, and a close working relation with the Data Scientist. Discover the client's existing data sources that are relevant to the problem we try to solve. This includes discussions with client IT, data owners, future business users, etc. Together with IT employees of our client, decide on the technical architecture for the ETL solution. Implement the data ingestion subsystem: this is the system responsible for moving all the necessary data sources to a single location where the actual analysis will happen. Implement the data analysis pipelines using standard Big Data technologies (Spark, Airflow) Perform feature engineering to transform raw data into features that better represent the underlying problem to predictive models. Provide the underlying infrastructure (DevOps) REQUIREMENTS 5-6 years or more of Data Engineering experience BS or Master's degree in a relevant field (Computer Science, Software Engineering, or similar) Experience in GCP, Airflow and Spark Solid experience in Python and SQL Experience in project delivery to business customers Strong problem-solving and communication skills will be needed. WHAT WE OFFER Opportunity to expand your knowledge of data engineering tools and platforms using state-of-the-art tech stack Create innovative solutions, take ownership of significant projects Work with large multinational clients globally. If you enjoy traveling around the globe, you will have the opportunity to do so Be a member of a very strong team including senior technology experts, mathematicians, ex-Googlers, Ivy League professors and telecommunications industry experts Startup atmosphere - collaborative company culture, openness for innovation, direct access to company management",
        "url": "https://www.linkedin.com/jobs/view/3839795257"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3961382279,
        "company": "Walmart",
        "title": "Senior, Software Engineer - Backend Big Data",
        "created_on": 1720636271.365502,
        "description": "Position Summary... What you'll do... About Team As part of Walmart's Affiliates and Social -Commerce team, you will be building highly scalable and reliable APIs, data pipelines, services and applications which will drive the next generation of affiliates, open- API and social commerce experiences. You'll independently handle high impact, critical software/systems monitoring issues, troubleshoot business and production issues. As a member of this fast-moving and highly entrepreneurial team, you'll be able to say that you work for the world's largest retailer and contribute to innovation and development to best-in-class methodologies that impacted perception and drastically changed business as we know it. What You'll Do Develop highly scalable data pipelines & services and solve complex software systems problems by leveraging state-of-the-art technology Gain exposure to various emerging technologies used in Marketing and E-commerce platforms. Drive projects of high visibility across the organization. Participates in medium- to large-scale, complex, cross-functional projects by reviewing project requirements; translating requirements into technical solutions; gathering requested information (for example, design documents, product requirement); writing and developing code; conducting unit testing; communicating status and issues to team members and stakeholders; collaborating with cross functional teams; troubleshooting open issues and bug-fixes; enhancing design to prevent re-occurrences of defects; ensuring on-time delivery. What You'll Bring Bachelor's Degree in Computer Science or related field and 2-3 years or master's degree in Computer Science or related field and 1-2 years of experience building scalable ecommerce applications Proficient in real time & batch data pipelines using big data technologies (i.e. Spark, Kafka, Hadoop & Hive). Worked extensively with Kafka or other high volume-low latency messaging infrastructure and built real time and batch data driven applications Proficient in RESTful Services, Java, Scala, Spring Boot/Play Framework, RDBMS, NoSql, Python Proficient with Experience with Cloud Technologies like Azure and GCP Designed, built, and maintained APIs, services of highly scalable platforms. Extensive knowledge of open-source libraries, design patterns and micro-service architecture. Familiarity with CI/CD and unit testing Experience in production system operations (logging, telemetry, alerting etc.) The keen eyes for detail and desire to learn, win, collaborate, and relish a challenge. Big Data engineering experiences. About Walmart Global Tech Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail. Flexible, Hybrid Work We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives. Benefits Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Equal Opportunity Employer Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people. The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process. At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more. ‎ ‎ ‎ You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. ‎ For information about PTO, see https://one.walmart.com/notices . ‎ ‎ Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart. ‎ Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. ‎ For Information About Benefits And Eligibility, See One.Walmart . ‎ The annual salary range for this position is $117,000.00-$234,000.00 ‎ Additional Compensation Includes Annual Or Quarterly Performance Bonuses. ‎ Additional Compensation For Certain Positions May Also Include ‎ ‎ Stock ‎ ‎ Minimum Qualifications... Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. Option 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 3 years' experience in software engineering or related area.Option 2: 5 years' experience in software engineering or related area. Preferred Qualifications... Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. Master's degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area., We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart's accessibility standards and guidelines for supporting an inclusive culture. Primary Location... 840 W California Ave, Sunnyvale, CA 94086-4828, United States of America",
        "url": "https://www.linkedin.com/jobs/view/3961382279"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Redwood City, CA",
        "job_id": 3937245333,
        "company": "PubMatic",
        "title": "Sr. Software Development Engineer in Test (Python, Pyspark, Big Data)",
        "created_on": 1720636272.9293113,
        "description": "Company Description PubMatic (Nasdaq: PUBM) is an independent technology company maximizing customer value by delivering digital advertising’s supply chain of the future. PubMatic’s sell-side platform empowers the world’s leading digital content creators across the open internet to control access to their inventory and increase monetization by enabling marketers to drive return on investment and reach addressable audiences across ad formats and devices. Since 2006, our infrastructure-driven approach has allowed for the efficient processing and utilization of data in real time. By delivering scalable and flexible programmatic innovation, we improve outcomes for our customers while championing a vibrant and transparent digital advertising supply chain. Job Description The Software Development Engineer in Test (SDET) will be responsible for designing best in class QA automation and Integration frameworks and smartly testing applications with tools supporting white box testing. You will work on testing solutions focused on AdTech components – API, AdEngine and Analytics Job Location: US(RWC) Hybrid (3 Days In-office) Responsibilities Testing big data ingestion and aggregation flows using spark shell and related queries Developing automation framework using programming languages such as python and automate the big data workflows such as ingestion, aggregation, ETL processing etc Debugging and troubleshooting issues within the big data ecosystem Set up the Big data platform and Hadoop ecosystem for testing Define test strategy and write test plan for the data platform enhancements and new features/services built on it. Define the operating procedures, service monitors and alerts and work with the NOC team to get them implemented. Responsible for system & performance testing of the data platform and applications Solve problems and establish plans and provide technical consultation in the design, development and test effort of complex engineering projects Review product specifications and write test cases, develop test plans for assigned areas. Identifies issues and technical interdependencies and suggest possible solutions. Recreate complex customer and production reported issues to determine root cause and verify the fix. Qualifications 3-5 years of experience in SDET or QA Engineer roles. 2+ years of experience on working Python, PySpark and BigData technologies. Good Programming skills. Experience in testing of sponsored product listing reporting and analytics for e-commerce company. Experience in testing closed loop reporting for e-commerce AdTech components Hands on Experience in Automating Backend Applications (e. g. db, REST API's) Hands on experience with Automating any backend applications (e. g db, server side). Knowledge of relational databases and SQL and Good debugging skills. Strong working experience working in Linux/Unix environment. Strong understanding of testing methodologies. Hands on experience in working on Big Data technologies like Hadoop, Spark Hand on experience in working with ETL Testing Hands on experience in QA Automation Framework development & Design & Strong hold on data structures. Preferred language Python/Shell Scripting Strong Understanding of OS and performance benchmarking Quick learner and good team member with positive attitude. Good verbal and written communication skills. Base Compensation Range: $120,000 - $140,000 In accordance with applicable law, the above salary range provided is PubMatic’s reasonable estimate of the base salary for this role. The actual amount may vary, based on non-discriminatory factors such as location, experience, knowledge, skills and abilities. In addition to salary PubMatic also offers a bonus and a competitive benefits package. Additional Information Return to Office : PubMatic employees throughout the global have returned to our offices via a hybrid work schedule (3 days “in office” and 2 days “working remotely”) that is intended to maximize collaboration, innovation, and productivity among teams and across functions. Benefits : Our benefits package includes the best of what leading organizations provide such as, paid leave programs, paid holidays, healthcare, dental and vision insurance, disability and life insurance, commuter benefits, physical and financial wellness programs, unlimited DTO in the US (that we actually require you to use!), reimbursement for mobile and internet expenses and fully stocked pantries plus in-office catered lunches 5 days per week.",
        "url": "https://www.linkedin.com/jobs/view/3937245333"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3964834763,
        "company": "SoFi",
        "title": "Senior Software Engineer, Cloud Infrastructure",
        "created_on": 1720636274.527699,
        "description": "Employee Applicant Privacy Notice Who we are: Shape a brighter financial future with us. Together with our members, we’re changing the way people think about and interact with personal finance. We’re a next-generation financial services company and national bank using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. Join us to invest in yourself, your career, and the financial world. The Role: We are seeking a highly skilled and experienced Senior Software Engineer to join our Cloud Infrastructure team to create high-quality solutions that simplify complex tasks and enhance developer productivity. You will have the opportunity to directly impact the direction and architecture of our cloud infrastructure, focusing on networking, compute, and storage using Kubernetes and AWS. If you are a seasoned Software Engineer with a passion for building robust infrastructure solutions and a strong background in cloud technologies, we invite you to apply for this exciting opportunity. What You’ll Do: Design, develop, and maintain software that enables developers to efficiently interact with our cloud infrastructure and services. Work closely with cross-functional teams to understand requirements and design solutions that are intuitive, efficient, scalable, and reliable. Provide technical leadership for the Cloud Infrastructure team to design and implement strategies for optimizing cloud costs, resource utilization, and overall performance. Lead the development of software solutions to enable engineers to seamlessly use networking, compute, and storage services within AWS and Kubernetes environments. Identify opportunities for automation and process improvement to enhance developer productivity. Collaborate with cloud and software engineers to integrate solutions seamlessly into cloud environments. Conduct code reviews and provide constructive feedback to other team members. Stay up-to-date with the latest trends and technologies in cloud infrastructure and software engineering. What You’ll Need: Bachelor's or Master's degree in Computer Science, Software Engineering, or a related technical field. 5+ years of software development experience. Expertise in cloud platforms including AWS and cloud-native technologies. Strong programming fundamentals (Java/Kotlin, Python, Go). Strong understanding of software design principles and best practices. Experience with infrastructure as code (IaC) tools and practices (e.g. Terraform). Experience with cloud storage solutions, compute resources management, and networking in AWS. Familiarity with CI/CD pipelines and tools (e.g., Jenkins, GitLab CI/CD). Excellent problem-solving skills and ability to think strategically about cloud infrastructure and platform design. Preferred Qualifications: Experience with container orchestration (e.g., Docker, Kubernetes), networking, and service meshes (e.g., Istio). Experience with monitoring and logging tools (e.g. Datadog). Experience with service discovery and load balancing solutions. Experience with security and compliance in cloud environments. Compensation And Benefits The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location. To view all of our comprehensive and competitive benefits, visit our Benefits at SoFi page! SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law. The Company hires the best qualified candidate for the job, without regard to protected characteristics. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. New York applicants: Notice of Employee Rights SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com. Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time. Internal Employees If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.",
        "url": "https://www.linkedin.com/jobs/view/3964834763"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Pittsburg, CA",
        "job_id": 3888440369,
        "company": "Donato Technologies, Inc.",
        "title": "EDW Data Engineer",
        "created_on": 1720636276.1183383,
        "description": "Job Title: EDW Data Engineer Location: Bay Area, CA - Onsite Job Description Bachelor's degree in Information Technology, Computer Science or other related fields of study Minimum 6 years of developing data pipelines using Talend\\Informatica and Python including the processing of NoSQL and JSON, XML formats, preferably in the financial services industry using Agile development process Advanced working experience in SQL/PL-SQL, Snowflake, API Excellent skills in scripting languages, including Python, Perl and Shell Excellent skills with Ant, Maven, GIT, Jenkins, TeamCity Excellent skills in source code repository tools such as Clear Case, SVN, CVS, and Gi. Deep understanding of ETL, ELT, Talend, Informatica, Hadoop, data warehousing schema and Cloud platforms Ability to work autonomously to manage time effectively and prioritize work appropriately to meet deadlines Excellent problem solving and critical thinking skills Strong business communication skills; able to write/speak clearly and professionally for a variety of audiences Demonstrate independence, creativity, and initiative Working knowledge of Microsoft Office Suite Certification/License: Talend Certification is preferred",
        "url": "https://www.linkedin.com/jobs/view/3888440369"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3787334844,
        "company": "Lever Middleware Test Company 2",
        "title": "Software Engineer II",
        "created_on": 1720636277.8747895,
        "description": "Information about us is here. You can see how we are an excellent company, and learn more about why you would be a perfect fit for our team! If you keep reading, you'll be able to see more information that is helpful in learning more about us! We appreciate you taking the time to learn about us and look forward to your application! We're excited to learn more about you!",
        "url": "https://www.linkedin.com/jobs/view/3787334844"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3929732300,
        "company": "Adobe",
        "title": "Software Development Engineer",
        "created_on": 1720636279.7016692,
        "description": "Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Adobe Experience Platform is the Adobe solution that helps customers to centralize and standardize their customer data and content across the enterprise powering 360-degree customer profiles, enabling data science and data governance to drive real-time personalized experiences. With Adobe Experience Platform, our enterprise customers are able to manage their data lifecycle. From ingestion to processing, analysis, attribution and activation, Adobe Experience Platform helps customer gain insight and use those insights in real time. We are looking for an experienced and curious engineer to be part of a core component team. As a software development engineer, we expect the candidate to contribute to one of the heavily used and technically sound feature of Adobe Experience Platform. Tasks here can range from software design and reviews to developing highly efficient enterprise software. Work closely with senior developers and architects and is able to produce good quality code. Since most of the work would involve either processing big data or managing sophisticated data pipelines, a candidate who can develop end to end view of a system or is willing to learn will be preferred. What You'll Do Design, implement, and own critical features in a micro-service architecture. Coordinate with architects, senior developers and other integrating teams. Subscribe to developments happening within Adobe ecosystem. Ensure quality of component meets high standards and ensure all appropriate validations are in place and being monitored. Work closely with product managers, asks questions and contribute to software architecture. Keep on look out for upcoming technologies and cost saving initiatives without compromising the product requirements and quality. Open to learning and experimenting with upcoming technologies in a fast paced environment. Act with clarity and precision, ensuring projects are driven with a strong sense of ownership and direction. What you'll need to succeed Bachelors' degree in Computer Science or equivalent. Prior experience working on large scale distributed systems or data processing systems. Proficiency in Java and/or Scala. Expertise in SQL DB, No-SQL DB, Web Services, Data Intensive applications, Big Data Processing pipelines. Exposure to Apache Spark, Apache Hadoop, Apache Kafka, AWS Services, Azure Services, Microservice Architecture, Databricks. Always striving to implement coding best practices and scalable design. Ability to model solutions for distributed processing problems. What Will Help You Stand Out From The Crowd Experience developing backend distributed applications on Java/JVM and Spring (or similar framework). Shown experience using structured, focused approaches to solving technical, data, and logical problems. Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $137,100.00 - $218,900.00 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process. At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP). In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award. Internal Opportunities Creativity, curiosity, and constant learning are celebrated aspects of your career growth journey. We’re glad that you’re pursuing a new opportunity at Adobe! Put your best foot forward: Update your Resume/CV and Workday profile – don’t forget to include your uniquely ‘Adobe’ experiences and volunteer work. Visit the Internal Mobility page on Inside Adobe to learn more about the process and set up a job alert for roles you’re interested in. Check out these tips to help you prep for interviews. If you are applying for a role outside of your current country, ensure you review the International Resources for Relocating Employees on Inside Adobe, including the impacts to your Benefits, AIP, Equity & Payroll . Once you apply for a role via Workday, the Talent Team will reach out to you within 2 weeks. If you move into the official interview process with the hiring team, make sure you inform your manager so they can champion your career growth. At Adobe, you will be immersed in an exceptional work environment that is recognized around the world. You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely. If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer. Adobe is an equal opportunity and affirmative action employer. We welcome and encourage diversity in the workplace regardless ofgender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other characteristics protected by law. If you have a disability or special need that requires accommodation to navigate our internal careers site or to complete the application process, please contact accommodations@adobe.com . Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $108,000 -- $198,500 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process. At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP). In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award. Adobe will consider qualified applicants with arrest or conviction records for employment in accordance with state and local laws and “fair chance” ordinances. Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015. Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.",
        "url": "https://www.linkedin.com/jobs/view/3929732300"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Diego, CA",
        "job_id": 3960613957,
        "company": "ResMed",
        "title": "Senior Data Engineer, Data Engineering",
        "created_on": 1720636281.4052048,
        "description": "Digital Health Technology team powers digital experiences and engagement to enhance the lives of millions of people every day through connected care. We build, deliver and manage a portfolio of data management platforms and mobile offerings in support of our core businesses. We thrive on simple and elegant architecture and agility. You’ll be immersed in a dynamic high-growth environment and empowered to excel, take informed risks, and drive ingenuity across the enterprise. Let’s Talk About The Team The primary role of Analytics Engineering function within the Global Data Platform, Global Technology Solutions team is to design and deliver new data products or improvements to existing data products. Works closely with customers, developers and other stakeholders to understand and define customer needs in these designs and continues to work with customer through release to production. Features are aligned to a timetable and areas of responsibility. Developers may solicit customers for feedback regarding product usability and desired future enhancements. Let’s Talk About The Role Build large-scale data processing systems to serve the analytics needs of users across Resmed. Implement data pipeline integrations and solutions, incorporating highly scalable cloud computing and large scale data stores including data lakes, data warehouses, and data marts. Work closely with data architects to determine what data management systems are appropriate, and data scientists/analysts to determine which data are needed for analysis and provides required data analytics tools. Manage Github repositories including working with Github actions Manage infrastructure of team's analytics platform with tools such as Terraform Develop analytics models using SQL and dbt on the Snowflake data platform Develop data pipelines using Kafka and Flink Orchestrate data pipeline operations using Dagster and Python Frequently leads sub-functional teams or projects and train and mentor junior team members. Let’s Talk About You Minimum of 5 years of experience with SQL on a large analytics data platform Minimum of 5 years of experience with developing software requirements, software coding, and software testing Minimum of 3 years of experience with Python, shared version control systems, and maintaining data pipelines Minimum of 2 years of experience with Github and using actions to deploy cloud applications Preferred: Experience with dbt, Dagster, Snowflake data platform Experience with managing software integration and deployment on Github Bachelor’s degree. Minimum of 8 years of related experience. We are shaping the future at ResMed, and we recognize the need to build on and broaden our existing skills and continue to attract and retain the world’s best talent. We work hard to offer holistic benefits packages, provide flexible work arrangements, cultivate a workforce culture that allows employees to grow personally and professionally, and deliver competitive salaries to our team members. Employees scheduled to work 30 or more hours per week are eligible for benefits. This position qualifies for the following benefits package: comprehensive medical, vision, dental, and life, AD&D, short-term and long-term disability insurance, sleep care management, Health Savings Account (HSA), Flexible Spending Account (FSA), commuter benefits, 401(k), Employee Stock Purchase Plan (ESPP), Employee Assistance Program (EAP), and tuition assistance. Employees accrue three weeks Paid Time Off (PTO) in their first year of employment, receive 11 paid holidays plus 3 floating days and are eligible for 14 weeks of primary caregiver or two weeks of secondary caregiver leave when welcoming new family members. Individual pay decisions are based on a variety of factors, such as the candidate’s geographic work location, relevant qualifications, work experience, and skills. This role is eligible to receive an annual cash bonus payment based on company, business unit, and/or individual performance. Base Pay Range for this position: $134,000 - $202,000 Joining us is more than saying “yes” to making the world a healthier place. It’s discovering a career that’s challenging, supportive and inspiring. Where a culture driven by excellence helps you not only meet your goals, but also create new ones. We focus on creating a diverse and inclusive culture, encouraging individual expression in the workplace and thrive on the innovative ideas this generates. If this sounds like the workplace for you, apply now! We commit to respond to every applicant.",
        "url": "https://www.linkedin.com/jobs/view/3960613957"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Los Angeles, CA",
        "job_id": 3912074708,
        "company": "Unreal Staffing, Inc",
        "title": "Software Engineer",
        "created_on": 1720636283.0457604,
        "description": "About Us: At our organization, integrations form the backbone of our operations, fueling our mission to streamline workflows and enhance productivity. Collaborating closely with our product and engineering teams, you'll be at the forefront of architecting, developing, and scaling integrations with third-party SaaS applications. If you're eager to shape our engineering strategy and product roadmap, while contributing to innovative solutions, we invite you to join us. Our welcoming, dog-friendly office is located in West LA, and for those based elsewhere in the US, we offer relocation assistance or remote work options. Requirements Responsibilities: Develop, Enhance, Create: Collaborate with senior engineers to devise solutions for integrations with third-party SaaS applications Continuously improve existing integration functionalities to deliver an exceptional user experience Identify, Innovate, Execute: Identify opportunities for enhancement within the integrations framework Actively participate in the execution and testing of cutting-edge features Understand, Empower, Transform: Take ownership of understanding diverse customer use cases and provide valuable insights Contribute to crucial product and architecture decisions based on user feedback You Should Have: 2+ years of experience with TypeScript, Node.js, and React Prior experience developing integrations with third-party SaaS APIs Confidence working in a dynamic environment where autonomy and quick decision-making are key Bonus Points if You Have: Experience with Next.js or server-side rendering frameworks A keen eye for design and a passion for crafting exceptional user experiences Benefits New laptop/equipment of your choice Comprehensive health, dental, and vision insurance coverage 401(k) retirement plan Unlimited paid time off Optional relocation assistance to LA Salary Range: $80,000 - $140,000 Equity: 0.01% - 0.05% in the company",
        "url": "https://www.linkedin.com/jobs/view/3912074708"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sacramento, CA",
        "job_id": 3967443648,
        "company": "RIT Solutions, Inc.",
        "title": "ETL Data Integration Developer -remote",
        "created_on": 1720636284.760437,
        "description": "Must be based in CA Must have a valid LinkedIn profile Duration: 6+ months Need IDMC/IICS PL SQL Erwin Informatica ETL",
        "url": "https://www.linkedin.com/jobs/view/3967443648"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Los Angeles, CA",
        "job_id": 3100528488,
        "company": "Freestar",
        "title": "Senior Data Engineer",
        "created_on": 1720636286.5908473,
        "description": "About Freestar Freestar engineer teams develop cutting-edge monetization solutions for websites and mobile apps. By combining industry-leading technology, data, and massive scale, we enable busy site owners and mobile app publishers to seamlessly maximize revenue while freeing themselves of the hassles of ad operations. The result is publishers having more time to do what they do best: create content and focus on their apps. Senior Engineer (Remote) We’re looking for a Senior Engineer for our Data Platform Team - the product that drives our core business. As a Senior Engineer at Freestar, you'll be one of the main contributors to a talented team of developers to innovate features for our product that separate us from our competitors. What You'll Be Doing Run points on whole projects by recommending, prototype, build and debug data infrastructures on Google Cloud Platform (GCP) with other principal and senior engineers within the team, and to mentor less experienced Data Engineers. Demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. Participate in early-stage conversation with our product development team about product / features. Improve decision quality across the company by ensuring metrics are trustworthy, discoverable, and easily consumable. Skills And Experience You'll Need To Have Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive, Kafka, PubSub). 4+ years of experience designing and implementing large-scale, complex, data-driven applications on the cloud, preferably on Google Cloud / AWS. 4+ years of hands-on experience using SQL to perform complex data manipulation 3+ years of experience modeling data warehouses 3+ years of experience building data pipelines, CI/CD pipelines, and fit for purpose data stores Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime. Experience writing software in one or more languages such as Python, Java, Scala, etc. Experience with systems monitoring/alerting, capacity planning and performance tuning Enjoy analyzing and organizing rapidly-changing business data to support product and business solutions Nice to have Qualifications: * Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, BigQuery, Dataprep, Composer, etc) Experience with IoT architectures and building real-time data streaming pipelines Experience operationalizing machine learning models on large datasets Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques Demonstrated skills in selecting the right statistical tools given a data analysis problem Comfortable interacting across multiple teams and management levels within the organization Previous background in the ad tech or media landscape (linear, digital, or social) is a plus Why You Want To Work With Us Full-Time, Salaried Position Working remotely Generous Medical, Dental, and Vision benefits 401K with company match, vested immediately The opportunity to be part of something high value, high impact, and high growth...Who doesn't love that! Freestar is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.",
        "url": "https://www.linkedin.com/jobs/view/3100528488"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Los Angeles Metropolitan Area",
        "job_id": 3951900558,
        "company": "Sony Interactive Entertainment",
        "title": "Software Engineer II, IAM",
        "created_on": 1720636288.304069,
        "description": "Why PlayStation? PlayStation isn’t just the Best Place to Play — it’s also the Best Place to Work. Today, we’re recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation®5, PlayStation®4, PlayStation®VR, PlayStation®Plus, acclaimed PlayStation software titles from PlayStation Studios, and more. PlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation. Sony Interactive Entertainment LLC seeks a Software Engineer II, IAM in Los Angeles, CA to work closely with development teams to ensure that content authorization policies are aligned with overall security objectives. Requires a Bachelor’s degree in Computer Engineering, Computer Science, Electrical Engineering or related field or equivalent, and three (3) years of experience designing and developing software for shared services including ingress and egress proxies, email services, logging, and metrics pipelines; utilizing JavaScript and Golang programming languages to implement backend services in a Service-Oriented Event-Driven architecture environment; maintaining and updating software codes to ensure optimal performance, compliance, and resiliency of company proprietary software using tools including Splunk, Source Clear and Fortify to identify and resolve application and/or security issues; and developing software systems utilizing ECS, DynamoDB, RDS, IAM, Elastic Kubernetes Service (EKS), Code build, Code Deploy, Lambda, Event Bridge, Redis, Datadog, Kafka and Solace. Telecommuting and/or working from home may be permissible pursuant to company policies. Sony is an EOE. Salary: $137,661.00 - $218,500.00/year Equal Opportunity Statement: Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to gender (including gender identity, gender expression and gender reassignment), race (including colour, nationality, ethnic or national origin), religion or belief, marital or civil partnership status, disability, age, sexual orientation, pregnancy or maternity, trade union membership or membership in any other legally protected category. We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond. PlayStation is a Fair Chance employer and qualified applicants with arrest and conviction records will be considered for employment.",
        "url": "https://www.linkedin.com/jobs/view/3951900558"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3948108648,
        "company": "Corvee",
        "title": "Senior Software Engineer",
        "created_on": 1720636290.147418,
        "description": "The Opportunity Taxes are your #1 expense. What’s everything you could be doing, Instead? Our goal is to build the largest tax company in the world and help people change how they organize their business and life finances to save money, time, and achieve financial independence. Note: We are in the process of rebranding from Corvee to Instead. You can check out more about careers at our company at www.Corvee.com and our new product at www.Instead.com. Our Software We have built a multi-entity, multi-year tax planning software utilized by business owners who are looking to properly plan for their taxes. Corvee & Instead software addresses two critical challenges: Planning: Strategically identify opportunities to proactively save on taxes, enabling better financial decisions with a keen understanding of tax implications. Preparation: Simplify the complex tax code to make it accessible and manageable for small business owners. What You Will Do As a Senior Software Engineer you will be responsible for developing key modules in our software roadmap. You will implement new features and UI and make sure our code base is stable and future proof. With your experience, you will provide new ideas and raise concerns on the future of the product. Ideally, you will grow in this role and become responsible for growing the front end team to increase the speed of development. You will essentially spend your days: Rapidly prototype and build new features in external and internal apps. From Tailwind to problem solving in JavaScript working with complex data architectures. Work alongside a brilliant team of development and tax engineers to transform the tax industry. Our Tech Stack Front End tools, always subject to change if something better comes along: Vue Nuxt TypeScript Tailwind Back End tools, always subject to change if something better comes along: Go Docker on AWS ECS/Fargate PostgreSQL on AWS RDS In addition, we are heavily utilizing LLMs (OpenAI, Anthropic, Gemini) in both product and internal development. What You'll Bring Demonstrable knowledge of HTML & CSS Minimum 2 years' experience of JS development Demonstrable experience developing SPAs with Vue.js Experience in Git Experience with testing frameworks is a plus Experience in interacting with REST APIs Have an eye for pixel perfection in GUIs Experience in developing native mobile applications is a plus High energy to try potential solutions and to keep dig deeper and deeper when finding a problem. Have high attention to detail and great analytical thinking. What You'll Love About Us We’re proud of our amazing high-growth and this is all due to our best and most important asset: our team! If you’ve got passion and enthusiasm for a product and a desire to come to a fast-growing fintech company to make an impact, we’ve got the perfect opportunity for you! Unlimited PTO Package Company equity (Participation Units) 401k Plan with company contributions 100% Paid Health Insurance Paid Parental Leave Awesome Co-Workers! Corvee is a distributed company with headquarters in San Francisco. If you are in the area, we would love to have you in the office. Team members want flexibility, balance, and the freedom to work from anywhere, and we fully support that. Our Core Values Are: Third Option Thinking Radical Transparency All In Client Success Champions Data Matters Adventure Together Outlearn & Outwork An Equal Opportunity Employer--M/F/D/V Because our team members are trusted to handle sensitive information, we require all candidates that receive and accept employment offers to complete a background check before being hired.",
        "url": "https://www.linkedin.com/jobs/view/3948108648"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Los Angeles, CA",
        "job_id": 3966734763,
        "company": "Convoso",
        "title": "Database DevOps Engineer",
        "created_on": 1720636291.6916595,
        "description": "Who We Are: Convoso is a leading provider of omnichannel contact center software. The company was founded on innovation and continues to push boundaries in our industry. Headquartered in Los Angeles, the company has employees around the globe working both hybrid and remote. The company culture fosters team integrity, positive persistence, and continuous growth. (A heads up - we were awarded as Built In LA’s Best Places to Work in 2020, 2021 and 2022!) The company’s foundational product provides the most powerful contact center software available for outbound teams. However, we are expanding our reach by relaunching an advanced version of our conversational AI product. The enhanced capabilities of our Intelligent Virtual Agent (IVA) gives our customers a competitive edge and streamlined productivity by dramatically reducing repetitive tasks. This future forward technology will allow Convoso to grow into new markets across hundreds of use cases. Convoso is looking for people who are excited about technology and the fast growing, innovative field of IVA and AI. We are a company of motivated team players driving accelerated growth in a supportive, positive culture. We celebrate a diversity of people, ideas, and backgrounds that contribute to one shared community. Most roles at Convoso function as “hybrid” with some opportunities for travel to in-person business events and company meetings. For remote positions, Convoso’s U.S. hiring is open to candidates who are residents of the following states: AL, AZ, CA, CO, CT, FL, GA, IL, IN, MA, NC, NJ, NV, NY, OH, PA, TX, UT. The Job: At Convoso, we’re constantly, vigilantly looking for ways to reshape the future of lead generation contact centers. Our mission is to revolutionize the call center industry by empowering agents to convert leads faster. That’s where you come in. We are looking for a MySQL Database expert who will be responsible for assessing, designing, deploying, and maintaining complex databases as well as brainstorming possible improvements that can be made to a system in the future. What You'll Be Doing: Maintain and support the current MYSQL/InnoDB & Redis /KeyDB database, including the creation of new DB's, migrations, backups, and replications. Design, plan and deploy database schemas. Review the existing databases and provide recommendations and drive the implementation to fine-tune and growth-proof the performance and scalability of our databases, including multi-sites replication. Ensure that data is properly backed up and consistent. Defines customers’ needs and functionality in a service development cycle. Provide and communicate the best practices and specific detailed information for database management, including present and future capacity requirements. Provide documentation as required to ensure accurate and current information is available for each database schema, relationships, performance bottleneck, and data flows. Assists in the coordination of various teams testing and evaluating for the development of design and its implementation including database tools and software selection, including present and future capacity requirements. Ensures the highest level of database and systems availability, stability and scalability. Implements warranty and support activities. Plans and implements system automation as required for better efficiency. Oversees the development of customized software and hardware requirements. Willing to stay up-to-date with security best practices and drive implementation accordingly Collaborates with other professionals to ensure high-quality deliverables within organization guidelines, policies, and procedures. Run diagnostics to resolve customer-reported issues Deals with work process, optimization methods, and risk management tools in the given projects for successful accomplishments according to the requirements of the stakeholders. Who You Are: Minimum 3 years experience configuring and supporting MySQL/MariaDB database management and data modeling. Databases running in Linux environments first, with strong domain knowledge. Solid database concepts and database design knowledge (ACID, abstraction levels, schemas and constraints, stored procedures, replication, etc.) Strong troubleshooting skill in database performance analysis and improvements. Good knowledge of storage, networking, and other systems directly impacting database performance. Solid experience in the administration and performance tuning of database-related tools and environments. Experience with monitoring systems like Grafana, Prometheus, Zabbix, etc. Experience with planning, executing, and managing large - scale system deployments, ensuring high availability and performance. Skilled in system scripting and automation to streamline deployment processes and operational tasks, utilizing tools such as Ansible, Chef, Terraform, etc. Solid scripting skills (e.g., Python, Ruby, Bash, Perl, etc) Proven working experience in configuring and troubleshooting UNIX/Linux-based environments. Strong work ethic and communication skills both spoken & written Flexibility to work a variety of shifts with availability to work overtime BS/MS degree in Computer Science, Engineering or a related subject. Work Perks Worth The Hype: Competitive compensation package Stock options 100% covered premiums for employees; Medical, Dental, Basic life insurance, Long term disability Affordable Vision plan and optional FSA PTO, Paid Sick Time, Holidays, Bereavement time, Parental Leave Your birthday off 401k program with generous company match No cost Employee Assistance Program and Travel Assistance Monthly Gym membership reimbursement Monthly credits toward food & beverage Company Outings On and offsite team building events Paid training for departments Apple laptop (most roles) And a team of highly experienced and kind colleagues! HQ Office: Casual office environment & dress Daily catered lunches Fully stocked kitchen (Dietary restriction-friendly) Happy Hours Monthly Massages On-site Car Wash Free Parking Compensation: The base salary range is: $110,000 - $115,000 The Base Pay Range for this position is based on the industry benchmark for position, function, level and the company's compensation strategies. However, final offers may vary from the amount listed based on geography, candidate experience and expertise, and other objective business. Convoso’s compensation package also includes equity for all eligible U.S full time roles and exceptional benefits, including generous 401k match. Your California Privacy Rights: As a California resident who is an applicant to be an employee of Convoso, you have certain rights under California law with respect to information collected by Convoso in the course and scope of its evaluation of your application. The types of information Convoso collects and your rights with respect to that information are contained in Convoso’s privacy policy, which you can review by going to https://www.convoso.com/privacy-policy/.",
        "url": "https://www.linkedin.com/jobs/view/3966734763"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3949396788,
        "company": "Pylon",
        "title": "Software Engineer",
        "created_on": 1720636297.921128,
        "description": "Pylon is hiring 🚀 We’re looking for frontend engineers to join our team who want to help own all things related to Pylon's web app 🖥️. We have a strong technical team of engineers from places like Samsara, Affinity, and Airbnb. Come help us build the future of customer operations from our beautiful office in downtown San Francisco! Post-covid, businesses have started shifting the way they communicate with customers from email to chat platforms like Slack, Microsoft Teams, and Discord. At Pylon, we are building a real-time customer operations platform to help support and success teams at places like Hightouch, Merge, and Sardine scalably meet their customers where they live. Our tech stack: React, TypeScript, GraphQL, and Go.",
        "url": "https://www.linkedin.com/jobs/view/3949396788"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Carlos, CA",
        "job_id": 3958147310,
        "company": "ZAP Surgical Systems, Inc.",
        "title": "Software Engineer",
        "created_on": 1720636299.6809282,
        "description": "About ZAP Surgical Systems Zap Surgical Systems is a surgical robotics start-up located in San Carlos, CA. Leveraging its unique gyroscopic motion and self-shielded design, our product, the ZAP-X®, is disrupting the industry and opening new frontiers in modern radiosurgery. Zap’s employees thrive in an environment where multiple fields of study come together to solve challenging and important problems. You will be joining a diverse, cross-functional team that is bringing to market the most advanced stereotactic radiotherapy technology. The Role Collaborates with R&D and Service teams to investigate discrepancy reports from clinical users. Develops software tools to streamline the deployment and service of the ZAP-X medical device. Collaborates with Software and other engineering teams to develop new software features for the ZAP-X. Assists Regulatory and Program Management teams with design documentation in support of ZAP's quality procedures. Assists Software and SQA teams with the verification and validation of software items prior to clinical release. Develops testing suites to automatically and continuously verify new software tools and features. Travels to clinical sites to assist Service teams with the installation of new ZAP-X components. While this roll allows for a Hybrid schedule, the successful candidate will need to be in the office several days a week and thus must be local. Qualifications Bachelors or Masters in Computer Science, Physics, Mathematics, or Engineering. Five to ten years of experience integrating software tools in complex hardware devices in a highly regulated industry--ideally, medical devices. Software development experience with C++, C#, .NET, and Python. Strong interpersonal and communication skills, with the ability to work effectively in a distributed team.",
        "url": "https://www.linkedin.com/jobs/view/3958147310"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3694259922,
        "company": "Applied Intuition",
        "title": "Data Infrastructure Engineer",
        "created_on": 1720636301.4202173,
        "description": "About Applied Intuition Applied Intuition is a Tier 1 vehicle software supplier that accelerates the adoption of safe and intelligent machines worldwide. Founded in 2017, Applied Intuition delivers the definitive ADAS/AD toolchain and a world-class vehicle platform to help customers shorten time to market, build industry-leading products, and create next-generation consumer experiences. 18 of the top 20 global automakers trust Applied Intuition’s solutions to drive the production of modern vehicles. Applied Intuition serves the automotive, trucking, construction, mining, agriculture, and defense industries and is headquartered in Mountain View, CA, with offices in Ann Arbor and Detroit, MI, Washington, D.C., Munich, Stockholm, Seoul, and Tokyo. Learn more at https://appliedintuition.com. Please note that we are an in-office company, which means the expectation is that you would come in to your Applied Intuition office 5 days a week. About The Role We are looking for infrastructure engineers with expertise in data pipelines to join the Data & ML infra group. This role will work across the entire data lifecycle (collection, ingestion, storage, querying, retrieval) and work directly with product teams across the company to design and develop both external and internal products. Handling massive volumes of data for Applied Intuition's platform needs is a critical area and we are looking for someone who can be hands-on in supporting our data products and services across the company. At Applied Intuition, we encourage all engineers to take ownership over technical and product decisions, closely interact with external and internal users to collect feedback, and contribute to a thoughtful, dynamic team culture. At Applied Intuition, you will: Develop and deploy event-driven pipelines using extract, load and transform (ELT) architecture focused on distributed ingestion. Build features to tune processing pipeline for fast data ingestion and indexing depending on customer's needs and workloads. Enable product workflows that expose performant query interfaces and offer easy-to-use integration hooks. Develop and deploy high-quality software using modern tooling and frameworks. Encourage change, especially in support of data engineering best practices, and maintain a high standard of excellence. Work with products and teams across Applied Intuition. We're looking for someone who has: Experience with large-scale open source data processing frameworks (Spark, Kafka, Airflow, Flink, Hudi, etc.). Experience with containerization and other modern software development workflows. Knowledge of the open source landscape with judgment on when to choose open source versus build in-house. Strong knowledge of data concepts, including experience in using a big data warehouse. Nice to have: Expertise with modern programming languages (Python, C++, GoLang, etc.). Experience with enterprise software, including on-prem and/or cloud environments. Deep knowledge of data quality, data profiling and cleansing techniques. The salary range for this position is $147,000 - $195,000 USD annually. This salary range is an estimate, and the actual salary may vary based on the Company's compensation practices. Don’t meet every single requirement? If you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles. Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position. Applied Intuition is an equal opportunity employer and federal contractor or subcontractor. Consequently, the parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.",
        "url": "https://www.linkedin.com/jobs/view/3694259922"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco Bay Area",
        "job_id": 3964645293,
        "company": "Acceler8 Talent",
        "title": "Software Engineer - Supercomputing Platform & Infrastructure",
        "created_on": 1720636303.3371656,
        "description": "Software Engineer - Supercomputing Platform & Infrastructure Introduction: Are you a software engineer with a passion for building resilient and optimized solutions for AI workloads? We are seeking a Software Engineer for our Supercomputing Platform & Infrastructure team to work on massive computing clusters. This role can be based in San Francisco or remote. About the Company: We are a forward-thinking organization committed to advancing humanity’s progress by developing safe AGI. Our mission focuses on automating research and code generation, leveraging frontier-scale pre-training, domain-specific RL, ultra-long context, and test-time compute. We aim to enhance model reliability and alignment beyond human capabilities. About the Role: As a Software Engineer on our Supercomputing Platform & Infrastructure team, you will be integral in designing and building highly available and secure AI training and inference infrastructure. Your work will ensure the reliability and optimization of GPU workloads, troubleshoot complex issues, and enhance the efficiency of our engineering processes. What We Can Offer You: Significant equity as part of total compensation 401(k) plan with 6% salary matching Comprehensive health, dental, and vision insurance for you and your dependents Unlimited paid time off Flexible work options: in-person in San Francisco or remote Visa sponsorship and relocation stipend Key Responsibilities: Build and maintain a software stack for large-scale (thousands of GPUs) AI training and inference infrastructure Troubleshoot and resolve issues across GPU resources, networking, OS, drivers, and cloud environments Automate detection and recovery processes to ensure high availability and security Investigate and resolve incidents affecting security and availability Develop solutions to enhance engineering efficiency and speed Proactively support the research and engineering teams Keywords: In this role as a Software Engineer , you will utilize networking technologies , cloud platforms like GCP, AWS, Azure , and apply your IaC knowledge with tools such as Terraform or Pulumi . Your expertise will ensure the reliability and optimization of our AI workloads and GPU deployments .",
        "url": "https://www.linkedin.com/jobs/view/3964645293"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3909917342,
        "company": "Altana",
        "title": "Senior Software Engineer, Backend",
        "created_on": 1720636304.9663625,
        "description": "Altana provides the world’s only dynamic, intelligent map of the global supply chain - the Altana Atlas - using AI and machine learning models to connect with and learn from massive sets of public and private data. Through the Atlas, companies and governments can understand the distant origins of products well beyond their own direct suppliers; discover trading relationships and national security risks deep in their networks; measure labor and environmental impacts; identify related risks and opportunities; ensure effective compliance and enforcement with trade requirements; and collaborate to manage all of it. We have built a fundamental understanding of how the world’s economy works, and the implications for global resiliency, sustainability and opportunity are enormous. Backed by leading investors and used by the world’s most important organizations (Maersk, US Customs and Border Protection, Boston Scientific, and more), Altana’s mission is to power a new era of globalization organized around trusted supply chain networks. This is a lofty mission, and our success depends on building a diverse, global team and creating an environment in which they can thrive. We operate in accordance with our values: we focus on value creation, not capture; we foster diversity and embrace difference; we embrace reality; we get things done; we amaze our clients. When you join Altana, you’ll be joining a vibrant, collaborative team working together to solve complex problems with the potential for global societal impact. The Opportunity at Altana The Engineering team is responsible for building out the platforms, API’s, services, workflows, and logical architectures for bringing this vision to life. We are creating a platform fundamentally driven by AI, which scales to a massive trove of data, and a diverse customer base; it is a complex system that will stretch engineering in many directions. You’ll work closely with our Data Scientists on projects to analyze and observe world-scale datasets, write code that can scale to produce never-before-seen insights, and construct APIs to deliver our product vision. You Will Ingest product requirements, define technical requirements, and design practical, iterative technology designs that achieve the goal while fitting into our overall technical and product roadmaps. Personally develop and deploy services creating and supporting our overall architecture. Build and maintain distributed data processing and machine learning pipelines. Analyze and propose technical solutions to invent, enable, and enhance our product offerings. Be responsible for automating, testing, and deploying your work. Review the code and technical designs authored by your fellow team members, and hold a high bar for quality. Mentor junior developers and help them level up their skills. You Have BS or MS degree in Computer Science, or equivalent experience. 5+ years of real-world professional experience writing back end or data-driven software in demanding environments. You’ve deployed production code and services to cloud-hosted environments. You have demonstrated experience delivering incremental releases from proof-of-concept to MVP to production. Self-starter with demonstrated experience working on large, complex problems. You care deeply about engineering excellence, clean code, and knowledge-sharing. You have strong written and verbal communication skills. Nice To Have, But Not Required Experience with Python Machine Learning toolsets (Numpy, Pandas, Dedupe). Experience with container technologies like Docker and Kubernetes. Technologies we love to use at Altana Languages: Python, PySpark Tools: Docker, Git, Kubernetes, Swagger/OpenAPI, AWS/Azure, MLFlow, Celery Datastores: Databricks and Delta Lakes This role can be based in any of our Altana hub locations, with hybrid work flexibility: New York City, Boston, MA, Washington D.C., San Francisco, CA, London, UK Why it’s great to work at Altana We love to collaborate, and we win as a team! We are committed to engineering excellence We value personal and professional development We learn from diverse backgrounds and perspectives We impact the world, from enabling developing countries to identifying drug traffickers At Altana, we believe that a diverse workforce enables greater creativity, performance, and adaptability. We’re proud to be an equal opportunity employer and welcome you to join us as you are. Our employment opportunities and decisions are based on business needs and individual qualifications, without regard to race, color, religious creed, national origin, ancestry, age, physical or mental disability, medical condition, marital status, sexual orientation, gender identity or expression, genetic information, family care or medical leave status, military or veteran status, or any other characteristic protected by the laws or regulations in the areas in which we operate. We prohibit discrimination and harassment of any type, in any situation.",
        "url": "https://www.linkedin.com/jobs/view/3909917342"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3953568412,
        "company": "Syntricate Technologies",
        "title": "Software Engineer with Python",
        "created_on": 1720636306.631842,
        "description": "Position: Software Engineer with Python Location: San Jose, CA (Onsite) Duration: C2C Contract Experience: 8+ Years Skills Required: Ansible/AWX, Python, Cloud native development/Tools, Oracle database, Oracle APEX, Elastic Stack Job Description \" 8 years' Experience in the Software Industry \" Experience with Python and Ansible and good to know backend databases Oracle, Mongo, MYSQL. \" Design and develop micro-services and APIs in a cloud-native model in conjunction with other team members \" Experience with Python, Ansible, Git, Bitbucket, Jira Cloud. \" Expertise in software development with a focus on continuous delivery and deployment, enterprise application development, and cloud automation \" Understanding of Software design patterns, SDLC, Continuous Integration and Continuous Delivery \" A drive to get things done in a highly collaborative and agile development environment \" Strong analytical and problem-solving skills \" AI/Client Skills Required \" Develop and deliver software required for building & improving the functionality, reliability, availability, and manageability of applications and cloud platforms using a DevOps model \" Design and develop micro-services and APIs in a cloud-native model in conjunction with other team members \" Ensure the quality, performance, robustness, and scalability of the services you implement \" Champion and drive the adoption of Infrastructure as Code (IaC) practices and mindset \" Automate the development, test, and deployment processes through CI/CD pipelines (Git, Jenkins, SonarQube, Artifactory, Docker containers) \" Digital : Amazon Web Service(AWS) Cloud Computing Regards, Ashutosh Pasbola Assistant Manager | Syntricate Technologies Inc. Direct: (phone number removed)| Fax: (phone number removed) Email: | Web: We're hiring! connect with us on and visit our Minority Business Enterprise (MBE) Certified | E-Verified Corporation | Equal Employment Opportunity (EEO) Employer This e-mail message may contain confidential or legally privileged information and is intended only for the use of the intended recipient(s). Any unauthorized disclosure, dissemination, distribution, copying or the taking of any action in reliance on the information herein is prohibited. Please notify the sender immediately by email if you have received this email by mistake and delete this e-mail from your system. You have received this email as we have your email address shared by you or from one of our data sources or from our member(s) or subscriber(s) list. If you do not want to receive any further emails or updates, please reply and request to .",
        "url": "https://www.linkedin.com/jobs/view/3953568412"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Mateo County, CA",
        "job_id": 3953353235,
        "company": "Rakuten Symphony",
        "title": "System Engineer",
        "created_on": 1720636308.405593,
        "description": "Why should you choose us? Are you interested in working for a Global Leader in E-commerce? Are you excited about working on highly scalable platforms and applications that are accessed by millions of users every day? If so, read on to find out more about the opportunity. Rakuten Symphony is a Rakuten Group company, providing global B2B services for the mobile telco industry and enabling next-generation, cloud-based, international mobile services. Building on the technology Rakuten used to launch Japan’s newest mobile network, we are taking our mobile offering global. To support our ambitions to provide an innovative cloudnative telco platform for our customers, Rakuten Symphony is looking to recruit and develop top talent from around the globe. We are looking for individuals to join our team across all functional areas of our business – from sales to engineering, support functions to product development. Let’s build the future of mobile telecommunications together! About Rakuten Rakuten Group, Inc. (TSE: 4755) is a global leader in internet services that empower individuals, communities, businesses and society. Founded in Tokyo in 1997 as an online marketplace, Rakuten has expanded to offer services in e-commerce, fintech, digital content and communications to approximately 1.5 billion members around the world. The Rakuten Group has over 27,000 employees, and operations in 30 countries and regions. For more information visit https://global.rakuten.com/corp/. Responsibilities : Maintaining lab network including VPNs, router, servers and other physical hardware. Oversees, plans and implements changes to infrastructure with the goal of enhancing performance. Oversees the performance of day-to-day operational support for server, storage or network infrastructures. Oversees storage and server data backup, data migration and disaster recovery operations. Oversees software and operating system upgrades and track system licensing. Oversees the configuration of security settings or access permissions for groups and individual. Documents complex procedures and complex troubleshooting procedures related to systems/networks software and hardware. Install and configured network equipment. Monitoring systems to improve network performance for all systems. Troubleshooting, resolving, and communicating networking issues to other employees and or management. Maintaining current knowledge and understanding of security and networking best practice to offer best solutions and protection to company systems. Knowledge of IPv4/IPv6 . Monitor and manage all installed systems and infrastructure. Maintain and supervise inventory. Experience with virtualization (e.g., VMware, Hyper-V etc.) Cloud experience (AWS, GCP, Azure etc.) [ Added advantage] Ability to code in scripting languages ( e.g.. Bash, Python or PowerShell). Qualifications : Knowledge of networking/wireless components and terminology. Knowledge of mobile device configurations and troubleshooting. Bachelor's Degree in Information Systems or related field or equivalent work experience. 5 or more years of demonstrated experience with desktop support/imaging. Experience with scripting languages such as BASH, PowerShell or python. Experience with reporting technologies in configuration management systems. Excellent problem solver; able to prioritize and coordinate between tasks. RAKUTEN SHUGI PRINCIPLES: Our worldwide practices describe specific behaviours that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success. Always improve, always advance. Only be satisfied with complete success - Kaizen. Be passionately professional. Take an uncompromising approach to your work and be determined to be the best. Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory. Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile. Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team. The successful applicant for this role will be eligible for health, vision, dental insurance, 401k matching, PTO and other employee benefits as the company implements. Rakuten is an equal opportunity employer. We do not discriminate based on race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status. Women, minorities, individuals with disabilities and protected veterans are encouraged.",
        "url": "https://www.linkedin.com/jobs/view/3953353235"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3907286562,
        "company": "HireIO, Inc.",
        "title": "Senior Backend Software Engineer",
        "created_on": 1720636312.2436776,
        "description": "Introduction We are an all-in-one video editing solution that helps you create incredible videos. With the mission of making content creation easier and more engaging, we were first launched on mobile platforms in April 2020. In less than a year, we were released in Brazil, US, Indonesia, Japan and several other countries. To better serve the diverse needs, we released its online and PC version in 2022. Starting in 2023, we have continued to invest in AI technology to provide product features that are more accessible and easier to use. As of today, our global monthly active users have exceeded 500 million. It has remained at the top of the download list in several app stores. We are currently available in over 170 countries/regions. We are an incredible young team with passion. We enjoy learning new things and taking on challenges. Team culture here is open and inclusive. Everyone can make things happen, good ideas will always win. Today, we are continuously increasing investment in AI technology to make content creation much easier for everyone, and we always take the protection of user privacy and data security very seriously. Therefore, we set up an engineer team with high talent density, mainly focusing on AI technology and Privacy&Security here. Responsibilities Develop efficient, highly scalable and secured services and tools to build/integrate Security & Privacy systems.- Optimize backend systems and services for data security, modularity, computational efficiency and scalability Deliver best-in-class engineering excellence practices across all product engineering disciplines Requirements Minimum Qualifications Bachelors or higher degree in Computer Science or related technical discipline 5+ years experience developing highly scalable backend services and systems using at least one of Golang/Java/Rust/C++ Deep understanding of data structure, algorithm design and analysis, networking, data security and highly scalable systems design In-depth knowledge of common databases and messaging frameworks like MySQL/Redis/Kafka etc Strong software programming capabilities, exhibits good code design and coding style Good collaborator and team player, comfortable working in a fast moving, culturally diverse and globally distributed team environment Preferred Qualifications Experience of privacy and security technology is a big plus",
        "url": "https://www.linkedin.com/jobs/view/3907286562"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3901702630,
        "company": "Google",
        "title": "Software Engineer III, Machine Learning, Google Ads",
        "created_on": 1720636314.0403054,
        "description": "Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; Los Angeles, CA, USA; Irvine, CA, USA; New York, NY, USA . Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning or natural language processing. Preferred qualifications: Master's degree or PhD in Computer Science or related technical field. 2 years of experience with performance, large scale systems data analysis, visualization tools, or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About The Job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions. Google Ads is helping power the open internet with the best technology that connects and creates value for people, publishers, advertisers, and Google. We’re made up of multiple teams, building Google’s Advertising products including search, display, shopping, travel and video advertising, as well as analytics. Our teams create trusted experiences between people and businesses with useful ads. We help grow businesses of all sizes from small businesses, to large brands, to YouTube creators, with effective advertiser tools that deliver measurable results. We also enable Google to engage with customers at scale. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3901702630"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3837056352,
        "company": "Slash",
        "title": "Software Engineer",
        "created_on": 1720636315.7447054,
        "description": "What You’ll Be Doing Contributing to the logic and systems that power our core financial product, guard against bad actors, and categorize customers into high and low risk — all at scale under demanding latency constraints. Influencing code-standards, shaping our engineering culture, contributing to our roadmap, and talking to customers to figure out how we can solve their problems with software. Designing and building scalable backend systems that can handle hundreds of thousands of requests per second with Typescript. Contributing to our production monitoring, logging, metrics, and analytics stack. Writing libraries and frameworks to speed up internal development and complicated workflows. We’re Looking For Someone Who Is looking to take full ownership of their work and make an immediate impact Thrives in a dynamic and fast-paced work environment Loves writing code and values deep technical knowledge as much as delivering great product experiences. Has experience shipping high-quality software products Interest in working with our tech stack (React, Typescript, NodeJS, Redis, CockroachDB) Knowledge of functional programming, Javascript, and Typescript’s type-systems is appreciated, but not required Experience working with an IaC such as Terraform to ship code on AWS is interesting, but not required What's In It For You Opportunity for high growth High autonomy + ownership culture Competitive pay + equity package Unlimited PTO, Health, Vision, and Dental coverage Free lunch and dinner daily at the office Latest 16 inch Macbook Pro",
        "url": "https://www.linkedin.com/jobs/view/3837056352"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3655203487,
        "company": "Burq",
        "title": "Software / API Integration Engineer",
        "created_on": 1720636317.4825063,
        "description": "About Burq Burq started with an ambitious mission: how can we turn the complex process of offering delivery into a simple turnkey solution. We started with building the largest network of delivery networks, partnering with some of the biggest delivery companies. We then made it extremely easy for businesses to plug into our network and start offering delivery to their customers. Now, we're powering deliveries for some of the fastest-growing companies from retailers to startups. It's a big mission and now we want you to join us to make it even bigger! 🚀 We're already backed by some of the Valley's leading venture capitalists, including Village Global, the fund whose investors include Bill Gates, Jeff Bezos, Mark Zuckerberg, Reid Hoffman, and Sara Blakely. We have assembled a world-class team all over the U.S. We operate at scale, but we're still a small team relative to the opportunity. We have a staggering amount of work ahead. That means you have an unprecedented opportunity to grow while doing the most important work of your career. We want people who are unafraid to be wrong and support decisions with numbers and narrative. Here's a quick overview of what you will be doing: API Integration Engineer As an API Integration Engineer at Burq, you will be joining a team of talented engineers working together to transform the way businesses offer on-demand & same-day delivery. You will be part of an emerging team that is building a product to power millions of businesses with their delivery needs. Basic Qualifications (Required Skills/Experience) Bachelor of science degree from an accredited university in Computer Science/Engineering, Software Engineering, or equivalent. 5+ years of experience working professionally designing and developing highly scalable software systems 5+ years of experience in REST API design for extensibility and portability, development and, integration of data sources, other APIs, and databases 5+ years of experience in Javascript/Typescript 3+ years of experience in NodeJS 3+ years of experience in SQL and at least one of these relational databases: MySQL, MariaDB, SQLite, PostgreSQL Experience with Jira or a similar issue-tracking system Experience in an AGILE/SCRUM development environment Experience with code versioning tools like GIT and participating in code reviews Strong understanding of asynchronous programming/promises and its application Strong understanding of user authentication, user authorization, and security compliance between environments, servers, and other systems using OAuth API Documentation automated generation and manual additions Writing testable, efficient, and reusable code via unit testing and end-to-end automated testing in frameworks like Jasmine, Karma, and Selenium An excellent ability to debug and fix issues Skilled in problem-solving with data structures, design patterns, and algorithms, and how they apply to the scalability of applications Skilled in code refactoring, best practices, design principles, and object-oriented programming Skilled in time management with excellent verbal and written communication skills An excellent communicator, flexible team player, independent thinking, strong in the documentation that has experience working with teams in different time zones Has humility and isn't afraid to ask questions while understanding the criticality of releases Ability to thrive in a fast-paced global engineering environment with continuous innovation A willingness to go above and beyond to solve problems and tackle dynamic challenges Strong customer service and client-facing skills and brings a positive attitude and energy Preferred Qualifications (Nice To Have) Experience in one of these frameworks: ExpressJS, NestJS Experience in one of these frameworks: Angular, React, or Vue Experience in HTML5 & CSS3 Experience working with microservices Experience with AWS infrastructure Responsibilities You will build a strategy for the integrations of our third party clients using the principles of scalability, quality, reusability, and security You will improve and refactor existing API endpoints while also building new ones You will improve the reliability of our API through unit testing and end-to-end testing You will understand and solve integration needs between numerous applications and data sources You will be planning the end-to-end development of our integrations ranging from high-level architecture all the way to code implementation while participating in a fast-paced global agile environment You will communicate with a wide array of internal and external stakeholders to understand the business goal and technical work going into the integrations You will have a deep understanding of feature break-downs, story pointing, and delivery of the integrations You will work with new technologies in order to design highly scalable software which achieves our desired functionality You will create documentation and be a champion of our integrations as the company is rapidly growing Benefits Investing in you 🙏 Competitive salary and opportunity for equity Option to work fully remotely or in-person Medical, dental and vision insurance Reimbursement for educational courses Generous Time Off 🏝 Workstation setup stipend 🧑🏻‍💻👩🏾‍💻 At Burq, we value diversity. We are an equal opportunity employer: we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3655203487"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "California, United States",
        "job_id": 3888446788,
        "company": "IT Minds LLC",
        "title": "Data Center Infra Engineer",
        "created_on": 1720636319.240296,
        "description": "Job Title: Data Center Infra Engineer Location: Remote Qualifications Someone with a deep understanding of software-hardware interactions that obsesses about low-level Linux configurations and optimizations Deep experience and fluency with Linux environments Experience building with modern infrastructure tools such as Docker, Kubernetes, Ansible, Packer and Terraform. Experience with TCP/IP configurations and troubleshooting on Linux systems Experience writing code to automate infrastructure management tasks with at least one language (Go, Python, Bash or similar) 5+ years of infrastructure management experience including bare metal server management and operating system image creation and deployments Responsibilities: Design and Implementation: Collaborate with IT teams to design and plan data center infrastructure, including server racks, networking equipment, power distribution, cooling systems, and security measures. Implement and deploy hardware and software solutions in the data center environment. Ensure compliance with industry standards, best practices, and security protocols. Maintenance and Troubleshooting: Perform regular maintenance tasks such as server hardware upgrades, firmware updates, and system patches. Monitor data center systems for performance, availability, and security, and proactively address issues as they arise. Troubleshoot hardware, software, and network problems to minimize downtime and maintain optimal performance. Capacity Planning and Optimization: Monitor data center resources, including power consumption, cooling efficiency, and server utilization, to ensure scalability and efficient resource allocation. Analyze performance metrics and recommend upgrades or optimizations to meet growing business needs. Networking and Connectivity: Configure and maintain network switches, routers, and firewalls to ensure seamless data flow and secure communication within the data center. Collaborate with network engineers to design and implement network architecture that supports high availability and redundancy. Security and Compliance: Implement and maintain security measures to protect data center assets from physical and cyber threats. Ensure compliance with industry standards and regulations such as ISO 27001, NIST, and HIPAA, depending on the industry. Documentation: Create and maintain documentation for data center layouts, configurations, and procedures. Keep accurate records of hardware and software inventory, licenses, and maintenance schedules. Vendor Management: Collaborate with vendors and suppliers to procure data center equipment, negotiate contracts, and ensure timely delivery of hardware and services. Evaluate and recommend new technologies and solutions that enhance data center efficiency and performance. Requirements: Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent experience). Proven experience in data center operations, infrastructure design, and implementation. Proficiency in server hardware, operating systems (Linux, Windows), virtualization technologies, and networking protocols. Familiarity with data center management tools and monitoring solutions. Strong troubleshooting and problem-solving skills. Knowledge of security best practices and experience implementing security measures in a data center environment. Excellent communication and collaboration skills for working with cross-functional teams and vendors. Relevant certifications such as CompTIA Server+, Cisco CCNA, VMware VCP, or equivalent, are a plus. You should have deep experience and nuanced opinions on existing cloud services and developer tools 5+ years of professional SRE experience 5+ years of experience contributing to architecture and design (architecture, design patterns, reliability and scaling) of new and current systems Bachelor's Degree in Computer Science or related field, or 8+ years relevant work experience Solid understanding of infrastructure design, including the operational trade-offs of various designs Experience writing high quality code with at least one programming language (Python, Go, or similar) Experience building with modern infrastructure tools such as Docker, Kubernetes, Ansible, Cloud Formation, Terraform Experience building with modern CI/CD practices and build systems, such as GitLab CI/CD, CircleCI, GitHub Actions Experience with logging, monitoring and alerting systems and tools Experience with Unix/Linux environments Experience with TCP/IP and network programming With Regards, NAGENDRA UNDAVALLI Hiring for Fulltime / Contract Employment Opportunities. IT Minds LLC. Phone: 949-534-3939 Ext : 412 | Direct: 949-210-9874 Cell: 949-649-3979 Email ID: Nagendra@itminds.net www.itminds.net",
        "url": "https://www.linkedin.com/jobs/view/3888446788"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3958087993,
        "company": "Google",
        "title": "Software Engineer III, YouTube",
        "created_on": 1720636320.926395,
        "description": "Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. Programming experience in C++. Preferred qualifications: Master's degree or PhD in Computer Science or related technical fields. 2 years of experience with performance, large scale systems data analysis, visualization tools, or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About The Job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions. Google is an engineering company at heart. We hire people with a broad set of technical skills who are ready to take on some of technology's greatest challenges and make an impact on users around the world. At Google, engineers not only revolutionize search, they routinely work on scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world. From Google Ads to Chrome, Android to YouTube, social to local, Google engineers are changing the world one technological achievement after another. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google. Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3958087993"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Pleasanton, CA",
        "job_id": 3959533191,
        "company": "Maxonic",
        "title": "Python Developer with GCP, Data Warehousing",
        "created_on": 1720636322.7024572,
        "description": "Maxonic maintains a close and long-term relationship with our direct client. In support of their needs, we are looking for a Python Developer with GCP, Data Warehousing Job Description: Job Title: Python Developer with GCP, Data Warehousing Job Location: Pleasanton Work Schedule: Hybrid Pay Rate: $72- $78 C2C, $55 - $64 W2 Responsibilities: Data Warehousing Understanding of data warehousing concepts Experience with tools like BigQuery for storing and querying large datasets. ETL (Extract, Transform, Load) Proficiency in designing and implementing ETL pipelines using tools like Dataflow Apache Beam or Cloud Composer Programming Languages Strong programming skills in languages such as Python, Java, or Scala for building data pipelines and performing data manipulation tasks. Database Management Knowledge of database systems, particularly BIg Query, Google Cloud SQL, Cloud Spanner Data Modeling Ability to design and implement data models for efficient storage and retrieval of data Google Cloud Services GCP services such as Pub/Sub for messaging, Cloud functions etc Data Catalog for metadata management Data Studio for data visualization Version Control and Code deployment Familiarity with version control systems like Git for managing code GitHub Actions About Maxonic: Since 2002 Maxonic has been at the forefront of connecting candidate strengths to client challenges. Our award winning, dedicated team of recruiting professionals are specialized by technology, are great listeners, and will seek to find a position that meets the long-term career needs of our candidates. We take pride in the over 10,000 candidates that we have placed, and the repeat business that we earn from our satisfied clients. Interested in Applying? Please apply with your most current resume. Feel free to contact Shubham (shubham.s@maxonic.com / (510) 955-1056 ) for more details",
        "url": "https://www.linkedin.com/jobs/view/3959533191"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3943920414,
        "company": "Walmart",
        "title": "Staff, Data Engineer (AdTech)",
        "created_on": 1720636326.7864697,
        "description": "Position Summary... What you'll do... About The Team Join our Walmart's Display Ad team of skilled engineers and help shape the performance optimization strategies of our cutting-edge systems. If you're a passionate and driven individual with a knack for uncovering system bottlenecks and fine-tuning performance, we encourage you to apply and be a part of our innovative journey. Position Overview We are seeking a talented and experienced Java Data Engineer to join our team of skilled professionals. As a Data Engineer, you will play a critical role in ensuring the optimal performance of our systems. The ideal candidate should possess a deep understanding of Java applications, have the ability to identify and resolve system issues and performance bottlenecks, and be comfortable working in complex distributed systems across multi-cloud environments. What You'll Do Collaborate closely with cross-functional teams including developers, architects, and operations to identify performance bottlenecks, system issues, and areas for optimization. Conduct thorough performance analysis of Java-based applications through profiling, monitoring, and benchmarking to identify performance degradation and suggest improvements. Deep dive into the codebase to understand the root causes of performance issues, including resource contention, memory leaks, and suboptimal algorithms. Develop and execute performance testing strategies to simulate real-world scenarios, stress-test system components, and uncover performance limitations. Design, implement, and execute performance experiments to evaluate the impact of code changes and system configurations. Work hands-on to fine-tune system parameters, configurations, and resource allocation to achieve optimal performance results. Collaborate with development teams to provide guidance and recommendations on code optimizations, caching strategies, and concurrency enhancements. Utilize performance monitoring and profiling tools to track and analyze system behavior, and proactively address potential bottlenecks. Collaborate on designing and implementing performance-related features that enhance the overall scalability and efficiency of the systems. Document performance analysis findings, optimization strategies, and best practices for future reference. Stay current with emerging technologies, industry trends, and best practices related to Java performance and distributed systems. What You'll Bring Bachelor's degree in computer science, Software Engineering, or a related field. Master's degree is a plus. Proven experience (8+ years) as a Performance Engineer, preferably with a focus on Java-based systems. Proficiency in Java programming language and deep knowledge of Java internals, memory management, and threading. Strong experience with performance profiling tools and techniques to identify bottlenecks in code and system components. Solid understanding of distributed systems architecture and design principles. Familiarity with multi-cloud environments and hands-on experience in optimizing applications for cloud deployment. Ability to analyze and interpret performance metrics to make informed decisions on system optimizations. Experience with performance testing frameworks and load generation tools. Familiarity with containerization technologies (e.g., Docker, Kubernetes) and their impact on application performance. Strong problem-solving skills with the ability to troubleshoot and debug complex systems. Excellent communication skills to collaborate effectively with cross-functional teams and present performance analysis findings. Ability to work independently and take ownership of performance-related tasks and projects. Certifications in performance engineering or relevant cloud platforms is a plus. Openness to learning new technologies and adapting to evolving challenges. About Walmart Global Tech Imagine working in an environment where one line of code can make life easier for hundreds of millions of people and put a smile on their face. That's what we do at Walmart Global Tech. We're a team of 15,000+ software engineers, data scientists and service professionals within Walmart, the world's largest retailer, delivering innovations that improve how our customers shop and empower our 2.3 million associates. To others, innovation looks like an app, service, or some code, but Walmart has always been about people. People are why we innovate, and people power our innovations. Being human led is our true disruption. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail. Flexible, hybrid work We use a hybrid way of working that is primarily virtual, while remaining near the locations Global Tech calls home. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives and spend less time commuting. Of course, being together in person is an important part of our culture and shared success. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities. Benefits Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Equal Opportunity Employer Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas, and opinions - while being inclusive of all people. At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more. ‎ ‎ ‎ You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. ‎ For information about PTO, see https://one.walmart.com/notices . ‎ ‎ Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart. ‎ Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. ‎ For Information About Benefits And Eligibility, See One.Walmart . ‎ Bellevue, Washington US-11075:The annual salary range for this position is $132,000.00-$264,000.00 ‎ Sunnyvale, California US-04397:The annual salary range for this position is $143,000.00-$286,000.00 ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎ Additional Compensation Includes Annual Or Quarterly Performance Bonuses. ‎ Additional Compensation For Certain Positions May Also Include ‎ ‎ Stock ‎ ‎ Minimum Qualifications... Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field. 3 years' experience in data engineering, database engineering, business intelligence, or business analytics. Preferred Qualifications... Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master's degree in Computer Science or related field and 4 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart's accessibility standards and guidelines for supporting an inclusive culture. Primary Location... 680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America",
        "url": "https://www.linkedin.com/jobs/view/3943920414"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Garden Grove, CA",
        "job_id": 3964813414,
        "company": "Harbinger",
        "title": "Software Engineer, Data Applications",
        "created_on": 1720636328.562854,
        "description": "About Harbinger Harbinger Motors Inc. is a Southern California-based electric vehicle manufacturer on a mission to transform the automotive and transportation industries, bringing to market EVs developed from the ground up to address the needs of the Medium Duty vehicle industry. This broad, and to date poorly addressed, market segment includes class 4 to 7 commercial delivery vehicles, RVs and utility vehicles, among others. Leveraging a foundation of proprietary, in-house developed vehicle technologies, Harbinger's first-of-its-kind EV platform will bring enhancements in vehicle performance, durability and operator comfort. And importantly, Harbinger's vehicles will be priced for zero acquisition premium relative to traditional gas- and diesel-based competitors, removing one of the most tenacious barriers to EV adoption. Harbinger's team, with operations in Southern California and Michigan, includes industry veterans with expertise in powertrain, battery, chassis and software development, along with leaders in advanced manufacturing, corporate development, operations and finance. Our team members come from leading innovators, both in and out of the automotive industry, including Tesla, Rivian, Canoo, Ford, Anduril, and SpaceX. Founded in 2021, Harbinger is a venture-backed startup on a rapid growth trajectory, looking for candidates that thrive on tackling complex challenges and who share in our passion to bring clean transportation alternatives to a segment of the market starving for innovation. Job Overview The data applications software engineer will be pivotal in designing, developing, and maintaining data analysis and integration solutions to draw insights from vehicle data. This role demands a strong background in software engineering, data science, and a passion for sustainable technology. The ideal candidate will work closely with cross-functional teams to develop applications which support engineering analysis, vehicle reliability and service operations, and support our mission to deliver the best experience for customers. What You’ll Do Database Infrastructure Development: Design and implement ETL processes and data storage to integrate data from different sources and combine to facilitate data analysis, metric development and visualization. Application Development: Collaborate with cross-functional engineers to create data applications including data-based correlation of simulation models, verification of control algorithm performance, vehicle performance and reliability analysis, event-tracking and other value-added applications for the development and continuous improvement of our technology. Performance Optimization: Monitor and optimize the performance of data applications. Identify and resolve performance bottlenecks. Documentation & Testing: Create and maintain detailed documentation of data applications, ensuring clarity and accessibility. Develop and execute comprehensive testing plans to guarantee the reliability and accuracy of integrated data. Troubleshooting & Support: Provide ongoing support and troubleshooting for data applications Work with stakeholders to resolve data-related problems promptly and effectively. Who You Are Bachelor’s degree in Computer Science, Information Technology, or a related field. Master’s degree preferred. Minimum of 3-5 years of experience in software engineering with a focus on data science and information systems. Strong fluency in Python and data analysis packages such as pandas, numpy, SciPy, and similar Experience with data analysis computational frameworks such as Apache Spark, Hadoop Experience with ETL processes and data warehousing solutions. Familiarity with cloud platforms (e.g., AWS, Azure, Google Cloud) and their data integration services. Experience with containerization: docker, kubernetes, Understanding of IoT data processing data analysis challenges. Familiarity with machine learning packages such as PyTorch and TensorFlow a plus Strong problem-solving skills and attention to detail. Excellent communication and teamwork skills. Ability to work independently and manage multiple tasks in a fast-paced environment. Rev up your career with our electrifying compensation and benefits package! At Harbinger Motors, we understand that your skills, experience, and expertise are as unique as our cutting-edge electric vehicles. That's why we tailor our offers to suit your individual profile, considering your years of experience, specialized knowledge, and market demands. In addition to a competitive base salary, our perks charge ahead of the competition: 100% Comprehensive Health Coverage: You and your loved ones are covered with top-tier medical, dental, and vision insurance. Accelerate Your Wealth: As one of our first 100 employees, you'll have the opportunity to rev up your financial future with early-stage stock options. Unleash Your Time: Take control of your work-life balance. Salaried teammates receive flexible PTO and the freedom to celebrate holidays and wellness days as you see fit. Cruise into Vacations: Enjoy an exciting annual vacation stipend to help you recharge your batteries. Fuel Your Day: Forget brown bag lunches; we've got you covered with paid lunches and dinners to keep you energized. These are just a few of our benefits and perks, as we're constantly adjusting and adding more benefits to best serve our teammates. At Harbinger Motors, we don't just offer jobs; we provide the fuel for your career journey. Join us in shaping the future of sustainable transportation, where your hard work and dedication are always rewarded. Get ready to drive your career forward with us! California Pay Range $140,000—$180,000 USD Equal Opportunity Harbinger is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender, gender expression, gender identity, genetic information or characteristics, physical or mental disability, marital/domestic partner status, age, military/veteran status, medical condition, or any other characteristic protected by law. Harbinger is committed to ensuring that our hiring process is accessible for persons with disabilities. If you have a disability or limitation, such as those covered by the Americans with Disabilities Act, that requires accommodations to assist you in the search and application process, please email us at info@harbingermotors.com. Candidate Data Privacy Harbinger may collect, use and disclose your personal information or personal data (within the meaning of the applicable data protection laws) when you apply for employment and/or participate in our recruitment processes (“Candidate Personal Data”). This data includes contact, demographic, communications, educational, professional, employment, social media/website, network/device, recruiting system usage/interaction, security and preference information. Harbinger may use your Candidate Personal Data for the purposes of (i) tracking interactions with our recruiting system; (ii) carrying out, analyzing and improving our application and recruitment process, including assessing you and your application and conducting employment, background and reference checks; (iii) establishing an employment relationship or entering into an employment contract with you; (iv) complying with our legal, regulatory and corporate governance obligations; (v) recordkeeping; (vi) ensuring network and information security and preventing fraud; and (vii) as otherwise required or permitted by applicable law. Harbinger may share your Candidate Personal Data with (i) internal personnel who have a need to know such information in order to perform their duties, including individuals on our HR, legal, and finance teams, and the team(s) with the position(s) for which you are applying; (ii) Harbinger affiliates; and (iii) Harbinger’s service providers, including providers of background checks, staffing services, and cloud services. Harbinger may transfer or store internationally your Candidate Personal Data, including to or in the United States, Canada, the United Kingdom, and the European Union and in the cloud, and this data may be subject to the laws and accessible to the courts, law enforcement and national security authorities of such jurisdictions. Please note that we are currently not accepting applications from third party application services. Any unsolicited resumes or candidate profiles submitted in response to our job posting shall be considered the property of Harbinger and are not subject to payment of referral or placement fees if any such candidate is later hired by Harbinger unless you have a signed written agreement in place with us which covers the applicable job posting.",
        "url": "https://www.linkedin.com/jobs/view/3964813414"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Redwood City, CA",
        "job_id": 3837051800,
        "company": "Vorticity Inc.",
        "title": "Software Engineer",
        "created_on": 1720636332.0917864,
        "description": "About The Role As a core software developer, you will directly impact how scientific computing applications are executed on CPUs, GPUs to our own hardware. In this position, you will develop software for compilation, optimization, execution, acceleration, debugging, profiling, and/or integration of scientific computing applications. Responsibilities Develop software in C++, CUDA or Python to optimize, compile, and/or execute scientific computing applications and numerical solutions to complex partial differential equations. Measure, analyze, debug, and improve the software stack that supports these models Integrate and deploy successful improvements into production software releases and to customers Requirements Strong proficiency in C/C++, CUDA and Python Ability to operate at multiple levels of abstraction in a complex software system Bachelor's degree in Engineering, Computer Science, Mathematics, Physics or related educational background. * Positions are available at all levels of seniority Preferred Skills Familiarity with scientific computing methods (e.g. Finite difference, Monte Carlo, FFT) Strong knowledge of computer science fundamentals",
        "url": "https://www.linkedin.com/jobs/view/3837051800"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Foster City, CA",
        "job_id": 3955379437,
        "company": "Visa",
        "title": "Sr. Database Engineer",
        "created_on": 1720636333.8079033,
        "description": "Company Description Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid. Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa. Job Description Visa U.S.A. Inc., a Visa Inc. company, needs a Sr. Database Engineer (multiple openings) in Foster City, CA to Design and implement innovative infrastructure solutions/infrastructure management solutions that take advantage of technology advances that allow cost reduction, standardization and commoditization. Design, implement and integrate solutions to expose all the services as API to be consumed as code by all the partners. Manage user access control/roles via IAM and other user management tools depending on application and its integrations. Design and implement VPCs, Subnets, NACLs, Security Groups and other networking related configurations based on the network requirements within cloud accounts. Architect and implement tools like Elasticsearch, Kafka and InfluxDB, Grafana etc. that form a core part of Data Engineering team’s software requirements as well as manage all the required security around it. Responsible for building reliable pipelines through which on-premise teams can deliver data reliably and securely to cloud targets. Collaborate with the team to evolve the public cloud / hybrid cloud ecosystem, establish and mature standards and integration for infrastructure management domains - logging, monitoring, configuration management and orchestration. Identify and implement standard tool sets to reduce complexity and support operational goals for increasing automation across the enterprise. Develop processes and procedures to integrate multiple disparate public cloud computing environments at scale. Work with multiple businesses within the organization and develop standard ways of working with Public cloud environments. Integrate cloud accounts with SIEM tools to monitor security and make changes to stay in compliance with security requirements. Develop advanced scripts and automation for manipulation of multiple data repositories to support analyst requirements. Develop automation for all cloud-based deployments. Design, build and manage deployments to achieve efficiency and repeatability. Work on tools like Kubernetes for automated deployments of applications, and use Terraform to automate Infrastructure Provisioning. Guide the team with initiatives and vision projects. Work with Vendors and Stakeholders to achieve specific set of application and security requirements. May telecommute. Qualifications Basic Qualifications: Master's degree, or foreign equivalent, in Computer Science, Information Systems Management or a related technical field and 2 years of experience in the job offered or in a related database engineer or database administrator occupation; Cloud computing and cloud security; Delivering plans for required functions using the Amazon AWS offerings Documenting infrastructure, procedures, and processes; and Cloud services and software utilizing the cloud environment Additional Information Worksite: Foster City, CA (May Telecommute) This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Travel Requirements: This position does not require travel. Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers. Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code. U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is $147,368.00 USD to $158,600.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for an annual bonus and equity. Visa has a comprehensive benefits package for which this position is eligible that includes Medical, Dental, Vision, 401(k), Employee Stock Purchase Program, FSA/HSA, Life Insurance, Paid Time off and Wellness Programs.",
        "url": "https://www.linkedin.com/jobs/view/3955379437"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Atherton, CA",
        "job_id": 3888470862,
        "company": "Zortech Solutions",
        "title": "Linux System Engineer",
        "created_on": 1720636335.5061493,
        "description": "Role: Linux System Engineer Location: Menlo Park, CA (Onsite) Mandatory : Bare- metal environment experience , Experience With Ansible . Job Description: Setting up server (Installation of OS, Disk and Network configurations) Maintenance of the server (On Demand firmware upgrades in the server and its components) Installation and Configuration of Software Packages (Eg., Automation framework in a Continuous Delivery mode) Monitor the stability of the Server and Software stack and troubleshoot and fix any issues Provide On-Call support in resolving any issues with the Server or Software packages from remote and local labs Participate in Weekly calls with Vendors/ODM (Original Device Manufacturers) in understanding any issues or enhancement requests and address them Skills Strong Linux experience with troubleshooting skills Experience in Shell scripting Involved in CI/CD using Ansible Experience in configuring different server types and models",
        "url": "https://www.linkedin.com/jobs/view/3888470862"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Palo Alto, CA",
        "job_id": 3955061226,
        "company": "Tesla",
        "title": "Software Engineer, Backend, AI Evaluation",
        "created_on": 1720636337.1090167,
        "description": "What To Expect The AI Evaluation team is the main line of defense in ensuring customer safety. We are looking for an experienced backend developer to take ownership of the tooling we use to determine the best model for release. These tools have high visibility within the organization and help drive key decisions about model architecture, data integrity, and exported model performance. This engineer will collaborate with AI researchers, infrastructure & fleet telemetry teams, and release managers to propel these efforts forward. What You'll Do Create, maintain and expand internal tools for evaluation of Autopilot vehicle behavior Design and implement tools and dashboards to accelerate the evaluation cycle of our model training Work with AI researchers to support the evaluation of evolving projects and implement new production features Drive projects from inception to completion & present projects to org leadership What You'll Bring Bachelor's Degree in Computer Science, or proof of exceptional skills in related field Strong Python coding skills Experience with web frameworks such as Django or Flask Strong knowledge of relational database systems (PostgreSQL, MySQL) Strong knowledge of AWS, Splunk or other infrastructure tools Experience with TypeScript and React is a plus Excellent interpersonal, communication, and collaboration skills Benefits Compensation and Benefits Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire: Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction Family-building, fertility, adoption and surrogacy benefits Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA Healthcare and Dependent Care Flexible Spending Accounts (FSA) LGBTQ+ care concierge services 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits Company paid Basic Life, AD&D, short-term and long-term disability insurance Employee Assistance Program Sick and Vacation time (Flex time for salary positions), and Paid Holidays Back-up childcare and parenting support resources Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance Weight Loss and Tobacco Cessation Programs Tesla Babies program Commuter benefits Employee discounts and perks program Expected Compensation $104,000 - $348,000/annual salary + cash and stock awards + benefits Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment. , Tesla",
        "url": "https://www.linkedin.com/jobs/view/3955061226"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3911662257,
        "company": "DivcoWest",
        "title": "System Engineer",
        "created_on": 1720636338.8722923,
        "description": "SUMMARY DivcoWest is seeking a versatile Senior System Engineer (SE)to join our team. The role entails crucial responsibilities, including the design, planning, assessment, and formulation of strategies for the Company’s migration and operation within the Microsoft cloud /on-prem ecosystem. This individual participates in technical research and development to enable continuing innovation within the infrastructure. This individual ensures that system hardware, operating systems, software systems, and related procedures adhere to organizational values, enabling staff, and partners. They will also assist project teams with technical issues in the initiation and planning phases of our standard project management methodology. These activities include the definition of needs, benefits, and technical strategy; research & development within the project life cycle; technical analysis and design; and support of operations staff in executing, testing and rolling-out the solutions. This is a hands-on position. This is a hybrid role, 3 days in office. When coming to the office, the individual will work primarily in our 301 Howard St, San Francisco, CA Corporate office. Interested candidates should send their resumes to Recruiting@divcore.com Responsibilities Act as the primary technical expert in the Microsoft 365 domain, On-Prem Active Directory etc. Develop, configure, and maintain the organization's Microsoft 365 environment as well as on-prem windows server environments. Translate business requirements into architectural designs and effectively communicate them to C-level executives. Lead end-to-end implementations of Microsoft 365 workloads, ensuring seamless integration. Manage the on-prem windows environment on VMWare running on Nimble Storage. Offer guidance to the IT management team on current and emerging Microsoft 365 /Azure technologies. Generate comprehensive documentation for both current and future cloud solutions, detailing both high-level overviews and specific technical configurations. Assess Microsoft 365 platform governance needs and evaluate security configuration options. Provide expertise and lead significant service migrations to Microsoft 365. Collaborate closely with Infosec teams to ensure that designs adhere to information security best practices and organizational requirements. Regularly conduct assessments of Microsoft 365 and cloud environments to identify and address critical deficiencies. Produce technical documentation for cloud solutions and projects, covering processes, procedures, troubleshooting steps, training materials, and change management protocols at an expert level. Mentor and coach other members of the IT team to enhance their skills and knowledge. Take ownership of solutions and provide subject matter expertise throughout the organization's software development life cycle (SDLC) process. Maintain effective provisioning, installation/configuration, operation, and maintenance of systems hardware and software and related infrastructure. REQUIREMENTS: Bachelor's degree (or equivalent work experience) required in Computer Science, Information Systems, Technology, System Analysis, Engineering, or a related field. 10+ years of progressive global enterprise-level experience with IT solutions and engineering. Advanced Microsoft 365 certifications are required. Subject matter expertise in Office 365, including Microsoft Entra ID, Exchange Online, Defender for Office 365, Teams, Teams voice services, and other O365 workloads. Proficiency in Microsoft Security components such as Defender for Identity, Defender for Cloud Apps, and Microsoft Entra ID Premium. Experience in Microsoft cloud security controls, Data Loss Prevention, Purview, and understanding of Litigation Hold, Retention, and eDiscovery. Hands-on experience delivering messaging and collaboration solutions utilizing Microsoft Exchange and Office 365. Experience managing and maintaining on-premises Active Directory, GPOs, and on-premises Active Directory migrations to M365. Experience with Azure is required. Experience with Microsoft Intune is required. 7+ years VMWare ESXi and vCenter administration experience. 10 years of Windows Endpoint system configuration, operating system upgrades, hardware & software support, Active Directory, GPO Administration, IIS, DNS and Power shell scripting. Backup jobs administration and annual DR testing experience Ability to wear multiple hats and provide exceptional support to all users. Exceptional verbal and written communication skills are a must. Availability to workevening and weekends, sometimes with little advanced notice, occasionally Travel to our company data centers when needed. Knowledge of email protection and security leveraging Mimecast is a plus.SQL Server administration experience a plus. ADDITIONAL SKILLS: Strong leadership abilities to lead internal IT groups and present on new technologies. Proficiency in identifying, scoping, and presenting detailed technical solutions to C Suite personnel. Ability to implement Microsoft cloud technologies and understand interdependencies with on-premises enterprise environments. Proactive collaboration across internal and third-party vendor teams. In-depth technical problem-solving capability. Effective articulation of escalations and communication of progress to stakeholders. Okta SSO and MFA Administration Remote Access Technologies: VPN, Remote Desktop etc. Cisco ISE /CUCM administration a plus Knowledge of networking concepts like MPLS / DNS / Routing /Switching and Firewall Ability to work proficiently and prioritize tasks with little daily guidance. Must be able to remain in a stationary position for 90% of the time. The person in this position might occasionally move about inside the office but will remain stationary for job responsibilities. Compensation: $165,000 - $180,000 Annual bonus opportunity Full benefits Divco West Services, LLC (“Company”), an equal opportunity employer, is committed to equal opportunity for all employees and applicants. The Company recruits, hires, trains, promotes, pays, and administers all personnel actions without regard to race, color, religion, sex (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), sex stereotyping (including assumptions about a person’s appearance or behavior, gender roles, gender expression, or gender identity), gender, gender identity, gender expression, national origin, age, mental or physical disability, ancestry, medical condition, marital status, military or veteran status, citizenship status, sexual orientation, genetic information, or any other status protected by applicable law. We interpret these protected statuses broadly to include both the actual status and also any perceptions and assumptions made regarding these statuses. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Please review our company Privacy Policy regarding the use of any personal information you provide us at: https://www.divcowest.com/privacy-policy/ This policy applies to all areas of employment, including recruitment, testing, screening, hiring, selection for training, upgrading, transfer, demotion, layoff, discipline, termination, compensation, benefits, and all other privileges, terms, and conditions of employment. This policy and the law prohibit employment discrimination against any employee or applicant on the basis of any legally protected status outlined above.",
        "url": "https://www.linkedin.com/jobs/view/3911662257"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Menlo Park, CA",
        "job_id": 3970102852,
        "company": "Aether",
        "title": "Software Engineer",
        "created_on": 1720636340.5336928,
        "description": "This is an on-site, Exempt, Full-Time position based in our Menlo Park, CA office. Relocation allowance will not be offered for this role and the individual hired for this role must be located in close proximity to the San Francisco, Bay Area. This position reports to the Senior Director of Automation. Aether Biomachines is on a mission to build the post-scarcity future using peptide based nanotechnology as the driving force for the next industrial revolution. By creating the world's most advanced high-throughput robotic laboratory, we are generating data at unprecedented scales to fuel deep learning algorithms. We're assembling a diverse and dynamic team of self-starters, engineers, sci-fi enthusiasts, and visionaries, and we invite you to join us on this journey. We're breaking barriers in laboratory automation to power world-class machine learning models with faster, broader, and more robust robotic sample processing systems. Our goal is to transform peptides from niche catalysts into general-purpose molecular assemblers using our platform, and enabling a future of abundance for the human race. Department Product R&D | Software | Automation Development | Automation Production | Biology | Machine Learning | G&A As a software engineer at Aether, you will contribute across our entire software platform interfacing with the high-throughput lab and machine learning systems. At the core of your responsibilities will be the maintenance of our LIMs system and supporting our lab automation drivers and data management tools. Who You Are A software generalist with 5+ years experience developing front and backend software. You have an education in a field of Science or 3+ years experience working in the biotech industry You are proficient in C#, Python, Git repository, Visual Studio, & GraphQL You have built and deployed production web applications using React You have experience working with & programming a Laboratory Information management system You have experience with programming PLCs and robotic components. You have experience with creating custom drivers for laboratory automation You have experience working in teams using git to commit clean, tested code. You have a strong understanding of UX principles/best practices. You enjoy factoring complex problems down into clear and manageable components. You enjoy working in a fast-paced, collaborative environment. You are a self-sufficient worker and maintain accountability for your own timelines. Bonus Points Experience working with GraphQL APIs. Experience programming with Thermo Momentum Scheduling software Experience with .net framework, MS Build, Jenkins, REST API, COMS, Django with graphene, Web Apps, Apollo-GraphQL, & postgresQL. Experience with data visualization libraries such as D3.js or HighCharts Experience creating wireframes and rapidly iterating on prototypes with tools such as Figma Experience building UI components and pages with tools such as Storybook.js Experience with Bioinformatics What You'll Do Develop and maintain a custom LIMS to track high volumes of experiments. Implement reliable systems to process, manage, and visualize our data. Work closely with scientists, engineers, and bioinformaticians to understand common workflows, identify opportunities for improvement and drive software requirements. Develop, update and maintain drivers and worklist template generators for laboratory automation Develop code to upload, export, & transform data into and out of databases and LIMS Maintain, manage, & optimize our database system. Articulate technical challenges and solutions across departments. Develop trust in and raise expectations for the software team. Contribute to a culture of continuous improvement and learning. About Aether Aether was founded in 2017 under the belief that synthetic biology is the key to building the post-scarcity future. In order to catalyze the next industrial revolution, we are building the world's highest throughput robotic laboratory, generating data on scales previously not possible to feed deep learning algorithms. We are building a diverse team of engineers, sci-fi nerds, and world-changers. We hope you can join us. Not sure you meet 100% of our qualifications? We encourage anyone who thinks they would excel at Aether to apply, no matter their background or how they identify. Benefits and Perks Aether pays 100% of the premiums for employees and 90% of the premiums for dependents. Importantly, these plans come couple with an HRA. Every employee receives an employer-funded, preloaded debit card that can be used for in-network medical expenses (deductibles, copays for all in-network care including Rx, office visits, specialist care, hospital stay, chiropractic acupuncture, etc. Medical (Kaiser and Anthem) Vision via VSP Dental via Delta Dental Ancillary benefits (Basic Life, AD&D, STD, LTD) HSA HRA (Fertility, Wellness) FSA (Dependent Care/Health Care/Commuter) 401K Retirement Plan via MoneyIntel Flexible Paid Time Off for Exempt Employees Employee Assistance Program (EAP) Equity (Stock options vesting over 4 years, with a 1 yr cliff) Learning & Development: You may purchase up to $50/month in books or other learning materials without any prior approval Candidate Referral Program Access to the gym at our Menlo Park location Access to our Menlo Park Labs Shuttle & Parking 10 Paid Company Holidays Monthly All-Hands Meetings Stocked kitchen with snacks and drinks Pet Insurance Discount Program Monthly team bagel breakfast Paid meals every day while you work, occasional catered meals Annual Holiday Party On-Site Fitness Center, free parking, bike racks, free EV Charging Fun--and useful--swag! EEO Our company values diversity and believes diverse teams make innovation possible. We work on complex, difficult problems with no linear or clear solutions. We believe that a diverse team can bring different perspectives and approaches, and whose experiences reflect the full set of clients we seek to serve. As such, Aether Biomachines, Inc. is committed to a diverse representation among our employees. Legal authorization to work in the U.S. is required. Aether may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills for this job. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. This position is based in our California location. This is the pay range for this position that we reasonably expect to pay. Individual compensation is based on various factors, including experience, education, skillset, and geographic location. This range is for the SF Bay Area, California location, and may be adjusted to the labor market in other geographic areas. SF Bay Area Pay Range $162,000—$198,000 USD",
        "url": "https://www.linkedin.com/jobs/view/3970102852"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Redwood City, CA",
        "job_id": 3969677577,
        "company": "Zūm",
        "title": "Staff Data Engineer",
        "created_on": 1720636342.2327392,
        "description": "Zūm has reimagined student transportation, the nation's largest mass transit system. Our integrated end-to-end cloud-based platform provides a modern service for school districts purpose-built around the needs of kids and the expectations of their families. Zūm provides one seamless, real-time interface for parents, drivers, schools, districts, administrators, and operators, to transport children safely and with increased visibility and personalized care. Our multi-sized vehicle approach includes an electric vehicle-first commitment, reduces student commute times by up to 20%, and coupled with our marketplace, delivers added fleet efficiency and optimization. We have been driving the industry forward since 2015, and with more than 8 million miles completed to date, we are leading a new era of safe, reliable, efficient, and sustainable transportation. Zūm is the leader in student transportation and logistics. We are building the next generation of technology and service platforms to bring student transportation into a new age while enabling equity, innovation, efficiency, and sustainability. We are a well-funded Series E (1.3B Valuation) company backed by top global VC firms. We are actively growing and scaling our product and engineering teams. We are looking for a Staff Data Engineer for our Data Science and Engineering team. Being the earliest member of this team, you will profoundly impact the technical direction of our data strategy. You will love this job if you are a self-driven developer who enjoys solving complex problems and building impactful solutions. What To Expect In This Role Work closely with Product, Engineering, and other key stakeholders to understand the data requirements and translate them into concrete executable roadmap Design, develop, and manage highly reliable and performant data infrastructure to support growing analytics and AI needs Build reusable frameworks that improve the reliability and scalability of our ETLs Introduce tools and processes to scale (and accelerate) our development processes Flexibility to maintain a physical presence in the office for a minimum of three days per week. Essential Technical Skills For This Role Bachelor’s degree or higher in Computer Science or equivalent degrees 10+ years of professional experience 8+ years experience working in data engineering, business intelligence, or a similar role Proficiency in programming languages such as Python/Java 5+ years of experience in ETL orchestration and workflow management tools like Airflow, Flink, Oozie, or similar technologies Expert in Database fundamentals, SQL Expert in Distributed systems Experience working with Postgres or any other DBMS platforms Experience working with BigQuery, RedShift, Snowflake, or any other Data Warehouse platform Experience working on reporting tools such as Tableau, Looker, Superset, or similar technologies Familiarity with cloud technologies like AWS/GCP/Azure. Other Skills Required To Succeed In This Role Excellent Communication skills Experience working with both technical and non-technical teams Comfortable working in a fast-paced environment and a self-starter Good planning, organization, and decision-making skills Good sense of humor with a great ability to work with others The targeted base salary range for this role is listed in the compensation section below. Actual salary may be above or below this range based on factors such as location, skills, and relevant experience. In addition, this position may include additional compensation in the form of bonus, equity, or commissions. If you are a full-time salaried or hourly worker, we offer the following benefits: Medical, Dental, Vision, 401(k), Holidays, Wellness, Vacation, and more. The targeted pay range for this role in US CA is: $175-225k Zum Services, Inc. and all its subsidiaries provide equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",
        "url": "https://www.linkedin.com/jobs/view/3969677577"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3958847926,
        "company": "AMD",
        "title": "Senior Staff Data Platform Engineer",
        "created_on": 1720636343.9076452,
        "description": "WHAT YOU DO AT AMD CHANGES EVERYTHING We care deeply about transforming lives with AMD technology to enrich our industry, our communities, and the world. Our mission is to build great products that accelerate next-generation computing experiences - the building blocks for the data center, artificial intelligence, PCs, gaming and embedded. Underpinning our mission is the AMD culture. We push the limits of innovation to solve the world’s most important challenges. We strive for execution excellence while being direct, humble, collaborative, and inclusive of diverse perspectives. AMD together we advance_ The Role We are seeking a Senior Data Platform Engineer who can design, develop, and manage some of the most impactful Enterprise-wide Big Data and Data Analytics Platform The Person You're a highly motivated team player with a strong development background, problem solving mentality, excellent communication skills, ability to prioritize tasks along with willingness to learn and adapt. Excellent teamwork skills and capable of working independently. Key Responsibilities Manage Kafka producer and spark consumer at very large scale. Design and implement Flink and Spark based ETL flow. Optimize and scale Iceberg Lakehouse Manage Data Integrity and Data Security for various big Data Platform Enterprise Data Warehousing scalability using Snowflake, Dremio, and Databricks Lakehouse Collaborate effectively with other technical teams to exploit new technologies to enhance the applications and service infrastructure. Managing highly scalable on-prem and cloud environment in Azure, GCP and AWS Preferred Experience Deep hands-on experience with big data platform Experience in Lakehouse Platforms preferably Apache Iceberg or/and Delta Lake ETL tool knowledge using Spark, Flink, Databricks, Apache Airflow etc. DW development and maintenance, to include ETL (extraction, transformation, and loading) to support Enterprise Level Business Intelligence platforms. Hands on experience with on-prem and cloud based big data platforms. Experience in cloud technologies managing end to end subscription. Solid knowledge in coding with Spark/Scala/Python/Java Strong understanding of Enterprise applications development platform Familiar with Data pipeline performance monitoring and load performance test framework/tools. Creative problem-solving style and strong critical thinking skills. Strong written and verbal communication skills. Write clear, concise, and comprehensive technical documentation. Academic Credentials Bachelor’s/master’s degree in computer science or related field strongly preferred. LOCATION: San Jose, CA At AMD, your base pay is one part of your total rewards package. Your base pay will depend on where your skills, qualifications, experience, and location fit into the hiring range for the position. You may be eligible for incentives based upon your role such as either an annual bonus or sales incentive. Many AMD employees have the opportunity to own shares of AMD stock, as well as a discount when purchasing AMD stock if voluntarily participating in AMD’s Employee Stock Purchase Plan. You’ll also be eligible for competitive benefits described in more detail here. AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process.",
        "url": "https://www.linkedin.com/jobs/view/3958847926"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Glendale, CA",
        "job_id": 3959947202,
        "company": "Evite",
        "title": "Senior Full-Stack Software Engineer (Python/React)",
        "created_on": 1720636345.6367533,
        "description": "(Local Candidates Only) Curious. Innovative. Collaborative. Inclusive. Committed to bringing people together to celebrate their most important life moments. That's who we are at Evite. We work hard, move quickly, support each other, act with integrity and have a lot of fun along the way! Sound like a party you want to be a part of? We’re currently looking for a passionate Senior Full-Stack Software Engineer (Python/React) to join our team in Los Angeles. The ideal candidate will have strong backend experience, solid computer science fundamentals, experience with a Python based web framework like Django or Flask, experience with cloud platforms (Google Cloud or AWS), and some experience with frontend web technologies (Javascript, HTML, CSS, React). Building websites is easy. Building a platform at this scale and releasing new multi-platform features with zero downtime multiple times a week is hard. If you haven’t done it before we can show you how, and our ideal candidate will have things to teach us as well. You will be developing world-class mobile web and desktop experiences using Python, Javascript, HTML/CSS, and React. You will be working cross functionally with Product and Design teams integrated into our agile “pods”. Come join the party! What We Value Making a Difference: Never be afraid to act fast and be curious. Transparency and Teamwork: Embrace collaboration and share those amazing ideas! Excellence Without Attitude: Be passionate and positive while always remembering to have fun. Core Capabilities Advanced skill in building web application backends in Python and Django/Flask. Experience with cloud-based platforms like Google Cloud (preferred), or AWS. Ability to work with client-side technologies like Javascript, HTML, CSS, and React. Experience with complex projects and the ability to work cross-team to solve problems. Responsibilities Build new capabilities into our web platform that is used by a million people per day while maintaining reliability, scalability, and code quality. Collaborate with our product team and UX/UI designers for technical guidance in building elegant and deceptively simple experiences. Participate in development of unit tests and code reviews. Analyze and troubleshoot complex system issues. Participate in our Agile Scrum process including stand-ups, sprint planning, and retrospectives. Additional Preferred Requirements At least 7 years of professional programming experience. Command of performance fundamentals and a history building high-traffic web applications. Experience with NoSQL data-stores, task queues, and common architectural components. Demonstrated experience with multiple frontend JS frameworks (React, MobX, Redux, Vue, Angular etc). Proficiency working with a Unix/Linux operating system. Familiarity with Docker and general containerization is a plus. Strong verbal and written communication skills. Desire to expand your skill sets and learn new technologies. Relentless dedication and discipline in building world-class enduring software. BA/BS, or equivalent experience. The compensation range for this role is $150-180K. Benefits & Perks At Evite Healthcare & retirement: Multiple medical plans to choose from 100% employer-paid dental & vision plans for employees and their families Employer-matched 401(k) plan 24/7 access to coaches & mental health benefits Vacation & Leaves Unlimited trust-based vacation Bereavement leave Paid time off to volunteer 12 weeks leave for parents at 100% of your salary for new births, adoptions and foster children 11 paid company-wide holidays Perks Free parking at our Glendale office or transit reimbursement Baby Bucks! An initial contribution to help cover some of those early parenting expenses Donation matching Volunteering and learning & development opportunities Fully stocked kitchen (occasionally lunches and happy hours too) And more! Evite, Inc. is committed to equal employment opportunity and values a diverse workforce. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or perception, national origin, age, marital status, disability, veteran status, genetics or other legally protected characteristics.",
        "url": "https://www.linkedin.com/jobs/view/3959947202"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Daly City, CA",
        "job_id": 3942370043,
        "company": "Motion Recruitment",
        "title": "100% Remote Data Engineer / Software Developer background needed",
        "created_on": 1720636347.313067,
        "description": "If you're a person who wants to work for an marketing company that has multiple clients in different industries. Required Skills & Experience 3+ years of Data Engineering experience Software development background SQL NoSQL Database experience Python AWS (EMR, RDS, Redshift, Kinesis) Hadoop or Spark Desired Skills & Experience Masters degree or higher in Computer Science or related field. What You Will Be Doing Tech Breakdown 70% Data Engineering 20% Data Analytics 10% Machine Learning Daily Responsibilities 80% Hands On 0% Management Duties 20% Team Collaboration The Offer 10% Bonus Stock Options You Will Receive The Following Benefits Medical Insurance Dental Benefits Vision Benefits Paid Time Off (PTO) Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Posted By: Julie Bennett",
        "url": "https://www.linkedin.com/jobs/view/3942370043"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Menlo Park, CA",
        "job_id": 3875919817,
        "company": "GRAIL",
        "title": "Staff Data Engineer (Menlo Park, CA) #3378",
        "created_on": 1720636349.0677757,
        "description": "Our mission is to detect cancer early, when it can be cured. We are working to change the trajectory of cancer mortality and bring stakeholders together to adopt innovative, safe, and effective technologies that can transform cancer care. We are a healthcare company, pioneering new technologies to advance early cancer detection. We have built a multi-disciplinary organization of scientists, engineers, and physicians and we are using the power of next-generation sequencing (NGS), population-scale clinical studies, and state-of-the-art computer science and data science to overcome one of medicine’s greatest challenges. GRAIL is headquartered in Menlo Park, California, with locations in Washington, D.C., North Carolina, and the United Kingdom. It is supported by leading global investors and pharmaceutical, technology, and healthcare companies. For more information, please visit grail.com . Are you a champion of automation interested in using your talents for optimizing processes that will make an impact on the fight against cancer? If so, join GRAIL on the Data Integration team in Research! GRAIL is seeking a Staff Data Engineer to join our team to support the growing data needs of GRAIL’s clinical and research activities. You will leverage your expertise in automation and data engineering to ensure our scientific teams have the data they need to succeed. This role is pivotal in advancing GRAIL's mission by enhancing our data infrastructure and contributing to our early cancer detection efforts. This role is located at GRAIL’s headquarters in Menlo Park, CA. It is a hybrid role in which you will work two (2) days a week onsite at headquarters. Responsibilities Be a part of a highly collaborative team that focuses on delivering value to cross-functional partners by designing, deploying, and automating secure, efficient, and scalable data infrastructure and tools, reducing manual efforts and streamlining operations. Help model Grail data and ensure that it follows FAIR principles (findable, accessible, interoperable and reusable). Drive the design, deployment, and automated delivery of data infrastructure, standardized data models, datasets, and tools. Integrate automated testing and release processes to improve the quality and velocity of software and data deliveries. Collaborate with cross-functional teams, from Research to Clinical Lab Operations to Software Engineering to provide comprehensive data solutions from conception to delivery. Ensure all software and data meet high standards for quality, clinical compliance, and privacy. Mentor fellow engineers and scientists, promoting best practices in software and data engineering. Preferred Experience B.S. / M.S. in a quantitative field (e.g., Computer Science, Engineering, Mathematics, Physics, Computational Biology) with at least 8 years of related industry experience, or Ph.D. with at least 5 years of related industry experience. Extensive experience with relational databases, data modeling principles, data pipeline tools and workflow engines (e.g., SQL, DBT, Apache Airflow, AWS GLUE, Spark. Extensive experience with DevOps practices, including CI/CD pipelines, containerized deployment (e.g., Kubernetes), and infrastructure-as-code (e.g., Terraform). Experience with supporting data science / machine learning data pipelines, preferably in the context of analysis of biological data. Experience in developing data pipelines using scalable cloud-based data warehouses / data lakes on AWS, Azure, or GCP. Solid programming skills in object-oriented and/or functional programming paradigms. Ability to embrace uncertainty, navigate ambiguity, and collaborate with product teams and stakeholders to refine requirements and drive towards clear engineering objectives and designs. A commitment to constructive dialogue, both in giving and receiving critical feedback, to foster an environment of continuous improvement. Highly Welcome Experience Prior industry experience in the healthcare, biotech, or life sciences industry, especially in the context of next-generation sequencing. Experience working in a regulated environment (e.g., FDA, CLIA, GDPR). Proficiency in Python, and R. Experience building microservices and web applications. The estimated, full-time, annual base pay scale for this position is $190,000 - $223,000. Actual base pay will consider skills, experience, and location. Based on the role, colleagues may be eligible to participate in an annual bonus plan tied to company and individual performance, or an incentive plan. We also offer a long-term incentive plan to align company and colleague success over time. In addition, GRAIL offers a progressive benefit package, including flexible time-off, a 401k with a company match, and alongside our medical, dental, vision plans, carefully selected mindfulness offerings. GRAIL is an Equal Employment Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status. We will reasonably accommodate all individuals with disabilities so that they can participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. GRAIL maintains a drug-free workplace.",
        "url": "https://www.linkedin.com/jobs/view/3875919817"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3911845001,
        "company": "Unreal Staffing, Inc",
        "title": "Software Engineer",
        "created_on": 1720636351.0504112,
        "description": "About The Role We're seeking a full-time Software Engineer to drive our core product initiatives from 0 to 1. You'll enjoy a high degree of autonomy and the opportunity to accelerate your learning curve. Our tech stack includes React, TypeScript, Rust, and Sinatra, with data storage on Postgres, Redis, and S3. Reporting directly to the Chief Technology Officer, you'll thrive in our trusting, growth-oriented environment alongside driven teammates. Requirements What You'll Do Extend the functionality of our main spreadsheet web UI by implementing features for flexible data manipulation and editing Own data architecture decisions and optimize performance for our web-based spreadsheet, supporting thousands of columns and millions of rows Collaborate closely with the design team to establish best practices for our component library and front-end data access patterns Take ownership of a core product area, such as our Rust data service for spreadsheet validations or our SDK suite enabling compatibility across React, Angular, and Vue Work directly with the CTO to understand customer needs and drive product decisions for an enhanced user experience Who You Are Essentials: 3+ years of experience building web products, proficient in AWS, React, Rust, Ruby, and PostgreSQL Comfortable navigating ambiguity and thriving in a fast-paced environment where wearing multiple hats is the norm Self-driven, fast learner capable of owning end-to-end projects Even Better If You: Have expertise with Redux, React-query, and Webpack Are proficient in Rust or another low-level language like C++ Have experience with Terraform and Docker Benefits Competitive compensation with meaningful stock options Comprehensive medical, dental, and vision plans Enjoy daily office lunches Participate in monthly team offsites and biannual company retreats Quarterly wellness budget 401k retirement plan Unlimited PTO and sick days Parental leave support Professional development budget Access to mentorship from engineering leaders",
        "url": "https://www.linkedin.com/jobs/view/3911845001"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3915650380,
        "company": "OpenAI",
        "title": "Software Engineer, Reliability",
        "created_on": 1720636352.678612,
        "description": "Join the engineering teams that bring OpenAI’s ideas safely to the world!! The Applied Engineering team works across research, engineering, product, and design to bring OpenAI’s technology to consumers and businesses. We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth. About The Role As OpenAI continues to grow, we are looking for experienced, problem-solving engineers to ensure our systems scale. Our success depends on our ability to quickly iterate on products while also ensuring that they are performant and reliable. You will work in a deeply iterative, collaborative, fast-paced environment to bring our technology to millions of users around the world, and ensure it’s delivered with safety and reliability in mind. Successful candidates will play a crucial role in ensuring the reliability, scalability, and performance of our systems as we continue to expand. As a reliability expert, you will be at the forefront of maintaining and enhancing the stability, scalability, and performance of our rapidly evolving infrastructure. You will work closely with cross-functional teams, including software engineers, product managers, and data scientists, to build and maintain resilient systems that can handle our growing user base and workload. In This Role, You Will Design and implement solutions to ensure the scalability of our infrastructure to meet rapidly increasing demands. Collaborate with development teams to make the systems they design and operate more reliable. Implement and manage monitoring systems to proactively identify issues and anomalies in our production environment. Develop and maintain service level objectives (SLOs) and service level indicators (SLIs) to measure and ensure system reliability. Implement fault-tolerant and resilient design patterns to minimize service disruptions. Build and maintain automation tools to streamline repetitive tasks and improve system reliability. Partner with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world. Participate in an on-call rotation to respond to critical incidents and ensure 24/7 system availability. You Might Thrive In This Role If You Enjoy seeking out and addressing bottlenecks and areas for performance improvement in our systems. Utilize Infrastructure as Code (IaC) principles to automate infrastructure provisioning and configuration management. Are experienced in collaborating with cross-functional teams to ensure that reliability and scalability are considered in the design and development of new features and services. Have a track record of accelerating engineering reliability by empowering your fellow engineers with excellent tooling and systems. Help create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group think. Have a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed. Own problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done. Qualifications Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience). Proven experience as an reliability engineer or a similar role in a fast-paced, rapidly scaling company. Strong proficiency in cloud infrastructure. Proficiency in programming/scripting languages. Experience with containerization technologies and container orchestration platforms like Kubernetes. Knowledge of IaC tools such as Terraform or CloudFormation. Excellent problem-solving and troubleshooting skills. Strong communication and collaboration skills. Experience with observability tools such as DataDog, Prometheus, Grafana, Splunk and ELK stack. Experience with microservices architecture and service mesh technologies. Knowledge of security best practices in cloud environments. This role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employees. About OpenAI OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity. We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status. For US Based Candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records. We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link. OpenAI Global Applicant Privacy Policy At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.",
        "url": "https://www.linkedin.com/jobs/view/3915650380"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Pasadena, CA",
        "job_id": 3907977425,
        "company": "Miso Robotics",
        "title": "Senior Software Engineer",
        "created_on": 1720636354.3644335,
        "description": "Our Company Miso Robotics is transforming the food industry, and making lives better. We've developed an AI-powered kitchen robot named Flippy which automates the most repetitive of kitchen tasks, such as operating a deep fryer. Flippy is fun to watch, but under the hood, he’s powered by a sophisticated AI platform – all driven by our proprietary deep learning experience and patented technologies. Miso is a well known first-mover in kitchen automation, AI, and robotics. The company has raised over $100 million from crowdfunding, which we believe makes it THE most successful crowdfunding story in history. It has successfully piloted its products with the most prominent global brands in food, and now it’s time for the company to partner with institutional capital and super-charge the commercialization of what we do. The challenge of bringing AI and robotics into commercial kitchens requires many disciplines to work together, and the composition of our teams at Miso reflects this multidisciplinary approach. We’re proud to have built a world-class team, and we’re looking for more exceptional people to join us. If you believe, like we do, that the future of the kitchen involves artificial intelligence and robots (HINT: It definitely does!), and if you want to count yourself among the handful of amazing people on the leading edge of creating them, then Miso Robotics may be the right place for you! Our Values We live with a TEAM mindset - we win together. We work relentlessly together to solve issues. We use polite and direct candor - ego has no place here. We operate with rigor - superb execution is a core skill. We are bought in, each of us is dedicated to the mission. Innovation is in our blood - we are intrepid. We think big and we’re here to make an impact. Benefits We Offer Company equity Flexible Vacation Comprehensive benefits 401K plan Accelerated growth opportunities Free snacks from our robot chefs The Role As a Senior Software Engineer, you will be responsible for designing, developing, and releasing our kitchen automation framework and cloud-connected infrastructure which power Flippy. You will perform hard-core coding, debugging, testing and troubleshooting throughout the development process that you will manage on your team. You will use your expertise in software engineering to own the design, prototype, and commercialization of core software. Additional Information: The pay range for this position is $140,000 - $170,000 + equity + benefits. Since the company is pre-revenue, we all view our equity as being a key driver of why we choose to work at Miso. Our salary ranges are determined by data from our industry peers, the level of responsibility, job-related skills required, training, education, experience, and the current stage of Miso’s growth. The range posted for this role represents a range that Miso Robotics, in good faith, believes it is willing to pay at the time of this posting. What You’ll Do Take ownership when developing, maintaining, improving, testing and releasing software. Create architectural diagrams which demonstrate flow of data through the system. Provide guidance and support within the software development organization. Design and develop computer software systems that are highly scalable and testable. Use best engineering judgment to iterate on code, refactoring repeatedly to improve our software generality and quality. Read our code and documentation to understand our existing architecture and practices. Reduce algorithmic complexity to improve performance. Adhere to and help improve our software development lifecycle (SDLC) processes. Create documentation to help identify and clarify architectural functional requirements. Participate in design review and provide helpful feedback. Create unit tests and system-level tests to verify code functionality. Coordinate with hardware engineers and other staff to forecast whether the design will be feasible under cost and time constraints. Must be available to work at our office in Pasadena. Experience working in a startup environment/fast-growing company is preferred. Requirements Bachelor’s Degree in Computer Science, Engineering, Mathematics or related field. Advanced degree preferred. 7+ years experience in developing general software frameworks in C++ and Python. Proven track record in delivering commercial software products through complete SDLCs within challenging timelines. Experience in full stack programming and event driven architectures. Experience developing, testing, and debugging with simulations and complex state machines (e.g., commercial video game development). Experience in leading a small development team. Expertise in Linux, CMake, Git, Docker and databases. Strong understanding of OOP, algorithms, and data structures, and software design patterns. Experience with practices for a SDLC, including agile development, coding standards, versioning, code reviews, and testing. Experience with Scrum Master responsibilities. Preferred Experience With Experience with the Robot Operating System (ROS) Experience with JIRA. Strong attention to detail, analytical skills and ability to learn at hyperspeed. Prolonged periods sitting at a desk and working on a computer.",
        "url": "https://www.linkedin.com/jobs/view/3907977425"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3603930366,
        "company": "TikTok",
        "title": "Senior Data Engineer, TikTok Multimedia",
        "created_on": 1720636356.7607062,
        "description": "Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices, including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. About the Team The Multimedia Data Platform team is responsible for optimizing app experience related to performance for TikTok users by providing data support. Working in collaboration with various teams throughout TikTok, the data platform team focuses on the creation and consumption of video content to provide comprehensive optimization solutions. This includes end-to-end optimization solutions such as client, video shooting, uploading, video playback, video delivery and player, etc. Responsibilities: Our Multimedia data platform team work closely with our product managers and data analysts by building state of the art streaming and batch data processing solution. The entire data pipeline is not only supporting the core business at TikTok -- short video, but also horizontal business across TikTok. In this role, you will see a direct link between your work, and the company's business success. You will have opportunities to deal with Petabyte-level data warehouse. Some of the world's most challenging technical and business problems are waiting for you to solve. - Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet quality needs. - Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational and engineering excellence best practices. - Analyze systems, define transformation requirements, design suitable data models and document the design/specifications. - Demonstrate passion for quality and productivity by using efficient development techniques, standards and guidelines. - Drive the design, to build, execute, and maintain automated tests and/or manage deep data profiling runs to ensure data products and pipelines meet expectations - Partner with analysts, engineers, subject matter experts, and product managers to apply TikTok Multimedia analytical and quality methods to satisfy client needs. - Participate in the growth of the Data Quality Excellence practice by sharing knowledge and lessons learned, continually improving best practices, and contributing to methods that will systematically advance workforce capabilities - Effectively communicate through technical documentation, commented code, and interactions with stakeholders and adjacent teams - Contribute to building a vibrant workplace, where teams can thrive, and model the organization’s positive, supportive culture of respect and excellence Qualifications - BS/BA in Technical Field, Computer Science or Mathematics. - 6+ years experience in the data warehouse space. - 6+ years experience in custom ETL design, implementation and maintenance. - 5+ years experience working with big data technologies (Hadoop, Hive, Spark, Clickhouse, etc.) . - 5+ years experience with schema design and dimensional data modeling. - 6+ years experience in writing SQL statements. -  Proficient in one of Programming languages (e.g., Python, Go, C++) -  Communication skills, including the ability to identify and communicate data driven insights. - Ability in managing and communicating data warehouse plans to internal clients. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at gprd.accommodations@tiktok.com. Job Information: 【For Pay Transparency】Compensation Description (annually) The base salary range for this position in the selected city is $194000 - $355000 annually. ​ Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units. ​ Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: ​ We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. ​ Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. ​ We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice. ​",
        "url": "https://www.linkedin.com/jobs/view/3603930366"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Roseville, CA",
        "job_id": 3811459809,
        "company": "GoodLeap",
        "title": "Senior Data Engineer",
        "created_on": 1720636358.8441448,
        "description": "About GoodLeap GoodLeap is a technology company delivering best-in-class financing and software products for sustainable solutions, from solar panels and batteries to energy-efficient HVAC, heat pumps, roofing, windows, and more. Over 1 million homeowners have benefited from our simple, fast, and frictionless technology that makes the adoption of these products more affordable, accessible, and easier to understand. Thousands of professionals deploying home efficiency and solar solutions rely on GoodLeap’s proprietary, AI-powered applications and developer tools to drive more transparent customer communication, deeper business intelligence, and streamlined payment and operations. Our platform has led to more than $27 billion in financing for sustainable solutions since 2018. GoodLeap is also proud to support our award-winning nonprofit, GivePower, which is building and deploying life-saving water and clean electricity systems, changing the lives of more than 1.6 million people across Africa, Asia, and South America. Position Summary The GoodLeap team is looking for a hands-on Data Engineer with a strong background in Data Analysis, Business Intelligence and development. The successful candidate is highly motivated individual with strong technical skills to create intuitive, secure and performant customer experiences. The ideal candidate is passionate about quality and has a keen eye for the details that delight our customers. The candidate in this role will be required to work closely with cross-functional teams to effectively coordinate the complex interdependencies inherent in the applications. We are looking for a hardworking and passionate engineer who wants to make a difference with the products they develop. Essential Job Duties & Responsibilities Implement data integrations across the organization as well as with business applications Participate in the design and development of projects, either independently or in a team Utilize agile software development lifecycle and DevOps principles Be the data stewards of the organization upholding quality and availability standards for our downstream consumers Be self-sufficient and fully own the responsibility of executing projects from inception to delivery Provide mentorship to team members including pair programming and skills development Participate in data design and architecture discussions, considering solutions in the context of the larger GoodLeap ecosystem Required Skills, Knowledge & Abilities 4-7 years of full-time Data Analysis and Development experience. Experience with an end to end reporting & analytics technology: data warehousing (SQL, NoSQL) to BI/Visualization (Tableau, PowerBI, Excel) Degree in Computer Science or related discipline Experience with DataBricks or other modern data warehouse Expertise with relational databases (including functional SQL/stored procedures) and non-relational databases (MongoDB, DynamoDB, Elastic Search) Experience with orchestrating data pipelines with modern tools such as Airflow Experience developing API's for third party data consumption Solid understanding of performance implications and scalability of code Experience with Amazon Web Services (IAM, Cognito, EC2, S3, RDS, Cloud Formation) Experience with messaging paradigms and serverless technologies (Lambda, SQS, SNS, SES) Experiences working with server-less applications on public clouds (e.g. AWS) Experience with large, complex codebases and know how to maintain them $137,000 - $160,000 a year In addition to the above salary, this role may be eligible for a bonus. Additional Information Regarding Job Duties And Job Descriptions Job duties include additional responsibilities as assigned by one's supervisor or other managers related to the position/department. This job description is meant to describe the general nature and level of work being performed; it is not intended to be construed as an exhaustive list of all responsibilities, duties and other skills required for the position. The Company reserves the right at any time with or without notice to alter or change job responsibilities, reassign or transfer job position or assign additional job responsibilities, subject to applicable law. The Company shall provide reasonable accommodations of known disabilities to enable a qualified applicant or employee to apply for employment, perform the essential functions of the job, or enjoy the benefits and privileges of employment as required by the law. If you are an extraordinary professional who thrives in a collaborative work culture and values a rewarding career, then we want to work with you! Apply today!",
        "url": "https://www.linkedin.com/jobs/view/3811459809"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3931749353,
        "company": "Checkpoint Technologies, LLC",
        "title": "Software Engineer",
        "created_on": 1720636360.623729,
        "description": "Job Description Checkpoint Technologies, LLC , located in San Jose, CA is the world’s leader in non-destructive optical probing for semiconductor failure analysis. Our tools combine advanced laser scanning (LSM) and photon emission (PEM) techniques with state of art optical resolution. We currently have an opening for a Software Engineer with experience in automated hardware systems. Local / Silicon Valley / Bay Area candidates only please Responsibilities: Create high quality semiconductor Failure Analysis tools by solving control equipment problems with mastery of Software Engineering skills. Develop and test software on Microsoft Windows Environment to control the operation of automated microscope and scanning systems. This includes the motion control for translation stages and various other position encoded hardware assemblies. Your duties also involve design and implementation of software for acquiring images from Framegrabber data and camera systems; software for camera control and manipulation of such images including the various image processing functions; developing a user-friendly GUI for microscope-based systems. Required skills: Work experience in using Visual Studio , mainly implementing the code in C# & C++ language to develop / debug Windows desktop application. Knowledge and experience of WPF and MVVM is desirable. Knowledge of real-time and multi-threading applications in PC controlled automated instruments is also beneficial. Preferred Experience: Basic understanding of Semiconductor devices, background in mathematics, physics, and software development experience in Microscope and Semiconductor probing tools will be a big plus. Knowledge of developing software in at least one or more of the following areas: Machine/Motion control Interfacing 3rd party Framegrabbers and Digitizer Image processing and visualization Salary Range: $130k - $175K If your background and interest match our requirements, we would like to hear from you! Please email your resume to: hr@checkpointtechnologies.com . Visit our website at www.checkpointtechnologies.com to learn more about Checkpoint Technologies and our products. Company Description Checkpoint Technologies, LLC manufactures automated Failure Analysis test equipment for the semiconductor industry. Checkpoint Technologies, LLC manufactures automated Failure Analysis test equipment for the semiconductor industry.",
        "url": "https://www.linkedin.com/jobs/view/3931749353"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3960947053,
        "company": "Google",
        "title": "Software Engineer III, Infrastructure, Google Cloud AI",
        "created_on": 1720636362.7116976,
        "description": "Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Kirkland, WA, USA; Sunnyvale, CA, USA . Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. 2 years of experience with developing large-scale infrastructure, distributed systems or networks, or experience with compute technologies, storage or hardware architecture. Preferred qualifications: Master's degree or PhD in Computer Science or related technical fields. 2 years of experience with performance, large scale systems data analysis, visualization tools, and/or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About The Job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions. Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3960947053"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3959146569,
        "company": "Google",
        "title": "Software Engineer III, Engineering Productivity, Chrome",
        "created_on": 1720636364.4360988,
        "description": "Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. 2 years of experience building developer tools that improve developer velocity, code quality and code health (e.g., compilers, automated releases, code design and testing, test automation frameworks). Preferred qualifications: Master's degree or PhD in Computer Science or related technical fields. 2 years of experience with performance, large scale systems data analysis, visualization tools, and/or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About The Job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions. Chrome is dedicated to building a better, more open web. We’re focused on making a better browser (on both desktop and mobile) to help users take advantage of all the web has to offer in a safe and secure way.Chrome is available across all major platforms — iOS, Android, Windows, Mac, Linux and Chrome OS. We also built Chrome as an open source project so the entire web ecosystem could benefit from the latest innovations in speed, simplicity and security. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3959146569"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3948663006,
        "company": "Walmart Global Tech",
        "title": "Senior Software Engineer (Back-End/Data) R-1838974",
        "created_on": 1720636366.1358526,
        "description": "At Walmart, we help people save money, so they can live better. This mission serves as the foundation for every decision we make and drives us to create the future of retail. We can’t do that without the best talent – talent that is innovative, curious, and driven to create exceptional experiences for our customers. Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on. You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives. About Data Ventures: Data Ventures exists to unlock the full value of Walmart’s data by developing and productizing B2B data initiatives that empower merchants and suppliers to make better, faster decisions for the business. As part of this transformation, we’re seeking entrepreneurial individuals to help drive data productization from concept to deployment. You’ll make an impact by: • Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function. • Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current analytics trends. • Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data. • Data Modeling: Analyses complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyses data-related system integration challenges and proposes appropriate solutions. • Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbook, and provides timely progress updates. • Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem. • Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Recommends new processes and ways of working. • Data Governance: Establishes, modifies, and documents data governance projects and recommendations. Implements data governance practices in partnership with business stakeholders and peers. Interprets company and regulatory policies on data. Educates others on data governance processes, practices, policies, and guidelines. Provides recommendations on needed updates or inputs into data governance policies, practices, or guidelines. • Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others. Supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationales. • Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders. Identifying business needs, determining, and carrying out necessary processes and practices. • Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application, ensuring compliance with them. • Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives. Applying suggestions for improving efficiency and cost effectiveness; and participating in and supporting community outreach events. • Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports. • Drives the execution of multiple business plans and projects by identifying customer and operational needs. Developing and communicating business plans and priorities, removing barriers and obstacles that impact performance. Providing resources, identifying performance standards, measuring progress, and adjusting performance accordingly. Developing contingency plans and demonstrating adaptability and supporting continuous learning. You’ll sweep us off our feet if: You have consistently high standards, your passion for quality is inherent in everything • Well versed with Hadoop, Spark, Cloud, Python/Scala and Java, Streaming, Kafka, Backend, J2EE. • You evangelize an extremely high standard of code quality, system reliability, and performance • You have a proven track record coding with at least one programming language (e.g., Scala, Python) • You’re experienced in one of cloud computing platforms (e.g., GCP, Azure) • You’re skilled in data modeling & data migration protocols • Experience with GCP, Datawarehousing, BI preferred • Experience with the integration tools like Automic, Airflow Mandatory Skills: Hadoop, Spark, Cloud, Python/Scala and Java, Streaming, Kafka, Backend, J2EE, Springboot API Desirable Skills GCP, Datawarehousing, BI Education/Qualification Bachelors or Masters in Engineering Benefits & Perks: Beyond competitive pay, you can receive incentive awards for your performance. Other great perks include stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Equal Opportunity Employer Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people. Who We Are? Join Walmart and your work could help over 275 million global customers live better every week. Yes, we are the Fortune #1 company. But you’ll quickly find we’re a company who wants you to feel comfortable bringing your whole self to work. A career at Walmart is where the world’s most complex challenges meet a kinder way of life. Our mission spreads far beyond the walls of our stores. Join us and you'll discover why we are a world leader in diversity and inclusion, sustainability, and community involvement. From day one, you’ll be empowered and equipped to do the best work of your life. careers.walmart.com Flexible, hybrid work We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives. The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.",
        "url": "https://www.linkedin.com/jobs/view/3948663006"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Los Angeles, CA",
        "job_id": 3965090544,
        "company": "Horizon Surgical Systems",
        "title": "Senior Database Engineer",
        "created_on": 1720636367.8138313,
        "description": "Open Position – Senior Database Engineer Horizon Surgical Systems Inc. Horizon Surgical Systems Inc. is revolutionizing the world of surgical ophthalmology by developing a novel, AI driven, and imaging-guided surgical robotic system. Horizon Surgical Systems Inc. aims to expand access to care, provide superior capabilities to the human surgeon, and enhance patient outcomes. Microsurgery in general and Ophthalmology are subfields of surgery for which the surgical outcomes can be significantly improved by robotic systems to allow superior dexterity, precision, accuracy, and visualization beyond the human surgeon's own capabilities. We are seeking highly motivated, and intellectually inquisitive individuals looking to make a positive impact on healthcare via the development of robotic technology. The core values of Horizon Surgical Systems Inc. are: Commitment to Excellence: We aim to deliver superior patient outcomes and surgeon experiences Passion for Creativity and Innovation: We are driven by new ideas and aim to push the boundaries of what's possible Teamwork and Camaraderie : We achieve our best when we collaborate and work together Welcoming of Critical Opinion: We are enriched by constructive criticism and support the best ideas Personal Accountability: We honor our commitments and take responsibility for our actions Horizon Surgical Systems Inc. offers: An opportunity to build autonomous surgical robotic systems driven by image guidance and AI technology for the future of affordable, high-quality healthcare. The opportunity to work alongside clinicians, engineers, and global leaders in cutting-edge AI, imaging, and robotics technology. Competitive compensation and an excellent company-paid benefits package. In your role as an engineer at Horizon Surgical Systems, you will design components and systems (hardware and software) as part of a complete product subjected to FDA regulations. Your design will be subject to safety and efficacy requirements. Required Qualifications and Abilities: Educational Background: Bachelor's degree in Computer Science. Experience: 5+ years of experience in software development for database systems and administration of large-scale database systems. PACS systems and DICOM format. AWS cloud platform. Osirix/Horos/Orthanc software platforms. Technical Skills: Programming Languages: Proficiency in languages like Python, JavaScript, C++, or others relevant to the stack. Knowledge of database technologies, SQL (e.g., PostgreSQL) and NoSQL (e.g., MongoDB). Operating Systems: Proficiency in working with Ubuntu and Windows. Soft Skills: Strong analytical, problem-solving, and organizational abilities. Good communication skills to collaborate with interdisciplinary teams. Responsibilities: System Architecture & Design: Collaborate with robotics and software engineers on developing scalable and robust databases, local and remote. Design, implement, and optimize backend components of our surgical robotics software. Integration with Robotic Systems: Develop and maintain APIs and services that interface with hardware, ensuring real-time and efficient communication. Implement data logging framework. Performance & Reliability: Ensure the robustness, reliability, and safety of the software, especially given the critical nature of surgical operations. Optimize applications for maximum performance, scalability, and user experience. Collaboration & Cross-functional Input: Participate in regular code reviews, stand-ups, and design sessions. This is an exciting opportunity to join a high-tech startup that is poised to revolutionize surgical robotics in ophthalmology.",
        "url": "https://www.linkedin.com/jobs/view/3965090544"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Menlo Park, CA",
        "job_id": 3967794436,
        "company": "Dice",
        "title": "Data Engineer",
        "created_on": 1720636369.3917003,
        "description": "Dice is the leading career destination for tech experts at every stage of their careers. Our client, Meta Platforms, Inc. (f/k/a Facebook, Inc.), is seeking the following. Apply via Dice today! Meta Platforms, Inc. (f/k/a Facebook, Inc.) has the following position in Menlo Park, CA: Data Engineer: Design, build, and launch data pipelines to move data across systems and build the next generation of data tools that generate business insights for a product. (ref. code REQ-2405-137996: $216,009/year - $235,400/year). Individual pay is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base salary only, and do not include bonus or equity or sales incentives, if applicable. In addition to base salary, Meta offers benefits. Learn more about benefits at Meta at this link: https://www.metacareers.com/facebook-life/benefits. For full information & to apply online, visit us at the following website http://www.metacareers.com/jobs & search using the ref code(s) above.",
        "url": "https://www.linkedin.com/jobs/view/3967794436"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3829178587,
        "company": "LinkedIn",
        "title": "Principal Staff Software Engineer, Distributed Database",
        "created_on": 1720636371.375547,
        "description": "LinkedIn is the world’s largest professional network, built to help members of all backgrounds and experiences achieve more in their careers. Our vision is to create economic opportunity for every member of the global workforce. Every day our members use our products to make connections, discover opportunities, build skills and gain insights. We believe amazing things happen when we work together in an environment where everyone feels a true sense of belonging, and that what matters most in a candidate is having the skills needed to succeed. It inspires us to invest in our talent and support career growth. Join us to challenge yourself with work that matters. At LinkedIn, we trust each other to do our best work where it works best for us and our teams. This role offers a hybrid work option, meaning you can both work from home and commute to a LinkedIn office, depending on what’s best for you and when it is important for your team to be together. Do you want to build and evolve the next generation Online Database solution for LinkedIn? It is a core building block of the entire LinkedIn stack. A distributed database solution that will seamlessly scale, serve 10s of millions of QPS, at ultra low latencies. We aspire for lights out operations, needing no human touch as the site scales to 10s of thousands of servers and beyond. Be the ambassador of the team in the Open Source community. We are a small team working on realizing a big vision. If you are looking for an opportunity to make a big impact, come join us in the Online Data Infrastructure Org. Responsibilities: -You will act as a domain expert for Online Databases at LinkedIn and own architectural decisions -You will partner with customers and leaders to create roadmaps, drive alignments and deliver products -You will lead and mentor teams, while actively building and operating large scale systems -You will define, enforce and continuously raise the bar for craftsmanship at LinkedIn, bringing in best practices from the industry -You will build a culture of innovation, with bias for execution Basic Qualifications: -BA/BS Degree or higher in Computer Science or related technical discipline, or equivalent practical experience -7+ years of industry experience in software design, development, and algorithm related solutions. -7+ years of experience programming in Java, C/C++, C#, Rust, Golang, Scala or similar languages -Hands on experience developing large-scale distributed systems, database, and storage -5+ years of experience as an architect or technical leadership position Preferred Qualifications: -MS or PhD in Computer Science or related technical discipline -12+ years experience in software design, development, and algorithm related solutions with at least 5 years of experience in a technical leadership position -12+ years experience in an object-oriented programming language such as Java, C/C++, C#, Rust, Golang, Scala -Knowledge of multi-threading, concurrency, and parallel processing technologies. -Experience with industry, open-source projects and/or academic research in large-data, parallel and distributed systems -Experience leading high-impact, cross-organization initiative Suggested Skills: -Distributed Systems -Technical Leadership -Databases -Storage -Open Source Development LinkedIn is committed to fair and equitable compensation practices. The pay range for this role is $207,000 to $340,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor. The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For more information, visit https://careers.linkedin.com/benefits. Equal Opportunity Statement LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information. LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful. If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation. Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to: -Documents in alternate formats or read aloud to you -Having interviews in an accessible location -Being accompanied by a service dog -Having a sign language interpreter present for the interview A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response. LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information. Pay Transparency Policy Statement As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency. Global Data Privacy Notice for Job Candidates This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",
        "url": "https://www.linkedin.com/jobs/view/3829178587"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3940970477,
        "company": "Google",
        "title": "Software Engineer III, Google Home",
        "created_on": 1720636375.66839,
        "description": "Minimum qualifications: Bachelor’s degree or equivalent practical experience. 2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting. 2 years of experience with data structures or algorithms in either an academic or industry setting. Preferred qualifications: Master's degree or PhD in Computer Science or related technical fields. 2 years of experience with performance, large scale systems data analysis, visualization tools, and/or debugging. Experience developing accessible technologies. Proficiency in code and system health, diagnosis and resolution, and software test engineering. About The Job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions. Google's mission is to organize the world's information and make it universally accessible and useful. Our Devices & Services team combines the best of Google AI, Software, and Hardware to create radically helpful experiences for users. We research, design, and develop new technologies and hardware to make our user's interaction with computing faster, seamless, and more powerful. Whether finding new ways to capture and sense the world around us, advancing form factors, or improving interaction methods, the Devices & Services team is making people's lives better through technology. The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3940970477"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Palo Alto, CA",
        "job_id": 3971554605,
        "company": "Snap Inc.",
        "title": "Software Engineer, Backend, 1+ Years of Experience",
        "created_on": 1720636377.277122,
        "description": "Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles. Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and it's AR glasses, Spectacles. Snap Engineering teams build fun and technically sophisticated products that reach hundreds of millions of Snapchatters around the world, every day. We’re deeply committed to the well-being of everyone in our global community, which is why our values are at the root of everything we do. We move fast, with precision, and always execute with privacy at the forefront. We’re looking for a Backend Engineer to join Snap Inc! What you’ll do: Design, implement, and operate our most critical and scalable services - ranging from user identity services, friend graph, and our core persistence layer Work across teams to understand product requirements, evaluate trade-offs, and deliver the solutions needed to build innovative products You evaluate, appropriately test, and debug your work, striving for high quality Advocate for and apply best practices when it comes to availability, scalability, operational excellence, and cost management Knowledge, Skills & Abilities: Experience with backend services or distributed systems Ability to independently execute on medium sized features, taking a few weeks and multiple PRs to complete Ability to understand the operational aspects of your system and may participate in incident or hotfix investigation and resolution Ability to collaborate and work well with others Proven track record of operating highly-available systems at significant scale Minimum Qualifications: BS/BA degree in a technical field such as Computer Science or equivalent years of experience 1+ years of software development experience Preferred Qualifications: Experience with Java, C++, and/or Python Experience with NoSQL solutions, Memcache/Redis, Kubernetes, or Google/AWS services Experience in at least one of the following areas: Large-scale microservices and distributed systems Cloud computing and storage systems Infrastructure and large-scale system design Security Networking and data storage Machine learning and natural language processing tools If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information. \"Default Together\" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week. At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success! Compensation In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future. Zone A (CA, WA, NYC): The base salary range for this position is $114,000-$171,000 annually. Zone B: The base salary range for this position is $108,000-$163,000 annually. Zone C: The base salary range for this position is $97,000-$145,000 annually. This position is eligible for equity in the form of RSUs.",
        "url": "https://www.linkedin.com/jobs/view/3971554605"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3911261770,
        "company": "ClassDojo",
        "title": "Staff Data Engineer",
        "created_on": 1720636379.0826309,
        "description": "ClassDojo's goal is to give every child on Earth an education they love. We started by building a powerful network for communication. ClassDojo’s flagship app is the #1 communication app connecting K-8 teachers, children, and families globally. Teachers use it to share what’s happening throughout the day through photos, videos, and messages that make parents feel like they’re there. It’s actively used in over 95% of US schools, reaching over 50 million children in 180 countries, with a team of just around 200 people [1]. We are now beginning to use this network to give kids the best learning experiences in the world, far beyond those a standard school can provide. We hire for talent density. Our team comprises the most talented, entrepreneurial, and innovative teammates from around the world, with experience in education and large scale consumer internet companies, including Instagram, Netflix, Dropbox, Stripe, Uber, Y Combinator, and more. We’re building a company where the most talented people want to work. We believe you’ll do the best work of your life here—and you’ll pioneer the future of education, too. What you’ll do: We are seeking a Data Platform engineer to join our Data and Engineering team. The ideal candidate will possess a passion for education and a strong foundation in all aspects of data engineering. In this pivotal role, you will be instrumental in making data accessible and actionable, facilitating informed decision-making throughout the company. You will be a match if: You have 7+ years experience with data / analytics engineering Collaboration and Communication: You have owned large-scale data projects that drove significant impact across the company You enjoy collaborating with and supporting others. You are an effective partner with engineering, data analysts, data scientists, and other business stakeholders. You have an ownership mindset and can make things happen Technical Excellence You're a strong independent contributor who's comfortable working across the data stack You've designed and built data platforms at previous organizations Your SQL, python, and infrastructure skills are top-notch. [1] Some more context: (If you are on LinkedIn, you will not be able to access the hyperlinks below. Once you click apply, you will be directed to our career website (if you are not on there already) and will be able to access the hyperlinks) ClassDojo's $125m Series D (Forbes) and Sam’s note about it. ClassDojo is one of Y Combinator’s Top 100 companies ClassDojo's Second Act Comes with First Profits (TechCrunch) and Sam's note about it. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. In accordance with the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. We are happy to accommodate any disabilities or special needs. We are a distributed company, so we hire regardless of location, as long as you are willing to have significant hours overlap with one of the Americas time zones. ClassDojo takes a number of factors into consideration when determining compensation, including geographic location, experience, and skillset. Salary ranges (United States): CA, WA, NY, NJ, CT states: $171,500 - $244,000 (USD) All other states in the US: $146,000 - $207,500 (USD)",
        "url": "https://www.linkedin.com/jobs/view/3911261770"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Burbank, CA",
        "job_id": 3966203186,
        "company": "RemoteWorker US",
        "title": "Sr. Data Engineer (Local/Remote)",
        "created_on": 1720636380.9967241,
        "description": "Job Description Job Description Sr. Data Engineer (Local/Remote) We have an immediate need for a contract Sr. Data Engineer to join a global mass media and entertainment conglomerate. Location: Burbank, CA. Remote but MUST be local to Burbank. This job expects to pay about $100 - 125 per hour plus benefits. What You Will Do: Contribute to maintaining, updating, and expanding existing Core Data platform data pipelines Build tools and services to support data discovery, lineage, governance, and privacy Collaborate with other software/data engineers and cross-functional teams Tech stack includes Airflow, Spark, Databricks, Delta Lake, and Snowflake Collaborate with product managers, architects, and others to drive the success of the Core Data platform Contribute to developing and documenting both internal and external standards and best practices for pipeline configurations, naming conventions, and more Ensure high operational efficiency and quality of the Core Data platform datasets to ensure our solutions meet SLAs and project reliability and accuracy to all our stakeholders Be an active participant and advocate of agile/scrum ceremonies to collaborate and improve processes Engage with and understand our customers, forming relationships that allow us to understand and prioritize both innovative new offerings and incremental platform improvements Maintain detailed documentation of work and changes to support data quality & data governance requirements What Gets You The Job: Bachelor’s Degree in Computer Science, Information Systems equivalent industry experience 5+ years of data engineering experience developing large data pipelines Proficiency in at least one major programming language (e.g. Python, Java, Scala) Strong SQL skills and ability to create queries to analyze complex datasets Hands-on production environment experience with distributed processing systems such as Spark Hands-on production experience with data pipeline orchestration systems such as Airflow for creating and maintaining data pipelines Experience with at least one major Massively Parallel Processing (MPP) or cloud database technology (Snowflake, Databricks, Big Query). Experience in developing APIs with GraphQL Deep Understanding of AWS or other cloud providers as well as infrastructure as code Familiarity with Data Modeling techniques and Data Warehousing standard methodologies and practices Strong algorithmic problem-solving expertise Irvine Technology Corporation (ITC) is a leading provider of technology and staffing solutions for IT, Security, Engineering, and Interactive Design disciplines servicing startups to enterprise clients, nationally. We pride ourselves in the ability to introduce you to our intimate network of business and technology leaders – bringing you opportunity coupled with personal growth, and professional development! Join us. Let us catapult your career! Irvine Technology Corporation provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Irvine Technology Corporation complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",
        "url": "https://www.linkedin.com/jobs/view/3966203186"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Burbank, CA",
        "job_id": 3965465365,
        "company": "The Walt Disney Company",
        "title": "Senior Software Engineer",
        "created_on": 1720636382.835401,
        "description": "We are looking for a Senior Software Engineer to sit in the Marketing Technology Unit, to create, experiment, and innovate with new media performance applications and automations. You'll get to understand the challenges of driving a highly data-driven and technically precise paid media strategy for a variety of titles and brand experiences, all while using the latest technologies and tooling in the data/tech space. If you're interested in working in a highly collaborative team environment embedded directly in a key business unit like this, please get in touch - we'd love to hear from you! What You Will Do Design and build tools that support the existing ad technology teams at The Walt Disney Studios—collectively known as “the performance marketing engine”; allow the teams to scale their work, increase the rate of delivery, and make space for future innovation Drive software engineering and architectural standards within the team, uphold standards and rigor around software development, testing, deployment, and documentation Create tooling and applications that can dynamically manage ad strategy configurations in a variety of social and digital platforms Collaborate with data scientists and product managers to rapidly iterate from prototypes to high-quality, production pipelines; contribute to emerging marketing analytics projects that address pressing business questions from collaborators in The Walt Disney Studios Marketing organization Implement quality controls, monitoring, and other safeguards to ensure optimizations are accurately and safely applied to in-flight ad campaigns and key business metrics are always presented accurately Adapt applications and workflows in the Performance Marketing Engine to changes arising from industry-wide events (such as the iOS14 update or cookie deprecation) as well as to more customary changes like standard updates to partner APIs. Collaborate with Studio Technology partners to ensure data fidelity and reenforce larger data initiatives at The Walt Disney Studios Implement paid media strategies at scale across multiple digital media channels Simplify media operations and improving operational efficiency Required Qualifications & Skills Bachelor’s and/or Master’s degree in Computer Science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience 5 years or more of related work experience Shown experience working on full-stack applications, with both back-end (e.g., FastAPI, Spring Boot) and front-end frameworks (e.g., React, Angular) Experience with data-rich environments and a familiarity with Python, Spark, and SQL Understanding of cloud compute (AWS, BigQuery) and modern dev ops practices; experience crafting and owning CI/CD pipelines for applications Knowledge of ad platforms including DMPs, Google Ads, Facebook/Instagram, Twitter, Innovid, LiveRamp and DSPs (Google DV360, Trade Desk, Verizon Media Group) Understanding of media and marketing, including how to define marketing/ media critical metrics (KPIs) Experience working effectively with data science teams Proven critical thinking and proven-solving skills Preferred Qualifications Understanding of cloud compute (AWS, BigQuery) and modern dev ops practices; experience crafting and owning CI/CD pipelines for applications Knowledge of Databricks and AWS Cloud Services Knowledge of digital ad serving, tracking and implementation Disability accommodation for employment applications The Walt Disney Company and its Affiliated Companies are Equal Employment Opportunity employers and welcome all job seekers including individuals with disabilities and veterans with disabilities. If you have a disability and believe you need a reasonable accommodation in order to search for a job opening or apply for a position, email Candidate.Accommodations@Disney.com with your request. This email address is not for general employment inquiries or correspondence. We will only respond to those requests that are related to the accessibility of the online application system due to a disability. The Walt Disney Company is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Disney champions a business environment where ideas and decisions from all people help us grow, innovate, create the best stories and be relevant in a constantly evolving world.",
        "url": "https://www.linkedin.com/jobs/view/3965465365"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Redwood City, CA",
        "job_id": 3952957335,
        "company": "Bear Robotics",
        "title": "Software Engineer (Multi-Robot)",
        "created_on": 1720636386.9799547,
        "description": "Job Title : Software Engineer (Multi-Robot) Department : Software Engineering FLSA : Exempt Job Summary : In this role, you’ll be working to scale up the systems that control how our robot interacts with the world. This team’s focus is on the robot's high-level behavior and coordination. This includes multi-robot coordination and our system for rapidly changing the robot's behavior for new tasks and use cases. You will be expected to wear many hats, working on core behaviors, communication, simulation infrastructure, and more. These systems work across multiple teams, so cross-team collaboration and an interest in learning new things are core parts of your role as an engineer here. Key Duties/Responsibilities : Build out infrastructure across our robot behavior, backend, network, and test systems Quickly learn and adapt your skills to new projects Own your projects from inception, to development, to deployment Collaborate across teams to make your projects succeed Performs other related duties as assigned. Supervisory Responsibilities : None. Required Skills/Abilities/Qualifications : Experience using C++ and Python Strong data structures and algorithms knowledge Past experience with ROS, or understanding of fundamental usage Preferred Skills/Abilities/Qualifications : Previous experience in startups or fast-paced engineering teams Experience with Behavior Trees Experience with 2D path planners/mobile robot navigation systems Master’s degree or PhD in CS or related field 5+ years industry experience Education/Experience : Bachelors in CS or related field 3+ years industry experience Physical Requirements : The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Prolonged periods of sitting/standing at a desk and working on a computer. The employee routinely is required to sit; stand, walk; talk and hear; use hands to keyboard Specific vision abilities required by this job include close vision, color vision, peripheral vision, depth perception, and ability to adjust focus. Ability to lift 30 lbs. Bear Robotics, Inc. is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, color, ancestry, national origin, religion or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other characteristics protected by state or federal law or local ordinance. The pay range for this position is $120K-$215K . Pay is dependent on the applicant's relevant experience.",
        "url": "https://www.linkedin.com/jobs/view/3952957335"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3939317124,
        "company": "Qventus, Inc",
        "title": "Senior Data Platform Engineer- Periop",
        "created_on": 1720636388.7218735,
        "description": "About Qventus: At Qventus, we’re transforming healthcare with real-time decision-making platforms that allow hospitals to focus on what matters most: patient care. Backed by leading venture capital, our innovative solutions harness the power of Machine Learning and Generative AI to empower nurses, doctors, and staff to anticipate and resolve issues before they arise. Join us in making healthcare smarter and more efficient for everyone. About the Role: Are you the next Qventoid? We’re looking for a driven and innovative Senior Data Platform Engineer to scale our solutions, focusing on our analytical and data science needs. The Data Platform team serves as the stewards for Qventus’ data, streaming hospital EMR to our core warehouses in real-time, and building out curated data layers to power our Healthcare AI & Analytical insights. This role is pivotal in ensuring Qventus data users have the tools they need to explore and empower the Qventus product at scale and cost, ultimately improving the lives of patients and doctors nationwide. As a Senior Data Platform Engineer, you will lead the design, development, and management across investments to the Perioperative solution and data pipelines. You will identify, monitor, and lead initiatives to ensure our pipelines remain scalable, reliable, and efficient in light of evolving data requirements of our solution. You will work closely with solution experts to design, iterate, and develop key pipelines to unlock new solution functionality, analytical insights, and machine learning features. You’ll translate product needs into high-quality schemas, pipelines, and scalability investments for our infrastructure and processes to support company expansion within the healthcare space, respecting HIPAA restrictions. You will be adept in partnering with cross-functional partners and data users to translate needs into technical solutions and leading the technical scoping, implementation, and general execution of improvements to our solutions and platform. You will be data curious and excited to have an impact on the team and in the company and to improve the quality of healthcare operations. As a Sr. Data Platform Engineer, you will: Lead scoping and execution of critical improvements to our platform to maintain overall system health and improve data observability in lieu of changing product needs and to optimize innovation velocity Manage the acquisition, assessment & integration of new datasets, collaborating closely with core data users to unpack the data and relevance to our core products and domain Translate product / analytical vision into highly functional data pipelines supporting high quality & highly trusted data products (incl. designing data structures, building and scheduling data transformation pipelines, improving transparency etc.). Provide expertise on the overall data engineering best practices, standards, architectural approaches and complex technical resolutions Support execution against key client implementations and team deliverables Key Responsibilities: Strong cross-functional communication - ability to break down complex technical components for technical and non-technical partners alike Robust aptitude for interpreting complex datasets, including the ability to discern underlying patterns, identify anomalies, and extract meaningful insights, demonstrating advanced data intuition and analytical skills. Excellence in quality data pipeline design, development, and optimization to create reliable, modular, secure data foundations for the organization's data delivery system from applications to analytics & ML Experience building, designing, and/or developing on a diverse set of modern data architecture designs and their relative capabilities and use cases (ex. Data Lake, Lakehouse, Lambda) Interest in mentoring and supporting new developers It's a Plus if You Have: 5+ years of experience designing, building, and operating cloud-based, highly available, observable, and scalable data platforms utilizing large, diverse data sets in production to meet ambiguous business needs Relevant industry certifications in a variety of Data Architecture services (SnowPro Advanced Architect, Azure Solutions Architect Expert, AWS Solutions Architect / Database, Databricks Data Engineer / Spark / Platform etc.) Experience designing and supporting multi-cloud architectures (particularly for ML / AI systems) Experience with data visualization tools and analytics technologies (Looker, Tableau, etc.) Degree in Computer Science, Engineering, or related field Experience working with healthcare data and HIPAA data protection Qventus is on a mission to take modern technologies and principles that have been proven in other industries — artificial intelligence, machine learning, behavioral science, and data science — and apply them to simplify healthcare operations. At Qventus, you will have the opportunity to work with an exceptional, mission-driven team, and the ability to directly impact the lives of patients. We’re inspired to work with healthcare leaders on our founding vision and unlock world-class medicine through world-class operations. The salary range for this role is $150,000 to $180,000. This salary represents the middle to the high end of market data across different geographies. We consider several factors when determining compensation, including location, experience, and the role’s responsibilities. Salary/OTE is just one component of Qventus’ total rewards package. Our benefits and perks currently include, but are not limited to: Competitive medical, dental and vision coverage with a 90% employer paid premiums for employees option Generous HSA contribution, when elected and participating in an eligible plan, up to $1,500 annual company contribution Employer provided (100% paid) Short Term and Long Term Disability insurance and Basic Life and AD&D insurance 100% paid Parental and Pregnancy Leave Monthly Wellness and Technology stipend up to $50 per month Ability to participate in the 401(k) plan Generous Stock Option awards We believe that diversity, equity, inclusion, and belonging are fundamental to improving healthcare and society, and that’s why we’re building a company that leads the way. We hold ourselves accountable to using fair hiring processes that mitigate the negative impacts of unconscious bias. We also work to ensure that people from underrepresented groups play meaningful roles on both sides of the interview table. We are an equal-opportunity employer and give all qualified applicants consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. This position does not provide visa sponsorship. Candidate information will be treated in accordance with our candidate privacy notice which can be found here: https://qventus.com/ccpa-privacy-notice/ Employment is contingent upon the satisfactory completion of our pre-employment background investigation and drug test.",
        "url": "https://www.linkedin.com/jobs/view/3939317124"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3969314738,
        "company": "CBC",
        "title": "Software Engineer (Java Backend)",
        "created_on": 1720636390.4194531,
        "description": "Job Title: Software Engineer (Java Backend) Location: Sunnyvale, CA (Hybrid) Description Top 3 Skills Needed or Required Backend: Java, Spring Framework, NodeJS Databases: Relational (MySQL), Cloud experience: GCP or Azure Cloud Platform (micro-services architectures (REST), event-based architecture (Kafka, JMS, etc.), Azure Storage, Kubernetes, Docker) Experience in managing web application and cloud with ability to debug at code level. Strong understanding of internals of web application along with database management. Ability to code/Script in one of the languages (Python or Java) and have working knowledge of SQL and Databases. Building monitoring tools and automation for managing the Production systems. Hands on experience in doing proofs of concepts based on business and technology needs and communicating Technology direction to top management. Experience with source code repositories (Git) and CI tools (Jenkins, Maven) and software provisioning and deployment automation tools. Exposure on Azure or Google Cloud and performing Orchestration, deployments & CI/CD using Ansible & Terraform. Exposure in deploying and managing Kubernetes and Container technologies like Docker is an added advantage. What are the day-to-day responsibilities? Design, build, and maintain high performant APIs and software services. Develop robust, maintainable, reusable code for managing functionality, configuration, deployment, monitoring, performance, scalability, availability, security, and alerting for software test, integration, and production environments. Develop, maintain, and enhance automated test cases and deployment procedures. Follow coding and design best practices developed by the teams and contribute towards their continuous improvement. Cloud BC Labs Inc is a digital transformation organization aimed at creating seamless solutions for clients to effectively manage their business operations. The company specializes in Business and Management Consulting, AI/ML, Data Analytics & Visualization, Cloud Data Warehouse Migration, Snowflake Implementation, Informatica Implementation & Upgrade, Staffing Services and Data Management Solutions",
        "url": "https://www.linkedin.com/jobs/view/3969314738"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Redwood City, CA",
        "job_id": 3869987497,
        "company": "Attain",
        "title": "Software Engineer, Platform",
        "created_on": 1720636392.098072,
        "description": "About Attain Built for consumers and companies, alike. In a world driven by data, we believe consumers and businesses can coexist. Our founders had a vision to empower consumers to leverage their greatest asset—their data—in exchange for modern financial services. Built with this vision in mind, our platform allows consumers to access savings tools, earned wages and rewards without cost or hidden fees. In exchange, they give permission to use their real-time data for research, insights and targeted advertising. At Attain, your contribution will help us build a more equitable and efficient data sharing ecosystem—whether helping consumers access modern financial services or businesses leverage data to achieve better outcomes. You'll have the opportunity to work directly with hands-on leaders and mission-driven individuals everyday. Attain Offices Hybrid Schedule: Redwood City, CA: Mondays (in-office) and choice of two days between Tues-Th Chicago, IL: Tues-Thursday (in-office) You'll be a great fit for the role if You are excited to build microservices using Rust You enjoy solving problems that aren't already solved in Stack Overflow You have a willingness to learn and teach in a collaborative environment You've been complimented on how well you participate in an open feedback environment What your day to day will look like Use new and modern technology to build new features and services across our microservice architecture Write thoughtful & quality code that is readable, testable, and easily maintainable Create data-driven and stable APIs for our mobile apps to consume Strive for excellent development practices and careful code architecture that is built around rapid releases Work cross-functionally with all mobile and backend engineers, and product teams to consistently release high-quality, customer-focused features Adhere to, and improve upon, our agile process through requirement documents, sprint retrospectives, and other regular cadence meetings Preferred Qualifications 6+ years of experience building backend services Experience in the financial tech industry is a plus Microservice or Service-oriented Architecture Experience using gRPC, protobuf, or GraphQL Experience with working with relational databases Experience with message queues or event streams Experience with cloud environments such as AWS, GCP, or Azure We're excited to hear from you. At Attain, we are passionate about finding people to continuously help us grow our organization. We encourage you to apply, even if your experience doesn't match every detail of the job description. If we don't see something that immediately fits, we will keep your resume on file for future opportunities.",
        "url": "https://www.linkedin.com/jobs/view/3869987497"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3948669246,
        "company": "Walmart Global Tech",
        "title": "Senior Software Engineer (Back-End/Data) R-1839006",
        "created_on": 1720636393.7210975,
        "description": "Job Description At Walmart, we help people save money, so they can live better. This mission serves as the foundation for every decision we make and drives us to create the future of retail. We can’t do that without the best talent – talent that is innovative, curious, and driven to create exceptional experiences for our customers. Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on. You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives. About Data Ventures: Data Ventures exists to unlock the full value of Walmart’s data by developing and productizing B2B data initiatives that empower merchants and suppliers to make better, faster decisions for the business. As part of this transformation, we’re seeking entrepreneurial individuals to help drive data productization from concept to deployment. You’ll make an impact by: Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function. Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current analytics trends. Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data. Data Modeling: Analyses complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyses data-related system integration challenges and proposes appropriate solutions. Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbook, and provides timely progress updates. Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem. Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Recommends new processes and ways of working. Data Governance: Establishes, modifies, and documents data governance projects and recommendations. Implements data governance practices in partnership with business stakeholders and peers. Interprets company and regulatory policies on data. Educates others on data governance processes, practices, policies, and guidelines. Provides recommendations on needed updates or inputs into data governance policies, practices, or guidelines. Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others. Supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationales. Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders. Identifying business needs, determining, and carrying out necessary processes and practices. Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application, ensuring compliance with them. Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives. Applying suggestions for improving efficiency and cost effectiveness; and participating in and supporting community outreach events. Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports. Drives the execution of multiple business plans and projects by identifying customer and operational needs. Developing and communicating business plans and priorities, removing barriers and obstacles that impact performance. Providing resources, identifying performance standards, measuring progress, and adjusting performance accordingly. Developing contingency plans and demonstrating adaptability and supporting continuous learning. You’ll sweep us off our feet if: You have consistently high standards, your passion for quality is inherent in everything Well versed with Hadoop, Spark, Cloud, Python/Scala and Java, Streaming, Kafka, Backend, J2EE. You evangelize an extremely high standard of code quality, system reliability, and performance You have a proven track record coding with at least one programming language (e.g., Scala, Python) You’re experienced in one of cloud computing platforms (e.g., GCP, Azure) You’re skilled in data modeling & data migration protocols Experience with GCP, Datawarehousing, BI preferred Experience with the integration tools like Automic, Airflow 6-10 years of experience Mandatory Skills Hadoop, Spark, Cloud, Python/Scala and Java, Streaming, Kafka, Backend, J2EE 6-10 years of experience. Desirable Skills GCP, Datawarehousing, BI Education/Qualification Bachelors or Masters in Engineering Who We Are? Join Walmart and your work could help over 275 million global customers live better every week. Yes, we are the Fortune #1 company. But you’ll quickly find we’re a company who wants you to feel comfortable bringing your whole self to work. A career at Walmart is where the world’s most complex challenges meet a kinder way of life. Our mission spreads far beyond the walls of our stores. Join us and you'll discover why we are a world leader in diversity and inclusion, sustainability, and community involvement. From day one, you’ll be empowered and equipped to do the best work of your life. careers.walmart.com Flexible, hybrid work: We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives. Benefits: Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Equal Opportunity Employer: Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people. The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.",
        "url": "https://www.linkedin.com/jobs/view/3948669246"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3860558581,
        "company": "LinkedIn",
        "title": "Sr. Staff Machine Learning Engineer - Foundational AI Technologies",
        "created_on": 1720636395.2717412,
        "description": "LinkedIn is the world’s largest professional network, built to help members of all backgrounds and experiences achieve more in their careers. Our vision is to create economic opportunity for every member of the global workforce. Every day our members use our products to make connections, discover opportunities, build skills and gain insights. We believe amazing things happen when we work together in an environment where everyone feels a true sense of belonging, and that what matters most in a candidate is having the skills needed to succeed. It inspires us to invest in our talent and support career growth. Join us to challenge yourself with work that matters. At LinkedIn, we trust each other to do our best work where it works best for us and our teams. This role offers both hybrid and remote work options. This means you can work from home and commute to a LinkedIn office, depending on what's best for you and when it is important for your team to be together, or you can work remotely from most locations within the country listed for this role. At LinkedIn, our Foundational AI Technologies (FAIT) organization stands as the innovation epicenter, addressing the fundamental AI challenges and the force behind LinkedIn's next-generation AI-driven member experiences. Our mission spans across the entire marketplace, leveraging our expertise in data curation, algorithm development, and robust infrastructure to spearhead AI innovations. We are dedicated to creating a transformative impact on all LinkedIn products, establishing the platform as a leader in the AI realm. As part of the FAIT team, you will be at the heart of member understanding that redefines the way LinkedIn understands and interacts with its entities across various marketplaces. You will be building the next generation member understanding framework based on Foundation Large Language models, specifically tailored to LinkedIn's data. While we build these models, we will be creating massive scale member data sets increasing leverage and efficiency via enabling downstream models. Our models will replace several legacy Member models. We will build new serving frameworks increasing the leverage and democratization of such key services. Our goal is to have state of the art availability and freshness of our data and services. As a Senior Staff Engineer in the Foundational AI Technologies team, you will act as the primary domain expert, and you will research, develop, build and ship cutting edge AI technologies. You are expected to provide technical leadership, and drive architectural decisions and implementation across the engineering organization. This individual will be a core member of LinkedIn’s Foundational AI Technologies team and will partner closely with other verticals in Data and AI, and Infrastructure teams. This is a rare opportunity to lead initiatives at the cutting-edge of Data and AI, which benefits every product and team at Linkedin and over 1 Billion members of the global workforce. Responsibilities Develop and implement the Foundation Large Language Model, customizing it to uniquely comprehend LinkedIn's diverse marketplace entities. Enhance the AI system's ability to understand LinkedIn members' interests, intents, and behaviors, using advanced LLM techniques. You will act as the primary domain expert to influence technology choices You will research and develop cutting edge AI technologies You will build and ship scalable software for AI tasks You will drive architectural decisions and implementation across the engineering organization You will provide technical leadership to cross-functional teams and drive alignment on technology strategy You will establish a culture that values diverse viewpoints while navigating complex decisions You will partner effectively with leads (ICs and managers) from other AI teams You will define the bar for quality and efficiency of software systems while balancing business impact, operational impact and cost benefits of design and architectural choices Lead by example to build a culture of craftsmanship and innovation Be an industry thought leader. Represent LinkedIn in relevant industry forums Basic Qualifications BA/BS Degree in Computer Science or related technical discipline or equivalent practical experience 5+ years of industry experience in software design, development, and algorithm related solutions 5+ years experience programming languages such as Java, C/C++, Python, etc. 2+ years in an architect or technical leadership position Preferred Qualifications PhD in Computer Science, Machine Learning, Statistics or related fields 8+ years of experience in AI/Data Science and Large Language Models Strong academic credentials with publications in top-tier journals and conferences Background in one or more of the following areas: deep learning, information retrieval, knowledge graph, natural language processing, optimization Experience in building large scale AI models and systems Experience in large language models and deep neural network solutions Demonstrated ability to work with peers in engineering across teams to set technical directions Excellent communication and presentation skills Suggested Skills: Deep learning Machine learning Large language models Data Science Information Retrieval LinkedIn is committed to fair and equitable compensation practices. The pay range for this role is $180,000 to $300,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor. The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For more information, visit https://careers.linkedin.com/benefits Equal Opportunity Statement LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information. LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful. If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation. Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to: -Documents in alternate formats or read aloud to you -Having interviews in an accessible location -Being accompanied by a service dog -Having a sign language interpreter present for the interview A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response. LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information. Pay Transparency Policy Statement As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency. Global Data Privacy Notice for Job Candidates This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",
        "url": "https://www.linkedin.com/jobs/view/3860558581"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3860725117,
        "company": "Padlet",
        "title": "Software Engineer – Frontend",
        "created_on": 1720636399.318961,
        "description": "Padlet is building software for a good education. A good education is one that inspires curiosity, creativity, and community. Our software enables that through visual content creation and collaboration in millions of classrooms worldwide. Think of an exceptional product, say the Dyson vacuum cleaner or WD40. What makes it exceptional is that not only does it perform its function well, it makes you feel great using it. It almost makes you want to have more problems so you could use the product more. We want Padlet to be an exceptional product. We are looking for Frontend Engineers to improve our web apps and delight a billion people. Responsibilities Building new features. E.g. creating beautiful slideshows in Padlet. Creating delight. E.g. through animations and micro UI. Making the web apps faster. E.g. reducing javascript payload. Improving how we work. E.g. improving our component library or tools we use to translate the web app into 40+ languages. Qualifications At some point in your life, someone has told you: “you write good code.” You know how to copy-paste code from Stack Overflow. Bonus: you have a good sense of humor. About Padlet Vision: Every child in the world will grow up with Mickey Mouse and Padlet. Product: We are making the default way of collecting and sharing thoughts on the Internet. People love the product. Impact: We have over 50 million active users making Padlet one of the most used apps on the planet. Our goal is to be THE the most used app on the planet. Money: We are venture backed AND profitable. We are built to last one hundred years. Badassery: We are 36 people (plus a baby crane that we've adopted but it doesn't really do much). That's over a million active users per employee. Some badass people work here. Tech stack Web: VueJS, Tailwind. Mobile apps: React Native (with Swift and Java where necessary.) Backend: Ruby (Rails), Typescript, Elixir (Phoenix), and Python. Storage: Postgres, Redis, Elasticsearch, Firestore, and Snowflake. Joys of engineering at Padlet We have very few meetings. We value keeping you in flow. A lot of people use Padlet. We have to solve interesting real-time collaboration problems. Our users are in over 200 countries, using all kinds of devices and connections, and speaking over 40 languages. We have to solve interesting internationalization problems. We like to craft delightful user experiences. They’re satisfying to build. We try to solve problems creatively instead of just throwing money at them. We are engineers! We thrive in constraints, not in the absence of them. We ship often. We value beautiful code. Sorrows of engineering at Padlet We grew pretty fast last year and our processes are still catching up. E.g. we don't have 100% code coverage yet. Our deployment process isn't as painless as it could be. This sometimes leads to spending time on things that aren't the most fun. We’re working on it! Our project management process could be better. This sometimes leads to re-speccing in the middle of development, getting in the way of programming flow. We’re working on it! Some people you‘d be working with Josh Hewitt: insists that wallabies and kangaroos are different animals, artificially inflating the biodiversity of his homeland. Is excellent at surgically improving an existing, complicated system. Colin Teahan: lives for one-liners. E.g: Colleague: “Wouldn’t it be funny if Iron Man were anemic?” Teahan: “It would be IRONIC.” Single-handedly wrote early versions of our iOS and Android apps. The office Our office is in the middle of Presidio, a beautiful national park. We’re 5 minutes from the beach, a walk we take often. The WiFi works outdoors. You can work sitting in a lawn overlooking the Golden Gate Bridge. The office itself is designed to be a space for all your interests and hobbies. We have a meditation room, game room, library, podcasting studio, art studio, kids room, and full makerspace with 3d printers, presses, laser cutters, sewing machines, and more. Benefits Top tier medical, dental, and vision insurance for you and your family. One Medical and Cue memberships for you and your family. 401(k) with matching. Commuter benefits. FSA. Good stock options. Catered lunches and dinners. 20 vacation days. Plus sickness and bereavement days for when life happens. All the gadgetry you need, including a new phone every year. Special time to join Because we're small, there's a lot of energy. And because we have tremendous traction, your first commit touches millions. This combination is rare and quite satisfying.",
        "url": "https://www.linkedin.com/jobs/view/3860725117"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Santa Clara, CA",
        "job_id": 3964390207,
        "company": "Steneral Consulting",
        "title": "Software Engineer-2 positions-locals",
        "created_on": 1720636400.8803625,
        "description": "Hybrid in Santa Clara, California. 2 openings. Contract through 03/31/2025 with extension. System/Software Technician 3 - Software Engineer Job Description Our R D domain covers broad range of future mobility systems, including autonomous driving, material informatics for innovative materials design and so on. As a Software Engineer, you will work on prototyping development of electric vehicle grid integration VGI , which can contribute smart charging of electric vehicles EVs for energy resiliency, CO2 reduction, electricity saving etc. We are exploring cutting edge new technologies to build future mobility businesses and energy systems. In our lab, you will be contributing to not only proof-of-concept, but also a commercial project. B. Job Responsibilities How You Will Be Contributing Work closely with other experts in Data Science, Optimization, Energy Systems, and Business to realize future service concepts of EVs. Develop and implement a cloud architecture for intelligent charging control of EVs. Perform evaluation of prototype, using EVs or real world big data of EVs. Communicate your work with stakeholders for business implementation. Author patents and reports. Bring your creativity to innovate future energy mobility systems. Job Knowledge and Skills: Qualifications For This Role Bachelors, Masters or above in Computer Science, or a related field with industry experience computer science. Foundation in programing in C/C++, Python, etc. 3+ years experience with cloud architecture Experience with AWS services e.g. EC2, Lambda, S3, Grafana Understanding of communication protocols e.g. MQTT, HTTP 5+ years experience with modern web technologies including: JavaScript/TypeScript, frameworks e.g. React, Vue.js , automated testing Experience with UI libraries Material UI, Bootstrap 1+ years experience with mobile development, preferably with cross-platform frameworks React Native, Flutter Experience with container systems e.g. Docker , deployment in a cloud architecture, and general Linux administration A strong passion for doing R D at the edge of human knowledge. Ways to stand out for the crowd: Experience with agile and ambition to lead agile teams Experience with development of cloud systems for decision making e.g. IoT device control, personalized recommendation Demonstrated ability to take initiative, create mockups, prototypes, and suggest application design without receiving detailed design specifications",
        "url": "https://www.linkedin.com/jobs/view/3964390207"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Sunnyvale, CA",
        "job_id": 3945991262,
        "company": "Chemix, Inc.",
        "title": "Senior Software Engineer",
        "created_on": 1720636402.525618,
        "description": "Chemix is seeking a highly-motivated software engineer to develop and expand our AI platform for autonomous battery materials discovery and optimization. Better batteries are a critical piece of humanity's transition to sustainable energy. As a software engineer at Chemix, you will contribute to our mission by building and maintaining the data pipelines that process our large experimental datasets. You'll make a fundamental contribution to developing the batteries that will power the electrification revolution in transportation and beyond. As an early employee at a fast-moving startup, we expect you to quickly and creatively solve all kinds of technical problems, including those beyond your core expertise. An ideal candidate is able to learn quickly, is eager to stretch their knowledge of software development and computational infrastructure, takes pride in the quality of their work, and wants to make a real impact in energy storage technologies for electric transportation. Responsibilities: Develop and maintain data pipelines and core infrastructure for various types of battery data and use cases Maintain and expand the codebases of our internal python libraries for battery data processing and machine learning Design and implement new computational infrastructure as needed to facilitate our daily computational workflows Introduce new software frameworks, workflows, and libraries, and development practices Interface with our machine learning research staff, data engineers, and battery engineers to understand our software and data use cases, and design and implement solutions Inform the optimization of the R&D process that generates our data Requirements Either: Degree in computer science and 2+ years of work experience, or Degree in the physical, chemical, or biological sciences, combined with 4+ years of work experience in software development Also: Extensive experience with the python data stack, e.g. pandas, numpy, Dask Experience with cloud web services (AWS, Google Cloud, Azure, etc.), databases, and Docker Experience with software dev-ops: git, testing, CI/CD Clear communication and good people skills Strong organization and ability to manage parallel projects Nice to have: Experience with workflow orchestration tools, e.g. Airflow, Prefect, Luigi Previous experience with batteries and battery data Familiarity with experimental chemistry/materials science Benefits Stock Option Plan Health Care Plan (Medical, Dental & Vision) Retirement Plan (401k) Paid Time Off (Vacation, Sick & Public Holidays) Family Leave (Maternity, Paternity)",
        "url": "https://www.linkedin.com/jobs/view/3945991262"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Diego, CA",
        "job_id": 3533314473,
        "company": "Tillster",
        "title": "Senior Software Engineer - Back End (#03222023MA)",
        "created_on": 1720636404.2713573,
        "description": "Senior Software Engineer - Back End ( #03222023MA) San Diego, CA Salary: $155,397.00 What You’ll Do Work with a team of local and globally-distributed Software Engineers/Developers, Product Management, Quality Assurance, and other professionals to design, develop and deliver software application products built to meet requirements for company’s mobile and online food ordering and e-commerce payment solutions, which allow customers to place and pay for orders at restaurants. Implement and extend company’s next generation eCommerce platform. Work with event-based architecture patterns. Leverage cloud technologies such as Amazon Web Services or Google Cloud. Implement continuous integration and deployment pipelines using GitHub Actions. Implement APIs and services using cutting edge technologies such as Quarkus, Amazon Lambda and DynamoDB. Extending APIs and service using industry standard frameworks like Spring Boot. Play a lead role in establishing a robust, scalable, and flexible technology/technical architecture and make recommendations for improvements. Work in a variety of software disciplines, and work with Business Analysts and Software Engineers/Developers to refine product requirements and deliver products built to these requirements. Provide extensive hands-on technological and technical expertise coupled with ingenuity and leadership skills to assist the team achieve the desired technology and business outcomes. Communicate software application design and implementation details effectively to teammates and internal customers, both verbally and in writing. Estimate and size development efforts to assist with planning, then deliver working software on schedule. Utilize experience developing technical solutions to best solve technological and business requirements. Support company-wide software engineering/development standards and optimize applications for maximum speed, scalability, dependability, and ease of development. Provide expert level of software programming/development, design, analysis, and mentoring. Be responsible for iteratively and incrementally improving both products and processes. Other duties as directed or required. Skills You’ll Bring MINIMUM EDUCATION: Master’s degree in Computer Science or related field of study. MINIMUM EXPERIENCE: Two (2) years’ relevant experience analyzing, designing and writing software code for web and mobile software applications using cloud technologies. The Tech Stack Amazon Web Services or Google Cloud; implementing continuous integration and deployment pipelines using GitHub; implementing APIs and services; and interacting with Core Java; Spring Frameworks; REST Web API; Unix/Linux Shell Scripting; AWS – S3 bucket, SNS, SQS, Lambda expression; Relational Databases with Hibernate; JMS; Postman; Soap UI; JIRA; GIT; JSON; XML/XSL; SSL; Web Application Security – all within an AGILE/SCRUM methodology. ALTERNATE EDUCATION: Bachelor’s degree in Computer Science or related field of study. ALTERNATE EXPERIENCE: Five (5) years’ relevant experience analyzing, designing and writing software code for web and mobile software applications using cloud technologies. The Tech Stack Amazon Web Services or Google Cloud; implementing continuous integration and deployment pipelines using GitHub; implementing APIs and services; and interacting with Core Java; Spring Frameworks; REST Web API; Unix/Linux Shell Scripting; AWS – S3 bucket, SNS, SQS, Lambda expression; Relational Databases with Hibernate; JMS; Postman; Soap UI; JIRA; GIT; JSON; XML/XSL; SSL; Web Application Security – all within an AGILE/SCRUM methodology. The Interview Process SPECIAL REQUIREMENTS: Must pass technical interview Please apply on company website: www.tillster.com/careers . Must put job code #03222023MA on resume. About Tillster Tillster is the global leader in digital ordering and customer engagement solutions. For over a decade we’ve developed revolutionary self-service, ordering and payments solutions – for mobile, tablet, online, kiosk, call center, and more – creating personalized interactions based on consumer preferences, language, and currency. Our platform is compatible with 15+ unique POS systems, representing over 90% coverage in multi-unit restaurants. We offer one platform; one scalable, enterprise class solution – to create world-class digital engagement solutions. For more information, check us out at http://www.tillster.com . Tillster is proudly an Equal Opportunity Employer Local Candidates Strongly Preferred Relocation Assistance Considered No visa sponsorship Principals only – no Agencies or calls please",
        "url": "https://www.linkedin.com/jobs/view/3533314473"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Jose, CA",
        "job_id": 3936820658,
        "company": "ByteDance",
        "title": "Backend Software Engineer - CapCut - San Jose",
        "created_on": 1720636406.0293632,
        "description": "【For Pay Transparency】Compensation Description (annually)The base salary range for this position in the selected city is $145000 - $250000 annually.​ Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.​ Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: ​ We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. ​ Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. ​ We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice. Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok and Helo as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content. Why Join Us Creation is the core of ByteDance's purpose. Our products are built to help imaginations thrive. This is doubly true of the teams that make our innovations possible. Together, we inspire creativity and enrich life - a mission we aim towards achieving every day. To us, every challenge, no matter how ambiguous, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At ByteDance, we create together and grow together. That's how we drive impact - for ourselves, our company, and the users we serve. Join us. How we become the NO.1 video editing app CapCut is an all-in-one video editing solution that helps you create incredible videos. With the mission of making content creation easier and more engaging, CapCut was first launched on mobile platforms in April 2020. In less than a year, CapCut was released in Brazil, US, Indonesia, Japan and several other countries*. To better serve the diverse needs, CapCut released its online and PC version in 2022. Starting in 2023, CapCut has continued to invest in AI technology to provide product features that are more accessible and easier to use. As of today, CapCut's global monthly active users have exceeded 500 million. It has remained at the top of the download list in several app stores. *CapCut is currently available in over 170 countries/regions. We are an incredible young team with passion. We enjoy learning new things and taking on challenges. Team culture here is open and inclusive. Everyone can make things happen, good ideas will always win. Today, we are continuously increasing investment in AI technology to make content creation much easier for everyone, and we always take the protection of user privacy and data security very seriously. Therefore, we set up an engineer team with high talent density, mainly focusing on AI technology and Privacy&Security in CapCut. Responsibilities - Develop efficient, highly scalable and secured services and tools to build/integrate Security & Privacy systems for CapCut. - Optimize backend systems and services for data security, modularity, computational efficiency and scalability. - Deliver best-in-class engineering excellence practices across all product engineering disciplines. Minimum Qualifications - Bachelors or higher degree in Computer Science or related technical discipline. - 2+ years experience developing highly scalable backend services and systems using at least one of Golang/Java/Rust/C++. Fresh graduates meeting the qualifications are also encouraged to apply. - Deep understanding of data structure, algorithm design and analysis, networking, data security and highly scalable systems design. - In-depth knowledge of common databases and messaging frameworks like MySQL/Redis/Kafka etc. - Strong software programming capabilities, exhibits good code design and coding style. - Good collaborator and team player, comfortable working in a fast moving, culturally diverse and globally distributed team environment. Preferred Qualifications - Experience of privacy and security technology is a big plus. ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. ByteDance Inc. is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2",
        "url": "https://www.linkedin.com/jobs/view/3936820658"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3812440891,
        "company": "Zanbato",
        "title": "Full Stack Software Engineer",
        "created_on": 1720636407.6868274,
        "description": "Who We Are At Zanbato, we believe it should be just as easy to trade in private companies as it is in public companies. Zanbato has created and operates ZX, a leading trading platform for private company stock. By creating trust and ease of use in an online platform, we can transform the technology and startup landscape for everyone, from individual employees to the largest financial institutions. Our team at Zanbato is making this transformation happen. Day-to-day you can catch us taking work breaks to play basketball or drip-brew fresh coffee. We enjoy catered lunches daily, chatting about the latest Netflix show or where to go hiking next weekend. Team events are a big deal at Zanbato, including going out to dinner, having game nights, and our annual ski trip in Tahoe. Just as important is having a work-life balance, we work our best when we’re well rested, so take advantage of our flexible vacation time. Responsibilities/What You Will Do Write quality, performant, well-tested code in Python/Django and ES6/React Participate in the entire product development lifecycle from ideation through evaluation Take ownership and head your own project in your first 8 weeks, coordinating with other engineers and design team Work autonomously and set your timeline, architecture, and task breakdown Explore and learn any technology or approach to get the job done Collaborate with the other engineers over code review and architecture discussion Compensation, Benefits, And Perks We offer competitive base salaries along with the following benefits and perks: $110,000 - $140,000 base salary (DOE) Medical, dental, and vision coverage Company stock options 401k Flexible vacation time 12 weeks paid parental leave Professional development stipend for continuing education Catered lunch daily Snack and beverages in-office Weekly 10% time to devote to a new skill or side project Diversity and Inclusion at Zanbato Zanbato provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity, or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",
        "url": "https://www.linkedin.com/jobs/view/3812440891"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3945530596,
        "company": "Firstup",
        "title": "Lead Software Engineer (Data & Microservices) - (Remote - US)",
        "created_on": 1720636409.494989,
        "description": "Who We Are At Firstup, our mission is to improve the employee experience at every moment that matters, large and small. As the communication pipeline for the world's workforce, we now serve 40 of the Fortune 100 companies, reaching and connecting more than 17 million employees daily. Our employees are experts in the employee experience, workforce communications and technology. Joining Firstup means joining a movement to make work better for every worker. As the world’s first intelligent communication platform, Firstup meaningfully engages employees at every moment from hire to retire, and delivers engagement insights to help companies support, promote and retain their talent. Our movement has taken root and is evident in our world-class customer base. Now we need your help. Ready to make a difference in the world? Our Values Every employee is an owner with responsibility and credit for our progress. Leadership is in our build and we see change as a catalyst for improvement. We win as a team, committed to help our coworkers and customers thrive. Role Overview As Lead Software Engineer you will be responsible for delivering innovative solutions and services while constantly improving our approach to architecture, scale, availability and fault-tolerance. You will partner with others across the company in shared code bases and contribute directly to other services when needed. Responsibilities Guide and mentor, the team in building scalable SaaS applications with a focus on deliverables for quality, value, and speed Foster a collaborative environment and mentor the team through technical challenges and career growth Direct the team’s technical and architectural perspective with a focus on the long and short-term roadmap goals Continuously gain knowledge about technologies that could help improve and scale the current technology stack of the domain Oversee the daily operations of the team to make sure they are on track and unblocked Take ownership for the team's technical decisions and consults other technical leads, when necessary, with focus on amplifying impact from each team member Maintain expertise in technology stack and product knowledge Requirements Bachelor’s degree in computer science or related field of study, or commensurate experience required Over 8 years of experience building reliable and high performance large distributed systems with an emphasis on streaming and data pipelines Hands-on experience building distributed platforms on AWS or GCP Proficient in languages used on our platform, including NodeJS, Python and Java Hands-on experience with streaming platforms such as Kafka and Spark Skilled in building and maintaining large data processing platforms Experience in building microservices platforms and RESTful APIs Experienced with scheduling tools such as Airflow, Dagster, StepFunctions Experience with data modeling and warehousing best practices Familiarity with enterprise BI tools such as Tableau, Metabase or Looker and integrating those into SaaS platforms Why Firstup? Because you care - about people, the work you do, and the connections you make. Work is such a large part of life; it only makes sense to make it awesome. If you want to engage brilliant minds in a high-growth and inclusive environment where ideas are rewarded regardless of who they come from, join us. This is a rapidly changing space so if you thrive on ambiguity, are hungry for a challenge, and have the guts to speak your mind, you could be a perfect fit. We offer an excellent PTO program, great health benefits, a casual and friendly environment, remote work, and a leadership team who truly believes in your growth – both personally and professionally. Firstup is committed to providing equal employment opportunities to all applicants for employment and to all employees, without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, protected disability, veteran status, or any other protected status in accordance with applicable federal, state or local laws. Firstup expects the base salary for this role to be between $170,000-$200,000. The starting rate of pay may vary based on factors including, but not limited to, position offered, location, education, training, and/or experience.",
        "url": "https://www.linkedin.com/jobs/view/3945530596"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Point Reyes Station, CA",
        "job_id": 3968622426,
        "company": "Auria Space",
        "title": "Software Engineer",
        "created_on": 1720636411.193477,
        "description": "Auria is looking for a Software Engineer with 1-3 years of experience to join our amazing team in Pt. Mugu, CA ! The Space Force DELTA 8/10 SOPS is responsible for operating, managing and maintaining assigned DoD satellites and network systems providing reliable communication services to the joint warfighter. The purpose of this effort is to provide specialized satellite software services to include the software maintenance, enhancement, development, and integration of software components, drivers, interfaces, and tools for: Integrated Satellite Control Systems (ISCS), satellite telemetry, tracking, & commanding (TT&C), and ancillary supporting systems. Salary range - $85,000-$95,000 DOE. Responsibilities: Will work both independently and as part of a small team under the supervision of a designated lead engineer Will provide programming support, code reviews, prepare test plans, perform unit testing, and documenting results Will serve in various roles (CM, unit test, coder) during significant programing events and / or assignments Will participate, then schedule to run a script based system check out procedure. Report anomalous findings, conditions, situations to a designated lead engineer Will participate, then schedule to perform system log file reviews. Interpret log file information. Report anomalous findings, conditions, situations to a designated lead engineer Under supervision from a designated lead engineer, then independently, will perform source code changes to script based procedures, C/C++ source code, JAVA code, Visual Basic Code, Python scripts, Makefiles, PERL scripts, Bash and other scripting languages and file types Under supervision from a designated lead engineer, study, analyze and communicate proposed software changes and courses of action Must be able to communicate clearly with operational end-users, technical community, customers, and coworkers Will use customers ClearCase configuration management tool and customer processes for source code maintenance Will use customers ClearQuest Trouble Ticket System (EAERS) and customer processes for documenting software and system changes Participate in customers trouble ticket (EAERS) and Configuration Control Board (CCB) meetings as a technical participant as needed Assist preparation and reviews of customer software Version Description Documents (VDDs). Review other system VDD’s, Technical Manuals, Interface Control Documents as necessary for informational purposes and when designing software interfaces Requirements: Education – BS in Computer Science or STEM Years of experience – 1-3 years Security Clearance Level - Secret Preferred Skills : Experienced in command line UNIX or Linux, sed, grep, awk, vi Basic networking experience and terminology Experience with MySql, MSAccess, Visual Studio 2019 IDE Experience with C/C++ programming, Python, Makefiles, Bash Scripting Experience with a source code configuration management tool (Git, ClearCase) Technical writing, interpretation of requirements Integrated Development Environments MS Word, MS Excel, MS PowerPoint, MS Outlook Understanding of software lifecycle Understanding of external libraries used when building software products Team player, Problem-solver, Excellent time-management, Strong communications skills, Ability to work autonomously About Auria Auria is a provider of solutions and software in support of complex Space, National Security, and Cyber missions of federal, international, and commercial customers. Headquartered in Colorado Springs, CO and with operations in Boulder, CO, Washington, DC, Huntsville, AL, Albuquerque, NM, Ogden, UT, and San Diego, CA, our success is built on the excellence of diverse teams advancing innovative systems and operational software to strengthen our customers’ superiority in Space. With a distinguished track record and a spirit of relentless pursuit, we set the pace for progress and execute every mission with the utmost precision. When you join Auria as a full-time employee, you get many benefits which include: Generous PTO package with yearly tenure increases Flex time policy providing you the flexibility needed 11 Company-Paid Holidays per year Up to 4% match on 401(k) employee contributions, employer and employee contributions immediately vested Tuition and Certification Fee Assistance Low-cost medical plans that include company-sponsored HSA No-cost life insurance Employee Assistance Program (EAP) And much more! Auria is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, marital status, national origin, age, veteran status, disability, or any other protected class.",
        "url": "https://www.linkedin.com/jobs/view/3968622426"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Palo Alto, CA",
        "job_id": 3945048075,
        "company": "Niantic, Inc.",
        "title": "Software Engineer, Machine Learning",
        "created_on": 1720636413.0582335,
        "description": "Niantic’s Engineering Team seeks a Software Engineer passionate about Machine Learning Engineering to enhance Niantic Products through using generative AI technologies. Our team powers capabilities across our games, geo-based, and AR platforms through productionizing large scale models. Your work will directly help grow the features in our games as well as the capabilities of our technology platforms. Niantic Engineering leads the advancement of AR and other immersive technologies while creating engaging apps for a user base in the billions. Responsibilities Implement and maintain scalable infrastructure solutions for the deployment of generative AI models. Develop automation tools and processes to streamline model evaluation and deployment workflows. Optimize infrastructure performance to ensure efficient resource utilization and minimize latency in model inference. Implement and maintain monitoring and alerting systems to ensure the reliability and availability of AI infrastructure components. Collaborate with cross-functional teams to understand requirements and design infrastructure solutions that meet business objectives. Stay up-to-date with the latest advancements in AI infrastructure technologies and best practices, and evaluate their applicability to the organization's needs. Participate in code reviews, design discussions, and architecture planning sessions to maintain high-quality standards in software development practices. Troubleshoot and resolve issues related to AI infrastructure, working closely with stakeholders to identify root causes and implement solutions. Collaborate with cross-functional team members and stakeholders, including regular and reliable attendance and participation in meetings. Required in-office 5 days a week. Qualifications You have at least a Bachelor’s degree in Computer Science, Engineering, or a related field. 4+ years of experience in software development, and with data structures/algorithms. 2+ years of experience in designing, building, and optimizing distributed systems or cloud-based infrastructure. Strong proficiency in programming languages such as Python, Javascript, and C++ with experience in developing production-quality code. Ability to work in a fast-paced hybrid environment and handle stress appropriately and/or ability to solve practical problems and be sufficiently adaptable to handle dynamic situations with little advance notice. Experience working on cross-functional teams with ability to communicate effectively through written and verbal communications, including synchronous interactions with others. Plus If... You have experience developing and maintaining machine learning platforms. You have experience with machine learning/AI in a cloud native environment. You have experience in Generative AI infrastructure. You have experience with DevOps practices, continuous integration/continuous deployment (CI/CD) pipelines, and infrastructure as code (IaC) tools (e.g., Terraform, Ansible) is a plus. You have strong communication skills with the ability to convey complex technical concepts to both technical and non-technical stakeholders. The total compensation package for this position includes a new hire offer base salary range of $149,400 - $194,000 + bonus + equity + benefits. Individual pay within this salary range is determined by work location and additional factors, including assessed job-related skills, experience, and relevant education or training. Your recruiter can answer any questions about new hire total compensation during the hiring process. An overview of benefit offerings for your location can be found on the careers page. Join the Niantic team! Niantic's global-scale augmented reality platform and digital map powers spatial computing experiences in the real world. Incubated out of the Maps team at Google, Niantic first created Ingress and then Pokémon GO, a cultural phenomenon and hit game played by tens of millions of people each month. Niantic’s Lightship platform, which powers Pokémon GO, also supports the company's other games including Pikmin Bloom, Peridot and Monster Hunter Now. Developers use Niantic’s platform to build their own AR applications and experiences, either with the Lightship Platform or directly through the web with 8th Wall. We believe that cultivating a workplace where our people are supported and included is essential to creating great products our community will love. Our mission emphasizes seeking and hiring diverse voices, including those who are traditionally underrepresented in the technology industry, and we consider this to be one of the most important values we hold close. We're a hard-working, fun, and exciting group who value intellectual curiosity and a passion for problem-solving! We have growing offices located in San Francisco, Sunnyvale, Palo Alto, Bellevue, Kansas, London, Tokyo, Hamburg, Hyderabad, and Zurich.",
        "url": "https://www.linkedin.com/jobs/view/3945048075"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3648714954,
        "company": "rideOS (acquired by Gopuff)",
        "title": "Software Engineer - Optimization",
        "created_on": 1720636414.748817,
        "description": "Who We Are rideOS is a wholly owned and operated subsidiary of Gopuff. We are responsible for driving innovation in Gopuff’s delivery optimization, fulfillment center operations, and other strategic initiatives. Collectively, our goal is to accelerate Gopuff’s mission to make daily life effortless. As pioneers and industry-leaders of the \"Instant Needs\" category, Gopuff is the go-to solution for consumer’s immediate everyday needs, aiming to complete all deliveries within 30 minutes. Gopuff makes delivering grocery, home, baby & pet essentials and over-the-counter medications easy and affordable for everyone. The Opportunity We are looking for a backend engineer who is passionate about developing technology for the next generation of transport. You will be collaborating with other engineers to design and build advanced, scalable mapping and transportation-related applications. You will build scalable services that support matching thousands of vehicles with hundreds of thousands of orders using discrete optimization to find the best solution that satisfies a set of constraints. As part of a high-growth startup, you will also have the opportunity to collaborate closely with company product leaders, partners, and non-engineering parts of the business. Every member of our organization plays a critical role in shaping the future of our services, team, and culture. What We Are Looking For 2+ years of industry experience Proficiency in Java or C++ or a similar language Strong algorithms fundamentals Passion for mobility or next generation transport A strong desire to learn, collaborate and mentorLocated or willing to commute to San Francisco Nice To Have Experience using gRPC and protocol buffers Experience with Docker and Kubernetes Experience with Discrete Optimization techniques Experience in the mobility, ride-sharing, or autonomous driving industry Experience building services and applications at high throughput Experience building batch and real-time data pipelines We Provide Equity in a well-funded ($3.4b), rapidly-growing startup (Gopuff) Top tier medical, dental, and vision insuranceLife insurance policy Flexible PTO - We trust employees to manage their time off, most people take around 20 vacation days per year Flexible working from home policy, especially for folks with families or commuters Lunch provided 3 days a week Tax savings from 401K, FSA Investment in safety - we provide transport home when you work late Investment in health and wellness - we reimburse $80 per month for fitness/gym memberships At rideOS, we place a strong emphasis on our culture, diversity, and employee wellbeing. We are proud to maintain our small startup hustle while also enjoying the benefits and excitement of Gopuff’s hypergrowth. Come join us to be a part of accelerating our collective mission. rideOS is an e-verified company.",
        "url": "https://www.linkedin.com/jobs/view/3648714954"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Santa Clara, CA",
        "job_id": 3968660556,
        "company": "NVIDIA",
        "title": "Senior Backend Engineer, Web and Data Infrastructure",
        "created_on": 1720636416.6183376,
        "description": "NVIDIA has continuously reinvented itself over two decades. Our invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing. NVIDIA is a “learning machine” that constantly evolves by adapting to new opportunities that are hard to resolve, that only we can seek, and that matter to the world. This is our life’s work, to amplify human inventiveness and intelligence. We are looking for inquisitive and driven full-time software engineers with a strong interest in building high-quality, long-lasting systems. The VLSI Productivity and Infrastructure team supports hundreds of chip design engineers by building internal tools and platforms that supercharge their everyday work. From build automation to machine learning, databases to web applications, and on-prem compute to cloud workloads, this team handles it all. What You’ll Be Doing Build robust backend systems for web and machine learning products. Design, develop and deploy scalable infrastructure for high-throughout and memory-heavy systems. Implement performant API’s, storage solutions, data pipelines and microservices in a distributed systems environment. Drive platform stability and performance through strategic integration of observability frameworks for applications and infrastructure. Own technical strategy for broad and complex challenges. Collaborate closely with product and engineering teams to translate high-level requirements into actionable deliverables. Handle multiple tasks and adapt to changing priorities. Be an engineering generalist. Discover and build skills needed at different times to solve the problems at hand. What We Need To See Bachelor’s degree in Computer Science, Engineering, or related field (or equivalent experience). Minimum 8+ years experience developing large-scale software applications and infrastructure (NodeJS and/or Python preferred). Strong fundamentals in data structures and algorithms. Excellent grasp of software design patterns, API design, event-driven architecture and distributed systems concepts. Experience with data storage solutions and query optimization approaches (e.g. MySQL, MongoDB, Elasticsearch, AWS S3, etc.). Familiar with orchestration, containerization, CI/CD and observability techniques. Ways To Stand Out From The Crowd A passion for well-written code, test-driven development and engineering best practices. Strong problem solving and communication skills, self-motivated, and a team player. A zeal to learn and perform beyond prior experience and expertise. With competitive salaries and a generous benefits package, NVIDIA is widely considered to be one of the technology world’s most desirable employers. We welcome you join our team with some of the most hard-working people in the world working together to promote rapid growth. Are you passionate about becoming a part of a best-in-class team supporting the latest in GPU and AI technology? If so, we want to hear from you. The base salary range is 180,000 USD - 339,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions. You will also be eligible for equity and benefits . NVIDIA accepts applications on an ongoing basis. NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",
        "url": "https://www.linkedin.com/jobs/view/3968660556"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Palo Alto, CA",
        "job_id": 3928581233,
        "company": "Sciton",
        "title": "Mathematica Software Engineer",
        "created_on": 1720636418.2099607,
        "description": "Contract to Hire (On site in Palo Alto) Compensation And Benefits The salary range for this position is $95 - $140k. In addition to a competitive market-based salary, Sciton offers the opportunity to participate in equity/stock incentive programs, a profit-sharing bonus, and a comprehensive benefits package, including a 401(k) with matching. Help us build the future! Join our R&D team in Palo Alto, CA. Our ideal candidate lives in our immediate area or is willing to relocate to the Bay Area in California – we will assist with relocation for the most qualified talent. In This Role, You Will Develop multiple applications using the Wolfram Mathematica software package, use of graphics, communication with hardware, and image processing. Essential Requirements For The Role 3+ years of work with Mathematica Bachelor's degree (Electrical Engineering, Computer Science, Mathematics, Physics or related fields) required. Programming and coding experience—Python, MATLAB, Java, etc. User interface design experience Worked in the Medical Device industry a plus. Self-starter and able to work well within a collaborative environment Strong oral and written communication skills, as well as project management skills Willing to be flexible in job duties and take on additional responsibility when necessary. Work experience or interest in medical device technology is preferred. FULL-TIME/PART-TIME Full-Time POSITION Mathematica Software Engineer LOCATION Palo Alto (HQ) #priority About The Organization SCITON is an industry leader and manufacturer of medical aesthetic lasers and light source technologies. Our top-tier devices are built to order with integrity by pioneering, customer-focused, and results-driven individuals with a vision to improve people's lives. At the heart of it, innovation is a fundamental cornerstone of our culture. We strongly believe that new ideas can come from anyone, anywhere, at any time, and we embrace an open-door culture that welcomes and fosters individuals who are creative, driven, passionate, and willing to take the lead with us. Join us for an opportunity to grow and make an impact. Life At Sciton At Sciton, people matter. We are more than a company; we are a family, which is why we give all our employees: The support, recognition, and room to grow their careers within Sciton. Empowerment to develop their creative genius and encouragement to be lifelong learners. Incentives for creativity and innovation across the organization.",
        "url": "https://www.linkedin.com/jobs/view/3928581233"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Mountain View, CA",
        "job_id": 3943733603,
        "company": "Coupang",
        "title": "Staff Data Engineer, Pricing",
        "created_on": 1720636419.8888154,
        "description": "*location is flexible to Mountain View or Seattle office. Company Introduction We exist to wow our customers. We know we’re doing the right thing when we hear our customers say, “How did we ever live without Coupang?” Born out of an obsession to make shopping, eating, and living easier than ever, we’re collectively disrupting the multi-billion-dollar e-commerce industry from the ground up. We are one of the fastest-growing e-commerce companies that established an unparalleled reputation for being a dominant and reliable force in South Korean commerce. We are proud to have the best of both worlds — a startup culture with the resources of a large global public company. This fuels us to continue our growth and launch new services at the speed we have been since our inception. We are all entrepreneurs surrounded by opportunities to drive new initiatives and innovations. At our core, we are bold and ambitious people that like to get our hands dirty and make a hands-on impact. At Coupang, you will see yourself, your colleagues, your team, and the company grow every day. Our mission to build the future of commerce is real. We push the boundaries of what’s possible to solve problems and break traditional tradeoffs. Join Coupang now to create an epic experience in this always-on, high-tech, and hyper-connected world. The Pricing team is one of the core pillars of Coupang’s business and is responsible for helping determine the price of every product sold on Coupang. As the Pricing team is responsible for serving hundreds of millions of requests every day our mission is to build and maintain highly scalable and extensible platforms that is also highly availability and robust. As a data engineer in the Pricing Engineering org, you will help build and maintain our data and analytics infrastructure. Our mission is to provide timely insights into key decisions to help drive the business forward as quickly and efficiently as possible. You will have immense scope to drive impact across the company as a lot of customers within Coupang need pricing signals. You will help the team to bring industry best practices in Data Engineering and operations. Working closely with a group of engineers in multiple geographic locations, you will solve challenging problems at scale with high reliability. Your efforts will directly have an impact on tens of millions of users every single day! What You Will Do Design and build large-scale data processing systems and infrastructure for Pricing systems Design and maintain data pipelines and create efficiencies around internal reporting, ensuring data accuracy and timely delivery Understand Pricing business logic and be able to translate it into distributed and efficient data processing models Contribute to the design and development of our next-generation data processing platform that can support our rapidly growing business for the years to come Setup systems to ensure high quality data served to customers internal to Coupang. Basic Qualifications Bachelor's degree in computer science or computer engineering or electrical/electronic engineering, mathematics or equivalent 5+ years of solid work with fundamental algorithms, system design, and large-scale distributed system 5+ years of coding experience in one of the following: Python, Hive, Presto, Spark, Airflow, EMR and Ability to write and understand complex SQL queries Self-starter and innovator who likes to solve complex problems Proven track record of taking ownership and successfully delivering results Ability to communicate with technical and non-technical stakeholders clearly and concisely across all levels of the organization Ability to work in multi-cultural, cross functional team Experience building highly scalable systems in a fast paced, team-oriented environment Preferred Qualifications: Experience with handling large data volumes in a distributed environment A passion to explore, improve, automate, and optimize distributed systems and tools Ability to think outside-the-box and challenge conventional wisdoms Experience with ecommerce technologies and pricing systems. Experience working with AWS (Amazon web services) Deep understanding of Operational Excellence and what it takes to run and monitor highly available systems Ability to work efficiently with teams outside of Pricing working on upstream and downstream dependencies Experience setting the culture of a team and ensuring code quality across a team A desire to grow those around you both technically and professionally Ability to challenge, professionally and respectfully, the existing norms to improve overall systems and processes. Pay & Benefits Our compensation reflects the cost of labor across several US geographic markets. At Coupang, your base pay is one part of your total compensation. The base pay for this position ranges from $138,000/year in our lowest geographic market to $297,000/year in our highest geographic market. Pay is based on several factors including market location and may vary depending on job-related knowledge, skills, and experience. General Description of All Benefits Medical/Dental/Vision/Life, AD&D insurance Flexible Spending Accounts (FSA) & Health Savings Account (HSA) Long-term/Short-term Disability Employee Assistance Program (EAP) program 401K Plan with Company Match 18-21 days of the Paid Time Off (PTO) a year based on the tenure 12 Public Holidays Paid Parental leave Pre-tax commuter benefits MTV - [Free] Electric Car Charging Station General Description of Other Compensation “Other Compensation” includes, but is not limited to, bonuses, equity, or other forms of compensation that would be offered to the hired applicant in addition to their established salary range or wage scale. Coupang is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race (including traits historically associated with race, including but not limited to hair texture and protective hair styles), color, religion, religious creed (including religious dress and grooming practices), sex or gender (including pregnancy, childbirth, breastfeeding, and medical conditions related to pregnancy, childbirth or breastfeeding), gender identity, gender expression, sexual orientation, ,ancestry, national origin (including language use restrictions), age (40 and over), physical or mental disability, medical condition, genetic information, HIV/AIDS or Hepatitis C status, family status (including but not limited to marital or domestic partnership status), military or veteran status, use of a trained dog guide or service animal, political activities or affiliations, ancestry, citizenship, family and medical leave status, status as a victim of any violent crime, or any other characteristic or class protected by the laws or regulations in the locations where we operate. Coupang is also committed to providing a safe work environment for its employees and its consumers. If you need assistance and/or a reasonable accommodation in the application of recruiting process due to a disability, please contact us at usrecruiting@coupang.com . Job Requisition ID: R0044531 Equal Opportunities for All Coupang is an equal opportunity employer. Our unprecedented success could not be possible without the valuable inputs of our globally diverse team.",
        "url": "https://www.linkedin.com/jobs/view/3943733603"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "Costa Mesa, CA",
        "job_id": 3818956081,
        "company": "Anduril Industries",
        "title": "Analytics Engineer",
        "created_on": 1720636421.84966,
        "description": "Anduril Industries is a defense technology company with a mission to transform U.S. and allied military capabilities with advanced technology. By bringing the expertise, technology, and business model of the 21st century’s most innovative companies to the defense industry, Anduril is changing how military systems are designed, built and sold. Anduril’s family of systems is powered by Lattice OS, an AI-powered operating system that turns thousands of data streams into a realtime, 3D command and control center. As the world enters an era of strategic competition, Anduril is committed to bringing cutting-edge autonomy, AI, computer vision, sensor fusion, and networking technology to the military in months, not years. Anduril’s Analytics team is focused on modeling our internal data into reusable entities that generalize how Anduril operates. From those entities, we build workflows, dashboards, and metrics that drive better and faster decision-making. You will work with stakeholders from across the company to understand how Anduril functions and model our data to create the digital twin of our operations. We’re looking for people who love ontologies - defining domains and writing the code that puts those models into action. Ideally, you are passionate about the next generation of defense technology and love building efficient and understandable data models. You prioritize velocity and are interested in pushing the frontiers of what analytics can do within an organization - think data applications rather than just dashboards. What You'll Do Lead the building of Anduril’s ontology for a specific domain such as Finance, Supply Chain, Manufacturing, People, and Sustainment Collaborate with stakeholders, collecting requirements and writing the code that results in secure, timely accurate, trusted, and extensible data models Seek out problems that can be solved with data and proactively work with the organization to make it a reality Become a trusted resource for Anduril leadership in helping them run their organizations more effectively Required Qualifications 2-5 years of experience in an analytics focused role - analytics engineer, data engineer or analyst / consultant with a strong engineering background You are motivated by our mission; we are working to solve the biggest problems in defense Your weekend reading sometimes involves authors named Kimball or Inmon You’re energized by business impact & a self-starter: you’d rather build an imperfect data model quickly that is used by many people than a perfect data model that collects dust You thrive in cross-functional projects that have a heavy combination of technical requirements and user-focused workflows Expert with SQL and experience with Python or other programming languages Experience with data stack tools: dbt, Redshift, Looker/Tableau, Palantir Foundry You are empathetic: you are eager to see the world from your users’ perspective U.S. Persons status is required as this position needs to access export-controlled data Preferred Qualifications Ability to obtain and hold a U.S. Top Secret security clearance. US Salary Range $122,000—$183,000 USD Benefits The salary range for this role is an estimate based on a wide range of compensation factors, inclusive of base salary only. Actual salary offer may vary based on (but not limited to) work experience, education and/or training, critical skills, and/or business considerations. Highly competitive equity grants are included in the majority of full time offers; and are considered part of Anduril's total compensation package. Additionally, Anduril offers top-tier benefits for full-time employees, including: Platinum Healthcare Benefits: For U.S. roles, we offer top tier platinum coverage (medical, dental, vision) that are 100% covered by Anduril for you and 90% covered for your dependents. For UK roles, Private Medical Insurance (PMI): Anduril will cover the full cost of the insurance premium for an employee and dependents. For AUS roles, Private health plan through Bupa: Coverage is fully subsidized by Anduril. Basic Life/AD&D and long-term disability insurance 100% covered by Anduril, plus the option to purchase additional life insurance for you and your dependents. Extremely generous company holiday calendar including a holiday hiatus in December, and highly competitive PTO plans. 16 weeks of paid Caregiver & Wellness Leave to care for a family member, bond with your baby, or tend to your own medical condition. Family Planning & Parenting Support: Fertility (eg, IVF, preservation), adoption, and gestational carrier coverage with additional benefits and resources to provide support from planning to parenting. Mental Health Resources: We provide free mental health resources 24/7 including therapy, life coaching, and more. Additional work-life services, such as free legal and financial support, available to you as well. A professional development stipend is available to all Andurilians. Daily Meals and Provisions: For many of our offices this means breakfast, lunch and fully stocked micro-kitchens. Company-funded commuter benefits available based on your region. Relocation assistance (depending on role eligibility). 401(k) retirement savings plan - both a traditional and Roth 401(k). (US roles only) The recruiter assigned to this role can share more information about the specific compensation and benefit details associated with this role during the hiring process. Anduril is an equal-opportunity employer committed to creating a diverse and inclusive workplace. The Anduril team is made up of incredibly talented and unique individuals, who together are disrupting industry norms by creating new paths towards the future of defense technology. All qualified applicants will be treated with respect and receive equal consideration for employment without regard to race, color, creed, religion, sex, gender identity, sexual orientation, national origin, disability, uniform service, Veteran status, age, or any other protected characteristic per federal, state, or local law, including those with a criminal history, in a manner consistent with the requirements of applicable state and local laws, including the CA Fair Chance Initiative for Hiring Ordinance. We actively encourage members of recognized minorities, women, Veterans, and those with disabilities to apply, and we work to create a welcoming and supportive environment for all applicants throughout the interview process. If you are someone passionate about working on problems that have a real-world impact, we'd love to hear from you! To view Anduril's candidate data privacy policy, please visit https://anduril.com/applicant-privacy-notice/.",
        "url": "https://www.linkedin.com/jobs/view/3818956081"
    },
    {
        "task_id": "8deb9e412d314927adeba8c48469afa6",
        "keyword": "Data Engineer",
        "location": "San Francisco, CA",
        "job_id": 3686203652,
        "company": "Burq",
        "title": "Full-Stack Software Engineer",
        "created_on": 1720636423.843284,
        "description": "About Burq Burq started with an ambitious mission: how can we turn the complex process of offering delivery into a simple turnkey solution. We started with building the largest network of delivery networks, partnering with some of the biggest delivery companies. We then made it extremely easy for businesses to plug into our network and start offering delivery to their customers. Now, we're powering deliveries for some of the fastest-growing companies from retailers to startups. It's a big mission and now we want you to join us to make it even bigger! 🚀 We're already backed by some of the Valley's leading venture capitalists, including Village Global, the fund whose investors include Bill Gates, Jeff Bezos, Mark Zuckerberg, Reid Hoffman, and Sara Blakely. We have assembled a world-class team all over the U.S. We operate at scale, but we're still a small team relative to the opportunity. We have a staggering amount of work ahead. That means you have an unprecedented opportunity to grow while doing the most important work of your career. We want people who are unafraid to be wrong and support decisions with numbers and narrative. Here's a quick overview of what you will be doing: Full-Stack Software Engineer As a Software Engineer at Burq, you will be joining a team of talented engineers working together to transform the way businesses offer on-demand & same-day delivery. You will be part of an emerging team that is building a product to power millions of businesses with their delivery needs. Who are we looking for: You want to get involved in the early days of building a highly-scalable platform with a strong market presence. You have experience with JavaScript and JS frameworks, such as React.js, Angular.js, and/or Node.js You are comfortable working with frameworks including, SQL, NoSQL, REST APIs, or AWS. You have experience building micro services and crafting APIs. Experience with Git / Github. You are comfortable working on an Agile team. Nice to have: Knowledge in Python, Java or GO What you will do: Responsible for the design, implementation, and delivery of complex projects Serve as a technical resource on best practices for API development with a primary focus on REST-style APIs Use data and user feedback to identify, design, and improve Burq's user experience to ensure clients are able to quickly and delightfully perform their mission critical delivery needs Uphold our high engineering standards and improve our practices in engineering, security, and design You may be fit for this role if you: Have an entrepreneurial mindset Have four or more years of experience in full time software development or similar role Have a strong technical background, with two or more years of experience building impactful end to end products Enjoy being a generalist working on the frontend, backend, and anything it takes to solve problems and delight users Can put yourself in the shoes of your users and be a steward of crafting great experiences Benefits Investing in you 🙏 Competitive salary and opportunity for equity Option to work fully remotely or in-person Medical, dental and vision insurance Reimbursement for educational courses Generous Time Off 🏝 Workstation setup stipend 🧑🏻‍💻👩🏾‍💻 At Burq, we value diversity. We are an equal opportunity employer: we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3686203652"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3835539040,
        "company": "Adame Services LLC",
        "title": "Python Data Engineer",
        "created_on": 1720636427.2901258,
        "description": "Role: Python Data Engineer Location: New York City, NY Summary We are looking for strong Python Developer with strong background in data engineering and integration experience. Duties Integration Engineer responsible for daily support and project based development of credit risk management systems. ETL developers are responsible for designing and creating the data warehouse and all related extraction, transformation and load of data functions. This is an opportunity to gain experience in risk management processing using new technologies. You Are Overall 10+ years of experience with Python development and SQL databases. 5 years of full-time development experience using Python/Pyspark. Experience building data piplines using Azure Data Factory and Databricks. Experience with Python application frameworks (Django, Flask, Pyramid, Tornado). Experience with Python testing and code analysis tools (Pytest, Pylint). Strong SQL skills. Familiarity with SSIS. Strong troubleshooting skills. On-point communication skills. Education Bachelor’s degree in computer science or finance.",
        "url": "https://www.linkedin.com/jobs/view/3835539040"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3925073371,
        "company": "Social Capital Resources",
        "title": "Data Engineer",
        "created_on": 1720636429.0086925,
        "description": "Data Engineer Hybrid Role 4 days/week NYC $120-130k base + bonus Our client, an investment manager in NYC, is looking to add a Jr. Data Engineer to their team. The ideal candidate will have 1-3 years of Data Engineer/Development experience. Financial services experience is a huge plus, but not required. Key Responsibilities of Data Engineer • Apply analytics and quantitative concepts to support investment needs and develop new data and reporting/visualization solutions. • Work with Risk/Marketing/FA teams with various internal initiatives and projects, including proof-of-concept, prototype and production solutions. • Develop and maintain programs on source systems, ETL applications, data cleansing functions, systems management functions including load automation, and data acquisition functions among others Requirements of Data Engineer • Bachelor's Degree in a quantitative or computational field such as Statistics, Computer Science or Applied Mathematics • 2-5+ years of experience in analytical development and/or data management • Full-cycle software development knowledge. • Proven track record in hands-on development of analytical solutions • High level of proficiency in SQL and programming tools (R, Python, MATLAB, VBA, SSRS) • Experience with PowerBI and MS SharePoint development • Interested in financial markets • Familiarity with Bloomberg API/BQL is a plus • Strong communication skills with the ability to take initiative and work independently • Timeliness, Consistency, and Accuracy of work is a top priority. • High level of integrity, professionalism and ethical standards.",
        "url": "https://www.linkedin.com/jobs/view/3925073371"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963957937,
        "company": "Kforce Inc",
        "title": "Data Engineer",
        "created_on": 1720636430.648659,
        "description": "Responsibilities Kforce's NYC-based financial services client is looking to add a Data Engineer to their team. Responsibilities: Work on migrating applications from an on-premises location to the cloud service providers The Data Engineer will develop products and services on the latest technologies through contributions in development, enhancements, testing and implementation Develop, modify, extend code for building cloud infrastructure, and automate using CI/CD pipeline Partners with business and peers in the pursuit of solutions that achieve business goals through an agile software development methodology Perform problem analysis, data analysis, reporting, and communication Work with peers across the system to define and implement best practices and standards The Data Engineer will assess applications and help determine the appropriate application infrastructure patterns Use best practices and knowledge of internal or external drivers to improve products or services Requirements Expert-level understanding of Agile, SDLC, CI/CD, DevOps; GitOps, and ProdOps is required Expert-level experience in data architecture, data types/formats, optimizing code and ETL jobs, data architecture, data modeling, data contracts - a key requirement for successful collaboration with data architects and visualization developers Expert-level professional hands-on experience in extensible data pipeline development using Databricks, Alteryx, AWS Glue and Lambda functions Expert-level professional hands-on experience with RDBMS, ETL scripting tools and IDEs, data pipeline development, and management using orchestration/monitoring tools Expert-level knowledge and experience in implementing software engineering security best practices and contributing to design/engineering for DevSecOps Expert-level experience with master data management strategies, rules-based engines, and tools for multi-stage data correlation on large data sets Experience managing deployment and leading the release of code to production Expert-level understanding of data visualization tools and requirements for business customers Expert-level experience working in agile setting or being an agile best-practice mentor Expert-level experience working in Jira, confluence, and contributing to engineering team documentation/playbooks Proven experience influencing and partnering with product management, Product Owners in translating business requirements into data and engineering specifications Expert-level expertise in SQL, Python, Scala or similar; Other object-oriented programming experience a plus The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future. We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave. Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law. This job is not eligible for bonuses, incentives or commissions. Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3963957937"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3954288395,
        "company": "RadNet",
        "title": "ETL Engineer",
        "created_on": 1720636434.1720593,
        "description": "Job Summary The Extract Transform Load (ETL) Engineer is responsible for designing, building, and maintaining the organization's ETL processes. They work closely with stakeholders to understand business requirements and develop solutions that ensure data is accurate, accessible, and secure. The ETL Engineer is also responsible for developing and enforcing data governance policies and procedures. Essential Duties and Responsibilities Design and develop ETL processes to move and transform data from source systems to data warehouses or data lakes. Collaborate with data engineers and database administrators to ensure that ETL processes align with business requirements and data infrastructure. Develop and maintain documentation of ETL processes and data flows. Monitor and optimize ETL process performance to ensure it meets business requirements and SLAs. Ensure that ETL processes are secure, compliant, and adheres to data governance policies and procedures. Evaluate and recommend new ETL technologies and tools that can enhance ETL processes and support business requirements. Work with data analysts and business intelligence engineers to ensure that data is available and accessible for analysis and reporting. PLEASE NOTE: This is not an exhaustive list of all duties, responsibilities and requirements of the position described above. Other functions may be assigned and management retains the right to add or change duties at any time. Minimum Qualifications, Education and Experience Bachelor's or Master's degree in Computer Science, Engineering, or related field. Three (3) plus years of experience in ETL development, including experience with ETL tools such as Informatica, ODI, or SSIS. Experience with database systems, SQL, and programming languages such as Python, Java, C#, R. Strong knowledge of data management best practices, data integration patterns, and data quality principles. Strong problem-solving and analytical skills. Excellent communication and teamwork skills. In addition to the above qualifications, experience with SSMS, SSIS, SSAS, SSRS and Self-Service BI tools are highly recommended. The ETL Engineer should also be able to work independently and as part of a team, and have a passion for learning new technologies and staying up-to-date with industry trends. Quality Standards Communicates, cooperates, and consistently functions professionally and harmoniously with all levels of supervision, co-workers, patients, visitors, and vendors. Demonstrates initiative, personal awareness, professionalism and integrity, and exercises confidentiality in all areas of performance. Follows all local, state and federal laws concerning employment to include but not limited to: I-9, Harassment, EEOC, Civil rights and ADA. Follows OSHA regulations, RadNet and site protocols, policies and procedures. Follows HIPAA, compliance, privacy, safety and confidentiality standards at all times. Practices universal safety precautions. Promotes good public relations on the phone and in person. Adapts and is willing to learn new tasks, methods, and systems. Reports to work regularly as scheduled; consistently punctual with respect to working hours, meal and rest breaks, and maintains satisfactory personal attendance in accordance with RadNet guidelines. Consistently adheres to the time management policies and procedures. Completes job responsibilities in a quality and timely manner. Physical Demands This position often requires sitting, standing, walking, bending, twisting reaching with hands and arms, using hands and fingers, handling, constant talking, and hearing, speaking, and listening. Visual acuity to read computer screens and written materials. The position requires the ability to travel (~10% of time), drive a vehicle, and utilize other forms of transportation.",
        "url": "https://www.linkedin.com/jobs/view/3954288395"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Owego, NY",
        "job_id": 3961726623,
        "company": "Trispoke Managed Services Pvt. Ltd.",
        "title": "Data Engineer",
        "created_on": 1720636435.8757935,
        "description": "Job Title: Data Engineer Job Duration: 12 Months Contract on W2 Job Location: - Owego, NY 13827 Note: US Citizen are required for this position. Job Description Our Data Engineers enable the collection, processing, and analysis of data to help our Analytics team develop immersive stories that answer tough business questions. As a member of our team, you will source and secure data that makes analytics come to life, in support of business requirements for Data Analytics projects that support multiple functional teams. You will be involved in all aspects of the platform team role of an analytics environment, from understanding security of data, data provisioning, automating promotion functionality, enhancing monitoring capabilities, with a focus on Continuous Improvement and Continuous Development in all aspects of the role. This position is for a Data Engineer to support within **** Chief Data & Analytics Office (CDAO) supporting Rotary and Mission Systems (RMS). The work location for this position is virtual. Duties And Responsibilities Collaborating with business stakeholders to identify business opportunities and requirements to develop solutions that deliver useful, robust, and accessible self-service reporting opportunities. Supporting and building out the HANA XSA functionality of an existing analytics environment. Building and/or developing unstructured data platform utilizing the cloud infrastructure. Developing automation processes to add functionality to and enhance the Continuous Improvement/Continuous Deployment pipelines of the environment. Provide recommendations on solutions and approaches to stakeholders that align with enterprise architecture and best practices Exhibiting a degree of ingenuity, creativity, and resourcefulness when working around obstacles to keep progress moving forward on work efforts. https://www.linkedin.com/company/trispoke-managed-services-pvt-ltd/jobs And above link for more jobs",
        "url": "https://www.linkedin.com/jobs/view/3961726623"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3964672158,
        "company": "InterEx Group",
        "title": "Senior Data Engineer",
        "created_on": 1720636437.5676248,
        "description": "Senior Data Engineer Senior Data Engineer – Insurance - New York/ Connecticut Senior Data Engineer (Tech stack: Azure DataBricks, Azure Synapse, Azure Data Factory, Data Flows, Azure Data Lake, Azure, ETL, DWH) A global specialty insurer who has expanded into the USA are building out their data team focusing on how to leverage their data and utilize data to ensure growth of the business. Multiple new offices are being opened within the USA and our client is looking for a talented, enthusiastic, and passionate Senior Data Engineer (Azure, ETL, DataBricks) to help enhance their data. As the Senior Data Engineer, you should be able to demonstrate knowledge of; Azure DataBricks, Azure Synapse, Azure Data Factory, Data Flows, Azure Data Lake, Azure, ETL, DWH. Training will be provided in any of the technologies you lack, allowing you to turn your technological weaknesses into your greatest strengths! The Senior Data Engineer position will come with following benefits; 20 vacation days plus public holidays. Flexible working hours Cash Bonus Discretionary compensation awarded by the company 401k match Medical Gym/health and wellness subsidized Location: New York City / Connecticut – Hybrid or Remote Salary: $140,000 - $180,000+ Bonus + Pension + Benefits To apply for this position please send your CV to s.bell@interex-group.com at InterEx. InterEx Group are Experts in Data, ERP and CRM, we are committed to supporting your career progression! INT/DE/BEL/82133",
        "url": "https://www.linkedin.com/jobs/view/3964672158"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3935306117,
        "company": "HappyFunCorp",
        "title": "Data Engineer / Analyst - Remote - Contract",
        "created_on": 1720636439.140731,
        "description": "This position is 100% remote* (This role will primarily operate on East Coast hours) HappyFunCorp helps businesses develop great products and deliver powerful technical solutions with a blend of deep engineering skills, human-focused design, and a culture that makes working with us enjoyable. We've partnered with startups, small and mid-size businesses, and enterprise clients, including those in the Fortune 500, to innovate and modernize across a variety of verticals. Though we're a distributed team, our roots are in Brooklyn, NY, where HappyFunCorp began. ﻿Our team of over 60 sharp and talented software engineers, designers, and product architects hail from diverse backgrounds, bringing empathy and business savvy to every digital project we take on. Whether you're looking to take an idea from conception to production, expand an existing web or mobile application, or lead a complicated digital transformation project, we can help. Responsibilities: We are looking for an experienced technologist with a blend of Data Engineering and Data Analysis skills who is comfortable working in a large cloud-based data environment You will need to become familiar with and extract data from a large data lake which will inform the development of new software product features You will synthesize data from multiple third party software platforms such as Salesforce Health Cloud and other EHR / EMR systems It is important to have a product delivery mindset as you will work closely with internal and external Design, Product, and Engineering teams We are a software product development agency, so prior experience in a startup environment or software agency / consultancy would be preferred Requirements Knowledge of technologies including Snowflake, Mulesoft, Salesforce Health Cloud, and at least one modern BI tool (Tableau preferred) Knowledge of the the pharmaceutical or healthcare industry is highly desirable Experience working with EHR / EMR systems is preferred Understanding of HIPAA, data privacy, and healthcare regulations Experience working in cloud environments is required Solid understanding of data-access SQL, and API integration and development. Proficiency in one or more modern programming languages such as Java or Python Benefits Company Values: Creative Optimism. We are problem-solvers who use a lens of opportunity to make the world a bit better with all that we do Dignity. Our best work can only be done in an environment in which HFCers and our partners treat each other - and themselves - with dignity Equity. We strive for diversity across many dimensions and we believe our team is strongest when it is fairest Entrepreneurial Spirit. Our \"engine\" is the energy that comes with ownership, agency, and responsibility for what we produce Trust The bedrock of any organization is the growth of trust in our leaders, peers, and partners - the most rewarding work demands it HFC is a good fit for entrepreneurially-minded doers that learn and adapt quickly and have a passion for what they do. What we look for is someone with experience turning ideas into fully-fledged products. We offer competitive pay, a fully remote company culture, and the opportunity to work on cool projects with great people. If this sounds like you, send us your application! Salary range: $120k - $170k (Exact compensation may vary based on skills, experience, and location.)",
        "url": "https://www.linkedin.com/jobs/view/3935306117"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3954793713,
        "company": "MedReview Inc.",
        "title": "System Engineer",
        "created_on": 1720636440.7062106,
        "description": "Working Conditions: Full time (M-F), Office Business Settings. This is an On-Premises position. Monday through Thursday (9-5) and remote on Fridays only (No exceptions). Position Summary –The System Engineer is responsible for the day-to-day operation and maintenance of Servers and infrastructure systems that are located on premise and in the cloud. The System Engineer fulfills responsibilities in some or all of the following technical areas: Azure, Servers maintenance, Systems upgrades and procurement, infrastructure design and layout, Disaster Recovery design and implementation, OS installation and maintenance, management of system tools and applications, Active Directory services. The System Engineer is also tasked with deploying best practices for helping with securing information as well as platforms in the infrastructure. Job Responsibilities: This list does not represent all responsibilities for this position. Candidate must be willing and able to assume roles and responsibilities other than these to meet the needs of the organization. (3 -5 years in the following): Administration of company’s Servers and digital infrastructure including management of network operating systems, servers, Cisco UCS , SAN’s, VMWare, V-Sphere, Windows, File and print services, Domain controllers, Automation, Office 365, Azure, Active Directory, monitoring and reporting, Data center capacity management and planning, Disaster recovery, backups, and recovery Very strong Azure experience. Responds to events, incidents, and outages with required as needed and under the direction of the Director of IT, and in coordination with the technology leadership team Assist in the development, implementation and maintenance of policies, procedures, and associated training plans Perform regular backup operations and implement appropriate processes for data protection, Disaster recovery, and failover procedures Working knowledge of common services: DNS, SMTP, DHCP, HTTP, etc Handles support tickets for issues and outages with Servers’ Issues, cloud providers, virtual environment, etc Working knowledge of Mimecast or similar experience for spam filtering, encryption, DLP, etc Windows Administration (Active Directory, Scripting, DNS, Group Policy’s) Plan for GPO policy upgrades to secure business operations (Active Directory) Adhere to best practices of securing currently used applications and platforms (MFA) Participate in internal and external audits (HiTrust) Required Experience: Four-year degree or higher in Information Systems, or related field or equivalent combination of work experience. Ability to perform under stress Collaborative \\ Team player \\ Dependable Strong Written and verbal communication skills Planning and organizational skills \\ Attention to detail Customer-service oriented mindset Previous system engineering experience is a must Advanced understanding of infrastructure. Azure, Clouds, Active Directory, Windows desktop/server OS, VMware, storage systems, DNS is a must Working knowledge of various Identity and Access management systems a plus Advanced understanding of protocols. WMI, SNMP, TLS, SSL, SMB Advanced understanding of securing systems and platforms through device/policy hardening Ability to communicate technical information in a clear manner, both written and verbally, to end users Proficient knowledge of MS Outlook, O365, Word, Excel, Visio, and PowerPoint Experience with HIPAA, HITRUST, HITECH, PCI, ISO 27001, ISO 27002, URAC regulations and awareness and/or experience with CMS, NIST and other healthcare industry related regulations a plus Knowledge of Veeam Backup tool, Netwrix, HPE Storage, Zscaler, Virtual Desktops, SharePoint a plus Availability to work nights and weekends during (un)planned outages and other special circumstances, with 24/7 accountability Availability to enter on call rotation Ability to lift 50 lbs Benefits and perks include: Healthcare that fits your needs - We offer excellent medical, dental, and vision plan options that provide coverage to employees and dependents 401(k) with Employer Match - Join the team and we will invest in your future Generous Paid Time Off - Accrued PTO starting day one, plus additional days off when you’re not feeling well, to observe holidays Wellness - We care about your well-being. From Commuter Benefits to FSAs we’ve got you covered Learning & Development - Through continued education/mentorship on the job and our investment in LinkedIn Learning, we’re focused on your growth as a working professional Salary: $135k-145k Powered by JazzHR KzWONiAsHL",
        "url": "https://www.linkedin.com/jobs/view/3954793713"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3944769189,
        "company": "Augment Jobs",
        "title": "Big Data Engineer",
        "created_on": 1720636442.2390301,
        "description": "Location: United States (Remote option available) Job Type: Full-time Salary Range: $120,000 - $160,000 per year Company Overview At our technology-driven firm, we leverage cutting-edge data solutions to transform industries and empower clients with actionable insights. Our dedicated team of data professionals is at the forefront of innovation, employing advanced technologies to solve complex problems and drive business success. Job Summary We are seeking a Big Data Engineer to join our dynamic team. This role involves managing vast amounts of data while ensuring its accessibility, accuracy, and security. You will collaborate with data scientists and architects to support data initiatives and ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities Design, construct, install, test, and maintain highly scalable data management systems. Ensure systems meet business requirements and industry practices. Integrate new data management technologies and software engineering tools into existing structures. Develop set processes for data modeling, mining, and production. Employ a variety of languages and tools to marry systems together or try to hunt down opportunities to acquire new data from other systems. Recommend ways to improve data reliability, efficiency, and quality. Collaborate with data architects, modelers, and IT team members on project goals. Support data scientists and analysts in data initiatives and ensure that data flows smoothly from source to database to end user. Conduct research for industry and business questions that can add new and valuable insights. Deploy sophisticated analytics programs, machine learning, and statistical methods. Qualifications Bachelor’s degree in Computer Science, Information Technology, Engineering, or related field; Master’s degree preferred. Proven experience as a Big Data Engineer or similar role. Strong experience in big data tools like Hadoop, Spark, Kafka, etc. Experience with data pipeline and workflow management tools. Experience with AWS cloud services: EC2, EMR, RDS, Redshift. Experience with stream-processing systems: Storm, Spark-Streaming, etc. Strong organizational and project management skills. Excellent problem-solving and troubleshooting skills. Proficient understanding of distributed computing principles. Proficiency with relational SQL and NoSQL databases, including Postgres and Cassandra. Benefits Competitive salary and performance bonuses. Comprehensive benefits package including medical, dental, and vision insurance. 401(k) plan with company match. Generous vacation and paid time off policies. Continuing education and professional development opportunities. Flexible work hours and remote work options. How To Apply Interested candidates should submit a resume and a cover letter that discusses their experiences with big data technologies and demonstrates their passion for data-driven decision making. Apply via our company's career portal. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3944769189"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3929516868,
        "company": "The Walt Disney Company",
        "title": "Senior Data Engineer",
        "created_on": 1720636443.8751452,
        "description": "Disney Entertainment & ESPN Technology On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world. A few reasons why we think you’d love working for Disney Entertainment & ESPN Technology Building the future of Disney’s media business: DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come. Reach & Scale: The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more. Innovation: We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news. Engineering Services designs, builds, and sustains technology that powers DE&E Technology’s worldwide content production and distribution platforms. In doing so, they contribute to a series of cross-functional services and technologies, including Quality Assurance, Data Analytics, Software Development, Broadcast Infrastructure, and Networking & Security. The Core Data & Services for the Data organization within the DEET organization is in search of a Senior Data Engineer. As a member of the Core Data team you will establish the foundational set of data pipelines and datasets which are a vital key to success – enabling dozens of engineering and analytical teams to unlock the power of data to drive key business decisions and provide engineering, analytics, and operational teams the critical information necessary to scale the largest streaming service. Expanding, scaling, and standardizing the core foundational principles through consistent observability, lineage, data quality, logging, and alerting across all engineering teams in the Data organization is imperative to the creation of a single pane of glass. The Core Data team is seeking to grow their team of world class Data Engineers that share their charisma and enthusiasm for making a positive impact! What You'll Do Contribute to maintaining, updating, and expanding existing Core Data platform data pipelines in Scala and Python / Spark while maintaining strict uptime SLAs Extend functionality of current Core Data platform offerings, including metadata parsing, extending the Metastore API, and building new integrations with APIs both internal and external to the Data organization Implement Ingestion of new batch and streaming data pipelines using Scala, Databricks, and Airflow Implement the Lakehouse architecture, working with customers, partners, and stakeholders to shift towards a Lakehouse centric data platform Implementation shared libraries in Scala and Python that abstract complex business logic to allow consistent functionality across all data pipelines across the Data organization Tech stack includes Airflow, Spark, Databricks, Delta Lake, Snowflake, Scala, Python Collaborate with product managers, architects, and other engineers to drive the success of the Core Data platform Contribute to developing and documenting both internal and external standards and best practices for pipeline configurations, naming conventions, partitioning strategies, and more Ensure high operational efficiency and quality of the Core Data platform datasets to ensure our solutions meet SLAs and project reliability and accuracy to all our stakeholders (Engineering, Data Science, Operations, and Analytics teams) Be an active participant and advocate of agile/scrum ceremonies to collaborate and improve processes for our team Engage with and understand our customers, forming relationships that allow us to understand and prioritize both innovative new offerings and incremental platform improvements Maintain detailed documentation of your work and changes to support data quality and data governance requirements Basic Qualifications At least 5 years of data engineering experience developing large data pipelines Strong algorithmic problem-solving expertise Strong fundamental Scala and Python programming skills Basic understanding of AWS or other cloud provider resources (S3) Strong SQL skills and ability to create queries to analyze complex datasets Hands-on production environment experience with distributed processing systems such as Spark Hands-on production experience with data pipeline orchestration systems such as Airflow for creating and maintaining data pipelines Some scripting language experience Willingness and ability to learn and pick up new skillsets Self-starting problem solver with an eye for detail and excellent analytical and communication skills Preferred Qualifications Experience with at least one major Massively Parallel Processing (MPP) or cloud database technology (Snowflake, Redshift, Big Query) Experience in developing APIs with GraphQL Deep Understanding of AWS or other cloud providers as well as infrastructure as code Familiarity with Data Modeling techniques and Data Warehousing standard methodologies and practices Familiar with Scrum and Agile methodologies Required Education Bachelor’s degree in Computer Science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience Additional Information #DISNEYTECH he hiring range for this position in Santa Monica, CA is $136,038.00 to $182,490.00 per year, in San Francisco, CA is $148,994.00 to $199,870.00 per year, in Seattle, WA is $142,516.00 to $191,180.00 per year, and in New York, NY is $142,516.00 to $191,180.00 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",
        "url": "https://www.linkedin.com/jobs/view/3929516868"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3954290210,
        "company": "RadNet",
        "title": "Business Intelligence Engineer",
        "created_on": 1720636445.4897175,
        "description": "Job Summary The Business Intelligence Engineer is responsible for designing, building, and maintaining an organization's BI solutions. They work closely with stakeholders to understand business requirements and develop solutions that provide insights and enable data-driven decision making. The Business Intelligence Engineer is also responsible for developing and enforcing data governance policies and procedures. Essential Duties and Responsibilities Design and develop BI solutions, including reports, dashboards, and data visualizations, that meet business requirements and enable data-driven decision making. Collaborate with business analysts, data analysts, and data engineers to ensure that BI solutions align with business requirements and data infrastructure. Develop and maintain documentation of BI solutions, including technical specifications, user manuals, and training materials. Monitor and optimize BI solution performance to ensure it meets business requirements and SLAs. Ensure that BI solutions are secure, compliant, and adhere to data governance policies and procedures. Evaluate and recommend new BI technologies and tools that can enhance BI solutions and support business requirements. Work with stakeholders to identify areas for BI improvements and provide recommendations for enhancing BI solutions. PLEASE NOTE: This is not an exhaustive list of all duties, responsibilities and requirements of the position described above. Other functions may be assigned and management retains the right to add or change duties at any time. Minimum Qualifications, Education and Experience Bachelor's or Master's degree in Computer Science, Engineering, or related field. Three (3) plus years of experience in BI development, including experience with BI tools such as Tableau, Power BI, or QlikView. Experience with database systems, SQL, and programming languages such as Python, R, DAX, MDX. Strong knowledge of data management best practices, data integration patterns, and data quality principles. Strong problem-solving and analytical skills. Excellent communication and teamwork skills. In addition to the above qualifications, experience with SSMS or SSAS, SSRS and Self-Service BI tools are highly recommended. The Business Intelligence Engineer should also be able to work independently and as part of a team, and have a passion for learning new technologies and staying up-to-date with industry trends. Quality Standards Communicates, cooperates, and consistently functions professionally and harmoniously with all levels of supervision, co-workers, patients, visitors, and vendors. Demonstrates initiative, personal awareness, professionalism and integrity, and exercises confidentiality in all areas of performance. Follows all local, state and federal laws concerning employment to include but not limited to: I-9, Harassment, EEOC, Civil rights and ADA. Follows OSHA regulations, RadNet and site protocols, policies and procedures. Follows HIPAA, compliance, privacy, safety and confidentiality standards at all times. Practices universal safety precautions. Promotes good public relations on the phone and in person. Adapts and is willing to learn new tasks, methods, and systems. Reports to work regularly as scheduled; consistently punctual with respect to working hours, meal and rest breaks, and maintains satisfactory personal attendance in accordance with RadNet guidelines. Consistently adheres to the time management policies and procedures. Completes job responsibilities in a quality and timely manner. Physical Demands This position often requires sitting, standing, walking, bending, twisting reaching with hands and arms, using hands and fingers, handling, constant talking, and hearing, speaking, and listening. Visual acuity to read computer screens and written materials. The position requires the ability to travel (~10% of time), drive a vehicle, and utilize other forms of transportation.",
        "url": "https://www.linkedin.com/jobs/view/3954290210"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3960930007,
        "company": "MashPoint - Technology & Staffing- merged with HuMetis group Inc",
        "title": "Senior Data Engineer (14326360)",
        "created_on": 1720636448.921582,
        "description": "Job Title: Senior Data Engineer Job Location: New York, NY, 10019 - HYBRID Duration: 5+ Months (Possibility of extension) Hybrid with 2 days per week in the office. Fully remote is acceptable for the right candidate. Job Summary As a Senior Data Engineer, you will oversee the entire development lifecycle of complex data projects, including integration and transformation tasks such as analysis, design, development, and support of intricate data pipelines in cloud environments. You will also assist in designing and configuring data management tools that extract and manipulate data from various in-house and external sources. Required Skills Proficiency in creating scalable and secure data pipelines for the ingestion, transformation, and transfer of large volumes of structured and unstructured data from diverse sources. Expertise in building complex database logic and APIs to automatically fetch and store data in various formats. Extensive experience with programming languages (such as Python), ETL tools, and both relational and non-relational databases. Skill in architecting and developing efficient, reusable modular components for complex applications. Knowledge of implementing data quality, security, and governance standards and best practices across different cloud environments. Experience in designing and building integrations between data management tools. Proficiency in designing, developing, and maintaining data solutions across cloud platforms like AWS or Google Cloud. Deep understanding of data structures, algorithms, software architecture, detailed testing, and documentation of complex systems. Experience with the secure movement and storage of PHI, PII, and PCI data. Ability to scale up applications, increase resiliency, and ensure code meets performance standards. Collaboration skills to work with data analysts, data scientists, and IT operations in installing and building tools that transform data for new data and AI products. Technical leadership experience in development projects and providing consultation and guidance to team members. Innovative problem-solving skills for complex business or production issues. Familiarity with modern DevSecOps practices and tools. Experience with Agile methodologies and tools (e.g., Jira, Scrum, Kanban). Nice To Have Experience in leading a team of data engineers and analysts in creating complex software and data pipelines. Knowledge of data governance processes. Familiarity with data classification and taxonomy tools. Qualifications Bachelor’s degree in Computer Science, Information Systems, or a related field; a Master's degree is preferred. 7+ years of experience as a Data Engineer.",
        "url": "https://www.linkedin.com/jobs/view/3960930007"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3811059542,
        "company": "TechTammina LLC",
        "title": "Senior Big Data Engineer",
        "created_on": 1720636450.523148,
        "description": "Job Title: Senior Big Data Engineer Work Location: NYC NY (Midtown) - Onsite Position Emp Type: Contract Visa: H1s, GC Skills Needed Must have 6+ years of ‘Recent’ experience working for a Major Bank or Brokerage house in the US. Must 12 yrs+ of experience maintaining applications utilizing Java, J2EE, SDLC, and WebSphere. Must have last 6 years experience working with CASSANDRA, Hadoop, MongoDB, Apache Spark, HDFS, YARN, MapReduce, PIG&HIVE, Flume & Scoop, and Zookeeper. Must have 6 years of experience maintaining Tier-1 data driven apps. Must have experience with 24/7 uptime and strict SLA. Extensive experience maintaining data pipelines, aggregate & transform raw data coming from a variety of data sources. Extensive experience optimizing data delivery and helping redesign to improve performance, handling, transformation, and managing BigData using BigData Frameworks. Extensive experience maintaining processed data parallel on top of distributed Hadoop storage using MapReduce. Must have experience wit SOA -Design principles. Must have 5+ years programming in Scala, Java, Python or GO Must have 5+ years developing on Hadoop/Spark. Must have 6+ years developing on an RDBMS such as Microsoft SQL Server, and PostgreSQL. Must have experience with large data sets – regularly transforming and querying tables or sets of greater than 20 million records Exposure to data hygiene routines and models Experience in database maintenance. Ability to identify problems, and effectively communicate solutions to team. The Job The consultants will be 'Big Data Engineers' helping, support, maintain and test the New Database for specific business units. These positions will be responsible for maintaining complex Databases for the Business Technology Group. The consultants will work with minimal supervision and guidance from more seasoned consultants, and may also be expected to provide application and Database support",
        "url": "https://www.linkedin.com/jobs/view/3811059542"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962173202,
        "company": "The Walt Disney Company",
        "title": "Data Engineer II - Reliability Ops",
        "created_on": 1720636452.2341666,
        "description": "Disney Entertainment & ESPN Technology On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world. A few reasons why we think you’d love working for Disney Entertainment & ESPN Technology Building the future of Disney’s media business: DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come. Reach & Scale: The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more. Innovation: We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news. The Product & Data Engineering team is responsible for end to end development for Disney’s world-class consumer-facing products, including streaming platforms Disney+, Hulu, and ESPN+, and digital products & experiences across ESPN, Marvel, Disney Studios, NatGeo, and ABC News. The team drives innovation at scale for millions of consumers around the world across Apple, Android, Smart TVs, game consoles, and the web, with our platforms powering core experiences like personalization, search, messaging and data. The Data Reliability Engineering team for Disney’s Product and Data Engineering team is responsible for maintaining and improving the reliability of Disney Entertainment’s big data platform, which processes hundreds of terabytes of data and billions of events daily. Job Summary: The Data Engineer II will help us in the ongoing mission of delivering outstanding services to our users allowing Disney Entertainment to be more data-driven. You will work closely with the senior members of our team to monitor and drive improvements for reliability and observability of critical data pipelines and deliverables. This is a high-impact role where your work informs decisions affecting millions of consumers, with a direct tie to The Walt Disney Company’s revenue. You will be making an outsized impact in an organization that values data as its top priority. We are a tight and driven team with big goals, so we seek people who are passionate about solving the toughest challenges and working at scale, using, supporting, and building distributed systems in a fast-paced collaborative team environment. We also support a healthy work-life-balance. Responsibilities You will assist with on-call rotations as a Live-Ops Incident Commander to help categorize and track real time data incidents, loop in engineering resources as needed to ensure a timely resolution to data issues. You will help drive our problem management process to ensure root cause of data incidents are analyzed and understood, and follow-up work is prioritized with our partner teams. You will play a key role in our long-term Incident and Problem Management strategy by contributing to the development of a Data Reliability Observability Platform that will assist in programmatically quantifying incident impacts and send targeted communications to both data owners and consumers. You will partner with our external support and data quality teams, defining success KPI’s, ensuring observability and automation coverage of our platform and help create dashboards and visualizations for teams to monitor the health of our data pipelines and platform. Basic Qualifications Bachelor’s Degree in computer science, information systems, or related field or equivalent work experience. 3+ years of relevant data engineering experience. Good understanding of data modeling principles including Dimensional modeling, data normalization principles. Experience with process engineering and continuous improvement. Detailed problem-solving approach, coupled with a strong sense of drive and ownership. Strong communication skills – written and verbal presentations. Comfortable working in a fast-paced and highly collaborative environment. Familiarity with Agile Scrum principles and ceremonies Preferred Qualifications 2+ years of work experience implementing and reporting on business key performance indicators in data warehousing environments, exposure to reliability engineering best practices a plus. 2+ years of experience using analytic SQL, working with traditional relational databases and/or distributed systems (Snowflake or Redshift), required. 1+ years of experience programming languages (e.g. Python, Pyspark), preferred. Experience with Snowflake, Databricks/EMR/Spark, and/or Airflow. The hiring range for this position in New York, NY or Seattle, WA is between $107,400 to $143,900, Los Angeles, CA is $102,500 to $137,500 year and in San Francisco is $112,300 to $150,500. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",
        "url": "https://www.linkedin.com/jobs/view/3962173202"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3895663223,
        "company": "Steneral Consulting",
        "title": "Onsite Work - Need Data Warehouse / Informatica ETL Engineer in NYC NY",
        "created_on": 1720636453.92689,
        "description": "Data Warehouse / Informatica ETL Engineer Position: Informatica Developer/Engineer Client: Church Pension Group, Midtown New York City Location: Hybrid work: NYC 3 days a week in office : Tuesday- Thursday and 2 from home. Must be local to NYC area. NO EXCEPTIONS Work Status: USC or GC candidates, as this will be a right to hire position Duration: 6 month + consultant to hire opportunity. Interview : First interview Zoom. Second Interview in office -mandatory, Description month CONTRACT TO HIRE POSITION!! GC or US Citizen Preferred Tuesday through Thursday in NYC Office and WFH Monday and Friday -local only Our client located in midtown NYC is looking for a savvy ETL Informatica developer to join their team of Database/Informatica Engineer/Architect to develop strategic ETL and data quality builds. Key Technologies Are Informatica PowerCenter MySQL/SQL Server, T-SQL Unix shell scripting DB Modeling Control-M Scheduling tool Position will assume design/architecture/development builds At least 3 years’ experience designing your ETL Informatica PowerCenter processes, preferably as a senior member of a team At least 8 years’ experience developing ETL processes At least 8 years of hands on use of Informatica PowerCenter Tools Expert SQL skills T-SQL experience. Experience with designing/building/supporting ETL error handling conditions/validations Linux and Ruby scripting experience is plus BS in Computer, Information Sciences or STEM Excellent communication skills",
        "url": "https://www.linkedin.com/jobs/view/3895663223"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Albany, NY",
        "job_id": 3932023008,
        "company": "ACS Consultancy Services, Inc",
        "title": "ETL Developer (IBM Data stage)",
        "created_on": 1720636455.6212595,
        "description": "Title: ETL Developer (IBM Data stage) Location: Albany, NY (Hybrid) We are currently seeking candidates who meet the following qualifications. Key Requirements Proven track record in utilizing IBM Datastage for ETL processes. Hands-on experience working with IBM DB2 databases, along with familiarity in handling XML schemas (definition, querying, and automated generation). Strong background in AIX/Unix scripting to automate processes and enhance efficiency. Demonstrated capability in performance tuning applications that interact with databases, ensuring optimal functionality. Experience in all phases of technical design, development, maintenance, and end-user support for complex systems. If you meet these qualifications, please submit your application via link provided in Linkedin. Kindly do not call the general line to submit your application.",
        "url": "https://www.linkedin.com/jobs/view/3932023008"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3965819219,
        "company": "Zortech Solutions",
        "title": "Sr Data Engineer (Databricks) - US",
        "created_on": 1720636457.5444279,
        "description": "Role: Sr Data Engineer (Databricks) Location: NY preference, remote is also fine Duration: Fulltime Job Description Experience Level: 7 to 12 Must Have Strong in Data engineering Strong developer profile Hand-on experience on:- Azure / AWS / Data bricks (Good to have) / Coding skills / Analytics skills.",
        "url": "https://www.linkedin.com/jobs/view/3965819219"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3818476827,
        "company": "TechTammina LLC",
        "title": "Senior Big Data Engineers",
        "created_on": 1720636459.2437503,
        "description": "Title: Senior Big Data Engineers Work Location: NYC NY (Midtown) Onsite Position Skills Needed Must have 6+ years of ‘Recent’ experience working for a Major Bank or Brokerage house in the US. Must 12 yrs+ of experience maintaining applications utilizing Java, J2EE, SDLC, and WebSphere. Must have last 6 years experience working with CASSANDRA, Hadoop, MongoDB, Apache Spark, HDFS, YARN, MapReduce, PIG&HIVE, Flume & Scoop, and Zookeeper. Must have 6 years of experience maintaining Tier-1 data driven apps. Must have experience with 24/7 uptime and strict SLA. Extensive experience maintaining data pipelines, aggregate & transform raw data coming from a variety of data sources. Extensive experience optimizing data delivery and helping redesign to improve performance, handling, transformation, and managing BigData using BigData Frameworks. Extensive experience maintaining processed data parallel on top of distributed Hadoop storage using MapReduce. Must have experience wit SOA -Design principles. Must have 5+ years programming in Scala, Java, Python or GO Must have 5+ years developing on Hadoop/Spark. Must have 6+ years developing on an RDBMS such as Microsoft SQL Server, and PostgreSQL. Must have experience with large data sets – regularly transforming and querying tables or sets of greater than 20 million records Exposure to data hygiene routines and models Experience in database maintenance. Ability to identify problems, and effectively communicate solutions to team.",
        "url": "https://www.linkedin.com/jobs/view/3818476827"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3910405892,
        "company": "Brigit",
        "title": "Senior Data Engineer",
        "created_on": 1720636463.3179405,
        "description": "Hi, we're Brigit! A holistic financial health company helping every American build a brighter financial future. With a business model that is aligned with our customers, we create transparent, fair, and simple financial products that put money back in the hands of our members, help them spend wisely, avoid unfair fees and build their credit quickly. If autonomy, ownership, and having meaningful input at the company you work for is important to you, come join our growing team! Brigit is doing innovative and exciting work, but don’t just take our word for it, our work is being recognized by others: Built In’s 2023 & 2024 Best Startups to Work For In New York City Built In’s 2024 Best Startups to Work For In the U.S. Fast Company’s Most Innovative Companies of 2022 Forbes Fintech 50 2022 Business Insider’s Most Promising Consumer Startups 2022 The Role We’re hiring a Senior Data Engineer to join our team responsible for building Brigit’s data platforms. You'll work closely with our Analytics Engineering, Engineers, Analysts, Data Scientists, and Product Managers as a thought partner, technical leader, and resource. This is a unique opportunity to build the data strategy and architecture at a data-driven startup that’s changing the world of FinTech. Today, our stack consists of Fivetran, Snowflake, dbt, Metaplane and Mode. Over the next 12-18 months you’ll help us architect and implement the data strategy for new products and new partners while maturing our current platform. You’ll be working closely with the Head of Data and Analytics to launch our new BI tool, with the Analytics Engineer to mature our instance of dbt and several Engineering and Product leads to help us think through the data flows in new and enhanced product offerings. What you’ll do: Data Infrastructure Development: Design, develop, and maintain data pipelines and data models to provide valuable business insights. Optimize data processing, storage, and retrieval capabilities with appropriate technologies, tools, and frameworks. Proactively monitor, maintain and optimize our data platform to ensure data systems' reliability, performance, and security. Collaboration and Project Management: Drive cross-functional projects to improve our data capture techniques and know-how. Liaise between data and engineering teams to align needs and priorities. Work with technical and non-technical stakeholders to explain complex technical concepts, present project updates, and gather feedback. Process Improvement and Best Practices: Shape a holistic data quality strategy that ensures accuracy, consistency, and reliability across our organization's data landscape. Establish and promote data engineering best practices and standards. Identify opportunities for process improvement and automation. Who you are: You have 6+ years of experience as a data engineer coding in Python and using SQL, preferably in a fast-paced consumer finance or fintech startup. Experience with building off-the-shelf and custom data pipelines on cloud infrastructure. Proficiency with data warehouse administration, operations, and optimization. Fluency with dbt and analytics engineering. Familiarity with a variety of data sources such as relational databases, APIs, SFTP, and customer data platforms (CDPs). Excellent problem-solving skills and ability to work in a fast-paced, dynamic environment. The anticipated annual base salary for this position is $155,000 - $180,000. This range does not include any other compensation components or other benefits for which an individual may be eligible. The actual base salary offered depends on a variety of factors, which may include as applicable, the qualifications of the individual applicant for the position, years of relevant experience, specific and unique skills, level of education attained, certifications or other professional licenses held, and the location in which the applicant lives and/or from which they will be performing the job. Our Benefits & Team Medical, dental, and vision insurance Equity participation Flexible PTO Policy 401k plan Paid Parental Leave Physical and mental wellbeing benefits including Wellhub for access to virtual workouts and discounted gym memberships, and Headspace for covered virtual therapy sessions and unlimited on demand health support Monthly reimbursements to use against wifi and cell phone bills Annual reimbursement for Learning & Development Help hard working Americans build a brighter financial future High-growth company at an early stage A dynamic, flexible and collaborative start-up work environment with a highly talented team Brigit is committed to providing equal employment opportunities for all applicants and employees without regard to race, religion, color, sex, pregnancy (including breast feeding and related medical conditions), national origin, citizenship status, uniform service member status, age, genetic information, disability, or any other protected status in accordance with all applicable federal, state and local laws. We are proud to be an equal opportunity workplace.",
        "url": "https://www.linkedin.com/jobs/view/3910405892"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3931363642,
        "company": "YO HR Consultancy",
        "title": "Founding Software Engineer - Python",
        "created_on": 1720636464.9017925,
        "description": "You Will Lead and own the full stack development of crucial product features Architect systems and ship lots of code Work directly with enterprise clients to understand and support their needs Collaborate with the founders - Mike, Vivek, and Ron - on vision, strategy, and the roadmap Take part in epic, impassioned discussions about world domination and which emoji to use on the landing page We’re Looking For Experience leading software projects on a team Expertise in Python Expertise in SQL Solid understanding of Production cloud environments (like AWS) Hungry self-starters who can adapt in face-paced and ambiguous environments Good peoples who will serve cultural leaders as we grow the team Would Be Great If You Have Experience leading an engineering team Experience with Django, Pandas, machine learning, data engineering Experience with React, JavaScript, Node.js Experience with Git, Continuous Integration/Deployment, Testing methodologies\\ Technology On the backend we primarily use Python/Django, a good deal of pandas. On the frontend we use React and Node.js. Our infrastructure consists of hosting in AWS, Redshift, Postgres, and Redis. Skills: python,django,aws,continuous integration",
        "url": "https://www.linkedin.com/jobs/view/3931363642"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3838641259,
        "company": "Accroid Inc",
        "title": "Big Data Operations Engineer",
        "created_on": 1720636466.479292,
        "description": "Remote Big Data Operations Engineer 12+ Months PH and Video Good Linux skills bash scripting, administration etc. 3-5 years Kubernetes, Spark, Docker working experience 1-2 years with real time experience Understanding of Python scripting/Java basics required on-prem experience is required",
        "url": "https://www.linkedin.com/jobs/view/3838641259"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3900650697,
        "company": "Big Cloud",
        "title": "Senior Data Engineer",
        "created_on": 1720636468.6829066,
        "description": "Do you have experience with the Azure Cloud stack and Azure Synapse? Are you interested in working with stakeholders to solve complex data pipeline and cloud problems? Are you open and able to work on a full-time/perm/W2 contract basis? A leading tech consulting company is seeing huge market success working with East Coast finance companies, Bay Area AI start-ups, European marketing agencies and much more. They have a specialised team, working on projects ranging from data to AI and cloud cybersecurity. They pride themselves in business customer satisfaction and using the latest technology to provide end-to-end solutions. In the next few months, they team are hiring for Senior Data Engineers to work with a finance client account they're scaling. You'd be working end-to-end on data pipelines built on the Azure platform, working closely with their mission-driven tech team and external stakeholders. What you need: · 3+ years of data engineering experience · Strength with Azure Stack , Synapse · understanding of the DevOps process and cloud migration · added bonus: experience with Python, PySpark, Databricks Believe this could be a fit? Apply below! Big Cloud is a machine learning recruiting firm. We’re lucky enough to recruit the best candidates in the most exciting companies all over the world. We try to reply to all applications, but we’re only human, for now! So, you may only hear from us if you are successful. Check out www.bigcloud.io/jobs to see what else we’re recruiting for.",
        "url": "https://www.linkedin.com/jobs/view/3900650697"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3875379247,
        "company": "GEI Consultants, Inc.",
        "title": "Jr. Web Application Data Engineer",
        "created_on": 1720636472.8201997,
        "description": "Description Your role at GEI. The Jr. Web Application Data Engineer position is responsible for the development and support of web applications that are highly data centric. This position goes beyond the typical web programmer and will design and support objects within Microsoft SQL Server. The person hired for this position will work with a team of Web programmers, Data Engineers, Data Architects, GISPs, Power BI designers, and subject-matter experts that are located on the east coast. Required Qualifications Practical experience with .Net framework for web development, C#, ASP.net, jquery, HTML/ razer, Linq, javaScript, and git or other version control management software. Expertise in SDLC. Ability to provide off-hour deployments and support for bug-fixes. Major in computer-related field (computer science/engineering) Able to work during east coast schedule. Preferred Qualifications Experience using Entity Framework Core Experience with Microsoft SQL Server via SSMS - DDL and DML, relationships, indexing, view, and stored procedure development. Knowledge of .Net Core Azure authentication Azure Blob storage integration Power BI cloud service Experience with VB.net for desktop applications, XML, XSD for supporting non-web applications. Essential Duties Design, program, test, deploy, and document web applications. Design and build SQL Server schema. Collaborate with data architects and data engineers. Develop a strong understanding of the subject matter for each application to assist with troubleshooting. Provide programming and data engineering assistance for desktop applications. Soft Skills Applicant should be self-motivated, detail-oriented, and organized. Must be a quick learner. Work well in a team environment but be self-directed and be able to work independently. Experience in providing high quality deliverables on time. Provide clear concise documentation for developed applications. Ability to research coding solutions and best practices via websites or the resources. We are GEI. Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow. We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges. With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry. Employee-owned. Employee-focused. As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here. GEI’s Total Rewards Package Includes Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus Pay Range For This Position: $25.00-32.00/hour dependent upon experience Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More Well-Being Program and Paid Parental Leave Commuter Benefits Hybrid Work Schedules and Cell Phone Stipends GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses Paid Holidays and Generous Paid Time Off Program Rewards and Recognition GEI-Funded Profit Sharing and 401(k) Opportunity to be an Owner and Shareholder (Learn more here) A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion And More…",
        "url": "https://www.linkedin.com/jobs/view/3875379247"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3892872640,
        "company": "Zortech Solutions",
        "title": "Cloud Data Engineer/Snowflake",
        "created_on": 1720636474.491126,
        "description": "Role: Cloud Data Engineer/ Snowflake Location: NYC / NJ (hybrid) Duration: 6+ Months Job Description In person interview is mandatory This position is for a Cloud Data / Reporting engineer with a background in SQL and data warehousing for enterprise level systems. The position calls for someone that is comfortable working with business users along with business analyst expertise. Major Responsibilities Experience designing and developing Enterprise Data Warehouse solutions. Demonstrated proficiency with Data Analytics, Data Insights Proficient writing SQL queries and programming including stored procedures and reverse engineering existing process Leverage SQL, programming language (Python or similar) and/or ETL Tools (Azure Data Factory, Data Bricks, Talend and SnowSQL) to develop data pipeline solutions to ingest and exploit new and existing data sources. Perform code reviews to ensure fit to requirements, optimal execution patterns and adherence to established standards. Skills 10+ years - Enterprise Data Management 10+ years - SQL Server based development of large datasets 5+ years with Data Warehouse Architecture, Snowflake experience preferred 3+ years' experience in Finance / Banking industry some understanding of Securities and Banking products and their data footprints. 2+ years Python coding experience Proficient with Data Visualization tools Hands-on experience with Snowflake utilities such as SnowSQL and SnowPipe Working knowledge of MS Azure configuration items with respect to Snowflake. Hands-on experience with Tasks, Streams, Time travel, Optimizer, Metadata Manager, data sharing Experience in Data warehousing - OLTP, OLAP, Dimensions, Facts, and Data modeling. Previous experience leading an enterprise-wide Cloud Data Platform migration with strong architectural and design skills Capable of discussing enterprise level services independent of technology stack Experience with Cloud based data architectures, messaging, and analytics Superior communication skills Cloud certification(s) Any experience with Regulatory Reporting is a Plus Education Minimally a BA degree within an engineering and/or computer science discipline Master's degree strongly preferred",
        "url": "https://www.linkedin.com/jobs/view/3892872640"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3897775332,
        "company": "Federal Reserve Bank of New York",
        "title": "Data Engineer",
        "created_on": 1720636476.821341,
        "description": "Company Federal Reserve Bank of New York Working at the Federal Reserve Bank of New York positions you at the center of the financial world with a unique perspective on national and international markets and economies. You will work in an environment with a diverse group of experienced professionals to foster and support the safety, soundness, and vitality of our economic and financial systems. The Bank believes in work flexibility to balance the demands of work and life while also connecting and collaborating with our colleagues in person. Employees can expect to be in the office a couple of days per week as needed for meetings and team collaboration and should live within a commutable distance. What we do: As a member of Markets Technology Delivery supporting the Markets business domain; the area responsible for the Auctions, Trading Desks and Operations, you will contribute to financial applications and tools in support of Markets’ auctions, trading, operations planning, and execution. You will be part of an agile squad that requires close collaboration with other members of the technology team, business users, and other development team members to solve for integration, and analytics use cases. Your role as a Data Engineer: In this role you will be responsible for designing, developing, and maintaining data pipelines in support of data management functions such as data engineering, data integration and data quality and governance activities. You must be passionate about data management with a solid background in AWS, Databricks, Python, Trino/Starburst, Databases and SQL. Design, develop, monitor, and maintain data pipelines in an AWS Gov Cloud ecosystem with AWS, Databricks, Delta Lake and Trino as the underlying platforms. Collaborate with cross-functional teams to understand data needs and translate them into effective data pipeline solutions. Establish data quality checks and ensure data integrity and accuracy throughout the data lifecycle. Automate testing of the data pipelines and configure as part of CICD. Optimize data processing and query performance for large-scale datasets within AWS and Databricks environments. Document data engineering processes, architecture, and configurations. Troubleshooting and debugging data-related issues on the AWS Databricks platform. Integrating Databricks with other AWS products such as SNS, SQS, and MSK. What we are looking for: Bachelor's or master's degree in computer science, Information Technology, or a related field. Strong technical proficiency to contribute to data engineering task in an AWS and Databricks ecosystem. Strong technical proficiency with Spark, Trino, Python, PySpark and SQL Proven ability in Gitlab with CI/CD. Proven ability in AWS Services like S3, RDS, Lambda, SQS, SNS, MSK is required. Strong SQL skills to perform data analysis and understanding of source data. Proven ability with data pipeline orchestration tools Proven ability with ETL tools and Relational databases Proven ability to troubleshoot complex data issues and implement effective solutions. Proven ability in staying updated with industry trends and emerging technologies in data engineering. Salary Range: $116500 - $200400 / year We believe in transparency at the NY Fed. This salary range reflects a variety of skills and experiences candidates may bring to the job. We pay individuals along this range based on their unique backgrounds. Whether you’re stretching into the job or are a more seasoned candidate, we aim to pay competitively for your contributions . Our Touchstone Behaviors —Communicate Authentically, Collaborate Inclusively, Drive Progress, Develop Others, and Take Ownership—help shape the culture of the Bank. They also provide a shared language for how we work together and achieve success, and they set clear expectations for leading with impact at every stage of your career with us. Learn more. Benefits: Our organization offers benefits that are the best fit for you at every stage of your career: Fully paid Pension plan and 401k with Generous Match Comprehensive Insurance Plans (Medical, Dental and Vision including Flexible Spending Accounts and HSA) Subsidized Public Transportation Program Tuition Assistance Program Onsite Fitness & Wellness Center And more The New York Fed expects its employees to perform their duties with honesty, integrity, and impartiality, and without improper preferential treatment of any person. Learn more about our code of conduct and conflicts of interest rules. The Federal Reserve Bank of New York is committed to a diverse workforce and to providing equal employment opportunity to all persons without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, age, genetic information, disability, pregnancy, or military service. We value accessibility for all candidates and are happy to provide an accommodation or assistance. Please email us at ny.leaves@ny.frb.org and we’ll be glad to help. Please note, this is a dedicated e-mail box designed exclusively to assist applications with accommodation requests in relation to our recruiting process. All other inquires including the status of applications will not receive a response from this e-mail box. This is not necessarily an exhaustive list of all responsibilities, duties, performance standards or requirements, efforts, skills or working conditions associated with the job. While this is intended to be an accurate reflection of the current job, management reserves the right to revise the job or to require that other or different tasks be performed when circumstances change. This position requires access to confidential supervisory information (CSI) and/or Federal Open Market Committee (FOMC) information. Access to CSI and FOMC information is limited to U.S. citizens, lawful permanent residents, individuals who meet the definition of “protected individual” under 8 U.S.C. 1324b(a)(3), and certain other nonimmigrants. All non-U.S. citizens authorized to access CSI and/or FOMC information must sign a declaration of intent to expeditiously become a lawful permanent resident and thereafter a U.S. citizen when eligible. Full Time / Part Time Full time Regular / Temporary Regular Job Exempt (Yes / No) Yes Job Category Information Technology Work Shift First (United States of America) The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences. Privacy Notice",
        "url": "https://www.linkedin.com/jobs/view/3897775332"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3937766823,
        "company": "Ipsos North America",
        "title": "Data Engineer",
        "created_on": 1720636478.5978181,
        "description": "Job Description About the Team: Ipsos Global Data Management Tower serves as the backbone of Ipsos’ efforts to harness and integrate the power of data, globally. GDMT is tasked with the critical role of ensuring that data, one of the most valuable assets in the modern digital economy, is accurately collected, stores, processed, and analyzed to support decision-making processes, drive innovation, and maintain Ipsos’ competitive advantage on a global scale. What we are looking for: We’re looking for someone with a deep interest and expertise in data engineering and the dedication to apply that passion. We need someone with the technical expertise to expand and optimize our existing data pipeline and architecture. The ideal candidate will have experience using cloud-based platforms, like AWS and Google Cloud Services, to build and maintain serverless data pipelines to efficiently process and warehouse large scale datasets. The role also requires conscientious attention to detail, an ability to work well on a small team, and a self-starter approach to problem solving and debugging. We are seeking candidates preferably based in the LATAM region, but as a global team, we are also open to US, Canada, UK and France. Candidate must have the ability to work in Eastern and Pacific time zones. As a Data Engineer, you will: Work with the team to design, code, and test cloud-based data pipelines to process and store large-scale datasets. Develop and maintain data warehouses to efficiently store large, complex datasets in a cost-optimal manner. Ingest and assemble data from various disparate sources using a variety of tools, including SQL and Python. Work with internal/external stakeholders to identify and understand needs and project goals. Lead the migration of development code into production, providing technical assistance and guidance to refine and optimize processes. Troubleshoot and improve existing infrastructure and codebases. This might be the job for you if you have: A Bachelor’s degree (or equivalent) in statistics, computer science, or related field Strong technical communication skills Proficiency in Python & advanced working knowledge of SQL. Experience with collaboration tools (e.g. Atlassian suite) and version control systems (e.g. Git). Experience with cloud services such as AWS/Google Comfortable working in a highly collaborative, consensus-oriented environment. Prior success designing and deploying data pipelines in large-scale production environments. Strong eye for detail, ability to communicate scientific concepts both in written form and verbally, and excellent time-management skills. Large dataset manipulation. Experience in distributed storage and computing. Experience with Linux server and system administration. Ability to speak and communicate fluently in English Ability to work in EST/PST time zones If you don’t meet 100% of the requirements, we encourage all who feel they might be a fit for the opportunity to apply. We may consider a variety of backgrounds for a particular role and are also committed to considering candidates for available positions throughout our organization, not just the one you’re applying to! What’s in it for you: At Ipsos you’ll experience opportunities for Career Development, an exceptional benefits package (including generous annual leave/paid time off, healthcare plans, wellness benefits), a flexible workplace policy, and a strong collaborative culture. To find out more about all the great reasons to work at Ipsos, how we’re making an impact around the world, and more about our benefits and employee programs, please visit: https://www.ipsos.com/en-uk/vacancies-at-ipsos Commitment to Diversity Ipsos recognizes the necessity of building an inclusive culture that values each employee’s individuality and diverse perspectives. For more than 40 years, our mission has been to generate and analyze data about society, markets, brands, and behaviors to provide our clients with the insights that elevate their understanding of the world. This could not be fulfilled without Ipsos’ diverse employees who compile and analyze this data—they are the essence of who we are and what we do. We are committed to providing equal opportunity to all employees, creating an environment that promotes inclusion, and enabling employees from all walks of life to flourish. Ipsos encourages our employees to act in a respectful and responsible manner, in line with code of best practices concerning diversity and inclusion, human rights, equality, and civility for every individual. Ipsos is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or any other protected class and will not be discriminated against on the basis of disability. In accordance with NY/CO/CA/WA law in the US, the estimated base salary range for this role is $75,000 to $100,000 USD in the US. Please note that we are a global team and would welcome candidates based in Canada, UK, France and LATAM, where a different local salary range may apply. The final base salary will be determined based on several non-discriminatory factors which may include but are not limited to location, work experience, skills, knowledge, education and/or certifications. About Us Ipsos is one of the world’s largest research companies and currently the only one primarily managed by researchers, ranking as a #1 full-service research organization for four consecutive years . With over 75 different data-driven solutions, and presence in 90 markets, Ipsos brings together research, implementation, methodological, and subject-matter experts from around the world, combining thematic and technical experts to deliver top-quality research and insights. Simply speaking, we help the biggest companies solve some of their biggest problems, serving more than 5000 clients across the globe by providing research, data, and insights on their target markets. And we’re proud to share we’ve received our Great Place to Work Certification in 2022 & 2023!",
        "url": "https://www.linkedin.com/jobs/view/3937766823"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3947425117,
        "company": "DoorDash",
        "title": "Senior Software Engineer, Data Engineering",
        "created_on": 1720636480.4458148,
        "description": "About The Team Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. By implementing pipelines, data structures, and data warehouse architectures; this team serves as the foundation for decision-making at DoorDash. About The Role DoorDash is looking for a Senior Data Engineer to be a technical powerhouse to help us scale our data infrastructure, automation and tools to meet growing business needs. This is a hybrid position in New York. You're Excited About This Opportunity Because You Will… Work with business partners and stakeholders to understand data requirements Work with engineering, product teams and 3rd parties to collect required data Design, develop and implement large scale, high volume, high performance data models and pipelines for Data Lake and Data Warehouse Develop and implement data quality checks, conduct QA and implement monitoring routines Improve the reliability and scalability of our ETL processes Manage a portfolio of data products that deliver high-quality, trustworthy data Help onboard and support other engineers as they join the team We're Excited About You Because… 5+ years of professional experience 3+ years experience working in data engineering, business intelligence, or a similar role Proficiency in programming languages such as Python/Java 3+ years of experience in ETL orchestration and workflow management tools like Airflow, Flink, Oozie and Azkaban using AWS/GCP Expert in Database fundamentals, SQL and distributed computing 3+ years of experience with the Distributed data/similar ecosystem (Spark, Hive, Druid, Presto) and streaming technologies such as Kafka/Flink. Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms Excellent communication skills and experience working with technical and non-technical teams Knowledge of reporting tools such as Tableau, Superset and Looker Comfortable working in fast paced environment, self starter and self organizing Ability to think strategically, analyze and interpret market and consumer information You must be located near one of our engineering hubs indicated above About DoorDash At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more. Our Commitment to Diversity and Inclusion We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel. Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on \"protected categories,\" we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination. Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation. If you need any accommodations, please inform your recruiting contact upon initial connection. Compensation The location-specific base salary range for this position is listed below. Compensation in other geographies may vary. Actual compensation within the pay range will be decided based on factors including, but not limited to, skills, prior relevant experience, and specific work location. For roles that are available to be filled remotely, base salary is localized according to employee work location. Please discuss your intended work location with your recruiter for more information. DoorDash cares about you and your overall well-being, and that's why we offer a comprehensive benefits package, for full-time employees, that includes healthcare benefits, a 401(k) plan including an employer match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid time off, paid parental leave, and several paid holidays, among others. In addition to base salary, the compensation package for this role also includes opportunities for equity grants. We use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on August 21, 2023. Please see the independent bias audit report covering our use of Covey here. New York Pay Range: $170,600—$255,800 USD",
        "url": "https://www.linkedin.com/jobs/view/3947425117"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888464236,
        "company": "Zortech Solutions",
        "title": "Big Data Engineer",
        "created_on": 1720636482.3045635,
        "description": "Role: Big Data Engineer Location: Remote/USA Duration: 6-12+ Months Job Description BS degree in computer science, computer engineering or equivalent 5 6 years of experience delivering enterprise software solutions Proficient in Spark, Scala, Python, AWS Cloud technologies 3+ years of experience across multiple Hadoop / Spark technologies such as Hadoop, MapReduce, HDFS, HBase, Hive, Flume, Sqoop, Kafka, Scala Flair for data, schema, data model, how to bring efficiency in big data related life cycle Must be able to quickly understand technical and business requirements and can translate them into technical implementations Experience with Agile Development methodologies Experience with data ingestion and transformation Solid understanding of secure application development methodologies Experienced in developing microservices using spring framework is a plus Experience in with Airflow and Python will be preferred Understanding of automated QA needs related to Big data Strong object-oriented design and analysis skills Excellent written and verbal communication skills Responsibilities Utilize your software engineering skills including Java, Spark, Python, Scala to analyze disparate, complex systems and collaboratively design new products and services Integrate new data sources and tools Implement scalable and reliable distributed data replication strategies Ability to mentor and provide direction in architecture and design to onsite/offshore developers Collaborate with other teams to design and develop and deploy data tools that support both operations and product use cases Perform analysis of large data sets using components from the Hadoop ecosystem Own product features from the development, testing through to production deployment Evaluate big data technologies and prototype solutions to improve our data processing architecture Automate everything",
        "url": "https://www.linkedin.com/jobs/view/3888464236"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3965813663,
        "company": "Zortech Solutions",
        "title": "AWS DE-Data Engineer - US",
        "created_on": 1720636484.1672924,
        "description": "Role: AWS DE-Data Engineer Location: NY preference, remote is also fine Duration: Fulltime Job Description Experience Level: 8 to 14 Must Have AWS Cloud, SQL, Data Engineering, Python",
        "url": "https://www.linkedin.com/jobs/view/3965813663"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3932467944,
        "company": "Quest Partners LLC",
        "title": "Quantitative Data Developer",
        "created_on": 1720636486.135299,
        "description": "About The Role Quest Partners is seeking a Quantitative Data Developer for our Research Technology team. This is a computationally intensive role that will allow you to utilize your software engineering, data engineering, analysis and technology skills. You will enhance, refine, and evolve the research platform which includes the data platform, the foundational technology infrastructure, and the core backtesting engine. Duties And Responsibilities Onboard data by working with different sources/stores of data (OneTick, CQG, ICE, Bloomberg, Refinitiv, etc.). Setup robust, performant, and resilient data workflows from ingesting data to creating enriched datasets for research. Engineer ETL frameworks with cutting-edge technologies such as Snowflake, Airflow, Apache Spark, Python etc. to enhance the foundational technology infrastructure of the firm. Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Enhance the research platform by creating/deploying CICD methodologies to deploy the full stack from data to trading strategies. Work on improving the backtesting engine by adding research specific features and reducing latency etc. Experience: Bachelors, Masters or PhD in Computer Science, Engineering, Mathematics, Statistics; or equivalent experience 1+ years of experience working with large amounts of financial data (ideally FX or Futures) Passion for the financial markets Knowledge of Algorithms and Data Structures. Advanced working SQL knowledge and experience working with relational databases. Proficient in SQL, Python and any OOPL (e.g. C#) Knowledge about industry best practices in CI/CD and leveraging AWS cloud technologies to build solutions. Knowledge building and optimizing 'big data' data pipelines, architectures and data sets. Strong analytical skills related to working with unstructured datasets. Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores. Should be organized, detail-oriented, and comfortable managing multiple work streams. The base range for this role is expected to be between $150,000 and $250,000. This does not include other aspects of compensation such as discretionary bonus and a competitive comprehensive benefits package. Actual compensation offered to a candidate will vary within the range above depending on factors such as qualifications, education, and skill level. By submitting the application, you are consenting to Quest Partners LLC using your mobile phone number for SMS messaging. About The Firm Quest is a quantitative investment advisor based in New York with over forty professionals and approximately $2.5 billion in assets under management as of May 31st, 2024. Quest was founded by Nigol Koulajian in March 2001 to pursue the development of specialized quantitative investment strategies with a focus on convexity. Quest’s strategies seek to generate attractive absolute returns with significant positive skew while maintaining strong hedging characteristics particularly during tail events that may cause surprise losses in hedge fund and equity portfolios. The firm currently manages assets for some of the world’s leading pension plans, family offices, fund-of-funds, foundations, and other institutional investors.",
        "url": "https://www.linkedin.com/jobs/view/3932467944"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3942867431,
        "company": "Lyft",
        "title": "Software Engineer, Data Platform",
        "created_on": 1720636489.7845101,
        "description": "At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization. We are seeking a talented Software Engineer to join our dynamic Streaming Compute Team. In this role, you'll be instrumental in designing, developing, and maintaining our low latency and high throughput systems, which are critical to a lot of teams like driver, mapping, fraud etc. and almost all ML models at Lyft. Our systems and platform are used to create, store and serve ML features for training and inference purposes for teams like payments, incentives etc. The majority of our streaming solutions run on Apache Flink and Apache Beam with support from reading and writing to various sources and sinks respectively. As a Software Engineer, with your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance the platform offerings. Your work will have a major impact on several areas of the business. We are looking for candidates who are self starters and have a proven track record of delivering software solutions that can solve critical business needs. The candidate should be able to dive deep into any problems with lots of ambiguity and build a technical solution to solve it. They should be willing to take ownership of a project or a feature and be able to drive it from design to implementation. Responsibilities: Design, develop, deploy, monitor, operate and maintain scalable and robust systems to support ML feature storage and retrieval Work with technologies such as Redis, dynamoDB, OpenSearch etc. to enhance our data platform's capabilities Collaborate with cross-functional teams to integrate feature service solutions into the broader data architecture Analyze our internal systems and processes and locate areas for improvement/automation Collaborate with product org stakeholders to address and prioritize custom edge cases Help lead large projects from inception to positive execution Experience: 5+ years of experience with building, deploying and maintaining low latency, high throughput services 5+ years of experience building and developing large-scale infrastructure, distributed systems or networks, and/or experience with compute technologies 3+ years of software engineering industry experience and with distributed streaming solutions like Apache Flink, Apache Samza, Spark streaming etc. 3+ years of software engineering industry experience and with storage technologies like DynamoDB, Redis, Open Search etc. 2+ years of experience working with ML feature stores and/or feature services Experience working with kubernetes and container technologies (e.g. Docker, cri-o, etc)Familiar with a cloud-based environments such as AWS/GCP/Azure Benefits: Great medical, dental, and vision insurance options Mental health benefits Family building benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid The expected base pay range for this position in the New York City area is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",
        "url": "https://www.linkedin.com/jobs/view/3942867431"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3943846769,
        "company": "TechTammina LLC",
        "title": "Senior GCP Data Engineers",
        "created_on": 1720636491.5872474,
        "description": "New York Summary The ideal candidate should have extensive experience in IT and data engineering, particularly with GCP in the financial sector. They should be proficient in managing and optimizing data storage, ensuring data security, and using Python and SQL for data manipulation. They must also have a strong background in distributed data processing frameworks and collaboration skills to work with various teams. Project Type The project involves designing, developing, and maintaining data pipelines on Google Cloud Platform (GCP). The focus is on transforming raw data into valuable insights. The candidate will be working on data ingestion, transformation, and storage optimization. Emphasis on data security and access control. Experience 12+ years of IT experience. 4+ years of recent experience with a major bank or brokerage house in the US. 8+ years as a Data Engineer. 5+ years with GCP. Specific experience with GCP services like Dataflow, Dataproc, Pub/Sub, GCS, BigQuery, Cloud Storage, and Dataflow. Experience in data storage management and optimization with BigQuery, Cloud Storage, and Cloud SQL. Implementation of data security and access controls using GCP IAM and Cloud Security Command Center. Data manipulation and querying using Python and SQL. Distributed data processing with Apache Beam and Apache Spark. Skills GCP services: Dataflow, Dataproc, Pub/Sub, GCS, BigQuery, Cloud Storage, Cloud SQL. Data security and access control principles. Python & SQL for data manipulation and querying. Apache Beam and Apache Spark. Monitoring and troubleshooting with GCP's Stackdriver and Cloud Monitoring tools. Automation of data processing tasks using scripting languages like Python. Strong collaboration skills to work with data experts, analysts, and product teams.",
        "url": "https://www.linkedin.com/jobs/view/3943846769"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3966792791,
        "company": "Mavinsys",
        "title": "Sr. Data Engineer",
        "created_on": 1720636493.3727605,
        "description": "Hello, We are from Mavinsys Talent Acquisition team based on One World Trade Centre, New York. We are specializing in IT services and staffing majorly in lateral hiring/contract. Below is one of our requirement to fill immediately, if you're interested, please share your candidature to joinus@mavinsys.com Job Title: Sr. Data Engineer Location: New York, NY Duration: 12months Job Description; A result-oriented Professional with 8+ years of experience in Big Data development along with Data administration and proposing effective solutions through an analytical approach with a track record of building large-scale systems using Big Data technologies. Proficient in cloud platforms such as Microsoft Azure and AWS, harnessing their capabilities for scalable and secure data storage and processing. Expertise in diverse data processing frameworks including Spark, Apache Flink, Apache NiFi, and Apache MapReduce, ensuring efficient data manipulation and analysis. Excellence in using Use Apache Hadoop to work with Big Data and analyse large data sets. Hands-on experience in ecosystems like Hive, Sqoop, MapReduce, Flume, and Oozie. Proficient in containerization strategies leveraging Azure Containers and Kubernetes, enhancing deployment and scalability of application. Work with Data Lakes and Big Data ecosystems (Hadoop, Spark, Hortonworks, Cloudera). Track record of results in an Agile methodology using data-driven analytics. Load and transform large sets of structured, semi-structured, and unstructured data working with data on Amazon Redshift, Apache Cassandra, and HDFS in Hadoop Data Lake. Proficient in managing databases such as Microsoft SQL Server and NoSQL (Cassandra) to ensure effective data organization and accessibility. Skilled with BI tools like Tableau and Power BI, data interpretation, modelling, data analysis, and reporting with the ability to assist in directing planning based on insights. Skilled in HDFS, Spark, Hive, Sqoop, HBase, Flume, Oozie, and Zookeeper Strong scripting skills in SQL, Python, and Scala, facilitating the development of efficient data pipelines and analytics workflows. Apply in-depth understanding/knowledge of Hadoop architectures and various components such as HDFS, MapReduce, Spark, and Hive. Create Spark Core ETL processes to automate using a workflow scheduler. Proficiency in reporting tools like SSRS for generating comprehensive and visually appealing reports. Experienced in utilizing various data-related technologies including Apache Kafka, Apache Beam, Apache Avro, Airflow, Snowflake, SSMS, ERD, Azure ADLS, and Trifacta to optimize data workflows and analytics processes. Gained experience in applying techniques to live data streams from big data sources using Spark and Scala.",
        "url": "https://www.linkedin.com/jobs/view/3966792791"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3837056413,
        "company": "Shaped",
        "title": "Senior Data Engineer",
        "created_on": 1720636495.096041,
        "description": "We are looking for a data engineer to design, build and optimize Shaped's real-time and batch streaming infrastructure. You will be a founding engineer working to reliably ingest customer data (both with batch and real-time processing) into our our state-of-the-art AI discovery engine. As one of Shaped’s early employees you will help shape our product, culture and vision. Skills should include Python, Data Warehouses (such as Clickhouse, Snowflake, or BigQuery) Nice-to-have skills should include DBT, Meltano, Airflow, and Apache Flink (or other stream processing frameworks) We’re excited to work with you. Come build the future of AI with us!",
        "url": "https://www.linkedin.com/jobs/view/3837056413"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3871945229,
        "company": "Arrow Search Partners",
        "title": "Senior Data Engineer",
        "created_on": 1720636498.8459227,
        "description": "About The Company Our client is a leading alternative investment firm with over $160 billion in AUM. The firm invests in credit, fixed income, venture capital, and real estate companies. The Senior Data Engineer will be responsible for the technical design, implementation, support and maintenance of the firm’s SQL/NoSQL database assets and the data ingestion and integration processes. Responsibilities Develop and support on-premise and cloud based data ingestion and processing infrastructure Provide enhancements and support for existing BI platforms, data warehouse, and data pipelines Perform architecture and code reviews of work performed by on and offshore resources to ensure secure quality deliverables Work with cloud migration team, information security, and BA’s to build out new applications, and migrate existing applications to external cloud Help create and execute on a technical strategic roadmap for leveraging new streaming data technologies to generate accurate and timely insights for our investment professionals Requirements Bachelor’s degree required 7-10 years of experience developing software application Experiencing with Python, C#, and Java Experience working with and creating medium-to-large scale data architectures Experience with Kafka, Flink, Spark Streaming, Kafka streams is a plus Proficient with current web scraping technologies Salary Range $150,000-$350,000",
        "url": "https://www.linkedin.com/jobs/view/3871945229"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Manhattan, NY",
        "job_id": 3953744566,
        "company": "MedReview Inc.",
        "title": "System Engineer",
        "created_on": 1720636500.5681674,
        "description": "Working Conditions : Full time (M-F), Office Business Settings. This is an On-Premises position. Monday through Thursday (9-5) and remote on Fridays only (No exceptions). Position Summary –The System Engineer is responsible for the day-to-day operation and maintenance of Servers and infrastructure systems that are located on premise and in the cloud. The System Engineer fulfills responsibilities in some or all of the following technical areas: Azure, Servers maintenance, Systems upgrades and procurement, infrastructure design and layout, Disaster Recovery design and implementation, OS installation and maintenance, management of system tools and applications, Active Directory services. The System Engineer is also tasked with deploying best practices for helping with securing information as well as platforms in the infrastructure. Job Responsibilities : This list does not represent all responsibilities for this position. Candidate must be willing and able to assume roles and responsibilities other than these to meet the needs of the organization. (3 -5 years in the following): Administration of company’s Servers and digital infrastructure including management of network operating systems, servers, Cisco UCS , SAN’s, VMWare, V-Sphere, Windows, File and print services, Domain controllers, Automation, Office 365, Azure, Active Directory, monitoring and reporting, Data center capacity management and planning, Disaster recovery, backups, and recovery. Very strong Azure experience. Responds to events, incidents, and outages with required as needed and under the direction of the Director of IT, and in coordination with the technology leadership team. Assist in the development, implementation and maintenance of policies, procedures, and associated training plans. Perform regular backup operations and implement appropriate processes for data protection, Disaster recovery, and failover procedures. Working knowledge of common services: DNS, SMTP, DHCP, HTTP, etc. Handles support tickets for issues and outages with Servers’ Issues, cloud providers, virtual environment, etc. Working knowledge of Mimecast or similar experience for spam filtering, encryption, DLP, etc. Windows Administration (Active Directory, Scripting, DNS, Group Policy’s). Plan for GPO policy upgrades to secure business operations (Active Directory). Adhere to best practices of securing currently used applications and platforms (MFA). Participate in internal and external audits (HiTrust). Required Experience: Four-year degree or higher in Information Systems, or related field or equivalent combination of work experience. Ability to perform under stress. Collaborative \\ Team player \\ Dependable. Strong Written and verbal communication skills. Planning and organizational skills \\ Attention to detail. Customer-service oriented mindset. Previous system engineering experience is a must. Advanced understanding of infrastructure. Azure, Clouds, Active Directory, Windows desktop/server OS, VMware, storage systems, DNS is a must Working knowledge of various Identity and Access management systems a plus. Advanced understanding of protocols. WMI, SNMP, TLS, SSL, SMB. Advanced understanding of securing systems and platforms through device/policy hardening. Ability to communicate technical information in a clear manner, both written and verbally, to end users. Proficient knowledge of MS Outlook, O365, Word, Excel, Visio, and PowerPoint. Experience with HIPAA, HITRUST, HITECH, PCI, ISO 27001, ISO 27002, URAC regulations and awareness and/or experience with CMS, NIST and other healthcare industry related regulations a plus. Knowledge of Veeam Backup tool, Netwrix, HPE Storage, Zscaler, Virtual Desktops, SharePoint a plus. Availability to work nights and weekends during (un)planned outages and other special circumstances, with 24/7 accountability. Availability to enter on call rotation. Ability to lift 50 lbs. Benefits and perks include: Healthcare that fits your needs - We offer excellent medical, dental, and vision plan options that provide coverage to employees and dependents. 401(k) with Employer Match - Join the team and we will invest in your future Generous Paid Time Off - Accrued PTO starting day one, plus additional days off when you’re not feeling well, to observe holidays. Wellness - We care about your well-being. From Commuter Benefits to FSAs we’ve got you covered. Learning & Development - Through continued education/mentorship on the job and our investment in LinkedIn Learning, we’re focused on your growth as a working professional. Salary: $135k-145k",
        "url": "https://www.linkedin.com/jobs/view/3953744566"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3958007035,
        "company": "Rightway",
        "title": "Data Engineer III",
        "created_on": 1720636502.437794,
        "description": "ABOUT THE ROLE: We are seeking a full-time Data Engineer III to join our team and define and deploy mission-critical data infrastructure. The primary responsibility for this role is defining the processing of large healthcare datasets, which enable Rightway to generate insights that improve the health of more than 1 million members. Leveraging your expertise in the AWS ecosystem and proficiency in writing production-ready Python code, you will play a significant role in our data operations. While familiarity with medical data is beneficial, it's not a requisite for this role. WHAT YOU'LL DO: Write production-level Python and SQL code. Utilize AWS services such as Lambda, Glue, and Fargate for data operations. Build and maintain large-scale data pipelines using Apache Airflow. Oversee the maintenance of Extract, Load, and Transform (ELT) processes using DBT. WHO YOU ARE: Bachelor's degree in Computer Science, Engineering, or a related field, or equivalent work experience. 5+ years of industry experience as a data engineer. Skilled in working with AWS systems in a production environment. Proficient in writing SQL and Python code in a production environment. EXTRA CREDIT: Experience working with medical and pharmacy claims data. Knowledge in deploying applications using serverless architecture. Hands-on experience managing AWS services such as Lambda, Glue, and Fargate. Experience with Master Data Management and data governance. BASE SALARY: $164,000 CYBERSECURITY AWARENESS NOTICE In response to ongoing and industry-wide fraudulent recruitment activities (i.e., job scams), Rightway wants to inform potential candidates that we will only contact them from the @rightwayhealthcare.com email domain. We will never ask for bank details or deposits of any kind as a condition of employment. If you have any questions about a suspicious interaction with Rightway, please feel free to reach out to us at hr@rightwayhealthcare.com. ABOUT RIGHTWAY: Rightway is on a mission to harmonize healthcare for everyone, everywhere. Our products guide patients to the best care and medications by inserting clinicians and pharmacists into a patient's care journey through a modern, mobile app. Rightway is a front door to healthcare, giving patients the tools they need along with on-demand access to Rightway health guides, human experts that answer their questions and manage the frustrating parts of healthcare for them. Since its founding in 2017, Rightway has raised over $130mm from investors including Khosla Ventures, Thrive Capital, and Tiger Global at a valuation of $1 billion. We're headquartered in New York City, with a satellite office in Denver. Our clients rely on us to transform the healthcare experience, improve outcomes for their teams, and decrease their healthcare costs. HOW WE LIVE OUR VALUES TO OUR TEAMMATES: We're seeking those with passion for healthcare and relentless devotion to our goal. We need team members who will: We are human first Our humanity binds us together. We bring the same empathetic approach to every individual we engage with, whether it be our members, our clients, or each other. We are all worthy of respect and understanding and we engage in our interactions with care and intention. We honor our stories. We listen to—and hear—each other, we celebrate our differences and similarities, we are present for each other, and we strive for mutual understanding. We redefine what is possible We always look beyond the obstacles in front of us to imagine new solutions. We approach our work with inspiration from other industries, other leaders, and other challenges. We use ingenuity and resourcefulness when faced with tough problems. We debate then commit We believe that a spirit of open discourse is part of a healthy culture. We understand and appreciate different perspectives and we challenge our assumptions. When working toward a decision or a new solution, we actively listen to one another, approach it with a \"yes, and\" mentality, and assume positive intent. Once a decision is made, we align and champion it as one team. We cultivate grit Changing healthcare doesn't happen overnight. We reflect and learn from challenges and approach the future with a determination to strive for better. In the face of daunting situations, we value persistence. We embrace failure as a stepping stone to future success. On this journey, we seek to act with guts, resilience, initiative, and tenacity. We seek to delight Healthcare is complicated and personal. We work tirelessly to meet the goals of our clients while also delivering the best experience to our members. We recognize that no matter the role or team, we each play a crucial part in our members' care and take that responsibility seriously. When faced with an obstacle, we are kind, respectful, and solution-oriented in our approach. We hold ourselves accountable to our clients and our members' success. Rightway is a healthcare company looking to improve healthcare outcomes for everyone, everywhere. With that in mind, we have to consider what is good for the health of our team, the company, and the communities we operate in. As such, Rightway has determined a mandatory COVID-19 vaccination policy for all employees , in combination with other safety precautions, is the best way forward. Rightway is PROUDLY an Equal Opportunity Employer that believes in strength in the diversity of thought processes, beliefs, background and education and fosters an inclusive culture where differences are celebrated to drive the best business decisions possible. We do not discriminate on any basis covered by appropriate law. All employment is decided on the consideration of merit, qualifications, need and performance.",
        "url": "https://www.linkedin.com/jobs/view/3958007035"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3899605480,
        "company": "Steneral Consulting",
        "title": "Hybrid Work - Need Data Warehouse / Informatica ETL Engineer in NYC NY",
        "created_on": 1720636504.1331224,
        "description": "Informatica ETL Engineer Position: Informatica Developer/Engineer Location: Hybrid work: NYC 3 days a week in office : Tuesday- Thursday and 2 from home. Must be local to NYC area. NO EXCEPTIONS Work Status: USC or GC candidates, as this will be a right to hire position Duration: 6 month + consultant to hire opportunity. Interview : First interview Zoom. Second Interview in office -mandatory, Description month CONTRACT TO HIRE POSITION!! GC or US Citizen Preferred Tuesday through Thursday in NYC Office and WFH Monday and Friday -local only Our client located in midtown NYC is looking for a savvy ETL Informatica developer to join their team of Database/Informatica Engineer/Architect to develop strategic ETL and data quality builds. Key Technologies Are Informatica PowerCenter MySQL/SQL Server, T-SQL Unix shell scripting DB Modeling Control-M Scheduling tool Position will assume design/architecture/development builds At least 3 years’ experience designing your ETL Informatica PowerCenter processes, preferably as a senior member of a team At least 8 years’ experience developing ETL processes At least 8 years of hands on use of Informatica PowerCenter Tools Expert SQL skills T-SQL experience. Experience with designing/building/supporting ETL error handling conditions/validations Linux and Ruby scripting experience is plus BS in Computer, Information Sciences or STEM Excellent communication skills",
        "url": "https://www.linkedin.com/jobs/view/3899605480"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911879397,
        "company": "Unreal Staffing, Inc",
        "title": "Software Engineer",
        "created_on": 1720636505.8706863,
        "description": "About The Job We're on the lookout for a motivated and visionary Software Engineer to join our dynamic team in New York City. This isn't just a typical job; it's an opportunity to shape the future of business intelligence from the ground up. As a Founding Engineer at our company, you'll play a pivotal role in leading the development of essential systems, tackling challenging data problems, and leveraging cutting-edge AI technologies. Requirements Key Responsibilities: Spearhead the full-stack development of critical product features Architect scalable systems and deliver high-quality code Engage directly with enterprise clients to comprehend and address their requirements Collaborate closely with our founders - Mike, Vivek, and Ron - to drive our vision, strategy, and roadmap Participate in spirited discussions about our aspirations for global impact and the finer details of emoji usage on our landing page We're seeking: Demonstrated experience in leading software projects within a team environment Proficiency in Python and SQL, with a solid grasp of production cloud environments (such as AWS) Self-starters who thrive in fast-paced, dynamic environments and contribute positively to our culture Bonus points for experience leading engineering teams, familiarity with Django, Pandas, machine learning, and React, among others Benefits What we Offer: Joining us means more than just a job; it's a commitment to living well. We ensure competitive benefits to support your needs and aspirations, including: A competitive salary and equity package, reflecting your pivotal role in our early growth Comprehensive health, dental, and vision insurance Unlimited PTO to recharge and rejuvenate Access to any WeWork location for a conducive work environment Opportunities for professional growth through mentorship, online courses, and top-tier conferences like Google I/O and Salesforce Dreamforce Salary Range: $140,000 - $170,000 annually,",
        "url": "https://www.linkedin.com/jobs/view/3911879397"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brookville, NY",
        "job_id": 3834675546,
        "company": "Abidi Solutions",
        "title": "Senior Big Data Engineer",
        "created_on": 1720636507.9928975,
        "description": "Job Title: Senior Big Data Engineer Location: [New York , United State] Responsibilities Design, develop, and maintain scalable and robust Big Data solutions. Collaborate with cross-functional teams to understand business requirements and translate them into technical specifications. Implement and optimize data pipelines, data integrations, and data storage solutions. Perform data analysis to identify trends, patterns, and insights that drive informed business decisions. Ensure the security, integrity, and performance of Big Data platforms. Qualifications Bachelor's or Master's degree in Computer Science, Information Technology, or related field. Proven experience (X+ years) as a Big Data Engineer in a senior role. Proficient in programming languages such as Java, Scala, or Python. Strong expertise in Big Data technologies, including Hadoop, Spark, and Kafka. Experience with data modeling, ETL processes, and data warehousing. Familiarity with cloud platforms, such as AWS, Azure, or GCP. Excellent problem-solving and communication skills. Preferred Skills Certification in Big Data technologies. Experience with containerization and orchestration tools (e.g., Docker, Kubernetes). Knowledge of machine learning concepts and frameworks.",
        "url": "https://www.linkedin.com/jobs/view/3834675546"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3942862406,
        "company": "Garner Health",
        "title": "Senior Data Engineer",
        "created_on": 1720636509.5696151,
        "description": "Garner's mission is to transform the healthcare economy, delivering high quality and affordable care for all. By helping employers restructure their healthcare benefit to provide clear incentives and data-driven insights, we direct employees to higher quality and lower cost healthcare providers. The result is that patients get better health outcomes while doctors are rewarded for practicing well, not performing more procedures. We are backed by top-tier venture capital firms, are growing rapidly and looking to expand our team. We are looking for a Senior Data Engineer with a high sense of ownership who is excited about our mission, eager to learn and teach others, and can deliver across the tech stack. The ideal candidate should have experience with a modern data stack and implementations of data pipelines using Python in AWS. This position can be fully remote or on-site (NYC). Main Responsibilities: Build, optimize, and maintain data pipelines that power our business Define and build out abstracted reusable data sets to be used for Business Intelligence, Marketing, and Data Science Research Design, build, and evangelize a federated data validation framework to be used to monitor potential data inconsistencies Protect our users' privacy and security through best practices Our Tools: Postgres, Snowflake, Python, AWS, NATS, Terraform, Argo, Stitch, DBT, ElasticSearch, Looker Ideal Qualifications: 5+ years of software/data engineering experience (distributed data processing, data warehousing, data governance, Big Data, data variance, data privacy, and data quality). Expertise in SQL, familiarity with Python Expertise in building scalable data pipelines, query optimization, PostgreSQL tuning (nice to have), data modeling, and defining reusable datasets Experience working with orchestration tools (especially Argo), databases (especially PostgreSQL), data warehouses (especially Snowflake) Familiarity with distributed event-driven architectures. NATS experience is a plus. Familiarity with healthcare or insurance Able to learn quickly and mentor others Why You Should Join Our Team: You are mission-driven, have a high sense of ownership, and want to work at a company that can change the healthcare system You want to be on a small, fast-paced team that nimbly moves to meet new challenges You are not afraid of challenges and love to learn You design and optimize for the long term while moving fast and iteratively delivering for the short term You love ideating on new features and working with data to find new insights You're excited about researching and working with the latest tools and technologies The target salary range for this position is $155K to 190K annually. Individual compensation for this role will depend on a variety of factors including qualifications, skills and applicable laws. In addition to base compensation, this role is eligible to participate in our equity incentive and competitive benefits plans. Garner Health is proud to be an Equal Employment Opportunity employer and values diversity in the workplace. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. Garner Health is committed to providing accommodations for qualified individuals with disabilities in our recruiting process. If you need assistance or an accommodation due to a disability, you may contact us at talent@getgarner.com. Beware of job scam fraudsters! Our recruiters use getgarner.com email addresses exclusively. We do not post open roles on Indeed, conduct interviews via text, instant message, or Teams and we do not ask candidates to download software, purchase equipment through us, or to provide sensitive information such as bank account or social security numbers. If you have been contacted by someone claiming to be a Garner recruiter or hiring manager from a different domain about a job offer, please report it as potential job fraud to law enforcement here and to candidateprotection@getgarner.com",
        "url": "https://www.linkedin.com/jobs/view/3942862406"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3922481356,
        "company": "HCL Global Systems Inc",
        "title": "Data Engineer",
        "created_on": 1720636516.114081,
        "description": "What We Are Looking For Experienced Data Engineer: We need an experienced data engineer with a proven track record of driving product success from an engineering perspective. We are looking for someone who has strong experience in building scalable and reliable data pipelines using Databricks and Spark. You will be working with various data sources and formats, and transforming them into valuable insights for our business. Cultural Fit: Join our collaborative, respectful, and intellectually curious team. We are persistent problem solvers, communicative, results-driven, and positivebringing accountability and ownership to everything we do. Holistic Learning: Dive into the intricacies of our platform, mastering its ins and outs. Strategic Contributions: Design, develop, and maintain data pipelines using Databricks and Spark, and other cloud technologies as needed. Hands-On Contribution: Tackle challenging tasks as a hands-on contributor, ensuring a seamless transition between various facets of this dynamic role throughout the workday. Optimize data pipelines for performance, scalability, and reliability. Ensure data quality and integrity throughout the data lifecycle. Collaborate with data scientists, analysts, and other stakeholders to understand and meet their data needs. Troubleshoot and resolve data-related issues, and provide root cause analysis and recommendations. Document data pipeline specifications, requirements, and enhancements, and communicate them effectively to the team and management. Create new data validation methods and data analysis tools, and share best practices and learnings with the data engineering community. Implement ETL processes and data warehouse solutions, and ensure compliance with data governance and security policies. = Required Qualifications Bachelor's degree in Computer Science, Engineering, or related field, or equivalent work experience. Strong background in Computer Science fundamentals including: algorithms, data structures, computational complexity, distributed computing. 5+ years of experience in data engineering, preferably with Databricks and Spark. Proficient in SQL and Python, and familiar with Java or Scala. Experience with cloud platforms, preferably Azure. Experience with data warehouse and data lake concepts and architectures. Experience with data integration and ETL tools, preferably Azure Data Factory. Strong analytical and problem-solving skills. Excellent communication and teamwork skills. Nice-to-Have Experience with big data technologies, such as Kafka, Hadoop, Hive, etc. Experience with data visualization and reporting tools, preferably Tableau. High-Performance Culture Be a key player in our high-performing team, surrounded by intellectual minds eager to collaborate and learn from each other. Key Contributions Be a key contributor on one of top-priority initiatives, backed by strong senior management support. The platform is already making waves, and now it's your chance to steer it to new heights. Visible Impact Make your mark by driving the platform forward, contributing to its success and widespread adoption",
        "url": "https://www.linkedin.com/jobs/view/3922481356"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3901997419,
        "company": "HCL Global Systems Inc",
        "title": "Data Engineer",
        "created_on": 1720636517.802358,
        "description": "High-Performance Culture: Be a key player in our high-performing team, surrounded by intellectual minds eager to collaborate and learn from each other. Key Contributions: Be a key contributor on one of top-priority initiatives, backed by strong senior management support. The platform is already making waves, and now it & your chance to steer it to new heights. Visible Impact: Make your mark by driving the platform forward, contributing to its success and widespread adoption. What We Are Looking For Experienced Data Engineer: We need an experienced data engineer with a proven track record of driving product success from an engineering perspective. We are looking for someone who has strong experience in building scalable and reliable data pipelines using Databricks and Spark. You will be working with various data sources and formats, and transforming them into valuable insights for our business Cultural Fit: Join our collaborative, respectful, and intellectually curious team. We are persistent problem solvers, communicative, results-driven, and positive—bringing accountability and ownership to everything we do. Your Role Holistic Learning: Dive into the intricacies of our platform, mastering its ins and outs. Strategic Contributions: Design, develop, and maintain data pipelines using Databricks and Spark, and other cloud technologies as needed Hands-On Contribution: Tackle challenging tasks as a hands-on contributor, ensuring a seamless transition between various facets of this dynamic role throughout the workday. Optimize data pipelines for performance, scalability, and reliability Ensure data quality and integrity throughout the data lifecycle Collaborate with data scientists, analysts, and other stakeholders to understand and meet their data needs Troubleshoot and resolve data-related issues, and provide root cause analysis and recommendations Document data pipeline specifications, requirements, and enhancements, and communicate them effectively to the team and management Create new data validation methods and data analysis tools, and share best practices and learnings with the data engineering community Implement ETL processes and data warehouse solutions, and ensure compliance with data governance and security policies NY-based (min. 2 days in office each week: Tuesday plus one other day) Required Qualifications Bachelor's degree in Computer Science, Engineering, or related field, or equivalent work Experience Strong background in Computer Science fundamentals including: algorithms, data structures, computational complexity, distributed computing 5+ years of experience in data engineering, preferably with Databricks and Spark Proficient in SQL and Python, and familiar with Java or Scala Experience with cloud platforms, preferably Azure Experience with data warehouse and data lake concepts and architectures Experience with data integration and ETL tools, preferably Azure Data Factory Strong analytical and problem-solving skills Excellent communication and teamwork skills Nice-to-Have Experience with big data technologies, such as Kafka, Hadoop, Hive, etc. Experience with data visualization and reporting tools, preferably Tableau",
        "url": "https://www.linkedin.com/jobs/view/3901997419"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963432800,
        "company": "Accord Technologies Inc",
        "title": "Lead AWS Data Engineer",
        "created_on": 1720636519.3960752,
        "description": "Job Summary We are looking for an experienced Data Visualization and Migration Specialist with a strong background in AWS QuickSight, AWS Redshift, and Amazon Q. The ideal candidate will have a proven track record of working with data visualization tools, as well as extensive experience in data migration activities, specifically moving data from on-premises data stores to Amazon Redshift. Key Responsibilities Design, develop, and maintain interactive dashboards and reports using AWS QuickSight. Leverage Amazon Q for natural language query capabilities to enhance data accessibility and usability. Manage and optimize AWS Redshift data warehouses, ensuring data integrity and performance. Conduct data migration from on-premises data stores to AWS Redshift, including planning, execution, and validation. Collaborate with cross-functional teams to understand business requirements and translate them into effective data visualizations and reporting solutions. Implement best practices for data management, data quality, and data governance. Troubleshoot and resolve issues related to data visualization and data migration. Provide training and support to end-users on using AWS QuickSight and Amazon Q. Stay updated with the latest trends and technologies in data visualization and data migration. Required Qualifications Bachelor’s degree in Computer Science, Information Systems, Data Science, or a related field. 4-5 years of experience working with data visualization tools, specifically AWS QuickSight. Strong expertise in AWS Redshift, including data warehousing and performance optimization. Experience with Amazon Q for enhancing data accessibility. Proven experience with data migration activities, particularly moving data from on-premises data stores to Amazon Redshift. Proficient in SQL and database management. Strong analytical and problem-solving skills. Excellent communication and collaboration skills. Ability to work independently and manage multiple projects simultaneously. Preferred Qualifications AWS Certification in any of the following: AWS Certified Solutions Architect, AWS Certified Data Analytics, AWS Certified Big Data. Experience with other data visualization tools like Tableau or Power BI. Knowledge of ETL processes and tools.",
        "url": "https://www.linkedin.com/jobs/view/3963432800"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3520074039,
        "company": "Cherre",
        "title": "Senior Data Engineer",
        "created_on": 1720636521.0722766,
        "description": "Cherre is the real estate industry's leading data management platform, powering more than $3 trillion AUM globally. Our end-to-end platform helps clients connect, transform, analyze, and act on trusted data to increase efficiencies, reduce risks, gain visibility into market trends, and make strategic moves in response to changing market conditions. Cherre is looking for an enthusiastic Senior Data Engineer who is interested in working with a fast-growing team in building industry-leading real estate data services. You will be part of designing and implementing server side services to ingest, organize, analyze, and display real estate data and insight. You will be working in a small team and be a real partner in the design and implementation of all aspects of our product. You will Develop and implement ETL processes Design data warehouse solutions to support ETL processes and data analytics applications Write SQL/NoSQL database queries, stored procedures, triggers, user defined functions, analytic functions, etc Own features that you develop end to end, develop and test your code, implement new processes in production, and maintain and support them over time Drive our data platform and help evolve our technology stack and development best practices Develop and unit test assigned features to meet product requirements You have 7-10 years experience in engineering BS in CS or related field or equivalent years of experience Strong experience in database technologies and data warehousing Strong experience in Python Experience with service oriented architecture and good understanding of distributed systems, data stores, data modeling, and indexing (experience with Event Sourcing and/or CQRS preferred) Hands on experience developing APIs and SDKs Hands on experience with BigQuery, PostgreSQL, and large-scale distributed storage and database systems Ability to deal with ambiguity and communicate well with both technical and non-technical teams Nice to have Airflow Docker Kubernetes Benefits Equity Range of Healthcare Plans Paid Parental Leave Unlimited Vacation Flexible Work Schedule Compensation Range: $165,000-200,000 / year If this opportunity sounds interesting, apply or reach out to our internal talent team. We are happy to tell you more about Cherre: the technology we work with, the problems we solve, the team we are assembling, and the culture we all contribute to. We are excited you are considering working with us and look forward to hearing from you! “At the top of the mountain we are all snow leopards.” - Hunter S. Thompson Cherre is an equal opportunity employer. We pride ourselves on hiring the best people for the job no matter their race, sex, orientation, nationality, religion, disability, or age.",
        "url": "https://www.linkedin.com/jobs/view/3520074039"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3884937517,
        "company": "CyberCoders",
        "title": "Founding Data Engineer - Python, SQL, Scala",
        "created_on": 1720636522.8184185,
        "description": "Location: 100% Remote Salary: Up to $210K for Base + Bonus + Stock Options (High Upside) We are a Technology Company that focuses on human interaction and providing access to events, peoples, and recommendations globally. As our company grows, we're in need of a Founding Data Engineer to build out our core data infrastructure, and looking to take a leadership role. Position Overview: The Founding Data Engineer will be responsible for developing, maintaining, and optimizing data pipelines and architectures. This role requires a strong technical background in Python, SQL, Scala, and other related technologies. The Data Engineer will be the go-to person for data engineering and work with stakeholders to define and implement data infrastructure solutions. Key Responsibilities Design, develop, and maintain data architectures and pipelines using a variety of technologies such as Python and SQL. Scala and MongoDB are a plus Lead data engineering projects from start to finish, and collaborate with stakeholders to ensure successful delivery. Monitor and optimize existing data pipelines and architectures. Develop and document best practices for data engineering. Identify and troubleshoot performance issues in data pipelines and architectures. Strong experience with data pipeline and workflow management tools like Apache Airflow, Luigi, or Prefect. In-depth knowledge of real-time data processing frameworks such as Kinesis, Kafka, Flink, or Spark Streaming. Experience with Segment is a plus. Experience with data modeling tools and ETL frameworks, with a strong emphasis on performance optimization. Qualifications 5+ years of experience in a Data Engineer role. Proven experience with Python, SQL and other related technologies. Experience with AWS Strong knowledge of data modeling and ETL processes. Experience leading data engineering projects. Benefits We offer comprehensive medical and dental coverage, $50 a day food delivery budget Equity Learning opportunities Unlimited vacation, 12 weeks paid parental leave, and we pay all employees $1,000 a year to go somewhere in the world Email Your Resume In Word To Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also: rajeev.peterson@cybercoders.com Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : RP6-1790602L755 -- in the email subject line for your application to be considered.*** Rajeev Peterson - Associate Manager Applicants must be authorized to work in the U.S. CyberCoders is proud to be an Equal Opportunity Employer All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity or expression, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, status as a crime victim, disability, protected veteran status, or any other characteristic protected by law. CyberCoders will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. CyberCoders is committed to working with and providing reasonable accommodation to individuals with physical and mental disabilities. If you need special assistance or an accommodation while seeking employment, please contact a member of our Human Resources team to make arrangements.",
        "url": "https://www.linkedin.com/jobs/view/3884937517"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3916428706,
        "company": "Haymarket Media US",
        "title": "Sr Data Engineer",
        "created_on": 1720636524.656854,
        "description": "Haymarket Media, Inc. is seeking a Sr Data Engineer to join the Data Engineering Team team. This position is located in our New York, NY office. Job Overview We are looking for a Sr Data Engineer to contribute to our Data Warehouse infrastructure, working as part of a small and talented team focused on data integration, structure, report automation, and BI/Analytics Support, etc. As our business continues to grow in size and complexity, we are looking for a dynamic, organized, and customer-focused data centric contributor who is interested in informing and shaping our long-term roadmap. The role should understand business, systems, and data challenges and translate them into requirements and solutions. Responsibilities Build integrated solutions that are in line with the architecture framework that meets business requirements Provide guidance regarding data modeling best practices, data governance and quality practices. Ensure data adheres to enterprise governance standards and maintain credibility and reputation of high quality data Work with IT and business customers to capture requirements for designing the data warehouse, data analytics and business intelligence architecture. Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the data engineering ecosystem to design systems that meet business needs Play a leading role in building systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices Develop, institutionalize and drive best practices and data architectural awareness Create the blueprint for data management systems to integrate, centralize and maintain data sources Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications Define and implement integrations between source data and data warehouse as needed to ensure data integrity and support data & reporting requirements Develop and maintain programs on source systems, ETL applications, data cleansing functions, systems management functions including load automation, and data acquisition functions among others Ensure a fault tolerant, self-correcting, adaptive, highly accurate ETL platform Continuously seek opportunities to optimize data flows, improve SQL query performance, and maintain reasonable user experience for field and power users working on data Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts Skills And Requirements Ability to think broadly, understand business strategy, provide consultative business analysis, and have a broad understanding of technology landscape for developing effective and scalable data warehouse and business intelligence solutions Strong overall architecture experience with high proficiency in data architecture 5-8+ years of building large scale data-processing systems with 2+ years in big data technologies Expertise in cloud database technologies such as Google BigQuery with proficiency in SQL Experience in data transformation tools such as DataForm or DBT Experience designing and coding in python Experience in BI tools like Looker Thorough understanding of dimensional modeling, as well as knowledge of best practices and techniques for transforming, validating, logging, auditing, error handling, and performance tuning in a data warehousing setting Proven track record of strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams Has excellent problem-solving skills and experience handling multiple projects and assignment in a fast-paced environment Can work well in a cross-team collaborative environment, with little oversight, and be able to engage stakeholders with various business and technical backgrounds Experience with ETL and DW platforms such as Stitchdata a plus Experience with orchestration tools such as Airflow is a plus Experience working with Agile methodologies in a data warehouse, BI environment Bachelor’s degree in math, computer science, engineering, statistics, or a related technical field is required. Master’s degree a plus What We Offer A competitive compensation package The salary range for this position is $170,000–$190,000. Compensation will be commensurate with experience, skill level, functional and/or industry knowledge, education level, certifications, as well as other qualifications. Paid annual vacation, holiday and sick time off Comprehensive health plans including medical, dental and vision Competitive 401(k) investment options and generous company matching program Life insurance Commuter benefits Employee referral awards Tuition reimbursement Training opportunities through industry-recognized programs A creative and passionate workplace and a fun, collaborative team environment Three Week “Work from Anywhere” benefit, to ensure work life balance About Haymarket Haymarket has its heart and soul in publishing and media. Since the company was founded half a century ago, Haymarket has always prided itself on being a highly creative business, with an unrelenting focus on the quality of the products and the people. The philosophy has always been quite simple: only by having the highest quality individuals can you produce the highest quality products, combining the best in content, design, production and customer services. Globalization is opening up the world further and provides many opportunities for growth. Haymarket has offices around the world and many of the titles are now truly global brands. Haymarket serves a broad spread of business markets, from marketing to medicine to technology along with exhibitions and live events. Predicting the shape of the business in 3, 5, or 10 years is almost impossible; and the unpredictability is part of the appeal. Haymarket aims to be the perfect company to work with or for – we have the processes and attitude that ensure quality and consistency, and an entrepreneurial spirit that makes every day rewarding. An equal opportunity employer, Haymarket Media does not discriminate in hiring or terms and conditions of employment because of an individual's race, color, religion, gender, gender identity, national origin, citizenship, age, disability, sexual orientation, marital status, or any other protected category recognized by state, federal, or local laws. Beware of fraudulent activity where individuals are contacting job seekers claiming to represent Haymarket Media. Please note that only emails from @ haymarketmedia.com are legitimate. When applying for roles with Haymarket Media, you will receive an email directly from a member of the Talent Acquisition team or communication through Linkedin. You can view our open positions on our website US careers section: www.Haymarket.com California Applicants may view Haymarket Media, Inc.'s Privacy Statement for California Residents here .",
        "url": "https://www.linkedin.com/jobs/view/3916428706"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962770189,
        "company": "Rearc",
        "title": "Senior Data Engineer",
        "created_on": 1720636526.2750595,
        "description": "At Rearc, we're committed to empowering engineers to build awesome products and experiences. Success as a business hinges on our people's ability to think freely, challenge the status quo, and speak up about alternative problem-solving approaches. If you're an engineer driven by the desire to solve problems and make a difference, you're in the right place! Our approach is simple — empower engineers with the best tools possible to make an impact within their industry. We're on the lookout for engineers who thrive on ownership and freedom, possessing not just technical prowess, but also exceptional leadership skills. Our ideal candidates are hands-on-keyboard leaders who don't just talk the talk but also walk the walk, designing and building solutions that push the boundaries of cloud computing. As a Senior Data Engineer at Rearc, you'll play a pivotal role in establishing and maintaining technical excellence within our data engineering team. Your deep expertise in data architecture, ETL processes, and data modelling will be instrumental in optimizing data workflows for efficiency, scalability, and reliability. You'll collaborate closely with cross-functional teams to design and implement robust data solutions that meet business objectives and adhere to best practices in data management. Building strong partnerships with both technical teams and stakeholders will be essential as you drive data-driven initiatives and ensure their successful implementation. What You Bring 8+ years in data engineering, with proven experience across various architectures, technology stacks, and use cases. Expertise in designing and implementing data warehouse and lake architectures. Extensive experience in writing and testing Python and or Java. Familiarity with libraries such as Requests, Selenium, and Luigi is a plus. Proven experience with data pipeline orchestration platforms such as Airflow, Prefect, or AWS Glue. Hands-on experience with data analysis tools like NumPy, Pandas, Dask etc. Proficiency with Spark, Databricks, or EMR is a major plus. Experience with SQL and NoSQL databases and data warehouses, including Postgres, RedShift, Delta Lake, and DynamoDB. In-depth knowledge of data architecture principles and best practices. Proven experience with cloud services on AWS, GCP, or Azure. Proficient in using CLI, SDK, and Infrastructure as Code (IaC) tools. Experience with IaC tools such as Terraform, CloudFormation, or AWS CDK. Exceptional communication skills, with the ability to articulate complex technical concepts to both technical and non-technical stakeholders. Demonstrated ability to quickly adapt to new tasks and roles in a dynamic environment. What You'll Do Strategic Data Engineering Leadership: Provide strategic vision and technical leadership in data engineering, guiding the development and execution of advanced data strategies that align with business objectives. Architect Data Solutions: Design and architect complex data pipelines and scalable architectures, leveraging advanced tools and frameworks (e.g., Apache Kafka, Kubernetes) to ensure optimal performance and reliability. Drive Innovation: Lead the exploration and adoption of new technologies and methodologies in data engineering, driving innovation and continuous improvement across data processes. Technical Expertise: Apply deep expertise in ETL processes, data modeling, and data warehousing to optimize data workflows and ensure data integrity and quality. Collaboration and Mentorship: Collaborate closely with cross-functional teams to understand requirements and deliver impactful data solutions. Mentor and coach junior team members, fostering their growth and development in data engineering practices. Thought Leadership: Contribute to thought leadership in the data engineering domain through technical articles, conference presentations, and participation in industry forums. Some More About Us Founded in 2016, we pride ourselves on fostering an environment where creativity flourishes, bureaucracy is non-existent, and individuals are encouraged to challenge the status quo. We're not just a company; we're a community of problem-solvers dedicated to improving the lives of fellow software engineers. Our commitment is simple - finding the right fit for our team and cultivating a desire to make things better. If you're a cloud professional intrigued by our problem space and eager to make a difference, you've come to the right place. Join us, and let's solve problems together! The Pay Range For This Role Is 140,000 - 175,000 USD per year(New York City)",
        "url": "https://www.linkedin.com/jobs/view/3962770189"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3950838468,
        "company": "Cybersyn",
        "title": "Senior Data Engineer",
        "created_on": 1720636530.337968,
        "description": "About Cybersyn Cybersyn is a new DaaS (data-as-a-service) company, backed by Sequoia, Coatue, and Snowflake. Our mission is to make the world's economic data transparent to businesses and entrepreneurs and enable a new generation of decision makers. We acquire unique data assets (companies, licenses, data rights, consumer dividends) and build derived products on top of that, focusing on measuring what consumers and businesses are spending money on. You can think of Cybersyn as a cross between an investment firm and a technology company focused on data: if we are successful, we will disrupt the traditional market intelligence space. The reward is great - if we are successful, we can disrupt an industry worth $100Bs and build SimCity for the real world . We have already released many datasets that we have cleaned, restructured and made joinable on the Snowflake Marketplace. View our data products here. Explore the sources we integrate, and the associated data products here. About the role: Cybersyn is looking for an experienced data engineer to help us refine our technology stack for our data team and implement ingestion pipelines of public domain and private data sources. We are looking for someone who is passionate about the Snowflake Data Cloud and optimizing costs and workloads, in particular. This is the perfect role for someone who loves to tune databases, thinks about cost-compute optimization, and knows their way around a query plan. What you will do: Take research and statistical models and pipelines and implement them in Snowflake in an efficient way. You need to worry about compute efficiency and also care about building context for what the data actually is. Tune Snowflake for performance and cost optimization. Provide infrastructure guidance of Snowflake capabilities to accommodate business/technical use cases. Provide production support for Data Warehouse issues such data load problems, transformation translation problems, query optimization. Take end-to-end ownership of your work and enjoy working with different functions across the company. Who you are: Experience with Snowflake is requisite Experience with query optimization is required. You are comfortable in the Snowflake Query Profiler. Snowflake micro-partitions, sortkeys, query acceleration, and search optimization service should all be terms that you are familiar with and ready to discuss. Experience in SQL is requisite. Experience working with multiple (external) datasets, cleaning, joining, and munging data; experience working with public data sources (ie. US Census, ACS Survey) is a plus. Experience with dbt and orchestrator systems (Dagster, Prefect, Mage, Kestra, or some equivalent) is highly valued. Experience building and operating data pipelines for real customers in production systems. What you get out of it: Ability to shape Cybersyn’s initial technology decisions. Access to some of the most interesting and largest economic data in the world, including real-time spending, transaction, clickstream data from both third-party and first-party sources. Much of our data is not available to any other third parties. Our system is built with heterogeneous data sources in mind: we are not working on data from a single product or theme, but data from governments, payment processing systems (think bank records), mobile devices and apps, and SaaS exhaust (think data B2B SaaS collects) Fast moving culture, lots of responsibility and autonomy from day 1. Collaborate and learn from a very dynamic and motivated team in an in-office work environment.",
        "url": "https://www.linkedin.com/jobs/view/3950838468"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959914310,
        "company": "Everest Consultants, Inc.",
        "title": "Sr. Data Engineer (onsite work)",
        "created_on": 1720636532.066785,
        "description": "Title: Sr. Data Engineer (onsite work) Duration: 5 months Location: New York, NY 10019 Hours: 8.00am – 5.00pm Pay Rate - $60 - $75/hr on W-2 (No 1099 or C2C) NOTE - Authorized to work in the US without any sponsorship. Client prefer the candidate to be local to New York, NY. Job Description Our client is seeking an individual who will help the organization achieve its technology vision. A Senior Data Engineer who will work with teams in a fast-paced technology organization. As a Senior Data Engineer, you will be responsible for the full development life cycle of complex data projects requiring integrations and transformations including analysis, design, development, and support of complex data pipelines in cloud environments. You will also assist in the design and configuration of data management tools that extract and manipulate data from various sources, including in-house and external databases. Required Skills 1. Experience in creating scalable and secure data pipelines that enable the ingestion, transformation, and transfer of large quantities of structured and unstructured data from various databases and sources . 2. Experience in building complex database logic and API's to automatically fetch and store data in various forms. 3. Extensive experience with programming languages (Python or related), ETL tools and their administration, as well as relational and non-relational databases. 4. Experience in architecting and developing efficient and reusable modularized components that drive complex applications. 5. Experience in implementing data quality, security, and governance standards and best practices across different cloud environments. 6. Experience in the design and build of the integration between data management tools. 7. Experience in the design, development, and maintenance of data solutions across different cloud platforms, such as AWS or Google Cloud. 8. Extensive understanding of data structures, algorithms, and software architecture as well as the design, detailed testing, and documentation of complex systems. 9. Experience with the secure movement and storage of PHI, PII, and PCI data . 10. Experience with scaling up or increasing application resiliency and assuring that code meets required performance standards. 11. Ability to work and collaborate with data analysts, data scientists and IT operations to install and build tools transforming data to be used in building a new generation of data and artificial intelligence products. 12. Experience in providing technical leadership for development projects and providing consultation and guidance to other team members. 13. Ability to provide innovative solutions when presented with complex business or production issues. 14. Experience with modern DevSecOps practices and tools. 15. Experience with Agile methodologies and tools (i.e. Jira, Scrum, Kanban). Nice to have 1. Experience in directing a team of data engineers and analysts in the creation of complex software and data pipelines. 2. Experience with data governance processes. 3. Experience with data classification and taxonomy tools. Qualifications 1. Bachelor's degree in Computer Science, Information Systems, or related field, Masters preferred 2. 7+ years of experience as a Data Engineer",
        "url": "https://www.linkedin.com/jobs/view/3959914310"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963186154,
        "company": "Zortech Solutions",
        "title": "Senior Big Data Engineer - US",
        "created_on": 1720636540.6328495,
        "description": "Role: Senior Big Data Engineer Location: New Jersey (hybrid) Duration: 6+ Months Job Description: Please submit someone who can go for in person interview Job Description: We are seeking a highly skilled and experienced Senior Data Engineer to join our dynamic team. As a Senior Data Engineer, you will play a crucial role in designing, implementing, and maintaining data pipelines and infrastructure for our big data projects. Your expertise in Java, Python, Spark cluster management, data science, big data, REST API development, and knowledge of Databricks and Delta Lake will be essential in driving the success of our data initiatives. Responsibilities: Design, develop, and implement scalable data pipelines and ETL processes using Java, Python, and Spark. Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and design efficient solutions. Manage and optimize Spark clusters to ensure high performance and reliability. Perform data exploration, data cleaning, and data transformation tasks to prepare data for analysis and modeling. Develop and maintain data models and schemas to support data integration and analysis. Implement data quality and validation checks to ensure accuracy and consistency of data. Utilize REST API development skills to create and integrate data services and endpoints for seamless data access and consumption. Monitor and troubleshoot data pipeline performance, identifying and resolving bottlenecks and issues. Stay updated with the latest technologies and trends in big data, data engineering, data science, and REST API development, and provide recommendations for process improvements. Mentor and guide junior team members, providing technical leadership and sharing best practices. Qualifications: Master's degree in Computer Science, Data Science, or a related field. Minimum of 3 years of professional experience in data engineering, working with Java, Python, Spark, and big data technologies. Strong programming skills in Java and Python, with expertise in building scalable and maintainable code. Proven experience in Spark cluster management, optimization, and performance tuning. Solid understanding of data science concepts and experience working with data scientists and analysts. Proficiency in SQL and experience with relational databases (e.g., Snowflake, Delta Tables). Experience in designing and developing REST APIs using frameworks such as Flask or Spring. Familiarity with cloud-based data platforms (e.g.Azure) Experience with data warehousing concepts and tools (e.g., Snowflake, BigQuery) is a plus. Strong problem-solving and analytical skills, with the ability to tackle complex data engineering challenges. Excellent communication and collaboration skills, with the ability to work effectively in a team-oriented environment. If you are a highly motivated and skilled Senior Data Engineer with a passion for big data, data engineering, and REST API development, we would love to hear from you. Join our team and contribute to the success of our data-driven initiatives as we strive to make a significant impact in the industry.",
        "url": "https://www.linkedin.com/jobs/view/3963186154"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3952551457,
        "company": "W3Global",
        "title": "Data Engineer",
        "created_on": 1720636542.3590953,
        "description": "Role: Data Engineer Need to be at NY/NJ (Fully Onsite 5 Day a Week ) Full time only Must-have Skills : AWS, Databricks, Snowflake, Pyspark and SQL Job Description 10+ years of data engineering experience Experience deploying and running services in AWS and in engineering big-data solutions using technologies like Databricks, EMR, S3, and Spark, Pyspark and SQL Experience building streaming pipelines using Kafka, Spark, Flink, or Samza Experience loading and querying cloud-hosted databases such as Snowflake Experience designing and developing backend microservices for large scale distributed systems using gRPC or REST Experience with graph-based data workflows such as Apache Airflow, Meson Excellent communication and people engagement skills",
        "url": "https://www.linkedin.com/jobs/view/3952551457"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3965268110,
        "company": "Arpari",
        "title": "Software Engineer (NYC)",
        "created_on": 1720636543.9676561,
        "description": "How we work As an early employee, you’ll get to work directly with the CEO and early team to define and execute on tasks with high impact to Arpari and our growth. We promote an outcome-focused, low-bureaucracy work environment with an emphasis on having impact and moving relevant metrics. The Role As a key member of our team, you'll have a significant impact on shaping the direction of the company and product. You will manage Arpari features from design to deployment, solve complex issues, and collaborate with different teams. For the right candidate, this is a rare opportunity to help build an industry-defining company from the ground up. What we're looking for We are not looking for specific frameworks, skillsets, and experiences. We value above all else folks who want to make real customer impact by building great software. For Example You thrive at solving tough problems You enjoy breaking down challenging problems into simple & well-designed solutions You are fact-driven and want to measure the real impact of your work You enjoy building products and making real-world impact You take responsibility over end-to-end deployment of what you build You like shipping code frequently, iteratively, and collaboratively You value MVPs and customer impact over perfectly engineered systems You care about scalable infrastructure & process. Even better if you are the one to help improve / implement the system! You choose the best framework / technology for the task, even if you might have favorites. We work primarily in Python on the backend, and React on the frontend, but are always experimenting with what framework enables the greatest performance and delivers the most value You like to work in an fast-paced, high-growth, team-based environment You are entrepreneurial. This means having a growth mindset, finding problems without being told about them, thinking independently about issues and clearly advocating your position, and taking full ownership of your work, even if things go wrong You are a helpful teammate and understand best practices for building products as part of a team e.g., code review / version control Benefits Competitive compensation package, including equity Periodic team retreats We’re looking for someone who is passionate about solving problems and is excited about the opportunity to shape our sales motion from the ground up. If you're ready to make a significant impact and grow with us, we'd love to hear from you!",
        "url": "https://www.linkedin.com/jobs/view/3965268110"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962700042,
        "company": "Futran Solutions",
        "title": "Azure Data Engineer",
        "created_on": 1720636545.646602,
        "description": "New York, NY 10017 Azure Cloud Expertise Design, implement, and optimize data solutions on the Azure cloud platform, ensuring scalability, security, and performance. Azure Data Factory And Databricks Develop and maintain data pipelines using Azure Data Factory for efficient and reliable data movement. Leverage Azure Databricks for analytics and data exploration SQL And DBT Design and optimize SQL-based queries for data extraction, transformation, and loading processes. Implement and manage DBT (Data Build Tool) workflows to transform raw data into meaningful insights, ensuring data quality and consistency. Data Architecture And Modeling Collaborate with data architects to design and implement scalable and maintainable data models. Ensure adherence to data governance and compliance standards in data modeling and architecture. Performance Optimization Identify and address performance bottlenecks in data pipelines and database queries. Implement strategies to optimize data processing and reduce latency in data delivery. Collaboration And Documentation Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand data requirements and deliver solutions. Document data engineering processes, data flows, and architecture to facilitate knowledge transfer and ensure maintainability. Qualifications Bachelor's or Master's degree in Computer Science, Information Technology, or a related field. Proven experience as a Data Engineer with a focus on Azure cloud technologies. Strong proficiency in Azure Data Factory, Azure Databricks, SQL, and DBT. 10+ years in the data and analytics space with experience in designing and implementing scalable and robust data architectures. Excellent problem-solving skills and the ability to troubleshoot complex data issues. Strong communication skills and the ability to collaborate effectively with cross-functional teams. Relevant certifications in Azure cloud technologies are a plus. Nice to have: Python (Re)Insurance industry experience",
        "url": "https://www.linkedin.com/jobs/view/3962700042"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888438624,
        "company": "Donato Technologies, Inc.",
        "title": "GCP Data Engineer",
        "created_on": 1720636547.333131,
        "description": "Job Title: GCP Data Engineer (BigQuery + Snowflake) Location: Manhattan NYC (3 days in week) Consultants must be local to NYC Position: 3 - 4 Duration: 6+ Months MUST HAVE SKILLS: Google Cloud Platform (GCP), Snowflake, Big Query, ETL, SQL Job Description Develop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks Identify trends and opportunities for growth through analysis of complex data sets Evaluate organizational methods and provide source-to-target mappings and information-model specification documents for data sets Create best-practice reports based on data mining, analysis, and visualization Evaluate internal systems for efficiency, problems, and inaccuracies, developing and maintaining protocols for handling, processing, and cleaning data Work directly with management and users to gather requirements, provide status updates, and build relationships Work closely with Business and project managers to understand and maintain focus on their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision-makers Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity Create and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources Define and implement data acquisition and integration logic, selecting the appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution Develop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets Skills And Qualifications 7+ years' experience data as a data engineer Experience in GCP and BigQuery with analytics Experience is Snowflake Proven analytic skills, including mining, evaluation, analysis, and visualization Technical writing experience in relevant areas, including queries, reports, and presentations Strong SQL and MS Excel skills with the ability to learn other analytic tools Prior experience with Analytics, model design and segmentation techniques Strong programming experience with ETL Practical experience in statistical analysis through the use of statistical packages Proven success in a collaborative, team-oriented environment Nice have Media & Entertainment experience",
        "url": "https://www.linkedin.com/jobs/view/3888438624"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3933409269,
        "company": "Sealed",
        "title": "Software Engineer",
        "created_on": 1720636549.1175985,
        "description": "The bridge between climate policy, contractors, and homeowners Sealed is taking action in the residential energy efficiency and electrification space by eliminating the frictions between ambitious climate policy programs and 100 million US homes which need to be upgraded. We build software which helps HVAC, electrical, and plumbing professionals identify and distribute billions of dollars of energy efficiency incentives to homeowners. Sealed brings together a unique blend of technologists, policy wonks, and home services experts to get the boots on the ground as fast and effectively as possible. We are looking for an outstanding product-focused software engineer who wants to work on pragmatic solutions to real day-to-day challenges faced by contractors in the field. As an Engineer at Sealed, you'll have the chance to ship features within weeks of developing new hypotheses about our users' biggest challenges. The data we collect will be one of the most comprehensive views of investments in residential energy efficiency and actual measured performance outcomes. As a member of our small team, you'll be instrumental in shaping our engineering culture and practices. We value a flexible orientation towards software roles, with most members of the team doing at least some full stack work. Our greatest need currently is in backend engineering in our core FastAPI Python application. Interest or experience in Python data ingestion, transformation, and/or serverless processes are additional opportunities for a great fit. As a Software Engineer, you will… Participate in all aspects of software development activities, including design, coding, code review, testing, bug fixing, and documentation. Collaborate closely with the rest of engineering and product, as well as other stakeholders from our operations, revenue, and policy teams to plan features and build a high quality product that makes contractors successful in doing their important work. Improve the Sealed app's performance and reliability by building new features or polishing existing parts of the product. Fast prototyping of ideas and concepts and researching the latest industry trends. Work across the entire technical stack to ensure users have the most efficient and delightful experience using Sealed. The features you develop will span all aspects of the user experience, making you an expert on what their needs are. Be a mentor and provide thoughtful feedback to your peers, and build strong personal connections with your teammates! You may be a good fit if... You are excited to build a new software product in a new industry niche with constant opportunities to learn from user feedback and solve the next challenge You have amazing engineering chops, but are also product- and user-focused You have 2-6 years of experience, with some exposure to early stage and high-growth environments You have great communication and collaboration skills Bonus: Familiarity with Python application development or our specific framework, FastAPI Familiarity with data ingestion, transformation with tools like Dagster and dbt Familiarity with with serverless data processing with Python in CloudFunctions for example Building software for small business customers and internal users At Sealed, we are dedicated to building a diverse, inclusive, and authentic workplace. So if you're excited about this role, but your past experience doesn't align perfectly with every qualification in this job description – we encourage you to apply anyways! We are a team of curious learners, and most of us are learning some skills for the first time (like our engineers developing in Python for the first time). You might be just the right candidate for this or other roles. What We Offer When we find the right person, we try to put our best foot forward with an offer that excites you. We consider what you'd like to be paid, the skills and level of experience you bring, what similar jobs pay, and make sure there's equal pay for equal work among those you'll be working with. The budgeted compensation amount for this role is targeted at $100,000 - $130,000. Competitive Salary & Equity Medical, Dental and Vision Benefits Flexible remote-first culture, with optional office space in NYC for folks who want to work together IRL Flexible PTO 401(k) Pre-Tax FSA Health / Dependent Care Savings Plans Individuals seeking employment at Sealed are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation.",
        "url": "https://www.linkedin.com/jobs/view/3933409269"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956390776,
        "company": "Perchwell",
        "title": "Senior Data Engineer",
        "created_on": 1720636551.0724607,
        "description": "Who We Are Perchwell is the premier workflow software and data platform for real estate professionals and consumers. Based on the industry’s foundational data, Perchwell builds a modern software suite to empower real estate professionals to do their best work, provide differentiated service to their clients, and grow their businesses. Backed by Founders Fund, Lux Capital, and some of the country’s leading Multiple Listing Services (MLSs), Perchwell builds next generation workflow software/data products for the multi-trillion dollar residential real estate industry. Perchwell is the first new entrant to come to market in decades and is currently scaling its best-in-class platform. Position Overview: Perchwell’s mission is to become the fastest growing MLS workflow and data platform in the country. With that, data is core to what Perchwell represents, and we are looking for a Senior Data Engineer to take charge of our data engineering initiatives, from building a data lake and warehouse solution to scaling our existing data infrastructure to onboard several new MLSes in the coming months. As a senior data engineer, you’ll be collaborating with cross-functional teams including Data Insights, Product, Design, and other engineering teams to build robust data solutions that help Perchwell become the best-in-class MLS workflow and data platform. We’re a small but growing team and as a foundational member you’ll have the opportunity to shape the standards, culture, and values of the data engineering team. What You’ll Do: Build out ETL tooling and data pipelines, consuming data into our system from 3rd party data sources and APIs Design and implement automated data governance measures to improve data quality and observability Build out team processes and culture around ownership and accountability Partner with Data Analyst team that will act as partner team to conduct analysis, dashboards, and quality assessments What You’ll Need: 5+ years experience in data engineering including experience with Python, SQL, or Kotlin Experience building scalable and fault tolerant data pipelines with data originating from 3rd party API’s for batch and real-time use cases Expertise with any of ETL schedulers such as Airflow (preferred), Dagster, Prefect or similar frameworks Experience with cloud architecture (preferably AWS) and technologies including S3, SQS, RDS, EMR, Glue, Athena, and Lambda Experience working with data warehouses: snowflake (preferred), redshift, or google bigquery Experience building CI/CD pipelines using GitLab, GitHub actions, Terraform, or Jenkins Familiarity with microservices architecture and cloud data lake implementations Excellent communication skills, both oral and written, with a demonstrated ability to effectively collaborate with cross-functional teams. In this role, you’ll work out of our New York City Office in Soho Manhattan at least 3 days/week. Bonus points for the following: Certifications in AWS, Snowflake, or Elasticsearch Ruby on Rails experience Compensation: To provide greater transparency to candidates, we share base salary ranges for all US-based job postings regardless of state. Our ranges are based on function and level benchmarked against similar stage growth companies. Final offer amounts are determined by multiple factors including skills, job-related knowledge and depth of work experience. The compensation for this position is $160-$190K base salary + equity + benefits Note: At this time, we are only considering candidates who are authorized to work in the U.S.",
        "url": "https://www.linkedin.com/jobs/view/3956390776"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3961555557,
        "company": "Algo Capital Group",
        "title": "Senior Data Center Engineer",
        "created_on": 1720636554.778403,
        "description": "Senior Data Center Engineer We're looking for an experienced Senior Data Center Engineer to join my client's Global IT Infrastructure team. You'll play a crucial role in supporting and evolving our sophisticated multi-data center environment, driving projects that aid in our expansion into new markets and asset classes. Responsibility: Maintain the integrity of the data center infrastructure at colocation facilities in Secaucus, Carteret, Mahwah, and other East Coast locations. Collaborate with the IT Infrastructure team to schedule and oversee daily data center operations supporting our trading systems. Handle installation, replacement, upgrades, and relocation of cables and equipment, including switches, servers, and hardware components. Advanced knowledge of fiber breakout cables is a must. Address technical issues and hardware failures promptly. Liaise with third-party vendors for support and remote hands. Work with the IT Infrastructure and Development teams to plan and execute data center moves and reorganizations, ensuring accuracy and timeliness. Ensure our data centers have the necessary space, power, and cooling, with appropriate monitoring in place. Requirements: 5 plus years in data center operations Ability to commute to critical data centers in the New York metro area; must have own transportation and a valid driver’s license. Travel to other regions may be required occasionally. And the ability to work out-of-state and occasionally work outside of core business hours and on weekends. Deep understanding of data center procedures and modern, large-scale data centers. Knowledge of network hardware, servers, and fiber optic cabling standards/types. Ability to quickly diagnose problems and implement solutions to ensure system uptime. Familiarity with basic Linux systems (PXE, RAID, user management, boot processes). Exposure to multiple infrastructure areas, including hardware support and low-latency networking. Understanding of power distribution/power management in data centers. Strong communication skills for detailed instructions both verbally and in writing. Excellent opportunity with a high-performing trading team rewarding package on offer with high growth career progression.",
        "url": "https://www.linkedin.com/jobs/view/3961555557"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brooklyn, NY",
        "job_id": 3888433022,
        "company": "Software People Inc.",
        "title": "Senior Data Engineer",
        "created_on": 1720636556.3250368,
        "description": "Remote an option with onsite visits for critical meetings as needed. Phone/Skype Hire. Location: Brooklyn, NY Duration: 12+ months (35 hrs/week) For the initial phases, the Senior Data Engineer will assist the Application Engineering in building a robust, secure, and modern data pipelines to ingest, process, transform applications data using Informatica Intelligent Cloud Services or a comparable ETL/ELT tool employing modern data movement strategies and methodologies. The data needs to be store in an Azure Data Lake and eventually brought into a cloud-based data store such as Snowflake or a similar data store. Then, the Analytics reporting solution needs to be built either using cloud-based Google Looker or Microsoft Power BI or another similar tool. Using the Cloud OTI Data Platform, the Senior Data Engineer will build highly available, robust, concrete data pipelines and reporting solutions following industry best practices, adhering to OTI security guidelines, modifying, and running automated CI/CD pipelines used for releasing code, and modifying and executing terraform modules for deploying infrastructure components, working collaboratively under the direction of OTI data engineering management and leads. The resource will be a person with integrity who is dependable and is fully focused on delivering optimal solutions with little to no maintenance and operations overhead. Responsibilities Be experienced in Data Engineering best practices, technologies, tools and processes. Bring sound knowledge of Data Warehouses and LakeHouse concepts and practical implementation experience. Build a framework of repeatable solutions and playbooks enabling efficient and predictable data pipelines. Have hands-on development experience in the implementation of an agile, cloud centric data warehousing and reporting platform with team members of various experience level. Interact with clients, both technical and non-technical stakeholders. Handle relationships with end users. Interact regularly to gather feedback, listen to their issues and concerns, and recommend solutions. Meet critical deadlines and deliver in short sprints. Ensure successful delivery of new reports and dashboards as needed. Maintain and curate data documentation including Architectural Decision Records (ADR), how-to guides, data lineage and ownership using Azure DevOps or similar tool. Maintain query performance and tuning to ensure cost optimization. Participate in joint application development sessions with co-engineers and end users and be willing to brainstorm. Complete technical documentation and be willing to transfer knowledge as needed. Skills Needed 12+ years developing Data Pipelines / Flows using ETL/ELT tools and technologies. 10+ years of strong SQL fluency (query optimization, windowing functions, aggregation, etc.). 5+ years building complex Analytics and Reporting solutions. 3+ years' experience with a cloud data lake/warehouse solution (Snowflake, Redshift, GCP etc.). Hands on experience working with data integration tools like Informatica Intelligent Cloud Services, Informatica Power Center or SSIS or a similar tool. Extensive experience developing production grade, large scale data solutions. Experience performing conceptual, logical, and physical data modeling using data modeling tools in complex, large-scale environments. Experience working with Microsoft Azure cloud computing platform and services. Experience managing data orchestration at scale using tools such as Airflow, Prefect and Dagster. Experience with traditional RDMS platforms (Oracle and SQL Server). Experience working with version control systems (e.g., Git) Good understanding of CI/CD principles. Experience developing dashboards and reports in applications such as Oracle Analytics Server (OAS), Microsoft Power BI and Google Looker. Experience using Azure services for Security, Blob Storage, Data Lake, Databricks, Data Factory etc. Programming experience with Python or Java Experience with Azure Monitoring services Microsoft Certified Azure Solutions Architect Expert or a Snowpro Certification or a similar one",
        "url": "https://www.linkedin.com/jobs/view/3888433022"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3942694035,
        "company": "Mondrian Alpha",
        "title": "Software Engineer - Leading Global Hedge Fund - $500k Total Compensation",
        "created_on": 1720636557.841282,
        "description": "I am working with a leading European multi-billion hedge fund, rapidly expanding their presence in New York, who are seeking an elite Python Software Developer to join a brand new team. My client is engaging in the build out of a new systematic business and is seeking a world-class Python Software Developer who can join this new team and assist in the development of this systematic trading platform. As a member of this team, you will be working on a number of different projects, including the development of pricing and risk models, the development of systems to communicate with exchanges, as well as the development of internal risk infrastructure and big data pipelines for historical training and real-time inference. You will be joining a highly prolific team in the firm, working alongside some of the brightest programmers and engineers in the industry, and tasked with building out their core technology that service all parts of their business. You will report directly into the Head of Technology and have continuous exposure to and interaction with PMs, traders and senior management. My client anticipates to pay a strong performer upwards of $500k year 1 total compensation package. As well as a market-leading compensation package, they offer exceptional benefits including a top-tier healthcare package, fully subsidised qualifications plus breakfast and lunch paid for each day. To apply, either respond to this advert or send your CV directly to sasha.duquesne@mondrian-alpha.com.",
        "url": "https://www.linkedin.com/jobs/view/3942694035"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brooklyn, NY",
        "job_id": 3931692236,
        "company": "Princeton IT Services, Inc",
        "title": "NG911 SQL Engineer",
        "created_on": 1720636559.5559032,
        "description": "Job Title: NG911 SQL Engineer Location: Brooklyn, NY (2 days in office) Duration: 12 Months Months Responsibilities Database Review and Maintenance Review all Microsoft SQL Server databases. Identify any issues such as performance bottlenecks, fragmentation, or inconsistencies. Perform routine maintenance tasks such as index rebuilds, statistics updates, and database integrity checks. Always On Availability Group Maintenance Monitor and maintain Always On Availability Groups for SQL Clusters. Ensure synchronization state across replicas. Perform failover testing and handle failover scenarios as necessary. Best Practice Recommendations Review SQL Server and database requests as part of the build cycle. Provide best practice recommendations for database design, performance tuning, and security. SQL Updates and Patching Schedule and perform SQL Server updates and patches. Coordinate with stakeholders to minimize downtime and ensure updates are applied in a timely manner. Application Migration to SQL 2019 Assess existing applications and databases. Work with application owners to plan and execute migrations to SQL Server 2019. Ensure compatibility and performance optimization during the migration process. SQL Server Consolidation Identify opportunities to consolidate SQL servers into shared instances. Evaluate resource utilization and performance impact. Plan and execute server consolidation efforts while minimizing disruption to existing services. Root Cause Analysis Perform root cause analysis on internal and external data and processes. Identify patterns, trends, and anomalies to answer specific business questions. Propose data-driven solutions and opportunities for improvement. Project Management Support Provide project management support for SQL-related initiatives. Coordinate tasks, timelines, and resources to ensure successful project delivery. Communicate effectively with stakeholders to provide updates and manage expectations. Backup and Recovery Management Review and optimize SQL backup schedules and technologies. Implement backup strategies to ensure data integrity and disaster recovery readiness. Monitor backup jobs, troubleshoot failures, and perform periodic recovery tests. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Mandatory Skills/Experience Minimum 12 years of experience in the following: Microsoft SQL Engineer/DBA must possess advanced SQL querying skills, including expertise in writing complex SQL queries, stored procedures, triggers, and optimizing SQL performance. Proficiency in database administration tasks such as database creation, configuration, monitoring, backup and recovery, security management, user access control, and database optimization. Knowledge and experience in implementing and maintaining high availability solutions such as Always On Availability Groups, database mirroring, failover clustering, and disaster recovery planning. Ability to diagnose and troubleshoot database-related issues effectively, using tools such as SQL Server Profiler, Dynamic Management Views (DMVs), and Extended Events. Desirable Skills/Experience Knowledge of MySQL, Oracle, MongoDB, VMWare, AD, DNS",
        "url": "https://www.linkedin.com/jobs/view/3931692236"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Richmond County, NY",
        "job_id": 3915311576,
        "company": "eTek IT Services, Inc.",
        "title": "Data Engineer-W2",
        "created_on": 1720636561.3255527,
        "description": "Overview The Data Engineer plays a crucial role in our organization, responsible for designing, developing, and maintaining scalable data pipelines and infrastructure. This role will have a significant impact on our ability to efficiently and effectively process and analyze large volumes of data, enabling data-driven decision-making across the organization. Key Responsibilities Design, build, and maintain an efficient and reliable ETL pipeline for large-scale data processing. Develop and optimize data models for use in data science and analytics applications. Implement data quality and validation processes to ensure accuracy and reliability of data. Collaborate with data scientists and analysts to understand data requirements and implement solutions. Manage and optimize data storage and retrieval systems. Create and maintain documentation for data infrastructure and processes. Monitor and troubleshoot performance issues with data pipelines. Implement security and privacy measures to protect sensitive data. Explore and evaluate new data technologies and tools to drive innovation. Participate in cross-functional teams to support data-related initiatives. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or related field. Proven experience in big data technologies and platforms. Proficiency in programming languages like Python, Java, or Scala. Strong SQL and database management skills. Experience with ETL tools and processes. Expertise in data modeling and data warehousing concepts. Familiarity with cloud-based data solutions such as AWS or Azure. Ability to work with distributed computing and parallel processing. Understanding of data governance and compliance requirements. Excellent problem-solving and analytical abilities. Strong communication and collaboration skills. Proven ability to manage multiple projects and priorities effectively. Experience with version control systems like Git. Knowledge of Agile and DevOps methodologies. Ability to thrive in a fast-paced, dynamic environment. Skills: collaboration skills,data warehousing,python,project management,scala,cloud,data modeling,data governance,parallel processing,spark,communication skills,sql,database management,distributed computing,problem-solving,azure,java,aws,git,etl,devops,big data,analytical abilities,agile",
        "url": "https://www.linkedin.com/jobs/view/3915311576"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3952724726,
        "company": "Wipro",
        "title": "System Engineer",
        "created_on": 1720636562.9800942,
        "description": "Wipro Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. A PROUD HISTORY OF OVER 75 YEARS FY22 REVENUE 10.4 BN USD WE’RE PRESENT IN 66 COUNTRIES OVER 1,400 ACTIVE GLOBAL CLIENTS Position : Systems Engineer Location : New york (Hybrid) FTE Relevant certifications/degree in Computer Science, Engineering or a related subject Proven working experience in installing, configuring and troubleshooting UNIX /Linux based environments. Solid experience in the administration and performance tuning of application stacks Cloud experience, preferably in Azure Experience with virtualization and containerization (e.g., VMware, Virtual Box) Experience with monitoring systems Experience with automation software Solid scripting skills Solid networking knowledge Responsibilities: Manage and monitor all installed systems and infrastructure -Install, configure, test and maintain operating systems, application software and system management tools -Proactively ensure the highest levels of systems and infrastructure availability -Monitor and test application performance for potential bottlenecks, identify possible solutions, and work with developers to implement those fixes -Maintain security, backup, and redundancy strategies -Write and maintain custom scripts to increase system efficiency and lower the human intervention time on any tasks -Participate in the design of information and operational support systems -Provide 2nd and 3rd level support -Liaise with vendors and other IT personnel for problem resolution Equal Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3952724726"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956391131,
        "company": "Shulman Fleming & Partners",
        "title": "Contract Data Engineer",
        "created_on": 1720636564.8230722,
        "description": "MUST be local to New York City. Hybrid schedule at least 3 days in office Qualifications: 5+ years’ of experience required Strong knowledge of Microsoft SQL Server, including designing, developing, and implementing complex SQL queries, stored procedures, and functions. Expertise in Python programming, including experience with data analysis libraries such as NumPy, and Pandas. Proficiency in SSIS (SQL Server Integration Services) for ETL (Extract, Transform, and Load) processes. Proficient in C# programming, including experience with .NET framework. Strong analytical and problem-solving skills, with the ability to analyze complex data and identify trends, patterns, and insights. Good communication and interpersonal skills, with the ability to work effectively in a team environment and collaborate with other IT professionals, business analysts, and stakeholders. Ability to adapt to changing requirements and priorities, with a proactive and flexible approach to work. Skills: Microsoft SQL Server, including designing, developing, and implementing complex SQL queries, stored procedures, and functions. Education: BS/BA in computer/data science/engineering or related fields Posted On: Tuesday, June 18, 2024",
        "url": "https://www.linkedin.com/jobs/view/3956391131"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3813095308,
        "company": "1872 Consulting",
        "title": "Database Engineer",
        "created_on": 1720636566.3680673,
        "description": "WHAT YOU'LL DO DAY-TO-DAY: Infrastructure Engineering designs and maintains the firm's operating systems, authentication systems, databases, virtualization infrastructure, core network services, and messaging and endpoints on Windows and Linux in both our internal- and external-facing environments. The database engineer will be responsible for owning and building out the existing database environment, workflows, and automation while working closely with a global team of database administrators. This engineer will work with other members of Infrastructure Engineering to provide self-service and automation-driven solutions. They will also work with software developers and trading teams to optimize and scale applications and software that pertain to database access. WHO WE'RE LOOKING FOR: • The ideal candidate should have a degree in computer science (or another technical discipline) or comparable work experience. • An in-depth knowledge of at least one database platform and working knowledge of other platforms—such as SQL Server, Postgres, Redis, MongoDB, or Cassandra—is required. • Experience and proficiency in programming languages such as Python, Java, and C# is preferred, as is working knowledge of networking protocols, information security concepts, and operating system internals. • Outstanding communication skills are imperative, as the role will entail significant interaction with different departments in the firm.",
        "url": "https://www.linkedin.com/jobs/view/3813095308"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3944304487,
        "company": "Zocdoc",
        "title": "Senior Analytics Engineer",
        "created_on": 1720636568.093603,
        "description": "Our Mission Healthcare should work for patients, but it doesn’t. In their time of need, they call down outdated insurance directories. Then wait on hold. Then wait weeks for the privilege of a visit. Then wait in a room solely designed for waiting. Then wait for a surprise bill. In any other consumer industry, the companies delivering such a poor customer experience would not survive. But in healthcare, patients lack market power. Which means they are expected to accept the unacceptable. Zocdoc’s mission is to give power to the patient. To do that, we’ve built the leading healthcare marketplace that makes it easy to find and book in-person or virtual care in all 50 states, across +200 specialties and +12k insurance plans. By giving patients the ability to see and choose, we give them power. In doing so, we can make healthcare work like every other consumer sector, where businesses compete for customers, not the other way around. In time, this will drive quality up and prices down. We’re 15 years old and the leader in our space, but we are still just getting started. If you like solving important, complex problems alongside deeply thoughtful, driven, and collaborative teammates, read on. Your Impact On Our Mission Zocdoc is seeking a Senior Analytics Engineer who will be part of a centralized team focused on creating and maintaining a robust analytics layer that powers Zocdoc’s analytics, operations, and reporting tools that enable the business to answer questions quickly, consistently, and reliably. You will take ownership of transforming raw data into production-quality models and creating sanctioned datasets that drive all critical analysis across the organization. You will also work closely with our Product Management, Product Engineering, Data Engineering, and Product Analytics teams to ensure data is created efficiently, repeatedly, and reliably for all teams involved. You will take ownership of large projects, acting as a lead for a portion of the Analytics Engineering team. You’ll enjoy this role if you are… Someone who is excited about building data products to push the whole company forward. Passionate for solving problems using data and analytics. Passionate about building the best version of whatever you’re working on. Someone who loves working in a highly collaborative and supportive environment. Passionate about building fully scalable data solutions with the latest technologies. Your day to day is… Enabling data consumers to answer critical questions and gain insights using trusted, sanctioned data sets designed to be high-performance, reusable, and scalable. Supporting teams across the company to enable self-serve analytics through our Analytics tools (Looker and Amplitude) and owning the administration, adoption, and end-user training support of those tools. Collaborating with analysts, product managers, and product engineering to ensure our data for analytics can support all our data requirements and is easy to maintain. Writing production-quality data transformations in SQL using DBT and Dagster with an eye towards performance, maintainability, scalability, and reliability. Collaborating with data engineers on infrastructure projects to improve ingestion pipelines and sourcing new data. Drive standards for data governance, security, privacy, quality, and retention. Providing mentorship for members of the team while building best practices. You’ll be successful in this role if you have… 5+ years experience as an analytics engineer, data engineer, or similar role. 2+ years of experience using dbt, with a strong understanding of data modeling and data warehousing concepts. Expertise in writing performant SQL, especially within cloud-based data warehouses like Snowflake, and have strong Looker developer skills, with an emphasis on LookML modeling and overall project design. Experience managing the administration and/or adoption of data visualization tools (e.g. Looker, Tableau) and event-based analytics/user journey tools (e.g. Amplitude). Ability to navigate ambiguity and work with urgency in a fast-moving environment with multiple stakeholders. Good communication skills across all levels of stakeholders (business & technical) with the ability to influence and build consensus. Experience as a mentor or team/tech lead, with the desire and drive to grow into a management role. Humility. You believe in treating all people with dignity and respect, regardless of title or tenure, and you approach tough conversations with empathy Plus: Experience with Dagster or other orchestration tools. Python coding skills, particularly in the areas of automation & integrations. Experience with data governance principles, KPI management, and supporting data operations for business intelligence. Benefits Flexible, hybrid work environment Unlimited PTO 100% paid employee health benefit options Employer funded 401(k) match Corporate wellness programs with Headspace and Peloton Sabbatical leave (for employees with 5+ years of service) Competitive parental leave Cell phone reimbursement In office perks including: Catered lunch everyday along with snacks Commuter Benefits Convenient Soho location Zocdoc is committed to fair and equitable compensation practices. Salary ranges are determined through alignment with market data. Base salary offered is determined by a number of factors including the candidate’s experience, qualifications, and skills. Certain positions are also eligible for variable pay and/or equity; your recruiter will discuss the full compensation package details. NYC Base Salary Range $154,000—$189,000 USD About Us Zocdoc is the country’s leading digital health marketplace that helps patients easily find and book the care they need. Each month, millions of patients use our free service to find nearby, in-network providers, compare choices based on verified patient reviews, and instantly book in-person or video visits online. Providers participate in Zocdoc’s Marketplace to reach new patients to grow their practice, fill their last-minute openings, and deliver a better healthcare experience. Founded in 2007 with a mission to give power to the patient, our work each day in pursuit of that mission is guided by our six core values. Zocdoc is a private company backed by some of the world’s leading investors, and we believe we’re still only scratching the surface of what we plan to accomplish. Zocdoc is a mission-driven organization dedicated to building teams as diverse as the patients and providers we aim to serve. In the spirit of one of our core values - Together, Not Alone , we are a company that prides itself on being highly collaborative, and we believe that diverse perspectives, experiences and contributors make our community and our platform better. We’re an equal opportunity employer committed to providing employees with a work environment free of discrimination and harassment. Applicants are considered for employment regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity, gender expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or any other class protected by applicable laws. Job Applicant Privacy Notice",
        "url": "https://www.linkedin.com/jobs/view/3944304487"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3615270614,
        "company": "Jobskey Search and Selection",
        "title": "BI Developer/Data Engineer",
        "created_on": 1720636569.7753909,
        "description": "Job Summary The Rapid Application Development and Business Intelligence team is responsible for the management reporting and analytics functions for Corporate Technology, supporting departments such as Finance, Human Resources, Investor Relations, Business Development and others. We produce well-designed and supportable reports, dashboards, and ad-hoc reporting solutions that provide insight and decision support to our business counterparts. We rely heavily on the Microsoft SQL Server BI stack, though with Tableau as our primary dashboard platform. This role focuses on the maintenance and continued development of our underlying data warehouse, the building of ETL's using Python and the Prefect ETL framework, and the construction of CI/CD data pipelines for our various SSRS reports and SSAS Tabular models. We are looking for a strong SQL architect with experience building and maintaining data warehouses and the data pipelines to load them. Strong Python skills (especially in the data science realm, such as pandas, numpy, etc) are required, and SSAS Tabular/Power BI experience is a plus. The nature of our team requires significant communication with end users, so strong user empathy and communication skills are also a requirement. Principal Responsibilities Building of ETL processes using Python and the Prefect framework Development of CI/CD pipelines for our various tools and technologies (SSRS, SSAS, SQL Server db objects) Rapid development of clean, supportable applications and processes using Python,Powershell and/or SQL Work closely with business users to understand the various business processes that make up our users' day-to-day responsibilities and helping to identify areas of improvement. Ongoing development of management reports and reporting solutions using SSAS Tabular and SSRS. Continued maintenance and build out of our internal data warehouse/datamarts. Qualifications/Skills Required: Strong Python data-engineering skills (5+ years experience), including pandas, numpy,FastAPI and/or Flask Strong SQL development skills, including data warehousing concepts and development practices. Experience building processes that supply and consume data using RESTful services Experience building and consuming RESTful services. Strong and effective interpersonal skills with proven ability to develop positive relationships with business partners. A strong attention to detail, eye for good design and a desire to continually improve and optimize. Skills Desired: Strong knowledge of DAX whether via experience with PowerBI or SSAS Tabular Working knowledge of SSIS Knowledge of concepts behind good data visualization and UX design JavaScript/HTML/CSS with knowledge in at least one web framework such as Angular,React/Redux, or Ember Experience working with front office business data and processes. Kind Regards, Jobskey Search and Selection KSA Office -- Email: Consultant@jobskeysearch.com| Website: www.jobskeysearch.com Resumes@Jobskey.com | Website: www.jobskey.com",
        "url": "https://www.linkedin.com/jobs/view/3615270614"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3933977124,
        "company": "Artech L.L.C.",
        "title": "Data Bricks Developer - Remote!",
        "created_on": 1720636571.5882537,
        "description": "Description Artech is currently looking for experienced professional for the below position. Job ID : 24-14377 Job Title: Data Bricks Developer Location: Remote Duration : 4+ Yrs. Pay Rate: $65.00 to 70.00/hr on W2. Job Description Task Description: Provide support and assistance to design, development, integrate, test, and deploy a modernized BMF platform and support day-to-day Operations & Maintenance (O&M) work based on IRS priorities. Provide for project management, O&M, development, modernization, enhancements, software development, legislative changes, and developmental O&M upgrades. Required Skills/Level Of Experience Hands on experience on working in AWS cloud platform. Experience in designing and implementing scalable and secure AWS cloud solutions using Databricks platform. Experience in designing and implementing scalable BI Reports in Tableau. Expert level in designing and Architect solutions in AWS Databricks platform. Experience with Databricks Delta Lake and Lakehouse Architecture. Experience in AWS cloud technologies. IRS EDP Databricks platform experience. IRS Analytical platform experience. Nice To Have Skills Good experience on Databricks and Tableau. IRS EDP Databricks platform experience. IRS Analytical platform experience. Please apply on our company website (www.artechinfo.com) with reference to job ID, or contact me at lakshya.sharma@artech.com for more details regarding position including feedback.",
        "url": "https://www.linkedin.com/jobs/view/3933977124"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3953361017,
        "company": "Fizz",
        "title": "Software Engineer",
        "created_on": 1720636573.3178701,
        "description": "Become a part of our high-output engineering team Join the Fizz team as a full stack engineer and play a key role in Fizz’s crusade to empower young adults to become financially confident and independent. Fizz is a well funded early stage startup serving college students. Our first product is a debit card that builds credit with no fees, no interest and no risk of overspending. Named the best credit building product for students by Business Insider, Fizz is beloved by thousands of students at over 300 universities including Michigan State, University of Florida, UCLA, Harvard and more. Fizz recently raised $14.4M from Kleiner Perkins and is backed by YC, SV Angel and the founders of companies including Public.com, Motive, Checkout.com and Postmates. In this role you would help us build a mobile app which will be the central platform for our users to manage their journey to financial independence. We are building cross platform with Flutter and have a Typescript/Node.js/MongoDB backend. Our day to day work consists of many interesting challenges, anti-fraud algorithms, or using a variety of APIs and Technologies (like Open-Banking and Card issuers ) to create a debit card that builds credit. In this role you can expect to Design, develop, test, and scale new and existing mobile architecture Build high-quality mobile UI experiences Write code that has an impact and is shipped to our growing user base Work with a variety of technologies and APIs To thrive in this role you have 2+ years of experience with either our backend stack (Typescript/Node.js/MongoDB) or our frontend stack (Flutter/Dart) Enthusiasm for product ownership, critical thinking, and proactive collaboration (+) Experience in Flutter as an added plus (+) Experience working independently at an early stage startup. (+) Experience in a startup or building side projects is an added plus Fizz Perks High potential for growth & complete ownership from the beginning 📈 Work with colleagues who get it 🧠 Rapid learning environment 🚀 Competitive base salary 💸 Generous equity in an early-stage startup 🤩 100% employer paid medical benefits 🩺 New York City Office with remote option and flexible WFH policy 💼 Unlimited vacation policy with 15 official company holidays 🏝 401K plan with 4% company match 💪🏻 16 weeks of paid parental leave including adoption and fostering",
        "url": "https://www.linkedin.com/jobs/view/3953361017"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963992684,
        "company": "PMX",
        "title": "Associate, Software Engineer",
        "created_on": 1720636575.4630375,
        "description": "Job Description Software Engineers within Publicis Media concentrate on the development, implementation, and ongoing innovation of world class leading engineering products, business analytics, and next generation technologies. The Associate Software Engineer we are looking to join our team will be on point for the design, development, implementation and on-going support of web applications. Included in design and development of these applications requires a collaborative spirit to partner with the broader engineering team whilst partnering on different layers of the infrastructure. You will report to Executive Vice President, Engineering. This is a hybrid role, requiring three days in-office each week. If you are contacted for an interview, your recruiter will discuss specifics with you, inclusive of any necessary reasonable accommodations. Your Day To Day Will Include Translating application storyboards and use cases into functional applications Identifying bottlenecks and bugs, devising solutions to mitigate and address these issues Integration of the front-end and back-end aspects of the web application Collaboration with other team members and stakeholders Developing features to enhance the user experience. Striking a balance between functional and aesthetic design. Ensuring web design is optimized for smartphones. Building reusable code for future use. Optimizing web pages for maximum speed and scalability.",
        "url": "https://www.linkedin.com/jobs/view/3963992684"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3713424078,
        "company": "WireScreen",
        "title": "Senior Backend Software Engineer - Multiple Openings",
        "created_on": 1720636583.032139,
        "description": "Senior Backend SWE - NYC ( Hybrid but in-office) - *Multiple Openings About Us: WireScreen is a Sequoia-backed startup building a sophisticated corporate intelligence platform to help multinational companies, asset managers, and regulators track and monitor their supply chains and business partnerships. Our leadership team includes a Pulitzer Prize winner and senior engineers who helped scale Google, Peloton, and Compass. We’re seeking a talented Senior Backend Software Engineer to join our growing Engineering team. If you're passionate about making a significant impact on global investment decisions, supply chain monitoring, and risk response, we want you on board. Your Role: Senior Backend Engineer As a Senior Backend Engineer, you’ll work closely with other teammates to design and build our next-generation platform and product features. The problems you’ll face are diverse and interesting, from modeling graph relationships between tens of millions of entities to augmenting datasets via new data pipeline stages to delivering data to our web UI and other products. However, the responsibilities are not only to deliver the product features that will be 10x our revenue but also to scale up those systems to handle that data, improve how our software operates, and push the envelope of what’s possible. Good communication skills are key in this role as we work closely with our research team of experts in international business and regulation. We believe in teamwork, collaboration, and helping each other to reach our goals. We have a lot of challenging problems to solve and are looking for someone with a positive outlook and a can-do attitude. Reporting directly to the Head of Engineering, you’ll have an excellent opportunity to grow quickly in your career as you develop a breadth of skills alongside a highly motivated, capable team. What You'll Do at WireScreen Work alongside a product manager, UX designer, and other engineers to deliver valuable new product features. Collaborate on our technical vision. Advocate for and prototype new technology solutions that solve real problems Build scalable, reliable, and maintainable systems able to handle more data, more queries, and more insights Design platform APIs upon which multiple product features depend Continuously and incrementally improve our engineering processes, documentation, tools, and systems Who You Are/You Have: 5+ years as a backend or full-stack software engineer Proficiency with relational databases and SQL A generalist approach, and an open mind to trying new ways of solving problems A passion for building software to solve business and product problems Strong technical skills that enable you to deliver a quality product, quickly to market An acumen for working with others to break down problems into smaller deliverables with intermediate milestones Strong communication skills with both technical and non-technical teammates A growth mindset and positive attitude Ideally, You'll Have: Strong Python programming skills Experience with large-scale data processing engines like Apache Spark Experience working with datasets of 10s of millions of entities, especially as a knowledge graph or similar format Experience building and scaling data pipelines Experience collaborating with stakeholders on data-related problems alongside data analysts, data engineers, and data scientists Why WireScreen? Why Now? We are seeking candidates who aspire to excellence; colleagues who are curious, passionate, and determined to build something innovative. We are eager to learn new things and collaborate on projects that aspire to change the way people understand the architecture of global business and its role in shaping our society and the environment. The base pay range for this position is 165-210k per/year and may vary depending on job-related knowledge, skills, and experience NO 3RD PARTY AGENCIES AT THIS TIME PLEASE",
        "url": "https://www.linkedin.com/jobs/view/3713424078"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3967314802,
        "company": "S&P Global",
        "title": "Senior Data Engineer",
        "created_on": 1720636584.792202,
        "description": "About The Role: Grade Level (for internal use): 10 About The Role: Title: Senior Data Engineer – Big Data The Team: You will be an expert contributor and part of the Rating Organization’s Ingestion Pipelines Engineering Team. This team, who has a broad and expert knowledge on Ratings organization’s critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy. All Data Services team members provide leadership, innovation, timely delivery, and the ability to articulate business value. Be a part of a unique opportunity to build and evolve S&P Ratings next gen Ingestion pipelines platform. Responsibilities And Impact : The Data Engineer will support our data department on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects Design & Develop “Transformations” aspects using ELT framework to modernize the Ingestion pipelines and build data transformations at scale Experience in the areas of design and implementation of Ratings Data Ingestion pipelines with modern AWS cloud and other technologies such as S3, Hive, Databricks, Scala, Python and Spark Build processes supporting data transformation, data structures, metadata, dependency and workload management. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources into SQL Server, MongoDB, and others Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc Be in tune with emerging trends Big data and cloud technologies and participate in evaluation of new technologies Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards Compensation/Benefits Information : S&P Global states that the anticipated base salary range for this position is $95,000 to $166,000. Final base salary for this role will be based on the individual’s geographic location, as well as experience level, skill set, training, licenses and certifications. In addition to base compensation, this role is eligible for an annual incentive plan. This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, please click here. What We’re Looking For: Basic Required Qualifications: BE, MCA or MS degree in Computer Science or Information Technology 3+ years of hands-on experience in implementing data lake systems using AWS/Azure cloud technologies such as S3, Databricks, Hive. 1+ years of Expertise in building application using Kafka,APIs and DBMS for building ingestion pipeline for Bulk and incremental data loads. Experience with development frameworks as well as data and integration technologies such Python, Scala Experience in microservices and API design and implementation, with service-oriented architectures, SOAP and RESTful APIs Hands-on experience in developing scalable data pipeline using technologies like Kafka, Databricks, Spark and Scala applying ETL and ELT concepts Deep Experience with three or more technologies of Java/J2EE, C#, AWS, Spark, Python, Scala, any RDBMS, Kafka, Informatica, Angular/ReactJS, Databricks, Kubernetes Experience with Continuous integration and deployment tools like Jenkins and Azure DevOps Experience working in UNIX/Linux environment including shell scripting Strong understanding of cloud native architectures, design patterns and best practices Should be in position to articulate and convert requirements into solution. Knowledgeable in technology and industry trends with ability to develop and present substantive technical solutions Knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally Quality first mindset with a strong background and experience developing products for a global audience at scale Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners Additional Preferred Qualifications: Experience With Machine Learning Libraries and Frameworks (TensorFlow, MLlib, Pandas, Numpy) is an added advantage Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management Ability to prioritize and manage work to critical project timelines in a fast-paced environment Financial services industry experience Right To Work Requirements: This role is limited to persons with right to work in the United States. Return To Work: Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative, Restart, we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. About S&P Global Ratings At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions. S&P Global Ratings is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today. For more information, visit www.spglobal.com/ratings What’s In It For You? Our Purpose: Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People: We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values: Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits: We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our Benefits Include: Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, And Inclusion At S&P Global: At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy. Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning) Job ID: 298437 Posted On: 2024-07-04 Location: New York, New York, United States",
        "url": "https://www.linkedin.com/jobs/view/3967314802"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956153488,
        "company": "Hinge",
        "title": "Data Engineer III, Data Platform Core",
        "created_on": 1720636588.1743987,
        "description": "Hinge is the dating app designed to be deleted In today's digital world, finding genuine relationships is tougher than ever. At Hinge, we’re on a mission to inspire intimate connection to create a less lonely world. We’re obsessed with understanding our users’ behaviors to help them find love, and our success is defined by one simple metric– setting up great dates. With tens of millions of users across the globe, we’ve become the most trusted way to find a relationship, for all. About the Role: As a Data Engineer for our Data Platform team, you will be responsible for maintaining and continuously improving our data platform. We are dedicated to designing, implementing and maintaining Hinge’s data infrastructure, while playing a critical role in selecting and implementing technology that will help Hinge to make data-driven decisions, build a best-in-class product, and enable ML/AI use cases. You will work cross-functionally with multiple engineering teams, providing leadership and advice while serving as a crucial partner to various teams and stakeholders, including Business Intelligence, Product Data Engineering, Data Science, MLE & AI, and more. You will be making a real impact on the Data Platform team and will be key to the success of Hinge. Your work will enable the organization to make data-driven decisions and drive improvements, which will affect the love lives of tons of people. Responsibilities: Design, develop, and maintain core services within Hinge’s data platform. Build and maintain our analytics data warehouse that provides clean, accurate, and robust data sets to be leveraged for reporting, analytics, and machine learning initiatives. Responsible for maintaining and enhancing data pipelines and database management frameworks, which include tasks such as automation, monitoring, alerting, governance, and cost optimization. Work on observability systems that enables holistic system and data quality monitoring. Solicit and incorporate internal user feedback to ensure productivity tooling meets the needs of our developers. Work with our data teams to ensure data is flowing accurately through data creation to our presentation layers. Continue to learn more about the Data Engineering discipline, utilize that knowledge in your deliverables, and identify opportunities to enhance our platform. Participate in our on-call rotation. What We're Looking For: 3+ years of professional/industry experience. Experience in building, automating, and enhancing tools and frameworks for the data platform to streamline pipeline development. Experience modeling data sets for different types of sources and business processes. Experienced with many or all of the following technologies: Python, Go, Scala, Java, Kubernetes, Docker, Terraform, CircleCi, GitHub Actions, Kafka, PubSub, Dataflow, Looker Experience in utilizing cloud environments such as GCP, AWS, or Azure. Experience with databases and Big Data tooling such as Redshift, BigQuery, Databricks, dbt. Strong written and verbal communication skills. Exposure to ML Ops or other data engineering workloads. Effective analytical, troubleshooting, and problem-solving skills. A degree in computer science, engineering, or a related field. $143,000 - $172,000 a year Factors such as scope and responsibilities of the position, candidate's work experience, education/training, job-related skills, internal peer equity, as well as market and business considerations may influence base pay offered. This salary range is reflective of a position based in New York City. This salary will be subject to a geographic adjustment (according to a specific city and state), if an authorization is granted to work outside of the location listed in this posting. As a member of our team, you’ll enjoy: 401(k) Matching: We match 100% of the first 10% of pre-tax 401(k) contributions you make, up to a maximum of $10,000 per year. Professional Growth: Get a $3,000 annual Learning & Development stipend once you’ve been with us for three months. You also get free access to Udemy, an online learning and teaching marketplace with over 6000 courses, starting your first day. Parental Leave & Planning: When you become a new parent, you’re eligible for 100% paid parental leave (20 paid weeks for both birth and non-birth parents.) Fertility Support: You’ll get easy access to fertility care through Carrot, from basic treatments to fertility preservation. We also provide $10,000 toward fertility preservation. You and your spouse/domestic partner are both eligible. Date Stipend: All Hinge employees receive a $100 monthly stipend for epic dates– Romantic or otherwise. Hinge Premium is also free for employees and their loved ones. ERGs: We have eight Employee Resource Groups (ERGs)—Asian, Unapologetic, Disability, LGBTQIA+, Vibras, Women/Nonbinary, Parents, and Remote—that hold regular meetings, host events, and provide dedicated support to the organization & its community. At Hinge, our core values are… Authenticity: We share, never hide, our words, actions and intentions. Courage: We embrace lofty goals and tough challenges. Empathy: We deeply consider the perspective of others. Diversity inspires innovation Hinge is an equal-opportunity employer. We value diversity at our company and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We believe success is created by a diverse workforce of individuals with different ideas, strengths, interests, and cultural backgrounds. If you require reasonable accommodation to complete a job application, pre-employment testing, or a job interview or to otherwise participate in the hiring process, please contact employeebenefits@matchgroup.com .",
        "url": "https://www.linkedin.com/jobs/view/3956153488"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3955971609,
        "company": "IT Accel, Inc.",
        "title": "Public Cloud Database PaaS Engineer",
        "created_on": 1720636589.766636,
        "description": "Public Cloud Database PaaS Engineer Contract-to-Hire Hybrid: NYC or Burlington County, NJ Department Overview : Building a World-Class, Diverse and Inclusive Technology Team. Public Cloud Database PaaS Service is responsible for the solution engineering, design, optimization, integration, automation and maintenance of popular Google Cloud Platform (GCP) and Microsoft Azure (AZ) database PaaS services, such as Microsoft SQL Server, PostgreSQL, No-SQL and Redis. Key responsibilities include R&D for introducing public cloud PaaS to the client's environment, DevOps pipeline development and on-going maintenance, optimization, and enhancement. Job Description : The client's Engineering covers a broad range of exercises and initiatives including requirements gathering, design specification, industry analysis, vendor engagement and analysis, software development, test plans and execution, and operational standards implementation. In this role, we're looking for a candidate with strong Google and Azure cloud architecture, pipeline automation experience and database knowledge. The candidate will provide expertise in database PaaS service design, security, performance, integration, and pipeline development using infrastructure as code while adhering to architecture, engineering, and security standards. Job Requirements : Required Skills Strong experience working with Google Cloud Platform and Microsoft Azure public clouds Extensive experience with database PaaS such as Microsoft SQL Server, PostgreSQL, No-SQL and Redis Strong experience working with DevOps tools such GitHub Actions and Terraform Strong working knowledge Networking, Linux and Windows operating system Strong Problem troubleshooting and root cause analysis skills Ability to quickly learn and develop expertise in highly complex existing applications and architectures Security best practices, Active Directory Agile Technical skills Microsoft SQL Server, PostgreSQL, No-SQL and Redis Terraform GitHub Actions Python Azure CLI/Google Cloud Shell Public cloud network security Cloud application architecture Additional Information: Inspire a positive work environment and help champion quality, innovation, teamwork and service to the business. Learn voraciously, stretch your thinking,",
        "url": "https://www.linkedin.com/jobs/view/3955971609"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3964670511,
        "company": "Harry's Inc.",
        "title": "Senior Software Engineer (Lume)",
        "created_on": 1720636593.541176,
        "description": "Lume is on a mission to normalize body odor beyond the pits and provide people with outrageously effective solutions so they never have to think twice about odor! Our Whole Body Deodorants can be used for any unwanted odor—from pits, to privates and beyond. It's doctor-developed, made with skin-safe ingredients that are gentle enough for the most sensitive parts and clinically proven to control any external B.O. for 72 hours. In 2023, we launched a men's line called Mando. Mando uses the same technology as Lume but has different scent profiles. We are a 6-year-old fast growing, omni-channel deodorant and personal care brand that's transforming the way that humans do hygiene. We joined forces with Harry's, another disruptive brand with great people and infrastructure, to accelerate our growth. We are a team of self-starters that roll up our sleeves and get it done. Our style is collaborative and very fast-paced so an adaptive personality is a must. Overview: Working closely with the software development and creative team, you will develop and create new features and experiences for our customers, working primarily with React and Shopify. Responsibilities include: Leadership of high-impact feature development on shopmando.com Working with other software engineers and architects to develop a full-stack headless eCommerce experience that's well structured, flexible, and will continue to scale with our growing business Build our design system, digital product infrastructure, and set the standard for modern eCommerce development for disruptive brands on the Shopify platform Creating and enhancing current shopping experience Work closely with UX, experimentation, and marketing professionals to ensure the technical feasibility of designs and initiatives while maintaining customer-centric focus Requirements: 5+ years experience in software engineering Experience building websites with React Deep expertise in web and cloud-native development Solid understanding of responsive design, web accessibility standards, and UX best practices Ability to debug and troubleshoot issues with browsers and cloud-based infrastructure Front-end performance optimization and strategies for optimizing Core Web Vitals Self-motivated professional with an interest in eCommerce and experience working in an asynchronous, agile environment Nice to have: Experience working with our core technologies, platforms and framework: Shopify Remix Cloudflare Figma We can't quantify all of the intangible things we think you'll love about working at Harry's, like the exciting challenges we tackle, the smart and humble team you'll get to work with, and our supportive and inclusive culture. That said, our salary ranges are based on paying competitively for our size and industry, and are one part of our total rewards package, which also includes a comprehensive set of benefits and our equity program. The base salary hiring range for this position is $135,000-$145,000, but the final compensation offer will ultimately be based on the candidate's location, skill level and experience. Lume is committed to bringing together individuals from different backgrounds and perspectives. We strive to create an inclusive environment where everyone can thrive, feel a sense of belonging, and do great work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, veteran status, sex, parental status, gender identity or expression, transgender status, sexual orientation, national origin, age, disability or genetic information. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our company.",
        "url": "https://www.linkedin.com/jobs/view/3964670511"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3898766974,
        "company": "Qualitative Financials",
        "title": "Data Engineer / Data Modeler",
        "created_on": 1720636595.6560378,
        "description": "Visa : USC/GC Experience : 9+ Contract : W2 (No C2C) Location : Hybrid schedule -240 Greenwich St, New York, NY 10286 (2 3 Days Work from Office) Look for a Candidate Completely Banking and Financial Background Must have skills client is looking in resume. Mongo DB Python SQL Data Modeling Data Pipeline ETL processes Job Description / Skills Required We seek a data engineer to lead the data modeling, management, and pipeline development for the new digital solution that connects multiple systems across wealth management, investment management, asset servicing, and custody. This role will report to the global engineering lead of the program and work closely with other engineers, architects, and Data Product Managers to design and develop highly scalable and performant infrastructure to support our product and data strategy. Bachelor's degree in computer science or related discipline 6+ years of experience in building highly scalable systems using MongoDB. 3+ years of data pipeline development experience with Python 1+ years of data governance experience Strong understanding of data design patterns culminating into microservices development Experience in developing data pipelines to support event-driven messaging and data processing. Experience in Agile methodologies, either Sprint or Kanban Hands-on experience with release management and CICD deployment workflow processes, from development release through production deployment Strong Technical And Communication Skills Required. Knowledge and experience in financial services or fintech is preferred",
        "url": "https://www.linkedin.com/jobs/view/3898766974"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961278365,
        "company": "Stellar Health",
        "title": "Senior Analytics Engineer",
        "created_on": 1720636597.4385297,
        "description": "About Stellar Health: Historically, US Healthcare has relied on a fee-for-service reimbursement system where providers are paid based on the quantity of patient visits and procedures, rather than the quality of health outcomes. At Stellar Health, we help primary care providers put patient health first. Our platform - a mix of technology, people, and analytics - supports providers at the point of care, delivering real-time patient information, activating practice staff, and empowering providers and care teams with incentives that reward the work they are already doing to keep patients healthy. Using the Stellar App, our web-based, point-of-care tool; practices receive a simple checklist of recommended actions that support the best quality care. Providers and care teams are then paid monthly for each action they complete, and Payors save money in reduced healthcare costs along the way. Stellar is a US-based Health-tech backed by Top VCs ( General Atlantic, Point72, & Primary Venture Partners) with an established product & proven operating model. We've shown that we make a real difference for physician practices and their patients. About the position: The BI Team is at the center of Stellar Health's analytics practice and has an outsized influence on the growth and success of the business. The BI Team is looking for a new member of the team to help build scalable and durable data models with Snowflake and dbt to help power self-service for all teams, primarily focusing on Customer Success and Product. The successful candidate will help scale Stellar as a whole, work with a modern data technology stack, work with healthcare Big Data, and have the opportunity to advance the quality of healthcare in the United States. What you'll do: Collaborate with team members across Stellar Health to collect business requirements, define successful analytics outcomes, design data models, implement data models, and automated data refreshes Design and deliver new analytics data models and schema with dbt, primarily designed using dimensional modeling Define, develop, and enhance the dbt codebase used to bring the Analytics Warehouse to life Develop code that establishes the benchmark for best practices in a high-scale data environment, including source code management, unit testing, CI/CD, and peer code reviews Work with team members to review and approve code and other software artifacts Keep documentation up-to-date in Notion, Docs, and other knowledge bases Advocate for Analytics best practices Keep the team and others up-to-date on plans and progress with Asana and related status meters As Senior Analytics Engineer you should have: 4+ years experience designing and implementing commercial Analytics Data Models, using Dimensional Modeling 4+ years total experience as an Analytics Engineer, Data Engineer, or equivalent 4+ years writing SQL with advanced level knowledge, including various join types, CTEs, partitioning, pivoting, and aggregates 2+ years creating project plans and related data-domain project management materials (design documents, BI wireframes, ERDs, metrics catalogs, milestone plans) 2+ years experience working collaboratively across business and engineering teams in areas like design reviews and code reviews to deliver scalable and high-quality output 2+ years experience working in source code management systems and code approval processes, ideally GitHub 2+ years building BI Dashboards (prefer Tableau or Looker) 1+ years defining and growing dbt best-practices including CI/CD practices, code promotion to production, dbt folder management, and code quality 1+ years working in the Snowflake Cloud Data Warehouse 1+ years working in an established and growing Snowflake/dbt environment with > 50 models, unit tests, Daily Build Job, linked to BI Dashboards Nice to Have: Experience in B2B, SaaS, or Gaming within the Healthtech or Medtech industries Who will love this job: BI & Analytics at Stellar Health is just getting started! Though we're starting with a stable technology stack and a great baseline of descriptive metrics and dashboards, there remains incredible room to grow and make an impact in our business, across our teams, and out to our customers. If you want to leverage your deep analytics technology and delivery experience to create brand new scalable analytics solutions \"the right way\" from scratch, this is your place. Pay: At Stellar, we believe in transparency and we do our best to make sure the company and our candidates are on the same page as it relates to compensation. In addition to posting salary ranges for our open roles, candidates should expect to be asked about compensation expectations and requirements early on in their interview process. Our goal is to highlight when expectations and Stellar's salary range may be out of sync, and work with the candidate to determine whether it makes sense to continue conversations. Where a new hire falls within this range will be based on their individual skills and experience, and how these competencies compare across other employees in the same role. Stellar's bands are designed to allow for individual compensation growth within the role. As such, new hires typically start at the lower end of the range. Stellar rewards performance and outcomes - should you join the company, you will have the opportunity to grow your salary over time. The base salary range for a Senior Analytics Engineer is $150,000-$190,000 and will be eligible for equity and an annual performance based bonus. Perks & Benefits: Stellar offers a carefully curated selection of wellness benefits and perks to our employees: Medical, Dental and Vision Benefits Unlimited PTO (and ask our recruiting team about the ways we make sure employees are actually taking PTO) Universal Paid Family Leave, with up to 21 weeks of fully paid leave available to new parents and caregivers Company sponsored One Medical memberships and Citibike memberships Medical Travel Benefits A monthly wellness stipend that gives employees the freedom to choose where they spend their cash, whether it be on wellness, pet care, childcare, WFH items, or charitable donations Stock Options & a 401k matching program Career development opportunities like Manager Training, coaching, and an internal mobility program A broad calendar of company sponsored social events that for our in-office and remote employees Diversity is the key to our success . Stellar Health is an equal opportunity employer and we are open to all qualified applicants regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, veteran status, or any other legally protected status. We believe that diverse teams -and the different identities, cultures, and life experiences our team members bring to the table- enable us to create amazing products, find creative solutions to interesting problems, and build an inclusive working environment. Stellar Health Employment Privacy Notice At Stellar Health, your privacy and security as a job seeker is a priority no matter where you are in the interview process . As recruiting scams have become more prevalent, please take note of the following practices to ensure the legitimacy of any interaction with our team. Please note that any communication from our recruiters and hiring managers at Stellar Health about a job opportunity will only be made by a Stellar Health employee with an @stellar.health email address. Stellar Health does not utilize third-party agencies for recruitment services and does not conduct text message or chat-based interviews. Any other email addresses, agencies, or forums may be phishing scams designed to obtain your personal information. We will not ask you to provide personal or financial information, including, but not limited to, your social security number, online account passwords, credit card numbers, passport information, and other related banking information until we begin onboarding activities, which will be coordinated by a member of the Stellar Health People Ops Team with an @stellar.health email address. If you are ever unsure whether you are in contact with a legitimate Stellar Health teammate, please contact people-team@stellar.health. If you believe you've been a victim of a phishing attack, please mark the communication as \"spam\" and immediately report it by contacting the U.S. Federal Trade Commission.",
        "url": "https://www.linkedin.com/jobs/view/3961278365"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3840409481,
        "company": "Accroid Inc",
        "title": "System Engineer",
        "created_on": 1720636599.1095612,
        "description": "Title: System Engineer Location: Onsite- BROOKLYN, NY Required Experience- 14+ Years LOCALS TO NJ-NY-PA-CT ONLY Description Assist with integration and testing of a Systems. Support system and component owners; provide quality control and oversight. Identify the appropriate sequence and scheduling of integration efforts for subsystems. Determine the external interfaces requirements necessary to support subsystem integration and testing and arrange to simulate. Identify any resources needed to conduct the integration and test functions, including identifying staffing requirements, tools and test equipment, installation support. Direct the configuration of equipment and subsystems into the PSAC environments. Coordinate, monitor and control all technical activities needed to support integration with the project and program management team. Required- 3 years with Oracle ZFS Appliance 3 years of Ansible configuration and scripting 3 years with Oracle Private Cloud Appliance 3 years with Oracle Exalogic 3 years with GoAnywhere SFTP server 3 years with Centrify on Linux 5 years of Solaris administration Preferred- Minimum 14+ years of experience in a particular technical and/or business application, product, platform, methodology Ability to articulate root cause of complex technical issues and demonstrate the ability to formulate technical options for protecting the production Strong Shell scripting (Bash/Ksh, PERL, Python)",
        "url": "https://www.linkedin.com/jobs/view/3840409481"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3748457848,
        "company": "eTeam",
        "title": "Data Pipeline / ETL Developer",
        "created_on": 1720636600.8439481,
        "description": "Key Skills SQL & Data Warehousing / Business Intelligence skills ETL/ data pipeline development experience Detailed Qualifications / Skills Experience in delivering Data Warehousing/Business Intelligence solutionsPreferably experienced in multiple DW/BI aspects from ETL, Data Access Control, Data quality to Metadata management & data governance Strong SQL skills in complex queries and data manipulation a must Experience in developing ETL / building data pipelines with ETL tools or programming languagesExperience in Pentaho a plus Python programming, shell scripting, java scripting experience a plus Ability to prioritize own tasks and manage project resources and dates Experience in dashboarding and data visualization a plus",
        "url": "https://www.linkedin.com/jobs/view/3748457848"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3971250223,
        "company": "Trepp, Inc.",
        "title": "Senior Software Engineer – Data Group",
        "created_on": 1720636602.5106237,
        "description": "(This position is based in Trepp's NYC office which operates in a hybrid work schedule) The Data Operations Group at Trepp is responsible for creating and developing our suite of software products responsible for our core applications. Being a member of the Data Operations Group allows you the flexibility to learn and hone your skills on various tools and technologies. You will have the opportunity of working with and creating services and pipelines used by teams including Structured Finance Modelers, Research, and Data Platform. Our products focus on data and analytics in structured finance (CMBS), collateralized loan obligations (CLO), commercial real estate (CRE), and banking & lending. This team works closely with our Product Groups to always refine & improve our product and feature sets, data capabilities and delivery, along with creating new Product Workflows. About this role: As a Senior Software Engineer, you are responsible for building complex backend systems that are responsible for Trepp’s core structuring application and providing technical leadership in support of the company’s initiatives in data ingestion and pipeline automation. The position requires an individual who can collaborate on setting mid/long term goals and objectives, then be self-directed to estimate timelines and take ownership of the work, while communicating with stakeholders regularly. The Senior Software Engineer role sets an example for junior team members through modelling best practices and provides guidance and feedback through code reviews, design discussions, etc., and generally supports the knowledge and skills development of junior team members. Responsibilities: Demonstrate software development expertise in building greenfield products and data architectures Ability to quickly learn, understand, and work with new emerging technologies, and methodologies Demonstrate technical ability to back decisions with research and the “why,” and articulate several options, the pros and cons for each, and a recommendation A drive to work on financial data systems & pipelines including experience working with structured finance or commercial real estate datasets Act as a mentor by facilitating code reviews, providing guidance on architecture reviews, helping to unblock team members, and short-circuiting bad design decisions Act as the technical communicator and work closely with internal and external stakeholders for addressing their requests Identify critical infrastructure dependencies / updates and work to plan those tasks Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, source management, and testing Qualifications: Bachelor's or Master's degree in computer science or in a related field 6+ years of experience building backend software systems 4+ years of experience with Python, Java, Scala, or C++ 3+ years of experience with SQL Experience with cloud services like AWS and/or GCP Analyze, design, and implement interactive RESTful services and APIs Exposure to multiple, diverse technologies and processing environments Knowledge of components within a technical architecture Experience with Agile and SDLC, GitHub workflows (or similar) for CI/CD Strong understanding of backend application development methodologies Preferred Skills: Experience building data pipelines using Spark/Airflow Understanding of serverless architectures, containers, and modern application development practices Experience working in Financial Services or related industry. Salary Range: Base salary starting from $165k plus bonus eligible Benefits and Perks: Base + target bonus compensation structure Medical, Dental, Vision insurance 401K (with employer match) Life insurance, long term disability, short term disability all covered by the company Flexible paid time off (PTO) Sixteen (16) weeks paid primary caregiver leave (Biological, adoptive, and foster parents are all eligible) Four (4) weeks paid parental leave Wellness subsidy provided by Trepp Pet insurance Laptop ​+ WFH equipment​ Career progression plan Pre-tax commuter benefit with company subsidy (For NYC-office based employees only) Involvement in Diversity and Inclusion programs Fun company events and volunteering opportunities Workplace Policy: NYC, Dallas, PA, and London office-based positions: Trepp’s offices follows a 3-2 hybrid-working policy with the expectation of in-office work on Tuesday-Thursday and the option to work from home on Monday and Friday. Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Trepp (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status). Trepp, Inc. is an equal opportunity / affirmative action employer, complying with all laws governing employment in each jurisdiction in which operating, and provides equal opportunity to all applicants and employees. All qualified applicants will be considered without regard to race, color, religion, gender, national origin, age, disability, marital or protected veteran status, sexual orientation, gender identity and other status protected by applicable laws.",
        "url": "https://www.linkedin.com/jobs/view/3971250223"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3948418861,
        "company": "Walnut",
        "title": "Software Engineer",
        "created_on": 1720636604.3147547,
        "description": "🏢 Company Description Walnut is building the future of healthcare payments. We are building financial infrastructure for healthcare to make healthcare payments instant, accurate, and transparent. We make moving money through the healthcare system as easy and programmable as moving data. Walnut is building new rails for healthcare payment data transmission – a network between patients, providers, and payers that enables healthcare payments to be real-time, accurate to the penny, and fully transparent. Hundreds of providers of all sizes use Walnut to accept payments, send claims, automate financial processes, and ultimately grow revenue. We've raised over $100 million from leading investors such as Google, 2048 Ventures, Afore Capital, and Newark Venture Partners. 👔 Role Description This is a full-time on-site role for a Software Engineer at Walnut with at least 5-7+ years of experience. As a Software Engineer, you will be responsible for implementing and maintaining back-end web development projects. This includes writing code, developing software solutions, and collaborating with cross-functional teams to enhance our platform's functionality and performance. You will also be involved in troubleshooting and resolving technical issues. 🎯 You will... Build a better and faster way for healthcare payments to happen. Build sizeable features quickly. You’ll go from idea to in-production in a couple of weeks. You’ll move fast, but we believe in spending a bit more time to think through and write more maintainable code so that we can continue shipping a stellar product experience. Impact the bottom line. Every engineer works on something critical to the business and you’ll be able to see your immediate impact in metrics. 🚀 You're good at... Digging into technical problems and communicating them cross-functionally. Seeing the bigger picture - you understand how what you’re working on impacts users and fits into the product as a whole. Prioritizing - managing quick sprints without compromising quality or functionality. 📱 The tech we use... Node Java Python NextJs Typescript AWS Experience Docker Networking MySQL MongoDB GitHub Linear Slack Notion",
        "url": "https://www.linkedin.com/jobs/view/3948418861"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888427505,
        "company": "Stellent IT",
        "title": "Sr. Data Engineer, New York City, NY (Hybrid)",
        "created_on": 1720636605.9032643,
        "description": "Sr. Data Engineer New York City, NY (Hybrid) Phone + F2F Job Description Database optimization and security Expanding and optimizing our data and data pipeline architecture. Build and optimize OLTP databases in support of scalable, high throughput solutions (preferred Postgres) The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Create and maintain optimal data pipeline architecture Automating manual processes, optimizing data delivery Optimal extraction, transformation, and loading of data from a wide variety of data sources Create replication pipelines, secure shares & Data Engineering pipelines to build proposed data model for reporting. Unit and Integration testing of data engineering pipelines built. Skills/Experience Experience with Database security and access control as a separate item, around GCP IAM and CloudSQL integration is a MUST HAVE Advanced working knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases PostgreSQL (aka CloudSQL on GCP) Strong experience in ETL processes using wide variety of data sources Advanced working knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases PostgreSQL (aka CloudSQL on GCP) Strong Experience with Code Management + DevOps: Github Experience with Google Cloud Platform (GCP) cloud services: BigQuery, DataFlow, PubSub, CloudSQL, Cloud Storage, Cloud Composer, VertexAI Working knowledge of Cloud platforms and the technologies that make them work. (Google Cloud Platform) Experience in design and development of large-scale data solutions using GCP services like DataProc, Dataflow, Cloud Bigtable, BigQuery, Cloud SQL, Pub/Sub, Cloud Data Fusion, Cloud Composer, Cloud Functions, Cloud storage, Compute Engine, Looker and Cloud IAM Experience building data processing pipelines to integrate large datasets from multiple sources and formats Experience designing and developing data pipelines from ingestion to consumption using Python, Java, SQL etc. Experience with building data pipelines in streaming and batch mode Bachelor's Degree Certification(s) Preferred GCP Professional Data Engineer Google Cloud Professional Cloud Architect certification and/or other Google Cloud certifications",
        "url": "https://www.linkedin.com/jobs/view/3888427505"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3818368295,
        "company": "AppLab Systems, Inc",
        "title": "Senior Python Developer + Data Engineer (Snowflake knowledge)",
        "created_on": 1720636607.5786486,
        "description": "Hi, I Hope you are doing well. My name is Shivam and I'm an IT recruiter at AppLab Systems. We are having very urgent opening for one of our clients. If you are qualified, available, interested, planning to make a change, or know of a friend who might have the required qualifications and interest, please share your updated resume with credential. I will call you back for detail discussion. Role: Senior Python Developer + Data Engineer (Snowflake knowledge) Location: New York City (3 days per week in the office) Zip Code: 10019 / 10036 C2C or W2 Immigration status: Any visa status Duration - Contract role Project Description: A global team of alternative investment managers passionate about delivering uncommon value to our investors and shareholders. With over 30 years of proven expertise across Private Equity, Credit and Real Estate, regions and industries, we're known for our integrated businesses, our strong investment performance, our value-oriented philosophy - and our people. We are seeking hands-on Data Engineer consultants to build out the next generation data warehouse/mess for the organization. To solve the data availability and access issues of all data across the organization. Enabling a graph of connectivity between 100s of data sets. We need people that are enthusiastic about enabling internal and external clients by streamlining and facilitating easy access to their critical data that is well defined and has established transparent levels of quality. This engineer will leverage our data platforms to achieve this, while providing critical input to extend data platform capabilities. Familiarity with ETL and Cloud Platform data pipeline solutions is critical, as is REST API authoring for data access. Responsibilities: Member of the Business Date Engineering team, work to deliver Data Ingest/Enrich Pipelines, and Access APIs using common cloud technologies. Work with consumers to understand the data requirements and deliver data contracts with well defined SLIs to track SLA agreements. Harness modern application best practices with code quality, API test Coverages, Agile Development, DevOps, and Observability and support. Maintain programming standards and ensure the usage of the pattern / template for API Proxy. Conduct code reviews and automatic test coverage Standardize the CI/CD setup for API management tools and automated deployment. Utilize problem-solving skills to help your peers in the research and selection of tools, products, and frameworks (which is vital to support business initiatives) Mandatory Skills Description: Data Engineer highly proficient in Python development with 6+ years of ETL development experience with Azure cloud-based experience. Can demonstrate the use of modular configurable reusable components, with logging, exception handling and rejection management. Strong Python development skills (rest API, and also for connections, encryption-decryption, managing data and storing data purposes) Solid understanding of API and integration design principles and pattern experience with web technologies. Design object-oriented, modularized, clean, and maintainable code and create policies in Python. Hands-on experience in designing and developing high-volume REST using API Protocols and Data Formats. Experience with test-driven development and API testing automation. Understanding of Data Warehouse Concepts such as Real-time Data Ingestion, Data Modeling, Dimensional Modeling, Denormalized Data structures, etc. Good exposure to the Azure cloud platform, and knowledge of its key components e.g., Azure Blob Storage, Azure Data Factory, etc. Clear understanding of Code testing, e.g., regression, performance & automated tests. Implemented ETL solutions in Snowflake, with knowledge of DB components and its DR capabilities. Exposed to scripting languages e.g., Shell scripts for data transfers, automated deployments, etc. Managed automated deployments using Source code Control & DevOps tools. Knowledge of Cloud Security features and their adoption in the Cloud environment and application development. Bachelor's degree in IT Nice-to-Have Skills: Financial experience: Public and Alternatives Asset Management Familiar in NoSQL\\NewSQL databases Working with Azure API and DB Platforms Strong documentation capability and adherence to testing and release management standards Design, development, modification, and testing of databases designed to support Data Warehousing and BI business teams Familiarity with SDLC methodologies, and defect tracking (JIRA, Azure DevOps, ServiceNow, etc.) Shivam Kamboj Technical Recruiter shivam@applabsystems.com 4365 Route 1 South, Suite 105 ,Princeton, NJ - 08540 Applabsystems linkedin.com/in/shivam-kamboj-16931921a/",
        "url": "https://www.linkedin.com/jobs/view/3818368295"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3918983534,
        "company": "Avani Tech Solutions Private Limited",
        "title": "Data Products Software Engineer",
        "created_on": 1720636609.3028228,
        "description": "Job Title: Data Products Software Engineer Location: Remote - Team works on the East Coast. Worker will need to work East Coast hours so we prefer candidates currently working East Coast, however open to candidates in other time zones who have flexibility. Duration: 10 months PR: $84.00/hr on W2 Description: Hours: 9-5pm EST What is your department's function within the company? Data technology solutions: focus on big data and data pipelines for many groups across organization. For this engagement, they will be focusing on developing components for an app used by data analysts/end users. UI applications for data that we manage. Looking for someone with experience in data and data applications. Description: A Data Product software engineer develops and maintains both the frontend and backend of applications to support data applications. The engineer works closely with data engineers, data scientist, data analyst, and stakeholders to design and develop UI or API solutions that improves and enriches data or AI processes. The role of the Data products Software Engineer is responsible for building and maintaining optimized and highly available data products solutions. In this role you actively participate in requirements gathering, design and architect software engineering solutions. support code reviews, improve performance and optimize existing implementations. Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery. Develop and promote best practices in software engineering. Participate in design and code reviews. Basic Qualifications: Bachelor's degree in Computer Science or equivalent experience in a related field. 5+ years of hands-on experience in full stack development. 3+ years HTML/CSS 3+ years of experience with React 2+ years experience with Next.js framework 1+ years experience developing and deploying full-stack solutions on GCP. 3+ years experience with Python and SQL programming skills. Experience with FastAPI or similar Python based web framework 575M Experience with a relational database such as MySQL or PostgreSQL. MongoDB is a plus Experience with Google Cloud Run. Familiar with REST API concepts and asynchronous patterns. Familiarity with ORMs (object relational mapping) Values software correctness and has a passion for automated tests. Can-do attitude on problem-solving, quality and ability to execute. Strong communication & interpersonal skills Nice To Have: Docker experience. Experience with Angular, and Chart.js. AI coding. Experience with version control systems (Git and GitHub). Familiar with Atlassian products Jira and Confluence. Familiar with Lucidchart. Familiar with BigQuery, Secret Manager, Cloud SQL, and Kubernetes",
        "url": "https://www.linkedin.com/jobs/view/3918983534"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911815686,
        "company": "Aura Intelligence",
        "title": "Staff Software Engineer (Data)",
        "created_on": 1720636610.803123,
        "description": "We are looking for an engineer to join our team and help us unlock the full potential of our most critical asset: our data. You will have direct impact on our revenue and delivering value to our customers by ensuring that our systems can handle the complex relationship between our entities. We are looking for someone who is constantly looking for ways to increase the effectiveness of the team through the use of technology, and who shares our values of being low ego, obsessed, curious, and collaborative. If this sounds like you, we would love to hear from you! setareh@auraintel.com What You Will Do You'll help in executing the roadmap for data infrastructure and systems to power high volume product features using Aura's data Develop and improve our data layers using statistical methods and machine learning, including LLMs, to generate insights and correct inaccuracies Continuously optimize and enhance the algorithms for similarity, relevance, and tagging that power our search engine Qualifications Track record of building highly performant, highly observable, and highly scalable systems 8+ years of experience building data intensive applications Fluency in Python and SQL Experience with messy/ large datasets Solid architectural vision: You have strong intuition around long-term system design and continuous improvements to performance and scaling Experience with Snowflake, Knowledge of orchestration tools Building and maintaining ETL/ELT pipelines Utilization of cloud monitoring and administration tools Understanding of data warehouse maintenance, including data wrangling, model integration, anomaly detection, and comprehensive documentation Awareness of CI/CD practices Be passionate about analytics use cases, data models, merges, and solving complex data problems, then this is the team for you! Preferred Qualifications 2+ years of experience in an early-stage startup. 3+ years of experience in leading teams either as a Technical Lead Proven track record migrating systems in a changing environment that allows for little to no downtime to meet increasing demand Experience in working in Python/strongly typed languages Our stack The Process Our recruitment strategy deviates from traditional software engineering interviews to focus on the practical aspects of the job. Our Interview Process 👨‍💻 Engineering Call 🤖 Product Partner Call 👑 CEO Chat 🔍 Referral Check",
        "url": "https://www.linkedin.com/jobs/view/3911815686"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3948430433,
        "company": "EXL",
        "title": "Senior Data Engineer",
        "created_on": 1720636615.7621846,
        "description": "Jersey City, NJ, USA New York, NY, USA Req #26650 Friday, June 14, 2024 Company Overview And Culture EXL (NASDAQ: EXLS) is a global analytics and digital solutions company that partners with clients to improve business outcomes and unlock growth. Bringing together deep domain expertise with robust data, powerful analytics, cloud, and AI, we create agile, scalable solutions and execute complex operations for the world’s leading corporations in industries including insurance, healthcare, banking and financial services, media, and retail, among others. Focused on creating value from data for driving faster decision-making and transforming operating models, EXL was founded on the core values of innovation, collaboration, excellence, integrity and respect. Headquartered in New York, our team is over 40,000 strong, with more than 50 offices spanning six continents. For information, visit www.exlservice.com. For the past 20 years, EXL has worked as a strategic partner and won awards in its approach to helping its clients solve business challenges such as digital transformation, improving customer experience, streamlining business operations, taking products to market faster, improving corporate finance, building models to become compliant more quickly with new regulations, turning volumes of data into business opportunities, creating new channels for growth and better adapting to change. The business operates within four business units: Insurance, Health, Analytics, and Emerging businesses. Responsibilities Collaborate with client stakeholders to understand product and technical requirements Build and monitor data pipelines to ingest and transform the data into data platform Support large scale data movement, capture data changes and apply incremental data load strategies Contribute to the overall team through mentorship, improvement in ways of working, reviewing code and test plans, verifying that design best practices as well as coding and architectural guidelines, standards, and frameworks are adhered to, communicating risk, and addressing roadblocks as they arise Qualifications (Required) Bachelor’s or Master's degree in economics, mathematics, computer science/engineering, operations research or related analytics areas Demonstrated leadership ability and willingness to take initiative Entrepreneurial hands-on approach to work Superior analytical and problem solving skills Outstanding written and verbal communication skills Effective time management and attention to detail 4+ years’ experience in data analytics or data engineering role Hands on experience in using SQL, Python and Workflow Schedulers (Apache Airflow, Cron) Experience of sourcing and processing data from APIs. Qualifications (Preferred) Experience in using Cloud Platforms (AWS / GCP / Azure) Experience in creating and maintaining data pipelines, data marts and dashboards Experience in using Visualization tools (Tableau / Power BI) Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.) EEO/Minorities/Females/Vets/Disabilities To view our total rewards offered click here —> https://www.exlservice.com/us-careers-and-benefits Base Salary Range Disclaimer: The base salary range represents the low and high end of the EXL base salary range for this position. Actual salaries will vary depending on factors including but not limited to: location and experience. The base salary range listed is just one component of EXL's total compensation package for employees. Other rewards may include bonuses, as well as a Paid Time Off policy, and many region specific benefits. Please also note that the data shared through the job application will be stored and processed by EXL in accordance with the EXL Privacy Policy. Application & Interview Impersonation Warning – Purposely impersonating another individual when applying and / or participating in an interview in order to obtain employment with EXL Service Holdings, Inc. (the “Company”) for yourself or for the other individual is a crime. We have implemented measures to deter and to uncover such unlawful conduct. If the Company identifies such fraudulent conduct, it will result in, as applicable, the application being rejected, an offer (if made) being rescinded, or termination of employment as well as possible legal action against the impersonator(s). EXL may use artificial intelligence to create insights on how your candidate information matches the requirements of the job for which you applied. While AI may be used in the recruiting process, all final decisions in the recruiting and hiring process will be taken by the recruiting and hiring teams after considering a candidate’s full profile. As a candidate, you can choose to opt out of this artificial intelligence screening process. Your decision to opt out will not negatively impact your opportunity for employment with EXL. Other details Pay Type Salary Min Hiring Rate $85,000.00 Max Hiring Rate $124,000.00 Apply Now",
        "url": "https://www.linkedin.com/jobs/view/3948430433"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3954770587,
        "company": "Zepz",
        "title": "Senior / Mid Analytics Engineer",
        "created_on": 1720636617.6581397,
        "description": "About Zepz Zepz is the group powering two leading global remittance brands: WorldRemit and Sendwave. Since 2010, we have been disrupting an industry previously dominated by offline legacy players with our relentless focus on reducing the cost of remittances and increasing safety and convenience for our users. Every day, our people work to unlock the prosperity of cross-border communities through finance and technology - driven by our vision of a world that celebrates migrants' impact on prosperity, at home and abroad. In 2023, our brands helped cross-border communities send over $15bn from 50 countries to recipients in 130 countries. We operate over 2800 money transfer corridors worldwide and employ over 1,000 people globally. Zepz is a remote-first employer, with team members located across six continents Come join us! Zepz.io Our Commitments: We act like owners - We are relentlessly delivering for our users and spending money thoughtfully. We embrace embarrassing honesty - We function best when we're open and honest with one another — especially about our challenges and doubts. We have a bias to action - We get to first outcomes quickly, iterate and learn. We strive to be better - We may make mistakes, but always learn from them. We are inclusive - to better reflect and serve our users. About the role: We are looking for a Senior Analytics Engineer to work within our FinCrime domain. This role will report to the Director of Engineering and collaborate with Analytics, Data Science and the wider organisation. Together you will build and maintain new data models and optimise existing ones to drive insights and recommendations from our data. Embarrassing honesty - we're in the process of consolidating technologies across the two brands and building a Zepz Data Platform. Currently, our tech stack includes: Redshift and BigQuery Kubernetes and AWS Lambda S3 and GCS Python is the primary language used for data processing dbt, Fivetran and Airflow Visualisation in Mode and Full Story As a Senior Analytics Engineer, you will own: Building and maintaining data models to expose reliable data for analysis and reporting Communicating with analysts and business stakeholders to understand the commercial requirements, translating them into a technical solution to ensure reliable self-serve data is available for decision making Developing standards and best practices for data consumption, including educating data consumers on data quality, availability and interpretation Identifying opportunities to reduce complexity and increase efficiency across data models and our data warehouse Ensuring the data and output is of high quality - tested, automated, scalable and documented This role will have an immediate impact on the quality of data presented and used to solve business problems. What we're looking for from you: You are comfortable with daily use of SQL and (preferably) have with a modern cloud datawarehouse environment. You're comfortable automating processes and deploying applications in Python, and developing production standard Python scripts to extract data and perform analysis You have the ability to work confidently with the tools of modern software engineering, for example working with the command line, version control, testing and performing code reviews You see yourself as a problem-solver who wants to understand the business problem and communicate the commercial impact alongside the technical solution You are an advocate for data-driven decision making who strives to improve processes, establish best practices and define standards You have familiarity with dbt to design and implement data models (nice to have) You have an open mind with respect to diversity and inclusivity. Our team (and customers) come from all over the world What we offer you: Please note that the benefits below will apply to permanent roles. We have five core benefits for our talent in the US, UK, Philippines, Poland, and South Africa. If you're not in one of those regions, don't worry - the Talent team can let you know what is available for you specifically: Unlimited Annual Leave: Most Zepz team members are eligible for unlimited annual leave. Colleagues in customer-facing roles, receive a competitive holiday allowance and four recharge days a year. Feel free to make the most of your time off and maintain a healthy work-life balance! Private Medical Cover:  You can opt-in to a Private Medical Insurance scheme. This provides you with access to thorough medical coverage, so you can feel confident in your health and well-being. Retirement: We offer pension schemes to help you plan for and secure your future. Life Assurance: Life assurance is available to give you peace of mind and protect your loved ones in case of the unexpected. Parental Leave: We offer competitive parental leave schemes to ensure you are spending as much quality time with your new bundle of joy as possible. We are also remote-first as an organisation, offering flexibility for you to work where you need to be most productive. In many locations, we have workspaces, which you can use as you desire. Most roles in the Philippines are predominately office-based, with this we offer free meals for those 100% on-site. In addition to the above, you will discover that we have a range of secondary perks (such as the cycle-to-work scheme and employee discounts) depending on your location, to help you thrive at Zepz! Why choose Zepz? Our team of over 1,000 employees is fully distributed across the world. We are working from coffee shops, homes, and co-working spaces — making us one of the larger fully distributed growth-stage startups in the world but we also offer workspace in our talent cluster locations - spaces we can meet, collaborate and connect. We are proud parents, community organizers, farmers, band members, yoga teachers, YouTube influencers, former Olympians, and serial entrepreneurs. We collectively speak over twenty languages, including Akuapem, Amharic, Bengali, Ewe, Fante, Ga, Igbo, Kalenjin, Luganda, Oromo, Somali, Swahili, Wolof, Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Irish, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish. At Zepz, embodying our commitments binds us together. We are collectively passionate about striving to achieve our vision and purpose - to continue to provide the best service to our users. Ready to Apply? Applications will be reviewed on a rolling basis. If interested, please submit your resume along with a cover letter (optional), highlighting why your experience demonstrates you meet the requirements of the role. Please also indicate the countries in which you have work authorization. Confidence can sometimes hold us back from applying for a job. But we'll let you in on a secret: there's no such thing as a 'perfect' candidate. Zepz is a place where everyone can thrive. So however you identify and whatever background you bring with you, and if at all you might need any form of support to make the process as comfortable as possible, please let us know and give us a shot by applying. We want you to be excited to wake up to make an impact every day.",
        "url": "https://www.linkedin.com/jobs/view/3954770587"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888461969,
        "company": "TekIntegral",
        "title": "Senior Data Engineer",
        "created_on": 1720636619.2948964,
        "description": "Senior Data Engineer - Python and Data Bricks Location: New York Hybrid Report on-site on day 1 (3 days per week in the office) Pay Rate: $60 - $65 /hour on C2C Visa: USC GC Duration: 8-12 Months Job Description We are seeking a highly skilled and experienced Senior Data Engineer to join our dynamic team. As a Senior Data Engineer, you will play a crucial role in designing, implementing, and maintaining data pipelines and infrastructure for our big data projects. Your expertise in Java, Python, Spark cluster management, data science, big data, REST API development, and knowledge of Databricks and Delta Lake will be essential in driving the success of our data initiatives. Responsibilities Design, develop, and implement scalable data pipelines and ETL processes using Java, Python, and Spark. Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and design efficient solutions. Manage and optimize Spark clusters to ensure high performance and reliability. Perform data exploration, data cleaning, and data transformation tasks to prepare data for analysis and modeling. Develop and maintain data models and schemas to support data integration and analysis. Implement data quality and validation checks to ensure accuracy and consistency of data. Utilize REST API development skills to create and integrate data services and endpoints for seamless data access and consumption. Monitor and troubleshoot data pipeline performance, identifying and resolving bottlenecks and issues. Stay updated with the latest technologies and trends in big data, data engineering, data science, and REST API development, and provide recommendations for process improvements. Mentor and guide junior team members, providing technical leadership and sharing best practices. Qualifications Master's degree in Computer Science, Data Science, or a related field. Minimum of 6 years of professional experience in data engineering, working with Java, Python, Spark, and big data technologies. Strong programming skills in Java and Python, with expertise in building scalable and maintainable code. Proven experience in Spark cluster management, optimization, and performance tuning. Solid understanding of data science concepts and experience working with data scientists and analysts. Proficiency in SQL and experience with relational databases (e.g., Snowflake, Delta Tables). Experience in designing and developing REST APIs using frameworks such as Flask or Spring. Familiarity with cloud-based data platforms (e.g.Azure) Experience with data warehousing concepts and tools (e.g., Snowflake, BigQuery) is a plus. Strong problem-solving and analytical skills, with the ability to tackle complex data engineering challenges. Excellent communication and collaboration skills, with the ability to work effectively in a team-oriented environment.",
        "url": "https://www.linkedin.com/jobs/view/3888461969"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3960659408,
        "company": "Quasar AI",
        "title": "Go Software Engineer",
        "created_on": 1720636620.9985445,
        "description": "Quasar AI seeks a Go software engineer to work on our components, extensions, and tooling. Quasar AI is a software platform that helps businesses find opportunities in their data, leading to better outcomes. If you want a job in AI and are passionate about writing high-impact, efficient software in go, this is the job you were looking for. Requirements Quasar, the core product, is written in C++ 20. Several components, such as the REST API server, tooling, and plug-ins, are written in Go. These components are usually customer-facing and critical to the user experience. You will join the solution teams and take ownership of these components to ensure that the Quasar engine is leveraged to the maximum of its potential. You will also work on the plug-ins and interfaces to other products that may be written in Go. This is a software engineering position where you will spend most of your time writing code. Requirements Fluency in English Outstanding software engineering skills Solid computer science background Demonstrated experience writing high-performance software in Go, with a good understanding of the network stack No prior experience in database design or AI is required Benefits You are working from home 100% of the time, hybrid, or at the office, as you prefer! The compensation package includes generous paid time off, benefits, and competitive pay.",
        "url": "https://www.linkedin.com/jobs/view/3960659408"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3964931429,
        "company": "Get It Recruit - Information Technology",
        "title": "Senior Data Engineer - Remote | WFH",
        "created_on": 1720636622.8548918,
        "description": "We're seeking a passionate Senior Data Engineer to join our dynamic team! In this role, you'll play a pivotal role in the development lifecycle of data projects, from design and analysis to building and supporting robust data pipelines in the cloud. You'll leverage your expertise to integrate and transform data from diverse sources, ensuring its accuracy and efficiency. Here's What You'll Be Doing Design and configure data management tools to extract and transform data from various sources (internal & external databases) Develop secure and scalable data pipelines that ingest, process, and transfer large volumes of data (structured & unstructured) Build complex database logic and APIs for automated data fetching and storage Design efficient and reusable data components for complex applications Implement best practices for data quality, security, and governance across cloud environments Collaborate with data analysts, scientists, and IT operations to transform data for cutting-edge AI and data products Provide technical leadership for projects and guidance to team members Develop innovative solutions for complex business and production issues What You Bring To The Table 7+ years of experience as a Data Engineer Proven track record of building scalable and secure data pipelines Experience with Python or similar programming languages, ETL tools, relational & non-relational databases Familiarity with data structures, algorithms, software architecture, and complex system design Experience with data governance processes (a plus) Experience with data classification and taxonomy tools (a plus) Bachelor's degree in CS, Information Systems, or a related field (Master's preferred) Strong understanding of cloud platforms (AWS/Google Cloud) Experience with DevSecOps practices and Agile methodologies (Jira, Scrum, Kanban) Excellent communication and collaboration skills Bonus Points For Experience leading a team of data engineers and analysts Experience with secure handling of PHI, PII, and PCI data Proven ability to scale applications for optimal performance We offer a collaborative work environment where your ideas are valued and you'll have the opportunity to learn, grow, and make a real impact! Note: This position is open to direct applicants only. Ready to take your data engineering skills to the next level? Apply today! Employment Type: Full-Time",
        "url": "https://www.linkedin.com/jobs/view/3964931429"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961273960,
        "company": "Charlie Health",
        "title": "Senior Data Engineer",
        "created_on": 1720636625.0583084,
        "description": "Why Charlie Health? Young people across the nation are grappling with a mental health crisis characterized by escalating rates of depression, anxiety, trauma, substance use disorders, and suicide. Individuals who seek support are met by geographical and financial barriers, driving increased urgency for a new approach to behavioral health treatment. At Charlie Health, our mission is to connect the world to life-saving mental health treatment. Our treatment programs combine curated peer groups, individual therapy, and family therapy into personalized, evidence-based treatment plans to provide long-term healing from home. By prioritizing connections among young people with shared mental health experiences and goals, Charlie Health fosters sustainable healing and achieves industry-leading clinical outcomes, with over 90% of our clients seeing improvement in their most severe mental health symptoms. Every member of the Charlie Health team is fueled by an unwavering passion for our mission. If you share this commitment, we invite you to join us in making a tangible impact on the mental health landscape. About the Role The data team at Charlie Health services all parts of our business by sourcing, curating, and activating internally and externally sourced datasets. As a software engineer on the data team, you will be responsible for building ELT pipelines, developing custom DAGs, transforming and warehousing data with DBT, and building integrations between our systems. Our team is comprised of passionate, forward-thinking professionals eager to take on the challenge of the mental health crisis and play a formative role in providing life-saving solutions. We are looking for a candidate who is inspired by our mission and excited by the opportunity to build a business that will impact millions of lives in a profound way. Duties & Essential Job Functions Develop, release, and maintain high quality data pipelines using Python, FiveTran, DBT, and Snowflake Own and guide the development of our data infrastructure Develop custom integrations using Dagster Configure reverse ETL integrations using Hightouch Identify bottlenecks and implement improvements to our data engineering processes, tools, and procedures. We're early and the expectation of folks joining at this stage is that you'll play a huge part in setting and improving how we work Collaborate with data architects and feature development teams to produce db designs suitable for analytics use cases Promote a culture of collaboration and learning across engineering, product, and design team via mentoring, documentation, presentations, or other knowledge-sharing methods Ensure our data is always available by participating in our on-call rotation Requirements Bachelor's degree in Information Systems, Computer Science, Data Science, Analytics, Mathematics, or equivalent practical experience 8+ years experience as a software engineer, with at least 4 years of experience in a data engineering role Deep expertise in SQL. You understand CTEs, aggregation functions, window functions, partitioning and clustering approaches to run correct and highly-performant queries High proficiency in Python and experience using common data engineering libraries such as Pandas, Numpy, and Great Expectations Experience with a modern data stack. Experience with our tools - FiveTran, Snowflake, DBT, Dagster, Hightouch, and Tableau - is a big plus Proficiency in database design; both warehouse (Kimball, Inman), and transactional systems (3NF) Experience with data exploration, profiling, governance, visualization, and activation Proven ability to thrive in an ambiguous and rapidly changing environment Experience working with sensitive data in a regulated environment Expertise in healthcare is a plus Please note: candidates located within 75 minutes' commuting distance of our NYC office are expected to come to office 1 day/week Charlie Health does not provide visa sponsorship. Benefits Charlie Health is pleased to offer comprehensive benefits to all full-time, exempt employees. Read more about our benefits here. Note to Colorado applicants: applications will be accepted and reviewed on a rolling basis. Our Values Connection Care deeply We care personally about every single person in the Charlie Health ecosystem: our clients, providers, and team members alike. Inspire hope We inspire hope with every interaction, reminding our clients that we truly and unconditionally believe in them. Congruence Stay curious We ask \"why\" five times before we're satisfied with the answer. We don't stick to the status quo; we challenge our assumptions and remain humble. Heed the evidence Above all, we're results-oriented. When we find data that calls our original plan into question, we modify or pivot. Commitment Act with urgency We work as swiftly as possible. The mental health crisis is relentless, and so are we. Don't give up Our clients don't give up and neither do we. Persistence is our superpower. Please do not call our public clinical admissions line in regard to this or any other job posting. Please be cautious of potential recruitment fraud. If you are interested in exploring opportunities at Charlie Health, please go directly to our Careers Page: https://www.charliehealth.com/careers/current-openings. Charlie Health will never ask you to pay a fee or download software as part of the interview process with our company. In addition, Charlie Health will not ask for your personal banking information until you have signed an offer of employment and completed onboarding paperwork that is provided by our People Operations team. All communications with Charlie Health Talent and People Operations professionals will only be sent from @charliehealth.com email addresses. Legitimate emails will never originate from gmail.com, yahoo.com, or other commercial email services. Recruiting agencies, please do not submit unsolicited referrals for this or any open role. We have a roster of agencies with whom we partner, and we will not pay any fee associated with unsolicited referrals. At Charlie Health, we value being an Equal Opportunity Employer. We strive to cultivate an environment where individuals can be their authentic selves. Being an Equal Opportunity Employer means every member of our team feels as though they are supported and belong. We value diverse perspectives to help us provide essential mental health and substance use disorder treatments to all young people. Charlie Health applicants are assessed solely on their qualifications for the role, without regard to disability or need for accommodation.",
        "url": "https://www.linkedin.com/jobs/view/3961273960"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3945783706,
        "company": "US Tech Solutions",
        "title": "HR/Employee Data Analytics Engineer",
        "created_on": 1720636626.6056387,
        "description": "Duration: 6 Months Contract, Full-Time Job Type: W-2 Job Description: As an Engineer, you will play an important role in helping the HR teams address the POps (People Operations) related data and analytical needs of their teams and clients across the globe. Your knowledge of people data will enable you to provide action-oriented analyses and accompanying insights to ensure they can be used to provide information and help make thoughtful, data-driven decisions. You'll be detail-oriented and conscientious, analytical and curious. You're a strong problem-solver, who uses both quantitative and qualitative methods to get things done. Responsibilities: Combine information for different sources to create analytical plans that address client/stakeholder needs and execute them. Manipulate and analyze large data sets to distill insights from data and convey findings. Create effective, scalable, and easy to understand reporting solutions (e.g. dashboards). Collaborate with teammates to solve organizational problems. Ability to manage multiple analyses and requests through active prioritization and communication with relevant stakeholders. Experience: Proficient with Spreadsheets and SQL. Experience manipulating large datasets, joining multiple datasets and aggregating data to create metrics to feed into cohesive narratives. Excellent attention to detail and focus on data accuracy. Experience with data Analysis and Analytical Thinking. Experience working in a cross-Functional, collaborative environment, Experience using data visualization (e.g., tables, charts, graphs) to represent analyses to relevant audience. Experience using quantitative and qualitative analytical strategies to measure the effectiveness of programs, interventions, and efforts for a large organization. Skills: SQL HR Data Resource Planning Dashboard Data Analysis Education: BA/BS degree or equivalent practical experience. About US Tech Solutions: US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com. US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Recruiter Details: Name: Karan Email: KaranM@ustechsolutionsinc.com Internal Id: 24-13750",
        "url": "https://www.linkedin.com/jobs/view/3945783706"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3928043895,
        "company": "Executive Staff Recruiters / ESR Healthcare",
        "title": "Informatica data engineer NYC ny ref",
        "created_on": 1720636627.7289317,
        "description": "Company Profile esrhealthcare.com.mysmartjobboard.com Infa data engineer NYC ny Experience level: Mid-senior Experience required: 8 Years Education level: All education level Job function: Information Technology Industry: Insurance Pay rate : $75 per hour Total position: 3 Relocation assistance: No NOTE FROM HM: The Candidate needs to be strong enough in Informatica Power center Development and Data Warehouse Multi-Dimensional modelling along with good SQL and PL/SQL skills. Please screen candidates thoroughly on these skills. Job Summary The Data Engineer is part of a Corporate Analytics team responsible for supporting data and analytics solutions for Client's Corporate Functions. This individual will collaborate with analytics team to design and implement Client corporate data strategy, ensuring reliable data infrastructure and creating data solutions for variety of business use cases. This individual will primarily support on enterprise financial data warehouse and multiple data marts working with various stakeholders and reporting applications team, successfully delivering the data requirement solutions. What you need to have: 8+ years of experience with Oracle and SQL Server databases 8+ years of experience with Informatica Power Center. 8+ years software development experience in one or more of the following areas: ETL, BI and DW 8+ years of experience in DW Multi-Dimensional modelling. Understanding of the Project Delivery Framework and SDLC Understanding of Waterfall and Agile Project Management Methodology Strong analytical, communication and interpersonal skills. Excellent and proven collaboration skills We will count on you to: Designs, develops, automates, and supports complex applications to extract, transform, and load data. Ensures data quality of the warehouse and data marts. Plans and conducts ETL unit and development tests; monitors result and takes corrective action. Work on basic and advanced transformations in informatica power center independently. Performance Tuning of SQLs and handles huge volumes of data. Ability to quickly diagnose the problem areas and come up with solutions and/or workarounds Build, maintain, and enhance all objects packages/functions in PL/SQL to support application process. Translates transformation and movement requirements into functional requirements and mapping designs. Designs automation processes to control data access, transformation, and movement. Ensures source data availability and update accessibility, data integrity, restart ability, and error handling. Participates in the overall development process via architecture guidance, design and code reviews, and estimation and planning assistance Performs other related duties as required Knowledge, Skills, And Abilities Documents and troubleshoot problems and effectively communicate with business and technical team members at all levels What makes you stand out? Excellent communication and presentation skills Domain knowledge in one of more of corporate functions such as HR, Finance, Real Estate is preferred Excellent Problem-solving skills with innovative and proactive approach Ability to recommend and implement best practices and processes Powered by Webbtree",
        "url": "https://www.linkedin.com/jobs/view/3928043895"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3964520882,
        "company": "Tickets.com",
        "title": "Senior Data Engineer",
        "created_on": 1720636629.313066,
        "description": "Tickets.com , an MLB company , delivers innovative, cutting-edge technologies to enable frictionless and unforgettable fan experiences in venues across the globe. Together with MLB, Tickets.com is changing the landscape of the live sports and entertainment industry, delivering new digital venue and ticketing experiences to millions of fans. Our Technology team builds platforms and products that provide a new smart ticketing solution and venue experience. Using cutting-edge technology, our platform and applications are consumed by fans, stadiums, and MLB teams We are assembling a world-class team to build on these experiences, to scale platforms and products that anticipate emerging opportunities, including dynamic pricing and offers and digital, contactless ticketing. Our mission is to provide premium, innovative live experiences for our clients and their patrons. Tickets.com is looking for a Senior Data Engineer passionate about building engaging products for our fans. The Opportunity: The Data Engineering team at Tickets.com builds and maintains data pipelines to integrate baseball fan interaction and transaction data from hundreds of sources into our Data Warehouse for use by our Business Intelligence, Data Science, Analytics, Marketing, Ticketing, Finance, and other internal business teams. In addition, we share this data with all 30 MLB Clubs, and interact with Club staff on a regular basis to ensure they are able to better understand and interact with their fans as well as run ticketing operations using this data. We leverage modern, real-time data-streaming solutions for all of our new data pipeline development, and we love it! We are moving towards Google BigQuery as our Data Warehouse platform. We’re Pythonistas, and regularly develop complex Python scripts to interact with APIs and data stores. And SQL is the lingua franca across all of the teams in our organization that interact with our Data Warehouse, so we speak it fluently. The Senior Data Engineer will be responsible for accelerating and solidifying the Data Engineering team’s development, deployment, and operational support practices by building tools leveraged by the entire Data Engineering team. In addition, the Senior Data Engineer will build new data pipelines and enhance and troubleshoot existing ones. The Senior Data The engineer will report directly to the Director, Ticketing Data Engineering and interact regularly with our team of Senior, Mid, and Junior Data Engineers. Essential Job Functions: High Impact - You’ll develop tools and processes leveraged by the entire Data Engineering team, and work on data sets leveraged to measure fan behavior, enhance our products, optimize marketing pipelines, and directly impact our business’ bottom line. Broad Range of Technology - You’ll have the freedom to use the right tools for the job, whether it’s vanilla SQL or a distributed processing framework such as Apache Spark. We run our processes within Google Cloud Platforms ecosystems, so we can take advantage of their managed services such as Oracle and BigQuery database administration to help us get the job done better or faster. Diverse Data Sources - You’ll work with hundreds of fan engagement data sources, including: Ticket sales from TicketMaster, Tickets.com, StubHub and other ticket brokers; additionally you will help construct data pipelines and analytics solutions to support the buildout of an enhanced MLB-controlled ticketing eco-system that supports broker-to-fan and fan-to-fan ticket exchanges. Diverse Data Sizes - Sure, we’ve got “Big Data” - but we also have plenty of valuable small and mid-size data sets too. You won’t be forced to use complex distributed technologies on small but valuable data sets where using them would be overkill - you’ll get to make decisions on the proper framework for each particular use case. Lead and Coach – You’ll mentor junior Data Engineers, and review design and code produced by them. Build and Support – You’ll embrace the DevOp mentality to build and support data applications in the cloud. You’ll deploy using infrastructure as code, ensuring that servers are treated like cattle, and not pets. You will help define processes that support CI/CD principles. Requirements: 7+ years of experience working on cloud data warehouses and data pipelines with a focus on data engineering and providing technical leadership building scalable and secure data platforms and systems powering intelligent applications. Expertise in Python, specifically interacting with data APIs and automating tasks. Expertise in SQL. Experience working with large (Terabyte-scale) data sets Experience with an MPP Data Warehouse such as BigQuery, Oracle Exadata, Redshift, or Teradata Experience with GCP, OCI, AWS, or Snowflake. Comfort in a Linux environment and with basic server administration tasks. Significant previous experience in a Data Engineering or ETL Engineering role. Experience with GitHub. Preferred Qualifications: Experience with any/all of the following: · Apache Airflow · Google BigQuery · Oracle RDBMS · DevOps - Jenkins/Ansible/Terraform · Docker / Kubernetes · Informatica PowerCenter, Mulesoft, RabbitMQ (used for legacy data pipelines) · Tableau and Jaspersoft (for operational reporting) Required Education: Bachelor’s degree or better in Computer Science or a related technical field or equivalent job experience Range for this position: $165-$185K We offer an Outstanding Benefits Package that includes: Medical Dental Vision STD & LTD 401K Retirement Plan Basic Life & AD&D Supplemental Life Insurance Paid Time Off (PTO, STO, Holidays including Year-End Holiday Break) HSA & FSA Legal Plan Pet Insurance Tuition Reimbursement Flexible Hybrid Work Environment MLB Tickets Tickets.com is an Equal Opportunity Employer.",
        "url": "https://www.linkedin.com/jobs/view/3964520882"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3507292940,
        "company": "Auxilius",
        "title": "Software Engineer (Front End)",
        "created_on": 1720636631.132775,
        "description": "Auxilius, a fast-growing, venture-backed B2B tech startup dedicated to helping innovative Biotechs bring life-saving drugs to market cost-effectively, is looking for a Front-End Software Engineer to own the user experience process and bring creative ideas and energy to the team! The role provides a great opportunity to develop a substantial portion of our platform from design and architecture to implementation and deployment! This position reports directly to the VP of Engineering and will collaborate with cross-functional teams such as product management, engineers, designers, and client managers. Who are you? You are a problem-solving engineer that does well working independently, but also values team collaboration. You know how to ask the right questions to make the user experience the best that it can be! You know how to take calculated risks with a bias to action while challenging our thinking! You are ready to roll up your sleeves to have an immediate impact! We’ll count on you to …. Participate in architecture, design, documentation, development, debugging, and deployment efforts while addressing security, cross-browser, and cross-platform expectations and concerns Create precise interfaces from wireframes or visual mockups using maintainable and reusable codes Be a guru in developing client-side/front end web application Work closely with and incorporate feedback from engineers, the user experience team, and product managers Have expertise in writing software in languages like Angular, Typescript, and Tailwind Be familiar with common front end development tools such as VSCode, Git, Npm, and ESLint Preferred Skills and Qualifications * 5+ years of relevant work experience Bachelor’s Degree preferred Experience developing client-side/front end web applications Experience in Agile development methodologies, scrum preferred Excellent analytical and problem-solving skills Strong leadership presence; comfortable interacting with and presenting to all levels of management Ability to work well independently and with remote teams A sense of humor! Who are we? * Auxilius is building data-driven, clinical trial financial management software for Biotechs. We help clinical trial Sponsors take control over trial costs, manage financial risk, and optimize spending in pursuit of trial outcomes. While our product looks like software, we are providing data, context, and frameworks that help Sponsors make decisions to achieve trial outcomes dynamically and cost-effectively — empowering teams of PhDs to bring drugs to market faster. Auxilius was founded by senior executives from the healthcare information and financial services industries. The founding team has spent almost a decade building workflow and intelligence tools for the Life Sciences industry by infusing data into intuitive SaaS solutions. We are backed by top-tier investors and advised by industry leaders.",
        "url": "https://www.linkedin.com/jobs/view/3507292940"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3957614384,
        "company": "Fathom",
        "title": "Software Engineer (Backend/Data)",
        "created_on": 1720636632.858837,
        "description": "Fathom is on a mission to use AI to understand and structure the world’s medical data, starting by making sense of the terabytes of clinician notes contained within the electronic health records of the world’s largest health systems. Our deep learning engine automates the translation of patient records into the billing codes used for healthcare provider reimbursement, a process today that costs hospitals in the US $15B+ annually and tens of billions more in errors and denied claims. We are a venture-backed company that completed a Series B round of financing for $46M in late 2022. We are looking for an Software Engineer (Backend/Data) to work on data products that drive the core of our business. We want to work with teammates based in New York City area, who are excited about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration. If you’d like to become a backend expert who can unify data, and build systems that scale for both operations and organization, then Fathom is your next big opportunity! Please note that New York area opportunities are hybrid only and require 3 days in office weekly at our financial district location in Manhattan. Your role and responsibilities will include: Developing data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs Building performant and expressive interfaces to the data Creating infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning We are looking for a teammate with: 2+ years of software engineering experience in a company/production setting Relevant experience developing backend, integrations, data pipelining, infrastructure, etc. projects in a production setting Problem solving skills and first principles thinking Strong computer science principles including: algorithms, databases (SQL and NoSQL), logic, etc. Hands-on backend coding and systems design using best practices in a company setting Effective communication and exceptional collaboration skills Bonus points if you have: Proficiency in coding with python or another modern backend language Expertise with wrangling healthcare data and/or HIPAA Experience with managing large-scale data labelling and acquisition Compensation: Salary: $100,000 USD - $175,000 USD Company Equity Benefits: PTO and Uncapped Sick Days Medical/Dental/Vision Coverage 401k Matching $1,500 USD Home Office Budget Virtual and Local Office (San Francisco, New York City and Toronto) Team Building Events Annual Company Off-site",
        "url": "https://www.linkedin.com/jobs/view/3957614384"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3931675102,
        "company": "theMednet",
        "title": "Data Engineer for Stack Overflow for Doctors",
        "created_on": 1720636634.441497,
        "description": "Company Mednet is StackOverflow for doctors. We are a rare company that is profitable, growing over 100% annually and making a positive social impact. Our mission has attracted some of the smartest and most accomplished people in technology and medicine. You will be working with leaders who have advised fortune 500 CEOs , built and sold companies to Google, and designed medical school curriculums. We started with oncology, and are now the most used digital platform in the field: over 80% of oncologists use Mednet. Our business model is based on teaching doctors about newly developed drugs that can improve their patients' outcomes. Our users say we are the best online resource to get help with difficult cases. Our Values Doctors first - Any decision we make must start by asking whether we are helping doctors make better decisions for their patients Have a can-do attitude - No work is below any member of the team. We all pitch in to help achieve our mission Take ownership - Develop your strategy, execute on it, iterate until you get the results that you want Treat each other right - Treat your colleagues with respect, kindness, professionalism and integrity Job Description We’re scaling Mednet to new medical fields this year and rebuilding the underlying knowledge platform to support new insights and products. Improving our data processing and engineering will play a key part in our next phase of development. As our first data engineering hire, you will work closely with our CTO and engineering team. You will be responsible for ingesting and structuring medical data and designing a pipeline and service that enable us to cleanly scale to doctors in new specialties. You will help us scale our editorial operations and evolve our data products by using LLMs and helping design the Mednet knowledge graph. Job Requirements You are passionate about your work having a social impact Experience with designing and building production systems Ability to own standalone mission critical services. 4-10 years of engineering experience. Additional experience (preferred but not required) Experience working with LLMs (open and closed source) and/or NLP Experience with Spark Experience with Go Experience building recommendation systems Experience working with medical claims data Understanding of medical terminology and the healthcare system Experience or familiarity with The Medical Subject Headings (MeSH) Familiarity with the Python scientific computing stack (Pandas, Numpy, SKLearn, etc.)",
        "url": "https://www.linkedin.com/jobs/view/3931675102"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Hawthorne, NY",
        "job_id": 3901359716,
        "company": "Taro Pharmaceuticals",
        "title": "Senior Data Engineer",
        "created_on": 1720636636.3029644,
        "description": "As a member of our Software Engineering Group, we look first and foremost for people passionate about solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle and partner continuously with your many stakeholders daily to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally. A successful candidate is an active listener with good interpersonal communication and can ask for and give feedback to others. The Sr. Data Engineer is someone who constantly communicates with different internal and external stakeholders and business owners. Duties And Responsibilities Work with management and internal stakeholders to define business requirements and analytical needs and execute against them. Develop a deep understanding of existing eCommerce performance, customer, brands, and productivity metrics, and develop new KPIs, metrics, and measures to gauge eCommerce performance. Own regular and ad-hoc analysis on operational performance and projects to continuously improve and scale Alchemee's eCommerce operations. Work to define and structure eCommerce customer and operational data and ensure the reliability and integrity of data sources. Perform data modeling using/modifying existing models. Build automated data flows on AWS by extracting and transforming data from existing e-commerce systems, log files, and API sources. Qualifications Expert-level skills in writing and optimizing SQL. Experience operating very large data warehouses or data lakes. Expertise in ETL optimization, designing, coding, and data ingestion from Rest and GraphQL API. Experience with building data pipelines and applications to stream and process datasets at low latencies. Show efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data. Sound knowledge of distributed systems and data architecture utilizing Lambda, Python, and Jupyter. Experience in AWS Data Analytics platform and related services - S3, AWS Glue, Redshift, Athena, Lake Formation, Lambda, etc. Experience in building data pipelines using Spark/Glue Good understanding of Data Warehousing and Data Modelling concepts on AWS Redshift Experience in designing and optimizing Redshift Workloads Good knowledge of defining data access roles and permission for Redshift Capable of learning and adapting to new technologies along with good Analytical skills Experience working on Visualization tools like AWS QuickSight, Tableau, or Sigma is a plus. Experience in Java, IntelliJ, Bitbucket, Gradle is plus. 4-year degree (Economics, Statistics, Mathematics, Computer Science, MIS, or similar focus) and 3-5 years of relevant work experience. 5+ years of experience in ETL, Data warehousing, Data pipelines, Data Analytics, in Microsoft or Amazon cloud. AWS Data Stack is preferred. As a member of our Software Engineering Group, we look first and foremost for people passionate about solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle and partner continuously with your many stakeholders daily to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally. A successful candidate is an active listener with good interpersonal communication and can ask for and give feedback to others. The Sr. Data Engineer is someone who constantly communicates with different internal and external stakeholders and business owners. Duties and responsibilities Work with management and internal stakeholders to define business requirements and analytical needs and execute against them. Develop a deep understanding of existing eCommerce performance, customer, brands, and productivity metrics, and develop new KPIs, metrics, and measures to gauge eCommerce performance. Own regular and ad-hoc analysis on operational performance and projects to continuously improve and scale Alchemee's eCommerce operations. Work to define and structure eCommerce customer and operational data and ensure the reliability and integrity of data sources. Perform data modeling using/modifying existing models. Build automated data flows on AWS by extracting and transforming data from existing e-commerce systems, log files, and API sources. Qualifications Expert-level skills in writing and optimizing SQL. Experience operating very large data warehouses or data lakes. Expertise in ETL optimization, designing, coding, and data ingestion from Rest and GraphQL API. Experience with building data pipelines and applications to stream and process datasets at low latencies. Show efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data. Sound knowledge of distributed systems and data architecture utilizing Lambda, Python, and Jupyter. Experience in AWS Data Analytics platform and related services - S3, AWS Glue, Redshift, Athena, Lake Formation, Lambda, etc. Experience in building data pipelines using Spark/Glue Good understanding of Data Warehousing and Data Modelling concepts on AWS Redshift Experience in designing and optimizing Redshift Workloads Good knowledge of defining data access roles and permission for Redshift Capable of learning and adapting to new technologies along with good Analytical skills Experience working on Visualization tools like AWS QuickSight, Tableau, or Sigma is a plus. Experience in Java, IntelliJ, Bitbucket, Gradle is plus. 4-year degree (Economics, Statistics, Mathematics, Computer Science, MIS, or similar focus) and 3-5 years of relevant work experience. 5+ years of experience in ETL, Data warehousing, Data pipelines, Data Analytics, in Microsoft or Amazon cloud. AWS Data Stack is preferred.",
        "url": "https://www.linkedin.com/jobs/view/3901359716"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888456777,
        "company": "TekIntegral",
        "title": "ETL Developer/ Database Developer",
        "created_on": 1720636638.0221343,
        "description": "Position: ETL Developer/ Database Developer Location: NYC midtown: Tuesday/ Wednesday/Thursday in office balance WFH. Local candidates only! Duration : 6 month consultant to hire Job Description Mid-town firm looking for a Data developer for on-site consulting position. Our client is adding to their team of Database/Informatica Engineer/Architect to architect strategic ETL and data quality builds. Position Will Assume Design/development Builds Key technologies are: Informatica ETL MySQL/SQL Server Unix shell scripting DB Modeling Control-M Scheduling tool At least 3 years' experience designing ETL processes, preferably as a senior member of a team At least 8 years' experience developing ETL processes At least 8 years of hands-on use of Informatica PowerCenter Tools T-SQL experience. Experience with designing/building/supporting ETL error handling conditions/validations Hands on Linux experience Ruby scripting experience is a plus Please share resume at Career@tekintegral.com OR nkumar@tekintegral.com",
        "url": "https://www.linkedin.com/jobs/view/3888456777"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3956578754,
        "company": "InterSources Inc",
        "title": "Sr Data Engineer",
        "created_on": 1720636639.7227058,
        "description": "Job Title: Sr Data Engineer Job Location: Remote Job Type: Contract Required Skills \" 3+ years of AWS Console, S3, Lambda, Kinesis, Glue, and CloudWatch. \" 3+ years of Kafka streams experience. \" 5+ years of data engineering, data pipeline development, and ETL experience using Python, SQL, and Snowflake \" Experience requesting, transforming, and ingesting data from REST and SOAP APIs \" Proficiency in the Python scripting language, SQL, Cloud databases, and ETL development processes & tools \" Strong understanding of traditional relational databases, data and dimensional modeling principles, and data normalization techniques \" Ability to initiate, drive, and manage projects with competing priorities. \" Ability to communicate effectively with business leaders, IT leadership, and engineers. \" Must have a passion for data and helping the business turn data into information and action. Bonus Skills \" Experience with data streaming technologies like PySpark \" Experience with pipeline technologies like DBT, Apache Airflow or FiveTran \" Experience with MPP technologies and databases \" Experience with data visualization tools like Tableau or Sigma \" Experience with container orchestration tools like Docker or Kubernetes \" Experience with Azure data product offerings and platform \" Experience working with Salesforce and SAP data. \" Experience using Terraform or other infrastructure as code tools. Required Education \" Bachelor's degree in information systems, computer science, or related technical field. About Us InterSources Inc , a Certified Diverse Supplier, was founded in 2007 and offers innovative solutions to help clients with Digital Transformations across various domains and industries. Our history spans over 16 years and today we are an Award-Winning Global Software Consultancy solving complex problems with technology. We recognize that our employees and our clients are our strengths as the diverse talents and opportunities they bring to the table enable us to grow as a global platform and they are causally linked with our success. We provide strategic and technical advice, and we have expertise in areas covering Artificial Intelligence, Cloud Migration, Custom Software Development, Data Analytics Infrastructure & Cloud Solutions, Cyber Security Services, etc. We make reasonable accommodations for clients and employees and we do not discriminate based on any protected attribute including race, religion, color, national origin, gender sexual orientation, gender identity, age, or marital status. We also are a Google Cloud partner company. We align strategy with execution and provide secure service solutions by developing and using the latest technologies that thrive our resources to deliver industry-leading capabilities to our clients and customers, making it convenient for our clients to do business with InterSources Inc. Our teams also drive growth by refining technology-driven client experiences that put the users first, providing an unparalleled experience. This results in strengthening the core technologies of clients, enabling them to scale with flexibility, create seamless digital experiences and build lifelong relationships.",
        "url": "https://www.linkedin.com/jobs/view/3956578754"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3797478705,
        "company": "Nextdoor",
        "title": "Senior Software Engineer - Backend",
        "created_on": 1720636641.3844845,
        "description": "#Team Nextdoor Nextdoor is where you connect to the neighborhoods that matter to you so you can belong. Our purpose is to cultivate a kinder world where everyone has a neighborhood they can rely on. Neighbors around the world turn to Nextdoor daily to receive trusted information, give and get help, get things done, and build real-world connections with those nearby — neighbors, businesses, and public services. Today, neighbors rely on Nextdoor in more than 305,000 neighborhoods across 11 countries. Meet Your Future Neighbors As a Senior or Staff Software Engineer at Nextdoor, you’ll join a focused team of developers, product managers, and designers who are passionate about using technology to cultivate a kinder world where everyone has a neighbor they can rely on. We are a small, high performing team of engineers that wear multiple hats and prioritize impact for our customers. We care about moving fast and delivering impact, without compromising on quality and reliability as guided by our Engineering Principles. You will have the opportunity to learn from your co-workers and teach them. As a team, we will make each other better and build great software. At Nextdoor, we offer a warm and inclusive work environment that embraces a hybrid employment experience, providing a flexible experience for our valued employees. The Impact You’ll Make We believe in empowering our teams to own all aspects of bringing Nextdoor to life. As such, you’ll get the opportunity to make key contributions across our engineering stack - this includes developing and improving frameworks across our backend services, in addition to making direct contributions to your team’s product area. In addition to writing code, you’ll help define the features that we build, through collaboration internally with product managers, data scientists, and other engineering leaders. We believe engineers should have a stake over all aspects of the product - from coming up with the next big ideas to build, through helping set expectations and plan roadmaps, all the way through understanding the impact of new features through rigorous data analysis. As your career at Nextdoor develops, you’ll also get the chance to grow your role towards what you’re most passionate about. Your Responsibilities Will Include Backend development in a variety of languages/frameworks including: Python/Django Kotlin / JVM Go SQL GraphQL Redis Postgres Kafka AWS Mentoring a team of talented engineers designing and building the next generation of Nextdoor Collaborating with product management, data science, and design to ensure we build the right things to maximize impact on neighbors Working with engineers in Toronto, New York, San Francisco and beyond Participate in in-person Nextdoor events, trainings, off-sites, volunteer days, and other team building exercises Build in-person relationships with team members and contribute to the KIND culture that Nextdoor values What You’ll Bring To The Team 6+ years of experience as a Software Engineer and a Bachelor's degree in Computer Science, or equivalent work experience High-initiative leader who can drive technical vision to enable the rapid iteration of Nextdoor’s product Strong coding and debugging abilities across multiple systems and domains Experience designing, building and deploying flexible backend systems at scale Strong desire to learn about new technologies and systems Rewards Compensation, benefits, perks, and recognition programs at Nextdoor come together to create one overall rewards package. The starting salary for this role is expected to range from $153,000 to $230,000 on an annualized basis, or potentially greater in the event that your 'level' of proficiency exceeds the level expected for the role. Compensation may also vary by geography. We also expect to award a meaningful equity grant for this role. With equal quarterly vesting, your first vest date would be within the first 3 months of your start date. Overall, total compensation will vary depending on your relevant skills, experience, and qualifications. We have you covered! Nextdoor employees can choose between a variety of great health plans. We cover 100% of your personal monthly premium for health, dental, and vision – and provide a OneMedical membership for concierge care. At Nextdoor, we empower our employees to build stronger local communities. To create a platform where all feel welcome, we want our workforce to reflect the diversity of the neighbors we seek to serve. We encourage everyone interested in our purpose to apply. We do not discriminate on the basis of race, gender, religion, sexual orientation, age, or any other trait that unfairly targets a group of people. In accordance with the San Francisco Fair Chance Ordinance, we always consider qualified applicants with arrest and conviction records. For information about our collection and use of applicants’ personal information, please see Nextdoor's Personnel Privacy Notice, found here.",
        "url": "https://www.linkedin.com/jobs/view/3797478705"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3971227115,
        "company": "PSRTEK",
        "title": "Sr Interop- Data Engineer (Remote)",
        "created_on": 1720636644.9092033,
        "description": "Sr Interop- Data Engineer Location: - Remote Job Description Responsibilities: - Design, develop, and maintain APIs with a focus on .NET, ensuring high performance and scalability. Implement and manage interoperability standards including HL7 V2/V3, ADT, FHIR, and CCDA. Utilize Firely and Azure FHIR services for efficient data integration and interoperability. Collaborate with cross-functional teams to gather requirements and deliver solutions that meet business and technical needs. Ensure data quality, integrity, and security across all interoperability processes and platforms. Provide technical leadership and mentorship to junior engineers. Stay updated with the latest industry trends and technologies to continuously improve interoperability practices. Educational Qualifications: - Engineering Degree – BE/ME/BTech/MTech/BSc/MSc. Technical certification in multiple technologies is desirable. PSRTEK is a reputed technology recruitment and IT staffing brand with a global footprint and an admired client base. As an ideas and innovation powerhouse with a culture of excellence, we bring remarkable expertise and deliver powerfully transformative results.",
        "url": "https://www.linkedin.com/jobs/view/3971227115"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888438521,
        "company": "Extend Information Systems Inc.",
        "title": "Azure Data Engineer",
        "created_on": 1720636646.5935712,
        "description": "Job Profile : Azure Data Engineer Job Location : New York (Day 1 Onsite) Job Description 7+ years of proven industry experience; bachelor's degree in IT or related fields Must-have Experience working in cloud data platforms such as Azure and Snowflake Hands-on development expertise in Azure Data Factory, Azure Data Lake Storage, Snowflake, Azure SQL database Good-to-have Create Talend ETL jobs to extract data from multiple data sources and load into data marts Design object-oriented, modularized, clean, and maintainable code in Python etc. Design, development, modification and testing of databases designed to support Data Warehousing and BI business teams Familiarity with SDLC methodologies, defect tracking (JIRA, Azure DevOps, ServiceNow etc.) Demonstrated track record of full project lifecycle and development, as well as post-implementation support activities Thanks & Regards, Shubham IT Recruiter Shubham@extendinfosys.com (571)-547-2870 Extend Information System INC",
        "url": "https://www.linkedin.com/jobs/view/3888438521"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3813096298,
        "company": "1872 Consulting",
        "title": "Senior Data Engineer",
        "created_on": 1720636648.2337692,
        "description": "RESPONSIBILITIES Build reliable data pipelines to clean , aggregate , and transform large volumes of data from multiple sources. Develop versatile software components to extract useful information from various unstructured or semi-structured text data. Implement advanced search functionalities and improve the efficiency of search indexing . Work closely with data scientists to develop , test and iterate data models and algorithms . Contribute to company-wide data privacy compliance efforts. REQUIRED Minimum 6 years of experience in the field Extensive experience in building large scale data pipelines with mainstream big data stack. Strong expertise in extracting useful information from unstructured and semi-structured text data. Strong software development skills and highly proficient with Java is a plus. Professional working experience with Elasticsearch , Apache Beam , Spark , and GCP Dataflow a big plus. Strong expertise in NLP or Text Mining is also a big plus.",
        "url": "https://www.linkedin.com/jobs/view/3813096298"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956043228,
        "company": "CAIS",
        "title": "Senior Data Engineer",
        "created_on": 1720636650.0172486,
        "description": "About CAIS CAIS is the pioneer in democratizing access to and education about alternative investments and structured notes for independent advisors, asset managers, and bank issuers, empowering them to engage and transact on a massive scale. We believe that the combination of industry-leading technology and human interaction throughout the pre-trade, trade, and post-trade experience delivers superior operational efficiency and a world-class client experience. CAIS provides advisors with a broad selection of alternative investment strategies, including private equity, private credit, real estate, infrastructure, hedge funds, and structured notes. CAIS supports over 34,000 advisors who oversee more than $4.5 trillion in network assets. Role Overview We are looking to hire a Senior Data Engineer into our technology team. You will design, develop and automate secure, robust, and high-performing data platform solutions to drive CAIS business growth using Python, Kotlin, Snowflake, DBT and Kubernetes. Key Responsibilities Design and develop data platform solutions. Automate data pipelines and workflows. Ensure the security and robustness of data solutions. Collaborate with cross-functional agile teams on mission-critical applications. Skills & Experience Required Degree in Computer Science or Software Engineering, or relevant industry experience. 5+ years of strong programming experience with expertise in extracting and transforming data, object-oriented programming and ability to write easy-to-scale, high-quality code . Strong understanding of AWS and how to create secure infrastructure and data pipelines . Schema design and dimensional data modelling. Proficiency in Python packaging and deployment. Knowledge of Airflow/DAGS and data pipelines. Extensive experience with DBT and Snowflake for data warehousing, demonstrated through the creation and management of complex SQL/ETL/ELT data workflows. Familiarity with cloud-native applications and CI/CD environments. Strong multi-threading and concurrent programming knowledge . Flexibility with programming languages (Kotlin, Java, Python). Experience with Kafka or similar technologies. Proficiency with Terraform. Highly Advantageous Experience with FiveTran . Knowledge of AI/ML. Skills in Typescript and React. Proficiency with Docker, Kubernetes, and AWS Experience as a software engineer building Java or Kotlin server-side applications. Expertise with Spring, Spring Boot, Spring Data, Spring Security, etc. D esigning , building and deploying REST APIs Experience with Gradle/ Maven build tools CAIS is consistently recognized as a Best Place to Work, and our culture is at the heart of our success. We are committed to fostering an inclusive environment where employees can be their most authentic selves and feel inspired and supported to bring their voice forward to drive community, growth, and innovation. We are an equal opportunity employer, and do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. Learn more about our culture, benefits, and people at https://www.caisgroup.com/our-company/careers . CAIS’ compensation package includes a market competitive salary, a performance bonus, and exceptional benefits. If you are located in New York, New York, the base salary range for this role is $190,000 - $235,000 . Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. CAIS offers a comprehensive benefits package that includes generously subsidized healthcare with 100% employer paid dental and vision insurance, an employer matched retirement plan, wellness programs, and flexible PTO and generous parental leave. Additionally, CAIS offers a hybrid in-office model. For more information on our benefits and career opportunities, please visit our website: https://www.caisgroup.com/our-company/careers .",
        "url": "https://www.linkedin.com/jobs/view/3956043228"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911863246,
        "company": "Unreal Staffing, Inc",
        "title": "Frontend Software Engineer",
        "created_on": 1720636651.7948723,
        "description": "About The Role What Early Engineering Means to us Joining us at this early stage means you'll be instrumental in shaping not only the technical but also the cultural landscape of our company. Together, we'll tackle the toughest technical challenges head-on, evolving and innovating as we grow. As the team expands, your expertise will be the cornerstone upon which we build our success. Requirements Your Responsibilities Solving Complex Challenges: Dive into our most intricate problems, such as streamlining onboarding flows and iterating on prompts, among others Crafting User Experiences: Influence how users interact, ensuring intuitive and delightful experiences Optimizing Frontend Performance: Fine-tune our frontend to deliver optimal performance and responsiveness A/B Testing and Iteration: Conduct A/B tests to enhance user success rates and iterate on improvements Greenfield Projects: Lead the definition and scoping of new projects that propel the company forward Customer Collaboration: Engage closely with customers to understand their needs, drive their success, and own end-to-end solutions Cultural Leadership: Serve as a cultural cornerstone within the team, embodying our values and fostering collaboration Our Technology Stack If You're Curious Frontend: React with Typescript Backend: Django for web servers, Flask for microservices Programming Language: Python Database: Postgres Cloud Provider: Google Cloud Platform Benefits Competitive salary range: $130,000 - $170,000 annually Equity options to share in our success and growth Comprehensive health, dental, and vision coverage for you and your family Flexible working hours and the option for remote work Professional development opportunities, including access to conferences and courses Generous vacation and paid time off Company-sponsored social events and team-building activities to foster camaraderie and collaboration",
        "url": "https://www.linkedin.com/jobs/view/3911863246"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3812552267,
        "company": "ActionIQ",
        "title": "Senior Backend Software Engineer - Data Platform",
        "created_on": 1720636655.7197962,
        "description": "What You'll Be a Part Of: ActionIQ is a new kind of customer data platform that lets marketing teams tap directly into central data sources and activate it anywhere in the customer journey. Unlike traditional CDPs, ActionIQ keeps data securely where it lives and makes it easy for marketers to design personalized interactions that unlock revenue across the entire customer lifecycle. We are backed by top-tier VCs Andreessen Horowitz, Sequoia Capital, and March Capital. We partner with enterprise brands such as Albertsons, e.l.f., Dell, The Washington Post and many more to achieve growth through extraordinary customer experiences. The Team You'll Join: The Data Platform team at ActionIQ plays a pivotal role in building and operating our big-data platform and core product offering. We develop the Scala code base used by our low-latency, high-throughput, reliable backend APIs and ETL processes to support a growing feature set. You'll work in all areas of the software development life cycle to launch new features and improve and refactor our backend systems. As a senior member of the team, you'll mentor early career engineers, make well-reasoned tech vs. product trade-offs, and work collaboratively across teams to deliver and support a quality product and platform which ingests, models, queries, and exports multiple terabytes of streaming and batch data every day. How You'll Contribute: Deliver high-quality, maintainable code. Operationally ensure services meet uptime and availability SLAs. Work with others to break down projects into smaller units of work with intermediate milestones. Collaborate with product managers, engineers, and architects to design and implement features and improvements throughout multiple areas of the platform. Mentor early career engineers. Design and build distributed services that are fault-tolerant, scalable, testable, maintainable, and work with large amounts of data on the cloud. Drive the team to build APIs efficiently. Use the cloud to manage data and systems. Optimize systems for improved performance and scalability. Work with technologies such as Kafka, Spark, and other tools relevant to our data platform. Play a key role in the end-to-end lifecycle of projects, from design and development to testing, implementation, and post-implementation support. What You Bring: 5+ years of experience as a backend software engineer. Experience working in a backend language, such as Java, Scala, Golang, etc. Experience leading the implementation of a large product feature or infrastructure changes. Experience with Spark, Kafka, and stream processing technologies. Experience with container orchestration systems, such as Kubernetes. Experience in analyzing, diagnosing, and problem-solving with large-scale distributed systems/data and cloud-based platforms. Experience working with both SQL and NoSQL databases Effective communication skills with technical and non-technical stakeholders. Experience working in an agile team environment. Excitement to work in a team environment with other engineers and product managers on service consumed by other engineering teams. Compensation: Our compensation package includes base salary, stock options, and the great benefits shown below. The salary range for this role is: $185,000 - $210,000 Benefits & Perks Preview: Stay Happy and Healthy: Enjoy leading Medical, Dental and Vision benefits, 401k, FSA, Commuter Benefits, Gym Reimbursement, flexible PTO and 12-weeks paid parental leave Accelerate Your Career: Opportunities to explore, enhance, and expand your skill set through conferences, workshops, and access to Udemy learning courses. Enjoy the View: We have a beautiful office in NYC right on Madison Square Park, and local employees come into the office on a hybrid schedule, three days a week (M, W, Th) . Office perks include catered lunches, a stocked kitchen with beverages and snacks, and monthly social hours. Join a Community: Work with a fun, inclusive, and smart team of people as we build a New York City based enterprise software company. For additional information about all of our benefit offerings, check out our Careers page. Learn from your future colleagues: For the latest on our people and products visit: Product Blog Tech Blog Life At ActionIQ Your Interview Journey: Check out this guide for an overview of our interview process. ActionIQ is committed to building an inclusive, equitable, and diverse organization. We embrace equal opportunities for all applicants and want to foster a culture of belonging for our employees. We recognize and appreciate that the more inclusive we are, the better we will function as a team. AIQ welcomes applicants of any race, color, ancestry, religion, sex, national origin, gender identity, gender expression, age, marital or family status, disability, military veteran status, and any other status or background.",
        "url": "https://www.linkedin.com/jobs/view/3812552267"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3920280872,
        "company": "Cockroach Labs",
        "title": "Software Engineer, Backend (Console) - New York, NY",
        "created_on": 1720636657.2745466,
        "description": "Databases are the beating heart of every business in the world. Cockroach Labs is the creator of CockroachDB, the planet's most highly evolved cloud-native, distributed SQL database that scales fast, survives anything, and thrives anywhere. Join us on our mission to unshackle teams from the constraints of their database and enable every developer to build world-changing applications! About The Role CockroachDB Cloud provides CockroachDB to anyone who needs to scale fast, survive anything, and thrive everywhere. We are looking for a backend software engineer who is excited to focus on the server side components of our Cloud Console application. The Console is our control plane application for CockroachDB Cloud and it allows users to manage clusters across their organization. Our team has broad ownership and some domain area examples include the signup/login/onboarding flows, creating/organizing/managing clusters, notifications and billing, and managing roles and permissions of a user or service account. This ownership also includes the external facing surfaces in which a user can interact with the control plane including the Console UI, Terraform, API, and other CLI tools. The Console team’s mission is to bring the power of CockroachDB to every developer, through a trusted managed-service offering that enables them to easily setup, manage, and operate their clusters for their world-changing applications. Working closely with our SRE team, Frontend and other Backend Engineers, and Database Engineers you will be part of a collaborative culture striving to make data easy at global scale by integrating distributed databases and the cloud with a world-class developer experience. You Will Design, build, test, and improve CockroachDB Cloud. You bring your expertise and commitment to excellence to build the best cloud database service for our users, partners, and customers. Develop in Go on the server-side, but if you don't know it, you'll learn while you're here. Collaborate with engineers, product managers, and designers across our cloud and database teams to design, implement, and deliver features that remove the headaches of database operations for our users. Make sure that as our DBaaS rapidly grows it remains scalable, survivable, and consistent. Take part in a collaborative culture and exchange knowledge with a highly experienced technical organization. The Expectations In the first month, you will join your engineering team and start to learn about our production systems, software development workflow, and the architecture of CockroachDB and our cloud offerings. We believe that it's essential for you to take this time to become familiar with our technology, company, and our culture. After three months, you'll be a fully-fledged member of the Cloud Console team and feel comfortable contributing to our platforms. You will begin determining the parts of our product that most interest you and work with your manager to focus your efforts on projects that align with your interests and our goals. We want our users to have a phenomenal experience using our product. You play a crucial role in making CockroachDB Cloud a joy to use, and as our team grows, you will have the opportunity to shape the direction of development for CockroachDB Cloud and CockroachDB. We also offer technical training and experienced mentorship to help you learn and advance your career into whatever you wish it to be. You Have A passion for working on complex technical products, particularly the design and implementation of modern, highly available web applications. Experience developing robust, scalable web applications using programming languages like Go, C/C++, Java, and Python. Experience with systems design, API design, and infrastructure including tooling such as Kubernetes, AWS, GCP, and Azure. Experience and interest in the Identity and Access Management (IAM) domain. Experience building collaborative relationships with your colleagues. You enjoy being part of the code review process and partnering with your teammates on challenging problems. Comfort in understanding how to deliver value within a rapid, iterative, release cycle. A genuine interest in creating great end-to-end experiences for developers. 2+ years of relevant experience. We are scaling fast and every contributor counts, from earlier career engineers who want to learn and grow alongside the company to seasoned experts who can lead and mentor. A BS in Computer Science or equivalent experience. The Team Jordan Lewis - Senior Director, Engineering Jordan is the Head of Engineering for CockroachDB Cloud. He’s responsible for the teams that build, maintain and keep CockroachDB Cloud reliably serving the needs of Cockroach Labs’ most demanding customer base. He joined Cockroach Labs as a database engineer in 2016 when it was just 25 people before moving into engineering leadership and most recently moving to lead the Cloud organization. Jordan lives in his hometown of Brooklyn NY with his wife. Outside of work he enjoys folk music and riding his electric scooter around town. Isaac Wong - EVP of Engineering Isaac is responsible for the health of the engineering organization at Cockroach Labs. He partners closely with teams to ensure we have a balanced culture that promotes quality and innovation in pursuit of our goals. Before joining Cockroach Labs Isaac was in life sciences for 16 years with Medidata Solutions where he had a front row seat on the exciting ride from a 30 person startup to more than 2000 people worldwide. But the lure of distributed, resilient, and consistent SQL databases, along with the amazing technology and culture at Cockroach Labs proved too much. When not working he likes to draw, play the piano, and search NYC for cannoli's with his wife and kids. Our Benefits Competitive Health Insurance Coverage (for you & your dependents!) Paid Parental Leave (with baby bucks) Flexible PTO Learning & Development Budget Relocation Support (as applicable) Cockroach Labs is proud to be an Equal Opportunity Employer building a diverse and inclusive workforce. If you need additional accommodations to feel comfortable during your interview process, please email us at accessibility@cockroachlabs.com. The annual anticipated base salary range for U.S. candidates for this role is USD $115,000 to $160,000, plus commission if a sales role. We set standard ranges for all U.S.-based roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location. Actual salaries may vary and fall outside of this range depending on factors such as a candidate’s qualifications, geographic location, skills, experience, and competencies. In addition, we are often open to a wide variety of profiles, and recognize that the person we hire may be less experienced (or more senior) than this job description as posted. Salary is one component of the Cockroach Labs’ total rewards package, which includes stock options, health insurance, life and disability insurance, funds towards professional development resources, flexible PTO, paid holidays, and parental leave, to name a few! Salaries for candidates outside the U.S. will vary based on local compensation structures.",
        "url": "https://www.linkedin.com/jobs/view/3920280872"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Manhattan, NY",
        "job_id": 3961553657,
        "company": "NYC Taxi and Limousine Commission",
        "title": "IT Data Engineer",
        "created_on": 1720636658.9523034,
        "description": "The New York City Taxi and Limousine Commission (TLC) is the City agency responsible for regulating for-hire transportation in New York City, including taxis, street hail liveries, high-volume for-hire services such as Uber and Lyft, black cars, luxury limousines, livery vehicles, commuter vans, and paratransit vehicles. The TLC licenses about 175,000 drivers, 115,000 vehicles, and 1,000 businesses, which together transport more than a million passengers a day, making TLC the most active for-hire transportation regulatory agency in the world with oversight of a key component of the City’s transportation network. With the introduction of new apps and technologies, TLC is on the front lines of a rapidly changing mobility landscape and our innovative efforts--whether regulating driver pay, ensuring wheelchair accessibility, working to eliminate traffic fatalities, or preventing discriminatory service--often serve as a model for other cities. The successful candidate will serve as a Data Engineer / Architect reporting to the Director of IT in the IT division. Responsibilities Will Include Research, perform and manage the deployment of data and data objects changes to all TLC database environment. Design and implement standards for resource provisioning in Azure Cloud. Perform administrative duties for resources provisioned in Azure Cloud including monitoring of health, availability, reliability and performance. Setup dashboards demonstrating current and forecasted cost of cloud (Azure) resources. Ensure Installation, maintenance and configuration of database servers, Integration tools (SSIS, Informatica etc), Reporting tools (SSRS, PowerBI etc) on all environments meet TLC’s data processing requirements. Research, design and develop current processes to automate standard data administration tasks to streamline manual processes. Investigate root cause, monitor and respond to production issues, outages, etc. Create and maintain database queries, stored procedures, SQL Jobs, SSIS packages, SSRS reports, and other data and database components required to support critical business and applications Investigate, tune and troubleshoot SQL, queries to ensure they are performing optimally Document data designs, processes, solutions and root cause analysis results Research and support legacy applications data, and ad hoc reports from other divisions. Analyze and organize raw data. Build data systems and pipelines Evaluate business needs and objectives Investigate and interpret trends and patterns Prepare data for prescriptive and predictive modeling Combine raw information from different sources Research ways to enhance data quality and reliability Investigate and identify opportunities for data acquisition Minimum Qualifications A baccalaureate degree from an accredited college and six years of satisfactory full-time experience related to the area(s) required by the particular position; or Education and/or experience which is equivalent to \"1\" above. Preferred Skills The preferred candidate should possess the following skills: - Experience writing SQL Server Integration Services (SSIS) packages for ETL and SQL Server Reporting Services (SSRS) for reports - Experience in data modeling, database design and well versed with DBMS best practices - Experienced in on-premises and cloud SQL Servers installations - Experience optimizing and tuning queries - Experience administering databases is a plus - Experience with Power BI is a plus - Experience with Informatica is a plus - Ability to see tasks through to completion without significant guidance - Strong issue resolution and investigation skills - Ability to articulate and document the steps taken to resolve an issue. - Strong oral and written communication skills and the ability to clearly articulate to all project members and stakeholders. - Flexibility to work overtime as required (may need to work various shifts to support deployments or production validation activities during peak times). One or more of the following certifications are preferred: - Microsoft Certified: Azure Database Administrator Associate - Microsoft Certified SQL Database Administrator Public Service Loan Forgiveness As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/. Residency Requirement New York City Residency is not required for this position Additional Information The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy. , $100,000.00 – $135,000.00",
        "url": "https://www.linkedin.com/jobs/view/3961553657"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3925500483,
        "company": "Cherre",
        "title": "Cloud Systems Engineer",
        "created_on": 1720636660.658959,
        "description": "Cherre is the real estate industry's leading data management platform, powering more than $3 trillion AUM globally. Our end-to-end platform helps clients connect, transform, analyze, and act on trusted data to increase efficiencies, reduce risks, gain visibility into market trends, and make strategic moves in response to changing market conditions. Cherre is looking for experienced Cloud Systems Engineers who are interested in working with a fast-growing organization building industry-leading real estate data services. You will be joining a small team using cutting edge technology and tools to build and support infrastructure for our diverse environment including customer facing applications, large scale data processing, and APIs. As a Cloud Systems Engineer, you will: Deploy and test new software tools, both internal and client-facing Design and execute safe maintenance procedures for production systems Consult with other teams to support their infrastructure and architecture decisions Build tools to reduce maintenance toil and enhance observability Maintain Infrastructure as Code automation and expand the coverage of IAC throughout our systems Participate in incident response, root cause analysis, and postmortems, helping to address production issues and make sure they don't happen again Participate in cross-team workgroups to set standards and unblock projects You'll be a great fit for this role if: You have experience building on public cloud infrastructure (e.g. AWS or GCP) and Kubernetes You're a firm believer in IAC, but also understand its limitations You understand the value of CI and CD and how to make them work for developers You're not afraid to get hands-on with production systems, but are happiest when building tools to manage production for you You reach for logs, metrics, and dashboards when something unexpected happens Technologies we use: Google Cloud (GKE, BigQuery, GCS, Cloud SQL) Kubernetes (including standard resources and custom operators) GitOps (Flux) IAC (Config Connector, Terraform) CI/CD (GitHub Actions, Google Cloud Build, Helm) Monitoring (Google Cloud Monitoring, Karate) GraphQL (Hasura) ETL processes (Airflow) BI Dashboards (PowerBI, Looker) Python Node.js Benefits Equity Range of Healthcare Plans Paid Parental Leave Unlimited Vacation Flexible Work Schedule Compensation: $120,000-175,000/ year If this opportunity sounds interesting, apply or reach out to our internal talent team. We are happy to tell you more about Cherre: the technology we work with, the problems we solve, the team we are assembling, and the culture we all contribute to. We are excited you are considering working with us and look forward to hearing from you! “At the top of the mountain we are all snow leopards.” - Hunter S. Thompson Cherre is an equal opportunity employer. We pride ourselves on hiring the best people for the job no matter their race, sex, orientation, nationality, religion, disability, or age.",
        "url": "https://www.linkedin.com/jobs/view/3925500483"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963963012,
        "company": "ClifyX",
        "title": "Snowflake Data Engineer /",
        "created_on": 1720636662.4714324,
        "description": "Snowflake Data Engineer NORTHEAST MULTIPLE LOCATIONS + All across usa Locations AL - Birmingham,AZ - Phoenix,CA - Freemont,CA - Irvine,CA - Los Angeles,CA - Palo Alto,CA - Pleasanton,CA - Sacramento,CA - San Diego,CA - San Francisco,CA - San Jose,CT - Hartford,DC,DC - Washington,FL - Miami,FL - Orlando,FL - Tampa,GA - Atlanta,IL - Bloomington,IL - Chicago,IN - Indianapolis,LA - New Orleans,MA - Boston,MD - Baltimore,MI - Detroit,MN - Minneapolis,MO - Kansas City,NC - Charlotte,NJ - Florham Park,NJ - Jersey City,NY - New York,OH - Cincinnati,OH - Cleveland,OH - Columbus,PA - Philadelphia,PA - Pittsburgh,TX - Arlington,TX - Austin,TX - Dallas,TX - Frisco,TX - Irving,TX - Plano,TX - San Antonio,VA - Arlington,VA - Ashburn,VA - Chantilly,VA - McLean,VA - Norfolk,VA - Richmond,WA - Seattle,WI - Milwaukee Qualifications What you need: Minimum of 5 years of experience with Data warehousing methodologies and modelling techniques Minimum of 2 years of experience working in Massively Parallel Processing (MPP) Analytical Datastores such as Netezza, Teradata General understanding of the Snowflake architecture Experience in Snowpipe for handling Streaming data is a plus Minimum of 1 year of experience in handling semi-structured data (JSON, XML) using the VARIANT attribute in Snowflake Experience in in Re-clustering of the data in Snowflake with good understanding on how Micro-Partition works inside Snowflake is a plus Minimum of 3 years of experience in creating master data datasets. Experience with MDM tool is plus Minimum of 2 years of experience in Migration, methods to cloud data solutions Minimum of 3 years of experience in working with Batch and Stream data Minimum Of 5 Years Of Experience With SQL Minimum of 2 years of hands-on experience in Cloud technologies such as AWS - S3, Glacier, EC2, Lambda, SQS, Redshift Azure - Blob Storage, Cool Blob Storage, Virtual Machine, Functions, SQL Datawarehouse GCP - Cloud Storage, Coldline Cloud Storage, Compute Engine, Cloud Functions, Big Query Minimum Of 3 Years Of Experience With ELT Concepts Minimum of 3 years of experience with ETL tools such as Informatica, Talend, Matillion Experience in Hadoop, Hive, HBASE, Spark is a plus",
        "url": "https://www.linkedin.com/jobs/view/3963963012"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3965543933,
        "company": "Dagster Labs",
        "title": "Software Engineer",
        "created_on": 1720636664.2534137,
        "description": "About us We're an early-stage, well-funded startup team with a proven track record of shipping open-source software with global adoption. We put a premium on respectful, clear, and complete communication, and we expect each other to be creative, curious, effective, and empathetic. We believe deeply that the right tools and abstractions enable not just technological transformation, but also organizational transformation. We strive to put the user and their hard work at the center of our decision making. In practice, that means we are looking for engineers who want to write clean APIs and helpful error messages, and who always try to understand user needs when designing a new system. All of our open-source work is done publicly. You can gain context about how we collaborate as a team and the problems we work on by exploring GitHub and looking at our code reviews. About the role Dagster's mission is to empower every organization to build a productive, scalable data platform. We're looking for a product-minded software engineer to join the team working on Dagster Plus, our hosted SaaS product, to help make Dagster the de facto cloud solution for organizations to build, manage, and leverage their data assets. In this role, you will drive improvements to Dagster's product suite, infrastructure, and underlying open source framework, implementing capabilities that unlock new use cases for our clients. You will solve difficult technical problems throughout the software stack and work collaboratively with the rest of the team to plan and execute. You will instrument, monitor, debug, and optimize distributed systems from end to end. You'll talk directly to our users (data engineers) to understand how best to improve our product. This is a full-time, competitively paid position with benefits. We are a distributed team with offices in San Francisco, New York, and Minneapolis. We have team members all over the U.S. and we are hiring fully remote candidates in the U.S. Every employee is provided a remote work stipend to cover the cost of home office equipment and anything else that makes your remote work location comfortable, productive, or successful. And if you'd rather not work from home, we'll cover the cost of a coworking or office space if you're fully remote. Responsibilities: Independently manage & drive engineering projects from design to user adoption. Participate in technical architecture discussions and help the team make key technical decisions. Solve difficult technical problems throughout the software stack and get projects over the finish line, across front-end, back-end, or infrastructure. Work collaboratively with the rest of the team to plan and execute on engineering projects. Must-have Qualifications If you don't think you meet all of the criteria below but still are interested in the job, please apply. Nobody checks every box, and we're looking for someone excited to join the team. 2+ years of relevant software development experience Strong command of computer science fundamentals like data structures and algorithms Fluent in a high-level programming language like Python or JavaScript Strong written and oral communication skills Experience in a high-functioning engineering organization working on large-scale distributed systems or B2B SaaS applications. Proven effectiveness at collaborating with and executing as part of a team Nice-to-have Qualifications Experience building services on Amazon Web Services, Kubernetes & Postgres Experience with using or supporting tools in the Modern Data Stack Experience engaging directly with users for research and support You belong here We are committed to building an inclusive team and an open-source community where no one feels out of place. We know that teams with diverse backgrounds state their assumptions more explicitly, think more rigorously, and build better software. Plus it's more fun and interesting to work with a wide variety of perspectives. You should apply to work at Dagster Labs if you want to work in, and help to build and strengthen, a high-performing software development environment where people of all backgrounds are welcome. Our Stack Dagster is built in Python and TypeScript to work on macOS, Posix, and Windows. We use GraphQL, Apollo, and React to develop beautiful frontend tooling. We integrate with a wide range of databases, data warehouses, orchestration engines, compute substrates, and cloud services. Other Resources: The launch of Dagster blog post Launching Dagster Cloud to GA blog post The Data Engineering Impedance Mismatch blogpost/presentation What Dagster Believes About Data Platforms Software-Defined Assets blog post, Data Council talk, and animated explainer The April 2024 Dagster+ launch event The estimated annual cash salary for this role is $170,000 - 190,000.",
        "url": "https://www.linkedin.com/jobs/view/3965543933"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3939292335,
        "company": "Kunai",
        "title": "Senior Data Engineer - hybrid remote",
        "created_on": 1720636667.7941666,
        "description": "Kunai is a fast-growing digital consultancy focused on banking, payments, and fintech powered by a global network that attracts the best and brightest people from all backgrounds and cultures, driven by innovation and experimentation, spread across almost every single continent. Over the past decade, we've shipped over 150 products for clients that include Visa, American Express, Capital One, WEX, Wells Fargo, Ernst & Young, and TOMS Shoes. Our founders built a previous agency (Monsoon) that was acquired by Capital One in 2015. Requires 4 days/ week on premises in the NYC office (M-Th) What will you do? You will design and build a strategic risk platform supporting various credit and risk areas, consuming data from multiple sources and vendors. You will develop complex dashboards to visualize multiple risk metrics and design workflows and approval processes. You will collaborate with cross-functional teams to analyze and integrate diverse data sources, ensuring data quality and consistency. You will develop and optimize data pipelines, support advanced data modeling, and provide insight through reporting tools. Could this be you? Must Haves: 10+ years experience as a software developer (tech agnostic) 5+ years of experience using common BI tools (Tableau, Alteryx, Power BI etc.) 5+ years experience with public cloud providers (preferably Azure) 5+ years experience with Data Warehousing (Redshift or Snowflake) Advanced SQL knowledge and experience working with a variety of databases. Technical expertise with data models, data mining, and segmentation techniques Bachelor’s degree in computer science or related field or equivalent work experience Nice to Haves: 5+ years of hands-on experience with SQL database design Strong analytic skills related to working with unstructured datasets. Working knowledge of message queuing, stream processing, and ‘big data’ At Kunai, we have built deep relationships with our clients. Our bar is high, and our mission is to always exceed our client’s expectations. If you are fanatical about customer success and driven to work on and solve tough technical challenges, we would love to chat with you!",
        "url": "https://www.linkedin.com/jobs/view/3939292335"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911170624,
        "company": "Extend Information Systems Inc.",
        "title": "Looking for Sr. Data Engineer- NYC, NY - Fulltime",
        "created_on": 1720636669.5320086,
        "description": "Hi, I hope you are doing well! We have an opportunity for Sr. Data Engineer with one of our clients for NYC, NY, Please see the job details below and let me know if you would be interested in this role. If interested, please send me a copy of your resume, contact details, availability, and a good time to connect with you. Title: Sr. Data Engineer Location: NYC, NY, Terms: Fulltime Job Description Skills : Scala, Spark, SQL 8+ years of data engineering experience Experience building streaming pipelines using Scala, Spark, and SQL Must have good exposure in AWS technology Excellent communication and ownership skills Thanks & Regards Priyanka tiwari Extend Information System Inc Phone: (703) 956-1120 Email: priyanka1@extendinfosys.com 44258 Mercure Circle, UNIT 102 A, Sterling VA, USA 20166",
        "url": "https://www.linkedin.com/jobs/view/3911170624"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956705573,
        "company": "TED Conferences",
        "title": "Front-End Software Engineer",
        "created_on": 1720636671.2588868,
        "description": "Company Description TED is a non-profit that believes powerful ideas, powerfully presented, move us: to feel something, to think differently, to take action. TED creates, produces and distributes audio and video media (most famously TED Talks) to millions of people around the world. As a Front-End Engineer on TED's Technology team, you will have the opportunity to have your work showcased on one of the largest stages in digital media. We strive to be on the cutting edge with our tech stack. The Front-End Engineer collaborates with an amazing team of developers, designers and product owners to take new features and products from conception to production. Expect to work on products within TED’s conference attendance platform which are critical to the success of TED’s flagship conferences. Your stack should include strong experience with Javascript/Typescript, most critically React.js on the front-end. Experience with mobile app development frameworks, progressive web apps and offline-first architectures and strongly preferred. Experience with Next,js, Vite, and Ruby on Rails are preferred. , Job Description Develop software with an emphasis on testing, performance, and code quality Foster growth and support other engineers through constructive, collaborative code reviews Clearly communicate technical constraints and opportunities with stakeholders Other duties and special projects as may be assigned from time to time Travel is a requirement for this role on a periodic basis (2-4 times per year). Enthusiasm for live events and travel is preferred. , Qualifications 4+ years of overall professional software development experience 3+ years of production Javascript/Typescript experience 3+ years of production React.js experience Comfortable integrating with APIs and working with remote services Experience a plus with Ruby on Rails, Vite, Node.js/Next.js, MySQL, Apollo server, GraphQL Curious and knowledgeable about web technologies and frameworks Passionate and enthusiastic about learning new tools and technologies Strong ownership of work with the ability to drive projects from inception through completion, balancing doing it right and doing it fast Able to refactor legacy projects in addition to greenfield development Level-headed during time-sensitive troubleshooting Value cross-functional collaboration and a diverse workplace Additional Information Benefits Full health benefits (medical, dental, vision) Paid family leave Work-life balance encouraged (TED closes for a 1-week winter break plus you're eligible for additional flexible paid time off) Free OneMedical and SpringHealth membership for you and your dependents to address physical and mental well-being 401k with match SALARY RANGE $100,000-$125,000 TED Conferences LLC is an equal opportunity/affirmative action employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. We invite all qualified candidates to apply online with their cover letter (no more than one page) and resume.",
        "url": "https://www.linkedin.com/jobs/view/3956705573"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3931511748,
        "company": "Jobs Malaysia - Two95 HR HUB",
        "title": "System Engineer - Linux",
        "created_on": 1720636673.0066433,
        "description": "Hi, Greetings!. I hope this email finds you in good spirit. I have a below Full-time opportunity with our client, It's a Remote opportunity with 25% travel after Covid. If interested please share your updated resume. We are looking for a Red Hat / Linux / Ansible / Open Shift Expert.... This is a fulltime / permanent Position with a leading consulting firm Direct Hire 25% Travel required - Post-COVID ( currently remote ) Any location is fine Salary : Market Rate / Open + Benefits Requirements Job Description ============ Our Client is looking for a Systems Engineer/ Expert ( Red Hat / Linux / OpenShift / Ansible skills) to provide day to day support for their clients. You must have strong skills in Red Hat Enterprise Linux, Ansible Tower, OpenShift, virtualization, SAN and storage technologies. You must be able to support both the x86 and IBM POWER hardware. Networking and AIX skills are also a plus. This role will require a well-rounded individual with very solid technical background as well as a proven history of successful interaction with customers. Strong communication skills both oral and written are required. Knowledge, Skills, And Abilities Excellent communication and customer service skills Experience with the Red Hat portfolio including: Red Hat Enterprise Linux Red Hat Satellite Server Ansible Tower Open Shift x86 hardware HPE Cisco Lenovo Virtualization VMWare vSphere Red Hat Virtualization",
        "url": "https://www.linkedin.com/jobs/view/3931511748"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3770664141,
        "company": "Unified",
        "title": "Software Engineer",
        "created_on": 1720636674.874032,
        "description": "Job Description The Role: We are looking for a full-stack engineer with a demonstrated track record of developing and maintaining production services, innovative thinking, and technical excellence. This role will be a mixture of technical design, individual contribution, and thorough testing. You will be part of our fast-paced, innovative team of engineers who engage in full stack development of features involving building delightful front-end experience as per our design specifications to building microservices and designing data stores for the backend. You are flexible with languages and tools and willing to learn whatever is necessary to get the job done. Collaborate with our product and design teams to understand pain points and build solutions. Help maintain a high level of engineering quality. You build collective ownership amongst the team by contributing to code reviews, designs, and whiteboarding. What You'll Do Gain valuable experience at a rapidly growing big data company Collaborate with independent technology teams using the agile methodology Build interactive and intuitive UIs that solve complex problems and are a delight to use Building new, efficient, and scalable front-end applications Contribute to robust APIs that pull from both graph and relational databases Collaborate closely with a product team to plan, execute, and ship business-critical projects Practice and enforce disciplined software engineering (writing tests, code reviews, and pair programming) Discuss and distribute knowledge, technical concepts, and ideas with any member of our diverse organization Test your creativity at Unified hack-a-thons Ship work you're proud of Need To Have Bachelor’s and/or Master’s degree, preferably in CS, or equivalent experience 2.5+ years experience of designing and building successful customer facing web applications Proficient in at least one, preferably statically typed, programming language i.e. (Java, Python, Golang) Strong understanding of Javascript and at least one frontend framework i.e. React, Vue, AngularJS Experience building Javascript based web applications with HTML5, CSS, Node.js Experience contributing to and integrating with REST APIs Hands-on experience in writing complex, highly-optimized SQL queries in at least one of the common database platforms such as MySQL and/or PostgreSQL Experience running shell commands, e.g. OS X or Linux terminal Experience writing unit and integration tests Good architectural level understanding, the ability to see the big picture, and the ability to evaluate different approaches and tools and use instincts to make timely judgements Excellent communication and teamwork skills A cooperative, understanding, open, and friendly demeanor A mindset of continuous improvement Experience with Git and Github, including Github Pull Request workflows Bonus Experience Experience working with GraphQL for querying APIs and serving relevant data Global UI state management with Apollo and React Apollo NPM and JavaScript build tools, e.g. Babel, Webpack, Browserify Python, TypeScript MVVM framework Vue.js Knowledge and experience designing solutions with cloud-native AWS Cloud services Microservice architecture design principles Graph databases, e.g. Neo4j Columnar data stores, e.g. Amazon Redshift, BigQuery CI/CD systems, e.g. Jenkins Experience with Atlassian software development and collaboration tools (JIRA, Confluence, etc.) Agile methodologies Social networks APIs, e.g. Facebook, Twitter, LinkedIn Data pipeline and streaming tech, e.g. Hive, Spark, Kafka, Kafka Streams ================================================================================ About Us Unified is a leading provider of digital advertising services and solutions powered by data and technology. Our proprietary technology is designed to change the business of digital advertising by helping brands achieve unprecedented marketing results. Unified provides expert Managed and Professional Services super-charged by innovative operations and insights platforms, as well as cutting-edge Data Management and Audience Insights solutions. With a range of offerings, we are able to create custom solutions for our clients, tailored to their needs and goals. Headquartered in New York City and with offices in Los Angeles and Atlanta, Unified has managed over $5B in advertising data for the world’s largest brands and agencies and run more than $1B in advertising campaigns. For more information, visit www.Unified.com or follow @Unified on Twitter. Unified is an equal opportunity employer. Compensation: From $85,000.00 to $110,000.00 per year",
        "url": "https://www.linkedin.com/jobs/view/3770664141"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Utica-Rome Area",
        "job_id": 3961088688,
        "company": "Ramp",
        "title": "Senior Analytics Engineer",
        "created_on": 1720636676.6363134,
        "description": "About Ramp Ramp is the ultimate platform for modern finance teams. Combining corporate cards with expense management, bill payments, vendor management, accounting automation and more, Ramp's all-in-one solution is designed to save businesses time and money, and free finance teams to do the best work of their lives. Our mission is to help build healthier businesses, and it’s working: over 25,000 businesses on Ramp to save an average 5% and close their books 8x faster. Founded in 2019, Ramp powers the fastest-growing corporate card and bill payment platform in America, and enables tens of billions of dollars in purchases each year. Ramp's investors include Founders Fund, Stripe, Citi, Goldman Sachs, Coatue Management, D1 Capital Partners, Redpoint Ventures, General Catalyst, and Thrive Capital, as well as over 100 angel investors who were founders or executives of leading companies. The Ramp team comprises talented leaders from leading financial services and fintech companies—Stripe, Affirm, Goldman Sachs, American Express, Mastercard, Visa, Capital One—as well as technology companies such as Meta, Uber, Netflix, Twitter, Dropbox, and Instacart. In 2023, Ramp was named Fast Company’s #1 Most Innovative Company in North America, LinkedIn’s #1 Top Startup in the U.S., a CNBC Disruptor, and a TIME100 Most Influential Company. About The Role We’re looking for someone to help lead the future of analytics at Ramp. This person will enable Ramp to get 1% better every day by developing data products and insights. They will partner closely with business stakeholders and product, engineering, and design counterparts to prioritize and execute on work, improve reporting, as well as drive results and process improvements. What You’ll Do Full stack analytics engineering development, building models to consume, transform, and expose data to stakeholders and production systems Drive a culture of experimental design, testing agenda, and best practices Contribute to the culture of Ramp’s data team by influencing processes, tools, and systems that will allow us to make better decisions in a scalable way Collaborate with P/E/D/D (product, engineering, data and design) teams to develop product roadmaps and measure success Work with closely with data engineering teams to capture, move, store, and transform raw data into highly actionable insights, and partner with business teams to turn those insights into action What You Need Strong knowledge of SQL (preferably Redshift, Snowflake, BigQuery) and how to write efficient SQL queries Familiarity with BI tools (preferably Looker, Mode, Tableau or equivalent) and experience distributing data insights via reports and dashboards Track record of shipping high quality products and features at scale Ability to thrive in a fast-paced, constantly improving, start-up environment that focuses on solving problems with iterative technical solutions Nice-to-Haves Experience with the modern data stack (Fivetran / Snowflake / dbt / Looker / Hightouch or equivalents) Strong perspective on analytics engineering development cycle (data modeling, version control, documentation + testing, best practices for codebase development) Experience within the payments and financial technology space Familiarity with B2B enterprise sales cycle metrics and processes About Our Teams Product Analytics | Ramp’s Product Analytics team is responsible for delivering data products and insights that shape Ramp’s product direction and unlock business value. The Product Analytics team is also responsible for building out the platform through which new products are launched, instrumented, tested, and QA’d. The team embeds deeply as a partner to engineering, product, and design. Risk & Capital Markets Analytics | Ramp’s Risk Analytics team is responsible for how risk is evaluated, and building the risk infrastructure to scale to millions of businesses in the United States. Areas include risk operations and underwriting, limit setting and pricing across financial products as well as fraud detection, regulatory reporting, and capital market relationships. Growth Analytics | Ramp's Growth Analytics team ships data products and insights that allow Ramp to acquire new business and expand existing business and partnerships at scale. Current areas of focus include: Web & Martech, Outbound Automation, Customer Data Platform, Self-Service Product, GTM Strategic Finance, and Business Systems. Compensation The annual salary/OTE range for the target level for this role is $136,000-$160,000 + target equity + benefits (including medical, dental, vision, and 401(k) Benefits (for U.S.-based full-time employees) 100% medical, dental & vision insurance coverage for you Partially covered for your dependents One Medical annual membership 401k (including employer match on contributions made while employed by Ramp) Flexible PTO Fertility HRA (up to $5,000 per year) WFH stipend to support your home office needs Wellness stipend Parental Leave Relocation support for NY Pet insurance Other notices Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",
        "url": "https://www.linkedin.com/jobs/view/3961088688"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3932299457,
        "company": "Census",
        "title": "Senior Software Engineer - ETL",
        "created_on": 1720636680.628455,
        "description": "About Census 🔁 Census is the first Data Activation platform built on your warehouse. Sync 360° customer data to 200+ business tools today with Reverse ETL. Empower marketing teams to build dynamic audiences with a no-code segment builder. Census is how data teams at companies like Canva, Figma, Rippling, Carta, and Notion build better business operations. Backed by a16z , Sequoia, Tiger Global & Insight; we're a hybrid team headquartered in San Francisco that loves taking annoying problems most people avoid and building elegant solutions for them. We believe that data should be used for more than just making charts. This is why we invented integrations that work directly from cloud data warehouses. Your Mission ⚡ As a Senior Software Engineer at Census, you'll be working closely with the founders and the engineering team to create and scale a data platform to billions of records. We have a small and senior team of engineers with years of industry experience from places like Amazon, Google and Dropbox as well tons of startup experience (we have 6 former YC founders on staff). If you are looking for a role where you can influence both the company culture and product experience, read on. Your Responsibilities 🗓 You will make contributions to all parts of our tech stack, which is comprised of Rails, Typescript, Vue, Heroku, and AWS. You will work closely with our product team to help design and develop new features. You will inform much of our early culture and be part of creating a truly special team. You will be a collaborative member of our sprint process - we do short sprint plans once every two weeks and 20 minute daily virtual stand-ups. You won't burn out – we are building a great product while creating a fun, family-friendly culture. You will learn some of our lingo, like \"do nothing\", \"done done\" and \"ponies\" Our Ideal Candidate 🏅 Can build things end-to-end. Our engineers build, deploy and maintain their code. Is adept with data & backend systems and unafraid to work with UI components. Has a Bachelor's degree in CS, Engineering, Math or equivalent experience. Thrives in ambiguous environments where you get to work directly with customers and make decisions that build trust and have a huge impact on the business. Compensation 💰 Salary $180,000 - $230,000 Our Benefits 🏆 Meaningful equity (we mean it!). We’re going to ask you to work hard and build an amazing company, so we are going to pay you well while we build, and set our sights on your equity having real value We want you to take care of yourself, medical, dental, and vision plans are heavily subsidized for you, AND for your qualifying dependents Investing in your future can be expensive so we want to help, their is a company match for 401K/Pensions Flexible work schedule & unlimited PTO Growing family? Amazing! 12 weeks of fully paid parental leave. Annual All-Hands Offsite - hangout with your work-friends and make some memories! All the tools you need to do your best work. We believe the best companies bring together diversity in race, age, physical and mental ability, sexuality, gender identity, ethnicity, perspectives, and ideas. People do their best work when they feel like they are included, valued, and equal — when they feel like they belong. The Census we are building is a place where everyone brings their full selves to work knowing that they’ll be heard, championed, and supported to succeed. Come and join our Census flock! 🦩 What are you waiting for? Apply ⬇️",
        "url": "https://www.linkedin.com/jobs/view/3932299457"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3884623018,
        "company": "Steneral Consulting",
        "title": "Sr. DataStage / ETL Developer/Banking",
        "created_on": 1720636682.3050218,
        "description": "Candidates must me local to the New York City or Troy, MI or Clevland, OH area and commute into the city three times a week. NO RELOCATION CONSIDERED. PLEASE Only send me candidates in the New York City or Troy, MI or Clevland, OH area. We need A senior (10+ years) DataStage ETL developer with 10+ years of experience designing, developing, testing, and implementing Extract, Transform and Load (ELT/ETL) solutions using DataStage as well as experience developing and implementing data integration, data lake and data warehouse solutions in an on-premise and cloud environments. ****CANDIDATES NEED TO HAVE BANKING OR FINANCIAL SERVICES EXPERIENCE. Provide Answers Number of years working with: Total IT Experience Years working with: DataStage ETL Development Years working with: Experience developing and implementing data integration, data lake and data warehouse solutions in an on-premise and cloud environment. Years working with: Banking/Financial services Job Description The Sr. DataStage Developer is responsible in understanding and supporting the businesses through the design, development, and execution of Extract, Transform, and Load (ELT/ETL), data integration, and data analytics processes across the enterprise. He/She will stay on top of tech trends, experiment with and learn new technologies, contribute to the growth of data organization, participate in internal & external technology communities, and mentor other members of the team. Provide technical leadership at every stage of the data engineering lifecycle, from designing data platforms, data pipelines, data stores, and gathering, importing, wrangling, querying, and analyzing data. The Sr data engineer will work closely with various customers including their immediate project teams, business domain experts and other technical staff members. Work daily within a project team environment, taking direction from project management and technical leaders. Responsible for design, development, administration, support, and maintenance of the Snowflake Platform and Oracle Platform. Participates in the full systems life cycle and cloud data lake/data warehouse design and build including recommendation of code development, integration with data marketplace or reuse and buy versus build solutions. Job Responsibilities Technical Leadership –Lead data integration across the enterprise thru design, build and implementation of large scale, high volume, high performance data pipelines for both on-prem and cloud data lake and data warehouses. Lead the development and documentation of technical best practices for ELT/ETL activities. Also, oversee a program inception to build a new product if needed. Solution Design – Lead the design of technical solution including code, scripts, data pipelines, processes/procedures for integration of data lake and data warehouse solutions in an operative IT environment. Code Development – Ensures data engineering activities are aligned with scope, schedule, priority and business objectives. Oversees code development, unit and performance testing activities. Responsible to code and lead the team to implement the solution. Testing – Leads validation efforts by verifying the data at various middle stages that are being used between source and destination and assisting others in validating the solution performs as expected. Meets or exceeds all operational readiness requirements (e.g., operations engineering, performance, and risk management) Ensure compliance with applicable federal, state and local laws and regulations. Complete all required compliance training. Maintain knowledge of and adhere to Flagstar's internal compliance policies and procedures. Take responsibility to keep up to date with changing regulations and policies. Job Requirements 10 years of experience designing, developing, testing, and implementing Extract, Transform and Load (ELT/ETL) solutions using DataStage. 10 years of experience developing and implementing data integration, data lake and data warehouse solutions in an on-premise and cloud environment. 10 years of experience with various Software Development Life Cycle methods such as Agile, SCRUM, Waterfall, etc. 3-year experience in 100+ TB data environment. Proven experience developing and maintaining data pipelines and ETL jobs using IBM DataStage, Informatica, Matillion, FiveTran, Talend or Dbt. Knowledge of AWS cloud services such as S3, EMR, Lambda, Glue, Sage Maker, Redshift & Athena and/or Snowflake. Experienced in data modelling for self-service business intelligence, advanced analytics, and user application. Ability to communicate complex technical concepts by adjusting messaging to the audience: business partners, IT peers, external stakeholders, etc. Proven ability to design and build technical solutions using applicable technologies; ability to demonstrate exceptional data engineering skills. Ability to prioritize work by dividing time, attention and effort between current project workload and on-going day to day activities. Demonstrates strength in adapting to change in processes, procedures and priorities. Proven ability to establish a high level of trust and confidence in both the business and IT communities. Strong teamwork and interpersonal skills at all management levels. Proven ability to manage to a project budget. Experience applying agile practices to solution delivery. Must be team-oriented and have excellent oral and written communication skills. Strong analytic and problem-solving skills. Good organizational and time-management skills. Experience in Strategic Thinking and Solutioning. Must be a self-starter to understand existing bottlenecks and come up with innovative solution. Demonstrated ability to work with key stakeholders outside the project to understand requirements/resolve issues. Experience with data model design, writing complex SQL queries, etc., and should have a good understanding of BI/DWH principles. Expertise in Relational Database Management System, Data Mart and Data Warehouse design. Expert-level SQL development skills in a multi-tier environment. Expertise in flat file formats, XML within PL/SQL, and file format conversion. Strong understanding of SDLC and Agile Methodologies. Strong understanding of model driven development. Strong understanding of ETL best practices. Proven strength in interpreting customer business needs and translating them into application and operational requirements. Strong problem-solving skills and analytic skills with proven strength in applying root cause analysis.",
        "url": "https://www.linkedin.com/jobs/view/3884623018"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3811464166,
        "company": "High5",
        "title": "Lead Data Engineer",
        "created_on": 1720636683.9750135,
        "description": "Job Title: Lead Data Engineer Location : Onsite 5 days in NYC Pay Rate: $60/hr - $65/hr Duration : 11 Months Job Description Our Ads & Data Platforms team, a segment under Disney Entertainment & ESPN Technology, is looking for a Lead Data Engineer. Data is essential for all our decision-making needs whether it’s related to product design, measuring advertising effectiveness, helping users discover new content or building new businesses in emerging markets. This data is deeply valuable and gives us insights into how we can continue improving our service for our users, advertisers and our content partners. Our Content Engineering team is seeking a highly hardworking Data Engineer with a strong technical background and passionate about diving deeper into Big Data to develop state of the art Data Solutions. Responsibilities Contribute to the design and growth of our Data Products and Data Warehouses around Content Performance and Content Engagement data. Design and develop scalable data warehousing solutions, building ETL pipelines in Big Data environments (cloud, on-prem, hybrid) Our tech stack includes AWS, Databricks, Snowflake, Spark and Airflow Help architect data solutions/frameworks and define data models for the underlying data warehouse and data marts Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions Maintain detailed documentation of your work and changes to support data quality and data governance Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to our customers (Data Science, Data Analytics teams) Be an active participant and advocate of agile/scrum practice to ensure health and process improvements for your team Basic Qualifications 7+ years of data engineering experience developing large data pipelines Strong SQL skills and ability to create queries to extract data and build performant datasets Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data at large scale Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query) Preferred Qualifications Nice to have experience with Cloud technologies like AWS (S3, EMR, EC2) Solid experience with data integration toolsets (i.e Airflow) and writing and maintaining Data Pipelines Familiarity with Data Modeling techniques and Data Warehousing standard methodologies and practices Good Scripting skills, including Bash scripting and Python Familiar with Scrum and Agile methodologies You are a problem solver with strong attention to detail and excellent analytical and communication skills Required Education Bachelor’s Degree in Computer Science, Information Systems or related field Preferred Education Master’s Degree in Computer Science, Information Systems or related field",
        "url": "https://www.linkedin.com/jobs/view/3811464166"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Rochester, NY",
        "job_id": 3921547388,
        "company": "Robert Half",
        "title": "Data Engineer",
        "created_on": 1720636685.7981226,
        "description": "Description We are on the lookout for a highly skilled Data Engineer to join our team! This role is based in Rochester, New York and will primarily involve defining and leading data projects, spearheading data management practices, and collaborating with various teams to improve data quality. Responsibilities Lead and define data projects in collaboration with Data Scientists and Engineers to enhance data workflows. Implement advanced solutions to meet complex data challenges. Develop and enforce data management practices, ensuring the highest quality of data in our data lake. Ensure compliance with data privacy standards. Collaborate with the Business Intelligence and Analytics team to share knowledge and improve data quality. Utilize skills in Microsoft SQL Server, Azure Synapse Analytics, C Sharp Programming (C#), Java, and Python to execute job functions effectively. Monitor and optimize data systems to ensure their performance and reliability. Develop protocols for data acquisition, processing, and utilization. Collaborate with stakeholders to understand and meet data requirements. Maintain accurate documentation to facilitate future project developments and optimizations Requirements A minimum of 2 years of experience in a Data Engineer role or similar capacity Proficiency in Microsoft SQL Server Experience with Azure Synapse Analytics Knowledge of C Sharp Programming (C#) Proficiency in Java programming language Proficiency in Python programming language Relevant experience in the Healthcare, Hospitals, and Social Assistance industry is a plus Excellent problem-solving skills and attention to detail Strong communication skills and ability to work in a team environment Bachelor's degree in Computer Science, Information Systems, or related field is preferred Technology Doesn't Change the World, People Do.® Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles. Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go. All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit © 2024 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to",
        "url": "https://www.linkedin.com/jobs/view/3921547388"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888445630,
        "company": "Harp Talent Solutions",
        "title": "Database Developer",
        "created_on": 1720636687.3678095,
        "description": "Data Base Developer {Contract} New York, NY On-Site Position Description Our client a large financial services institution is looking for a Database Engineer to setup and manage multiple components for Margin Lending applications. Candidate must have significant expertise; in design and development of financial applications. should be fluent in related technologies including Spring, databases, database interface layers, web protocols and standards associated development tools. To be successful, the role will require the individual to; understand the banking technology landscape, and to offer creative solutions that integrate current capabilities with proprietary system builds. The system will run on Azure cloud and premise using modern distributed architecture. You must love building robust teams, resilience systems and enjoy precise nature of technology in finance. This role demands continuous learning in business, technology and management, personal excellence and resourcefulness. Job Functions/Duties And Responsibilities Perform all database related work. Design and develop enterprise level data transformations. Solve complex engineering problems and lead system design and development activities. Understand business processes, a bigger picture and core ideas behind the developed software. Define engineering guidelines and quality control pipeline; perform code reviews. Advocate and advance toward cutting edge engineering practices. Design stable, scalable application database/data warehouse. Code and develop the functionality as per the proposed design and requirements. Plan and coordinate the data/process migration across database. Working in the Agile development methodologies, collaborating with business and tech. Bachelor's Degree",
        "url": "https://www.linkedin.com/jobs/view/3888445630"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3688991610,
        "company": "Pierce",
        "title": "Sr. System Engineer",
        "created_on": 1720636689.0835626,
        "description": "Key Accountabilities: Delivery of IT infrastructure Solutions, reference architectures, product selection, product standards and design patterns Conduct research on emerging products, services, protocols, and standards in support of security enhancement and development efforts Work with Business and IT stakeholders to contribute in the identification and development of systems SLA's Contribute in the improvement of service availability, stability and development of performance baselines and ensure proactive systems, applications and end user experience and business process monitoring, Tune monitoring system/dashboards and respond to monitoring alerts. Monitor server logs and network traffic. Interpret activity and make recommendations Delivery of infrastructure engineering and automation services to on premise/cloud platforms Enable, encourage and support innovation Develop strong relationships with key business stakeholders to develop a deep understanding of business plans and priorities in each area Develop and maintain relationships with suppliers, other 3rd parties and SaaS partners Maintain expertise on infrastructure technology developments and trends Lead/participate in the design review and approval process to ensure that designs meet the project requirements, applicable risks are considered, and that strategies/standards are adhered to Strong broad knowledge in architecture, security across a broad range of infrastructure domains Ability to translate business needs into technology solutions High level of technical competence Excellent communication, presentation, influencing and interpersonal skills Strong understanding of IT operations and project engineering Ability to balance the \"big picture\" and short-term implications of individual decisions Design and implement disaster recovery plan for operating systems, databases, networks, servers, and software applications Keep current and plan for emerging security threats, advisories alerts and issues Excellent knowledge of market trends and new developments Ability to travel to remote office to help support environment, as needed Acquisition & Deployment Interact and negotiate with vendors, and contractors to secure system-related products and services Recommend, schedule, and perform server and network improvements, upgrades, and/or purchases Deploy new applications and enhancements to existing applications, software, and operating systems Perform cost-benefit and return on investment analyses for proposed systems to aid management in making implementation decisions Conduct research on software and systems products to justify recommendations and to support purchasing efforts Propose and create system specifications, diagrams, and charts to provide direction to system programmer and development teams Design, Document and Conduct regular server audits, system backup and recovery procedures, and regular recovery tests in accordance with the company's disaster recovery and business continuity strategies Ensure system connectivity of all servers, shared software, groupware, and other applications Create and maintain documentation as it relates to system configuration, mapping, processes, and service records Operational Management Gauge the effectiveness and efficiency of existing systems; and processes develop and implement automation strategies for improving or further leveraging these systems Gauge the effectiveness and efficiency of existing systems; and processes develop and implement automation strategies for improving or further leveraging these systems Ensure Systems and Software compliance, compatibility and interoperability of all on premise and public cloud computing systems deployed and used by the organization Requirements At least 8 years' experience with working in systems integration and IT architecture planning, design and development Extensive knowledge of data center architectures, converged infrastructure consolidation, security, service orchestration In-depth strong hands-on administration & troubleshooting experience knowledge of IT infrastructure stack, not limited to, Server OS and Clusters on Win 2012/2016/2019, Hyper-V, MS SQL 2012/2014/2019, Multi-Site Active Directory, Powershell Automation, Hyper-V Replication, Cisco LAN/WAN/WLAN technology, CISCO Firepower/ASA, AWS, Windows Backups, Linux, Apache, and MS Infrastructure Services, hardware and software RAID, Block, NAS SAN storage solutions, Pure, HP, EMC, Server and other Hardware Rack, Stack, Firmware upgrades IaaS delivery to on premise and on Public cloud platforms ITIL, Agile, Scrum frameworks, methodologies, processes and supporting tools Familiarity with Service Oriented Architecture (SOA) and Network Architecture Translate business requirements using complex methods/models to determine appropriate architectural solutions Possession of excellent analytical, conceptual and problem-solving skill",
        "url": "https://www.linkedin.com/jobs/view/3688991610"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3931513469,
        "company": "Jobs Malaysia - Two95 HR HUB",
        "title": "Software Engineer | Remote | Contract to hire",
        "created_on": 1720636690.8421748,
        "description": "Job title: Software Engineer. Location: 100% remote. Duration: 6+ month contract to hire. Rate: $Open. Requirements Job Description Experience with enterprise database systems such as SQL Server or Oracle (SQL Server preferred) Knowledge and experience working with SSIS or other ETL tools Working with healthcare and/or financial services data Experience working with large transactional databases and data warehouses Ability to create reports and retrieve data from large databases and data warehouses using SQL and stored procedures Skilled in compiling large amounts of data into innovative presentations of information Good communication skills and the ability to work closely with customers and third parties to complete large system integration projects Excellent problem-solving, communication, and time management skills Detail oriented; able to work independently and set priorities Knowledge of healthcare industry and measurements preferred Must have Experience With NestJS, Typescript, Microservices, AWS ECS, Lambda, Batch, Glue, CloudFormation, Serverless applications Nice to have Benefits Preferred Experience in Ionic, Angular If interested please send your updated resume to rehana.j@two95intl.com and include your rate/salary requirement along with your contact details with a suitable time when we can reach you. If you know of anyone in your sphere of contacts, who would be a perfect match for this job then, we would appreciate if you can forward this posting to them with a copy to us. We look forward to hearing from you at the earliest.",
        "url": "https://www.linkedin.com/jobs/view/3931513469"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3860724173,
        "company": "Rogo",
        "title": "Software Engineer (Search)",
        "created_on": 1720636694.1625261,
        "description": "About Rogo Rogo is a generative AI platform reinventing how people work, starting with financial services. Our team is lean, smart, and enormously ambitious. We're growing fast, and we work in person at our beautiful office in NYC. Our mission is to make people smarter by giving everyone an AI analyst. We're unabashedly ambitious, and we're dead set on building the biggest Financial AI company in the world. Why join? Exceptional traction: strong PMF with the world's largest investment banks, hedge funds, and private equity firms. World-class team: we take talent density seriously. We like working with incredibly smart, driven people. Crazy velocity: we work fast, which means you learn a lot and constantly take on new challenges. Frontier technology: we're developing cutting-edge AI systems, pushing the boundaries of published research, redefining what's possible, and inventing the future. N-of-1 Product: Our platform is state-of-the-art and crazily powerful. We're creating tools that make people smarter, reinventing how you discover, create, and share knowledge. About The Role As a search engineer for Rogo , you will enhance and evolve our extensive search and retrieval systems. In this capacity, you'll: Build the infrastructure for high-performance, low-latency search and retrieval systems, tackling challenging constraints such as latency and costly model inference. Generate, index, and manage vast collections of public and private datasets containing many millions of documents. Research and implement cutting-edge search and retrieval methods that integrate classic search techniques, embeddings, and LLMs. A typical day could involve: Reading research papers on RAG, LLM fine-tuning, and other cutting-edge search topics. Discussing AI strategies and workflows with top executives to grasp their needs. Fine-tuning our search infrastructure for our general product and for specific client needs. Designing and implementing end-to-end automations to save our users hours a day. It’s cutting-edge engineering at the AI frontier. Qualifications Hard Requirements: You write amazing code, fast. Proven experience in managing complex search pipelines and search infrastructure, including familiarity with indexing techniques such as BM25, understanding of search optimization metrics, and expertise in embeddings and vector databases. Proficiency in leveraging LLMs in a production context, with specialization in Retrieval Augmented Generation (RAG) and advanced Prompt Engineering techniques Highly proficient with Python and SQL, and an intuitive understanding of multi-threading, multi-processing, asyncio, and other concurrency primitives Experience with at least one of: Postgres, Snowflake or Elasticsearch Experience deploying and monitoring mission-critical ETL pipelines with large and heterogenous datasources Practical experience with containerization technologies, including Docker and Kubernetes Solid understanding of networking, security principles, and best practices Experience with AWS or other cloud environment Bonus Requirements: Experience with a strongly typed language (e.g., Rust) Experience working with Apache Airflow Experience at a hypergrowth startup Financial Services work experience Product experience working directly with users Experience with stream processing Knowledge of Datadog and other Telemetry tooling You'll fit in at Rogo if... You have fun solving problems that others think are impossible You are high-intensity and care a lot about what you do You are ecstatic to work at a start-up You're innately curious and find joy in learning about AI and finance You are autonomous, self-directed, and comfortable working with ambiguity You have eclectic interests",
        "url": "https://www.linkedin.com/jobs/view/3860724173"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963712529,
        "company": "Truelogic Software",
        "title": "Data Platform Infrastructure Engineer - Software and Data Company (ID: 1915)",
        "created_on": 1720636698.385218,
        "description": "Data Platform Infrastructure Engineer - Software and Data Company (ID: 1915) Other Location Remote, anywhere in LATAM Truelogic is a leading provider of nearshore staff augmentation services, located in New York. Our team of 500 tech talents is driving digital disruption from Latin America to the top projects in U.S. companies. Truelogic has been helping companies of all sizes to achieve their digital transformation goals. Would you like to make innovation happen? Have you ever dreamed of building Products that impact millions of users? Nice! Then we have a seat for you on our team! What are you going to do? You will have the opportunity to work in a forward-thinking and growth-oriented environment, at a rapidly growing data-driven Go-To-Market software company, we are accelerating the development of our data platform. Our vision is to be the single source of truthfor data and enable the rapid creation of large-scale data solutions and applications. Occupy a unique position in the market , As a Data Platform Engineer in our team you'll have a key role in the design, implementation, and deployment of our Data Platform. The ideal candidate is an experienced software engineer having built large-scale data pipelines or systems using excellent problem-solving skills and know-how of working in very large scales. Our data platform is a nascent initiative and you’ll have the opportunity to affect its direction. You’ll take the lead in bringing in new ideas, testing and validating them quickly and independently, and incorporating them while socializing them with the team. Design and build a highly scalable data platform to support data pipelines for diversifiedand complex data flows. Track and identify relevant new technologies in the market and push theirimplementation into our pipelines through research and POC activities. Deliver scalable, reliable and reusable data solutions. Leading, building and continuously improving our data gathering, modeling, reportingcapabilities and self-service data platforms. Working closely with Data Engineers, Data Analysts, Data Scientists, Product Owners,and Domain Experts to identify data needs. Develop processes and tools to monitor, analyze, maintain and improve data operation,performance and usability. What will help you succeed Relevant Bachelor degree or other equivalent Software Engineering background. 10+ years of experience as an infrastructure / data platform / big data softwareengineer. Experience with AWS/GCP cloud services such as GCS/S3, Lambda/Cloud Function,EMR/Dataproc, Glue/Dataflow, Athena. IaC design and hands-on experience. Familiarity designing CI/CD pipelines with Jenkins, Github Actions, or similar tools. Experience in designing, building and maintaining enterprise systems in a big data environment on public cloud. Strong SQL abilities and hands-on experience with SQL, performing analysis and performance optimizations. Hands-on experience in Python or equivalent programming language. Experience with administering data warehouse solutions (like Bigquery/ Redshift/Snowflake). Experience with data modeling, data catalog concepts, data formats, datapipelines/ETL design, implementation and maintenance. Experience with Airflow and DBT - advantage Experience with Kubernetes using GKE or EKS - advantage.. Experience with development practices – Agile, TDD - advantage. #J-18808-Ljbffr",
        "url": "https://www.linkedin.com/jobs/view/3963712529"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3943500107,
        "company": "CloudHire",
        "title": "Senior Database Engineer (PostgreSQL)",
        "created_on": 1720636699.9604454,
        "description": "Do you have a passion for building high-performance, scalable database architectures? Are you excited about the challenge of architecting the foundation for a revolutionary, encrypted chat application? If so, we want to hear from you! Our client, a well-funded, seed-stage startup, is searching for a talented and experienced Senior Database Engineer to join their growing team. In this architect-level role, you'll play a pivotal role in building and optimizing the PostgreSQL database that will power their innovative, interactive chat application with end-to-end encryption. Job description: Collaborate with the CTO to design and implement a robust, scalable PostgreSQL database architecture for our client's secure chat application Optimize database performance to ensure a smooth and responsive user experience Develop and implement data security best practices to safeguard sensitive user information Automate database administration tasks through scripting and automation tools Monitor database health and performance, proactively identifying and resolving any potential issues Stay up-to-date with the latest trends and technologies in the database management field You may have the opportunity to grow into a future CIO role, shaping the overall technology direction of the company Requirements A seasoned database professional with 10+ years of experience, ideally within a fast-paced startup environment A PostgreSQL guru with deep expertise in schema design, query optimization, performance tuning, and data security best practices Proven experience in designing and implementing scalable database architectures to handle significant data growth Experience with Supabase, a cloud-native PostgreSQL platform, is a plus Excellent communication and collaboration skills with the ability to effectively partner with the CTO and development team A strong work ethic, a proactive problem-solver, and a team player who thrives in a dynamic startup culture Location : Brooklyn (Hybrid role) Benefits Be a part of a passionate and innovative team building a disruptive chat application with real-world impact. Work in a fast-paced startup environment where your ideas and contributions will be valued. Competitive salary of $230,000 per year and a comprehensive benefits package. Equity grant to become a vested owner in the company's success (specific details provided during interview process). Embrace a hybrid work model, with the flexibility to work remotely and collaborate in their Brooklyn office",
        "url": "https://www.linkedin.com/jobs/view/3943500107"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Buffalo, NY",
        "job_id": 3958847532,
        "company": "Delaware North",
        "title": "Principal Data Engineer",
        "created_on": 1720636701.7059164,
        "description": "The Opportunity Delaware North is hiring a Lead Databricks Engineer to join our IT team in Buffalo, New York. As a Lead Databricks Engineer, you will be responsible for leading the development and optimization of our Databricks-based data processing and analytics platform. You will work closely with business stakeholders to design, implement, and maintain scalable and efficient data pipelines, as well as to advance our capabilities in data analysis, machine learning and AI-driven applications. Buffalo, New York location, hybrid in office 2-3 days/week onsite. Relocation assistance available. Pay Minimum – Anticipated Maximum Base Salary: $95900 - $129400 / year In addition to base salary, we offer an annual bonus plan based on company and individual performance, or a role-based, uncapped sales incentive plan. The advertised pay range represents what we believe at the time of this job posting, that we would be willing to pay for this position. Only in special circumstances, where a candidate has education, training, or experience that far exceeds the requirements for the position, would we consider paying higher than the stated range. Information on our comprehensive benefits package can be found at https://careers.delawarenorth.com/whatweoffer . Benefits At Delaware North, we care about our team members' personal and professional journeys. These are just some of the benefits we offer: Medical, dental, and vision insurance 401(k) with up to 4% company match Annual performance bonus based on level, as well as individual, company, and location performance Paid vacation days and holidays Paid parental bonding leave Tuition and/or professional certification reimbursement Generous friends-and-family discounts at many of our hotels and resorts Responsibilities Architect and optimize data pipelines for performance and cost-efficiency within the Databricks environment Design and implement ETL processes using Databricks jobs to process and transform raw data into a usable format for analysis Develop and optimize Spark jobs for data processing, analysis, and machine learning tasks Pinpoint and resolve efficiency issues, enhancing the speed of data processing and o ptimizing the use of resources Establish and uphold security protocols to safeguard confidential data, aligning with applicable Legal and CyberSecurity standards Qualifications Bachelor's degree in computer science, engineering, or a similar STEM related field Minimum of 5 y ears of experience in data engineering with a strong focus on Databricks Experience designing and implenting ETL processes using Databricks. Deep understanding of Apache Spark, Delta Lake, and related big data technologies , and p roficiency in modern programming languages such as Python and Scala Strong knowledge of SQL and experience with relational, NoSQL, Data Warehouse, and Data Lake methodologies Experience with version control systems, SDLC best practices, Agile methodologies , and cloud architecture, AWS preferred Experience with Spark jobs for data processing, analysis, and machine learning tasks using Databricks. Must be legally authorized to work in the US without sponsorship. Who We Are At Delaware North, you’ll love where you work, who you work with, and how your day unfolds. Whether it’s in sporting venues, casinos, airports, national parks, iconic hotels, or premier restaurants, there’s no telling where your career can ultimately take you. We empower you to do great work in a company with 100 years of success, stability and growth. If you have drive and enjoy the thrill of making things happen - share our vision and grow with us. Delaware North Companies, Incorporated and its subsidiaries consider applicants for all positions without regard to race, color, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, or any other legally protected status. Delaware North is an equal opportunity employer.",
        "url": "https://www.linkedin.com/jobs/view/3958847532"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3969275592,
        "company": "Fathom",
        "title": "Software Engineer (Infrastructure)",
        "created_on": 1720636705.8845668,
        "description": "Fathom is on a mission to use AI to understand and structure the world's medical data, starting by making sense of the terabytes of clinician notes contained within the electronic health records of the world's largest health systems. Our deep learning engine automates the translation of patient records into the billing codes used for healthcare provider reimbursement, a process today that costs hospitals in the US $15B+ annually and tens of billions more in errors and denied claims. We are a venture-backed company that completed a Series B round of financing for $46M in late 2022. Fathom is hiring for an Software Engineer (Infrastructure) based in the New York City area to join our expanding team. This opportunity is worth exploring if you are someone who is passionate about intelligent automation and you get excited about being the 10X multiplier on your team. To that end, we are looking for experienced candidates who are comfortable operating with autonomy. We need you to utilize your combination of strong software engineering experience, infrastructure and cloud service mastery savvy to design, deploy, and monitor all operational aspects of our platform. Please note that New York area opportunities are hybrid only and require 3 days in office weekly at our financial district location in Manhattan. Your role and responsibilities will include: Working to ensure the stability, security, and performance of Fathom's platform Developing dependable internal tools that aid our machine learning and software engineers more efficient, in everything from infrastructure deployment, to continuous integration and testing Maintaining and configuring internal development Knowledge of algorithms, data structures and systems design and access control systems Collaborating with our product and engineering teams to identify strategic long-term projects and preempt infrastructure needs in advance We are looking for a teammate with: 2+ years of software engineering experience in a company/production setting Relevant experience developing backend, integrations, data pipelining, infrastructure, etc. projects in a production setting Problem solving skills and first principles thinking Strong computer science principles including: algorithms, databases (SQL and NoSQL), logic, systems design, etc. Hands-on backend coding and systems design using best practices in a company setting Experience with building, controlling, and monitoring secure cloud-based platforms An ability to help pick and implement the right tool for a given job and to define, defend, and drive technical infrastructure decisions and initiatives Effective communication and exceptional collaboration skills Bonus points if you have: Fluency in Python Knowledge of Google Cloud Experience with tools like Docker, Kubernetes and/or Spark Familiarity with continuous integration systems like CircleCI or Jenkins and/or continuous delivery systems such as Spinnaker Skills in MLOps Interest in machine learning and/or healthcare Compensation: Salary: $100,000 USD - $175,000 USD Company Equity Benefits: PTO and Uncapped Sick Days Medical/Dental/Vision Coverage 401k Matching $1,500 USD Home Office Budget Virtual and Local Office (San Francisco, New York City and Toronto) Team Building Events Annual Company Off-site",
        "url": "https://www.linkedin.com/jobs/view/3969275592"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3843678303,
        "company": "Evolve Group",
        "title": "Software Engineer - Top-Performing Hedge Fund",
        "created_on": 1720636707.8190644,
        "description": "Software Engineer Leading Hedge Fund New York Python Programming Language We are looking for Software Engineers with Python experience to join one of the top-performing hedge funds in the world. This firm has experienced tremendous growth and is expanding the headcount within its New York office this year. Joining a team of some of the most brilliant minds within the hedge fund space, you will have the opportunity to collaborate with Quantitative Researchers, Portfolio Managers and Quantitative Developers to create services that will impact the profit needle of these leading hedge funds. All-in-all, you will work on high-impact projects, have high visibility, quicker speed and development cycles, and can develop your skills and knowledge as well as your earnings! Requirements: 3-15 Years of working experience A background of working with Python You must be able to demonstrate high proficiency in; writing, reviewing, and testing Python code A Bachelor’s in Computer Science, Mathematics, or Statistics from a top school with a minimum GPA of 3.5 Commercial experience - Communicating with multiple teams and stakeholders and understanding the greater impact of the systems and services you have built Strong communicator - being able to work across multiple role types in engineering teams is critical. If you’re interested in learning more about this position, in addition to the other dozen that we have available across other highly rated hedge funds – apply now!",
        "url": "https://www.linkedin.com/jobs/view/3843678303"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3915495126,
        "company": "Haymarket Media US",
        "title": "Senior Data Engineer",
        "created_on": 1720636709.3613043,
        "description": "Sr Data Engineer Haymarket Media, Inc. is seeking a Sr Data Engineer to join the Data Engineering Team team. This position is located in our New York, NY office. Job Overview: We are looking for a Sr Data Engineer to contribute to our Data Warehouse infrastructure, working as part of a small and talented team focused on data integration, structure, report automation, and BI/Analytics Support, etc. As our business continues to grow in size and complexity, we are looking for a dynamic, organized, and customer-focused data centric contributor who is interested in informing and shaping our long-term roadmap. The role should understand business, systems, and data challenges and translate them into requirements and solutions. Responsibilities: Build integrated solutions that are in line with the architecture framework that meets business requirements Provide guidance regarding data modeling best practices, data governance and quality practices. Ensure data adheres to enterprise governance standards and maintain credibility and reputation of high quality data Work with IT and business customers to capture requirements for designing the data warehouse, data analytics and business intelligence architecture. Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the data engineering ecosystem to design systems that meet business needs Play a leading role in building systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices Develop, institutionalize and drive best practices and data architectural awareness Create the blueprint for data management systems to integrate, centralize and maintain data sources Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications Define and implement integrations between source data and data warehouse as needed to ensure data integrity and support data & reporting requirements Develop and maintain programs on source systems, ETL applications, data cleansing functions, systems management functions including load automation, and data acquisition functions among others Ensure a fault tolerant, self-correcting, adaptive, highly accurate ETL platform Continuously seek opportunities to optimize data flows, improve SQL query performance, and maintain reasonable user experience for field and power users working on data Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts Skills and Requirements: Ability to think broadly, understand business strategy, provide consultative business analysis, and have a broad understanding of technology landscape for developing effective and scalable data warehouse and business intelligence solutions Strong overall architecture experience with high proficiency in data architecture 5-8+ years of building large scale data-processing systems with 2+ years in big data technologies Expertise in cloud database technologies such as Google BigQuery with proficiency in SQL Experience in data transformation tools such as DataForm or DBT Experience designing and coding in python Experience in BI tools like Looker Thorough understanding of dimensional modeling, as well as knowledge of best practices and techniques for transforming, validating, logging, auditing, error handling, and performance tuning in a data warehousing setting Proven track record of strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams Has excellent problem-solving skills and experience handling multiple projects and assignment in a fast-paced environment Can work well in a cross-team collaborative environment, with little oversight, and be able to engage stakeholders with various business and technical backgrounds Experience with ETL and DW platforms such as Stitchdata a plus Experience with orchestration tools such as Airflow is a plus Experience working with Agile methodologies in a data warehouse, BI environment Bachelor’s degree in math, computer science, engineering, statistics, or a related technical field is required. Master’s degree a plus What We Offer: A competitive compensation package The salary range for this position is $170,000–$190,000. Compensation will be commensurate with experience, skill level, functional and/or industry knowledge, education level, certifications, as well as other qualifications. Paid annual vacation, holiday and sick time off Comprehensive health plans including medical, dental and vision Competitive 401(k) investment options and generous company matching program Life insurance Commuter benefits Employee referral awards Tuition reimbursement Training opportunities through industry-recognized programs A creative and passionate workplace and a fun, collaborative team environment Three Week “Work from Anywhere” benefit, to ensure work life balance About Haymarket: Haymarket has its heart and soul in publishing and media. Since the company was founded half a century ago, Haymarket has always prided itself on being a highly creative business, with an unrelenting focus on the quality of the products and the people. The philosophy has always been quite simple: only by having the highest quality individuals can you produce the highest quality products, combining the best in content, design, production and customer services. Globalization is opening up the world further and provides many opportunities for growth. Haymarket has offices around the world and many of the titles are now truly global brands. Haymarket serves a broad spread of business markets, from marketing to medicine to technology along with exhibitions and live events. Predicting the shape of the business in 3, 5, or 10 years is almost impossible; and the unpredictability is part of the appeal. Haymarket aims to be the perfect company to work with or for – we have the processes and attitude that ensure quality and consistency, and an entrepreneurial spirit that makes every day rewarding. An equal opportunity employer, Haymarket Media does not discriminate in hiring or terms and conditions of employment because of an individual's race, color, religion, gender, gender identity, national origin, citizenship, age, disability, sexual orientation, marital status, or any other protected category recognized by state, federal, or local laws. Beware of fraudulent activity where individuals are contacting job seekers claiming to represent Haymarket Media. Please note that only emails from @ haymarketmedia.com are legitimate. When applying for roles with Haymarket Media, you will receive an email directly from a member of the Talent Acquisition team or communication through Linkedin. You can view our open positions on our website US careers section: www.Haymarket.com California Applicants may view Haymarket Media, Inc.'s Privacy Statement for California Residents here .",
        "url": "https://www.linkedin.com/jobs/view/3915495126"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3960908342,
        "company": "A-Line Staffing Solutions",
        "title": "Sr. Data Engineer",
        "created_on": 1720636710.97804,
        "description": "Title: Senior Data Engineer Location: New York City – Midtown Manhattan (2-days onsite, 3-days remote Hybrid Schedule) Schedule: Mon – Fri, 8:00AM – 5:00PM EST Note: C2C & 3rd Party Candidates will NOT be considered We are seeking a Senior Data Engineer to work with our technical teams in a fast-paced technology organization. Ideal candidates for this role will be able to work on a 2-day onsite/3-day remote hybrid schedule, however we are open to fully remote for the right candidate. As a Senior Data Engineer, you will be responsible for the full development lifecycle of complex data projects requiring integration and transformation, including analysis, design, development, and support of complex data pipelines in cloud environments. You will assist in the design and configuration of data management tools that extract and manipulate data from various sources, including in-house and external databases. Position Qualifications 7+ years of relevant Data Engineering work experience Experience creating scalable and secure data pipelines that enable the ingestion, transformation, and transfer of large quantities of structured and unstructured data from various databases and sources Experience building complex database logic and APIs to automatically fetch and store data in various forms Extensive experience with programming languages (Python or related), ETL tools and their administration, as well as relational and non-relational databases Experience architecting and developing efficient and reusable modularized components that drive complex applications Experience implementing data quality, security, and governance standards and best practices across different cloud environments Experience in the design and build of integration between data management tools Experience in the design, development, and maintenance of data solutions across different cloud platforms, such as AWS or Google Cloud A strong understanding of data structures, algorithms, and software architecture, as well as the design, detailed testing, and documentation of complex systems Experience with the secure movement and storage of PHI, PII, and PCI data Experience scaling up or increasing application resiliency and assuring that code meets required performance standards Experience working and collaborating with data analysts, data scientists, and IT operations to install and build tools, transforming data to be used in building a new generation of data and artificial intelligence products Experience providing technical leadership for development projects and providing consultation and guidance to other team members Experience providing innovative solutions when presented with complex business or production issues Experience with modern DevSecOps practices and tools Experience with Agile methodologies and tools (Jira, Scrum, or Kanban) Experience in directing a team of data engineers and analysts in the creation of complex software and data pipelines preferred Experience with data governance processes preferred Experience with data classification and taxonomy tools preferred A minimum of a Bachelor’s Degree in Computer Science, Information Systems, or other related field; Master’s Degree in a related field preferred Note: C2C & 3rd Party Candidates will NOT be considered If you're interested in this job opportunity, please apply to this job posting directly or email a copy of your resume to Devon Apel at dapel@alinestaffing.com !",
        "url": "https://www.linkedin.com/jobs/view/3960908342"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3930416572,
        "company": "PSRTEK",
        "title": "AWS Engineer - REMOTE",
        "created_on": 1720636714.3875113,
        "description": "Position: AWS Data Engineer Remote Healthcare Domain AWS Certified The candidate should be an experienced data pipeline builder who will optimize and build data systems from the ground up. Built data pipelines using AWS Use Lambda or EC2 to manipulate data using Python Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, AWS Web Services, AWS Glue and Pyspark Keep our enterprise data assets secure through data de-risking and access controls Work with data and analytics professionals to strive for greater functionality in our data ecosystem Requirements Bachelor's degree in computer science, software/computer engineering, applied mathematics, or physics statistics 7+ years of relevant AWS Data engineering. Should have work exposure to AWS Glue, Pyspark, Lambada, Redshift, AWS Aura with Postgres Intellectual curiosity to find new and unusual ways of how to tackle data management issues Ability to approach data organization challenges while keeping an eye on what's important Sophisticated working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases Experience performing root cause analysis on internal and external data and processes to answer specific business questions and find opportunities for improvement Strong analytic skills related to working with structured/unstructured/relational datasets. Build processes supporting data transformation, data structures, metadata, dependency, and workload management Experience supporting and working with multi-functional teams in a dynamic environment. Experience with object-oriented/object function scripting languages: Python A successful history of manipulating, processing, and extracting value from large, disconnected datasets preferred Prior experience with a health care data model is preferred",
        "url": "https://www.linkedin.com/jobs/view/3930416572"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York County, NY",
        "job_id": 3970071631,
        "company": "Evolutyz Corp",
        "title": "Lead Data Engineer - Azure",
        "created_on": 1720636715.9900262,
        "description": "This is a client facing role so they should have good communication skills. Type : Remote Role : Full Time Position Lead Tech Lead Azure Salary - $150k plus benefits Senior Principal Consultant-Azure Tech Lead! Responsibilities Experience on ADLS, Azure Databricks, Azure SQL DB and Data warehouse(Azure Synapse Analytics) SQL Server development, Azure Data Factory, Azure Automation, Power-shell scripting, SQL databases Python scripting, Spark SQL & PySpark, Knowledge in ETL tools (SSIS, Talend etc) Have in-depth ETL Processing Good expertise in Data warehousing/Dimensional Modelling Have knowledge in Azure Storage services (ADLS, Storage Accounts) Handle Data Ingestion projects in Azure environment Qualifications we seek in you! Minimum Qualifications Domain Consumer Goods, Life Sciences, Manufacturing, Banking& Capital Markets Azure certified data engineering professional Required Qualification Ability to communicate efficiently with customer s key Business and IT folks to present/defend architecture/design CI/CD- Azure Pipeline Outstanding grasp on Azure Monitor, Redis Cache, Load Balancer, Application Gateway, Azure Functions, Azure Data Factory Integrations Knowledge of microservices and API development Excellent analytical, problem solving, communication and ability to communicate efficiently with individuals, business and can work as part of a team as well as independently. Good knowledge of CI/CD pipelines such as Jenkins Experience No SQL and Document databases Experience in Production Support as a Lead role managing all asClientt of Production support ( L1/L2/L3) Experience in Transition any Production support from Incumbent . Operation and Performance reporting of Production activities Automation or Drive Impact to clients while managing applications Team Management CI/CD or Devops experience . Azure Purview does not mandate but good to have Agile Framework",
        "url": "https://www.linkedin.com/jobs/view/3970071631"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3826677534,
        "company": "Bask Health",
        "title": "Front-End Software Engineer (Remote)",
        "created_on": 1720636719.47495,
        "description": "As a engineer at Bask you will work directly with the CEO and CTO to build and design the software infrastructure that will serve as the backbone of telehealth. We are looking to expand our software engineers, seeking those with deep rooted entrepreneurial spirit. Our serverless platform is built using Next.js, Drizzle and SST for a powerful multi-tenant application. It is important to be fluent in these frameworks, with Typescript and Javascript being a must. What You'll Do Design, build, and implement new services through the full development cycle: write elegant, well-tested code in a modern technology stack. Build libraries and frameworks that can help us build quickly and efficiently, and deliver value to our users. Work closely with the product team: make architecture and design decisions, participate in stand-ups, code reviews, and retros, and help contribute and drive the engineering culture that focuses on simple, intuitive, high-impact experiences. Be an engineering generalist: from developing servers and databases, to integrating APIs to expand our platforms capabilities, to final Ul implementation, to you'll have the opportunity to take end-to-end ownership and responsibility across the full development lifecycle. Build from 0 to 1: You'll have the opportunity to both scale and automate existing services while also bringing new innovations to life. This is unique opportunity to help join a team where you'll be able to both build rapidly, and also contribute to product strategy and development! We are a highly collaborative team. Who We're Looking For The ideal candidate is a full-stack generalist, and has experience taking a product from 0-1 product. We're looking for someone who's entrepreneurial and willing to roll up their sleeves to get the work done, and passionate about our mission to build a platform that will intensely disrupt the healthcare industry. You are dangerous on the frontend of the stack. You are a highly skilled dev (React, TypeScript, Next.js, Javascript). You also have backend skills (SST, Drizzle, SQL, Node). You can work independently and are comfortable owning entire projects and or large areas of the code base Strong experience in building paid products and services is preferred. You are a strong communicator - you are able to clearly articulate technical problems, constraints and timelines. You are comfortable working in a fast-paced, unstructured, startup environment.",
        "url": "https://www.linkedin.com/jobs/view/3826677534"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3943248554,
        "company": "Zepz",
        "title": "Mid Backend Software Engineer - Python",
        "created_on": 1720636721.2381604,
        "description": "About Zepz Zepz is the group powering two leading global remittance brands: WorldRemit and Sendwave. Since 2010, we have been disrupting an industry previously dominated by offline legacy players with our relentless focus on reducing the cost of remittances and increasing safety and convenience for our users. Every day, our people work to unlock the prosperity of cross-border communities through finance and technology - driven by our vision of a world that celebrates migrants' impact on prosperity, at home and abroad. In 2023, our brands helped cross-border communities send over $15bn from 50 countries to recipients in 130 countries. We operate over 2800 money transfer corridors worldwide and employ over 1,000 people globally. Zepz is a remote-first employer, with team members located across six continents Come join us! Zepz.io Our Commitments: We act like owners - We are relentlessly delivering for our users and spending money thoughtfully. We embrace embarrassing honesty - We function best when we're open and honest with one another — especially about our challenges and doubts. We have a bias to action - We get to first outcomes quickly, iterate and learn. We strive to be better - We may make mistakes, but always learn from them. We are inclusive - to better reflect and serve our users. What you will own: Write great code: We understand code is read more than it's written, better off tested and maintainability is a must. Help shape what we build: You'll be working closely with product owners, designers and other engineers to design and refine our work. We work as a team and your input is key. Influence technology evolution: We are designing new platforms with long-term goals in mind and are also happy to improve with new technology capabilities Own delivery: We're obsessed with shipping value; you'll own work beyond a pull request. You'll care about bugs, scalability, uptime and other non-functional requirements. Grow together: You'll review others' work and happily seek feedback on yours to ensure we build a better codebase and sharpen each other's skills. Share your knowledge and points of view: We promote knowledge sharing across our teams and count on you to become an active member of one. Experiment with new tools, present your findings, shape our future standards. Scope and Impact: You invent and try to simplify what we do. You insist on the highest standards from your team and yourself. You have charisma. You lead or influence a team. You tackle open-ended somewhat ambiguous problems What you bring to the table: Strong experience in building backend services/APIs. This role specifically is for an engineer with solid experience with Python backend services. A large part of the codebase you will be working on is currently in Python. We welcome generalists and polyglots. We are in the process of breaking down a monolith application into smaller services and self contained data models. Therefore, experience working with microservices as well as monolith applications will come in handy. And if you have worked on a successful migration, even better. Solid experience with system design and architecture Experience with unit and integration tests You are a system design enthusiast and have experience designing and transforming existing systems collaboratively to make them scalable, maintainable and reliable. You have a true DevOps mindset and are able to support your team towards becoming true owners of their product/platform You work well with Engineering and Product members and are comfortable building effective relationships with stakeholders outside technology. An open mind with respect to diversity and inclusivity. Our team (and customers) come from all over the world. Bonus Points if you: Have worked at a scaling startup previously. Have experience in successfully transitioning a monolith platform into domain-driven services. Please be aware that this role may require out of hours on-call. What we offer you: Please note that the benefits below will apply to permanent roles. We have five core benefits for our talent in the US, UK, Philippines, Poland, and South Africa. If you're not in one of those regions, don't worry - the Talent team can let you know what is available for you specifically: Unlimited Annual Leave: Most Zepz team members are eligible for unlimited annual leave. Colleagues in customer-facing roles, receive a competitive holiday allowance and four recharge days a year. Feel free to make the most of your time off and maintain a healthy work-life balance! Private Medical Cover:  You can opt-in to a Private Medical Insurance scheme. This provides you with access to thorough medical coverage, so you can feel confident in your health and well-being. Retirement: We offer pension schemes to help you plan for and secure your future. Life Assurance: Life assurance is available to give you peace of mind and protect your loved ones in case of the unexpected. Parental Leave: We offer competitive parental leave schemes to ensure you are spending as much quality time with your new bundle of joy as possible. We are also remote-first as an organisation, offering flexibility for you to work where you need to be most productive. In many locations, we have workspaces, which you can use as you desire. Most roles in the Philippines are predominately office-based, with this we offer free meals for those 100% on-site. In addition to the above, you will discover that we have a range of secondary perks (such as the cycle-to-work scheme and employee discounts) depending on your location, to help you thrive at Zepz! Why choose Zepz? Our team of over 1,000 employees is fully distributed across the world. We are working from coffee shops, homes, and co-working spaces — making us one of the larger fully distributed growth-stage startups in the world but we also offer workspace in our talent cluster locations - spaces we can meet, collaborate and connect. We are proud parents, community organizers, farmers, band members, yoga teachers, YouTube influencers, former Olympians, and serial entrepreneurs. We collectively speak over twenty languages, including Akuapem, Amharic, Bengali, Ewe, Fante, Ga, Igbo, Kalenjin, Luganda, Oromo, Somali, Swahili, Wolof, Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Irish, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish. At Zepz, embodying our commitments binds us together. We are collectively passionate about striving to achieve our vision and purpose - to continue to provide the best service to our users. Ready to Apply? Applications will be reviewed on a rolling basis. If interested, please submit your resume along with a cover letter (optional), highlighting why your experience demonstrates you meet the requirements of the role. Please also indicate the countries in which you have work authorization. Confidence can sometimes hold us back from applying for a job. But we'll let you in on a secret: there's no such thing as a 'perfect' candidate. Zepz is a place where everyone can thrive. So however you identify and whatever background you bring with you, and if at all you might need any form of support to make the process as comfortable as possible, please let us know and give us a shot by applying. We want you to be excited to wake up to make an impact every day.",
        "url": "https://www.linkedin.com/jobs/view/3943248554"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959957316,
        "company": "Russell Tobin",
        "title": "Senior Data Engineer",
        "created_on": 1720636722.9401586,
        "description": "What are we looking for in our Senior Data Engineer? Responsibilities Create scalable and secure data pipelines enabling the ingestion, transformation, and transfer of large quantities of structured and unstructured data from various databases and sources. Build complex database logic and APIs to automatically fetch and store data in various forms. Architect and develop efficient and reusable modularized components that drive complex applications. Implement data quality, security, and governance standards and best practices across different cloud environments. Design and build the integration between data management tools. Design, develop, and maintain data solutions across different cloud platforms, such as AWS or Google Cloud. Ensure the secure movement and storage of PHI, PII, and PCI data. Scale up or increase application resiliency and assure code meets required performance standards. Collaborate with data analysts, data scientists, and IT operations to build tools transforming data for a new generation of data and AI products. Provide technical leadership for development projects and offer consultation and guidance to other team members. Provide innovative solutions when presented with complex business or production issues. Employ modern DevSecOps practices and tools. Utilize Agile methodologies and tools (i.e. Jira, Scrum, Kanban). Required Skills Experience creating scalable and secure data pipelines for the ingestion, transformation, and transfer of large quantities of structured and unstructured data from various databases and sources. Proficiency in building complex database logic and APIs for automated data fetching and storage. Extensive experience with programming languages (Python or related), ETL tools, and their administration, as well as relational and non-relational databases. Expertise in architecting and developing efficient and reusable modularized components. Knowledge of data quality, security, and governance standards and best practices across different cloud environments. Competence in designing and building integrations between data management tools. Proficiency in developing and maintaining data solutions across different cloud platforms, such as AWS or Google Cloud. Thorough understanding of data structures, algorithms, software architecture, and the design, detailed testing, and documentation of complex systems. Experience with the secure movement and storage of PHI, PII, and PCI data. Ability to scale up applications, increase resiliency, and ensure code meets performance standards. Experience working and collaborating with data analysts, data scientists, and IT operations. Technical leadership experience in development projects, providing consultation and guidance. Innovative problem-solving skills for complex business or production issues. Familiarity with modern DevSecOps practices and tools. Experience with Agile methodologies and tools (i.e. Jira, Scrum, Kanban). Russell Tobin offers eligible employee’s comprehensive healthcare coverage (medical, dental, and vision plans), supplemental coverage (accident insurance, critical illness insurance and hospital indemnity), a 401(k)-retirement savings, life & disability insurance, an employee assistance program, identity theft protection, legal support, auto and home insurance, pet insurance, and employee discounts with some preferred vendors. #CB Rate/Salary: $65-70/hr",
        "url": "https://www.linkedin.com/jobs/view/3959957316"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3930466629,
        "company": "Fathom",
        "title": "Senior Software Engineer (Backend/Data)",
        "created_on": 1720636724.6426973,
        "description": "Fathom is on a mission to use AI to understand and structure the world's medical data, starting by making sense of the terabytes of clinician notes contained within the electronic health records of the world's largest health systems. Our deep learning engine automates the translation of patient records into the billing codes used for healthcare provider reimbursement, a process today that costs hospitals in the US $15B+ annually and tens of billions more in errors and denied claims. We are a venture-backed company that completed a Series B round of financing for $46M in late 2022. We are looking for a Senior Software Engineer (Backend/Data) to work on data products that drive the core of our business. We want to work with teammates in New York City, who are excited about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration. If you are a backend expert able to unify data, and build systems that scale from both an operational and an organizational perspective, Fathom is an opportunity worth exploring! Please note that New York area opportunities are hybrid only and require 3 days in office weekly at our financial district location in Manhattan. Your role and responsibilities will include: Developing data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs Building performant and expressive interfaces to the data Creating infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning We are looking for a teammate with: 5+ years of software engineering experience in a company/production setting Knowledge of algorithms, data structures and systems design Experience building data pipelines from disparate sources Hands-on experience building and scaling up compute clusters A solid understanding of databases and large-scale data processing frameworks like Hadoop or Spark and the ability to evaluate which tools to use on the job A unique combination of creative and analytic skills apt of designing a system capable of pulling together, training, and testing dozens of data sources under a unified ontology A desire to collaborate in office 3 days weekly Bonus points if you have: Know-how of developing systems to do or support machine learning, including experience working with NLP toolkits like Stanford CoreNLP, OpenNLP, and/or Python's NLTK Expertise with wrangling healthcare data and/or HIPAA Experience with managing large-scale data labelling and acquisition, through tools such as through Amazon Turk or DeepDive Compensation: Salary: $175,000 USD - $220,000 USD Company Equity Benefits: PTO and Uncapped Sick Days Medical/Dental/Vision Coverage 401k Matching $1,500 USD Home Office Budget Virtual and Local Office (San Francisco, New York City and Toronto) Team Building Events Annual Company Off-site",
        "url": "https://www.linkedin.com/jobs/view/3930466629"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3951927708,
        "company": "Clairvoyant",
        "title": "Manager - Data Engineer",
        "created_on": 1720636726.3274164,
        "description": "New York, NY, USA Req #26654 Monday, June 17, 2024 Company Overview And Culture EXL (NASDAQ: EXLS) is a global analytics and digital solutions company that partners with clients to improve business outcomes and unlock growth. Bringing together deep domain expertise with robust data, powerful analytics, cloud, and AI, we create agile, scalable solutions and execute complex operations for the world’s leading corporations in industries including insurance, healthcare, banking and financial services, media, and retail, among others. Focused on creating value from data for driving faster decision-making and transforming operating models, EXL was founded on the core values of innovation, collaboration, excellence, integrity and respect. Headquartered in New York, our team is over 40,000 strong, with more than 50 offices spanning six continents. For information, visit www.exlservice.com. For the past 20 years, EXL has worked as a strategic partner and won awards in its approach to helping its clients solve business challenges such as digital transformation, improving customer experience, streamlining business operations, taking products to market faster, improving corporate finance, building models to become compliant more quickly with new regulations, turning volumes of data into business opportunities, creating new channels for growth and better adapting to change. The business operates within four business units: Insurance, Health, Analytics, and Emerging businesses. Job Description Data Engineer The Data Engineer will contribute in migrating existing data platform to modern data bricks/azure data platform. Implementing standards, governance, and automation. Qualifications At least 4 years of Information Technology experience Hands on experience in architecting Cloud data solutions using Azure Synapse, Databricks, Python, PySpark, SQL Significant experience with Cloud Data lake technologies and complex data architecture and models Experience building and managing cloud data platforms. Strong experience in building data ingestion, data catalog and data analytics framework.End to end Cloud Data Lake architecture design & implementation including data ingestion, data modeling and data distribution. Build data integrations between on-prem/cloud-based systems. Good experience in end-to-end implementation of data warehouse and data marts Experience and detailed knowledge with ETL, Data Quality, metadata management, Data Engineering, streaming data loads Experience designing and implementing complex solutions for distributed systemsExperience in leading and mentoring teams in onshore-offshore model. Preferred Qualifications: Good understanding of data warehousing concepts, data integration, data quality and data architecture Good to have experience in Snowflake Experience in Relational Modeling, Dimensional Modeling and Modeling of Unstructured Data Strong knowledge and hands-on experience in SQL, Unix shell scripting Good understanding of Agile software development frameworks Strong communication and Analytical skills Ability to work in teams in a diverse, multi-stakeholder environment comprising of Business and Technology teams and be able to manage the stake holders Experience and desire to work in a global delivery environment EEO/Minorities/Females/Vets/Disabilities To view our total rewards offered click here —> https://www.exlservice.com/us-careers-and-benefits Base Salary Range Disclaimer: The base salary range represents the low and high end of the EXL base salary range for this position. Actual salaries will vary depending on factors including but not limited to: location and experience. The base salary range listed is just one component of EXL's total compensation package for employees. Other rewards may include bonuses, as well as a Paid Time Off policy, and many region specific benefits. Please also note that the data shared through the job application will be stored and processed by EXL in accordance with the EXL Privacy Policy. Application & Interview Impersonation Warning – Purposely impersonating another individual when applying and / or participating in an interview in order to obtain employment with EXL Service Holdings, Inc. (the “Company”) for yourself or for the other individual is a crime. We have implemented measures to deter and to uncover such unlawful conduct. If the Company identifies such fraudulent conduct, it will result in, as applicable, the application being rejected, an offer (if made) being rescinded, or termination of employment as well as possible legal action against the impersonator(s). EXL may use artificial intelligence to create insights on how your candidate information matches the requirements of the job for which you applied. While AI may be used in the recruiting process, all final decisions in the recruiting and hiring process will be taken by the recruiting and hiring teams after considering a candidate’s full profile. As a candidate, you can choose to opt out of this artificial intelligence screening process. Your decision to opt out will not negatively impact your opportunity for employment with EXL. Other details Pay Type Salary Apply Now New York, NY, USA",
        "url": "https://www.linkedin.com/jobs/view/3951927708"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961933173,
        "company": "iHeartMedia",
        "title": "Software Engineer",
        "created_on": 1720636727.986248,
        "description": "iHeartMedia Current employees and contingent workers click here to apply and search by the Job Posting Title. The audio revolution is here – and iHeart is leading it! iHeartMedia, the number one audio company in America , reaches 90% of Americans every month -- a monthly audience that’s twice the size of any other audio company – almost three times the size of the largest TV network – and almost 4 times the size of the largest ad-supported music streaming service. In fact, we have: More #1 rated markets than the next two largest radio companies combined; We’re the largest podcast publisher, with more monthly downloads than the second- and third-largest podcast publishers combined. Podcasting, the fastest-growing new media, today has more monthly users than streaming music services or Netflix; iHeart is the home of many of the country’s most popular and trusted on-air personalities and podcast influencers, who build important connections with hundreds of communities across America; We create and produce some of the most popular and well-known branded live music events in America, including the iHeartRadio Music Festival, the iHeartRadio Music Awards, the iHeartCountry Festival, iHeartRadio Fiesta Latina and the iHeartRadio Jingle Ball Tour; iHeartRadio is the #1 streaming radio digital service in America; Our social media footprint is 7 times larger than the next largest audio service; and We have the only complete audio ad technology stack in the industry for all forms of audio, from on demand to broadcast radio, digital streaming radio and podcasting, which bring data, targeting and attribution to all forms of audio at an unparalleled scale. As a result, we’re able to combine our strong leadership position in audience reach, usage and ad tech with powerful tools and insights for our sales organizations to help them build success for their clients at a more efficient cost than any other option. Because we reach almost every community in America, we’re committed to providing a range of programming that reflects the diversity of the many communities we serve – and our company reflects that same kind of diversity. Our company values stress collaboration, curiosity, welcoming dissent, accepting mistakes in the pursuit of new ideas, and respect for everyone. Only one company in America has the #1 position in everything audio: iHeartMedia! If you’re excited about this role but don’t feel your experience aligns perfectly with the job description, we encourage you to apply anyway. At iHeartMedia we are dedicated to building a diverse, inclusive, and authentic workplace and are looking for teammates passionate about what we do! What We Need: Unified Enterprises Corp. seeks candidates for the position of Software Engineer, responsible for the full software lifecycle development from design, development and testing, all the way through training and production support utilizing big-data driven, micro service stacks to discover creative solutions for real world problems in the marketing and technology sectors. What You'll Do: Responsible for the full software lifecycle development from design, development and testing, all the way through training and production support utilizing big-data driven, micro service stacks to discover creative solutions for real world problems in the marketing and technology sectors. What You'll Need: What You'll Bring: Respect for others and a strong belief that others should do this in return Experience with various technical disciplines and applications Close attention to detail, following up until issues are resolved Ability to multitask on a variety of critical projects Ability to work independently, while also collaborating with others Strong communication skills, with the ability to communicate moderately complex technical information within the team Skills to recognize and solve frequently occurring problems Analytical thinking Resourcefulness and independent judgement Compensation: Salary to be determined by multiple factors including but not limited to relevant experience, knowledge, skills, other job-related qualifications, and alignment with market data. $120,000 - $130,000 Location: New York, NY: 125 West 55th Street, 10019 Position Type: Regular Time Type: Full time Pay Type: Salaried Benefits: iHeartMedia’s benefits offering is flexible and offers a variety of choices to meet the diverse needs of our changing workforce, including the following: Employer sponsored medical, dental and vision with a variety of coverage options Company provided and supplemental life insurance Paid vacation and sick time Paid company holidays, including a floating holiday that enable our employees to celebrate the holiday of their choosing A Spirit day to encourage and allow our employees to more easily volunteer in their community A 401K plan Employee Assistance Program (EAP) at no cost – services include telephonic counseling sessions, consultation on legal and financial matters, emotional well-being, family and caregiving A range of additional voluntary programs, such as spending accounts, student loan refinancing, accident insurance and more! We are accepting applications for this role on an ongoing basis. The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status. Non-Compete will be required for certain positions and as allowed by law. Our organization participates in E-Verify. Click here to learn about E-Verify.",
        "url": "https://www.linkedin.com/jobs/view/3961933173"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3496170873,
        "company": "TikTok",
        "title": "Data Engineer, Global Payments - USDS",
        "created_on": 1720636729.7332087,
        "description": "Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. The Global Payment team of the US Tech Service department of TikTok provides all-round payment solutions for the company's overseas products, overseas commercialization, and the company's overseas travel and procurement, including channel access, product order design, user interaction, capital management, tax and exchange optimization, settlement Reconciliation and so on. In this role, you'll have the opportunity to develop and manage the complex challenges of scale with your expertise in large-scale system design. In order to enhance collaboration and cross-functional partnerships, among other things, at this time, our organization follows a hybrid work schedule that requires employees to work in the office 3 days a week, or as directed by their manager/department. We regularly review our hybrid work model, and the specific requirements may change at any time. Responsibilities - Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach. - Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching. - Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications Minimum Qualifications - Bachelor's degree in Computer Science, Statistics, Data Science or a related field. - 1+ year experience in SQL and/or additional object-oriented programming language (e.g. Scala, Java, or Python). Preferred Qualifications - Experience in issue tracking and problem solving on data pipelines. - Fast business understanding and collaborative in teamwork. - Experience working with user growth is a plus. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/ktJP6 This role requires the ability to work with and support systems designed to protect sensitive data and information. As such, this role will be subject to strict national security-related screening. Job Information: 【For Pay Transparency】Compensation Description (annually) The base salary range for this position in the selected city is $116000 - $250000 annually. ​ Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units. ​ Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: ​ We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. ​ Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. ​ We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice. ​",
        "url": "https://www.linkedin.com/jobs/view/3496170873"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3771755337,
        "company": "Hebbia",
        "title": "Software Engineer, Frontend",
        "created_on": 1720636731.2928627,
        "description": "About Hebbia The user interface for AGI– Hebbia is AI that works the way you work. Designed to be generally capable– it can tackle even the most complex tasks, citing answers over any amount of sources. By showing its work, Hebbia empowers users to collaborate with AI on each step and validate responses instead of blindly trusting them. Our mission is to put capable AI in the hands of 1 billion people by 2030. Job Description As a Frontend Software Engineer at Hebbia AI, you will play a critical role in designing, developing, and delivering high-quality software UIs that support our AI-driven products and services. You will own major product features across the stack from design to launch. You'll have close feedback loops with users and with our Customer Success team. You will work closely with a cross-functional team of engineers, and domain experts to architect scalable systems, implement robust frontend experiences, and ensure the reliability and performance of our software platforms. Your technical expertise, leadership abilities, and problem-solving skills will contribute to the success of our AI products and shape the future of our technology stack. This role is based out of our New York City office in Soho. Responsibilities Own product features: Take a customer need and turn it into delightful user experiences that solve real customer needs Meet with users: Serve as a deployed engineer to build customer empathy that enables us to create innovative UX that drives meaningful value Deliver a world-class UI: Craft delightful experiences that redefine AI interfaces. Unlock universal indexing: Build intuitive user experiences to simplify the configuration and execution of complex data integrations that allow customers to index any content in the world Who You Are Bachelor's or Master's degree in Computer Science, Data Science, Statistics, or a related field. A strong academic background with coursework in data structures, algorithms, and software development is preferred. 3+ years software development experience at a venture-backed startup or top technology firm. Proficiency in React, Typescript, and popular frontend frameworks for component design and state management. Deep expertise in one or multiple: full-stack development, frontend engineering, web development, UX/UI engineering. Knowledge of cloud platforms (e.g., AWS, Vercel) Demonstrated awareness of best practices in UI architecture and development Problem-solving and analytical skills: Ability to analyze complex problems, propose innovative solutions, and effectively communicate technical concepts to both technical and non-technical stakeholders. Leadership and teamwork: Proven experience in leading software development projects and collaborating with cross-functional teams. Strong interpersonal and communication skills to foster a collaborative and inclusive work environment. Continuous learning mindset: Enthusiasm for continuous learning and professional growth. A passion for exploring new technologies, frameworks, and software development methodologies. Embraces rapid prototyping with an emphasis on user feedback Autonomous and excited about taking ownership over major initiatives. Compensation In consideration of market analysis and relevant factors, the salary range for this position is set between $160,000 and $250,000. However, adjustments outside of this range may be considered for candidates whose qualifications significantly differ from those outlined in the job description. Additionally, this role is eligible to participate in our equity plan and benefits program. Benefits include, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, daily catered lunch, and unlimited PTO.",
        "url": "https://www.linkedin.com/jobs/view/3771755337"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3952225715,
        "company": "MongoDB",
        "title": "Software Engineer, Data Platforms",
        "created_on": 1720636732.991183,
        "description": "The worldwide data management software market is massive (According to IDC, the worldwide database software market, which it refers to as the database management systems software market, was forecasted to be approximately $82 billion in 2023 growing to approximately $137 billion in 2027. This represents a 14% compound annual growth rate). At MongoDB we are transforming industries and empowering developers to build amazing apps that people use every day. We are the leading developer data platform and the first database provider to IPO in over 20 years. Join our team and be at the forefront of innovation and creativity. Who you are Have worked on production-grade web applications and be capable of making backend improvements in languages such as Python and Go Have experience building tools and platforms for business users and software developers Have experience with or working knowledge of cloud platforms and services Enjoy working on full stack applications including UI/UX, API Design, databases and more Looking for a high impact role with variety of opportunities to drive adoption of data via services and tooling Passionate about developing reliable and high quality software Curious, collaborative and intellectually honest A great team player What you will do Design and build UI, API and other data platforms services for data users including but not limited to analysts, data scientists and software engineers Work closely with product design teams to make improvements to the internal data platform services with an emphasis on UI/UX Perform code reviews with peers and make recommendations on how to improve our code and software development processes Design boilerplate architecture that can abstract underlying data infrastructure from end users Further improve the team’s testing and development processes Document and educate the larger team on best practices Help drive optimization, testing, and tooling to improve data platform quality Collaborate with other software engineers, machine learning experts, and stakeholders, taking learning and leadership opportunities that will arise every single day Bonus Points Have experience with modern Javascript environment including frontend frameworks such as React and Typescript You are familiar with data infrastructure and toolings such as Presto, Hive, Spark and BigQuery You are familiar with deployment and configuration tools such as Kubernetes, Drone, and Terraform You are interested in web design and have experience directly working with product designers You have experience designing and building microservices You have experience building a machine learning platform using tools like SparkML, Tensorflow, Seldon Core, etc. Success Measures In three months you will have familiarized yourself with much of our data platform services, be making regular contributions to our codebase, will be collaborating regularly with stakeholders to widen your knowledge, and helping to resolve incidents and respond to user requests In six months you will have successfully investigated, scoped, executed, and documented a small to medium sized project and worked with stakeholders to make sure their user experiences are vastly enhanced by implementing improvements to our platform services In a year you will have become the key person for several projects within the team and will have contributed to not only the data platform’s roadmap but MongoDB’s data-driven journey You will have made several sizable contributions to the project and are regularly looking to improve the overall stability and scalability of the architecture To drive the personal growth and business impact of our employees, we’re committed to developing a supportive and enriching culture for everyone. From employee affinity groups, to fertility assistance and a generous parental leave policy, we value our employees’ wellbeing and want to support them along every step of their professional and personal journeys. Learn more about what it’s like to work at MongoDB, and help us make an impact on the world! MongoDB is committed to providing any necessary accommodations for individuals with disabilities within our application and interview process. To request an accommodation due to a disability, please inform your recruiter. MongoDB, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type and makes all hiring decisions without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. MongoDB’s base salary range for this role is posted below. Compensation at the time of offer is unique to each candidate and based on a variety of factors such as skill set, experience, qualifications, and work location. Salary is one part of MongoDB’s total compensation and benefits package. Other benefits for eligible employees may include: equity, participation in the employee stock purchase program, flexible paid time off, 20 weeks fully-paid gender-neutral parental leave, fertility and adoption assistance, 401(k) plan, mental health counseling, access to transgender-inclusive health insurance coverage, and health benefits offerings. Please note, the base salary range listed below and the benefits in this paragraph are only applicable to U.S.-based candidates. MongoDB’s base salary range for this role in the U.S. is: $101,000—$198,000 USD",
        "url": "https://www.linkedin.com/jobs/view/3952225715"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3854596425,
        "company": "Conch Technologies, Inc",
        "title": "Network Data Center Engineer",
        "created_on": 1720636734.8169718,
        "description": "HI, Position: Network Operations Engineer (Data Center Network) Few points Rolling workdays mean – Tues to Sat / Wed to Sun and So on Location – Buffalo NY mandatorily 12+ Months Contract 100% work from office all 5 days Open Roles: 2 Job Description Position: Network Operations Engineer Location : Buffalo, New York As a Network Operations Engineer, You Will Provide 1st/2nd line technical support & incident management, monitoring for circuits and hardware. Report and track carrier issues, hardware RMA’s etc. Manage operational network maintenance activities and implement changes Provide monitoring & fault management and remediation of alerts. Tuning & optimization of monitoring systems Assist with root cause analysis of incidents Assist with periodic network reviews and analysis Help with establishment of operational procedures & support documentation Review, track and update network operations policies, standards and documentation Assist with development of the network management platform adoption, configuration and tuning Complete Daily network checks and operational handover duties Participate in shift rotation coverage Jump on command Center bridge to troubleshoot the network issues. Review service now requests and follow change management cycle to complete the requirement. What You'll Need 4 – 7 years’ experience in IT infrastructure operations/support role Knowledge of network routing and switching technologies and routing protocols Experience with various Cisco equipment (routers, switches) Experience with Checkpoint, Cisco firewalls, load balancers and WAN accelerators is desirable Experience with F5 load balancer, Cisco NX OS, Cisco ISE & Z scaler cloud. Knowledge in cloud computing network domain. Experience in scripting and programming skills (Python, Ansible, Terraform) is desirable Formal technical certification such as CCNA/CCNP and any cloud computing certification. Thanks and Regards, Naveen US IT Recruiter Conch Technologies Inc, 6750 Poplar Ave # 711, Memphis, TN. Direct: 901-317-3454 Email: naveeng@conchtech.com",
        "url": "https://www.linkedin.com/jobs/view/3854596425"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3855014125,
        "company": "Chubb",
        "title": "Data Solution Engineer",
        "created_on": 1720636736.436129,
        "description": "Job Description A data solution engineer generally works on implementing complex big data projects with a focus on collecting, parsing, managing, analyzing, and visualizing large sets of data to turn information into insights using multiple platforms. He or she should be able to decide on the needed hardware and software design needs and act according to the decisions. The big data engineer should be able to develop prototypes and proof of concepts for the selected solutions. Ideal candidate for this role is someone with a strong background in computer programming, statistics, and data science who is eager to tackle problems with large, complex datasets using the latest python, R, and/or Spark. You are a self-starter who will take ownership of your projects and deliver high-quality data-driven analytics solutions. You are adept at solving diverse business problems by utilizing a variety of different tools, strategies, algorithms, and programming languages. Specific Responsibilities Are As Follows Strong analytical & logical skills Utilize the data engineering skills within and outside of the developing Chubb information ecosystem for discovery, analytics and data management Work with data scientists, architects, business partners and business analysts to understand requirements, design and build effective solutions Understanding of P&C insurance processes, risk data attributes and concepts such as Limits, Exposure bases, Coverages, Packaged, Rating Factors, etc. Experienced in identifying, capturing, profiling & analyzing data from multiple sources (internal and external). Skilled in identifying remediation solutions for addressing data issues. Experience in documenting data capture requirements, source to target mappings, data flow diagrams, entity relationships and complex data models. Experienced in translating business needs into systems requirements including rating systems, reports, dashboards and scorecards with minimal or no supervision Work with various relational and non-relational data sources with the target being Azure based SQL Data Warehouse & Cosmos DB repositories Work closely with the Data Science team to perform complex analytics and data preparation tasks Sourcing data from multiple applications, profiling, cleansing and conforming to create master data sets for analytics use Experience with Complex Data Parsing (Big Data Parser) and Natural Language Processing (NLP) Transforms on Azure a plus Design solutions for managing highly complex business rules within the Azure ecosystem Qualifications Knowledge of Azure, Hadoop 2.0 ecosystems, HDFS, MapReduce, Hive, Pig, Sqoop, Mahout, Spark etc. a must Experience with Web Scraping frameworks (Scrappy or Beautiful Soup or similar) Extensive experience working with Data APIs (Working with RESTful endpoints and/or SOAP) Knowledge of any commercial distribution like Horton Works, Cloudera, MapR, DataBricks etc. a must Excellent working knowledge of relational databases, MySQL, Oracle etc. Hands on experience of ETL tools like Informatica and SSIS is preferred Experience with Complex Data Parsing (Big Data Parser) a must. Should have worked on XML, JSON and other custom Complex Data Parsing formats Natural Language Processing (NLP) skills Good knowledge of Python libraries like Pandas, NumPy, scikit-learn etc. Ready to learn new technologies and tools Experience Bachelor’s in computer science or related educational background Prior experience of Insurance domain a huge plus 5+ years of experience The pay range for the role is $92,500 to $158,000. The specific offer will depend on an applicant’s skills and other factors. This role may also be eligible to participate in a discretionary annual incentive program. Chubb offers a comprehensive benefits package, more details on which can be found on our careers website . The disclosed pay range estimate may be adjusted for the applicable geographic differential for the location in which the position is filled. About Us Chubb is a world leader in insurance. With operations in 54 countries, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. The company is distinguished by its extensive product and service offerings, broad distribution capabilities, exceptional financial strength, underwriting excellence, superior claims handling expertise and local operations globally. At Chubb, we are committed to equal employment opportunity and compliance with all laws and regulations pertaining to it. Our policy is to provide employment, training, compensation, promotion, and other conditions or opportunities of employment, without regard to race, color, religious creed, sex, gender, gender identity, gender expression, sexual orientation, marital status, national origin, ancestry, mental and physical disability, medical condition, genetic information, military and veteran status, age, and pregnancy or any other characteristic protected by law. Performance and qualifications are the only basis upon which we hire, assign, promote, compensate, develop and retain employees. Chubb prohibits all unlawful discrimination, harassment and retaliation against any individual who reports discrimination or harassment.",
        "url": "https://www.linkedin.com/jobs/view/3855014125"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3488416299,
        "company": "Wiz",
        "title": "DevOps Engineer (NYC)",
        "created_on": 1720636738.095566,
        "description": "Come join the company that is reinventing cloud security and empowering businesses to thrive in the cloud. As the fastest-growing startup ever, Wiz is on a mission to help organizations secure cloud environments that will accelerate their businesses. Trusted by security teams all over the world, we have a proven track record of success and a culture that values world-class talent. Our Wizards from over 13 countries work together to protect the infrastructure of our hundreds of customers, including over 40% of the Fortune 100, who trust us to scan and secure over 230 billion files daily. We’re the leading player in a massive and growing market, but it’s still early enough for you to make a significant impact. At Wiz, you’ll have the freedom to think creatively, dream big, and use your full range of skills to contribute to our record growth. Come join our team and help us create secure cloud environments that allow the best companies to move faster. About the DevOps Team: Wiz R&D group is a skilled team of developers with a unique DNA of creativity, flexibility, and an open mindset. We are looking for a passionate DevOps Engineer to join us as a core member of our growing DevOps team. In this position, you will design and implement scalable systems that will keep Wiz running smoothly and support our significant business growth. You will join an innovative, high-performance team and work with cutting-edge technologies in a dynamic and agile environment. Please note: This position will be based in NY (Hybrid work model - 3 days in-office, two days remote). What You’ll Do Take an active part of all DevOps areas: Wiz’s infrastructure and cloud environment, tools, services and up-time. Be part of our product’s architectural and infrastructure design, examine and implement new cloud technologies, and open-source tools to improve the delivery and availability of the product. Plan and push forward the growth and scale of data capacity for various products. Be responsible for the smooth production-grade execution of provided solutions. What You’ll Bring 5+ years of experience as a DevOps engineer on a high-scale distributed system, working in a Linux environment. Proven hands-on experience with containerized environments and microservices; Docker and Kubernetes are a must Extensive experience working in a multi-cloud environment The mindset and approach for automating away from manual efforts In-depth knowledge of build/release systems, CI/CD pipelines Scripting/programming skills with Python/Bash/Go An innovative approach, with the ability to quickly learn technologies A strong sense of ownership and accountability FedRAMP knowledge and experience (strong preference) Applicants must be able to provide evidence that you meet EAR part 772 and ITAR 120.15 definition of a U.S. person (Any individual who is granted U.S. citizenship; or, any individual who is granted U.S. permanent residence (green card holder); or, any individual who is granted status as a “protected person”) and that you reside in the contiguous United States. For candidates who receive an offer, the estimated pay range for this role is listed below and represents annual base salary range for non-commissionable roles or annual base salary + on-target earnings (\"OTE\") for commissionable roles. The offered compensation may also include restricted stock units. Final compensation will be determined based on various factors, including but not limited to the candidate's experience and skills. We are committed to offering fair and equitable compensation in accordance with labor laws and regulations. For more information on our employee benefits, visit our Careers page. Pay Range: USD $145,000 - $199,000 If your experience is close but doesn’t fulfill all requirements, please apply. Wiz is on a mission to build a special company. To achieve our goal, we are focused on hiring Wizards with different backgrounds, perspectives, and experiences. Wiz is an equal opportunity employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. By submitting your application, you acknowledge that Wiz will process your personal data in accordance with Wiz's Privacy Policy.",
        "url": "https://www.linkedin.com/jobs/view/3488416299"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Woodmere, NY",
        "job_id": 3943498776,
        "company": "CloudHire",
        "title": "Senior Database Engineer (PostgreSQL)",
        "created_on": 1720636742.0080156,
        "description": "Do you have a passion for building high-performance, scalable database architectures? Are you excited about the challenge of architecting the foundation for a revolutionary, encrypted chat application? If so, we want to hear from you! Our client, a well-funded, seed-stage startup, is searching for a talented and experienced Senior Database Engineer to join their growing team. In this architect-level role, you'll play a pivotal role in building and optimizing the PostgreSQL database that will power their innovative, interactive chat application with end-to-end encryption. Job description: Collaborate with the CTO to design and implement a robust, scalable PostgreSQL database architecture for our client's secure chat application Optimize database performance to ensure a smooth and responsive user experience Develop and implement data security best practices to safeguard sensitive user information Automate database administration tasks through scripting and automation tools Monitor database health and performance, proactively identifying and resolving any potential issues Stay up-to-date with the latest trends and technologies in the database management field You may have the opportunity to grow into a future CIO role, shaping the overall technology direction of the company Requirements A seasoned database professional with 10+ years of experience, ideally within a fast-paced startup environment A PostgreSQL guru with deep expertise in schema design, query optimization, performance tuning, and data security best practices Proven experience in designing and implementing scalable database architectures to handle significant data growth Experience with Supabase, a cloud-native PostgreSQL platform, is a plus Excellent communication and collaboration skills with the ability to effectively partner with the CTO and development team A strong work ethic, a proactive problem-solver, and a team player who thrives in a dynamic startup culture Benefits Be a part of a passionate and innovative team building a disruptive chat application with real-world impact. Work in a fast-paced startup environment where your ideas and contributions will be valued. Competitive salary of $230,000 per year and a comprehensive benefits package. Equity grant to become a vested owner in the company's success (specific details provided during interview process). Embrace a hybrid work model, with the flexibility to work remotely and collaborate in their Brooklyn office",
        "url": "https://www.linkedin.com/jobs/view/3943498776"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3965660449,
        "company": "Akraya, Inc.",
        "title": "Senior Data Engineer: 24-01817",
        "created_on": 1720636743.6328979,
        "description": "Primary Skills: Scala, Spark, CICD Contract Type: W2 Duration: 12+ Months Contract Location: New York, NY () Pay Range: $75 - $80 Per Hour W2 #DP Job Responsibilities Contribute to maintaining, updating, and expanding existing Core Data platform data pipelines in Scala and Python / Spark while maintaining strict uptime SLAs Extend functionality of current Core Data platform offerings, including metadata parsing, extending the Metastore API, and building new integrations with APIs both internal and external to the Data organization Implement Ingestion of new batch and streaming data pipelines using Scala, Databricks, and Airflow Implement the Lakehouse architecture, working with customers, partners, and stakeholders to shift towards a Lakehouse centric data platform Implementation shared libraries in Scala and Python that abstract complex business logic to allow consistent functionality across all data pipelines across the Data organization JOB REQUIREMENTS: 5+ years of data engineering experience developing large data pipelines Strong fundamental Scala and Python programming skills Basic understanding of AWS or other cloud provider resources (S3) Strong SQL skills and ability to create queries to analyze complex datasets ABOUT AKRAYA \"Akraya is an award-winning IT staffing firm consistently recognized for our commitment to excellence and a positive work environment. Voted the #1 Best Place to Work in Silicon Valley (2023) and a Glassdoor Best Places to Work (2023 & 2022), Akraya prioritizes a culture of inclusivity and fosters a sense of belonging for all team members. We are staffing solutions providers for Fortune 100 companies, and our industry recognitions solidify our leadership position in the IT staffing space. Let us lead you to your dream career, join Akraya today! \"",
        "url": "https://www.linkedin.com/jobs/view/3965660449"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3968581036,
        "company": "Gorgias",
        "title": "Senior Software Engineer Python",
        "created_on": 1720636745.3840005,
        "description": "Gorgias empowers ecommerce brands to grow through AI-powered customer experience. We are the #1 CX platform in the industry, trusted by over 15,000 merchants worldwide – from small independent shops to some of the largest ecommerce brands in the world. We offer the most integrations of any tool on Shopify (100+) and the ability to get setup fast, without the need for complex onboarding. Gorgias offers its users a unified platform to manage every aspect of their customer support on every channel. We can automate 60% of a brand’s support so that agents can focus on high-value conversations and driving sales. Plus, we offer purpose-built marketing tools to help merchants convert more shoppers into customers, driving GMV. The position is available across our European and Canadian hubs, including Toronto, Canada, Paris (France), Lisbon (Portugal), and Belgrade (Serbia). Our work arrangement is hybrid, with a requirement of two days per week in the office. About The Apps Team The Apps Team is responsible for creating and maintaining Native Apps between external services and Gorgias, as well as enabling others to create apps in Gorgias. Apps are the connecting piece between Gorgias and the rest of the ecosystem: through them, support tickets are created and answered, customer data is ingested, actions on external services are executed. There are two main types of apps: Messaging apps: apps which allow users to send and receive messages from third-party channels. Those include for example Gmail, Facebook Messenger, or Aircall. Ecommerce apps: apps which allow users to have more data about customers contacting them and to execute actions for those customers. Those include for example Shopify, Recharge, or Magento 2. What You'll Do This position is for the Apps Native team. Your mission will be to: Develop new APIs and maintain existing ones, to integrate Gorgias with third-party services and allow other companies to easily do the same Maintain and extend the Email features and integrations of Gorgias Maintain existing Social and Ecommerce Apps Develop new features for existing and new Apps Work closely with Teams in charge of the other Gorgias products (Phone, Automate, Convert) to help them integrate their features into Gorgias Apps Support our customers directly with issues on the Team’s domain once every 6 weeks Who You Are 5+ years of experience working as a Software Engineer 4+ years working with Node.js / Python 4+ years working with REST APIs and web services Experience with Event Sourcing and data streaming technologies Picky about code performance and reliability Experience with high traffic and scaling relational databases Team player Nice to Have 5+ years working with React / Flask / Celery Experience with Kafka, RabbitMQ, Pub/Sub, or similar technologies Knowledgeable about Kubernetes Experience with PostgreSQL and data modeling Previous SaaS experience Previous startup experience Company Benefits And Perks (for France) 🏖️ 5-week vacation plus 2 weeks RTT (We follow each country's appropriate PTO Laws) 🤕 Paid sick leave 🧸 Paid parental leave (16 weeks) 💻 MacBook Pro 🍽️ Personal credit card to buy lunches (we use Swile) 🏥 We provide private health insurance (we use Alan) 💆🏻‍♀️ Get up to €700 to set up your workstation at home (working from home should feel breezy) 📚 Get up to €2000 of learning material and wellness support per year! This includes €1500 for learning material (such as books, courses, and individual coaching sessions) directly linked to your job scope, as well as a €500 wellness budget. Take advantage of these resources to grow in your role and prioritize your personal development and wellness. 🥰 Every quarter, we organize an online company-wide summit to discuss where we’re going and strengthen social bonds. Once per year we organize offsite team retreats and company retreats! (Here is the photo album from our last company retreat in Mexico in 2022, when we were a total of 200 people! & the video of the September 2023 P&E team retreat in Romania) Join our team for the opportunity to: 👩🏼‍💻Work with smart, passionate people every day 💪 Get extreme ownership over your work and results 🧠 Be treated like the expert you are Engineering Team Culture Getting Stuff Done, Ownership, Team Work, Excellence, and Agility. You should join us if you want to ship stuff fast without sacrificing quality. We've put great importance on testing our code, cleaning it, treating errors first, and features later. We also value growth and ownership. People make mistakes. We learn from them to avoid them in the future. We cannot achieve excellence if there are no bumps in the road. Why join us? 🚀 We're among the fastest-growing startups in the eCommerce ecosystem 🦄 We've built an extremely efficient go-to-market engine 🥇 Work with a talented team you'll learn a lot from 🙏 Join a company where automation and good & clean data are core beliefs shared by all 🎥 Here is an interview with one of our team member’s experiences from our most recent company retreat to Cancun! More Cool Things To Know About Gorgias... 😁 Raised our Series C-2 for $29M in May 2024: Article Here ⬅️ We went from 0 to 15,000+ merchants using our platform since 2016 We have a 4.3 rating on Glassdoor & 4.7 Comparably culture score What our customers are saying: apps.shopify.com/helpdesk#reviews Other positions: gorgias.com/about-us/jobs Discover the Gorgias Platform Learn about our Compensation Policy Gorgias ensures equal employment opportunity without discrimination or harassment based on race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, veteran status, or any other characteristic protected by law. Gorgias is committed to the full inclusion of all qualified individuals and will take the steps to assure that people with disabilities are provided reasonable accommodations. Accordingly, if reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please contact accommodation@gorgias.com",
        "url": "https://www.linkedin.com/jobs/view/3968581036"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brooklyn, NY",
        "job_id": 3895342815,
        "company": "Princeton IT Services, Inc",
        "title": "Sr Data Engineer",
        "created_on": 1720636747.031074,
        "description": "Job Title: Senior Data Engineer Location: 2 Metrotech, Brooklyn, NY Role Type: Contract (W2 only) Scope Of Services The primary focus areas include data analysis for improving agency operations, making Open Data accessible, and advancing citywide data infrastructure. We are currently seeking a Senior Data Delivery and solution Engineer to play a key role in implementing and supporting complex data engineering solutions. Key Responsibilities Support the implementation of a new Master Data Management (MDM) Business Domain integrating multiple data sources and associated web services and APIs. Develop architectural blueprints utilizing MDM as a foundational service, supporting the creation of unified profiles for business transactions. Coordinate senior-level data engineers in building pipelines to MDM and selected data platforms under the guidance of Technical Leads. Develop analytics tools utilizing data pipelines for actionable insights into customer engagement, operational efficiency, and key business performance metrics. Review Extraction, Transformation, Load strategies (ETL) for data from various sources using SQL, cloud, and 'big data' technologies. Create, update, and maintain system documentation. Manage the development of APIs for data access or landing data for downstream consumption in the appropriate target data store. Coordinate security scan accreditations. Perform special projects and initiatives as assigned. Mandatory Skills/Experience 8+ years managing the development and implementation of large technology projects, with at least 3+ years involving MDM implementation. 8+ years of experience in writing SQL. 8+ years of experience in copying, transferring, manipulating, and automating data operations. Experience with data architecture tools like Informatica Power Center, IICS, SSIS, or similar ETL tools. Experience with Amazon Web Services or Microsoft Azure cloud computing platforms. In-depth knowledge of SQL and other database solutions. Knowledge of modeling database schemas for large datasets. Experience developing cloud-ready applications. Experience with programming languages like Python, Java, and Perl. Desirable Skills/Experience 5+ years hands-on experience in development with Informatica PowerCenter and B2B Data Transformation. Experience with Oracle 10g/11g, SQL Server, and/or a database appliance. Knowledge of metadata-driven enterprise reporting platforms. Special Requirements Strong hands-on experience with Master Data Management (MDM) implementation for a large enterprise. Prior experience working on complex data integration projects for the City of New York. Note: Candidates lacking mandatory skills/experience will not be considered.",
        "url": "https://www.linkedin.com/jobs/view/3895342815"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Queens County, NY",
        "job_id": 3801258862,
        "company": "VISTRADA",
        "title": "Senior Data Systems Engineer - BI",
        "created_on": 1720636748.8150656,
        "description": "Vistrada is seeking highly motivated candidates to serve as senior data systems engineers to work as part of our Business Intelligence team supporting multiple clients. Vistrada’s clients look to us to provide technical leadership and assist them in solving many of today’s most challenging digital transformation issues and complex data needs. In this role, you will help address operational challenges associated with data modeling, system architectures, and reporting requirements by applying advanced capabilities, modern technology, and best practices to real-world scenarios. Key Responsibilities: Work closely with clients to develop technology innovation plans and enhancements on a broad range of areas, including: Model-based system engineering Relational data architectures Data modeling Data integration processes and ETL development Report / Dashboard creation using leading visualization technology platforms (i.e., Tableau; Qlik; Power BI) Data analytics platform design, development, and testing Machine Learning and/or Statistical Analysis Required Qualifications: Bachelor’s Degree and 8+ years of related experience 5+ years of experience with SQL databases, such as MSSQL, Oracle, MySQL, and/or PostgreSQL 5+ years of experience with leading visualization technology platforms (i.e., Tableau; Qlik; Power BI) Ability to work independently and eager to learn new technologies, techniques, processes, software languages, platforms, and systems Expertise to provide unbiased advice, formulate courses of action, analyze programs, and make recommendations across a wide spectrum of issues Passionate, goal driven, team-oriented, and outgoing Flexible, self-starter, and demonstrated ability to operate effectively with ambiguous and evolving objectives in a client-facing environment Effective communication skills Preferred Qualifications 2+ years of experience with cloud architecture systems, such as Azure, Google Cloud, or AWS Competency with source code management systems Competency with Office365 Strong written communication skills Powered by JazzHR jp7lMuTS1t",
        "url": "https://www.linkedin.com/jobs/view/3801258862"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962574438,
        "company": "Zortech Solutions",
        "title": "Databricks Engineer with Pyspark & Python Exp ---US",
        "created_on": 1720636750.4733503,
        "description": "Role: Databricks Engineer with Pyspark & Python Exp Location: NYC, NY OR Iselin, NJ (Hybrid 3 days' work from office) Duration: 6+ Months Job Description: Inperson interview is must, Expenses will be paid for in-person if not local Job Description: This position is for a Cloud Data / Reporting engineer with a background in SQL and data warehousing for enterprise level systems. The position calls for someone that is comfortable working with business users along with business analyst expertise. Major Responsibilities: Design, develop, and deploy Databricks jobs to process and analyze large volumes of data. Collaborate with data engineers and data scientists to understand data requirements and implement appropriate data processing pipelines. Optimize Databricks jobs for performance and scalability to handle big data workloads. Monitor and troubleshoot Databricks jobs, identify and resolve issues or bottlenecks. Implement best practices for data management, security, and governance within the Databricks environment. Experience designing and developing Enterprise Data Warehouse solutions. Demonstrated proficiency with Data Analytics, Data Insights Proficient writing SQL queries and programming including stored procedures and reverse engineering existing process Leverage SQL, programming language (Python or similar) and/or ETL Tools (Azure Data Factory, Data Bricks, Talend and SnowSQL) to develop data pipeline solutions to ingest and exploit new and existing data sources. Perform code reviews to ensure fit to requirements, optimal execution patterns and adherence to established standards. Skills: 10+ years - Enterprise Data Management 10+ years - SQL Server based development of large datasets 5+ years with Data Warehouse Architecture, hands-on experience with Databricks platform. Extensive experience in PySpark coding. Snowflake experience is good to have 3+ years Python (numpy, pandas) coding experience 3+ years' experience in Finance / Banking industry some understanding of Securities and Banking products and their data footprints. Experience with Snowflake utilities such as SnowSQL and SnowPipe - good to have Experience in Data warehousing - OLTP, OLAP, Dimensions, Facts, and Data modeling. Previous experience leading an enterprise-wide Cloud Data Platform migration with strong architectural and design skills Capable of discussing enterprise level services independent of technology stack Experience with Cloud based data architectures, messaging, and analytics Superior communication skills Cloud certification(s) Any experience with Regulatory Reporting is a Plus Education: Minimally a BA degree within an engineering and/or computer science discipline Master's degree strongly preferred",
        "url": "https://www.linkedin.com/jobs/view/3962574438"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3886350467,
        "company": "FIT:MATCH.ai",
        "title": "Senior Software Engineer",
        "created_on": 1720636752.1940968,
        "description": "About this Job: FIT:MATCH is seeking a highly skilled and innovative LiDAR Camera System Engineer and Computer Vision Developer to join our team. In this role, you will play a key part in designing, developing, and optimizing a camera system integrated with LiDAR technology, as well as creating computer vision and software solutions to process and analyze the captured data. You will be at the forefront of cutting-edge technology, contributing to the development of systems with applications across various industries. All source code is written to formalized, detailed, coding standards. The document is 96 pages of clear guidance (for example: documentation defines which versions of strcpy are safe, or whether to avoid it altogether). This role is a fully remote position. Preference is someone on the East Coast, but open to other time zones. Key Responsibilities: Collaborate with cross-functional teams to define project requirements and objectives Design and implement a camera system integrated with LiDAR sensors Develop and optimize computer vision algorithms for real-time data processing Create software components for data acquisition, analysis, and visualization Work on 3D point cloud processing, object recognition, and spatial mapping Conduct performance testing, debugging, and optimization of the system Stay up-to-date with the latest advancements in LiDAR technology and computer vision. Your Areas of Expertise: Bachelor's, Master's, or Ph.D. in Computer Science, Electrical Engineering, Robotics, or a related field Proven experience in LiDAR technology integration and camera system development Strong proficiency in computer vision, including feature detection, tracking, and 3D reconstruction Proficient in programming languages such as C++, Python, and relevant libraries (OpenCV, PCL) Experience with LiDAR data processing, point cloud manipulation, and object recognition Knowledge of machine learning and deep learning for computer vision tasks is a plus Familiarity with hardware design and sensor integration is advantageous Strong problem-solving skills and the ability to work independently and in a team Excellent communication and collaboration skills. We work with: Version Control: Git Bug Tracking and Project Management: JIRA, Confluence Deployment (CI/CD): Jenkins, Travis CI, CircleCI Test Management: RTM Programming Languages: C++, Python, Swift, Node.js API Testing: Postman, Insomnia Browser DevTools: Familiarity with browser developer tools for inspecting web elements, network traffic, and debugging Database Testing: Basic knowledge of SQL for writing queries to validate data integrity Browser and Device Compatibility: Knowledge of different browsers and devices to ensure cross-platform compatibility Performance Testing: Tools like JMeter or Gatling for load and performance testing Cloud Services: AWS Console, Amazon EC2, Amazon S3, AWS Lambda, Amazon RDS, DynamoDB About The Company Fit:match is a B2B2C technology company on a mission to revolutionize the apparel industry through data science to deliver increased relevance and satisfaction for shoppers, improve retail economics and help the industry as a whole make significant strides towards sustainable apparel retail. We are looking for people who share the same passion. Fit:Match is backed by an investor group including experienced angel investors, institutional firms, and multi-billion dollar retailers. The best part of working at Fit:Match is without a doubt, the people. We pride ourselves on hiring team members who embody our people characteristics of low ego, collaboration, dependability, and proven domain expertise. At Fit:Match, you would work cross-functionally with another top global talent with experience in the technology, data science, apparel design and fit, marketing, and retail industries. We obsess over growth, speed, and accuracy. We love a scrappy idea, an out-of-the-box growth hack, and live for reimagining and trying new things. Compensation, Benefits And Perks Generous PTO policy + 12 paid US holidays Medical, dental, and vision insurance for you and your family Paid Parental leave 401k Powered by JazzHR 0KFOx04anu",
        "url": "https://www.linkedin.com/jobs/view/3886350467"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3934489766,
        "company": "Transformity",
        "title": "Software Engineer",
        "created_on": 1720636753.9175076,
        "description": "Transformity is empowering beer, wine & liquor stores with amazing technology. We bring enterprise-level sophistication to independent liquor retailers, giving them one integrated operating system for every part of their business. We're growing fast, efficiently, & serving some of the top retailers in the US. We’re well-capitalized by great investors like YC, 1984, General Catalyst, Pioneer Fund, and Soma Capital. We understand our customers because we come from liquor store families. The team is three engineers from Amazon & Chewy. We have a high bar for engineering excellence. Our product moves millions of dollars a month and is used for 10-12 hours per day by every customer for many years. Everything we ship is useful. We work very closely with customers - you'll see the benefits of every feature you build first-hand. We value caring for our customers, work ethic, moving fast, communication, engineering + operational excellence. We're not a 9-5 company and we're very transparent about this. Requirements 3+ years of full-stack development experience using React Experience building well-designed product with great UX Familiarity with backend + cloud infrastructure Strong operational ability to root cause and resolve issues quickly when on-call Committed to working in-person from our NYC office 5 days per week & possibly travel",
        "url": "https://www.linkedin.com/jobs/view/3934489766"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911352239,
        "company": "Bloomberg",
        "title": "Senior Software Engineer - MySQL Data Infrastructure",
        "created_on": 1720636755.6266358,
        "description": "Bloomberg runs on data, it's our business and our product. The DataHub Engineering team provides a distributed platform for hosting datasets, complete with managed data stores, search, discovery, lakehouse and real-time stream processing capabilities. The platform provides a single place in the company to discover, access, publish and subscribe to data. The DataHub team introduced the abstraction of 'dataset', and invented a schema language to formally define all data at Bloomberg, complete with schema evolution, versioning, and true point in time semantics. We were the first team to introduce Kafka, Avro, company-wide Dataset Schema Registry, Mesos, Clustered MySQL, Vitess and Spark for ETL, at Bloomberg for designing this new data intensive platform that is the hub of financial datasets. The DataHub's DataOps and Infrastructure team designs, engineers and operates the infrastructure powering the DataHub platform. Who are you? We're looking for innovative problem solvers who enjoy pursuing complex issues to their root cause. Curiosity, kindness, and an appetite to continually learn and share knowledge are key traits to being a member of DataHub. On a technical level, we're looking for engineers who have proficiency and an interest in the following stack - Linux, Kubernetes, MySQL/RocksDB and infrastructure tools like OpenTofu, Ansible, OpenTelemetry. We'll trust you to: Design, build and maintain large clusters of Distributed Datastores composed of engines like MySQL/MyRocks scaled using Vitess to Petabytes of data with millisecond response on billions of reads and writes across 100s of independent financial applications Ensure platform reliability, observability and efficiency Customize Kubernetes clusters You'll need to have: 4+ years of software engineering experience Experience with an object-oriented programming language (ideally Python or Golang) Prior experience diagnosing failures in MySQL or related database engines, replication protocols - Experience building reliable data infrastructure A Degree in Computer Science, Engineering, Mathematics, similar field of study or equivalent work experience We'd love to see Any of your contributions in open source to Vitess, MySQL, RocksDB, MyRocks Vitess Production Experience Experience building custom resource controllers and Kubernetes operators. About Us: Meet the DataHub Engineering Team - https://www.techatbloomberg.com/blog/meet-the-team-datahub-engineering/ Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or maternity/parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law. Bloomberg provides reasonable adjustment/accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable adjustment/accommodation to apply for a job or to perform your job. Examples of reasonable adjustment/accommodation include but are not limited to making a change to the application process work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you would prefer to discuss this confidentially, please email AMER_recruit@bloomberg.net (Americas), EMEA_recruit@bloomberg.net (Europe, the Middle East and Africa), or APAC_recruit@bloomberg.net (Asia-Pacific), based on the region you are submitting an application for. Salary Range: 160,000 - 240,000 USD Annually + Benefits + Bonus The referenced salary range is based on the Company's good faith belief at the time of posting. Actual compensation may vary based on factors such as geographic location, work experience, market conditions, education/training and skill level. We offer one of the most comprehensive and generous benefits plans available and offer a range of total rewards that may include merit increases, incentive compensation [Exempt roles only], paid holidays, paid time off, medical, dental, vision, short and long term disability benefits, 401(k) +match, life insurance, and various wellness programs, among others. The Company does not provide benefits directly to contingent workers/contractors and interns.",
        "url": "https://www.linkedin.com/jobs/view/3911352239"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3969214770,
        "company": "The Walt Disney Company",
        "title": "Software Engineer II",
        "created_on": 1720636757.2947345,
        "description": "Disney Entertainment & ESPN Technology On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world. A few reasons why we think you’d love working here: Building the future of Disney’s media business: DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come. Reach & Scale: The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more. Innovation: We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news. Media Engineering Media Engineering is an innovative organization that is focused on providing the best possible video playback experience, art, and metadata to customers around the world, powered by exceptional technology. This strategic work requires streamlining and repurposing technology across different business and distribution channels – including streaming, linear, and theatrical – so that technology can ebb and flow across the needs of the business. Disney Streaming is looking for a Software Engineer II to join the Playback Quality Optimization team inside the Media Engineering organization. They play a critical role in the experience our customers enjoy with our streaming services. They focus on both managing and observing the quality of the playback users get while watching video. This includes making decisions in real time about how to optimize the Quality of Experience as well as collecting information about how the playback performed which is analyzed to continue improving the experience. This team writes components which embed directly into the video players as well as analytic tools around the results. As a Software Engineer II on this team, you will build software which will help us to refine and define our analytic techniques used for evaluating the performance of new playback and optimization algorithms and work with our existing predictive models and help build new models to improve the quality of video playback for our customers. There will be opportunities to collaborate with a varied team of data engineers, other software engineers, researchers, product managers and more, as well as to provide leadership by example to other developers on the team and in the organization. If you enjoy streaming media, are interested in live sports and entertainment, or just want to join a fast-growing team that plays an integral part of the revenue producing arm of a company, then our team is for you. Responsibilities Ability to analyze data to product insights to feed back into model development Apply statistical analysis techniques, including hypothesis testing, regression analysis, and data visualization. Basic Qualifications: Minimum of 3 years of related work experience. Bachelor’s degree in Computer Science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience Proficient in SQL with a focus on data manipulation, analysis, and visualization Proficient in Pandas, SciPy, NumPy and/or R Experience with Spark and the Databricks platform Experience implementing and training machine learning models, evaluating their performance, and fine-tuning hyperparameters Prior domain experience with video/audio streaming Strong teamwork and collaboration skills to work effectively with cross-functional teams. #DISNEYTECH The hiring range for this position in Seattle, WA and in New York City, NY is $117,998 to $158,290 per year; the hiring range for this position in Santa Monica/Burbank/Glendale/L.A., California and in Bristol, Connecticut is $112,586 to $151,030; and the hiring range for this position in San Francisco, California is $123,328 to $165,440 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",
        "url": "https://www.linkedin.com/jobs/view/3969214770"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3964964933,
        "company": "myGwork - LGBTQ+ Business Community",
        "title": "Senior Data Engineer",
        "created_on": 1720636759.241596,
        "description": "This inclusive employer is a member of myGwork – the largest global platform for the LGBTQ+ business community. About the Role: Grade Level (for internal use): 10 About the Role: Title: Senior Data Engineer – Big Data The Team: You will be an expert contributor and part of the Rating Organization’s Ingestion Pipelines Engineering Team. This team, who has a broad and expert knowledge on Ratings organization’s critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy. All Data Services team members provide leadership, innovation, timely delivery, and the ability to articulate business value. Be a part of a unique opportunity to build and evolve S&P Ratings next gen Ingestion pipelines platform. Responsibilities and Impact: The Data Engineer will support our data department on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects Design & Develop “Transformations” aspects using ELT framework to modernize the Ingestion pipelines and build data transformations at scale Experience in the areas of design and implementation of Ratings Data Ingestion pipelines with modern AWS cloud and other technologies such as S3, Hive, Databricks, Scala, Python and Spark Build processes supporting data transformation, data structures, metadata, dependency and workload management. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources into SQL Server, MongoDB, and others Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc Be in tune with emerging trends Big data and cloud technologies and participate in evaluation of new technologies Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards Compensation/Benefits Information: S&P Global states that the anticipated base salary range for this position is $95,000 to $166,000. Final base salary for this role will be based on the individual’s geographic location, as well as experience level, skill set, training, licenses and certifications. In addition to base compensation, this role is eligible for an annual incentive plan. This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, please click here. What We’re Looking For: Basic Required Qualifications: BE, MCA or MS degree in Computer Science or Information Technology 3+ years of hands-on experience in implementing data lake systems using AWS/Azure cloud technologies such as S3, Databricks, Hive. 1+ years of Expertise in building application using Kafka,APIs and DBMS for building ingestion pipeline for Bulk and incremental data loads. Experience with development frameworks as well as data and integration technologies such Python, Scala Experience in microservices and API design and implementation, with service-oriented architectures, SOAP and RESTful APIs Hands-on experience in developing scalable data pipeline using technologies like Kafka, Databricks, Spark and Scala applying ETL and ELT concepts Deep Experience with three or more technologies of Java/J2EE, C#, AWS, Spark, Python, Scala, any RDBMS, Kafka, Informatica, Angular/ReactJS, Databricks, Kubernetes Experience with Continuous integration and deployment tools like Jenkins and Azure DevOps Experience working in UNIX/Linux environment including shell scripting Strong understanding of cloud native architectures, design patterns and best practices Should be in position to articulate and convert requirements into solution. Knowledgeable in technology and industry trends with ability to develop and present substantive technical solutions Knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally Quality first mindset with a strong background and experience developing products for a global audience at scale Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners Additional Preferred Qualifications: Experience With Machine Learning Libraries and Frameworks (TensorFlow, MLlib, Pandas, Numpy) is an added advantage Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management Ability to prioritize and manage work to critical project timelines in a fast-paced environment Financial services industry experience Right to Work Requirements: This role is limited to persons with right to work in the United States. Return to Work: Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative, Restart, we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. About S&P Global Ratings At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions. S&P Global Ratings is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today. For more information, visit www.spglobal.com/ratings What’s In It For You? Our Purpose: Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People: We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values: Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits: We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our benefits include: Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, and Inclusion at S&P Global: At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy. ----------------------------------------------------------- Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. ----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning) Job ID: 298437 Posted On: 2024-07-04 Location: New York, New York, United States",
        "url": "https://www.linkedin.com/jobs/view/3964964933"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Uniondale, NY",
        "job_id": 3964427943,
        "company": "CenterLight Health System",
        "title": "DATA ENGINEER III",
        "created_on": 1720636760.95622,
        "description": "Job Purpose The Data Engineer III will play a pivotal role in designing, developing, and maintaining the data architecture for our organization. This individual will be responsible for T-SQL development, ETL processes, and Python scripting to ensure efficient data transfer, transformation, and integration. The primary focus will be on automating data workflows, supporting diverse file formats, and utilizing APIs for seamless data import and export. The Data Engineer will collaborate closely with cross-functional teams to enhance data-driven decision-making and contribute to the overall success of our data infrastructure. Job Responsibilities Utilize advanced T-SQL skills to design, optimize, and maintain database structures. Develop complex SQL queries for reporting and data transformation. Design, implement, and optimize ETL processes for efficient data extraction, transformation, and loading. Develop and maintain ETL scripts using Python for seamless integration with existing data workflows. Automate SFTP file transfer processes, ensuring secure and reliable data exchange. Import and export data and files in various formats, including flat file, XML, JSON, X12, Excel, and Parquet using Python. Utilize Python to integrate with APIs for importing and exporting data. Collaborate with team members and stakeholders to review and optimize code for efficiency and maintainability. Collaborate with analysts and business stakeholders to understand data visualization requirements. Work closely with cross-functional teams to understand data requirements and ensure data integrity. Document data engineering processes, standards, and best practices. Use Git and Github for version control of scripts and queries, ensuring a collaborative and organized development environment. Integrate Tableau for effective data representation and reporting. Schedule: 8:30 AM – 5:30 PM Weekly Hours: 40 Qualifications Education: Bachelor's Degree in Computer Science, Information Technology, or a related field. Experience: Minimum of 5 years of hands-on experience in T-SQL development and ETL processes. Proven experience in Python scripting for data manipulation and automation. Additional Requirements Technical Skills: Strong expertise in database design, optimization, and maintenance using T-SQL. Proficient in developing and optimizing ETL processes. Experience with automating SFTP file transfers and handling diverse file formats. Knowledge of data formats such as XML, JSON, X12, Excel, and Parquet. Familiarity with API integration for data import and export using Python. Proficient in version controlling scripts and queries using Git and Github. Preferred Skills Experience in data visualization using Tableau. Strong problem-solving skills and ability to troubleshoot data-related issues effectively. Identify and implement solutions to complex technical projects. Ability to work independently and in a team environment. Excellent communication and collaboration skills. Knowledge of health care delivery and operations a plus. Physical Requirements Individuals must be able to sustain certain physical requirements essential to the job. This includes, but is not limited to: Standing – Duration of up to 6 hours a day. Sitting/Stationary Positions – Sedentary position in duration of up to 6-8 hours a day for consecutive hours/periods. Lifting/Push/Pull – Up to 50 pounds of equipment, baggage, supplies, and other items used in the scope of the job using OSHA guidelines, etc. Bending/Squatting – Have to be able to safely bend or squat to perform the essential functions under the scope of the job. Stairs/Steps/Walking/Climbing – Must be able to safely maneuver stairs, climb up/down, and walk to access work areas. Agility/Fine Motor Skills - Must demonstrate agility and fine motor skills to operate and activate equipment, devices, instruments, and tools to complete essential job functions (ie. typing, use of supplies, equipment, etc.) Sight/Visual Requirements – Must be able to visually read documentation, papers, orders, signs, etc., and type/write documentation, etc. with accuracy. Audio Hearing and Motor Skills (Language) Requirements – Must be able to listen attentively and document information from patients, community members, co-workers, clients, providers, etc., and intake information through audio processing with accuracy. In addition, they must be able to speak comfortably and clearly with language motor skills for customers to understand the individual. Cognitive Ability – Must be able to demonstrate good decision-making, reasonableness, cognitive ability, rational processing, and analysis to satisfy essential functions of the job. Disclaimer: Responsibilities and tasks outlined in this job description are not exhaustive and may change as determined by the needs of the company. We are an affirmative action and equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, height, weight, or genetic information. We are committed to providing access, equal opportunity, and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. Salary Range (Min-Max) $115,000.00 - $130,000.00",
        "url": "https://www.linkedin.com/jobs/view/3964427943"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3919925200,
        "company": "Perennial Resources International",
        "title": "Senior Data Engineer (Snowflake) CONFIDENTIAL",
        "created_on": 1720636765.3034327,
        "description": "I have a full time opportunity for a Senior Data Engineer proficient in Snowflake development. This role is 3 days onsite, 2 days remote with one of our leading financial firms in Midtown Manhattan. In this role you will work with the Global Data Manager to build high-performing cloud data platforms to meet our analytical and BI reporting needs. This role will work as a key member of a data management team to drive development, delivery, and continuous improvement of the enterprise data warehouse architecture in support of our cloud data strategy. The role requires solid development experience in cloud data warehousing and modern data engineering technologies. The successful candidate will have experience in building a scalable cloud data platform using best practices and data warehouse principles. This person must understand business requirements and work closely with stakeholders to convert business requirements into technical solutions. This is a hands-on engineering role requiring extensive data engineering and advanced data analytical skills, as well as the ability to provide mentorship and guidance to junior resources. Essential Functions Translate business requirements into data model design and technical solutions. Mentor and guide the work of junior database developers and analysts. Develop high-performing, secure ELT/ETL processes to transform and integrate source data from internal and external systems to the cloud data warehouse. Maintain data warehouse and data pipeline processes, including troubleshooting issues, performance tuning, and implementing data quality improvements. Develop a framework for data validation rules and reports to ensure data quality and control. Automate standard code deployment and production release processes, adhering to change management processes. Create high-quality technical documentation, including data mapping, data processes, and operational support guides. Provide guidance on effective use of the data warehouse platform and facilitate BI reporting and data science model development. Troubleshoot process and data issues, investigate user questions, and identify solutions to resolve issues. Work in a fast-paced, dynamic environment and perform effectively in an agile development environment. Skills: 3+ years of hands-on experience in building large cloud data warehouses using Snowflake; including database architecture design, data transformations, stored procedures, account and security principles, performance management, etc. Experience in data modeling tools (e.g. Erwin, ER/Studio, etc.) and data modeling methodologies such as data vault and dimensional data models. 5+ years of strong technical experience in building scalable data pipelines to integrate structured and unstructured data in both cloud and on-premise environments. 8+ years of overall experience in data warehousing, advanced database design, SQL, stored procedures, views, performance tuning and optimization, database indexing techniques, and database maintenance. Understanding of data security and cloud security methodologies, and experience in configuration and management of data security to meet compliance and IT security requirements. Experience using Airflow or similar tools for developing scheduling and monitoring batch-oriented workflows. Working knowledge of Microsoft Power BI and Tableau. Experience with SDLC processes, agile development, and source code repositories (e.g. Git or Bitbucket). Experience in AWS services, related data and storage services is a plus. Working knowledge of Salesforce or other CRM systems is a plus. Understanding of micro services architecture and methodology is a plus. Excellent communication, organization, and problem-solving skills. Education & Experience: 8+ years in in data engineering and data warehouse engineering in cloud environment. Experience with Snowflake needed. Experience with agile development is a plus. Domain expertise with financial services is a plus. Bachelor's degree in computer science, data science, or related field. Successful candidates will be self-motivated with a strong desire to contribute to the success of the department and company. Additional Information: Hybrid role with requirement to be in New York office 3 days a week.",
        "url": "https://www.linkedin.com/jobs/view/3919925200"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956041919,
        "company": "Pumex Computing, LLC",
        "title": "Oracle Fusion Data Engineer",
        "created_on": 1720636767.0975783,
        "description": "Exciting Opportunity: Oracle Fusion Data Engineer The Role: We are seeking an experienced Oracle Fusion Data Engineer to join our team. You will play a crucial role in our data engineering and Oracle Cloud ERP transformation projects. This is an excellent opportunity to leverage your expertise in data migration, transformation, and Oracle Cloud Financials implementation. Key Responsibilities: Data Engineering: Execute data migrations in a Big Data environment, ensuring data integrity and performance. ERP Transformation: Lead the transformation of Oracle Fusion Cloud ERP, specifically focusing on Financials. Complex Implementation: Manage and deliver complex Oracle Cloud Financials implementations. Data Transformation/ETL: Utilize Spark, Python, PySpark, and HiveQL for robust data transformation and ETL processes. Data Processing: Perform data cleansing and curation tasks using Spark/Python to support analytical models. CI/CD Tools: Preferably experienced with CI/CD tools and code management processes. Independent Delivery: Deliver work items independently and lead data discussions with Tech Leads, Architects, and Implementation Partners. Required Skills and Experience: Extensive US Experience: 10+ years working for US companies in the US. Recent Banking Experience: 4+ years of recent experience (since 2019) in the banking sector. Data Ingestion Pipelines: Hands-on experience building data ingestion pipelines from Oracle Recruitment Cloud to a Big Data environment. Spark, Python, PySpark, HiveQL: 5+ years of recent experience with these technologies. Oracle Fusion Cloud ERP: 8+ years of experience with Oracle Fusion Cloud ERP Transformation – Financials. Complex Implementation: 8+ years of experience in delivering and managing complex implementations of Oracle Cloud Financials. Regulatory Understanding: Strong understanding of regulatory concerns impacting Oracle Cloud environments in both private and public sectors. Oracle Identity Cloud Services: 5+ years of experience in integrating with Oracle Identity Cloud Services. Taleo to Oracle Fusion Cloud Transition: Experience with this transition is a nice to have. Join us and be part of a forward-thinking team where your skills and expertise will make a significant impact on our projects. If you are passionate about data engineering and Oracle Cloud ERP transformation, we would love to hear from you!",
        "url": "https://www.linkedin.com/jobs/view/3956041919"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3962769950,
        "company": "Oliver Bernard",
        "title": "Senior Python Developer - $150k-$180k",
        "created_on": 1720636769.2348595,
        "description": "Senior Python Engineer – New York - $150k-$180k Location: Manhattan, New York Salary: $150,000 - $180,000 Industry: Travel Tech Stack: Python, Django, Flask, Kubernetes, CI/CD, AWS 👩🏻‍💻 Great opportunity for a talented Senior Backend Engineer (Python, Django, Flask, AWS) to join a scaling travel business allowing individual travel agents to connect people with their dream holidays. The Company 🚀 Growing travel business that provide an entire back office system for travel agents. Their 3-strong founding team are on a mission to build a next generation travel platform to give the world access to their dream destinations. The Role ✨ They are seeking a skilled Engineer (Python, Django, Flask, AWS) to be responsible for the integration and scaling up of their data platforms. The successful Engineer’s (Python, Django, Flask, AWS) primary responsibilities will include architecting, building and developing their systems. This is a great opportunity to work directly their core platform (Python, Django, Flask, AWS) and build out greenfield products used by hundreds of thousands of customers daily. Desired Skills ⚙️ Python Django, Flask Docker, Kubernetes REST AWS Distributed Systems Systems Design Benefits 🏖 Full medical insurance 401(k) Ability to book travel for friends and family and earn commission Two full remote working weeks encouraged If you are a skilled Engineer (Python, Django, Flask, AWS) who is interested in this role then please apply below and I will be in touch with more details.",
        "url": "https://www.linkedin.com/jobs/view/3962769950"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3880449562,
        "company": "Nextdoor",
        "title": "Principal Software Engineer - Data Platform",
        "created_on": 1720636771.2679684,
        "description": "#Team Nextdoor Nextdoor is where you connect to the neighborhoods that matter to you so you can belong. Our purpose is to cultivate a kinder world where everyone has a neighborhood they can rely on. Neighbors around the world turn to Nextdoor daily to receive trusted information, give and get help, get things done, and build real-world connections with those nearby — neighbors, businesses, and public services. Today, neighbors rely on Nextdoor in more than 315,000 neighborhoods across 11 countries. Meet Your Future Neighbors At Nextdoor, we believe that data is one of our most valuable assets. As a Principal Engineer on the Data Platform team, you’ll be driving an acceleration of product development, machine learning, data science and more by providing world class data infrastructure and self-service tools. At Nextdoor, we offer a warm and inclusive work environment that embraces a hybrid employment experience, providing a flexible experience for our valued employees. The Impact You’ll Make If you enjoy delighting coworkers with easy-to-use, fast, cost-efficient data infrastructure at massive scale, the Data Platform team at Nextdoor just might be the place for you. You will be pushing the boundaries of data freshness and query performance while simultaneously supporting thousands of tables at petabyte scale. Your Responsibilities Will Include You’ll envision, architect, build, and own a highly scalable data platform that will help power the development of Nextdoor for the foreseeable future You’ll actively participate in all phases of the software development lifecycle: analysis, technical design, planning, development, testing/CICD, release, and post production/escalation support You’ll build partnerships with key stakeholders, evangelize the use of the platform, and develop a roadmap for future development Participate in in-person Nextdoor events, trainings, off-sites, volunteer days, and other team building exercises Build in-person relationships with team members and contribute to the KIND culture that Nextdoor values What You’ll Bring To The Team 7-10 years demonstrated experience working on data infrastructure at petabyte scale Deep understanding of data infrastructure, governance, compliance and how enterprises use data Knowledge of SQL, Spark/pySpark and other data processing tools Computer science fundamentals such as data structures, algorithms, performance complexity, and optimization Software engineering fundamentals: version control systems (i.e Git, Github) and workflows, and ability to write production-ready code Knowledgeable with data science and machine learning tools and frameworks Familiarity with experimentation methodologies, such as A/B testing, multivariate testing, and statistical analysis Experience deploying scalable software Experience with cloud technologies (AWS preferred) Strong oral and written communication skills Ability to conduct meetings and make professional presentations, and to explain complex concepts and technical material to non-technical users Rewards Compensation, benefits, perks, and recognition programs at Nextdoor come together to create one overall rewards package. The starting salary for this role is expected to range from $230,000 to $290,000 on an annualized basis, or potentially greater in the event that your 'level' of proficiency exceeds the level expected for the role. Compensation may also vary by geography. We also expect to award a meaningful equity grant for this role. With equal quarterly vesting, your first vest date would be within the first 3 months of your start date. Overall, total compensation will vary depending on your relevant skills, experience, and qualifications. We have you covered! Nextdoor employees can choose between a variety of great health plans. We cover 100% of your personal monthly premium for health, dental, and vision – and provide a OneMedical membership for concierge care. At Nextdoor, we empower our employees to build stronger local communities. To create a platform where all feel welcome, we want our workforce to reflect the diversity of the neighbors we seek to serve. We encourage everyone interested in our purpose to apply. We do not discriminate on the basis of race, gender, religion, sexual orientation, age, or any other trait that unfairly targets a group of people. In accordance with the San Francisco Fair Chance Ordinance, we always consider qualified applicants with arrest and conviction records. For information about our collection and use of applicants’ personal information, please see Nextdoor's Personnel Privacy Notice, found here.",
        "url": "https://www.linkedin.com/jobs/view/3880449562"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Commack, NY",
        "job_id": 3949731325,
        "company": "IntelliShift",
        "title": "Software Engineer",
        "created_on": 1720636775.7506323,
        "description": "We are IntelliShift, a rapidly growing B2B SaaS company with more than 20 years of expertise in fleet management technology. IntelliShift is the fleet intelligence platform for safety and operations teams, and we empower construction, utilities, field services, and last mile delivery businesses to make the intelligent shift from siloed data using point solutions, to one simple, powerful platform. We provide these customers with a level of insight they've never had before to improve safety, establish next generation operational efficiency, and make intelligent decisions. The Software Developer role will focus on the back end of IntelliShift's applications and you will be tasked to create and manage software development projects using C# and strong Object-Oriented programming skills to help IntelliShift enhance and build our software portfolio and partake in the growth of IntelliShift! Required Skills: .net C#, SQL, Creation of web services Desired Skills: TDD, Understanding of SOLID principles, Creation of unit tests, REST, GraphQL, RabbitMQ While this is a remote position, you must be able to work Eastern Time Zone hours. What you will do: Participate in planning, designing and implementing new web, mobile, and server-side applications Work with other developers and project managers to engineer and develop new web, mobile, and server-side applications Troubleshoot issues quickly and stay up-to-date on current and emerging technologies, standards, and trends Handle continued testing, maintenance, and updates throughout the lifecycle of the applications Along with strong technical skills, you must have strong written and oral communication skills and exceptional time management capabilities What you bring: Minimum of 1-3 years of application development experience using C# Be able to follow and implement industry accepted best practices and standards Seamlessly switch between multiple projects Possess a self-starter attitude Have strong problem-solving skills Troubleshoot and communicate effectively Enthusiasm to work in a fast-paced collaborative environment The values you'll live by as part of the team: Always Put the Customer First - with the customer experience in mind, build trust and loyalty Embrace and Drive Change - have an innovative mindset and embrace the change Think Bigger - commit to growing the organization and grow as an individual. Be a Good Human - treat everybody with respect and always do what is best Execute with Passion and Urgency - we need to be the very best at what we do. Drive Trust and Transparency - open and honest communication, trust each other and take risks. Benefits We offer competitive compensation, commensurate with experience $90,000 - $100,000. We also offer outstanding benefits to simplify the lives of our employees and show them how much we appreciate their contributions. IntelliShift provides company-subsidized medical insurance for all employees (and largely subsidized coverage for families), dental, vision, and 401K with a 4% company contribution.",
        "url": "https://www.linkedin.com/jobs/view/3949731325"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3966475753,
        "company": "BioSpace",
        "title": "Senior Data Engineer",
        "created_on": 1720636777.605723,
        "description": "About Formation Bio At Formation Bio, we are building the pharma company of the future , redefining drug development with our proprietary, tech-driven platform, focused on bringing new treatments to patients faster and more efficiently . At Formation Bio we license clinical stage drug assets and develop them in-house using our proprietary, technology-driven platform. Over the past few years, we have been able to significantly expedite the drug development process, evidenced by our acceleration of over 300 clinical trials and reducing trial durations by up to 50%. This innovation translates to getting life-saving drugs to market 1-3 years faster, where we specialize in partnering with and nurturing in-house clinical-stage drugs. Our diverse team of experts come from across multiple industries, combining the best of tech and pharma talent. Join our culture of innovation where your work directly contributes to transforming patient care in areas such as rheumatology, dermatology, CNS, and cardiometabolic diseases. Our dynamic environment blends advanced technology with strategic drug development, speeding up the delivery of new treatments. Here, every role plays a part in our mission to bring new treatments to patients faster and more efficiently. About The Position As a Senior Data Engineer you will be a major contributor to the tech future for Formation Bio as we expand into an AI enabled world. You would be responsible for contributing to our fundamental Data Infrastructure by building data pipelines, integrations, and tools that are used by in-house experts, leveraging traditional automation, cutting edge LLM integrations, and everything in between. In this role, you will collaborate closely with engineers, product managers, and domain experts in the drug development field to design, build, and implement systems that will significantly enhance the capacity of teams to make strategic and operational drug development decisions swiftly and effectively. This position is ideal for the delivery-focused engineer who is passionate about leveraging technology for meaningful and impactful applications. Your expertise in software development will be instrumental in driving Formation Bio’s mission to bring new treatments to patients faster and more efficiently. Responsibilities Collaborate with cross-functional teams, including product managers and domain experts, to discover, build, and iterate on innovative features and products. Ensure the scalability, security, and performance of our data platform and pipelines. Rapidly develop and iterate on proofs-of-concept to test new ideas and hypotheses to efficiently validate and evolve our software solutions in alignment with strategic objectives in drug development. Stay abreast of emerging trends and advancements in data engineering, and software development to continually enhance our product offerings. Act as an internal evangelist for use of data and best practices with the organization, providing expert guidance and insights to other teams within the organization. About You Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field, or equivalent experience. Minimum of 5 years of experience in data engineering in Python, with a demonstrated ability to thrive in ambiguous and rapidly-changing environments, with a proven track record of contributing significantly to the successful launch and scaling of new and innovative products, especially in a 0-1 setting. Deep understanding of complex data, data curation and data quality, such as traceability, security, performance latency and correctness across supply and demand processes. Exceptional collaboration and communication skills to effectively engage and work along stakeholders from diverse disciplines and varying levels of technical expertise. Ideally, adept at translating complex technical concepts into clear, actionable insights for all audiences. Experience with Infrastructure as Code (IaC) using modern tools such as Terraform or Cloud Formation and the full end-to-end process of modern software deployment (e.g., containerization, CI/CD). Experience in the pharmaceutical or biotech industry is a plus, but not required. Experience with AI technologies, particularly in LLMs and machine learning is a plus, but not required. Experience with vector storage is a plus but not required. We offer competitive compensation because we want to hire the best people and reward them for their contributions to our mission. We pay all employees competitively relative to the New York City market, regardless of their location. In compliance with NYC’s pay transparency law and in pursuit of pay equity and fairness, we publish salary ranges for all open roles at Formation Bio. The target salary range for this role is $175,000 - $230,000. On top of base salary, we also offer equity, generous perks, location flexibility, and comprehensive benefits – learn more about them and our compensation philosophy here. If this range doesn’t match your expectations, please still apply because we may have something else for you. You will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.",
        "url": "https://www.linkedin.com/jobs/view/3966475753"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3964658174,
        "company": "Robert Half",
        "title": "Senior Data Engineer",
        "created_on": 1720636782.4506683,
        "description": "Description The Core Data & Services team within the Data organization is seeking a Senior Data Engineer. In this role, you will be instrumental in establishing foundational data pipelines and datasets that are critical for enabling numerous engineering and analytical teams to harness data for key business decisions. You will provide vital information to engineering, analytics, and operational teams, supporting the scaling of the largest streaming service. Your efforts to expand, scale, and standardize core principles through observability, lineage, data quality, logging, and alerting across all engineering teams are essential for creating a unified data platform. We are looking to grow our team with world-class Data Engineers who share our passion for making a positive impact! NO C2C, Relocation won't be considered. Must live in New York. Key Responsibilities Maintain, update, and expand existing Core Data platform data pipelines using Scala and Python/Spark, ensuring strict uptime SLAs. Extend current Core Data platform functionality, including metadata parsing, extending the Metastore API, and building new integrations with internal and external APIs. Implement new batch and streaming data pipelines using Scala, Databricks, and Airflow. Develop the Lakehouse architecture, collaborating with customers, partners, and stakeholders to shift towards a Lakehouse-centric data platform. Create shared libraries in Scala and Python to abstract complex business logic, ensuring consistent functionality across all data pipelines. Utilize tech stack including Airflow, Spark, Databricks, Delta Lake, Snowflake, Scala, and Python. Collaborate with product managers, architects, and engineers to drive Core Data platform success. Develop and document internal and external standards and best practices for pipeline configurations, naming conventions, partitioning strategies, and more. Ensure high operational efficiency and quality of Core Data platform datasets to meet SLAs and ensure reliability and accuracy for all stakeholders. Actively participate in agile/scrum ceremonies to improve team processes. Engage with and understand customers, forming relationships to prioritize innovative new offerings and platform improvements. Maintain detailed documentation to support data quality and data governance requirements. Requirements Basic Qualifications: 5+ years of data engineering experience developing large data pipelines. Strong algorithmic problem-solving skills. Proficient in Scala and Python programming. Basic understanding of AWS or other cloud provider resources (S3). Strong SQL skills with the ability to create queries to analyze complex datasets. Hands-on experience with distributed processing systems such as Spark in a production environment. Experience with data pipeline orchestration systems such as Airflow. Familiarity with scripting languages. Willingness and ability to learn new skill sets. Self-starter with an eye for detail and excellent analytical and communication skills. Preferred Qualifications Experience with major MPP or cloud database technologies (Snowflake, Redshift, Big Query). Experience developing APIs with GraphQL. Deep understanding of AWS or other cloud providers and infrastructure as code. Familiarity with data modeling techniques and data warehousing best practices. Familiarity with Scrum and Agile methodologies. Required Education STEM Bachelor’s or Master’s Degree Technology Doesn't Change the World, People Do.® Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles. Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go. All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit © 2024 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to",
        "url": "https://www.linkedin.com/jobs/view/3964658174"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3873345728,
        "company": "CurbWaste",
        "title": "Senior Software Engineer",
        "created_on": 1720636783.969323,
        "description": "About The Role We're looking for a Sr Software Engineer who will align with our own passion for delivering an innovative, world-class product that makes our customers successful and gives them joy along the way. The ideal candidate has an eye for high quality code, best practices & industry standards, and takes pride/ownership of whatever feature, product or codebase they're working on. In this position the candidate will work closely with the Head of Engineering, Product Managers, and stakeholders to execute on the product roadmap in effort to address business and customer needs. About Us We are an early stage vertical SaaS business dedicated to bringing the most innovative technology to the historically underserved Waste Management Industry. We care deeply about the hard working, dedicated, and humble people of the Waste Management industry and will stop at nothing to ensure that they get the most value technology can offer. We lean on each other to deliver the best value to our customer and we constantly challenge each other to be the best version of ourselves every day. We settle at nothing short of being the best at what we do. What You Will Do Take on challenging projects, everything from refactoring to developing new complicated feature Work with engineering leadership to help refine the product roadmap Work on making our application scalable through code and/or architecture & infrastructure Work with and mentor other developers via pair programming & code reviews Lead by example in being a craftsman of software development Work in an agile environment & software development life cycle Champion testing & automation Encourage habits around technical excellence, evolutionary design and lifelong learning Requirements What You Will Need Bachelors (or higher) in Computer Science or related field Minimum of 5 years of experience in javascript/typescript Proficiency in API building & design Experience in Node.js & React Experience in AWS, Docker, Kubernetes (a plus) Experience using PostgreSQL Experience in search technologies (ElasticSearch or Apache Solr) Deep knowledge of design patterns, best practices, microservice architecture, CI/CD Benefits What We Offer: This is not just a job. This is a career, a chance to make a direct impact. Here's how we help: Flextime, recognition, and support for autonomous work: Flexible time off with ample learning and development opportunities to continue growing your career Health benefits: Company-paid medical, dental, and vision Our Mission: We aim to change the way waste companies run their business. We are a software founded by haulers and built for haulers. We care about the environment and want to play a positive role in the future of the waste industry. Software helps create solutions and we are focused on being the leaders in change. At CurbWaste we celebrate individuality and uniqueness. We believe that the convergence of fresh perspectives and experiences from all walks of life is what makes our product and culture so great. We strongly encourage people from underrepresented groups to apply. We do not discriminate against employees based on race, color, religion, sex, national origin, gender identity or expression, age, disability, pregnancy (including childbirth, breastfeeding, or related medical condition), genetic information, protected military or veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws.",
        "url": "https://www.linkedin.com/jobs/view/3873345728"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956356771,
        "company": "Grubhub",
        "title": "Senior Software Engineer",
        "created_on": 1720636785.49364,
        "description": "About The Opportunity We’re all about connecting hungry diners with our network of over 300,000 restaurants nationwide. Innovative technology, user-friendly platforms and streamlined delivery capabilities set us apart and make us an industry leader in the world of online food ordering. When you join our team, you become part of a community that works together to innovate, solve problems, grow, work hard and have a ton of fun in the process! Why Work For Us Grubhub is a place where authentically fun culture meets innovation and teamwork. We believe in empowering people and opening doors for new opportunities. If you’re looking for a place that values strong relationships, embraces diverse ideas–all while having fun together–Grubhub is the place for you! Grubhub is looking for a Senior Software Engineer to join the payments platform team in NYC. The payments platform team is responsible for ensuring seamless, secure and efficient transactions for our customers. As a member of our team, one will get an opportunity to collaborate with talented professionals to enhance payment capabilities, integrate new technologies and learn about the dynamic digital financial ecosystem. The Impact You Will Make You’ll gain expertise in your domain and build highly scalable & reliable additions to our platform You’ll be accountable for delivery, deployment, maintenance, and monitoring the performance of your applications and the platform as a whole You’ll evaluate tools, technologies, frameworks, and vendors for the platform along with other senior team members You’ll write performant and concise code to meet the defined standards here at GrubHub, review the code of peers, and ensure security and scalability of the features you work on You’ll help to create the backlog of tech debt and features, suggesting areas for improvement and enhancement You’ll actively work with other team members in the domain and be a team player What You Bring to the Table Bachelor’s Degree in a science, programming or engineering related field 5+ years experience building highly-scalable consumer-facing applications (e-commerce preferred) Experience with Java or other object-oriented languages Experience architecting, designing, and developing testable, fault tolerant, and performant software with emphasis on future evolution. Experience in building and maintaining payments platforms, preferably in an e-commerce setting. Familiarity with industry best practices, compliance standards, and security protocols related to financial transactions. Knowledge of payment gateways, processors, and payment methods to ensure a comprehensive understanding of the payments ecosystem. Exposure to fraud prevention and risk mitigation strategies in the context of online payments. Experience collaborating with financial institutions, understanding their APIs and integrations to facilitate seamless transactions. Experience in developing and implementing strategies for incident response and recovery specifically tailored for payments systems, minimizing downtime and ensuring data integrity. NYC Salary Range: $171,500 - $257,500 The Base Pay component of our Total Rewards package is based on a variety of factors including but not limited to: job responsibilities, location, experience and, education/certifications. In addition to the pay component, this role may be eligible for equity and benefits as part of the Total Rewards package. The Total Rewards package will be determined at the time a contingent offer is made. And Of Course, Perks! Flexible PTO. Grubhub employees enjoy a generous amount of time to recharge. Health and Wellness. Excellent medical benefits, employee network groups and paid parental leave are just a few of our programs to support your overall well-being. Competitive Pay. You’ll receive a competitive base salary with eligibility for generous incentives, bonuses, commission or RSUs (role-specific). Learning and Career Growth. Your personal and professional development is a priority at Grubhub. We empower you to be a leader and grow your career through training, coaching and mentorship opportunities. MealPerks. Get meals on us! Our employees get a weekly Grubhub credit to enjoy and support local restaurants. Fun. Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives like Wellness Wednesdays, Slack competitions and virtual happy hours! Social Impact. At Grubhub we believe in giving back through programs like the Grubhub Community Relief Fund and donating $1 million to the Equal Justice Initiative in 2020. Employees are also given paid time off each year to support the causes that are important to them. Grubhub is an equal opportunity employer. We welcome diversity and encourage a workplace that is just as diverse as the customers we serve. We evaluate qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics.",
        "url": "https://www.linkedin.com/jobs/view/3956356771"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Tarrytown, NY",
        "job_id": 3888466125,
        "company": "Zortech Solutions",
        "title": "Lead Data Engineer",
        "created_on": 1720636787.175815,
        "description": "Role : Lead Data Engineer Location : Tarrytown NY 10591 (Hybrid role 3 days onsite 2 days WFH) Duration: 6-12+ Months Job Description Must have AWS , Apache Airflow , Pyspark , Redshift Candidate should have 12+ years of experience in Data Engineering Designing, creating, testing and maintaining the complete data management & processing systems. Working closely with the stakeholders & solution architect. Ensuring architecture meets the business requirements. Building highly scalable, robust & fault-tolerant systems. Taking care of the complete ETL process. Knowledge of Hadoop ecosystem and different frameworks inside it HDFS, YARN, MapReduce, Apache Pig, Hive, Flume, Sqoop, ZooKeeper, Oozie, Impala and Kafka Must have knowledge and working experience in Real-time processing Framework (Apache Spark), PySpark and in AWS Redshift Must have experience on SQL-based technologies (e.g. MySQL/ Oracle DB) and NoSQL technologies (e.g. Cassandra and MongoDB) Should have Python/Scala/Java Programming skills Discovering data acquisitions opportunities Finding ways & methods to find value out of existing data. Improving data quality, reliability & efficiency of the individual components & the complete system. Creating a complete solution by integrating a variety of programming languages & tools together. Creating data models to reduce system complexities and hence increase efficiency & reduce cost. Introducing new data management tools & technologies into the existing system to make it more efficient. Setting & achieving individual as well as the team goal. Problem solving mindset working in agile environment",
        "url": "https://www.linkedin.com/jobs/view/3888466125"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3897086694,
        "company": "1199SEIU Benefit and Pension Funds",
        "title": "System Engineer II",
        "created_on": 1720636788.8921697,
        "description": "Responsibilities Design, implement, and maintain Citrix environments to meet organizational requirements. Ensure high availability, scalability, and performance of Citrix solutions. Maintain, monitor, and troubleshoot all issues related to application and database servers, including upgrades, patches, and operating system issues. Maintain a healthy Windows Active Directory environment by reviewing and modifying group policies, logon scripts, and Active Directory permissions and security on the entire domain. Collaborate with network engineering, business application, and database administration units to ensure server and system resources are meeting business demands. Support and deploy Information Security (IS) system guidelines to a secure Information Technology (IT) infrastructure. Act as the technical lead for the IT Engineering team. Handle escalated helpdesk issues; provide support and offer technical advice on Citrix, Windows, VMware, and related issues. Identify and resolve Citrix-related issues promptly to minimize downtime. Conduct root cause analysis for recurring problems and implement preventive measures. Perform additional duties and projects as assigned by management. Qualifications Bachelor’s degree in Computer Science, Information Technology, or equivalent years of experience required. Minimum five (5) years experience in Windows and/or Unix/Linux operating system administration. Minimum three (3) years experience with VMware and Citrix VAD required. Experience with Citrix Virtual Apps and Desktops (Required, and v1906 and above preferred). Extensive experience with Citrix Application Layering (and/or similar application layering technology) Extensive experience with Citrix Provisioning Services Expert level proficiency with Windows 2016, 2019, 2022 Group Policy and Active Directory, solid understanding of Active Directory design and implementation. Experience with Ivanti UWM (formerly AppSense) v2018 and above preferred (Experience with other profile management solutions acceptable). Working knowledge of Citrix ADC and ADM a plus. Experience with thin clients and their management (Dell Wyse and Wyse Management suite or Elux). Exchange Online / Office365 Management a plus. Understanding of IT Service Management terms and processes. Citrix certifications are a plus. Vision and leadership skills with the ability to troubleshoot complex issues and provide solutions. Ability to establish and maintain positive working relationships with other team members, unit directors, upper management, technology leaders, and support staff on as enterprise-wide basis. Excellent written and verbal communication skills; ability to articulate vision, direction, requirements, and priorities. Must be able to participate in 24/7 on-call rotation schedule. We offer extraordinary benefits including outstanding health, dental, pension and family benefits for most positions which are paid entirely by the Funds without co-payments, deductibles, or out-of-pocket expenses for covered services. We also offer tuition reimbursement, generous holiday, vacation, and sick leave, as well as a 401K plan.",
        "url": "https://www.linkedin.com/jobs/view/3897086694"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Ithaca, NY",
        "job_id": 3816942210,
        "company": "Cornell University",
        "title": "Database Engineer (Hybrid/Fully Remote)",
        "created_on": 1720636790.6293812,
        "description": "Join Our Team as a Database Engineer for the Lab of Ornithology at Cornell University! If you're eager to make an impact and be part of a dynamic team, then we invite you to explore this exciting opportunity with us! The College of Agriculture and Life Sciences at Cornell University embraces diversity and seeks candidates who will contribute to a climate that supports students, faculty, and staff of all identities and backgrounds. We strongly encourage individuals from underrepresented and/or marginalized identities to apply. About The Department The Cornell Lab of Ornithology is a globally recognized leader in technology, data management, and large-scale participatory science supporting birds and biodiversity conservation. We curate more than a petabyte of digital assets, nearly two billion bird sightings, and leverage innovative big data analysis tools and machine learning to produce web applications and services to empower a global community of bird and nature enthusiasts, researchers, conservationists, and educators. The Cornell Lab is in an incredible growth phase and we rely on a team of high-performance engineers to navigate complex challenges to scale our data-driven tools and services for conservation communities in all corners of the globe. The Lab engages millions of people a year through our innovative educational platforms and data-powered citizen science enterprises. We are committed to fostering a healthy workplace that values diverse perspectives and backgrounds as well as supporting growth and advancement opportunities. The Lab welcomes staff who are still learning in their careers and who are motivated to take on new challenges. About The Opportunity This role is part of our core engineering team and will develop and maintain database infrastructure and services that support numerous user-facing applications, including eBird, Merlin, Macaulay Library, Birds of the World, and BirdCast. We are seeking a skilled and highly motivated full-time Database Engineer who will: Design, implement, and maintain highly available large-scale cloud based production database infrastructure for the Cornell Lab of Ornithology (CLO). Participate actively in the design and evolution of CLO technical infrastructure and database platforms, including scalable, agile, cloud-based systems. Actively develop, monitor, and improve the performance and reliability of database systems, working closely with application developers and other technical staff to optimize database architecture and query design. Serve as a technical liaison supporting coordination and integration of application infrastructure to meet CLO strategic objectives. Stay current on database infrastructure and database development best practices and processes. The engineering team is based at the Cornell Lab of Ornithology in Ithaca, NY. There is some flexibility on work location for this position which could either be located in Ithaca with a hybrid work arrangement or be fully remote. What We Need The successful candidate will have Bachelor’s degree in computer science or related field with 5+ years experience or equivalent combination administering large relational databases in a 24x7 production environment that includes installing, configuring, monitoring, upgrading, and maintaining complex database systems. Experience in and/or demonstrated commitment to supporting diversity, equity, access, inclusion, and wellbeing. Extensive experience with managed database services such as Amazon RDS. In depth knowledge of relational DBMS theory, design, and technology. Exceptional SQL development and performance tuning skills. Experience writing database functions in a procedural language such as PL/pgSQL. Experience working with and supporting software developers including with schema design, query development, performance tuning, and optimization. Experience with source control management systems such as git. Experience designing, documenting, and implementing backup and recovery plans and database security policy. Ability to troubleshoot and solve database performance and functionality issues. Experience with proactive monitoring and problem solving to continuously improve database performance. Ability to work weekends or evenings when participating in the 24-7 on call duty rotation. Preferably the successful candidate will also have the following; Advanced degree in computer science or related field. Experience administering PostgreSQL databases and expertise with PostgreSQL system metrics and optimization strategies. Experience with ETL architecture and implementation. Experience with Infrastructure as Code and with Terraform or similar IaC tooling. Experience with scheduling and automation tools such as Rundeck. Experience or familiarity with database migrations using tools like Flyway or Liquibase. Familiarity with the Linux command-line and experience with shell scripting. Experience working with data analysts and researchers including writing efficient and accurate SQL queries to extract data for research and reporting. Prior use and understanding of eBird, Merlin, BirdCast or other Cornell Lab tools and resources. Interest in birds, nature, conservation, and/or natural science. Rewards And Benefits Cornell receives national recognition as an award-winning workplace for our health, wellbeing, sustainability, and diversity initiatives. Our benefits programs include comprehensive health care options, generous retirement contributions, access to wellness programs, and employee discounts with local and national retail brands. We invite you to follow this link to get more information about our benefits: https://hr.cornell.edu/benefits-pay. Follow this link to learn more about the Total Rewards of Working at Cornell: https://hr.cornell.edu/jobs/your-total-rewards. No Visa Sponsorship is available for this position. How To Apply You must submit both a Resume and Cover letter. When applying through our system, please attach your application materials (resume and cover letter). You can upload documents either by “dragging and dropping” them into the dropbox or by using the “upload” icon on the application page. For more detailed instructions on how to apply to a job at Cornell, visit How We Hire on the HR website. If you are an internal employee, please log in to Workday. Cornell University is an innovative Ivy League university and a great place to work. Our inclusive community of scholars, students, and staff impart an uncommon sense of larger purpose and contribute creative ideas to further the university's mission of teaching, discovery, and engagement. Diversity and Inclusion are a part of Cornell University’s heritage. We are a recognized employer and educator valuing AA/EEO, Protected Veterans, and Individuals with Disabilities. We also recognize a lawful preference in employment practices for Native Americans living on or near Indian reservations. Familiarize yourself with Cornell's COVID-19 workplace guidance as well as the university's COVID-19 services and information. University Job Title Database Administrator IV Job Family Information Technology Level G Pay Rate Type Salary Pay Range $105,889.00 - $129,419.00 Remote Option Availability Hybrid Remote Company Contract College Contact Name Denise Smith Job Titles And Pay Ranges Non-Union Positions Noted Pay Ranges Reflect The Potential Pay Opportunity For Each Job Profile. The Hiring Rate Of Pay For The Successful Candidate Will Be Determined Considering The Following Criteria Prior relevant work or industry experience Education level to the extent education is relevant to the position Unique applicable skills Academic Discipline (faculty pay ranges reflects 9-month annual salary) To learn more about Cornell’s non-union staff job titles and pay ranges, see Career Navigator. Union Positions The hiring rate of pay for the successful candidate will be determined in accordance with the rates in the respective collective bargaining agreement. To learn more about Cornell’s union wages, see Union Pay Rates. Current Employees If you currently work at Cornell University, please exit this website and log in to Workday using your Net ID and password. Select the Career icon on your Home dashboard to view jobs at Cornell. Online Submission Guidelines Most positions at Cornell will require you to apply online and submit both a resume/CV and cover letter. You can upload documents either by “dragging and dropping” them into the dropbox or by using the “upload” icon on the application page. For more detailed instructions on how to apply to a job at Cornell, visit How We Hire on the HR website. Employment Assistance For general questions about the position or the application process, please contact the Recruiter listed in the job posting or email mycareer@cornell.edu. If you require an accommodation for a disability in order to complete an employment application or to participate in the recruiting process, you are encouraged to contact Cornell University's Office of Institutional Equity and Title IX at voice (607) 255-2242, or email at equity@cornell.edu. Applicants that do not have internet access are encouraged to visit your local library, or local Department of Labor. You may also request an appointment to use a dedicated workstation in the Office of Talent Attraction and Recruitment, at the Ithaca campus, by emailing mycareer@cornell.edu. Notice To Applicants Please read the required Notice to Applicants statement by clicking here . This notice contains important information about applying for a position at Cornell as well as some of your rights and responsibilities as an applicant. EEO Statement Diversity and Inclusion are a part of Cornell University’s heritage. We are a recognized employer and educator valuing AA/EEO, and we do not tolerate discrimination based on any protected characteristic, including race, ethnic or national origin, citizenship and immigration status, color, sex/gender, pregnancy or pregnancy-related conditions, age, creed, religion, actual or perceived disability (including persons associated with such a person), arrest and/or conviction record, military or veteran status, sexual orientation, gender expression and/or identity, an individual’s genetic information, domestic violence victim status, familial status, marital status, or any other characteristic protected by applicable federal, state, or local law. We also recognize a lawful preference in employment practices for Native Americans living on or near Indian reservations in accordance with applicable law. Cornell University embraces diversity and seeks candidates who will contribute to a climate that supports students, faculty, and staff to all identities and backgrounds. We encourage individuals from underrepresented and/or marginalized identities to apply. 2024-01-30",
        "url": "https://www.linkedin.com/jobs/view/3816942210"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Albany, NY",
        "job_id": 3951748976,
        "company": "ACS Consultancy Services, Inc",
        "title": "oracle data developer",
        "created_on": 1720636792.2640073,
        "description": "Job Title: oracle data developer Location: Hybrid (Albany) We are currently seeking candidates who meet the following qualifications Responsibilities Design, develop, and maintain Oracle database systems to meet business requirements. Create and optimize database schema, tables, indexes, views, and stored procedures. Develop complex SQL queries, functions, and triggers to support application development. Collaborate with application developers to design and optimize data access and storage. Perform data modeling and design data structures to support business processes. Ensure data integrity, performance, and security of Oracle databases. Conduct performance tuning and optimization of SQL queries and database operations. Implement and maintain data integration processes using ETL tools. Monitor database performance, implement changes, and apply new patches and versions when required. Provide database support for development, testing, and production environments. Develop and maintain documentation for database systems, processes, and procedures. Troubleshoot and resolve database-related issues and provide technical support to users. Qualifications Experience as an Oracle Data Developer or in a similar role. Proven experience in designing, developing, and maintaining Oracle databases. Strong experience with SQL programming and developing complex queries, functions, and triggers. Experience with Oracle PL/SQL and database performance tuning. Experience in data modeling tools and techniques. Experience with ETL processes and tools. Knowledge of database security practices and data governance. Bachelor’s degree in Computer Science, Information Technology, or a related field, or equivalent work experience. Proficiency in Oracle database technologies and tools. Strong understanding of database design principles and data architecture. Experience in other database systems (e.g., SQL Server, MySQL) is a plus. Knowledge of data warehousing concepts and best practices. Experience with database migration and upgrade projects. Excellent problem-solving and analytical skills. Strong communication and interpersonal skills. Ability to work both independently and as part of a team. Detail-oriented with a focus on quality and accuracy. If you meet these qualifications, please submit your application via link provided in Linkedin. Kindly do not call the general line to submit your application.",
        "url": "https://www.linkedin.com/jobs/view/3951748976"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3953253473,
        "company": "Altice USA",
        "title": "Senior Data Engineer",
        "created_on": 1720636793.8618658,
        "description": "Altice USA is a cutting-edge communications, media, and tech company. We connect people to what matters most to them; texting with friends, advertising that resonates, or binge watching their favorite show. Our differentiated approach centers around technologies that push the envelope and deliver the ultimate customer experience. We’re building a workforce that attracts and retains the best talent, not only to meet the needs of our customers, but that also reflects the diverse communities we serve. Job Summary This job is for a talented full-stack developer with experience working with the latest and greatest tools and technologies. As a Full Stack Engineer at Altice USA, you will play a key role in designing, developing, and maintaining our self-service data applications. You will work closely with cross-functional teams to deliver high-quality software solutions that meet our business requirements. The ideal candidate will have expertise in front-end and back-end technologies. Responsibilities Front-End Development Develop user-friendly interfaces using frontend technologies. Collaborate with stakeholders to implement intuitive designs. Optimize solutions for performance and scalability. Back-End Development Design, implement, and maintain backend components. Build and maintain APIs for integration with front-end applications. Ensure the security and performance of all services. Collaboration and Communication Collaborate with cross-functional teams, including business stakeholders and other developers. Communicate technical concepts to non-technical stakeholders effectively. Continuous Learning Stay updated on industry trends and emerging technologies. Proactively seek opportunities to enhance skills and knowledge. Qualifications Bachelor's Degree in relevant field of study or equivalent work experience. 3+ years of relevant employment experience. Experience in software design techniques, methodologies, and tools. Proven experience as a full-stack developer with a deep understanding of front and backend technologies. Strong proficiency with the following technologies Cloud technologies (GCP preferred) Frontend technologies - TypeScript, JavaScript, and ReactJS Python - Flask, FastAPI, and/or Django SQL API (REST and/or GraphQL) Docker Strong problem-solving and interpersonal collaboration skills and the ability to work effectively with a team. If you are passionate about creating innovative web solutions and want to be part of a dynamic team, apply now. Altice USA is an Equal Opportunity Employer committed to recruiting, hiring and promoting qualified people of all backgrounds regardless of gender, race, color, creed, national origin, religion, age, marital status, pregnancy, physical or mental disability, sexual orientation, gender identity, military or veteran status, or any other basis protected by federal, state, or local law. Altice USA, Inc. collects personal information about its applicants for employment that may include personal identifiers, professional or employment related information, photos, education information and/or protected classifications under federal and state law. This information is collected for employment purposes, including identification, work authorization, FCRA-compliant background screening, human resource administration and compliance with federal, state and local law. Applicants for employment with Altice will never be asked to provide money (even if reimbursable) as part of the job application or hiring process. Please review our Fraud FAQ for further details. This position is identified as being performed in/or reporting to company operations in New York State. Salary ranges are supplied in compliance with New York State law. Pay is competitive and based on a number of job-related factors, including skills and experience. The starting pay rate/range at time of hire for this position in the posted location is $100,246.00 - $164,689.00 / year. The rate/range provided herein is the anticipated pay at the time of hire, and does not reflect future job opportunity.",
        "url": "https://www.linkedin.com/jobs/view/3953253473"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3957698817,
        "company": "Rockerbox",
        "title": "Senior Data Engineer (Senior Software Engineer III)",
        "created_on": 1720636795.6295815,
        "description": "Rockerbox empowers marketing executives to confidently make data-driven decisions, helping brands such as Tula, Figs, and Burton with the strategic decision-making that drives growth. Our guiding principle is that no marketing organization should require a data engineering team to make data-driven decisions. We take on the technical challenges of collecting and consolidating all marketing data into a single platform to enable any marketing organization, big or small, to focus on their core strength: building their brand. At Rockerbox, the Core Data team is pivotal, managing everything from live data collection and aggregation to data warehousing, including governance. As a Senior Data Engineer, you will play a crucial leadership role within our technical organization, focusing on optimizing data storage, access patterns for efficiency and safety, and guiding data warehouse strategies. The ideal candidate will bring profound expertise in data warehouses like Redshift and Snowflake, alongside a solid grasp of alternative data storage solutions (e.g., data lakes, NoSQL databases). Your experience should also include crafting data pipelines and a hands-on familiarity with technologies for event processing, pub/sub models, and orchestration tools such as Airflow. We seek a Senior Data Engineer passionate about contributing to a team-focused, dynamic environment, eager to influence our product's evolution as we expand our reach to thousands of customers. Responsibilities: Take the lead in building scalable, resilient, well-monitored, and cost-efficient data pipelines utilizing a range of technologies Provide expert advice and guidance on data architecture, ensure quality and scalability through design and code reviews Serve as the organization's resident expert on SQL; mentor other engineers on improving and optimizing their queries Provide expertise and leadership in the application of effective patterns in the data engineering codebase, bringing your extensive experience to bear Lead the application of effective monitoring and quality control measures, including automated testing and alerting, to ensure data integrity across all data products. As a tech lead, work with Product Managers and cross-functional teams to design data solutions meeting business requirements, detailed in clear technical specifications Identify and evaluate emerging technologies, tools, and trends to improve efficiency and effectiveness in data engineering processes. Requirements: 10+ years of experience as a data engineer, working with data warehouses, pipelines and cloud technologies (ideally AWS) Proficient in data modeling and architecture for distributed data warehouses and cloud solutions, with deep knowledge of the trade-offs between data warehouses, databases, and data lakes to guide informed decisions on when to use each Skilled in crafting modern data pipelines, both real-time and batch, with tight SLOs and complex transformations, utilizing messaging, serverless, and streaming tech Expert-level SQL; experience with other database paradigms (key-value stores, graph databases) is a plus Expert-level python; comfort working with version control and CI/CD is required; significant exposure to other languages is a plus Experience mentoring engineers, especially on data warehousing, pipelines, and related technology architectures, with a proven ability to simplify complex topics in both written and verbal communication Strong comfort level with technical project leadership and the communication skills to bring stakeholders together around a project plan and architecture, demonstrated by successful large-scale projects spanning multiple teams Product mindset to embrace business needs and produce scalable data/engineering solutions Why you'd love us: If you are looking for an opportunity to make an impact within a growing, low-ego tech startup that alleviates a significant client pain point, Rockerbox is the place for you. You'll take on ownership of projects end-to-end to deliver value against our product roadmap - with our fast, iterative release schedule, you will see the result from your efforts materialize quickly. Not least, you'll work alongside colleagues who have a (sometimes wacky) sense of humor and who support each other to continually improve. We genuinely like each other as people, and work together to make good things happen for all of us. Compensation and Benefits Salary range between $175,000 - $195,000, depending on level as determined through the interview process; Equity options Remote-first - work anywhere in the US Health, vision, and dental insurance Unlimited PTO 10 Paid Holidays Rockerbox Unplugged - we shut down the last week of the year 12 weeks Parental Leave for all parents of a new child Traditional and ROTH 401k options $1000 annual training stipend Rockerbox is a remote-first, equal opportunity employer. We actively encourage applicants from underrepresented backgrounds, and we are accepting candidates based anywhere in the United States. Please note that we are not able to accommodate C2C candidates for this role.",
        "url": "https://www.linkedin.com/jobs/view/3957698817"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3676514539,
        "company": "Sensorum Health",
        "title": "Senior AI Software Engineer",
        "created_on": 1720636797.3237247,
        "description": "Sensorum is seeking a Senior Software AI Engineer who can accelerate the development of our AI-based software through individual contribution and close partnership with our CTO and other engineers. You will be responsible for the implementation of our activity recognition audio model pipelines, sequential time series models, and all of our datasets. Under the guidance of the CTO, you will take existing and new modeling tasks from whiteboard to production working through design, dataset creation, model selection, training, tuning, edge/cloud deployment, and maintenance.",
        "url": "https://www.linkedin.com/jobs/view/3676514539"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3819958898,
        "company": "Emerald",
        "title": "Principal Data Engineer",
        "created_on": 1720636800.6649113,
        "description": "Emerald is seeking a Principal Data Engineer to join our Elastic group as part of the Data Engineering Team. The Data Engineering Team focuses on the software and data engineering related to the consuming and processing of ecommerce domain data into timely, trustworthy, accessible, and meaningful analytics schemas for the business to use to understand key metrics and perform analytics. We reduce data redundancy by creating systems and datasets that serve as domain data products. We enable discovery and governance of our data, and we support key business goals. Specifically, we are growing our e-commerce customer base, understanding how customers use products, and enable data-driven growth and retention strategies. To thrive in this role, you are excited about data and motivated to learn new technologies. You are comfortable collaborating with engineers from other teams, product owners, business teams, data analysts and data scientists. You own and shape your technical domain area and move the related business goals forward. You are eager to resolve upstream data issues at the source instead of applying workarounds. You analyze and test changes to our data architectures and processes and determine what the possible downstream effects and potential impacts to data consumers will be. This position can be performed from any of our US-based offices or remotely from anywhere within the US. Please note that we are unable to provide sponsorship for work visas for this position. Only candidates authorized to work in the US without sponsorship requirement will be considered. •  Overall delivery of the cloud data platform as well as its transformation efforts • Contributions to the development and execution of the overall technical strategy • Providing technical direction on initiatives with significant bottom line impact • Modernizing and simplify data pipelines and datasets by utilizing by industry best practices and advanced techniques • Automating tasks such as end-to-end testing and report generation • Prototyping and building transformation pipelines with tools such as Databricks, AWS Services, FiveTran, and other services in Cloud Platform using languages such as Python, Go & SQL 10+ years of experience with large scale data warehousing, dimensional modelling, modern data architectures (data lake, delta lake) & BI. Experience with data bricks products is required Proven and demonstrated technical leadership experience with building prototypes and scoping work into iterative development plan with definitions of done, acceptance criteria, etc. Proven experience in Big Data technologies, Python & Apache Spark ecosystem or with Databricks products in designing streaming, self-healing & scalable ELT data pipelines architectures. Proven experience in strong SQL background, Data Modeling, deep understanding of current cloud offerings (AWS preferred) and the ability to design effective data-as-a-service architectures. Experience with document databases (e.g., mongo dB) a plus Proven experience with backend systems and software engineering. Programming experience in a relevant language, e.g. Python, Java Proven experience working with cloud platforms like GCP or AWS ABOUT EMERALD Emerald’s talented and experienced teams grow our customers’ businesses 365 days a year with products that create connections, deliver content, and drive commerce. We produce over 140 annual events, create and deliver content through print and digital channels, and power commerce through our seamlessly integrated in-person and digital platforms and channels. For more information, please visit http://www.emeraldx.com. At Emerald, we strive to foster a diverse and inclusive community. We actively recruit and champion candidates who bring new perspectives from varied professional backgrounds and experiences, and we are intentional about ensuring a positive hiring experience for everyone. Our job postings don’t contain experience inflation, and most don’t require college degrees. Instead, they’re crafted to focus on outcomes and transferable experiences that are assessed in a structured interview process carried out by trained hiring teams. COMPENSATION & BENEFITS Target Compensation: $120,000-$150,000 (Bonus Eligible) Please note that this range reflects a reasonable estimate of the target compensation for this position. This range may ultimately vary based on a candidate’s qualifications and may be higher where required by applicable law. We offer a competitive benefits package designed to strengthen our employees’ physical and mental health, including unlimited vacation for exempt employees, flexible working locations, 401(k) plan with a company match, medical/dental/vision coverage with inclusive provisions including transgender services and fertility benefits, parental and caregiver leave, dependent, commuter and FSA benefits, professional development programs like Toastmasters, and mental wellness tools such as weekly guided meditation programs. If you need accommodation in our application process or have questions about our posted salary range, please email our Talent Acquisition team at Careers@EmeraldX.com.",
        "url": "https://www.linkedin.com/jobs/view/3819958898"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3860723175,
        "company": "Method",
        "title": "Senior Software Engineer, Data",
        "created_on": 1720636802.3495018,
        "description": "Meet Method 🔮 We built Method to propel consumer finance into the next decade. Method’s APIs are redefining financial connectivity with real-time, read-write, and frictionless access to all consumer liability data with integrated payment rails. The composability of our APIs and robust integrations into 10,000+ financial institutions allows lenders, fintechs, and other financial institutions to build products that unlock a level of autonomy never before harnessed by consumers. We have helped 2+ million users connect 30+ million liability accounts, save them millions in interest and fees, get them access to billions of dollars in personalized loans, and earn millions of points on their purchases. We have partnered with 60+ financial institutions - including Bilt Rewards, SoFi, PenFed, Figure, Happy Money and Aven - to deliver frictionless, personalized and engaging user experiences. We are backed by investors and advisors from Andreessen Horowitz, Y Combinator, SV Angel, Ardent Ventures, Abstract Ventures, Truist Ventures, Truebill, Upstart, and more. About Our Team As a small but fast-growing team, we value teammates who are passionate about building, scaling, all while having fun together! While we have our own roles to fill, we often find ourselves wearing multiple hats. No day is the same when you’re building from scratch. Our founding team is based across Austin and Washington D.C., with offices in New York. To learn more about us, check out our blog! Location : Austin, TX., Washington D.C., or New York The Impact We are seeking a highly analytical Senior Software Engineer, Data at Method. You will have autonomy over your projects, collaborate with the engineering, customer success, and business operations team to drive the development of cutting edge consumer finance products. What You'll Do Build, scale, and improve new applications that directly impact how the business (i.e. Sales, Customer Success, Finance, etc.) at Method operates Develop algorithms to transform data into actionable insights Analyze large volumes of high-velocity financial data to identify patterns and anomalies indicative of errors, utilizing statistical and machine learning techniques Develop canonical datasets to track key product metrics including user growth, engagement, and revenue Prepare, process, analyze, and visualize data, discovering patterns and trends and answering key questions along the way Write code to capture database performance, and create tools and dashboards to provide actionable insight into that data Collaborate with peers on architecture, design, and code reviews Who You Are 5+ years of software engineering experience, with deep experience working with the company’s data-centric products Experience with: Programming Languages: Python, JavaScript, Spark Data exploration tools: Grafana, Jupyter Notebooks, Metabase, Quicksight, PowerBI, or similar Relational and non-relational databases, data lakes: MongoDB, Snowflake / Redshift Have the ability to work with a high degree of autonomy but also balancing out working dynamically with a wide range of people, both internally and externally Good understanding of financial data, machine learning algorithms, and frameworks Have strong communication skills, both verbal and written, and be able to work under pressure to solve technical problems for Method’s customers Follow the flow of data through various pipelines to debug data issues Collaborate with Method’s business groups, to drive end to end solutions Are curious how things work; when they break you are eager and able to help fix them Extra awesome Experience in Financial Services / FinTech. Experience working at a smaller stage company / start-up environment Disclaimer to Staffing/Recruiting Agencies: Method Financial does not accept unsolicited resumes from recruiters or employment agencies in response to our Career page or a Method Financial social media/job board post. Method Financial will not consider or agree to payment of any referral compensation or recruiter fee relating to these unsolicited resumes. Method Financial explicitly reserves the right to hire those candidate(s) without any financial obligation to the recruiter or agency. Any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of Method Financial.",
        "url": "https://www.linkedin.com/jobs/view/3860723175"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962963145,
        "company": "Publicis Media",
        "title": "Associate, Software Engineer",
        "created_on": 1720636803.975499,
        "description": "Publicis Media harnesses the power of modern media through global agency brands CJ, Performics, Publicis Collective, Publicis Health Media, Spark Foundry, Starcom and Zenith. A key business solution of Publicis Groupe ([Euronext Paris FR0000130577, CAC 40], Publicis Media’s digital-first, data-driven global practices deliver client value and increase growth in a platform-powered world. It is present in more than sixty countries with over 23,000 employees worldwide. Job Description Software Engineers within Publicis Media concentrate on the development, implementation, and ongoing innovation of world class leading engineering products, business analytics, and next generation technologies. The Associate Software Engineer we are looking to join our team will be on point for the design, development, implementation and on-going support of web applications. Included in design and development of these applications requires a collaborative spirit to partner with the broader engineering team whilst partnering on different layers of the infrastructure. You will report to Executive Vice President, Engineering. This is a hybrid role, requiring three days in-office each week. If you are contacted for an interview, your recruiter will discuss specifics with you, inclusive of any necessary reasonable accommodations. Your day to day will include: Translating application storyboards and use cases into functional applications Identifying bottlenecks and bugs, devising solutions to mitigate and address these issues Integration of the front-end and back-end aspects of the web application Collaboration with other team members and stakeholders Developing features to enhance the user experience. Striking a balance between functional and aesthetic design. Ensuring web design is optimized for smartphones. Building reusable code for future use. Optimizing web pages for maximum speed and scalability. Qualifications You have: Strength in React, HTML, CSS, JavaScript. Strong understanding of JavaScript and jQuery Knowledge and understanding of JS frameworks Experience working with cloud technologies such as Amazon Web Services Strong knowledge of consuming RESTful and SOAP APIs Proficient understanding of code versioning tools such as GitHub Bachelor's degree in Computer Science or related field 1+ years of experience Additional Information Our Publicis Groupe motto “Viva LaDifférence”meanswe’rebetter together, and we believe thatour differences make us stronger. It means wehonor and celebrate all identities, across all facetsof intersectionality, and it underpins all that we doas an organization.We are focusedon fostering belonging and creating equitable &inclusive experiences for all talent. Publicis Groupe provides robust and inclusive benefit programs and policies to support the evolving and diverse needs of our talent and enable every person to grow and thrive. Our benefits package includes medical coverage, dental, vision, disability, 401K, as well as parental and family care leave, family forming assistance, tuition reimbursement, and flexible time off. If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com. All your information will be kept confidential according to EEO guidelines. Compensation Range: $52,500 - $80,00 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 07/15/2024. Req #24-6898",
        "url": "https://www.linkedin.com/jobs/view/3962963145"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Manhattan, NY",
        "job_id": 3829973701,
        "company": "City of New York",
        "title": "SOFTWARE ENGINEER",
        "created_on": 1720636807.5208635,
        "description": "The New York City Campaign Finance Board manages New York City’s small donor democracy program and educates and engages voters via NYC Votes. The CFB has enjoyed a tremendous arc of progress over its 30-year history, and our updated flagship small donor democracy program is the centerpiece of this progress. We eliminate barriers to participation by providing access to the resources New Yorkers need to vote or run for office and amplify the voices of small donors with New York City’s small donor democracy program. We are dedicated to making New York City’s local democracy more open, transparent, and equitable. You would be working with a team that is mission-driven and committed to continuous improvement. The technology unit is responsible for custom software development, networking, technical support, and cybersecurity. The unit works to develop and maintain software systems tailored to the organization's needs, manage, and secure the organization's network infrastructure, and protect against potential cyber threats. Responsibilities CFB’s technology unit seeks an experienced full-stack software engineer. Under general supervision, with a broad scope for the exercise of independent initiative and judgment, this engineer is responsible for the system analysis, technical design, development, testing, enhancement, and maintenance of various applications that support the Agency’s business functions. The selected candidate will be required to perform tasks related to the development of software applications and data transformation activities for the Agency. Responsibilities include, but are not limited to: Collaborate with cross-functional teams to identify software requirements and develop solutions. Develop software solutions using the .NET framework, including C#, ASP.NET, JavaScript, SQL, etc. Design software architecture and develop technical specifications based on requirements. Analyze and improve software performance by conducting tests and debugging issues. Collaborate with QA engineers to ensure software meets quality standards and user requirements. Document software designs, code, and tests for future reference. Participate in code reviews to maintain code quality and identify areas for improvement. Stay up to date with emerging trends and technologies in software development and incorporate new practices into current projects. Proficiency in writing unit tests and using unit testing frameworks. Knowledge of performance tuning, security, and scalability. Experience with Dependency Injection frameworks (built-in .NET Core, Ninject, Unity). Experience with Microservices. Experience with NoSQL databases. Experience with Salesforce integration. Bachelor’s degree or above in Computer Science or related discipline. Essential Skills 3+ Years of hands-on C#, .net software design and development experience. 3+ years of strong demonstrable experience in service-oriented architecture, N-tier application development using Microsoft’s web technology stack (.NET, ASP.NET, C#, MVC, ADO.NET, Entity Framework, Web API, HTML/CSS/JavaScript). 3+ years of experience with the ability to build/create/maintain application databases utilizing MS SQL Server/Azure SQL, including SSIS, TSQL, stored procedures, views, and functions. 3+ years of experience in Object-Oriented Design (OOD) - should be familiar with terms like Abstraction, Encapsulation, Inheritance, and Polymorphism. Experience working with a team of engineers. Proven track record of becoming a subject matter expert in areas related to current assignments. Ability to collaborate and partner across a diverse team tapping the strength and unique skills of every team member. 2+ years of experience with Azure, AWS, GCP, or other cloud providers. Experience with Microsoft Azure DevOps CI/CD. Experience with working in an Agile environment. Tools – MS Visual Studio, SQL Server Management Studio (SSMS), Azure DevOps with Git, and cloud services in Azure. Ability to speak and write clearly and succinctly in a variety of communication settings and styles. Experience solving complex problems using logical thinking first and coding second. Additional Information New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview. As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at StudentAid.gov/PSLF. The CFB is an equal opportunity employer firmly committed to diversity. All individuals are encouraged to apply. If you anticipate needing any type of reasonable accommodation to apply for an employment opportunity, please contact access@nyccfb.info or (212) 409-1800. The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy. TO APPLY All applicants must apply through NYC Government Jobs | Explore Careers | City of New York Please search and apply to the job ID number listed above. Resume and cover letter are required for consideration. Note that only applicants under consideration will be contacted. For more information on careers with the NYC Campaign Finance Board visit our website at https://www.nyccfb.info/ to access the full listing of job opportunities and to learn more about our agency. Minimum Qualifications A baccalaureate degree from an accredited college and one year of satisfactory full-time experience in computer programming and applications, computer systems analysis and development, or a closely related area; or An associate degree from an accredited college with a major in computer science and two years of experience as described in \"1\" above; or A four-year high school diploma or its educational equivalent and four years of experience as described in \"1\" above; or Education and/or experience equivalent to \"1\", \"2\", or \"3\" above. Public Service Loan Forgiveness As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/. Residency Requirement New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview. Additional Information The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy. , $110,000.00 – $115,000.00",
        "url": "https://www.linkedin.com/jobs/view/3829973701"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3948073074,
        "company": "Asana",
        "title": "Senior Software Engineer, Product",
        "created_on": 1720636809.4476771,
        "description": "We're looking for experienced software engineers to join our product engineering group in New York where we're building features that are core to the Asana product. Our focus is to improve work management both within and across teams, ranging from helping team leads and individual contributors plan and execute their work in Asana, to helping senior managers leverage Asana to monitor and support broad, complex initiatives within their organizations. The Product team builds features end-to-end. From designing our data models to implementing the subtle interaction behaviors that differentiate good software from great software. We work closely with UI designers and are supported by our infrastructure team. We aim to delight users with both large new features and smaller, daily product enhancements—thanks to our continuous deployment architecture. We want to create a superlative user experience, down to the smallest details. This role is based in our New York City office with an office-centric hybrid schedule. The standard in-office days are Monday, Tuesday, and Thursday. Most Asanas have the option to work from home on Wednesdays. Working from home on Fridays depends on the type of work you do and the teams with which you partner. If you're interviewing for this role, your recruiter will share more about the in-office requirements. What You’ll Achieve You will work full-stack to design, build and release new functionalities used by millions of Asana users Make consistent contributions to Asana’s core product with a focus on overcoming tricky technical challenges and modelling practices that improve quality and velocity Mentor other engineers through activities like pairing and code reviews to promote a culture of technical excellence Own and support technical design and execution for medium and large projects on the team (and sometimes partner teams) Partner with the team’s Tech Lead to drive aspects of the technical strategy About You Around 5 years of experience working in large codebases 1+ years of experience leading complex projects Sound judgment when balancing moving quickly with producing quality code and long-term code maintainability Experience working cross-functionally with stakeholders and PM/Design partners to define requirements, make tradeoffs and align on long-term plans Appreciation for productivity and deep care for helping teams collaborate more effectively and efficiently At Asana, we're committed to building teams that include a variety of backgrounds, perspectives, and skills, as this is critical to helping us achieve our mission. If you're interested in this role and don't meet every listed requirement, we still encourage you to apply. What We’ll Offer Our comprehensive compensation package plays a big part in how we recognize you for the impact you have on our path to achieving our mission. We believe that compensation should be reflective of the value you create relative to the market value of your role. To ensure pay is fair and not impacted by biases, we're committed to looking at market value which is why we check ourselves and conduct a yearly pay equity audit. For this role, the estimated base salary range is between $171,000 - $258,000 . The actual base salary will vary based on various factors, including market and individual qualifications objectively assessed during the interview process. The listed range above is a guideline, and the base salary range for this role may be modified. In addition to base salary, your compensation package may include additional components such as equity, sales incentive pay (for most sales roles), and benefits. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role. We strive to provide equitable and competitive benefits packages that support our employees worldwide and include: Mental health, wellness & fitness benefits Career coaching & support Inclusive family building benefits Long-term savings or retirement plans In-office culinary options to cater to your dietary preferences These are just some of the benefits we offer, and benefits may vary based on role, country, and local regulations. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role. About Us Asana helps teams orchestrate their work, from small projects to strategic initiatives. Millions of teams around the world rely on Asana to achieve their most important goals, faster. Asana has been named a Top 10 Best Workplace for 5 years in a row, is Fortune's #1 Best Workplace in the Bay Area, and one of Glassdoor’s and Inc.’s Best Places to Work. After spending more than a year physically distanced, Team Asana is safely and mindfully returning to in-person collaboration, incorporating flexibility that adds hybrid elements to our office-centric culture . With 11+ offices all over the world, we are always looking for individuals who care about building technology that drives positive change in the world and a culture where everyone feels that they belong. We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We provide equal employment opportunities to all applicants without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by law. We also comply with the San Francisco Fair Chance Ordinance and similar laws in other locations.",
        "url": "https://www.linkedin.com/jobs/view/3948073074"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3910969271,
        "company": "Vori",
        "title": "Backend Software Engineer",
        "created_on": 1720636811.0007112,
        "description": "We're looking for a passionate, results oriented backend software engineer who's excited to bring an entire industry online for the first time. You will be joining a team of world class engineers to help tackle some of the most challenging and impactful problems that are transforming how people buy groceries every day. If you're a world class software engineer who loves food and fighting to empower small and medium sized businesses in old school industries, join us! Qualifications SF Bay Area or NYC Experience developing back end services (Rest, Typescript, Nodejs, AGgrid) Experience developing and maintaining production web services and data systems (we use GCP) Experience with orchestration, data pipelines and data warehousing (Temporal, Big Query, DBT) Experience working with SQL databases (Postgres) Strong communication and interpersonal skills Bonus: Experience working in hyper-growth startup environment Bonus: Full stack capabilities - Front end/data eng/data science How To Apply If you'd like to be considered, please reach out to us with a summary of your work and why you're excited to join Vori. Email : careers@vori.com",
        "url": "https://www.linkedin.com/jobs/view/3910969271"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963158573,
        "company": "DKMRBH Inc",
        "title": "Software Engineer",
        "created_on": 1720636812.5741465,
        "description": "Position: Software Engineer Location: Remote (Preference - NYC, Boston or SF) Employment Type: Full-Time Visa: US Citizen Strong preference if they're in NYC, Boston or SF but open to anywhere else but needs to be rockstar. Need candidates who were previously worked for good startups bcs startup experience is a must. Candidate Requirements The ideal candidate will have experience shipping products, working with cloud platforms, and have familiarity with containerization tools. Additionally, experience with prompting tools, NLP packages, and cybersecurity is a plus. Minimum Requirements a Candidate Must Meet Had ownership over aspects of product development in both small and large organizations at differing points in your career. Have used Langchain, LangGraph, or other prompting tools in production or for personal projects. Familiarity with NLP packages such as Spacy, Stanza, PyTorch, and/or Tensorflow. Shipped a working product to users, either as part of a team or on your own. 5+ years of experience as a software engineer Nice-to-haves What could make your candidate stand out. Experience with cybersecurity. Ideal companies Successful b2b growth stage startups that have a strong emphasis on product and design. Orgs with competent management where talent is dense and protected.",
        "url": "https://www.linkedin.com/jobs/view/3963158573"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Rochester, NY",
        "job_id": 3965905661,
        "company": "AP Rochester",
        "title": "System Engineer",
        "created_on": 1720636814.341321,
        "description": "AP Professionals has partnered with a local, family owned, MSP that is growing and looking to add a Senior Systems Engineer/Administrator to their local Rochester team. In this role, as the Senior Systems Engineer you will work directly with business owners to design and implement high-tech products and solutions for local businesses. Serve as both a consultant to decision making, and a technical resource in implementation. 7-10+ years of experience within Windows, SQL, Linux, and more is required. Prior MSP experience a plus! This is a full-time, direct hire position with an onsite requirement at a centrally located Rochester, NY office. This position offers opportunities for bonuses, continued advancement, and certifications! RESPONSIBILITIES Design, engineering, and manage technical projects, including implementation, oversight, and tier three infrastructure support Network, server, and cybersecurity/security solutions installation and support Deployment and maintenance of cloud solutions, such as AWS, Google, and MSO365/Azure Setup and support of UTM devices, routers, and switches Ongoing management of backup and disaster recovery, antivirus, and system patching for various clients EXPERIENCE 7+ years of experience servicing commercial environments such as Windows Domains, Windows Servers, SQL, Exchange, MAC, and Linux 7+ years of experience with one or more cloud solutions such as Azure, AWS, or Google 7+ years of experience with firewalls, routing, UTM devices, and VPNs Experience with Kaseya, Autotask, ITGlue, and other MSP tools is a plus Experience with MAC and Linux is a plus Prior experience working within an MSP desired KNOWLEDGE, SKILLS, ABILITIES, AND OTHER CHARACTERISTICS Automation and scripting a plus Strong troubleshooting and critical thinking skills required Interest in cybersecurity and IT security Enjoys challenges, and excels at solving puzzles Certifications are strong desired!",
        "url": "https://www.linkedin.com/jobs/view/3965905661"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3848159399,
        "company": "Meta",
        "title": "Software Engineer, Network",
        "created_on": 1720636818.2663002,
        "description": "Meta is actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. As a member of this small and growing team, you will be in charge of designing and implementing how we build, model, analyze and monitor Meta’s current and next generation networks. In addition to software development, your duties may involve evaluating third party and open source software, interacting with various other Engineering teams and working with network hardware vendors. There is a wide range of areas to work on, spanning next-gen datacenter networking architecture (e.g., OpenFlow or similar technologies for software defined networking), software systems to configure, monitor, analyze, model, and manage our datacenter, backbone, and content delivery networks. This is a full-time position. Software Engineer, Network Responsibilities: Develop software to scale the production network Work with networking devices and protocols Integrate with other systems, evaluate third party solutions Collaborate with Network Engineering team to automate various processes, build software infrastructure for network monitoring and analysis, aid in capacity planning and architecture change analysis Minimum Qualifications: Experience with network devices (routers, switches, load balancers) and an understanding of network routing protocols Web traffic experience related to data centers and websites Experience with design and implementation of network management systems 5+ years of experience in C/C++ and Python 5+ years experience in Systems programming, TCP/IP, HTTP/HTTPS, SPDY, DNS, and load balancers Knowledgeable with MySQL databases Understanding of the Linux operating system Experience debugging issues within custom code High aptitude and technology-agnostic approach to engineering About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com. $70.67/hour to $208,000/year + bonus + equity + benefits Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about  benefits  at Meta.",
        "url": "https://www.linkedin.com/jobs/view/3848159399"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3774034549,
        "company": "Palantir Technologies",
        "title": "Software Engineer - Python Developer Infrastructure",
        "created_on": 1720636819.8718286,
        "description": "A World-Changing Company Palantir builds the world’s leading software for data-driven decisions and operations. By bringing the right data to the people who need it, our platforms empower our partners to develop lifesaving drugs, forecast supply chain disruptions, locate missing children, and more. The Role Software Engineers at Palantir build software at scale to transform how organizations globally use data. As a Software Engineer on Developer Infrastructure, you’ll identify, develop, and drive investments to improve the velocity and quality of our engineering, as well as bolster the happiness and productivity of other developers. The Developer Infrastructure role spans a spectrum of areas, such as build and software supply-chain systems, platform runtime environments, telemetry relating concurrency, memory/performance optimizations, and monitoring/alerting. Your primary users will be other developers at Palantir. They will be empowered with the software you develop to build capabilities used by research scientists, aerospace engineers, intelligence analysts, and economic forecasters in countries around the world. There will be opportunities to contribute to open source software, including projects maintained by others that we leverage. You’ll work autonomously within a community that will support and challenge you as you grow to become a strong technical contributor and engineering leader. Given the push of our new AIP product, and as we expand our AI product offerings, the demand for Python expertise has grown significantly. In response, we are building a Python Development Infrastructure team that will play a crucial role in shaping Palantir's approach to Python, a language that has not been extensively used in our products before. Core Responsibilities We're hiring engineers who are passionate about empowering developers to solve real-world problems. If you’re motivated to develop reliable, performant, scalable systems and tools, here are some examples of the types of work you’d get to do: Define and build standard practices for how services are operated and observed throughout their deployment Build libraries and tooling for defining service APIs and the RPC interactions between microservices; like the conjure ecosystem Help developers understand and adhere to development best practices by building great tools and development processes Push Palantir to the cutting edge of software supply chain security Technologies We Use A variety of languages, including Python, Java, Go, and TypeScript. Open-source databases like Cassandra, Lucene, Elasticsearch Open-source libraries/frameworks like GraphQL, Undertow, Jackson, Log4j, Rattler and Conda. Industry-standard build tooling, including Gradle, Webpack, Hatch, CircleCI, and GitHub. What We Value Growing subject matter expertise and depth of understanding of a problem space. Embracing, centralizing, and abstracting complexity away from our users in order to expose simple, powerful APIs. Ability to understand how technical decisions impact your users and a drive to super-power those people, particularly through empathy for developer/operator workflows and productivity. Awareness of recent industry best practices and open source advancements. Great problem solving skills with ability to evolve complex systems. What We Require 2+ years of software engineering experience, preferably in fields such as Computer Science, Mathematics, Software Engineering, Physics. Strong coding skills with demonstrated proficiency in programming languages, such as Java, C++, Python, JavaScript/TypeScript, or similar languages. Ability to dive into and navigate complex systems to better understand the nuances in how they work. Demonstrated ability to learn and work independently and make decisions with minimal direction. Strong written and verbal communication skills. Initially 3 days per week in-office Our benefits aim to promote health and wellbeing across all areas of Palantirians’ lives. We work to continuously improve our offerings and listen to our community as we design and update them. The list below details our available benefits and some of the perks that can be enjoyed as an employee of Palantir Technologies. Benefits Medical, dental, and vision insurance Life and disability coverage Paid leave for new parents and emergency back-up care for all parents Family planning support, including fertility, adoption, and surrogacy assistance Stipend to help with expenses that come with a new child Commuter benefits Relocation assistance Unlimited paid time off 2 weeks paid time off built into the end of each year Salary The estimated salary range for this position is estimated to be $135,000 - $200,000/year. Total compensation for this position may also include Restricted Stock units, sign-on bonus and other potential future incentives. Further note that total compensation for this position will be determined by each individual’s relevant qualifications, work experience, skills, and other factors. This estimate excludes the value of any potential sign-on bonus; the value of any benefits offered; and the potential future value of any long-term incentives. Life at Palantir We want every Palantirian to achieve their best outcomes, that’s why we celebrate individuals’ strengths, skills, and interests, from your first interview to your longterm growth, rather than rely on traditional career ladders. Paying attention to the needs of our community enables us to optimize our opportunities to grow and helps ensure many pathways to success at Palantir. Promoting health and well-being across all areas of Palantirians’ lives is just one of the ways we’re investing in our community. Learn more at Life at Palantir and note that our offerings may vary by region. In keeping consistent with Palantir’s values and culture, we believe employees are “better together” and in-person work affords the opportunity for more creative outcomes. Therefore, we encourage employees to work from our offices to foster connectivity and innovation. Many teams do offer hybrid options (WFH a day or two a week), allowing our employees to strike the right trade-off for their personal productivity. Based on business need, there are a few roles that allow for “Remote” work on an exceptional basis. If you are applying for one of these roles, you must work from the state in which you are employed. If the posting is specified as Onsite, you are required to work from an office. Palantir is committed to promoting a culture of diversity, equity, and inclusion and is proud to be an Equal Employment Opportunity and Affirmative Action employer. We believe that all Palantirians share the responsibility of upholding our commitment to these values and encourage candidates from a wide range of backgrounds, perspectives, and lived experiences to join us in solving the world’s hardest problems. Palantir does not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Palantir is committed to working with and providing reasonable accommodations to qualified individuals with physical and mental disabilities. Please see the United States Department of Labor’s EEO poster , EEO poster supplement and Pay Transparency Notice for additional information. Palantir is committed to making the job application process accessible to everyone. If you are living with a disability (visible or not visible) and need to request a reasonable accommodation for any part of the application or hiring process, please reach out and let us know how we can help.",
        "url": "https://www.linkedin.com/jobs/view/3774034549"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3934165126,
        "company": "Notion",
        "title": "Software Engineer, Product Infrastructure",
        "created_on": 1720636821.5022259,
        "description": "About Us We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft. We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide. Notion is an in person company, and currently requires its employees to come to the office for two Anchor Days (Mondays & Thursdays) and requests that employees spend the majority of their week in the office (including a third day). About The Role The Product Infrastructure team’s mission is to deliver a fast , reliable , flexible and secure experience for Notion users. We achieve this by building technical foundations that will reduce complexity across multiple product surfaces, fostering innovation in previously challenging domains. What You'll Do Shape and Build: Spearhead the creation of new product abstractions and data models to enhance user experience and facilitate scalable growth. Solve Challenging Technical Problems: Involving complex systems design spanning multiple products and systems. For example, designing and migrating to a new permission model or enabling offline mode for Notion. Full-Stack Expertise: Engage with all layers of the stack, spanning server and client environments, utilizing technologies like AWS, Postgres, NodeJS, WebSockets, React etc. What We're Looking For Keen Problem Observer: Have a clear and accurate understanding of context and possess a sharp eye for identifying potential problems and risks both short term and long term. Thoughtful Problem-solving: You seek to understand complex problems deeply in order to develop multiple solutions, from which you can articulate tradeoffs between user impact, timeline, scope, craft, and tech debt. Impact Driven: You care about user impact and prioritize projects accordingly. You're not motivated to use new technologies on their own, but through careful analysis of their applicability to the problem at hand, taking into account long term implications of technical decisions. Clear and Empathetic Communication: You communicate nuanced ideas clearly, whether you're explaining technical decisions in writing or brainstorming in real time. In disagreements, you engage thoughtfully with other perspectives and work together to find agreeable outcomes. Collaborative Team Member: You enjoy collaborating cross-functionally beyond team boundaries to accomplish shared goals. You care about learning, growing, and helping others to do the same. Bonus Points You have worked on improving functionality of typed languages (e.g. TypeScript, Flow), have have deep familiarity with query languages (e.g. GraphQL) or have implemented your own data modeling paradigms (e.g. writing or extending a custom ORM) You've heard of computing pioneers like Ada Lovelace, Douglas Engelbart, Alan Kay, and others—and understand why we're big fans of their work. We hire talented and passionate people from a variety of backgrounds because we want our global employee base to represent the wide diversity of our customers. If you’re excited about a role but your past experience doesn’t align perfectly with every bullet point listed in the job description, we still encourage you to apply. If you’re a builder at heart, share our company values, and enthusiastic about making software toolmaking ubiquitous, we want to hear from you. Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know. Notion is committed to providing highly competitive cash compensation, equity, and benefits. The compensation offered for this role will be based on multiple factors such as location, the role’s scope and complexity, and the candidate’s experience and expertise, and may vary from the range provided below. For roles based in San Francisco or New York, the estimated base salary range for this role is $130,000 - $250,000 per year.",
        "url": "https://www.linkedin.com/jobs/view/3934165126"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961095352,
        "company": "MRINetwork",
        "title": "Platform Engineer - Data - Hedge Fund - NYC (PW)",
        "created_on": 1720636823.1710374,
        "description": "Prior US Work Authorization Required - Thank You. Please, no 3rd party applications - direct submissions only - no C2C - thank you. This role is not a SQL, data warehouse, data pipeline position. The firm is embarked on a state-of-the-art engineering effort to enable access the vast amounts of data present across the firm's systems. The Data Platform team aims to build the next generation data enablement platform. We want to understand every aspect of every data set and their relationships. We will build the world's most comprehensive data platform that will enable our users to leverage the data in the most sophisticated ways. We Are Looking For Self-starters Who Are Curious And Enjoy Working With Data And Coming Up With Innovative Solutions. You Will Be Exposed To Data science Machine Learning Scalability People you will work with the best and the brightest Key Requirements 3+ years of software experience 3+ years data engineering experience Bachelor's degree in Computer Science or similar field Object-oriented and coding skills (Java and/or C/C++) Experience with distributed (multi-tiered) systems Experience building highly scalable web applications Preferred Advanced degree in Computer Science, Computer engineering or related discipline Ability to handle multiple competing priorities in a fast-paced environment Excellence in communication",
        "url": "https://www.linkedin.com/jobs/view/3961095352"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3931944939,
        "company": "Blackstone",
        "title": "Lead Data Engineer, SVP - Cloud & Platforms Engineering",
        "created_on": 1720636824.805971,
        "description": "Blackstone is the world’s largest alternative asset manager. We seek to create positive economic impact and long-term value for our investors, the companies we invest in, and the communities in which we work. We do this by using extraordinary people and flexible capital to help companies solve problems. Our $1 trillion in assets under management include investment vehicles focused on private equity, real estate, public debt and equity, infrastructure, life sciences, growth equity, opportunistic, non-investment grade credit, real assets and secondary funds, all on a global basis. Further information is available at www.blackstone.com. Follow @blackstone on LinkedIn, Twitter, and Instagram. Blackstone Technology & Innovations: Blackstone Technology & Innovations (BXTI) is the technology team at the core of each of Blackstone’s businesses and new growth initiatives. Serving both internal and external clients, we work to build the next generation of systems that manage risk, create efficiency, and improve transparency within the firm and across our broad community of investors and portfolio companies. BXTI is nimble and entrepreneurial – our open, iterative design processes and rapid pace of development mean that everyone on the team has the opportunity to make an impact from day one. We are problem solvers who can take projects from idea to implementation. We believe in active mentoring and developing excellence. We collaborate to find the best answers for our customers and for Blackstone. We are critical to the firm maintaining its competitive edge. Lead Data Engineer: We are seeking individuals with a deep understanding of data onboarding and quality best practices, as well as a strong commitment to fostering team growth, optimizing operations, implementing effective tools and driving automation. This position primarily involves hands-on development and delivery, stakeholder management, data process and architecture design, and coaching and knowledge sharing. Job Responsibilities: Collaborate with business stakeholders and technology teams to facilitate data consumption and automation Orchestrate, monitor and optimize ETL processes Proactively enhance data infrastructure and processes with best practices and latest technologies Define standard procedures and requirements for data warehousing at Blackstone Lead and mentor data engineers Requirements: 10+ years of data engineering experience utilizing modern SDLC processes to deliver quality technological solutions in a transparent, reliable way Experience in building and designing solutions for data warehouses A proven track record of working with complex data environments and associated technology and analytics infrastructure needed to support these environments Expert knowledge in Snowflake Strong Python skills Effective capabilities with git Ability to establish / mature Data Engineering ‘best practices’ Highly effective technical communication and interpersonal skills Strong problem-solving skills, fast learner Experience in the following would be an advantage: Vector Stores such as Pinecone DevOps/CI/CD tooling (Gitlab, Jenkins, Artifactory, Terraform) AWS Services Traditional database platforms such as SQL Server and MySQL Financial data, such as market data and trade/positions data The duties and responsibilities described here are not exhaustive and additional assignments, duties, or responsibilities may be required of this position. Assignments, duties, and responsibilities may be changed at any time, with or without notice, by Blackstone in its sole discretion. Expected annual base salary range: $225,000 - $275,000 Actual base salary within that range will be determined by several components including but not limited to the individual's experience, skills, qualifications and job location. For roles located outside of the US, please disregard the posted salary bands as these roles will follow a separate compensation process based on local market comparables. Additional compensation: Base salary does not include other forms of compensation or benefits offered in connection with the advertised role. Blackstone is committed to providing equal employment opportunities to all employees and applicants for employment without regard to race, color, creed, religion, sex, pregnancy, national origin, ancestry, citizenship status, age, marital or partnership status, sexual orientation, gender identity or expression, disability, genetic predisposition, veteran or military status, status as a victim of domestic violence, a sex offense or stalking, or any other class or status in accordance with applicable federal, state and local laws. This policy applies to all terms and conditions of employment, including but not limited to hiring, placement, promotion, termination, transfer, leave of absence, compensation, and training. All Blackstone employees, including but not limited to recruiting personnel and hiring managers, are required to abide by this policy. If you need a reasonable accommodation to complete your application, please email Human Resources at HR-Recruiting-Americas@Blackstone.com. Depending on the position, you may be required to obtain certain securities licenses if you are in a client facing role and/or if you are engaged in the following: Attending client meetings where you are discussing Blackstone products and/or and client questions; Marketing Blackstone funds to new or existing clients; Supervising or training securities licensed employees; Structuring or creating Blackstone funds/products; and Advising on marketing plans prepared by a sales team or developing and/or contributing information for marketing materials. Note: The above list is not the exhaustive list of activities requiring securities licenses and there may be roles that require review on a case-by-case basis. Please speak with your Blackstone Recruiting contact with any questions. To submit your application please complete the form below. Fields marked with a red asterisk * must be completed to be considered for employment (although some can be answered \"prefer not to say\"). Failure to provide this information may compromise the follow-up of your application. When you have finished click Submit at the bottom of this form.",
        "url": "https://www.linkedin.com/jobs/view/3931944939"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3967138946,
        "company": "KANERAI",
        "title": "Senior Software Engineer",
        "created_on": 1720636828.9358995,
        "description": "About The Job KANERAI is currently interviewing candidates to join our Research & Development Team. You’ll be responsible for small and large projects, some tactical, others strategic, that directly impact our business. You will have the opportunity to contribute value across our entire stack: cloud computing, distributed computing, data management, advanced financial analytics, sophisticated data visualization, and web applications. You will also have the opportunity to receive training on our stack as well as financial analytics, work with talented team members, and provide input on our research and product development roadmaps. This role is 100% remote, and we are seeking candidates located in North and South America . We also have on-site and hybrid opportunities available in our New York City office. The workday follows the Eastern Time Zone. About You You love software. Whether you just graduated, or have years of experience, whether you are a developer by training or just happen to use programming in another field, you have always been more curious about how software works than your peers. Legacy and modern programming languages, operating systems, distributed systems, open-source frameworks, UI technology, how concepts and implementations compare and contrast. And you have been satisfying this curiosity, accumulating over time exceptional technical breadth and depth. You don’t want to stop. You want to be part of a team of like-minded learners and doers to build something big and interesting that is changing the way that Wall Street uses technology to invest in complex financial instruments. About Us KANERAI was formed by a unique team of entrepreneurial and talented Wall Street traders, quants, technologists, and scientists who shared a passion for technology and the vision to empower investors with unprecedented insight into complex financial instruments. Today, the largest and most sophisticated investors use KANERAI’s suite of trading and investment platforms. KANERAI prides itself on being a lean and efficient company of passionate, hands-on, and hardworking individuals who strive as a cohesive team to do much more with less.",
        "url": "https://www.linkedin.com/jobs/view/3967138946"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3920740624,
        "company": "Avani Tech Solutions Private Limited",
        "title": "Sr BI Engineer",
        "created_on": 1720636832.9185781,
        "description": "Job Title: Sr BI Engineer Location: okay with remote- would love to have someone in the NY area to work hybrid if possible (1-2 days a week) Duration: 12+ months PR: $87.50/hr on W2 Description Hours: Typical 8 hour day Top 3 Skills High proficiency in SQL(required), Proficiency in designing, developing, and managing SQL-based ETL pipelines using tools such as Airflow, dbt, or Databricks, 4+ years of business intelligence development experience including designing data models and developing BI dashboards, Proficiency in Tableau, Experience with cloud-based data warehouses (ex. Snowflake, Google BigQuery, Amazon Redshift). etting up ETL- Taking codes you write and turning it into a program. Experience with git and git providers such as Github, Bitbucket, Gitlab(this is a requirement). Other Skills/Nice to Haves: Experience working with large and complex data sets generated by websites and mobile/tv applications, Experience with Python/Java, Experience with Google BigQuery. Experience with Adobe Analytics, Google Analytics or similar digital analytics tool. Reporting to the Director of BI Engineering, the Sr. Business Intelligence Engineer will design, develop, and support business intelligence solutions that turn data into actionable insights which support business decision making, analytics, and product development. An ideal candidate should be extremely data-savvy, and should have solid skills in data modeling, data visualization, and overall business intelligence solutions. Responsibilities Develop, maintain, and optimize business intelligence solutions, including data models, dashboards, and reports. Collaborate with cross-functional teams to gather requirements and ensure data solutions meet business needs. Ensure data quality and integrity by implementing data validation and monitoring processes. Create and manage complex SQL queries including those used in ETL scripts. Establish and maintain best practices for the design, development and support of BI solutions. Provide technical expertise and guidance to team members and stakeholders. Respond and resolve operational problems as necessary. Document, troubleshoot, and resolve day to day data issues. Process, clean, and validate the integrity of data to be used for analysis. Perform Tableau support work including training and provisioning access. Analyze large amounts of information to find patterns and solutions. Proactively and continuously pursue professional development and training Required Qualifications 4+ years of business intelligence development experience including designing data models and developing BI dashboards. High proficiency in SQL. Proficiency in designing, developing, and managing SQL-based ETL pipelines using tools such as Airflow, dbt, or Databricks. Proficiency in Tableau Experience with cloud-based data warehouses (ex. Snowflake, Google BigQuery, Amazon Redshift). Experience collecting business requirements and building reporting solutions to convert large amounts of data into usable information for analysts and business users. Familiarity with relational and dimensional database concepts and principles, data modeling, data warehouse design, and data management. Strong written and documentation skills for communicating specifications, processes, and metadata to both technical and non-technical audiences. Strong organizational, prioritization, and planning skills with an ability to work on multiple projects simultaneously and collaboratively with cross-functional units. Strong analytical and problem-solving skills with high attention to detail. Preferred Qualifications Bachelor’s or master’s degree in business, economics, computer science, information systems, statistics, or similar quantitative field. Experience working with large and complex data sets generated by websites and mobile/tv applications. Experience with Python. Experience with Google BigQuery. Experience with Adobe Analytics, Google Analytics or similar digital analytics tool. Experience with git and git providers such as Github, Bitbucket, Gitlab.",
        "url": "https://www.linkedin.com/jobs/view/3920740624"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3921223893,
        "company": "Bilt Rewards",
        "title": "Senior Analytics Engineer",
        "created_on": 1720636834.6992874,
        "description": "Reporting to: Senior Director, Data Analytics Location: New York, NY What is Bilt? With Bilt, paying rent now unlocks rewards & benefits at home, in your neighborhood, and when you travel–no matter where you live. Bilt Members can earn points and access exclusive benefits at any home on rent payments, condo & co-op fees, and around their neighborhood at local restaurants, fitness studios, rideshare, and more. Ranked the highest-value point currency by top publications, Bilt Points can be transferred 1:1 to major airline and hotel programs, or used towards rent payments, shopping, fitness, and even a down payment on a home. Members also get access to credit-building benefits, member-only experiences, and an Elite Status program. In partnership with the top multifamily owners & operators across the country, we’ve also created the Bilt Rewards Alliance, a network of 4M+ apartments and homes across the country. Residents who live in the Bilt Rewards Alliance make payments directly through the Bilt Payment Center and get access to benefits including additional earn opportunities on new leases, renewals, and more. While Bilt Members can use any debit or credit card to earn points and access their benefits, Bilt has partnered with Mastercard and Wells Fargo to create the Bilt Mastercard® - the first and only credit card that lets you pay rent and earn points without the transaction fee. What’s the role? We are looking for an experienced data professional to join a renowned team that is transforming the future of renting, home ownership, and rewards. You will play a key role driving business growth by building the data foundation to unlock strategic & analytical insights, with an emphasis on structuring, modeling, testing and mapping our data in dbt. The ideal candidate has a proven track record developing data-driven analytics solutions and key stakeholder relationships. You will work directly with Bilt’s leadership as a key influencer driving growth and strategy at Bilt. In this role, you will… Be instrumental in growing Bilt’s analytics engineering function as the first hire dedicated exclusively to analytics engineering to support the business’ goals Define and analyze metrics that quantify the performance of Bilt’s product suite in the markets that we serve Partner with the Analytics team to model data into usable and scalable formats to drive speed-to-insights and self-service analytics, for internal and external stakeholders Own end-to-end development of models/tests/alerts/semantic models/metrics to be consumed by internal and external stakeholders Identify and execute on opportunities for employing advanced analytics and building complex models to answer business problems such as sessionization of events data, marketing attribution, granular profit modeling, LTV and Churn Build strong relationships with stakeholders across the business and influence product and strategic roadmap Accelerate our dbt instance from 1 to 100 In Terms Of Qualifications, We’re Seeking About you: A data professional with a yearning to solve big-picture problems, learn new things, seek answers in data and finds comfort in uncertainty A natural communicator, who can think in terms of solutions instead of tools, and can explain sophisticated systems to technical and non-technical audiences with equal clarity Engineering-minded with a strong bias towards action, delivering results quickly with iteration instead of waiting for perfection Strong prioritization and organizational skills the ability to juggle many tasks at once in a fast-paced, entrepreneurial environment Experience implementing advanced alerting and monitoring and building resilient systems and processes A heart-first contributor who is able to deliver complex projects with multiple stakeholders Experience: 4-8 years of data analytics, analytics engineering, or BI analytics experience A SQL wizard, who feels at home in a modern data warehouse (e.g. BigQuery, Snowflake) and experienced with Python, other programming languages such as Java a plus Experience with dbt, comfortable owning / building out dbt projects, leveraging Jinja, YAML to enable analytics at scale, experience with dbt semantic layer or similar backend semantic modeling Experience orchestrating large datasets and DAG dependencies; familiar with tools such as dbt Cloud, Airflow, Cloud Composer or similar tools Experience applying best practices and frameworks such as DRY, incremental models, testing and alerting, and generating documentation Partnering with Data Engineering to ingest and model new data sources, and manage database migrations Experience with a variety of BI Tools (e.g. Looker, Mode, ThoughtSpot, Sigma etc.) and integrating dbt or equivalent semantic layer with these tools Benefits Compensation - We offer a competitive salary with a meaningful stake in the company via equity and our performance bonus program Health insurance for you (& your loved ones) from day one - Enjoy a One Medical Membership, wellness stipends, family programs and more, on us. We’ve got you and your family covered from day one. 401k plan with a match - Retirement may feel more like a pipe dream than a reality but we’re here to help you get there. Commuter FSAs - We believe the best ideas come from being together in one place. We just don’t think getting there should be so expensive. UNLIMITED PTO - Because we believe that working hard shouldn’t mean always working. Take time for you as often as you need it. Exclusive Employee only Bilt Points - We give our employees unique opportunities to earn points throughout their time at Bilt. Team Events - We believe in human connection so we hold events to help our employees break from the monotony of the typical work week. At Bilt Rewards, we believe in transparency and we do our best to make sure the company and our candidates are on the same page as it relates to compensation. In addition to posting salary ranges for our open roles, candidates should expect to be asked about compensation expectations and requirements early on in their interview process. Our goal is to highlight when expectations and Bilt’s salary range may be out of sync, and work with the candidate to determine whether it makes sense to continue conversations. We are considering candidates with differing levels of expertise for this position. Leveling will be based upon your experience and performance in the interview process. Where a new hire falls within a range will be based on their individual skills and experience, and how these competencies compare across other employees in the same role. Bilt's bands are designed to allow for individual compensation growth within the role. As such, new hires typically start at the lower end of the range. Bilt rewards performance and outcomes - should you join the company, you will have the opportunity to grow your salary over time. The salary range for a Senior Analytics Engineer is $150,000 - 200,000 and will be eligible for equity and an annual performance-based bonus.",
        "url": "https://www.linkedin.com/jobs/view/3921223893"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3933965732,
        "company": "Cockroach Labs",
        "title": "Software Engineer, Frontend (Console) - New York, NY",
        "created_on": 1720636836.2565515,
        "description": "Databases are the beating heart of every business in the world. Cockroach Labs is the creator of CockroachDB, the planet's most highly evolved cloud-native, distributed SQL database that scales fast, survives anything, and thrives anywhere. Join us on our mission to unshackle teams from the constraints of their database and enable every developer to build world-changing applications! About The Role CockroachDB Cloud provides CockroachDB to anyone who needs to scale fast, survive anything, and thrive everywhere. We are looking for an experienced frontend software engineer who is excited to focus on the user experience components of our Cloud Console application. The Console is our control plane application for CockroachDB Cloud and it allows users to manage clusters across their organization. Our team has broad ownership and some domain area examples include the signup/login/onboarding flows, creating/organizing/managing clusters, notifications and billing, and managing roles and permissions of a user or service account. This ownership also includes the external facing surfaces in which a user can interact with the control plane including the Console UI, Terraform, API, and other CLI tools. The Console team’s mission is to bring the power of CockroachDB to every developer, through a trusted managed-service offering that enables them to easily setup, manage, and operate their clusters for their world-changing applications. Working closely with our SRE team, Backend and other Frontend Engineers, and Database Engineers you will be part of a collaborative culture striving to make data easy at global scale by integrating distributed databases and the cloud with a world-class developer experience. You Will Design, build, test, and improve CockroachDB Cloud. You bring your expertise and commitment to excellence to build the best cloud database service for our users, partners, and customers. Develop in React/Typescript and Go, but if you don't know it, you'll learn while you're here. Collaborate with engineers, product managers, and designers across our cloud and database teams to design, implement, and deliver features that remove the headaches of database operations for our users. Make sure that as our DBaaS rapidly grows it remains scalable, survivable, and consistent. Take part in a collaborative culture and exchange knowledge with a highly experienced technical organization. The Expectations In the first month, you will join your engineering team and start to learn about our production systems, software development workflow, and the architecture of CockroachDB and our cloud offerings. We believe that it's essential for you to take this time to become familiar with our technology, company, and our culture. After three months, you'll be a fully-fledged member of the Cloud Console team and feel comfortable contributing to our platforms. You will begin determining the parts of our product that most interest you and work with your manager to focus your efforts on projects that align with your interests and our goals. We want our users to have a phenomenal experience using our product. You play a crucial role in making CockroachDB Cloud a joy to use, and as our team grows, you will have the opportunity to shape the direction of development for CockroachDB Cloud and CockroachDB. We also offer technical training and experienced mentorship to help you learn and advance your career into whatever you wish it to be. You Have A passion for building beautiful, intuitive, and responsive user experiences that help people succeed at their jobs. Experience architecting and implementing UI/UX for robust, scalable web applications using technologies like Javascript, Typescript, and React. Experience delivering value within a rapid, iterative, and data-driven release cycle. Experience building collaborative relationships with your colleagues. You enjoy being part of the code review process and partnering with your teammates on challenging problems. A passion and interest in creating great end-to-end experiences for developers. 8+ years of relevant experience. We are scaling fast and every contributor counts, from earlier career engineers who want to learn and grow alongside the company to seasoned experts who can lead and mentor. A BS in Computer Science or equivalent experience. The Team Reporting to Jordan Lewis - Senior Director, Engineering Jordan is the Head of Engineering for CockroachDB Cloud. He’s responsible for the teams that build, maintain and keep CockroachDB Cloud reliably serving the needs of Cockroach Labs’ most demanding customer base. He joined Cockroach Labs as a database engineer in 2016 when it was just 25 people before moving into engineering leadership and most recently moving to lead the Cloud organization. Jordan lives in his hometown of Brooklyn NY with his wife. Outside of work he enjoys folk music and riding his electric scooter around town. Isaac Wong - EVP of Engineering Isaac is responsible for the health of the engineering organization at Cockroach Labs. He partners closely with teams to ensure we have a balanced culture that promotes quality and innovation in pursuit of our goals. Before joining Cockroach Labs Isaac was in life sciences for 16 years with Medidata Solutions where he had a front row seat on the exciting ride from a 30 person startup to more than 2000 people worldwide. But the lure of distributed, resilient, and consistent SQL databases, along with the amazing technology and culture at Cockroach Labs proved too much. When not working he likes to draw, play the piano, and search NYC for cannoli's with his wife and kids. Our Benefits Competitive Health Insurance Coverage (for you & your dependents!) Paid Parental Leave (with baby bucks) Flexible PTO Learning & Development Budget Relocation Support (as applicable) Cockroach Labs is proud to be an Equal Opportunity Employer building a diverse and inclusive workforce. If you need additional accommodations to feel comfortable during your interview process, please email us at accessibility@cockroachlabs.com. The annual anticipated base salary range for U.S. candidates for this role is USD $174,000 to $230,000, plus commission if a sales role. We set standard ranges for all U.S.-based roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location. Actual salaries may vary and fall outside of this range depending on factors such as a candidate’s qualifications, geographic location, skills, experience, and competencies. In addition, we are often open to a wide variety of profiles, and recognize that the person we hire may be less experienced (or more senior) than this job description as posted. Salary is one component of the Cockroach Labs’ total rewards package, which includes stock options, health insurance, life and disability insurance, funds towards professional development resources, flexible PTO, paid holidays, and parental leave, to name a few! Salaries for candidates outside the U.S. will vary based on local compensation structures.",
        "url": "https://www.linkedin.com/jobs/view/3933965732"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3971517134,
        "company": "Alpha Search Advisors",
        "title": "Software Engineer",
        "created_on": 1720636838.0115724,
        "description": "Our Software Engineers are responsible for building the systems that power every aspect of their investment process, from research and analysis to trading, risk management, funding and settlement. Working side by side with investors and quantitative researchers, they use their technical skills to drive critical commercial outcomes. If you’re interested in financial markets and excited by the prospect of having real impact in a fast-paced environment where everyone is inspired to be their best, they are excited to meet you. Our client’s most successful engineers are critical thinkers who know how to dissect the problem as proficiently as they know how to build the solution. While we look for technical acumen, commercial acumen is just as important. That includes the ability to flex, change course, and iterate without always having pre-defined specs. YOUR OPPORTUNITY: From engineers who create next-gen platforms to desk-aligned developers who partner with investment teams to increase efficiency and maximize returns, engineering opportunities are as varied as they are challenging. YOUR SKILLS & TALENTS: • 3+ years of professional software engineering experience • Solid computer science fundamentals • Expert level programing skills in at least one of the following: Java, C++, Python • Proven track record in software design and development • Excellent analysis / problem solving skills • Strong communication and teamwork skills • Ability to manage multiple tasks in a demanding and dynamic environment • Minimum of a Bachelor’s degree in Computer Science or a related STEM discipline",
        "url": "https://www.linkedin.com/jobs/view/3971517134"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3964535555,
        "company": "RIIM",
        "title": "System Engineer",
        "created_on": 1720636839.6762655,
        "description": "Qualifications: Bachelors degree or equivalent knowledge and experience Expert knowledge of Linux servers, specifically RHEL Demonstrable knowledge of TCP/IP Experience of high-level scripting language (Python, etc.) and software design and life cycle Practical knowledge and use of source control systems, Preferably GIT Experience with IT Automation Software (Puppet, Chef, SaltStack) Knowledge of basic network administration Operational testing, change control and implementation management experience Practical experience with monitoring and alerting workflows and technologies General understanding of capacity and performance management Possess the ability to adapt and adjust to rapidly changing land-scape and priorities Strong ability to work independently and prioritize tasks with little or no direction Passionate lifelong learner and innovator that understands that current technologies and problems will continue to change Familiarity with open-source software development culture, community and workflows",
        "url": "https://www.linkedin.com/jobs/view/3964535555"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3783149533,
        "company": "ActionIQ",
        "title": "Senior Backend/FullStack Software Engineer",
        "created_on": 1720636841.2802505,
        "description": "What You'll Be a Part Of: ActionIQ is a new kind of customer data platform that lets marketing teams tap directly into central data sources and activate it anywhere in the customer journey. Unlike traditional CDPs, ActionIQ keeps data securely where it lives and makes it easy for marketers to design personalized interactions that unlock revenue across the entire customer lifecycle. We are backed by top-tier VCs Andreessen Horowitz, Sequoia Capital, and March Capital. We partner with enterprise brands such as Albertsons, e.l.f., Dell, The Washington Post and man The Team You'll Join: We develop the Scala code base used by our low-latency, high-throughput, reliable backend APIs and ETL processes to support a growing feature set. You'll work in all areas of the software development life cycle to launch new features and improve and refactor our backend systems. As a senior member of the team, you'll mentor early career engineers, make well-reasoned tech vs. product trade-offs, and work collaboratively across teams to deliver and support a quality product and platform which ingests, models, queries, and exports multiple terabytes of streaming and batch data every day. How You'll Contribute: Deliver high-quality, maintainable code. Operationally ensure services meet uptime and availability SLAs. Work with others to break down projects into smaller units of work with intermediate milestones. Collaborate with product managers, engineers, and architects to design and implement features and improvements throughout multiple areas of the platform, including UI. Mentor early career engineers. Design and build distributed services that are fault-tolerant, scalable, testable, maintainable, and work with large amounts of data on the cloud. Drive the team to build APIs efficiently. Use the cloud to manage data and systems. Optimize systems for improved performance and scalability. Work with technologies such as Kafka, Spark, and other tools relevant to our data platform. Play a key role in the end-to-end lifecycle of projects, from design and development to testing, implementation, and post-implementation support. What You Bring: 5+ years of experience as a backend software engineer. Experience working in a backend language, such as Java, Scala, Golang, etc. Experience leading the implementation of a large product feature or infrastructure changes. Experience with modern web-server frameworks, such as Express, Rails, Flask, Django, or Play. Experience with React, Angular, or other modern web UI frameworks. Experience with Spark, Kafka, and stream processing technologies. Experience with container orchestration systems, such as Kubernetes. Experience in analyzing, diagnosing, and problem-solving with large-scale distributed systems/data and cloud-based platforms. Experience working with both SQL and NoSQL databases Effective communication skills with technical and non-technical stakeholders. Experience working in an agile team environment. Excitement to work in a team environment with other engineers and product managers on service consumed by other engineering teams. This role requires being onsite in our NYC office 3x per week If you're interested in this exciting opportunity to contribute and play a key role in shaping the future of our Customer Data Platform, we'd love to hear from you! Our work is broad and complex in nature - please don't rule yourself out if you do not meet every requirement. Apply now and be a part of our dynamic team at ActionIQ. Compensation: Our compensation package includes base salary, stock options, and the great benefits shown below. The salary range for this role is: $185,000 - $210,000 Benefits & Perks Preview: Stay Happy and Healthy: Enjoy leading Medical, Dental and Vision benefits, 401k, FSA, Commuter Benefits, Gym Reimbursement, flexible PTO and 12-weeks paid parental leave Accelerate Your Career: Opportunities to explore, enhance, and expand your skill set through conferences, workshops, and access to Udemy learning courses. Enjoy the View: We have a beautiful office in NYC right on Madison Square Park, and local employees come into the office on a hybrid schedule, three days a week (M, W, Th) . Office perks include catered lunches, a stocked kitchen with beverages and snacks, and monthly social hours. Join a Community: Work with a fun, inclusive, and smart team of people as we build a New York City based enterprise software company. For additional information about all of our benefit offerings, check out our Careers page. Learn from your future colleagues: For the latest on our people and products visit: Product Blog Tech Blog Life At ActionIQ Your Interview Journey: Check out this guide for an overview of our interview process. ActionIQ is committed to building an inclusive, equitable, and diverse organization. We embrace equal opportunities for all applicants and want to foster a culture of belonging for our employees. We recognize and appreciate that the more inclusive we are, the better we will function as a team. AIQ welcomes applicants of any race, color, ancestry, religion, sex, national origin, gender identity, gender expression, age, marital or family status, disability, military veteran status, and any other status or background.",
        "url": "https://www.linkedin.com/jobs/view/3783149533"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3945098028,
        "company": "Diverse Lynx",
        "title": "AWS Data Engineer",
        "created_on": 1720636842.9045446,
        "description": "Job Title: AWS Data Engineer Location: New York, NY Hybrid Duration: Full Time Job Description Relevant Experience (in Yrs) 8-10 yrs Must Have Technical/Functional Skills Apache Spark, Scala/ Python and PySpark Experience Required Min. 5-7 years hands on experience working in data modeling Roles & Responsibilities \" Work on migrating applications from an on-premises location to the cloud service providers. \" Develop products and services on the latest technologies through contributions in development, enhancements, testing and implementation. \" Develop, modify, extend code for building cloud infrastructure, and automate using CI/CD pipeline. \" Partners with business and peers in the pursuit of solutions that achieve business goals through an agile software development methodology. \" Perform problem analysis, data analysis, reporting, and communication. \" Work with peers across the system to define and implement best practices and standards. \" Assess applications and help determine the appropriate application infrastructure patterns. \" Use best practices and knowledge of internal or external drivers to improve products or services. What We Are Looking For \" Hands-on experience in building/implementing cloud platforms/applications on AWS platform. \" Experience in developing data pipeline solutions to ingest and exploit new and existing data sources. \" Expertise in leveraging SQL, programming language like Python and ETL tools like Databricks \" Perform code reviews to ensure fit to requirements, optimal execution patterns and adherence to established standards. \" Expertise in AWS Compute (EC2, EMR), AWS Storage (S3, EBS), AWS Databases (RDS, DynamoDB), AWS Data Integration (Glue). \" Advanced understanding of Container Orchestration services including Docker and Kubernetes, and a variety of AWS tools and services. \" Good understanding of AWS Identify and Access management, AWS Networking and AWS Monitoring tools. \" Proficiency in CI/CD and deployment automation using GITLAB pipeline. \" Proficiency in Cloud infrastructure provisioning tools e.g., Terraform. \" Proficiency in one or more programming languages e.g., Python, Scala Regards Ved Prakash Singh Sr. Technical Recruiter Diverse Lynx LLC |300 Alexander Park|Suite #200|Princeton , NJ 08540 Office: +1732-452-1006 Ext - 241 Email: Vedprakash.singh@diverselynx.com LinkedIn URL: https://www.diverselynx.com Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.",
        "url": "https://www.linkedin.com/jobs/view/3945098028"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3867881631,
        "company": "Goldman Sachs",
        "title": "Senior Data Engineer- Asset & Wealth Management- New York- Vice President",
        "created_on": 1720636844.591481,
        "description": "Job Description At Goldman Sachs, our Engineers don’t just make things – we make things possible. We change the world by connecting people and capital with ideas and solve the most challenging and pressing engineering problems for our clients. Our engineering teams build scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Engineering, which is comprised of our Technology Division and global strategist groups, is at the critical center of our business. Our dynamic environment requires innovative strategic thinking. Want to push the limit of digital possibilities? Start here. What We Look For Goldman Sachs Asset Management (GSAM) is one of the world’s leading investment managers. GSAM provides institutional and individual investors with investment and advisory solutions, with strategies spanning asset classes, industries, and geographies. We help our clients navigate today’s dynamic markets, and identify the opportunities that shape their portfolios and long-term investment goals. We extend these global capabilities to the world’s leading pension plans, sovereign wealth funds, central banks, insurance companies, financial institutions, endowments, foundations, individuals and family offices. The Client Solutions Group is looking for a data engineer to assist in the buildout and scaling of the business globally using cloud based hybrid Big Data solutions to provide Sales and Marketing teams seamless experience in achieving their objectives through productivity tools, easy access to analytics and insights along with real time tracking towards their goals. Skills And Experience We Are Looking For 8+ years of relevant work experience in a team-focused environment Have relevant Big Data experience using a modern processing frameworks (Hadoop, Spark, Airflow, Flink) and programming languages (Java/Scala/Python) Experience in REST and/or GraphQL Experience in working with data-bases – NoSQL and/or Relational. In-depth knowledge of relational and columnar SQL databases, including database design BS. or higher in Computer Science (or equivalent work experience) Ability to stay commercially focused and to always push for quantifiable commercial impact Strong work ethic, a sense of ownership and urgency Strong analytical and problem solving skills Ability to collaborate effectively across global teams and communicate complex ideas in a simple manner Preferred Qualifications Asset management / front office / sales domain knowledge Experience with AWS Experience with Snowflake Salary Range The expected base salary for this New York, New York, United States-based position is $150000-$250000. In addition, you may be eligible for a discretionary bonus if you are an active employee as of fiscal year-end. Benefits Goldman Sachs is committed to providing our people with valuable and competitive benefits and wellness offerings, as it is a core part of providing a strong overall employee experience. A summary of these offerings, which are generally available to active, non-temporary, full-time and part-time US employees who work at least 20 hours per week, can be found here .",
        "url": "https://www.linkedin.com/jobs/view/3867881631"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3854670639,
        "company": "Figma",
        "title": "Software Engineer - FigJam",
        "created_on": 1720636848.6256263,
        "description": "Figma is growing our team of passionate people on a mission to make design accessible to all. Born on the Web, Figma helps entire product teams brainstorm, design and build better products — from start to finish. Whether it’s consolidating tools, simplifying workflows, or collaborating across teams and time zones, Figma makes the design process faster, more efficient, and fun while keeping everyone on the same page. From great products to long-lasting companies, we believe that nothing great is made alone—come make with us! FigJam is an online whiteboard for teams to ideate and brainstorm together. Purpose-built for every stage of your end-to-end workflows, FigJam makes everything from whiteboarding to design sprints easier and more fun — whether you’re working alone or collaborating with your extended team, no matter where in the world they’re based. This is Figma’s newest standalone product offering and is still in its earliest stages of opportunity; we’ll look to you to help own and shape product direction as we explore this greenfield space. You’ll use our unique technical stack to solve complex technical challenges and help launch some of FigJam’s most compelling forthcoming features. We use C++ (we call it fullscreen) for the main canvas working space in FigJam, which compiles to WebAssembly to run in the browser and enables our powerful performance and rendering capability - an industry setting standard for what is possible on the web. We use React and Typescript for our UI, where things like our toolbar and context menus live; it works in close concert with the WebAssembly layer, so we can offer a responsive, interactive, and delightful user experience. Livegraph is Figma’s own implementation of GraphQL , which helps us query data from our databases efficiently. We occasionally dabble in REST APIs and our infrastructure code as well! Figma is a highly collaborative organization and most projects are owned by small teams of 2-3 people. You’ll form strong relationships and collaborate with engineers outside of your immediate team, designers, leaders, PMs, data scientists, and user researchers to both scale our product efforts and invest in each other’s learning, growth, and success. We strive to foster an inclusive culture that promotes equity and belonging, and use our engineering values to guide how we work together: communicate early and often , lift your team , focus on craftsmanship , and prioritize impact . Learn more about our values and how we developed them here. This is a full-time role that can be held from one of our US hubs or remotely in the United States What you’ll do at Figma: Ship a feature to production, which might include things like a UX update to our delightful toolbar. Participate in design reviews, technical reviews, and give feedback during user testing sessions. Craft performance objectives with your manager that align with company priorities and career development opportunities. Begin contributing to feature workstreams organized around weekly roadmap goals and longer-term milestones in partnership with engineers and designers - we don’t operate in silos. We'd love to hear from you if you have: 4+ years of experience in programming languages (Typescript/Javascript, React, C++, Python, Java, Objective-C, Go, or Rust) 4+ years of professional experience shipping user-facing features or products Experience communicating and working across functions to proactively drive solutions While not required, it’s an added plus if you also have: Experience working on or leading development on a large web application. Experience writing C++ (or related languages such as Objective C or C) in a user-facing context (e.g. gaming, native applications). Experience working on collaboration tools Experience in and a desire to teach fellow engineers through pairing, code review, and in-the-moment feedback. At Figma, one of our values is Grow as you go. We believe in hiring smart, curious people who are excited to learn and develop their skills. If you’re excited about this role but your past experience doesn’t align perfectly with the points outlined in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles. Pay Transparency Disclosure If based in Figma’s San Francisco or New York hub offices, this role has the annual base salary range stated below. Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), market demands, and specific work location. The listed range is a guideline, and the range for this role may be modified. For roles that are available to be filled remotely, the pay range is localized according to employee work location by a factor of between 80% and 100% of range. Please discuss your specific work location with your recruiter for more information. Figma offers equity to employees, as well a competitive package of additional benefits, including health, dental & vision, retirement with company contribution, parental leave & reproductive or family planning support, mental health & wellness benefits, generous PTO, company recharge days, a learning & development stipend, a work from home stipend, and cell phone reimbursement. Figma also offers sales incentive pay for most sales roles. Figma’s compensation and benefits are subject to change and may be modified in the future. You may view our Pay Transparency Policy by clicking on the corresponding link. Annual Base Salary Range (SF/NY Hub): $149,000—$350,000 USD At Figma we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our product and our community to flourish. Figma is an equal opportunity workplace - we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity/expression, veteran status , or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. We will work to ensure individuals with disabilities are provided reasonable accommodation to apply for a role, participate in the interview process, perform essential job functions, and receive other benefits and privileges of employment. If you require accommodation, please reach out to accommodations-ext@figma.com. These modifications enable an individual with a disability to have an equal opportunity not only to get a job, but successfully perform their job tasks to the same extent as people without disabilities. Examples of accommodations include but are not limited to: Holding interviews in an accessible location Enabling closed captioning on video conferencing Ensuring all written communication be compatible with screen readers Changing the mode or format of interviews By applying for this job, the candidate acknowledges and agrees that any personal data contained in their application or supporting materials will be processed in accordance with the applicable candidate section of Figma's Privacy Policy.",
        "url": "https://www.linkedin.com/jobs/view/3854670639"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3860726833,
        "company": "Rain",
        "title": "Full-Stack Software Engineer",
        "created_on": 1720636852.0403008,
        "description": "Rain’s mission is to create the fastest and easiest pathways to spend crypto in the real world. We’re a small and mighty team of passionate builders and veteran founders. We are looking for a full-stack software engineer to join us to build at the cutting edge of the intersection of crypto and fintech. You will have the opportunity to deliver massive impact at a small and quickly growing company that is funded by some of the top investors in fintech and crypto; you would be joining at the earliest possible time. Many of our engineers are based in NYC but we are open to fully remote candidates. Our Ethos: We believe in an open structure and you will be able to grow into the roles that most align with their goals. Our team members at all levels have the freedom to explore ideas and impact the roadmap and vision of our company. What You'll Do Be a critical part of the technical and product roadmap. Build products across our stack (using React, Typescript, NextJS, Tailwind, NodeJS) Help drive the technical roadmap and architectural decisions as we grow Interact with smart contracts across on multiple chains What We're Looking For Experience with Javascript, React, Typescript, NextJS, Tailwind, NodeJS (a subset of these works too). A builder mentality, someone who experiments with side projects Nice to haves, but not mandatory Fintech experience (neobank or card issuing experience gets extra brownie points) Experience with dApps Skills Javascript React Typescript NextJS Tailwind NodeJS Our perks enable working at Rain to be a fulfilling, healthy and happy experience. Unlimited time off 🛼 Unlimited vacation can be daunting, so at Rain we require our teammates to take 10 days minimum for themselves. Flexible working ☕ We support a flexible workplace, if you feel comfortable at home please work from home. If you’d like to work with others in an office feel free to come in. We want everyone to be able to work in the environment in which they are their most confident and productive selves. Flexible Benefits 🧠 Easy-to-access benefits, for all employees based in the US, Rain pays a percentage of your benefits for the employee and for your dependents. We offer comprehensive health, dental and vision plans as well as a 100% company-subsidized life insurance plan. Equity plan 📦 On top of a competitive salary, we offer every Rain employee an equity option plan so we can all can benefit from our success. Rain Cards 🌧️ We want our teammates to be knowledgeable about our core products and services and to support this mission we issue a card for our team to utilize the card for testing. Health and Wellness 📚 High performance begins from within. Our members are welcome to use their company card for eligible health and wellness spending like gym memberships, fitness classes and other wellness items. Team summits ✨ Summits play an important role at Rain! Time spent together helps us get to know each other, strengthen our relationships, and build a common destiny. Stay tuned for upcoming destinations!",
        "url": "https://www.linkedin.com/jobs/view/3860726833"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963076736,
        "company": "First Street",
        "title": "Geospatial Data Engineer - Climate Change",
        "created_on": 1720636853.6231337,
        "description": "Who we are: First Street is the industry standard for physical climate risk data. We use transparent and peer-reviewed methodologies to calculate the past, present, and future climate risk for every property in the world. We started eight years ago by working with the world’s leading climate scientists to create groundbreaking, climate-adjusted, property specific models and haven’t stopped. Our mission: We exist to connect climate change to financial risk Our data: We create physics-based, deterministic models of flooding, wildfire and hurricanes, and advanced statistical models of extreme heat, air quality, drought, hail, severe convective storms, winter storms, and more. All of this data is used to create property-level financial risk metrics and macroeconomic variables to quantify the impacts of climate change. Our customers: We empower governments at the highest levels to make smart regulations, businesses to avoid bad investments, and everyday Americans to understand their personal risk from climate change. We are relied on every day by: Agencies ranging from the U.S. Department of Treasury to Fannie Mae The world's biggest banks such as Bank of America and Wells Fargo Institutional investors like Nuveen and Blackstone Millions of users on Redfin, Realtor.com, Homes.com, and more We believe: Our work needs to match the pace and scope of the climate problem. This is why we have invested tens of millions of dollars into our science, data, people, and products and have raised tens of millions more to move even faster. Come join us and use your talents to create solutions to address humanity's biggest problem. Team & Role Overview: We are looking for a Data Engineer with experience working with Geospatial Data to join our team. The successful candidate will be someone who deeply cares about the environment, loves information technology, and appreciates the importance of data for the success of the First Street mission. They will assist in the ingestion of climate risk and ancillary data from First Street modelers and data partners, develop data pipelines, query geospatial databases, calculate applicable statistics, implement Quality Assurance and Quality Control processes, utilize geographical imagery, and ensure that the Data Team’s databases and pipelines are coordinated and synchronized with the Software Engineering Team’s databases, APIs, and web services. This individual will be responsible for developing data operations across the Data Team, and through their expertise and leadership generally enabling all members of the Data Team to be successful in their roles. What you’ll do: Provide technical support in the processing, analysis, and interpretation of geospatial observations and modeling data. Process large volumes of flood and wildfire risk prediction data to improve risk assessment quality and accuracy. Plan, execute and direct UNIX-based workflows on local and cloud-based clusters, using GDAL, PostgreSQL, Python, and QGIS. Analyze raster and vector data at scale to improve model accuracy, identify quality control issues, and develop suggested remedies for identified issues. Perform statistical analysis to validate hazard model predictions and assess model uncertainties. Design and implement quality assurance checks on the climate risk data and derived statistics Assist in resolution of customer support issues through quality control checks and explanation of the models and risk statistics What you’ll need: Bachelor's Degree in Data or Climate Science, or a related Field 2+ year of professional experience Data operations: Experience with the design, maintenance, and use of geospatial databases, such as PostgreSQL GIS knowledge: Experience with working with spatial data and GIS software such as QGIS Programming: Proficiency with SQL queries to efficiently and reproducibly analyze complex datasets preferred. Additional languages like Python or R also required Strong understanding of probability and statistics as applied to spatial data Expertise using scripted languages to build data pipelines on both local and cloud-based systems Experience with big data analysis, parallel processing, and batch/spot workflows on cloud platforms including AWS, GCP, and/or Azure Proficiency with source control platforms such as Git A science-based approach with a high degree of concern for reliability, accuracy and reproducibility Experience in GIS and/or geospatial statistical analysis What will make you stand out: Previous experience in the physical sciences Masters Degree Preferred How we work: Passion: We are driven by our shared goal to fight climate change Impact: We only focus on things that move the needle Urgency: We move quickly because the world depends on it Positivity: We are optimistic and enthusiastic in all that we do What we offer: Competitive salary commensurate with experience Ownership interest in the company via Employee Stock Option Plan Hybrid Schedule with in-office work days on Monday, Wednesday and Thursday 15 vacation days along with 13 company holidays and 10 sick days Health benefits covered at 100% for employee or a significant contribution for family plans Vision and dental benefits with partial employee contribution 12 weeks of paid parental leave Access to One Medical, Teledoc, HealthAdvocate, Kindbody, and Talkspace Company 401k program Commuter benefits Life Insurance Tech startup environment Weekly team meals and an office stocked with coffee and snacks Working on the world’s biggest issue with other passionate professionals We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3963076736"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3948587849,
        "company": "Bloomberg",
        "title": "Senior Web Engineer - Bloomberg.com",
        "created_on": 1720636855.2207525,
        "description": "Bloomberg Media empowers global business leaders with breaking news, expert opinion and proprietary data distributed with global reach to millions of visitors every month. We are looking for a Senior Engineer who is excited about modern web development and passionate about UI/UX and design. You will join a team that is responsible for supporting Bloomberg.com’s paywall, user authentication flows, and other core aspects of our Subscriptions business. You will work with Product, Design, Marketing, and other Engineering teams to expand our ability to deliver and enhance the experience our site visitors want and expect from Bloomberg. What’s in it for you: As a Senior Engineer, you’ll build on modern open-source web technologies (NodeJS, ReactJS, NextJS etc.) and work closely with our infrastructure team leveraging public cloud infrastructure, CDN, kubernetes, & networking. You will be involved in planning and executing multiple A/B tests and experiments across our web properties, and we’ll depend on you to advise on the system design, architecture, and scalability of the applications and libraries that play a critical role in determining and delivering the subscriber experience to Bloomberg.com users. We'll trust you to: - Collaborate within an Agile, multi-disciplinary, fast-moving team - Take ownership of technical solutions, development, and delivery to production - Develop in all levels of a web application stack, from the client to server-side - Explore and evaluate the value of new and emerging web technologies You'll need to have: - A strong understanding of web fundamentals and accessibility, and an understanding of system design patterns - Expertise in modern web frontend technologies (e.g. NodeJS, ReactJS, HTML, CSS, Typescript) - Proficiency in HTML, TypeScript/JS, CSS, HTTP, API design (GraphQL/REST), cookies, caching, security, web accessibility standards - Fluency in test-driven development, code reviews, distributed source code management, and automated quality assurance Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or maternity/parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law. Bloomberg provides reasonable adjustment/accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable adjustment/accommodation to apply for a job or to perform your job. Examples of reasonable adjustment/accommodation include but are not limited to making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you would prefer to discuss this confidentially, please email AMER_recruit@bloomberg.net (Americas), EMEA_recruit@bloomberg.net (Europe, the Middle East and Africa), or APAC_recruit@bloomberg.net (Asia-Pacific), based on the region you are submitting an application for.",
        "url": "https://www.linkedin.com/jobs/view/3948587849"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3886144660,
        "company": "Cockroach Labs",
        "title": "Corporate Systems Engineer - New York, NY, Austin, TX, Toronto",
        "created_on": 1720636857.215641,
        "description": "Databases are the beating heart of every business in the world. Cockroach Labs is the team behind CockroachDB, an open source, distributed SQL database. In addition to the open source version of the DB, we offer CockroachCloud, a self-service, fully managed cloud offering of CockroachDB. We aim to build infrastructure that keeps pace with the world, so developers can focus on what matters most: building the best products. Join us on our mission to Make Data Easy. About The Role CockroachDB helps anyone who needs to scale fast, survive anything, and thrive everywhere. We are looking for a Corporate Systems Engineer who will manage key systems (Okta, Jamf, Google Workspace, InTune). This role will report to the Senior Corporate Engineering Manager and work closely with the Security, Office & People teams. This role will be the second member of the Corporate Systems Team. You Will Act as an Okta administrator, configuring integrations & building workflows. Interacting with and building custom API flows and integrations. Be responsible for maintaining/troubleshooting our Mac fleet using Jamf & MDM. This includes keeping our Macs up to SOC2 and other compliance standards. Expand our automations and zero-touch deployments. Assist with managing our Windows fleet via Microsoft InTune. Work closely with the Security team on maintaining endpoint health. Write and maintain documentation for both internal team use as well as for users. Work as an escalation point for the global Corporate Operations team. Assist with Mobile Device Management for personal mobile devices. Assist the Corporate Engineering team with broader projects such as New Office Expansions, Compliance Certifications, Automations, etc. You Have 3+ years of experience administering Okta Experience creating detailed Okta Workflows as well as experience with Connector Builder 3+ years of technical experience in a Level II & III support role supporting Jamf with both MacOS, and iOS Jamf Certification 300 or equivalent work experience (Munki, Fleetsmith, Kandji) Familiarity with Terraform or other IaC tools and concepts Experience developing and maintaining scripts (Bash, Python) An in-depth understanding of how to administer Apple’s Zero Touch Deployment system Comfortable with supporting/maintaining Windows & Android systems if needed Security centered mindset Experience supporting national & international employees An excitement for getting things done in a fast-paced environment Expectations In the first month, you will join your Corporate Systems Team and learn the processes in place for our various Corporate IT systems. We believe that it's essential for you to take this first month to become familiar with our technology, company, and our culture. By your second month, you will assist the team with Okta, building Okta Workflows, Google Workspace, Jamf, Azure, or any other areas where the team needs your help. You will work with the team lead and management to plan current and future work. As our team grows, you will have the opportunity to help shape the direction of our systems and endpoints. We want our employees to have a seamless productivity experience. Our best work should be invisible. We also offer technical training and experienced mentorship to help you learn and grow continuously. The Team In addition to your reporting director, you will work closely with senior management. Reporting to Richard Dachtera - Senior Manager, Corporate Engineering Richard is the founding member of the Corporate Engineering team at Cockroach Labs. Over the last two and a half years he’s owned every aspect of the organization. He helped bring the company to SOC2 compliance, supported the company during the COVID transition and opened three offices for the company. Before Cockroach Labs he spent five years at Dropbox as their founding Corporate Engineer hire in New York and then Seattle. Outside of work he’s an avid photographer, with rolls of film easily found in his coat pockets. Also Richard is the unofficial photographer for the company, volunteering his time to take headshots for all employees. Mike Geehan - Senior Director of Security Mike Geehan is responsible for the safety and security of CockroachDB Cloud and surrounding infrastructure. Mike joined Cockroach Labs from a DC based start-up, and prior to that spent time in larger tech companies in a wide range of roles. Mike is focused on team development. Enabling and growing his team is paramount to the success of the team, and hence the business as a whole. Mike is based in Houston, Texas, and outside of work is focused on his family, his bikes, and in getting a cycling related non-profit organization off the ground. Benefits Competitive Health Insurance Coverage (for you & your dependents!) Paid Parental Leave (with baby bucks) Flexible PTO Learning & Development Budget Relocation Support (as applicable) Cockroach Labs is proud to be an Equal Opportunity Employer building a diverse and inclusive workforce. If you need additional accommodations to feel comfortable during your interview process, please email us at accessibility@cockroachlabs.com. The annual anticipated base salary range for U.S. candidates for this role is USD $115,000 to $145,000, plus commission if a sales role. We set standard ranges for all U.S.-based roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location. Actual salaries may vary and fall outside of this range depending on factors such as a candidate’s qualifications, geographic location, skills, experience, and competencies. In addition, we are often open to a wide variety of profiles, and recognize that the person we hire may be less experienced (or more senior) than this job description as posted. Salary is one component of the Cockroach Labs’ total rewards package, which includes stock options, health insurance, life and disability insurance, funds towards professional development resources, flexible PTO, paid holidays, and parental leave, to name a few! Salaries for candidates outside the U.S. will vary based on local compensation structures.",
        "url": "https://www.linkedin.com/jobs/view/3886144660"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3778357875,
        "company": "Stable",
        "title": "Software Engineer, Full Stack",
        "created_on": 1720636858.8334303,
        "description": "👩‍💻👨‍💻 Role Over 3,000 businesses use Stable — they are supported by our small (but growing) engineering team. We have no product managers and one designer. We’re proud of this, and expect every software engineer to get to know our customers and stakeholders deeply because we believe that’s the best way to build tools to help them. Our business is scaling, and we’re tackling difficult problems because of it — from APIs, to internal tools, to customer facing web applications, the infrastructure you build here will empower our growing customer base, team, partners, and consumers. Stable is simplifying outdated and convoluted regulatory frameworks with software. As an engineer on our team, you’ll create elegant abstractions over archaic foundations so that consumers of this infrastructure can unlock solutions never before possible. Your Day-to-day Work Will Directly Influence How Customers And Partners Interact With Our Products. Here Are a Few Examples Of The Types Of Projects You’ll Work On Stable Dashboard –– A modern web application for customers to view and take action on their mail, find meaningful business information, and more. From founders to ops teams to HR, our users log in to Stable daily to handle critical business operations. Mail Operations –– Build the internal web applications and integrate with the hardware at the nexus of our physical and digital mail operations. These tools power workflows like physical mail ingestion, fulfillment of operational requests, warehouse inventorying, and more. Core Infrastructure –– Architect, implement, and scale the underlying infrastructure that powers our products and physical logistics. Stable API –– A public API that allows consumers to utilize the software abstractions we’ve put over our physical operations for use cases in industries like fintech, healthcare, and more. This role is ideal for engineers invigorated by solving difficult problems and by building software with a large impact. You’ll be one of the first engineers at an early-stage startup, and should be excited to apply your analytical, hacker-first, mindset towards problems of all types. ‍ 😀 Who You Are Driven by impact: You consistently see the possibility in what could be. The idea that you can make the future better than the present is exciting — and you want to be surrounded by others that share this ambition. Learn by doing: You are motivated by results — you collect the information you need to understand which problems are most important to solve first. When challenges arise, you believe the best way to solve them is by tackling them head on. Form deep relationships: You can easily put yourself in others’ shoes and enjoy understanding varying perspectives. You’ve found a result of this tendency are relationships you care about deeply. ‍ ✅ What You'll Do Obsess over the customer to build pragmatic and effective solutions to their problems Architect and implement core infrastructure as we scale with growing customer and product demand Improve engineering best practices for code deployment, review, and development Pull from previous engineering experiences to creatively solve real world logistics problems using software Lead product and feature implementation while balancing customer, team member, and stakeholder requirements with engineering team priorities Technologies we use: React, Typescript, Node, GraphQL, MySQL, and AWS (if you think a new technology can solve an engineering problem, we’re all ears) 🎁 What We Offer Competitive salary and generous equity 🚀 Unlimited paid time off 🏖 Medical, dental, and vision insurance 🏥 Home office set-up 🖥 Work from anywhere within continental US time zones (PT, MT, CT, or ET) 💻 Opportunities to shape the future of Stable and grow into leadership roles 💌",
        "url": "https://www.linkedin.com/jobs/view/3778357875"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3850644576,
        "company": "Clear Street",
        "title": "Senior Data Engineer - Trading Systems",
        "created_on": 1720636860.3917353,
        "description": "About Clear Street: Clear Street is modernizing the brokerage ecosystem. Founded in 2018, Clear Street is a diversified financial services firm replacing the legacy infrastructure used across capital markets. We started from scratch by building a completely cloud-native clearing and custody system designed for today’s complex, global market. Our platform is fully integrated with central clearing houses and exchanges to support billions in trading volume per day. We’ve agonized about our data model abstractions, created horizontal scalability, and crafted thoughtful APIs. All so we can provide a best-in-class experience for our clients. By combining highly-skilled product and engineering talent with seasoned finance professionals, we’re building the essentials to compete in today’s fast-paced markets. The Team: The Securities Finance Engineering team builds trading platforms for various Securities Finance businesses including Securities Lending, Repo, and Derivatives across multiple markets and geographies. We are a team of specialists with skills across various aspects of engineering, quantitative modeling, and product. Clear Street is building out its Securities Finance Trading Platform from the ground up. Members of the team have the unique opportunity in the industry to build large scale, sophisticated trading systems on a modern and scalable technology stack from scratch. Tech Stack: We employ a wide variety of technologies including Java/Spring Boot (for our service mesh), React (front-end), Python for ETL/Analytics and statistical modeling respectively. Clear Street Engineering provides a modern developer experience for engineers, including excellent CI/CD tooling and a managed k8s environment. You Will: Architect and build data pipelines and analytics platforms that support Securities Finance businesses Work closely with your stakeholders (Trading Desk, Product) to deliver products that solve real world business problems Put your experience to good use by mentoring teammates, defining engineering standards, and driving a system design approach to building new services. Own systems end-to-end, including support and ongoing improvements. Develop a deep understanding of the business domain. Skills We’re Looking For: You have at least seven (7) years of experience designing and architecting systems that deliver solutions to complex data problems. You have hands-on experience with ETL toolchains e.g. Argo, Apache Airflow You are a data modeling pro; you understand how to create unified definitions of types from different source data representations. You are an SQL guru. You are able to write concise, readable queries to accomplish a given task as efficiently as possible You have extensive experience with relational databases like Postgres, a deep understanding of distributed systems and their tradeoffs, and a working knowledge of streaming data. Bonus Points: Experience with big data tools e.g. Snowflake, Apache Spark, Flink, Athena etc Experience in the Securities Finance domain. Prior experience going from zero to one (building and rolling out a new product). Experience with AWS / cloud-native tooling. Understanding of Docker and container orchestration. The Senior Level Base Salary Range is $170,000 - $190,000. These ranges are representative of the starting base salaries for this role at Clear Street. Which range a candidate fits into and where a candidate falls in the range will be based on job related factors such as relevant experience, skills, and location. These ranges represent Base Salary only, which is just one element of Clear Street's total compensation. The ranges stated do not include other factors of total compensation such as bonuses or equity. At Clear Street, we offer competitive compensation packages, company equity, 401k matching, gender neutral parental leave, and full medical, dental and vision insurance. Our belief has always been that we are better as a business when we are all together in person. As such, beginning on January 2, 2023, we are requiring employees to be in the office 4 days per week. In-office benefits include lunch stipends, fully stocked kitchens, happy hours, a great location, and amazing views. Our top priority is our people. We’re continuously investing in a culture that promotes collaboration. We help each other through challenges and celebrate each other's successes. We believe that modern workplaces succeed by virtue of having high-performance workforces that are diverse — in ideas, in cultures, and in experiences. We put in the effort to make such a workplace a daily reality and are proud to be an equal opportunity employer.",
        "url": "https://www.linkedin.com/jobs/view/3850644576"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3798147245,
        "company": "Narmi",
        "title": "Software Engineer II - Platform",
        "created_on": 1720636862.0544884,
        "description": "About Narmi: Narmi is how community financial institutions unlock the very latest capabilities in digital banking and account opening – so they can move faster, tap new growth opportunities, and be where banking is going. Since our founding, Narmi has moved billions of dollars and opened hundreds of thousands of accounts for banks and credit unions across the US. As a result, our customers have seen meaningful increases in deposits, revenues, and happy customers. In fact, one of the first financial institutions to leverage Narmi was recognized by Bankrate and NerdWallet for providing the #1 digital experience for a bank or credit union in the US. About the Platform Engineering team: The Platform team is responsible for the overall integrity of Narmi's account and transaction data, as well as building and maintaining the code that connects Narmi's software to core banking systems. Engineers on the Platform team work to unify a wide variety of complex banking systems into simple, developer-friendly APIs that make basic banking operations reliable and performant. A Platform engineer may find themselves implementing real-time transaction alerts, improving the reliability of transfers over unreliable network links, or investigating the details of how payments are settled in practice against a financial institution's ledgers. Minimum Qualifications BS degree in Computer Science or equivalent work experience At least 3 years of professional software engineering experience Hard working, agile, and a top performer Excellent communication skills in verbal and written English Experience focused on backend development Located or willing to work in New York City United States citizen or authorized to work in the United States Preferred Qualifications 5 or more years of professional software engineering experience Advanced proficiency in some of the following: Python (especially Django or DRF), Terraform, Ansible, or Linux administration Experience at a startup or financial technology firm The expected annual base salary for this role is $120,000 - $135,000. Base salary is only part of your total compensation. In addition to base salary, you will receive an equity option grant, and are eligible for performance-based cash and equity bonuses. Compensation included in an offer will be commensurate with the candidate’s skills, experience and geographic location. Compensation ranges for candidates located outside of New York City may differ. You will also receive a full benefits package. We believe that high-performing teams include people from different backgrounds and experiences who can challenge each other's assumptions with fresh perspectives. To that end, we actively seek a diverse pool of applicants, including those from historically marginalized groups. Please note that all correspondence related to this role will come directly from Narmi (email addresses ending in @narmi.com or @narmitech.com), and not a third party. If you receive correspondence from an individual claiming to represent Narmi please let us know immediately at security@narmi.com",
        "url": "https://www.linkedin.com/jobs/view/3798147245"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962541701,
        "company": "Rearc",
        "title": "Lead Data Engineer",
        "created_on": 1720636863.6974459,
        "description": "At Rearc, we're committed to empowering engineers to build awesome products and experiences. Success as a business hinges on our people's ability to think freely, challenge the status quo, and speak up about alternative problem-solving approaches. If you're an engineer driven by the desire to solve problems and make a difference, you're in the right place! Our approach is simple — empower engineers with the best tools possible to make an impact within their industry. We're on the lookout for engineers who thrive on ownership and freedom, possessing not just technical prowess, but also exceptional leadership skills. Our ideal candidates are hands-on-keyboard leaders who don't just talk the talk but also walk the walk, designing and building solutions that push the boundaries of cloud computing. As a Lead Data Engineer at Rearc, you'll play a pivotal role in establishing and maintaining technical excellence within our data engineering team. Your deep expertise in data architecture, ETL processes, and data modelling will be instrumental in optimizing data workflows for efficiency, scalability, and reliability. You'll collaborate closely with cross-functional teams to design and implement robust data solutions that meet business objectives and adhere to best practices in data management. Building strong partnerships with both technical teams and stakeholders will be essential as you drive data-driven initiatives and ensure their successful implementation. What You Bring With 10+ years of experience in data engineering, data architecture, or related fields, you offer a wealth of expertise in managing and optimizing data pipelines and architectures. You have a proven track record of leading complex data engineering projects, including designing and implementing scalable data solutions. Your hands-on experience with ETL processes, data warehousing, and data modelling tools allows you to deliver efficient and robust data pipelines. You possess in-depth knowledge of data integration tools and best practices, enabling seamless data flow across systems. Your strong understanding of cloud-based data services and technologies (e.g., AWS Redshift, Azure Synapse Analytics, Google BigQuery) ensures effective utilization of cloud resources for data processing and analytics. You bring strong strategic and analytical skills to the role, enabling you to solve intricate data challenges and drive data-driven decision-making. Proven proficiency in implementing and optimizing data pipelines using modern tools and frameworks, including Databricks for data processing and Delta Lake for managing large-scale data lakes. Your exceptional communication and interpersonal skills facilitate collaboration with cross-functional teams and effective stakeholder engagement at all levels. What You'll Do Role As a Lead Data Engineer at Rearc, your role is pivotal in driving the success of our data engineering initiatives. You will lead by example, fostering trust and accountability within your team while leveraging your technical expertise to optimize data processes and deliver exceptional data solutions. Here's what you'll be doing: Understand Requirements and Challenges: Collaborate with stakeholders to deeply understand their data requirements and challenges, enabling the development of robust data solutions tailored to the needs of our clients. Implement with a DataOps Mindset: Embrace a DataOps mindset and utilize modern data engineering tools and frameworks, such as Apache Airflow, Apache Spark, or similar, to build scalable and efficient data pipelines and architectures. Lead Data Engineering Projects: Take the lead in managing and executing data engineering projects, providing technical guidance and oversight to ensure successful project delivery. Mentor Data Engineers: Share your extensive knowledge and experience in data engineering with junior team members, guiding and mentoring them to foster their growth and development in the field. Promote Knowledge Sharing: Contribute to our knowledge base by writing technical blogs and articles, promoting best practices in data engineering, and contributing to a culture of continuous learning and innovation. Some More About Us Founded in 2016, we pride ourselves on fostering an environment where creativity flourishes, bureaucracy is non-existent, and individuals are encouraged to challenge the status quo. We're not just a company; we're a community of problem-solvers dedicated to improving the lives of fellow software engineers. Our commitment is simple - finding the right fit for our team and cultivating a desire to make things better. If you're a cloud professional intrigued by our problem space and eager to make a difference, you've come to the right place. Join us, and let's solve problems together! Benefits and Perks Health Benefits Generous time away Maternity and Paternity leave Educational resources and reimbursements 401(k) plan with a company contribution The Pay Range For This Role Is 175,000 - 200,000 USD per year(New York City)",
        "url": "https://www.linkedin.com/jobs/view/3962541701"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3936619851,
        "company": "Augment Jobs",
        "title": "Software Engineer III",
        "created_on": 1720636865.1946518,
        "description": "We are seeking a skilled and driven Software Engineer III to join our innovative engineering team. The ideal candidate will possess a deep passion for technology, a robust understanding of advanced software development principles, and the capability to lead projects and mentor junior engineers. This role offers an exceptional opportunity to influence the development of high-quality software products, collaborate with seasoned professionals across disciplines, and grow into a leadership role within the technology space. Key Responsibilities Design, develop, and maintain complex software applications to meet both customer requirements and company innovation initiatives. Lead code reviews and enhance code quality, implementing best practices and coding standards across the team. Collaborate with product managers, UX/UI designers, and other engineers to conceive and launch new features. Analyze and optimize software applications for maximum speed and scalability. Provide technical leadership and mentorship to junior engineers, fostering a collaborative team environment. Diagnose, troubleshoot, and resolve software issues, ensuring robustness and reliability in application performance. Drive continuous integration and continuous delivery (CI/CD) processes and automate tasks through appropriate tools and scripting. Author and maintain technical documentation, including software design descriptions and user manuals. Research and integrate cutting-edge technologies, frameworks, and tools to maintain software innovation and competitiveness. Engage in agile development practices and participate actively in scrum meetings and project planning. Qualifications Bachelor’s or Master’s degree in Computer Science, Software Engineering, or a related technical field. 5+ years of professional software development experience. High proficiency in multiple programming languages such as Java, C#, Python, or JavaScript. Advanced knowledge of software architecture, design patterns, and object-oriented design principles. Experience with modern software development practices and tools, including Agile and DevOps methodologies. Strong understanding of database management, SQL, and NoSQL technologies. Experience with cloud services (AWS, Azure, Google Cloud) and building scalable cloud applications. Excellent problem-solving abilities and analytical skills. Exceptional communication and leadership skills, capable of leading project teams and interfacing with stakeholders. Proven ability to mentor junior developers and share knowledge across the team. Preferred Qualifications Certifications in relevant technologies or methodologies (e.g., AWS Certified Developer, ScrumMaster). Experience with containerization technologies (e.g., Docker, Kubernetes). Expertise in cybersecurity best practices. Salary Range $120,000 - $160,000 per year, dependent on experience and location. Skills List Advanced programming capabilities Software architecture and system design Agile and DevOps methodologies Cloud technology integration Database management Strong analytical thinking Leadership and team mentorship Effective communication Problem-solving and troubleshooting Continuous learning and technology adoption Benefits Competitive compensation package including bonuses and stock options Comprehensive healthcare coverage including medical, dental, and vision Retirement savings plan with company matching Generous PTO and flexible working arrangements Professional development opportunities and tuition reimbursement Access to the latest tools and technologies Dynamic and creative work environment",
        "url": "https://www.linkedin.com/jobs/view/3936619851"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3860723975,
        "company": "Opal Security",
        "title": "Software Engineer",
        "created_on": 1720636866.8581321,
        "description": "Opal is building the next generation of access management. We've all felt the pain of not getting the access we need to do our job. At Opal, we’re building a central hub for authorization to make access management automated, intelligent, and easy to use. We are taking an age old problem in enterprise software and making it simple. Our product prioritizes consumer grade simplicity with enterprise scale, reliability, and security. Our customers love our product, and we’re humbled to work with amazing companies like ScaleAI, Databricks, and Figma. You'll be joining an experienced team of engineers with direct experience building and scaling teams through massive growth at companies like Slack, Meta, and Samsara. On the back of this experience and our success to date, we’ve raised over $32M from leading investors including Greylock and Battery Ventures. Join us as we build the next generation identity security platform! Your Responsibilities Develop and ship features with our tech stack: Kubernetes, Golang, Postgres, Redis, GraphQL, TypeScript, and React Work closely with leadership, our product team, and other engineers in roadmapping, architecture, and product discussions Help develop and improve engineering best practices and processes Interact directly with customers on product feedback and issues Our ideal candidate Can take a broad mandate and design/build a system end-to-end to implement it Can work full stack and is comfortable with frontend and backend work Has 4+ years experience as a full-time software developer or equivalent experience Thrives in ambiguous environments with significant ownership and with the opportunity to make decisions that have a huge impact on the business Benefits & Perks Competitive Salary Daily lunch & coffee allowance Unlimited PTO + 11 company holidays Health, Dental, Vision insurance One Medical Membership 401k plan (no matching at this time) Pre-Tax Commuter Benefits This is a hybrid role based in either New York City or San Francisco. Research shows that candidates from underrepresented backgrounds rarely apply unless they meet all the job criteria. We aren’t looking for someone who ticks every single box on a page; we’re looking for lifelong learners and people who can make us better with their unique experiences. If you think you’d be a great fit, then please get in touch to tell us about yourself. Opal is an Equal Employment Opportunity Employer. Compensation Range: $120K - $200K",
        "url": "https://www.linkedin.com/jobs/view/3860723975"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3939288824,
        "company": "Kunai",
        "title": "Staff Data Engineer - hybrid remote",
        "created_on": 1720636868.6034293,
        "description": "Kunai is a fast-growing digital consultancy focused on banking, payments, and fintech powered by a global network that attracts the best and brightest people from all backgrounds and cultures, driven by innovation and experimentation, spread across almost every single continent. Over the past decade, we've shipped over 150 products for clients that include Visa, American Express, Capital One, WEX, Wells Fargo, Ernst & Young, and TOMS Shoes. Our founders built a previous agency (Monsoon) that was acquired by Capital One in 2015. Requires 4 days/ week on premises in the NYC office (M-Th) What will you do? You will design and build a strategic risk platform supporting various credit and risk areas, consuming data from multiple sources and vendors. You will develop complex dashboards to visualize multiple risk metrics and design workflows and approval processes. You will collaborate with cross-functional teams to analyze and integrate diverse data sources, ensuring data quality and consistency. You will develop and optimize data pipelines, support advanced data modeling, and provide insight through reporting tools. In some cases you may interact directly with executive stakeholders and be responsible for the buildout of the strategic treasury infrastructure. Could this be you? Must Haves: 7+ years experience supporting market, credit or counterparty risk organizations 10+ years experience as a software developer (tech agnostic) 10+ years of experience using common BI tools (Tableau, Alteryx, Power BI etc.) 5+ years experience with public cloud providers (preferably Azure) 5+ years experience with Data Warehousing (Redshift or Snowflake) Advanced SQL knowledge and experience working with a variety of databases. Technical expertise with data models, data mining, and segmentation techniques Bachelor’s degree in computer science or related field or equivalent work experience Nice to Haves: 10+ years of hands-on experience with SQL database design Strong analytic skills related to working with unstructured datasets. Working knowledge of message queuing, stream processing, and ‘big data’ At Kunai, we have built deep relationships with our clients. Our bar is high, and our mission is to always exceed our client’s expectations. If you are fanatical about customer success and driven to work on and solve tough technical challenges, we would love to chat with you!",
        "url": "https://www.linkedin.com/jobs/view/3939288824"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3909919756,
        "company": "Echo IT Solutions",
        "title": "AWS Cloud Engineer",
        "created_on": 1720636870.2502003,
        "description": "NYC, NY Contract To Hire AWS Cloud Engineer will be supporting, maintaining, and upgrading environments and vendor platform Triaging issues, fix, building knowledge base articles and collaborating with production support desk Engaging with multiple business partners and external vendors Navigating a large and complex organization, and engaging with multiple diverse teams in order to achieve objectives Change and Incident Management processes and tools Use structured, disciplined, and data-oriented process to identify root cause and solve problems across platforms As an AWS Cloud Engineer, you will work with a variety of individuals and groups in a constructive and collaborative manner Effectively communicate progress to senior team Commitment to quality and high standards Requirements Managed AWS hosted applications with focus on AWS services such as EC2, Systems Manager, S3, CloudWatch, etc., with experience of containerization and Kubernetes a plus Created and maintained Jenkins Core pipelines Ability to configure, monitor, and act upon Data Dog observables Ability to source and interpret logging data from various sources, (e.g., Vendor logs, for debugging and issue resolution) Automation skills (PowerShell, Python) and understanding of automation and process improvement Basic understanding a database querying language Basic knowledge of networking and infrastructure Experience with vendor products, managing cloud infrastructure, and SaaS product",
        "url": "https://www.linkedin.com/jobs/view/3909919756"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3939691369,
        "company": "ConsultAdd Inc",
        "title": "Software Engineer",
        "created_on": 1720636871.929301,
        "description": "Description Front End Developer Pythonwise Inc is an IT Consulting and IT Recruiting company with a presence all around the USA, We implement and monitors a diverse range of IT projects to suit the growing needs of the business. Role & Responsibilities The Front-End Engineer will be responsible for the development of consumer-facing web applications. In this role, you’ll work alongside the existing application team and collaborate closely with data engineering and product teams to transform the concept into code. Self-starters and independent thinkers are highly valued and thrive in our environment. You’ll be both challenged and rewarded with the opportunity to bring transformative products to market. Own the development of full applications and features Collaborate with cross-functional teams to evolve products Make testing and quality a priority Optimize application for performance and scale Communicate effort, progress and results in Qualifications: good understanding of web application development Good command of JavaScript (ES6), CSS3, and HTML 1+ year experience with frameworks such as React, Angular, etc. Experience with server-side programming such as Node.js Experience creating and consuming APIs Familiarity with UI/UX concepts Benefits Competitive salary Health benefits Experience React: 1 year (Preferred) CSS: 1 year (Preferred) Benefits Offered Health insurance Workplace perks such as food/coffee and flexible work schedules",
        "url": "https://www.linkedin.com/jobs/view/3939691369"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961459613,
        "company": "Kforce Inc",
        "title": "Software Engineer III",
        "created_on": 1720636873.6696768,
        "description": "Responsibilities Kforce has a client that is seeking a Fully Remote Software Engineer III to join their team. Summary: This candidate will perform full-stack development across the complete development life cycle delivering highly available cloud solutions and adding new capabilities to existing applications. In this role, you will work with development teams and ensure the best practices are adhered to in areas such as unit and integration testing, CI/CD, documentation, security, and software design principals. Key Tasks: Responsible for development of web-based enterprise applications from specifications Responsible for staying current on advancements in technology, design practices, and architecture, as well as the latest software and networking processes, tools, and methods, and for making recommendations on how these advances can be applied to the current products and engineering practices Work in an Agile/Scrum SDLC Requirements Bachelor's degree in Computer Science or related Major Minimum 8 years of related experience, including prior experience as a programmer in a commercial software development environment Strong experience with CI/CD pipelines with Git/GitHub; Nexus, jFrog/Artifactory, Docker Experience in working in a cloud environment such as AWS, Azure Experience with Web Services, Spring MVC, Hibernate, JPA frameworks Experience integrating with Web Services (REST) and parsing JSON and XML data Experience designing and operating solutions with relational & NoSQL Databases (MySQL/PostGreSQL Oracle, MongoDB) Understanding of messaging systems like Kafka Expert-level development experience using Java, J2EE and Web applications using MVC model Awareness of Front-end technologies like Angular, Node.js, Java Script, HTML5, CSS) Technical Skills Java, J2EE, Tomcat Spring, Micro Services, Spring Boot, REST API, GraphQL, Hibernate Elastic Search/Mongo DB, Oracle/SQL Server Kafka, RabbitMQ, ActiveMQ, Web Services XML, XSL, HTML, Java Script, Angular, AWS, Docker The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future. We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave. Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law. This job is not eligible for bonuses, incentives or commissions. Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3961459613"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3887473962,
        "company": "Figma",
        "title": "Software Engineer - Databases",
        "created_on": 1720636875.3484597,
        "description": "Figma is growing our team of passionate people on a mission to make design accessible to all. Born on the Web, Figma helps entire product teams brainstorm, design and build better products — from start to finish. Whether it’s consolidating tools, simplifying workflows, or collaborating across teams and time zones, Figma makes the design process faster, more efficient, and fun while keeping everyone on the same page. From great products to long-lasting companies, we believe that nothing great is made alone—come make with us! The Databases team is responsible for the stateful distributed systems that power all of Figma’s applications. As Figma continues to rapidly grow, the biggest challenge we face is scaling our database systems while balancing reliability. The team is taking a novel approach to Postgres sharding that requires engineers with strong distributed systems experience. Check out our latest blog post on how Figma built its in-house horizontally scalable Postgres stack. Additionally, we plan to ramp up our investments in a Streaming platform built on top of Kafka and a Caching platform on top of Redis. We are looking for engineers who are excited about scaling stateful distributed systems, and who have an eye for building simple abstractions to offer our database systems to the rest of the engineering org at Figma. This is a full time role that can be held from one of our US hubs or remotely in the United States. What you'll do at Figma: Design, build and operate scalable database systems. Improve engineering standards, tooling, and processes. Collaborate with infrastructure and product teams to define simple interfaces that improve developer velocity while supporting our scalable database products. Help debug production issues across services and multiple levels of the stack. We’d love to hear from you if you have: 5+ years of experience building infrastructure components / services at scale. Experience building and scaling distributed systems as an individual contributor and/or team lead. Proven track record of successfully shipping and landing high-quality products in high growth environments. Mentorship experiences with both junior and senior engineers. Experience communicating and working across multiple teams and functions to deliver solutions. Excellent technical communication skills. While it’s not required, it’s an added plus if you also have: Experience building out and operating database clusters or stateful systems at scale. Experience with running Postgres, MySQL, Redis or other database technologies in a production environment. Experience building and operating core, “critical path” production services. Experience building out distributed systems in high-performance server-side languages like Golang, Rust, Java or C++. At Figma, one of our values is Grow as you go. We believe in hiring smart, curious people who are excited to learn and develop their skills. If you’re excited about this role but your past experience doesn’t align perfectly with the points outlined in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles. Pay Transparency Disclosure If based in Figma’s San Francisco or New York hub offices, this role has the annual base salary range stated below. Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), market demands, and specific work location. The listed range is a guideline, and the range for this role may be modified. For roles that are available to be filled remotely, the pay range is localized according to employee work location by a factor of between 80% and 100% of range. Please discuss your specific work location with your recruiter for more information. Figma offers equity to employees, as well a competitive package of additional benefits, including health, dental & vision, retirement with company contribution, parental leave & reproductive or family planning support, mental health & wellness benefits, generous PTO, company recharge days, a learning & development stipend, a work from home stipend, and cell phone reimbursement. Figma also offers sales incentive pay for most sales roles. Figma’s compensation and benefits are subject to change and may be modified in the future. You may view our Pay Transparency Policy by clicking on the corresponding link. Annual Base Salary Range (SF/NY Hub): $149,000—$350,000 USD At Figma we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our product and our community to flourish. Figma is an equal opportunity workplace - we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity/expression, veteran status , or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. We will work to ensure individuals with disabilities are provided reasonable accommodation to apply for a role, participate in the interview process, perform essential job functions, and receive other benefits and privileges of employment. If you require accommodation, please reach out to accommodations-ext@figma.com. These modifications enable an individual with a disability to have an equal opportunity not only to get a job, but successfully perform their job tasks to the same extent as people without disabilities. Examples of accommodations include but are not limited to: Holding interviews in an accessible location Enabling closed captioning on video conferencing Ensuring all written communication be compatible with screen readers Changing the mode or format of interviews By applying for this job, the candidate acknowledges and agrees that any personal data contained in their application or supporting materials will be processed in accordance with the applicable candidate section of Figma's Privacy Policy.",
        "url": "https://www.linkedin.com/jobs/view/3887473962"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3944133884,
        "company": "Zepz",
        "title": "Senior / Mid Backend Software Engineer - Python",
        "created_on": 1720636877.1618912,
        "description": "About Zepz Zepz is the group powering two leading global remittance brands: WorldRemit and Sendwave. Since 2010, we have been disrupting an industry previously dominated by offline legacy players with our relentless focus on reducing the cost of remittances and increasing safety and convenience for our users. Every day, our people work to unlock the prosperity of cross-border communities through finance and technology - driven by our vision of a world that celebrates migrants' impact on prosperity, at home and abroad. In 2023, our brands helped cross-border communities send over $15bn from 50 countries to recipients in 130 countries. We operate over 2800 money transfer corridors worldwide and employ over 1,000 people globally. Zepz is a remote-first employer, with team members located across six continents Come join us! Zepz.io Our Commitments: We act like owners - We are relentlessly delivering for our users and spending money thoughtfully. We embrace embarrassing honesty - We function best when we're open and honest with one another — especially about our challenges and doubts. We have a bias to action - We get to first outcomes quickly, iterate and learn. We strive to be better - We may make mistakes, but always learn from them. We are inclusive - to better reflect and serve our users. Join the Sendwave Payment Core team, the beating heart of our mission to make affordable international payments a reality. You'll be at the forefront of building and maintaining the critical infrastructure that powers our mobile apps and connects users with their loved ones worldwide. In this role, you'll: Be the architect: Craft reliable and efficient backend systems using Python and Flask, integrating seamlessly with diverse third-party APIs. Own the payouts: Build and maintain robust integrations with global payout partners, ensuring funds reach their destination accurately and swiftly. Master of errors: Minimize costly mistakes by designing error-proof systems and implementing effective escalation processes. API expert: Collaborate with mobile engineers to define and develop APIs that empower efficient communication between platforms. Lead with influence: Contribute to architectural decisions, drive best practices, and mentor junior engineers. High-stakes impact: Every line of code matters. Your work directly affects millions of users and the company's financial health. What you bring: Python mastery: A deep understanding of Python, Flask, and related frameworks. Design architect: A penchant for designing and building scalable, reliable systems. Problem solver: Ability to diagnose and debug complex issues under tight deadlines. Passion for impact: Desire to make a real difference in people's lives. Why you'll love it: High visibility and ownership: Your work directly impacts the core of Sendwave's operations. Challenging and rewarding: Solve critical problems that push your technical skills to the limit. Dynamic and collaborative: Work in a fast-paced, supportive environment with passionate colleagues. Make a difference: Contribute to a mission that improves lives across the globe. Please be aware that this role may require out of hours on-call. What we offer you: Please note that the benefits below will apply to permanent roles. We have five core benefits for our talent in the US, UK, Philippines, Poland, and South Africa. If you're not in one of those regions, don't worry - the Talent team can let you know what is available for you specifically: Unlimited Annual Leave: Most Zepz team members are eligible for unlimited annual leave. Colleagues in customer-facing roles, receive a competitive holiday allowance and four recharge days a year. Feel free to make the most of your time off and maintain a healthy work-life balance! Private Medical Cover:  You can opt-in to a Private Medical Insurance scheme. This provides you with access to thorough medical coverage, so you can feel confident in your health and well-being. Retirement: We offer pension schemes to help you plan for and secure your future. Life Assurance: Life assurance is available to give you peace of mind and protect your loved ones in case of the unexpected. Parental Leave: We offer competitive parental leave schemes to ensure you are spending as much quality time with your new bundle of joy as possible. We are also remote-first as an organisation, offering flexibility for you to work where you need to be most productive. In many locations, we have workspaces, which you can use as you desire. Most roles in the Philippines are predominately office-based, with this we offer free meals for those 100% on-site. In addition to the above, you will discover that we have a range of secondary perks (such as the cycle-to-work scheme and employee discounts) depending on your location, to help you thrive at Zepz! Why choose Zepz? Our team of over 1,000 employees is fully distributed across the world. We are working from coffee shops, homes, and co-working spaces — making us one of the larger fully distributed growth-stage startups in the world but we also offer workspace in our talent cluster locations - spaces we can meet, collaborate and connect. We are proud parents, community organizers, farmers, band members, yoga teachers, YouTube influencers, former Olympians, and serial entrepreneurs. We collectively speak over twenty languages, including Akuapem, Amharic, Bengali, Ewe, Fante, Ga, Igbo, Kalenjin, Luganda, Oromo, Somali, Swahili, Wolof, Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Irish, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish. At Zepz, embodying our commitments binds us together. We are collectively passionate about striving to achieve our vision and purpose - to continue to provide the best service to our users. Ready to Apply? Applications will be reviewed on a rolling basis. If interested, please submit your resume along with a cover letter (optional), highlighting why your experience demonstrates you meet the requirements of the role. Please also indicate the countries in which you have work authorization. Confidence can sometimes hold us back from applying for a job. But we'll let you in on a secret: there's no such thing as a 'perfect' candidate. Zepz is a place where everyone can thrive. So however you identify and whatever background you bring with you, and if at all you might need any form of support to make the process as comfortable as possible, please let us know and give us a shot by applying. We want you to be excited to wake up to make an impact every day.",
        "url": "https://www.linkedin.com/jobs/view/3944133884"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3906012638,
        "company": "Current",
        "title": "Software Engineer, Associate",
        "created_on": 1720636878.8423696,
        "description": "SOFTWARE ENGINEER, ASSOCIATE At Current, we’re on a mission to enable our members to create better financial outcomes for themselves. Headquartered in NYC, we’re a leading U.S. fintech and one of the fastest growing companies with nearly 4 million members. No matter your title, we’re a team that collaborates on building great products and making an impact together. Current’s Engineering team is dedicated to building our products and infrastructure. With our applications running on Google Cloud Kubernetes Engine, we support a proprietary banking core that can scale to handle millions of transactions a day. We use a variety of databases, including MongoDB,Postgres, and Spanner. Our services are written in Java and TypeScript. We are looking for a Backend Engineer to join our team in New York. This role has a base salary range of $125,000 - $150,000. You will work to deliver on key business initiatives, improve existing architecture and services, and design large-scale data-intensive applications. The ideal candidate should have a background in backend development and experience working with cloud-hosted services. This person should also be a motivated self-starter who is able to feel at ease working in a fast-paced environment. What To Expect Owning the end-to-end delivery of key business initiatives from product discovery, to system design, and all the way to feature launch Learning and apply distributed system optimization patterns A strong culture of code and architecture review Designing and delivering large-scale data-intensive applications with cutting edge techniques in: Real-time transaction decisioning Stream-processing Machine learning Evolving the company standards for engineering excellence by helping to improve architecture, testing, and monitoring practices Helping Current’s users access new decentralized financial systems for wealth creation About You Less than one year of professional experience in software development or related roles Degree in Computer Science, Mathematics, or equivalent Production experience with one of the following languages: Java and Scala Experience with cloud-hosted services, like AWS or GCP Proficiency in both RDBMS and NoSQL databases A good grasp of concurrency and multi-threading Prior internship or project experience in software development is a plus Benefits Hybrid workspace Competitive salary Meaningful equity in the form of stock options 401(k) plan Discretionary performance bonus program Biannual performance reviews Medical, Dental and Vision premiums covered at 100% for you and your dependents Flexible time off and paid holidays Generous parental leave policy Commuter benefits Fitness benefits Healthcare and Dependent care FSA benefit Employee Assistance Programs focused on mental health Healthcare advocacy program for all employees Access to mental health apps Team building activities Our modern Chelsea-based office with open floor plan, stocked kitchen, and catered lunches",
        "url": "https://www.linkedin.com/jobs/view/3906012638"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3931646669,
        "company": "Modern Life",
        "title": "Software Engineer",
        "created_on": 1720636880.6170099,
        "description": "Join our team and accelerate your career. Modern Life combines great technology with the advice of the country’s top life insurance experts. We help our advisors streamline their practice, so they can focus on building better connections, delivering better solutions, and helping their clients lead better lives. We have raised $20 million in seed funding, led by Thrive Capital, with participation from 12 unicorn founders from Hippo, Plaid, Reddit, Flatiron Health, Newfront, At Bay, Vouch, Cedar, Lattice, and more. Join a passionate team of product-minded technologists and insurance professionals who are at the leading edge of a massive industry. Make a tangible difference in people’s lives and help deliver our mission to help everyone protect what matters most through advanced technology and tailored advice. What you'll do Write high-quality, well-tested code that runs smoothly in production Contribute to and lead complex projects, and make business vs technology decisions during all phases of the project lifecycle Weigh trade-offs and focus on value delivery. A fast-paced startup demands making trade-offs that balance the near term and long term value add of solutions Help create and uphold our engineering standards and bring consistency to the codebases and processes you build and encounter Your impact Shape the best practices, product, and more broadly the culture of the company from an early stage. Your DNA will be deep into what and how we build Create contemporary and tech-forward solutions to help insurance agents across the full stack of insurance advice and distribution Set the standard for quality and design in an industry that is ripe for innovation About you You have 5+ years of experience as a builder shipping to production You’re product-minded and deeply curious and empathetic about your users You have excellent self-management, sense of ownership, and organization You thrives in a dynamic and fast-growing environment with a high degree of ambiguity You’re genuinely excited about tackling hard technical and product problems Bonus points You’ve worked as (and loved being) a founding or early engineer You have experience at an insurtech, healthtech or broader fintech company You’ve helped build a successful, fast-growing, product-focused startup You’re excited to share your side projects with us and what you learned from them",
        "url": "https://www.linkedin.com/jobs/view/3931646669"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3912827867,
        "company": "Compass",
        "title": "Senior Software Engineer (Backend)",
        "created_on": 1720636882.0836866,
        "description": "At Compass, our mission is to help everyone find their place in the world. Founded in 2012, we’re revolutionizing the real estate industry with our end-to-end platform that empowers residential real estate agents to deliver exceptional service to seller and buyer clients. We are hiring for multiple positions across core domains of our platform spanning search, authorization, and end-to-end transaction management. As a Senior Software Engineer, you will use your experience with microservices based architecture to build products that deliver high business impact for our customers. You will lead design and development of services to support an industry leading consumer experience while also supporting the growth of the world’s most scalable brokerage. There is tremendous opportunity grow your career at Compass and positively impact how our customers interact with the Compass platform each day. At Compass, You Will Build, develop, and scale the platform that empowers real estate professionals, buyers, and sellers. Become a domain expert in real estate technology, serving as an empathetic partner to our customers. Inspire, recruit, and mentor fellow engineers. Architect distributed microservices architecture. Operate in a scalable engineering culture that leverages modern principles of decoupled systems and automated CI/CD/testing/monitoring to drive efficiencies Execute on standard agile development methodology Join a great team with high visibility and challenging projects on the horizon to help grow your career What We Look For BS in Computer Science, Software Engineering or equivalent practical experience 5+ years of experience developing comprehensive, well-tested, and high-performance software applications with languages such as Java, Go, or Python Experience with gRPC, Thrift, and other server-to-server communication protocols. Experience with Kafka and event-driven systems 3+ years using AWS / cloud technologies High proficiency designing and implementing microservices that are well tested, fault tolerant, and scalable Understanding and adherence to industry-standard best practices in software development and architecture Experience with Scrum/Agile development methodologies Strong critical thinking skills, great communication skills and passion for delivering an operational excellence Compensation: The base pay range for this position is $110,800-$166,100 annually; however, base pay offered may vary depending on job-related knowledge, skills, and experience. Bonuses and restricted stock units may be provided as part of the compensation package, in addition to a full range of benefits. Base pay is based on market location. Minimum wage for the position will always be met. Perks That You Need To Know About Participation in our incentive programs (which may include where eligible cash, equity, or commissions). Plus paid vacation, holidays, sick time, parental leave, marriage leave, and recharge leave; medical, tele-health, dental and vision benefits; 401(k) plan; flexible spending accounts (FSAs); commuter program; life and disability insurance; Maven (a support system for new parents); Carrot (fertility benefits); UrbanSitter (caregiver referral network); Employee Assistance Program; and pet insurance. Do your best work, be your authentic self. At Compass, we believe that everyone deserves to find their place in the world — a place where they feel like they belong, where they can be their authentic selves, where they can thrive. Our collaborative, energetic culture is grounded in our Compass Entrepreneurship Principles and our commitment to diversity, equity, inclusion, growth and mobility. As an equal opportunity employer, we offer competitive compensation packages, robust benefits and professional growth opportunities aimed at helping to improve our employees' lives and careers. Notice for California Applicants",
        "url": "https://www.linkedin.com/jobs/view/3912827867"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3953550502,
        "company": "Meta",
        "title": "Security Engineer - Detect & Respond (University Grad)",
        "created_on": 1720636886.2544336,
        "description": "Meta Security is looking for a Security Engineer with experience in threat modeling, TTP identification, and detection engineering. You’ll work alongside Software Engineers and Offensive Security Engineers to identify critical assets, assess the top risks, and evaluate potential internal and external attacks against Meta systems. You will be working across engineering teams supporting Production and Corporate systems to develop detection and response automation leveraging both industry-standard and custom detection and response platforms. You’ll generate detection ideas utilizing some of the world’s largest data sets and build on top of hyper-scale data pipelines. Security Engineer - Detect & Respond (University Grad) Responsibilities: Work in cross-functional projects to improve our capabilities to effectively detect and respond to security incidents Review security architecture of large-scale custom and commercial systems and independently propose logging, detection and prevention controls Perform TTP-based Threat Modeling for a wide variety of assets including endpoints, mobile, servers, internal services, public & private cloud environments and networking equipment Perform analysis against logs from a variety of sources (e.g., individual host logs, network traffic logs) to identify potential threats and detection ideas Build response workflows and actions that auto-resolve false positives and provide context scaling our ability to investigate Support security incident response in a cross-functional environment and drive incident resolution for internal and external threats Design and implement attack testing automation to validate detection coverage Build logging pipelines using our custom datasets and infrastructure Track threat clusters posing threats to Meta’s infrastructure and employees Improve the tooling of threat cluster tracking and intelligence data integration to existing systems and various intelligence feeds Minimum Qualifications: Currently has, or is in the process, of obtaining a Bachelor's degree or equivalent experience in Security Experience designing systems used for responding to external and/or insider threats Experience analyzing network and host-based security events Knowledge of networking technologies, specifically TCP/IP and the related protocols Knowledge of operating systems, file systems, and memory structures on Windows, MacOS and Linux Coding/scripting experience in one or more general purpose languages Experience with attacker tactics, techniques, and procedures Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment Preferred Qualifications: Experience in Detection & Response Engineering or similar Security Engineering role Experience building automations and integrations using SOAR platforms Background in security-focused software engineering, designing large scale systems and data pipelines, or offensive security Experience in threat hunting including leveraging intelligence data to proactively identify and iteratively investigates suspicious behavior across networks and systems Experience with anomaly detection applicable to the insider threat detection space Familiarity with campaign tracking techniques and skills to convert the tracking results to long term countermeasures Familiarity with threat modeling framework, such as Diamond Model and/or MITRE ATT&CK framework Experience with intelligence-driven threat hunting to spot suspicious activities and identify potential risks, and experience with building notebooks to automate such hunts Broad knowledge across the Security domain, as well as deep focus in one (or more) areas such as Logs and events processing, Incident Management, Digital Forensics, Offensive Security Testing, Detection and/or Response tooling development About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com. $105,000/year to $137,000/year + bonus + equity + benefits Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about  benefits  at Meta.",
        "url": "https://www.linkedin.com/jobs/view/3953550502"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3854492146,
        "company": "SoHo Dragon",
        "title": "Software Engineer - II",
        "created_on": 1720636887.979371,
        "description": "SoHo Dragon represents an investment bank with offices in New York, NY that needs to hire a Software Engineer - II. The role is hybrid in Midtown Manhattan or Metro Park in NJ as office sites. Responsibilities Responsible for support activities for Murex DEV and TEST environments (Refreshes, Debugging, BAU tasks. Skills Unix/Linux Knowledge Shell/Bash/Python Scripting Relational Database and SQL Knowledge (Sybase preferred) MX.3 Environments Management/Deployment/Monitoring (L1/L2) MX.3 Technical Architecture Knowledge Education Bachelor of Engineering or Science in Computer Science",
        "url": "https://www.linkedin.com/jobs/view/3854492146"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3928182434,
        "company": "Rose AI",
        "title": "Frontend Software Engineer Intern",
        "created_on": 1720636891.5468504,
        "description": "Data is far more useful when you can see it and interact with it. Rose is about creating a home for your data with an end-to-end system that allows you to find, engage with, and share data. Rose is actively looking for front-end software engineering interns to help design and build our data platform. For the Frontend position, we are looking for people with experience in D3, React, and data viz principles. The work will involve wireframing new features for our website, improving/replacing our existing UI/UX to help customers learn our tool better, and building new methods to visualize and explore data.",
        "url": "https://www.linkedin.com/jobs/view/3928182434"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3952244207,
        "company": "Stripe",
        "title": "Backend Engineer, Optimized Checkout & Link Data Engineering",
        "created_on": 1720636893.1587098,
        "description": "Who we are About Stripe Stripe is a financial infrastructure platform for businesses. Millions of companies—from the world’s largest enterprises to the most ambitious startups—use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone’s reach while doing the most important work of your career. About The Team The Optimized Checkout & Link team at Stripe builds best-in-class checkout experiences across web and mobile that delight consumers and streamline checkout flows for merchants. Based across North America, we're a diverse team who are deeply passionate about redefining the payment experience creating outstanding value for merchants, increasing revenue, lowering cost and growing their business. We work on Checkout, Payment Links, Elements, Payment Methods, and Link – each playing a crucial part in augmenting the economic landscape of the internet. Our days are filled with exciting challenges and collaborative problem-solving as we strive to simplify payment options, create unique business solutions and enhance checkout ease. Join us in crafting the future of digital commerce. What you’ll do We’re looking for people with a strong background in data engineering and analytics to help us scale while maintaining correct and complete data. Responsibilities Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems Be an advocate for data quality and excellence of our platform. Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve Gather requirements, understand the big picture, create detailed proposals in technical specification documents. Productizing data ingestion from various sources, data delivery to various destinations, and creating well-orchestrated data pipelines. Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts Conduct SQL data investigations, data quality analysis and optimizations. Contribute in peer code reviews, and help the team produce high quality code. Mentor team members by giving/receiving actionable feedback Who you are We’re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement. Minimum Requirements Bachelor's degree in Computer Science or Engineering Master’s degree is preferred. Have a strong engineering background and are interested in data 5+ years of experience with writing and debugging data pipelines using a distributed data framework (Hadoop/Spark/Pig etc…) Great data modeling skills, database design, relational/non-relational. Very strong SQL proficiency, and preferably SQL query optimization experience. Strong coding skills in Scala or Java preferably for building performance data pipelines. Strong understanding and practical experience with systems such as Hadoop, Spark, Presto, Iceberg, and Airflow Versed in software production engineering practices, version control, code peer reviews, automated testing, and CI/CD. Excellent communication skills. Experience in AWS cloud is preferred. Hybrid work at Stripe This role is available either in an office or a remote location (typically, 35+ miles or 56+ km from a Stripe office). Office-assigned Stripes spend at least 50% of the time in a given month in their local office or with users. This hits a balance between bringing people together for in-person collaboration and learning from each other, while supporting flexibility about how to do this in a way that makes sense for individuals and their teams. A remote location, in most cases, is defined as being 35 miles (56 kilometers) or more from one of our offices. While you would be welcome to come into the office for team/business meetings, on-sites, meet-ups, and events, our expectation is you would regularly work from home rather than a Stripe office. Stripe does not cover the cost of relocating to a remote location. We encourage you to apply for roles that match the location where you currently or plan to live. Pay and benefits The annual US base salary range for this role is $163,100 - $244,700. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. This salary range may be inclusive of several career levels at Stripe and will be narrowed during the interview process based on a number of factors, including the candidate’s experience, qualifications, and location. Applicants interested in this role and who are not located in the US may request the annual salary range for their location during the interview process. Additional benefits for this role may include: equity, company bonus or sales commissions/bonuses; 401(k) plan; medical, dental, and vision benefits; and wellness stipends.",
        "url": "https://www.linkedin.com/jobs/view/3952244207"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3860724242,
        "company": "Rogo",
        "title": "Software Engineer (Full-Stack)",
        "created_on": 1720636894.9216416,
        "description": "About Rogo Rogo is a generative AI platform reinventing how people work, starting with financial services. Our team is lean, smart, and enormously ambitious. We're growing fast, and we work in person at our beautiful office in NYC. Our mission is to make people smarter by giving everyone an AI analyst. We're unabashedly ambitious, and we're dead set on building the biggest Financial AI company in the world. Why join? Exceptional traction: strong PMF with the world's largest investment banks, hedge funds, and private equity firms. World-class team: we take talent density seriously. We like working with incredibly smart, driven people. Crazy velocity: we work fast, which means you learn a lot and constantly take on new challenges. Frontier technology: we're developing cutting-edge AI systems, pushing the boundaries of published research, redefining what's possible, and inventing the future. N-of-1 Product: Our platform is state-of-the-art and crazily powerful. We're creating tools that make people smarter, reinventing how you discover, create, and share knowledge. About The Role As a Full-Stack Engineer at Rogo, you will be instrumental in shaping the user experience of a cutting-edge AI tool, crucially keeping us at the forefront of what's possible with LLMs. Your primary focus will be on developing new user interfaces and enhancing how our users interact with the AI systems our researchers build. Collaborating closely with our product team, you will lead the way in delivering an exceptional experience for our clients across the board. Qualifications Requirements You write amazing code, fast. Extensive knowledge of React and TypeScript. Deployed Production code with Python, NextJS, NestJS, Typescript, Docker, AWS, and Tailwind. Keen interest in developing unique AI tools and user experiences. Experience updating codebases with the newest framework features (RSC, streaming, etc.). Exceptional attention to detail. Proven track record in similar roles. Self-motivated with a drive to take ownership of projects end-to-end. A passion for craftsmanship. 4+ years of industry experience. Bonus Experience at a leading AI research institution. Early engineer at a hyper-growth startup. Experience in world-class product organizations (e.g., Notion, Figma). Demonstrated passion for startups or early-stage companies. Experience with UI/UX and product design. You'll fit in at Rogo if... You have fun solving problems that others think are impossible You are high-intensity and care a lot about what you do You are ecstatic to work at a start-up You're innately curious and find joy in learning about AI and finance You are autonomous, self-directed, and comfortable working with ambiguity You have eclectic interests",
        "url": "https://www.linkedin.com/jobs/view/3860724242"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962786115,
        "company": "Gecko Robotics",
        "title": "Forward Deployed Software Engineer",
        "created_on": 1720636898.9973354,
        "description": "What We Do Gecko Robotics is helping the world's most important organizations ensure the availability, reliability, and sustainability of critical infrastructure. Gecko's complete and connected solutions combine wall-climbing robots, industry-leading sensors, and an AI-powered data platform to provide customers with a unique window into the current and future health of their physical assets. This enables real-time decision making to increase the efficiency and safety of operations, promote mission readiness, and protect the environment and civilization from the effects of infrastructure failure. Role at a Glance Forward Deployed Engineers build our business within the context of a single customer at a time. They seek out valuable problems that hold our customers back. The problems we work on are multi-domain, affecting cashflow, production, safety, and the environment. A Forward Deployed Engineer doesn't stop at finding problems, but goes on to create solutions and prove their value, owning the process from start to finish. Forward Deployed Engineers, by solving a specific version of the problem for a specific customer, also help to navigate Gecko's platforms - Gecko's tools that scale across customers. What you will do Solve Real Problems: We search for the highest impact problems we can find, we spend a lot of time with our customers to understand their true nature, we come up with new ways, and we don't quit until we've reached impact. Growth: The problems we work on are hard. No one has yet solved them. We are constantly learning and trying - and that includes learning about ourselves. We are a group who loves to grow - even if it requires hard work to do so. Technologies We Use Python, Javascript, React Google Cloud, Amazon Web Services About You Bachelor's degree in fields such as Computer Science, Mathematics, Software Engineering, Physics or relevant experience. Familiarity with data structures, storage systems, cloud infrastructure, front-end frameworks, and other technical tools. Understanding of how technical decisions impact the user of what you're building. Proficiency with programming languages such as Java, C++, Python, JavaScript, or similar languages. Ability to work effectively in teams of technical and non-technical individuals. Skill and comfort working in a rapidly changing environment with dynamic objectives and iteration with users. Demonstrated ability to continuously learn, work independently, and make decisions with minimal supervision. Willingness and interest to travel as needed. NYC and Washington, D.C. Pay Transparency Disclosure: Salary Range: $120,000.00 to $245,000.00 annually plus equity and perks. This salary range is based on the current available market data, and represents the expected salary range for this role. Gecko Robotics has minimal hierarchy and few titles, but has broad ranges of experience represented within roles. Should you have compensation expectations that exceed these bands, we'd love to hear from you and would welcome you to reach out to further discuss. Who We Are At Gecko, our people are our greatest investment. In addition to competitive compensation packages, we offer company equity, 401(k) matching, gender-neutral parental leave, full medical, dental, and vision insurance, mental health and wellness support, ongoing professional development, family planning assistance, and flexible paid time off. Gecko values collaboration, innovation, and partnership, and we believe we do our best work when we're together in person. We're an office-first culture but understand that sometimes you may need to work from home. Many people are in the office five days a week, others need a bit more flexibility. Ultimately, we care about the outcomes we achieve - and creating a culture of autonomy and trust that enables that impact. Gecko is committed to creating a culture of inclusion and belonging, and we are proud to be an equal opportunity employer. We believe it is our collective responsibility to uphold these values and encourage candidates from all backgrounds to join us in our mission to protect today's infrastructure and give form to tomorrow's. All qualified applicants will be treated with respect and receive equal consideration for employment without regard to race, color, creed, religion, sex, gender identity, sexual orientation, national origin, disability, uniform service, veteran status, age, or any other protected characteristic per federal, state, or local law. If you are passionate about what you do and want to use your talents to support our critical mission, we'd love to hear from you.",
        "url": "https://www.linkedin.com/jobs/view/3962786115"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Albany, NY",
        "job_id": 3884689478,
        "company": "ACS Consultancy Services, Inc",
        "title": "Oracle data warehouse developer",
        "created_on": 1720636900.6458547,
        "description": "Job Title: Oracle Data Warehouse Developer Location: Albany, NY (Hybrid) We are currently seeking candidates who meet the following qualifications: Key Responsibilities Reverse engineer Oracle Warehouse Builder (OWB) ETL processes and develop new Oracle Data Integrator (ODI) processes, ensuring consistent functionality. Utilize expertise in data modeling (Dimensional & Relational), process improvement, and data manipulation within a child welfare environment. Perform development tasks in an Oracle Data Warehouse environment using PL/SQL. Implement advanced Extract/Transform/Load (ETL) techniques such as bulk select, bulk insert, arrays, and dynamic SQL for detailed incremental ETL processes. Develop and test maps, perform source-to-target mappings, and plan storage capacity within Oracle Data Integrator (ODI). Engage in the full Software Development Life Cycle (SDLC), including requirement gathering, development, testing, debugging, deployment, documentation, and production support. Handle load issue resolutions, inquiries, 2nd level testing of issues and code fixes, and participate in infrastructure upgrades and enhancements, including Oracle upgrades. Utilize Unix or Linux environments for Unix Shell Scripting and sftp protocols. Contribute to the design and implementation of database schemas, tables, views, indexes, and stored procedures. Qualifications Bachelor’s Degree in a relevant field. Demonstrated experience in Oracle Data Warehouse development. Proficiency in PL/SQL and Oracle Data Integrator (ODI). Familiarity with Unix or Linux environments and Unix Shell Scripting. Strong understanding of database schema design and development. Excellent communication skills and ability to work both independently and collaboratively in a hybrid work setting. If you meet these qualifications, please submit your application via link provided in Linkedin. Kindly do not call the general line to submit your application.",
        "url": "https://www.linkedin.com/jobs/view/3884689478"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959569925,
        "company": "Kensho Technologies",
        "title": "Senior Backend Software Engineer",
        "created_on": 1720636904.7423236,
        "description": "Kensho is a Machine Learning (ML) and Natural Language Processing (NLP) company, centered around providing cutting-edge solutions to meet the challenges of some of the largest and most successful businesses and institutions. We are owned by S&P Global and operate independently. Our toolkit illuminates insights by helping the world better understand, process, and leverage messy data. Specifically, Kensho’s solutions largely involve speech recognition (ASR), entity linking (NED), structured document extraction, automated database linking, text classification, and more. Kensho’s Applications group develops the web apps and APIs that deliver Kensho’s AI capabilities to our customers. Our teams are small, product-focused, and intent on shipping high-quality code that best leverages our efforts. We’re collegial, humble, and inquisitive, and we delight in learning from teammates with backgrounds, skills, and interests different from our own. As a Senior Backend Engineer, you will develop reliable, secure, and performant APIs that apply Kensho’s AI capabilities to specific customer workflows. You will collaborate with colleagues from Product, Machine Learning, Infrastructure, and Design, as well as with other engineers within Applications. You have a demonstrated capacity for depth, and are comfortable working with a broad range of technologies. Your verbal and written communication is proactive, efficient, and inclusive of your geographically-distributed colleagues. You are a thoughtful, deliberate technologist and share your knowledge generously. At Kensho, we believe in flexibility-first, and give our employees the opportunity to work from where they feel most productive and engaged (must be in the United States). We also value in-person collaboration, so there may be times when travel to one of our Kensho hubs (e.g., Cambridge, MA or NYC) will be required for team meetings or company events. Kensho states that the anticipated base salary range for the position is 150k–225k. In addition, this role is eligible for an annual incentive bonus and equity plans. At Kensho, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. What You’ll Do: Design, develop, test, document, deploy, maintain, and improve software Manage individual project priorities, deadlines, and deliverables Work with key stakeholders to develop system architectures, API specifications, implementation requirements, and complexity estimates Test assumptions through instrumentation and prototyping Promote ongoing technical development through code reviews, knowledge sharing, and mentorship What You'll Need: At least five years of direct experience developing customer-facing APIs within a team Thoughtful and efficient communication skills (both verbal and written) Experience developing RESTful APIs using a variety of tools Experience turning abstract business requirements into concrete technical plans Experience working across many stages of the software development lifecycle Sound reasoning about the behavior and performance of loosely-coupled systems Proficiency with algorithms (including time and space complexity analysis), data structures, and software architecture At least one domain of demonstrable technical depth Technology You'll Encounter: Python, Django, Flask, mypy, OpenAPI Git, Jsonnet, Jenkins, Docker, Kubernetes At Kensho, we pride ourselves on providing top-of-market benefits, including: Medical, Dental, and Vision insurance 100% company paid premiums Unlimited Paid Time Off 26 weeks of 100% paid Parental Leave (paternity and maternity) 401(k) plan with 6% employer matching Generous company matching on donations to non-profit charities Up to $20,000 tuition assistance toward degree programs, plus up to $4,000/year for ongoing professional education such as industry conferences Plentiful snacks, drinks, and regularly catered lunches Dog-friendly office (CAM office) Bike sharing program memberships Compassion leave and elder care leave Mentoring and additional learning opportunities Opportunity to expand professional network and participate in conferences and events About Kensho Kensho is an Artificial Intelligence company that builds solutions to uncover insights in messy and unstructured data that enable critical workflows and empower businesses to make decisions with conviction. Kensho was founded in 2013 and was acquired by S&P Global in 2018. Kensho continues to operate as a startup in order to maintain our distinct, independent brand and to promote our breakthrough, innovative culture. Our team of Kenshins enjoy a dynamic and collaborative work environment that runs autonomously from S&P Global, while leveraging the unparalleled breadth and depth of data and resources available as part of S&P Global. As Kenshins, we pride ourselves on maintaining an innovative culture that depends on diversity and inclusion. We are an equal opportunity employer that welcomes future Kenshins with all experiences and perspectives. Kensho is headquartered in Cambridge, MA, with offices in New York City, and Washington D.C. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.",
        "url": "https://www.linkedin.com/jobs/view/3959569925"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3912832127,
        "company": "Compass",
        "title": "Senior Software Engineer",
        "created_on": 1720636906.5419855,
        "description": "At Compass, our mission is to help everyone find their place in the world. Founded in 2012, we’re revolutionizing the real estate industry with our end-to-end platform that empowers residential real estate agents to deliver exceptional service to seller and buyer clients. We are seeking a motivated frontend engineer to join our team. In this role, you will be responsible for designing and developing the platform upon which Compass’s front end ecosystem is built. You will have the opportunity to utilize your knowledge of frontend best practices, and work closely with both technical and non-technical stakeholders to ensure that our websites and applications are performing at their best. If you have a strong understanding of what makes web applications run in a stable and performant manner, and enjoy working on the front-end of web projects, we encourage you to apply for this exciting opportunity. What You Will Do Work in a startup-like environment building agile products and services Collaborate closely with engineers on your team, engineers on other teams, as well as your product and design counterparts to successfully launch projects which solve real-world customer problems Evaluate and understand the technical trade offs necessary to bring product initiatives to fruition, weighing different approaches and arriving to a recommended solution, detailing its pros and cons Independently define, decompose, and lead delivery of complex projects Perform code reviews, design reviews, and write high quality tests Advocate for efficient, scalable, and extensible approaches that solve technical problems in a manner that stands the test of time Hold yourself and your team to a high standard of code quality and operational rigor, ensuring that code is well-tested, and your systems have appropriate monitoring, alerting, and runbooks implemented Become the subject matter expert for one or more services in your domain Create clear and concise documentation (diagrams, service descriptions, decisions, runbooks) Identify and remove bottlenecks to address inefficiencies in the developer experience Mentor junior engineers on the team, building their technical skills and ensuring that they understand best practices around engineering and operational excellence What We Look For Bachelor’s degree in Computer Science or equivalent practical experience Minimum 5 years of software engineering experience with HTML, CSS, and Javascript. Minimum 2 years of experience with TypeScript and React Experience integrating with RESTful server-side services and third party APIs. Understanding of Computer Science fundamentals and frontend design patterns and best practices Knowledge and experience with software development best practices such as coding standards, code/design reviews, continuous integration/deployments, test driven development. Experience leading the development of a project from planning to release, dispatching work among a small team, mentoring and guiding junior engineers A sheer eye for design and attention to detail, the products you build should not merely be functional but should take in context and anticipate our customer’s needs in a beautiful way Experience with Scrum/Agile development methodologies Excellent verbal and written communication skills Demonstrated experience working in fast paced and collaborative environment Nice to have: Prior experience with infrastructure, such as CI/CD pipeline management, CLI tools, or build systems Compensation: The base pay range for this position is $110,800-$166,100 annually; however, base pay offered may vary depending on job-related knowledge, skills, and experience. Bonuses and restricted stock units may be provided as part of the compensation package, in addition to a full range of benefits. Base pay is based on market location. Minimum wage for the position will always be met. Perks That You Need To Know About Participation in our incentive programs (which may include where eligible cash, equity, or commissions). Plus paid vacation, holidays, sick time, parental leave, marriage leave, and recharge leave; medical, tele-health, dental and vision benefits; 401(k) plan; flexible spending accounts (FSAs); commuter program; life and disability insurance; Maven (a support system for new parents); Carrot (fertility benefits); UrbanSitter (caregiver referral network); Employee Assistance Program; and pet insurance. Do your best work, be your authentic self. At Compass, we believe that everyone deserves to find their place in the world — a place where they feel like they belong, where they can be their authentic selves, where they can thrive. Our collaborative, energetic culture is grounded in our Compass Entrepreneurship Principles and our commitment to diversity, equity, inclusion, growth and mobility. As an equal opportunity employer, we offer competitive compensation packages, robust benefits and professional growth opportunities aimed at helping to improve our employees' lives and careers. Notice for California Applicants",
        "url": "https://www.linkedin.com/jobs/view/3912832127"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888842228,
        "company": "Steneral Consulting",
        "title": "Hybrid Work - Need Cloud Engineer/AWS/Scripting in Midtown NY",
        "created_on": 1720636908.2010825,
        "description": "We need: A SENIOR Cloud engineer (Not Pure DevOps) with excellent experience working in AWS and with extensive scripting for automation experience (language does not matter) This position is heavy on support so candidates should be comfortable doing 3rd level support along with regular AWS Cloud engineer responsibilities. **Candidates must have Long Projects/Good Tenure, Excellent communication skills and a State issued ID (Not Bills) showing they are Local. ***CERTIFICATIONS ARE REQUIRED, THE MORE THE BETTER. AWS. THIS IS NOT A PURE DEVOPS POSITION. CLOUD ENGINEERS WILL HAVE EXPERIENCE WITH DEVOPS BUT PLEASE DO NOT SEND ME DEVOPS ENGINEERS. Candidates must be LOCAL to the NEW YORK or NEW JERSEY area and COMMUTE into the office THREE TIMES A WEEK . NO RELOCATION CONSIDERED . *** Candidate Must Have’s on a resume and for submittal: How many years working with: Cloud Engineer/NOT PURE DEVOPS How many years working with: Scripting for automation How many years working with: AWS Position Summary The successful candidate will be responsible for designing, implementing, and maintaining our cloud infrastructure on AWS, ensuring high availability, scalability, and security. The candidate should have a deep understanding of Amazon Web Services and be proficient in managing cloud infrastructure. The AWS Cloud Engineer is responsible for providing technical leadership in support of corporate initiatives in cloud computing and automation, with a focus on the support of systems and services that run on cloud platforms. They develop and coordinate cloud solutions across diverse areas including application development, identity and access management, networking, security, data management, and more. Duties And Responsibilities Design, deploy, and maintain AWS infrastructure and services, including EC2 instances, S3 buckets, RDS databases, and Lambda functions Ensure high availability and scalability of AWS resources Develop and implement security best practices to ensure the security and compliance of AWS resources Automate infrastructure provisioning and management using tools like Terraform, CloudFormation, or Ansible Deploy, configure, and manage virtual machines, storage, network, and security resources Monitor AWS resources and troubleshoot issues as they arise Work with development teams to optimize application performance on AWS infrastructure Provide technical guidance and mentorship to junior team members Ensure high availability, scalability, and performance of the cloud infrastructure Work with development and operations teams to optimize application performance and troubleshoot issues. Implement security and compliance policies and procedures Create and maintain documentation for the cloud infrastructure and services Stay up-to-date with the latest AWS technologies and features and provide recommendations to improve the cloud infrastructure Setup Backups and Monitoring of resources Participate in operational triage calls to help resolve issues when they arise Experience in triaging components of traditional on-premises distributed systems (storage, network, compute). Ensure delivered solutions meet/perform to technical and functional/non-functional requirements Provide technical expertise and ownership in the diagnosis and resolution of an issue, including the determination and provision of workaround solution or escalation to service owners Skills/Knowledge/Abilities Requirements Successfully prioritize and oversee multiple simultaneous work streams Must be able to work in a demanding environment; flexible work scheduled can be required Comfortable with providing Tier I and Tier II problem resolution with team members and business community users within expected SLAs Strong analytical and problem-solving skills as well as oral and written communication skills. Hands On with PaaS and IaaS cloud ecosystems Minimum of 5 years' experience within the financial industry and/or at a highly complex regulated technology organization desired Knowledge and expertise with Cloud technology architecture and design in a hybrid environment a plus Excellent communication skills Adaptable, innovative and stays current in Cloud technologies. Education/Certification Requirements Bachelor’s degree in computer science, systems analysis or a related study, or equivalent experience 10 + years of experience spanning at least two IT disciplines, including technical architecture, network management, application development, middleware, database management or operations Ability to provide technical documentation, diagrams, process flows, data flows and artifacts is required Must possess solid hands on experience with Amazon Web Services (AWS) Enterprise environments Experience with mutli-cloud environments a plus Experience with Azure Engineer role highly valued Strong understanding of operating systems such as Linux, Unix, Solaris, & Windows. Familiar with the concepts, pros, and cons of the various operating systems. High level understanding of vital cyber security concepts. Basic knowledge of firewall and other security components is necessary Understanding of network architecture and application development methodologies Knowledge of business process re-engineering principles and procedures Certifications in AWS required",
        "url": "https://www.linkedin.com/jobs/view/3888842228"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3927346419,
        "company": "Amazon",
        "title": "Sr. Data Engineer, Amazon Shopping Videos",
        "created_on": 1720636909.9052923,
        "description": "Description It’s an exciting time to be on the Amazon Shopping Videos team. We have millions of videos that help customers shop every day. These include product demos, customer reviews, buying guides, and how-to guides. How do we choose the right videos to show, to the right customer, at the right time, helping them make the right shopping decision? That’s where you come in. Data is at the center of every product we develop as we create new features and products that serve the needs of our growing base of consumers and brands. As a Data Engineer on the Amazon Video Shopping team, you will lead the design and implementation of systems capable of processing, storing and querying large datasets. You will partner with product managers and engineers to help build and support data needs of partner teams, reporting solutions, machine learning systems and analytics. About The Team Now more than ever, customers watch videos when they shop. Videos and livestreams make shopping easier and more fun, whether a customer is researching a product or tuning in to chat with their favorite content creator live. The Amazon Shopping Video (ASV) team’s mission is to enable customers to find inspiration, information, entertainment, and community through videos at any point in their shopping journey. If you are interested in building an entertainment product, enjoy a creative and fast-paced working environment, and want to work on a strategic new initiative, join our team today! We are open to hiring candidates to work out of one of the following locations: New York, NY, USA | Seattle, WA, USA Basic Qualifications 5+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Experience with SQL Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS Experience mentoring team members on best practices Preferred Qualifications Experience with big data technologies such as: Hadoop, Hive, Spark, EMR Experience operating large data warehouses Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $139,100/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon.com Services LLC Job ID: A2644060",
        "url": "https://www.linkedin.com/jobs/view/3927346419"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3860725483,
        "company": "Prime Financial Technologies",
        "title": "Staff Data Engineer",
        "created_on": 1720636911.6538782,
        "description": "About Prime Prime Financial Technologies is a software company with a mission to accelerate small businesses. At Prime, we harness advanced data science in credit decisioning to simplify and accelerate credit distribution to small and medium-sized businesses. Operating at the cutting edge of Embedded Finance and Ecosystem Lending, Prime’s focus is on embedded lending, where sophisticated data analytics are utilized to sharpen the accuracy of pre-qualification and underwriting processes and also deliver financial solutions that are customized to the needs of businesses. Prime’s integrations are designed specifically for marketplace and SaaS platforms, ensuring a seamless transaction experience for merchants and new diversified revenue streams for platforms. Our investors include Capital One and NEA. Most join us because they connect with our mission of democratizing access to credit for small businesses. If you are energized by the impact you can make at Prime, we’d love to hear from you! Position Location This role is available in the following locations: Los Angeles, CA, NYC metro area, or Bay Area, CA. Time Zone Requirements The team operates in either East/West Coast time zones. Travel Requirements This team has regular onsite collaboration sessions. These occur several times per year and span consecutive days in the Bay Area, CA, Los Angeles, CA, or NYC office. If you need to travel to make these meetups, Prime will cover all travel related expenses. How You’ll Make An Impact You will be instrumental in building out Prime’s data mesh. As a Staff Data Engineer at Prime, you will be solving problems around data modeling, scale, integrity, denormalization, availability, warehousing, analytics, machine learning infrastructure, and the list goes on. You will work directly with Product, Engineering, Data Science, ML, and Credit functions to understand stakeholder use cases and develop reliable, trusted data infrastructure for internal stakeholders. By joining our company at this stage, you’ll be taking on a meaningful role on an engineering team of just under 10 individuals with an average of 15 years of experience on which to draw from and learn from. You will have an immense impact on the company’s architecture and technical roadmap, not to mention the impact on financial outcomes of small business borrowers through their shared journey with Prime. What You’ll Do Design large scale, distributed data processing systems and pipelines Ensure the reliability and integrity of data at Prime Collaborate with other engineering, data science, and cross functional partners in service of our customers Influence and develop our architecture and technical roadmap Write high quality, maintainable and scalable code Identify and troubleshoot issues Maintain the quality bar for engineering excellence at Prime Stay up to date with emerging technologies, best practices, and industry trends in data engineering and software development Commit to integrating our core values of Win the Day, Get out of the Building, Embrace the Unknown, and Excellence as a Habit in all aspects of your daily responsibilities and professional interactions Technologies we use Languages: Python, Javascript Infrastructure: AWS, Terraform, Elastic Container Service, Elastic Load Balancer, API Gateway, SQS, SNS, Step Functions Database / Warehouse: PostgreSQL, DynamoDB, Databricks Unity Catalog Distributed Compute: Spark/Databricks Frameworks: Flask, React, Tailwind, REST Tooling: Github, Sentry, Grafana Multiple 3rd party financial system integrations Minimum Requirements What We're Looking For 8+ years of professional data engineering or software engineering experience, with a focus on heterogeneous, large-scale data processing for machine learning pipelines 4+ years as a data engineer building data products Direct hands on experience with highly scalable data pipelines using BigData technologies (Spark, Hive, Airflow, DBT, Parquet / ORC, Kafka / Streaming, etc) Passion for everything data: data models, catalogs, analytics, pipelines, and solving complex data problems Experience with the complete development cycle, from product definition to delivery Excellent communication skills Growth mindset Bias to action Evidence of constant learning The motivation and ability to work well in a high-growth and dynamic environment Preferred Qualifications Experience serving Data Science & ML Engineering Teams Start up and fintech experience a huge plus DevOps knowledge What You'll Love Competitive salary and equity grants Top tier medical, dental vision insurance Life insurance and disability benefits Personal development, technology, and ergonomic Budgets 401K matching Unlimited PTO, work from home flexibility, and parental leave Transparent company culture and proactive communication via weekly all hands, lunch & learns, and monthly founder AMAs Senior team of experienced professionals highly motivated to solve tough problems and ship remarkable products Join our growing team as we build out the next generation of lending infrastructure for small businesses.",
        "url": "https://www.linkedin.com/jobs/view/3860725483"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3942384207,
        "company": "FOX Tech",
        "title": "Software Engineer",
        "created_on": 1720636913.3192964,
        "description": "Overview Of The Company Fox Corporation Under the FOX banner, we produce and distribute content through some of the world’s leading and most valued brands, including: FOX News Media, FOX Sports, FOX Entertainment, FOX Television Stations and Tubi Media Group. We empower a diverse range of creators to imagine and develop culturally significant content, while building an organization that thrives on creative ideas, operational expertise and strategic thinking. Job Description TMZ is looking for a Software Engineer to join our existing team. The ideal candidate is a creative thinker and concise communicator who enjoys taking ownership of and stewarding web-based projects throughout the software lifecycle. Must be a solutions-driven team player who is excited to learn new technologies and produce results while managing priorities and meeting deadlines. Specific technologies used by the team: Symfony, Twig, React, React Native, Docker, Cloud Formation. About Tmz TMZ goes where stars work, live, and play and takes its audience into a world where the reality is even more fascinating than the hype. TMZ breaks the biggest stories in entertainment as only it can with accuracy, irreverent humor and youthful energy. TMZ connects with the public across its broadcast and digital platforms by providing a fresh, unvarnished, and honest take on celebrities and their real lives. The TMZ brand is the most trusted, the most talked about, and the highest quality entertainment news outlet in the world. TMZ is an Equal Opportunity Employer. a Snapshot Of Your Responsibilities Design, develop, and deliver web/native applications, services, integrations, and system logic for powering user-facing and internal products Effectively manage priorities to achieve agreed-upon deadlines, communicating throughout the development period Collaborate with internal/external designers, product, and editorial teams What You Will Need Willing to work on any part of the system from cloud infrastructure to cross-browser css bugs Significant server-side development experience with frameworks such as Symfony, Django,ASP.NET, etc. controllers and the request/response lifecycle dependency injection security and authentication performance monitoring and tuning debugging via logs and other tools Significant front-end development experience with HTML, CSS, JavaScript (ECMAScript >=6) frameworks such as React/Svelte|Vue|Angular/etc build tools such as Babel/webpack/esbuild/etc styling tools such as Sass/Less/Bootstrap/etc automated testing tools using Tape/Jest/Mocha/etc Significant experience using standards-based development styles and patterns(MVC/EDA/Microservices/Monolith/etc) Comfortable working with source control tools such as Git and GitHub/GitLab NICE TO HAVE, BUT NOT A DEALBREAKER Degree in Computer Science, Engineering, or related field Hands-on experience running applications on cloud platforms such as AWS/Azure/GCP Experience with tools such as ElasticSearch, Redis/Memcached Experience with React Native, Android (Kotlin/Java) and/or iOS (Swift/Objective-C) CMS driven web publishing experience (WordPress/Drupal/etc) Comfortable working with third-party vendors via packages, web APIs, feeds, etc including opening and resolving support cases Experience with a variety of programming languages/ecosystems Learn more about Fox Tech at #foxtech We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law. At FOX, we foster a culture and environment where everyone feels welcome and can thrive. We are deeply committed to diversity, equity, and inclusion, including attracting, retaining, and promoting diverse talent across our company. We live in a diverse world, with different ideas and different perspectives that come together to spark new ideas and make great things happen. That means reflecting the diversity of the world around us is critical to our company’s success. We ensure that our viewers, communities and employees feel heard, represented, and celebrated both on screen and off. Pursuant to state and local pay disclosure requirements, the pay range for this role, with final offer amount dependent on education, skills, experience, and location is: $95,000.00-133,000.00 annually for California. This role is also eligible for an annual discretionary bonus, various benefits, including medical/dental/vision, insurance, a 401(k) plan, paid time off, and other benefits in accordance with applicable plan documents. Benefits for Union represented employees will be in accordance with the applicable collective bargaining agreement.",
        "url": "https://www.linkedin.com/jobs/view/3942384207"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Manhattan, NY",
        "job_id": 3863605235,
        "company": "Career Developers, Inc.",
        "title": "SQL/Python - Data Engineer Tools (Finance Industry a Must) - USC OR Green Card is a must (140-150K)",
        "created_on": 1720636914.9816797,
        "description": "Refer a friend:  Referral fee program Career Developers Inc , a well-established staffing agency/consulting firm, is celebrating 30 years in business. Previously in Ramsey, NJ for 25 years and now headquartered in sunny West Palm Beach, FL, we offer comprehensive commercial and government staffing services nationwide (GSA Contract holder). With a portfolio of carefully chosen clients to represent, we ensure a productive partnership that exceeds most others. Our commitment and goal for our candidates lie in efficiently managing your expectations through business intelligence, spending time for interview preparations, providing open communication, and delivering exceptional feedback throughout the process.We look forward to helping advance your career! ----------------------------------------------------------------------------------------------------------------------------------------------- Data Engineer (Capital Markets / Financial Services) Location: NYC - (3 days a week on-site) Salary: 140-150K + 7% Bonus / Pension / Full Benefits Green Card and USC is a must due to US FHFA regulations that this company follows. Must possess a STRONG Capital Markets or similar finanical background with Fixed Income, Bonds, swaps, etc, supporting a large data warehouse and provide Python tools within this team. You must have a strong demonstrated experience with supporting and implementing tools withn the data infrastruture. The ideal candidate will be responsible for designing and implementing a robust data infrastructure and analytical toolset to support Balance Sheet management and optimization activities of the Capital Markets group. This role is ideal for someone passionate about leveraging data to drive high-impact business decisions. Technical Expertise: Advanced Proficiency in SQL and Python are essential. Proven track record of deploying and managing python codebase in a production setting. Experience with Data Warehousing Solutions: Proven experience with Snowflake or similar platforms. Data Visualization Tools: Proficiency in using tools like Plotly, QlikSense, Tableau for data visualization. Working knowledge of a Git repository for version control and collaborative development Data Engineering Skills: Data Processing: Experience in handling, processing, and extracting value from large, disconnected datasets. Data Pipeline Development: Skilled in designing and implementing data pipelines for efficient data flow. Quantitative Skills: Statistical and Mathematical Methods: Familiarity with PCA, linear regression, logistic regression, KNN algorithm, and Monte Carlo simulations. Analytical Abilities: Capability to analyze complex sets of data and provide actionable insights. Experience in building high impact analytical tools. Collaborative Skills: Experience working closely with various groups across an organization. Excellent communication skills for effective cross-team collaboration. At least 3 years of relevant experience in a similar role INDH Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing, Capital Markets data analytics, SQL python, data warehousing,",
        "url": "https://www.linkedin.com/jobs/view/3863605235"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3759560632,
        "company": "Courier Health",
        "title": "Software Engineer, Backend",
        "created_on": 1720636916.536085,
        "description": "Courier Health is on a mission to solve one of the biggest and most meaningful opportunities in healthcare: reinvent how people living with chronic and rare diseases are supported . We are building the future of patient engagement for life sciences companies. Our software is leveraged by biopharma companies to support patients in their complex journey from diagnosis to initiating and remaining on therapy to achieve optimal health outcomes. We are looking for talented individuals who are motivated by the opportunity to have an outsized impact on not just their company, but the healthcare industry at large. What You'll Do Play a lead role designing and building new features for our core products Improve the speed and reliability of existing applications Work with other employees to find new product opportunities Help us scale the company, the culture, and our products Qualifications BS or MS in computer science or related field 3+ years professional experience Experience with object oriented programming and a high bar for code quality Experience with AWS services Passionate about solving technical challenges and architecting infrastructure that is both sustainable and scalable Inspired by our mission to improve healthcare through technology Seek simple approaches to complex problems Proven track record of being an independent self-starter Bonus Points Experience with AWS services, such as DynamoDB, API Gateway, SES, Cognito, Lambda, or AppSync Experience with Javascript, TypeScript, GraphQL, or Node.js Experience building healthcare applications Experience delivering complex software systems all the way to production Benefits Highly competitive pay, including equity Top notch health benefits Flexible PTO Paid parental leave Monthly healthy lifestyle stipend Team events and bi-annual off-sites Career coaching opportunities Open office with unlimited coffee, snacks, etc. The annual salary range for the target level for this role is $125,000 - $165,000 + equity + benefits, including medical, dental, and vision. Courier Health is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",
        "url": "https://www.linkedin.com/jobs/view/3759560632"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3906855601,
        "company": "Optima Global Solutions Inc.",
        "title": "Database Engineer",
        "created_on": 1720636918.2536404,
        "description": "Optima Global Solutions Inc.is a valuable IT Services and Solution provider that customers, employees, and stakeholders feel proud to be associated with. Optima's Intelligent Automation Solutions leverage robotic process automation, intelligent data capture, and business process management best practices to streamline operations. Our IT Services practice provides organizations with highly personalized, comprehensive, U.S. based recruiting services supported by our internal onsite team of subject matter experts. Currently, we are hiring for a Database Engineer SCOPE OF SERVICES TASKS: • Install, configure, customize, create, implement, and support Oracle databases in Non-RAC and RAC environments, and software and related tools/products for the database systems atOTI. • Implement Grid Infrastructure release 19c on a OS Unix/Linux platform support databases; • Implement Oracle Automatic Storage Management (ASM) cluster Filesystem and maintain it; Add new disks to an ASM disk group. • Patching grid infrastructure and Oracle rdbms. • Setup Oracle database security environment. • Carry out DB Performance Tuning, and RMAN backups. • Working with Oracle, implement best of class solutions. • Utilize Linux Administration skills as needed; develop UNIX shell scripts; Automation using ansible; work with the Database team and teams of Unix engineers and administrators to design, build, upgrade and support the necessary Oracle infrastructure to meet the needs of OTI and OTI hosted supported agencies. • Work hands on more extensive projects such as migration, implementing of new features, architectures and validation and assisting OTI. • Configure Golden gate replication; both integrated and microservices based configuration. • Configure Oracle RAC and ASM technologies on Redhat Linux. • Configure Oracle Data Guard with Active and Standby database modes. • Assist developers and end users in implementing best practices and addressing performance issues in implementation. • Ensure all databases are backed up and meets the business's Recovery Point Objectives (RPO) and Recovery Time Objectives (RTO) • Lead team efforts in adopting in modernized architecture such as hybrid cloud and database ready for hybrid cloud. • Perform RCA; manage different database encryption technologies; and implement DR by design and validate. • Perform special projects, and initiatives as assigned by OTI. • Experience with latest Oracle versions and their features but not limited to Multi-tenant Architecture, Oracle Partitioning, Real Application Testing (RAT), Oracle Database Vault. MANDATORY SKILLS/EXPERIENCE Note: Candidates who do not have the mandatory skills will not be considered • Minimum 12 years of hands- on experience in database engineering. • Ability to work independently. • Experience in implementing/managing Oracle Databases in a RAC environment with at least 2 years of production support. • Experience in Implementing Grid Infrastructure release 19 or higher on a Redhat Linux environment. • Experience implementing ASM cluster Filesystem with knowledge of how to maintain it for successful operational delivery. • Knowledge of Best Practices for adding a new disk to an ASM disk group. • Experience patching grid infrastructure software. • Familiarity with Oracle database resource manager. • Familiar with Ansible/automation/scripting. • Familiarity with huge pages on Linux. • Experience supporting a high-availability production database. • Experience in configuring/supporting Oracle Active Data Guard required. • Experience in database architecture and design; Oracle Advanced Security Option; and Golden Gate for Oracle Replication • Knowledge of working on cloud environments preferable AWS & AZURE. Participate in application/DB outage incidents during trouble shooting and provides solution and RCA. DESIRABLE SKILLS/EXPERIENCE: N/A • Experience with Oracle Advanced Security Option is highly desirable. Interested candidates, please apply online with a detailed resume and contact information. Thank you.",
        "url": "https://www.linkedin.com/jobs/view/3906855601"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3934710828,
        "company": "Hudson River Trading",
        "title": "Systems Engineer - Big Data",
        "created_on": 1720636919.9358213,
        "description": "Hudson River Trading (HRT) is looking for Systems Engineers to join our growing Research & Development team. This team builds and maintains an exceptionally large and growing distributed compute cluster, many-PB-scale storage systems, operating systems, automation software, and development tools. We are seeking a highly skilled engineer with expertise in Linux administration and experience with Big Data technologies, particularly Kafka, Trino, and Elasticsearch. As a Big Data Systems Engineer, you will play a critical role in ensuring our data infrastructure is robust, scalable, and reliable. You will work closely with our engineering and research teams to design, deploy, and maintain systems that support our research and trading activities. Responsibilities Trino Administration: Set up and manage Trino clusters for large-scale data analytics. Optimize and troubleshoot query performance and ensure data integrity across the system Kafka Administration: Design, deploy, and maintain Apache Kafka clusters. Implement and monitor Kafka-based data pipelines to ensure efficient and reliable data flow Elasticsearch Administration: Configure and maintain Elasticsearch clusters on managed compute platforms such as Kubernetes System Monitoring: Develop and implement monitoring solutions to ensure high system uptime and reliability; utilize tools to detect and resolve issues proactively Linux Administration: Maintain and manage a large-scale Linux-based infrastructure; ensure system stability, security, and performance through best practices in system administration Collaboration: Work closely with development and research teams to understand their requirements and provide robust data infrastructure solutions, participating in cross-functional projects as needed Documentation: Create and maintain comprehensive documentation for system architecture, processes, and best practices Skills Bachelor's degree in computer science, information technology, or a related field Minimum of 3-5 years of experience in systems engineering, with a focus on Linux administration Experience with large scale, big data query engines and technologies such as Trino, Presto, Iceberg, and Hive Experience with operating and managing large scale Kafka clusters, including design, deployment, and capacity management Experience with operating and managing large scale Elasticsearch clusters Experience with container orchestration platforms and technologies such as Kubernetes, Terraform, and Helm Proficiency in scripting languages such as Python or Bash Strong problem-solving skills and the ability to work in a fast-paced environment Excellent communication and collaboration skills Annual base salary range of $150,000 to $250,000. Pay (base and bonus) may vary depending on job-related skills and experience. A sign-on and discretionary performance bonus may be provided as part of the total compensation package, in addition to company-paid medical and/or other benefits. Culture Hudson River Trading (HRT) brings a scientific approach to trading financial products. We have built one of the world's most sophisticated computing environments for research and development. Our researchers are at the forefront of innovation in the world of algorithmic trading. At HRT we welcome a variety of expertise: mathematics and computer science, physics and engineering, media and tech. We’re a community of self-starters who are motivated by the excitement of being at the cutting edge of automation in every part of our organization—from trading, to business operations, to recruiting and beyond. We value openness and transparency, and celebrate great ideas from HRT veterans and new hires alike. At HRT we’re friends and colleagues – whether we are sharing a meal, playing the latest board game, or writing elegant code. We embrace a culture of togetherness that extends far beyond the walls of our office. Feel like you belong at HRT? Our goal is to find the best people and bring them together to do great work in a place where everyone is valued. HRT is proud of our diverse staff; we have offices all over the globe and benefit from our varied and unique perspectives. HRT is an equal opportunity employer; so whoever you are we’d love to get to know you.",
        "url": "https://www.linkedin.com/jobs/view/3934710828"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962487572,
        "company": "Vimeo",
        "title": "Sr. Data Engineer - DataOps",
        "created_on": 1720636921.8150356,
        "description": "We're seeking an innovative, solution-oriented Sr. Data Engineer to join our dynamic Data Ops team. Your mission is to develop, maintain, and scale a sophisticated platform for product and event analytics capable of handling vast amounts of data. This exciting role will see you at the heart of transformative projects, turning complex datasets into accessible insights that drive strategic decisions. As part of our team, you'll be shaping the future of data in our organization, crafting scalable data systems that can keep pace with our rapid growth. We can't wait to meet you if you're passionate about data and ready to push boundaries. Our platform has robust analytics tools that can tell video creators where people are from, where they click, and even track where in a video someone stopped watching—giving you insight into creating engaging content in the future. While working as a peer to both technical and non-technical staff throughout the company, you will drive the improvement process of our products and business operations. You will help define data access and discoverability requirements and work to create infrastructure and services that provide access to event streams. What you'll do: Design, develop and maintain Vimeo’s product and event analytics platform that processes billions of records every day in real-time to enable analytics and event-driven systems Partner with analytics leaders and analysts to ensure adherence to data governance and data modeling best practices Partner with product engineering teams to enhance the efficiency of product analytics clients and data collection mechanisms Contribute software designs, code, tooling, testing, and operational support to a multi-terabyte analytics platform Provide technical leadership to the data engineering team and actively lead design discussions Constantly monitor our data platform and make recommendations to enhance system architecture Work collaboratively with other data engineers, analysts, and business stakeholders to understand and plan technical requirements for projects Prioritize project intake, perform cost/benefit analysis, and make decisions about what work to pursue that best balances our platform’s users, stakeholders, and technology Skills and knowledge you should possess: 5+ years of engineering experience in a fast-paced environment; 3+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud Deep understanding of distributed data processing architecture and tools such as Kafka and Spark Working knowledge of design patterns and coding best practices Experience with and understanding of data modeling concepts, techniques, and best practices Experience with Airflow, Celery, or other Python-based task-processing systems Proficiency in SQL Proficiency in Python or Java Proficiency with modern source control systems, especially Git Experience working with non-technical business stakeholders on technical projects Bonus points (nice skills to have, but not needed): Cloud-based DevOps: AWS or Google Cloud Platform or Azure Experience with Amplitude, Snowplow, Segment, or other event analytics platforms Relational database design Snowflake or other distributed columnar-store databases Basic Linux/Unix system administration skills Familiarity with containerization technologies (e.g., Docker, Kubernetes) Targeted Base Salary Range: $117,000 to $178,000 The base salary range listed above is for candidates located in the U.S., including the New York City metro area. At Vimeo, we strive to hire and nurture amazing talent across the globe. Actual salaries will vary depending on factors including but not limited to experience, specialized skills, internal alignment and a candidate’s home base. Base salary is just one component of Vimeo’s total rewards philosophy. We offer a wide range of benefits and perks that appeal to the variety of needs across our diverse employee base! Other rewards may include bonus or commission, Restricted Stock Units (RSUs), paid time off, generous 401k match, wellbeing resources, and more. About Us: Vimeo (NASDAQ: VMEO) is the world's most innovative video experience platform. We enable anyone to create high-quality video experiences to better connect and bring ideas to life. We proudly serve our community of millions of users – from creative storytellers to globally distributed teams at the world's largest companies – whose videos receive billions of views each month. Learn more at www.vimeo.com. Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We’re proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.",
        "url": "https://www.linkedin.com/jobs/view/3962487572"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Forest Home, NY",
        "job_id": 3964706823,
        "company": "LanceSoft, Inc.",
        "title": "Software Engineer II",
        "created_on": 1720636923.4762871,
        "description": "Overview Provides designs, specifies information systems solutions and highly technical direction in the development of new or existing applications to solve basic to complex problems or enhancements. Serves as a principal application designer for major modifications effectively using analytical and technical skills and available technology and tools in the evaluation of client requirements and processes. Provides solutions that are technologically sound. May complete day-to-day support activities and special projects. Often directs and monitors the activities of less experienced personnel. Primary Responsibilities Complete and oversee basic to complex systems analysis, design and development. Play a key role as an individual contributor on complex projects. Maintain an excellent functional understanding of the supported application(s). Direct and monitor less experienced resources and coordinate development tasks on small to large scope projects. Prepare and manage the technical component of project plans. Participate with other Development, operations and Technology staff in overall systems development direction from technical analysis to user acceptance testing. Prepare and review test data and execute detailed test plans. Complete any required debugging. Evaluate and understand complex interrelationships and effects among programs, interfacing applications and platforms. Provide highly analytical consulting and leadership in identifying and implementing new uses of information technologies to assist business units in meeting strategic objectives. Prepare thorough, clear technical and functional specifications and update systems documentation. Prepare charts, tables and diagrams to assist in analyzing problems. Review documentation prepared by less experienced staff. Prepare and review assessments to include required tasks, estimated time frames and effort for any scope project. Maintain efficient operation and effectiveness of supported applications. Recommend new technology, policies or processes to benefit the organization and improve deficiencies. May lead or participate in technical evaluations of vendor software. Follow and promote use of development standards and procedures. Maintain a good understanding of the business being supported and its functions, processes, operations and strategic direction. May assist in developing expense and capital budgets. Understand and adhere to the Company's risk and regulatory standards, policies and controls in accordance with the Company's Risk Appetite. Identify risk-related issues needing escalation to management. Promote an environment that supports diversity and reflects the *** brand. Maintain M&T internal control standards, including timely implementation of internal and external audit points together with any issues raised by external regulators as applicable. Complete other related duties or projects as required, which may include playing a lead role in due diligence, cost/benefit analysis or business study activities. Scope Of Responsibilities The position works under supervision of the Technology Team Lead. The job holder is competent to work independently on all high level systems analysis and technical phases of development. The position is capable of managing the activities of others on a project basis for small to large scope efforts and may lead project activities. The job holder monitors staff performance on assigned projects relative to their overall abilities and effectiveness in completing projects within schedules. The position interacts with senior management, other technology personnel, clients and vendors. The job holder provides backup to higher management as required and may be called on to serve as a technical representative on committees, ad-hoc projects, etc. Education And Experience Required Minimum of an Associates degree and 5 years systems analysis/application development experience, or in lieu of a degree, a combined minimum of 7 years higher education and/or work experience, including a minimum of 5 years systems analysis/application development experience. Familiar with application development software and hardware platforms. Proficiency with personal computers as well as pertinent project management, word processing and spreadsheet software. Capable of working on multiple projects of a complex nature. Excellent problem-solving skills to assist in issue resolution. Strong verbal and written communication skills, with prior experience presenting to the target audience. Strong organizational and time management skills. Detail-oriented. Strong lateral thinking skills. Experience coordinating between Applications and business units. Experience recommending and implementing systems solutions. Experience driving project milestones and delivery dates. Education And Experience Preferred Good understanding of the Bank's application framework. Subject matter expert in business with knowledge or experience utilizing application/system being supported. Advanced understanding of applications supported with a sound knowledge of interfacing/integrated applications. Ability to work in a team environment as well as autonomously. Ability to multitask for various components of complex projects. Action-oriented. Pro-active. Advanced knowledge and focus of the entire system to work on projects outside of normal business-as-usual (BAU).",
        "url": "https://www.linkedin.com/jobs/view/3964706823"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3905249520,
        "company": "Ropes & Gray LLP",
        "title": "Senior Data Engineer",
        "created_on": 1720636925.2296221,
        "description": "About Ropes & Gray Ropes & Gray is a preeminent, global law firm. The firm has been ranked in the top-three on The American Lawyer's prestigious \"A-List\" for seven years and is ranked #1 on Law.com International's \"A-List\" in the U.K.—rankings that honor the \"Best of the Best\" firms. The firm has approximately 2,500 lawyers and professionals serving clients in major centers of business, finance, technology, and government in Boston, Chicago, Dublin, Hong Kong, London, Los Angeles, New York, San Francisco, Seoul, Shanghai, Silicon Valley, Singapore, Tokyo and Washington, D.C. The firm has consistently been recognized for its leading practices in many areas, including asset management, private equity, M&A, finance, real estate, tax, antitrust, life sciences, health care, intellectual property, litigation & enforcement, privacy & cybersecurity, and business restructuring. Ropes & Gray is an equal opportunity employer. Overview A successful Senior Data Engineer must possess superior analytical skills and be detail-oriented. This role requires the ability to communicate effectively as part of a larger team within the finance technology department. Additionally, you will need to explain complex technical concepts to non-technical staff. Since development of data models and logical workflows is common, a Senior Data Engineer must also exhibit advanced visualization skills, as well as creative problem-solving. Responsibilities Design, develop, implement, and maintain business intelligence, dashboard, and reporting solutions for the enterprise Design, develop, implement, and maintain enhancements to the data warehouse, master and reference data management capabilities, data integration layer, and enterprise data services shared across applications and reporting Partner with business sponsors, senior management and across IS teams to understand, document, and propose business intelligence and reporting solutions Develop and maintain accurate project and task estimates Stays current on technology best practices, trends in UI/UX Continuously drives process improvements and technical innovations Provide technical expertise and guidance on software development tools. technology, frameworks, and development methodologies Understand our business comprehensively, including the applications' functional and non-functional requirements and their impact on staffing Provide technical expertise to help resolve development and application issues, resolve performance problems, and drive career development As a member of the Data Management team, deliver high quality data management solutions through proactive testing and on-going quality monitoring Actively engage with business sponsors and stakeholders to review, provide feedback, and understand business requirements Identify, champion, and lead platform improvement opportunities of processes and tooling Actively participant in program development, be willing to investigate and present topics to the rest of the team Develop and maintain solutions adhering to business processes with defined data quality rules and bi-directional workflow integration with other data platforms Mentor junior developers on learning new technologies and approaches to data management All other duties as assigned Essential Capabilities Ability to maintain strict confidentiality of the firm’s internal and personnel affairs as well as those of our clients Customer service focused with internal and external clients with ability to develop effective partnerships across the organization Ability to organize, plan, and carry out multiple concurrent objectives or activities, and effectively make judgments in prioritizing and time allocation in a high-pressure environment Ability to commit to and deliver on deadlines Appreciation of front-end UI aesthetics, functionality, design, and development Growing into BI Solutions Lead experience, strong work ethic, and analytical skills Excels in an innovative, intellectually challenging, and fast-paced environment Excellent communication skills (written & verbal) and be equally effective interacting with both business and IT professionals Strong leadership and interpersonal skills Legal services or professional services experience a plus Qualifications Bachelor's degree in Computer Science, Information Systems, or related field; or equivalent work experience A minimum of 7+ years' software development experience, with experience in .NET, C#, Asp.net, and MVC Minimum 7 years of experience in business intelligence and report development (4 years within Microsoft BI Stack) Experience working with Java Script frameworks and third-party components. Angular, React and Type Script is a plus 3 years of cloud technology experience, preferably with the Microsoft Azure data management and development platform Must have an in-depth understanding and experience with Front-End and Back-End development and databases Strong experience developing Windows, Apple, cloud-based applications; in addition to development of API integration with APl's, and other webhooks and services Proficient in MS SQL Server 2019 or later and related technologies (SSIS, SSRS, SSAS, MDM) Experience building data pipelines using programing languages such as .NET, Python, Java, Scala, or similar technologies. Experience with development, data management, and solution deployments in both on-prem and cloud technology platforms Experience with TFS or similar technology used for work management and coding repositories Strong troubleshooting and performance tuning skills - should be able to identify and resolve performance issues involving complex code Demonstrated understanding of relational and multi-dimensional database design and architecture Demonstrated ability to develop front-end data gathering, reporting and analytical solutions that meet business need Development experience with Tableau 10, MicroStrategy, PowerBI, Profisee a plus Familiarity with Redgate, Git, Alteryx, Python, APIs a plus Compensation And Total Rewards Package Ropes & Gray is proud to offer a comprehensive Total Rewards package to our business support team members. The firm also offers comprehensive health and well-being benefits, personal and professional development, career growth opportunities and a collegial and supportive culture. The anticipated pay range for this role is Boston: $100,000 - $151,000, NY: $105,000 - $158,000 which represents our good faith and reasonable estimate of the starting salary range at the time of posting. In addition, this role is eligible for a discretionary bonus based on performance. The actual offered rate for this position will be determined based on job-related, non-discriminatory factors, including qualifications and experience, geographic location, education, external market data and consideration of internal equity. Working Conditions This position requires hybrid on-site presence as an essential function of the role. Consistent and predictable on-site presence is required for ongoing business continuity, professional development and effective collaboration with colleagues and management.",
        "url": "https://www.linkedin.com/jobs/view/3905249520"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3922241966,
        "company": "Traba",
        "title": "Software Engineer (Frontend)",
        "created_on": 1720636927.2767022,
        "description": "Traba is a technology company that enhances the productivity of the light industrial supply chain. We connect businesses with vetted workers to meet their staffing needs by leveraging location monitoring, predictive algorithms, machine learning, AI, computer vision, and other advanced technologies. Our mission is to empower both businesses and workers to reach their full productivity and potential. We’re proud to be backed by some of the world’s best investors, including Founders Fund, Khosla Ventures, and General Catalyst. We are seeking an experienced & entrepreneurial front-end engineer to join the founding team to help build our core suite of products—mobile apps for both workers & business, and web platforms for our business customers and our internal Ops team. You'll partner with our CTO to help own product decisions, iterate on the product roadmap, and architect & build our foundational tech platform. About You: Voracious learner. You love diving into new areas and exploring new languages, frameworks, and technologies, and can discuss product with a UX designer one minute and deployment infrastructure with tech leads the next. Value clear communication. You recognize the importance of clear communication, documented planning, and transparent, frequent feedback. Sweat the small stuff. You have strong opinions on design patterns, IDEs, tabs vs. spaces—you understand that how you do one thing is how you do everything, so you care about the details. Deep expertise building pixel-perfect, performant web applications. You have designed and built performant, scalable applications, and have expertise in client side state management, responsive design, and frontend tooling. You Will: Lead the development of our web & mobile applications, guiding other engineers as needed Establish best practices in code reusability and build processes for our frontend monorepo Collaborate with product & design to build a best-in-class user experience Build analytics & monitoring to help understand our user experience & application health Contribute in a ton of other ways to a scrappy founding team building the future of flexible light industrial staffing! You Have: 3+ years experience with Typescript/Javascript, and React or React Native A track record of shipping amazing products Pixel-perfect attention to detail Experience building APIs is a plus Experience working in an early-stage engineering team, working through ambiguity, and being a self-starter A passion for helping people find meaningful work that works for them Benefits: 📈 Start-up equity 💰 Competitive Salary 🩺 100% Paid health, dental & vision coverage 🍽️ Dinner Provided via Grubhub & stocked kitchen for NY employees 🚍 Commuter benefit 🎤 Team building events 🏋🏽 Gympass Benefit 🌴 Flexible PTO ✚✚ Additional: One Medical Membership, Gympass, HSA via Optum, Talkspace, HealthAdvocate, Teledoc Health Salary Range Details The compensation range for this position is set between $140,000 and $170,000, reflecting our market analysis and other relevant considerations. However, exceptions may be made for candidates with qualifications that significantly differ from those outlined in the job description. Equal Opportunity Employer Traba is dedicated to promoting Equal Opportunity employment practices. We evaluate all applicants without discrimination based on race, color, religion, creed, national origin, age, sex, gender, marital status, sexual orientation and identity, genetic information, veteran status, citizenship, or any other characteristics that are legally protected by local, state, or federal regulations. We encourage applicants from a variety of backgrounds, experiences, and skill sets. Our Values Dream Big - We are on a path to change the world for the better. We create and communicate a bold direction that inspires a life-changing vision. We don’t sacrifice long-term value for short-term results. Olympian’s Work Ethic - Changing the world never comes easy. We work harder, longer, and smarter, not just two out of three. We put everything we have on the field. Growth Mindset - We confront the toughest challenges head-on and persevere. Sometimes we fail, but we brush ourselves off, adapt, learn, and push forward with resilience. Customer Obsession - We go the extra mile for our workers and businesses. We remain focused on delivering high-quality products and services that solve this massive and overlooked industries’ problems What is light industrial labor? Light industrial flexible staffing is a $50B labor market that encompasses entry-level jobs in warehouses & distribution centers. These workers pack boxes, load trucks, and manage warehouse operations to keep supply chains running at peak efficiency. Compensation Range: $120K - $160K",
        "url": "https://www.linkedin.com/jobs/view/3922241966"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888438931,
        "company": "PSRTEK",
        "title": "GCP Lead Data Engineer- REMOTE",
        "created_on": 1720636929.191956,
        "description": "Position:- GCP Lead Data Engineer Type:- Remote Hands on experience working in GCP services like Big Query, Cloud Storage (GCS), cloud function, cloud dataflow, Pub/sub, Cloud Shell, GSUTIL, Big Query, Data Proc, Operations Suite (Stack driver). Performed in-memory data processing for batch, real-time, and advanced analytics",
        "url": "https://www.linkedin.com/jobs/view/3888438931"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3844344336,
        "company": "Norgate Technology",
        "title": "Software Engineer",
        "created_on": 1720636930.8859181,
        "description": "Long Term Contract Responsible for support activities for Murex DEV and TEST environments (Refreshes, Debugging, BAU tasks) Skills: Skills Unix/Linux Knowledge Shell/Bash/Python Scripting Relational Database and SQL Knowledge (Sybase preferred) MX.3 Environments Management/Deployment/Monitoring (L1/L2) MX.3 Technical Architecture Knowledge Keywords Education: Education Bachelor of Engineering or Science in Computer Science Skills and Experience: Required Skills SHELL SCRIPTING RELATIONAL DATABASE DEPLOYMENT SYBASE TECHNICAL ARCHITECTURE Additional Skills PYTHON SCRIPTING SQL UNIX",
        "url": "https://www.linkedin.com/jobs/view/3844344336"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3933182994,
        "company": "Addepar",
        "title": "Sr. Software Engineer - Data Intelligence",
        "created_on": 1720636932.4444969,
        "description": "Who We Are Addepar is a global technology and data company that helps investment professionals provide the most informed, precise guidance for their clients. Hundreds of thousands of users have trusted Addepar to empower smarter investment decisions and better advice over the last decade. With client presence in more than 40 countries, Addepar’s platform aggregates portfolio, market and client data for over $6 trillion in assets. Addepar’s open platform integrates with more than 100 software, data and services partners to deliver a complete solution for a wide range of firms and use cases. Addepar embraces a global flexible workforce model with offices in Silicon Valley, New York City, Salt Lake City, Chicago, London, Dublin, Edinburgh, Scotland and Pune, India. Marketplace and brokerage services provided by Acervus Securities, Inc., an SEC registered broker‑dealer and member FINRA / SIPC. The Role The finance industry generates immense amounts of data, crafting a strong demand for sophisticated data platform solutions. While the data and platforms remain sophisticated, the data consumption can be revolutionized through exceptionally easy access enabled by AI and modern data architecture. Join Addepar Data eXchange team as one of the early members charged with building a world class financial data platform! We are seeking Software Engineers with a proven track record of excellence to join our Engineering team. In this role, you will collaborate with a diverse and ambitious team to craft, develop, and evolve a data platform solution that empowers the world's leading investment professionals on top of the portfolio, market, and client data for over $6 trillion in assets at Addepar. Addepar takes a market-based approach to pay. A successful candidate’s starting pay will be determined based on the role, job-related skills, experience, qualifications, work location, and market conditions. The range displayed on each job posting reflects the minimum and maximum target base salary for roles in Colorado, California, and New York. The current range for this role is $125,000 - $195,000 + bonus + equity + benefits. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Additionally, these ranges reflect the base salary only, and do not include bonus, equity, or benefits. What You Will Do Participate in the design and development of a strategic product for Addepar. Be responsible for all engineering aspects of a new product development including product features, infrastructure, CI/CD, data, and services. Write clean, efficient, and maintainable code that's also scalable and extensible. Innovate in financial data presentation and accessibility to transform client consumption with AI and set new industry standards. Who You Are Bachelor's degree in Computer Science or a related field, or equivalent experience. 4+ years of software engineering experience. Proficient in backend development, specifically with Python or Java. Experienced in data processing and analysis using SQL, PySpark, or similar frameworks. A rapid learner with robust analytical and problem-solving abilities. Previous work with major cloud services (AWS, GCP, Azure) and familiarity with Databricks and AI are significant pluses. Equal Opportunity Employer Statement Addepar values diversity and inclusion in our workplace. We strive to foster an environment that embraces a wide range of ideas, experiences, perspectives, backgrounds, and identities, which in turn fuels our ability to develop innovative solutions. We are committed to creating a welcoming atmosphere where everyone feels a sense of belonging. Reasonable Accommodation Statement We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. Our Values Act Like an Owner - Think and operate with intention, purpose and care. Own outcomes. Build Together - Collaborate to unlock the best solutions. Deliver lasting value. Champion Our Clients - Exceed client expectations. Our clients’ success is our success. Drive Innovation - Be bold and unconstrained in problem solving. Transform the industry. Embrace Learning - Engage our community to broaden our perspective. Bring a growth mindset. In addition to our core values, Addepar is proud to be an equal opportunity employer. We seek to bring together diverse ideas, experiences, skill sets, perspectives, backgrounds and identities to drive innovative solutions. We commit to promoting a welcoming environment where inclusion and belonging are held as a shared responsibility. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. PHISHING SCAM WARNING: Addepar is among several companies recently made aware of a phishing scam involving con artists posing as hiring managers recruiting via email, text and social media. The imposters are creating misleading email accounts, conducting remote “interviews,” and making fake job offers in order to collect personal and financial information from unsuspecting individuals. Please be aware that no job offers will be made from Addepar without a formal interview process. Additionally, Addepar will not ask you to purchase equipment or supplies as part of your onboarding process. If you have any questions, please reach out to TAinfo@addepar.com.",
        "url": "https://www.linkedin.com/jobs/view/3933182994"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3955921372,
        "company": "Arrow Search Partners",
        "title": "Data Engineer",
        "created_on": 1720636934.200397,
        "description": "About The Company Our client is a large savings bank with over $20 billion in assets catering to individuals and business in New York and New Jersey. The Data Engineer is responsible for contributing to a wide range of database development, including but not limited to stored procedures, functions, data analyses, cleansing, validations, reporting, and ETL. Responsibilities Perform SQL database development, leveraging strong knowledge of Database design Utilize SSIS to build data extracts from specifications, test, and automate Code and automate validations to ensure data quality Map data as needed in order to create extracts Develop sophisticated analyses, reports, and dashboard Contribute to broader enterprise data management decisions Requirements Bachelor’s degree required 5+ years of Data Engineering experience Strong proficiency in SQL Server development and structure (SSIS) Experience in creating ETL packages on SQL Server Scripting language experience (C# or Python) Some knowledge of C# and scripting languages Proficiency with two out of the three: SSRS, Tableau, Power BI Knowledge of data types, errors, data comparison, and data cleaning Salary Range $135,000-$175,000",
        "url": "https://www.linkedin.com/jobs/view/3955921372"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959856101,
        "company": "Goldman Sachs",
        "title": "Software Engineer | VP | New York",
        "created_on": 1720636935.8849163,
        "description": "Job Description MORE ABOUT THIS JOB Please note division and function examples are representative of opportunities common for this skill-set. The list is not exhaustive, and availability of open roles is determined based on business need. Specific roles will be confirmed through the interview process. Responsibilities Software engineers primarily focus on software design and development. This is meant to cover most programming positions in Engineering, and include positions that were previously considered business software engineers, platform engineers, and quality assurance engineers. Combine the best open source software, databases, cloud solutions, and programming languages, to solve problems and provide accurate, complex, scalable applications that help our business and clients gain new insights. As a software engineer, you are the change agents that transform Goldman Sachs by applying your technical know-how. Be a part of our embedded engineering teams, that work as a unit with our business partners. Collaborate with trading, sales, asset management, banking, finance and others, to build and automate solutions to keep our firm’s position on the cutting edge. Or, join our core engineering teams, and elevate all of our businesses by providing reliable, scalable platforms for data engineering, machine learning, networking, developer tooling, collaboration and more. Innovate with UI/UX designers, data scientists, cloud engineers, and more in a collaborative, agile environment where your enthusiasm to take on new problems and learn will have an immediate impact. Basic Qualifications A successful candidate will possess the following attributes: Bachelor’s Degree 7-12 years of prior work experience in a relevant field. Proficient to advanced skills with MS Office (Excel, PowerPoint, Word, Outlook) Highly organized with exceptional attention to detail and follow-through Strong ability to manage multiple projects with competing deadlines Team player with positive attitude and strong work ethic Strong communication skills (written and verbal) Ability to work in a fast-paced environment Ability to adapt quickly to a variety of industries and businesses Ability to self-direct, analyze and evaluate and form independent judgments Ability to effectively interact and build relationships with senior management and global stakeholders Commercially savvy with ability to exercise discretion with respect to highly confidential/sensitive information Integrity, ethical standards and sound judgment Experience in some of the following is desired and can set you apart from other candidates: UI/UX development API design, such as to create interconnected services, message buses or real time processing, relational databases knowledge of the financial industry and compliance or risk functions, influencing stakeholders. About Goldman Sachs At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world. We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers. We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html Salary Range The expected base salary for this New York, New York, United States-based position is$150,000-$250,000. In addition, you may be eligible for a discretionary bonus if you are an active employee as of fiscal year-end. Benefits Goldman Sachs is committed to providing our people with valuable and competitive benefits and wellness offerings, as it is a core part of providing a strong overall employee experience. A summary of these offerings, which are generally available to active, non-temporary, full-time and part-time US employees who work at least 20 hours per week, can be found here . © The Goldman Sachs Group, Inc., 2023. All rights reserved. Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",
        "url": "https://www.linkedin.com/jobs/view/3959856101"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3971285296,
        "company": "TekWissen ®",
        "title": "Data Engineer II",
        "created_on": 1720636937.5827181,
        "description": "Overview TekWissen Group is a workforce management provider throughout the USA and many other countries in the world. Our client is a company operating a marketplace for consumers, sellers, and content creators. It offers merchandise and content purchased for resale from vendors and those offered by thirdparty sellers. Job Title: Data Engineer II Duration: 5 Months Location: New York, NY 10018 Job Type: Contract Work Type: Hybrid Job Description Impact Our retail business teams work with a massive array of vendors and business financial performance metrics to expand selection and drive costs lower. Given the rapid growth of our business, this requires our category leaders, financial analysts, site merchandisers and vendor managers to quickly analyze vendors, categories and brands, diving deep into data showing business efficiency down to the unit sale level. The technology that enables this has huge visibility and impact and is critical to Client's continued profitability and growth. Innovation We're working on the future. If you are seeking an environment where you can drive innovation. If you want to apply state-of-the-art software technologies to solve real world problems. If you want the satisfaction of providing visible benefit to end-users in an iterative fast paced environment, this is your opportunity. The responsibilities of this role will be key in paving the future of Client Retail and transforming how we do business. Opportunity You will be part of a team of creative, top-notch software developers to work hard, have fun, and make history. Software engineers at Client are more than just order takers; they see a problem and leverage innovative technology to address it. You will be working with very large data sets, well beyond the scalability limits of conventional relational databases. We're looking for people who innovate, love solving hard problems, and never take \"no\" for an answer. Responsibilities As a Data Engineer you will be working in one of the complex data warehouse environments. You will be developing and supporting the analytic technologies that give our customers timely, flexible and structured access to their data. Be part of a high performance, high profile team with a complete, entirely localized business charter to enhance business profitability for the Client Consumer business. Research new technologies regularly and invest for the future of our scalability Reason For Request Adding support to current team to work on current Large Scale project to deliver priorities for targeted Q3 and Q4 Dates. Surrounding Team And Key Projects These four Data Engineer contractors will help completing integration of P&L data within Ripple to ensure 2K+ decision makers within Client have timely and comprehensive P&L data via Turismo. Project is to ensure the migration of the P&L data to Client’s Chronical Platform by targeted Q3/Q4 dates. Daily Schedule / OT Expectations M-F 9-5 / Up to 5 HRS / WK OT Possible due to supporting West Coast Clients Interaction With Team Heavily Collaborative role with immediate team, Clients and other support teams. Typical Task Breakdown Developing and supporting the analytic technologies that give our customers timely, flexible and structured access to their data. Research new technologies regularly and invest for the future of our Desired Leadership Principles Deliver Results Innovate Think Big Degrees / Certs And/or Experience Required 3+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions. Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases) Performance Indicators Deliverable Schedule provided – hitting target dates Top 3 Must-have Hard Skills Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions. Experience in Craddle, SQL, EMR, Quick Site, and Python Experience with data modeling, warehousing and building ETL pipelines TekWissen® Group is an equal opportunity employer supporting workforce diversity.",
        "url": "https://www.linkedin.com/jobs/view/3971285296"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Port Chester, NY",
        "job_id": 3919333334,
        "company": "The Shade Store",
        "title": "Senior Data Engineer",
        "created_on": 1720636939.2584114,
        "description": "Job Details Job Location Port Chester NY - Port Chester, NY Description Position: Senior Data Engineer (Contractor or Full Time) Location: Currently Remote / Port Chester, NY Position Reports to: SVP, Development About The Shade Store At The Shade Store, we have handcrafted the finest Shades, Blinds and Drapery for 75 years. We believe designing beautiful custom window treatments should be an effortless experience, so we offer outstanding services to help our customers every step of the way, from inspiration to installation. WHY WORK AT THE SHADE STORE We set out to create a company culture that is enjoyable, rewarding, and where there is continuous upward mobility and growth opportunity. If you work hard, give the company your all, use good judgment, and have a positive attitude then the sky’s the limit. In return, there are numerous perks and benefits including: Competitive compensation Comprehensive Medical, Dental and Vision benefits Generous Paid Time Off inclusive of holidays and flexible floating holidays 401k retirement plan with company matching THE POSITION: Senior Data Engineer As The Shade Store continues our aggressive growth, it has become ever more apparent that we need to continue to grow and scale this very important team. We’re committed to building an excellent team of collaborators and innovators. Our team is ambitious and passionate; the environment is close-knit, fast paced and fun. We are a company that values doers over talkers and mentors over managers. If you work well with people and most importantly have the technical skill set to help support the business in the functions described above -- then we would love to hear from you. The position will report directly to the SVP, Development and will be part of the Development team responsible for building and scaling our existing data and reporting operational functions that support and inform strategic decision making for The Shade Store. The role requires hands-on technical data skills, and good communication skills for collaboration with the rest of the development team and business stakeholders in other departments. RESPONSIBILITIES: Design, build, develop, deploy and maintain applications using the Looker and Snowflake business intelligence platforms. Develop and optimize large-scale batch and real-time data pipelines that ingest structured and unstructured data from a variety of sources. Experience loading and unloading data with different file types (such as CSV, JSON, XML, etc) Hands-on experience with LookML and SnowSQL (writing procedures) Strong experience with SQL language and data warehousing architecture Develop and maintain pipelines using DBT Experience with ETL technologies and integrations Experience using code versioning and build processes (GIT) Able to perform data quality checks and validation rules and various stages of processing. Develop reporting solutions to challenging complex business problems. Work closely with the business stakeholder team and shared development resources across all phases of projects Lead and/or participate in project efforts using an Agile development methodology. Collaborate with QA to develop comprehensive and appropriate test strategies for each release POSITION REQUIREMENTS: Bachelor’s degree in computer science, Engineering or a related subject, or equivalent experience 5+ years in a data engineer or SQL-heavy data analyst role Track record of success in building new data engineering processes with a wide range of data sets from various sources. Demonstrated ability to work across disparate teams to achieve consensus on key business decisions. Expert-level SQL skills. Advanced knowledge with Looker, DBT, Snowflake and/or equivalent tools. Willingness to roll up your sleeves and fix problems in a hands-on manner. Intellectual curiosity and research abilities. Demonstrated knowledge of modern SDLC, Agile/Scrum, Kanban etc. Ability to organize and manage multiple tasks and priorities Strong communication skills with the ability to cross collaborate amongst internal departments Self-motivated and willing to \"do what it takes\" to get the job done NICE TO HAVES: Experience building on AWS Expert level with basic tools like Excel MySQL tuning and database optimization THE SHADE STORE offer is contingent upon: Proof of legal authorization to work in the United States for The Shade Store, which will be confirmed by E-Verify within three business days of your hire date The base salary range for this position is $150-$170k, commensurate with experience. The Shade Store provides equal employment opportunities to all employees and applicants without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",
        "url": "https://www.linkedin.com/jobs/view/3919333334"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Chestnut Ridge, NY",
        "job_id": 3969047431,
        "company": "Teledyne Technologies Incorporated",
        "title": "Software/Firmware Engineer",
        "created_on": 1720636940.9490857,
        "description": "Be visionary Teledyne Technologies Incorporated provides enabling technologies for industrial growth markets that require advanced technology and high reliability. These markets include aerospace and defense, factory automation, air and water quality environmental monitoring, electronics design and development, oceanographic research, deepwater oil and gas exploration and production, medical imaging and pharmaceutical research. We are looking for individuals who thrive on making an impact and want the excitement of being on a team that wins. Job Description Teledyne LeCroy designs, manufactures and markets state of the art test and measurement equipment. Originally founded as LeCroy Corporation, the company was formed in 1964; the company was acquired by Teledyne Technologies (NYSE: TDY) in 2012 and now operates as a wholly owned subsidiary. Our Chestnut Ridge, NY (Rockland County) office is looking to add a SOFTWARE/FIRMWARE ENGINEER with solid software skills to our Product Development Group. Are you a problem solver with eagerness to learn and contribute to the evolving world of electronics test solutions? Here at Teledyne LeCroy, Product Development Group develops the most extensive range of test solutions. You will be working in a software team which designs digital oscilloscope software, device driver and firmware and supports multiple cross-functional teams. Software/Firmware Engineer - - R&D Based Opening Acquiring in depth knowledge of digital oscilloscope at functionality level as well as design level. Design and implement functional software drivers for digital oscilloscope to control complex electronics Design software that will run on our digital oscilloscopes to extract general purpose and application specific measurements from the acquired signals. Design measurement software to automatically test customer systems to serial data standards using Teledyne LeCroy oscilloscopes and bit error rate testers. Devise test scripts to provide automated testing for validation and regression testing of software. Working in a team environment to debug, diagnosis and fix various software issues reported by customers. Working in a team environment to develop various software application/features for main various product line. Qualifications 2+ years of experience with Bachelor of Science in Computer Science or Electrical Engineering Master of Science in Computer Science or Electrical Engineering Development experience in C, C++, and Python programming Knowledge of operating system and device driver Knowledge of microcontroller and firmware programming principles Knowledge of digital and analog hardware electronics Knowledge of electronics test equipment like oscilloscope and logic analyzer Must be an inquisitive problem solver and a proactive thinker Ability to work in a team environment Must have good communication skills Desirable Experience of Windows based application programming Experience of Microsoft Windows kernel level drivers Knowledge of ATL/COM Experience with Win CE or Windows Embedded platform Salary Range $60,500.00-$80,850.000 Pay Transparency The anticipated salary range listed for this role is only an estimate. Actual compensation for successful candidates is carefully determined based on several factors including, but not limited to, location, education/training, work experience, key skills, and type of position. Teledyne and all of our employees are committed to conducting business with the highest ethical standards. We require all employees to comply with all applicable laws, regulations, rules and regulatory orders. Our reputation for honesty, integrity and high ethics is as important to us as our reputation for making innovative sensing solutions. Teledyne is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age, or any other characteristic or non-merit based factor made unlawful by federal, state, or local laws.",
        "url": "https://www.linkedin.com/jobs/view/3969047431"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3762874508,
        "company": "Fabric by Gerber Life",
        "title": "Software Engineer - Growth",
        "created_on": 1720636942.9088824,
        "description": "From electronic signatures to underwriting, engineering is at the core of everything we build. We aim to create humane software that includes only the essential complexity. Like software, we are a constant work in progress, and we believe that personal growth comes from making mistakes and exploring thorny problems. The quality of our work is driven by the diversity of our individual backgrounds and experiences. As a Software Engineer in Growth, you will join a team in building a fleet of free tools - such as Wills, Account Sharing, Emergency Savings, and Rainy Day Funds - to help parents stop procrastinating and start tackling their long term financial to-do lists. You are self-motivated, can wear many hats, and are excited to ship code across the stack, both on the web and in our mobile app, that solves challenging business problems and brings joy to our customers. Come join us as we re-make a $650 Billion industry and work to improve the lives of millions of families. Your role at Fabric: Ship code across the stack, quickly and reliably. Participate in design and implementation of features to grow Fabric's core platform. Write tools and introduce approaches that we didn't know we needed, helping us deliver value more quickly and efficiently. Contribute to an ever-evolving engineering culture. Help your fellow engineers grow in new and exciting ways! What you'll bring to the table: 5+ years of software development experience in a product-centric environment. Expertise building highly performant User Interfaces and the scalable, reliable APIs that hydrate them. Effective communication skills used in technical problem solving. Compassion, both for Fabric's customers and your fellow teammates. Willingness to make mistakes. Enthusiasm for engineering and technology. Bonus points if you have: Experience in a JavaScript or TypeScript environment. Experience with modern, functional UI paradigms. We use React. Experience building and managing distributed systems with AWS. We use services like Lambda, Cognito, DynamoDb, S3, SQS, SNS, andStep Functions. Knowledge of financial and insurance products. Salary Range: $140,000 - $180,000",
        "url": "https://www.linkedin.com/jobs/view/3762874508"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3860723048,
        "company": "Continua AI, Inc.",
        "title": "Systems Software Engineer",
        "created_on": 1720636944.5165586,
        "description": "As a Systems (backend) Software Engineer, you will be responsible for designing and developing the core systems that power our products. You will work closely with mobile and ML engineers to create a seamless experience for users. Responsibilities: Develop and maintain efficient backend services to support our mobile applications Implement secure and reliable data storage solutions Ensure service availability through real-time monitoring and high quality incident response Integrate with and optimize usage of 3rd-party services and APIs Create and maintain scalable data pipelines for ML engineers Qualifications : Bachelor's, Master's, or Ph.D. in Computer Science, Software Engineering, or a related field Strong proficiency in at least one programming language such as Python, Java, or C# Solid understanding of data structures, algorithms, and software design principles Experience with cloud computing platforms such as AWS, Azure, or GCP Understanding of DevOps practices and CI/CD pipelines Excellent problem-solving and analytical skills Strong communication and collaboration abilities Nice-to-haves: Knowledge of front-end development technologies (HTML, CSS, JavaScript) for full-stack collaboration Experience integrating with Foundation Model training and inference APIs from Google, Microsoft, or Amazon Experience building something from nothing, either at a startup or in a successful side project. If you are passionate about building innovative new products, and you’re eager to work in a dynamic startup environment, please send us your resume, we would love to hear from you.",
        "url": "https://www.linkedin.com/jobs/view/3860723048"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3927673986,
        "company": "JobDiva Middleware Test Company",
        "title": "Software Engineer",
        "created_on": 1720636946.2724724,
        "description": "The successful candidate will be Remote - Working from home in the United States, OR working in our corporate offices in New York, New York. Please note at least 1 year of Python experience is required for this role. Iteris is looking for a motivated individual who wants to help make transportation systems safer and more efficient. This individual will work within Iteris’ Transportation Analytics team, which is a core group of software engineers, data scientists, designers, and product managers who develop software products, dashboards, and reports to help our public agency clients better understand, plan, and manage the transportation network. This opportunity is for a mid-level software development role in one of Iteris’s offices or at a remote location. What Makes This Position/Workplace Exciting: Do you ever get stuck at a series of red lights or find traffic problems and want to do something about them? And do you like making dynamic applications using modern tech stacks? Then come work for Iteris to help make traffic lights more green and traffic flow more reliable. Be immersed in some of the most exciting big data areas, including intersection performance, traffic reliability, connected vehicles and smart cities. Have a real impact as a core member of a small team, working to solve problems that impact lives and convert your programming skills into tools to help travelers and agencies. Work in a highly collaborative and agile software development environment, coordinating closely with teammates and regrouping through daily scrums. Be part of an amazing company culture – we’ll look to you to bring fresh ideas and new perspectives to our existing products. Responsibilities: Develop and enhance Iteris leading transportation analytics products that collect, analyze, and visualize traffic data from a variety of sources to help cities and states make smart investment decisions. Support exploratory analysis of new datasets and develop proofs of concept for new analyses, features, and products Collaborate with product and technical staff on product roadmap and R&D planning Qualifications Required: 4+ years software development experience 2+ years Python experience Strong relational database skills with PostgreSQL and/or Redshift (preferred), or MySQL or Experience with developing web applications deployed to the cloud (AWS preferred) Ability to work directly with Subject Matter Experts to translate requirements into specifications and code Qualifications Desired: Django ORM experience, or solid familiarity with ORM concepts in another stack RESTful API development experience [website] Django Rest Framework) Experience in an Agile development methodology including best practices such as automated tests, continuous integration, shared ownership, pull requests and code reviews Experience working in small teams in a startup-like environment Experience with various AWS application technologies such as Lambda, API Gateway, Kinesis Experience with developing and/or supporting CI/CD pipelines [website] Bamboo/Jenkins, AWS ECS, Elastic Beanstalk, Load Balancer, Docker, etc.) Experience with NoSQL data stores [website] Redis, ElasticSearch) Experience with Pandas, Dask, or NumPy Experience or interest in map based data Experience or interest in data analytics and machine Type: Full-time",
        "url": "https://www.linkedin.com/jobs/view/3927673986"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3952423328,
        "company": "Maybern",
        "title": "Software Engineer II",
        "created_on": 1720636947.9277816,
        "description": "Who We Are Maybern is transforming the way private fund managers effectively manage their funds through cutting edge technology. Maybern is founded by top engineering experts with deep knowledge of the fund management space. Private funds manage $15T in capital and are growing at 20% YoY, but with increasing regulatory scrutiny and investor demands for transparency, the need for world class software to help private fund CFOs is crucial. This is where Maybern comes in. We are equipping fund managers with intuitive, flexible fund management software, enabling private investment managers to focus on what they do best: driving returns for their investors. We are backed by leading venture capital firms and a large number of strategic investors. Maybern is an NYC based company with a strong in-office culture to drive collaboration, and we are looking to make strong additions to our team. What We’re Looking For We are looking for a seasoned product-focused engineer that is not afraid to get into the weeds in order to drive solutions on our most challenging projects. The problems we solve are highly complex and require a product driven mindset, expert level technical skills and business acumen to drive the best outcomes for our customers. Ideally you have spent a few years working as a technical lead on system design and backend development. What You'll Do To thrive in this role, you must be an entrepreneurial engineer who enjoys getting into the weeds. Build: Build, test, and deploy software in a continuous manner Lead: Architect, scope, and build core parts of our system from the ground up Partner: Work closely with problem experts to design elegant, flexible solutions that solve our early clients' problems while being forward-thinking about future use cases This Could Be a Great Fit If You... Have 2+ years of experience working with server-side languages (e.g. Python, Ruby, Java) and web frameworks (e.g. Django, Rails) Experience with one of the following Javascript frameworks is desired: Angular, React, Ember, and Backbone. React preferred Solid grasp of relational databases and transactions. Knowledge of platform/cloud technologies and distributed systems. AWS experience is a bonus. Are obsessed with details and excited to \"get into the weeds\" Have excellent written and verbal communication skills Capacity to work in high growth, fast-paced environments, and can adapt to change Benefits We offer a competitive salary + equity package, comprehensive benefits, and a flexible family-friendly work environment. Some of our perks include: Competitive Compensation (base salary between $150k-$180k and equity) Comprehensive healthcare benefits Covered medical, dental, vision - 100% covered by Maybern Health savings accounts, and more Personalized care and tools to make your life easier, such as: One Medical (on-demand primary care) Teladoc (virtual healthcare) TalkSpace (online mental health therapy) KindBody (fertility care) Family-Friendly policies Paid parental leave Family planning benefits for you or your eligible dependents (covered membership to KindBody) Flexible schedule Unlimited PTO / sick leave WFH as needed to fit your needs Compensation Range: $150K - $175K",
        "url": "https://www.linkedin.com/jobs/view/3952423328"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3964707103,
        "company": "Traba",
        "title": "Software Engineer",
        "created_on": 1720636949.5988665,
        "description": "Traba’s mission is to empower businesses and workers to reach their full productivity and potential. Traba is a technology company that is revolutionizing the broken staffing industry through a marketplace that connects light industrial businesses with reliable talent while providing workers with flexible and meaningful opportunities. By connecting both, new levels of productivity, earning potential, and avenues for growth are unlocked. We’re proud to be backed by the world’s best investors, such as Founders Fund, Khosla Ventures, and General Catalyst. We are seeking an experienced & entrepreneurial full-stack engineer to join the founding team to help build our core suite of products—the React Native worker mobile app, the React/Node.js business web app, and a React/Node.js tools platform for our ops team. You'll partner with our CTO to help provide key input on the product roadmap, own product decisions, and build our foundational tech platform. About You Voracious learner. You love diving into new areas and exploring new languages, frameworks, and technologies, and can discuss product with a UX designer one minute and deployment infrastructure with tech leads the next. Value clear communication. You recognize the importance of clear communication, documented planning, and transparent, frequent feedback. Sweat the small stuff. You have strong opinions on design patterns, IDEs, tabs vs. spaces—you understand that how you do one thing is how you do everything, so you care about the details. Experience with or desire to learn React Native. You have the front-end chops to build beautiful performant apps and love creating products that delight users. You Will Write & review high quality, performant code for our React Native mobile app, React/Typescript web apps, and Node.js/PostgreSQL APIs Architect & document our tech platform and advise key product & infrastructure decisions Collaborate with designers to implement pixel-perfect, eye-pleasing UIs Implement our CI/CD workflows, using Docker & Github Actions Add analytics & monitoring to help understand our user experience & application health Contribute in a ton of other ways to a scrappy founding team building the future of flexible light industrial staffing! You Have 3+ years experience with Typescript, Javascript, React Native, React, Node.js, and/or PostgreSQL Experience with Docker Experience working in an early-stage engineering team, working through ambiguity, and being a self-starter A passion for helping people find meaningful work that works for them Benefits 100% healthcare, dental, and vision Early Equity in Traba Competitive Salary Dinner is provided at the office via Grubhub Fully-equipped snack bar Additional: One Medical Membership, Gympass, HSA via Optum, Talkspace, HealthAdvocate, Teledoc Health Our Values Dream BIG - We are on a path to change the world for the better. We create and communicate a bold direction that inspires a life-changing vision. We don’t sacrifice long-term value for short-term results. Olympian’s Work Ethic - Changing the world never comes easy. We work harder, longer, and smarter, not just two out of three. We put everything we have on the field. Growth Mindset - We confront the toughest challenges head-on and persevere. Sometimes we fail, but we brush ourselves off, adapt, learn, and push forward with resilience. Customer Obsession - We go the extra mile for our workers and businesses. We remain focused on delivering high-quality products and services that solve these often overlooked communities’ problems. What is light industrial labor? Light industrial flexible staffing is a $40B labor market that encompasses entry-level jobs in warehouses & distribution centers. These workers pack boxes, load trucks, and manage warehouse operations to keep supply chains running at peak efficiency.",
        "url": "https://www.linkedin.com/jobs/view/3964707103"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3900215845,
        "company": "Daybreak Health",
        "title": "Software Engineer",
        "created_on": 1720636951.352317,
        "description": "We're Daybreak Health (http://www.daybreakhealth.com/), and we're on a mission to ensure that every young person has the benefit of mental health support. We deliver evidence-based virtual and in-person therapy to kiddos and teens aged 6-19, making a real difference in their lives. We've teamed up with public school districts and health insurance companies to provide free, accessible mental health care to all families. Why? Because we firmly believe that every child should have access to mental health support as an essential part of their education. Watch this video We're a YC-backed company that raised its Seed from Maven Ventures, Series A from Lightspeed Ventures and just announced our Series B led by Union Square Ventures. Over the past 2 years, we've seen incredible success and are growing rapidly and efficiently. Now, we're on the hunt for amazing people to join us in critical roles as we continue to speed ahead with our national expansion. If you want to get a sense of the impact your work can have here, watch this powerful story told directly by Clifford, his mom, and school counselor about his mental health challenges and how his Daybreak therapist worked with him to change the trajectory of his life https://www.youtube.com/watch?v=y6X1HDfbsPQ. Here at Daybreak, we: Believe and rally around our mission Are a bunch of creative, humble, hard-working folks who are determined to win. Collaborate and execute superbly well by \"doing more with less\" - we value efficiency and output over hours worked. Put a high value on mental health: being open and vulnerable is a big part of our culture. We also enjoy regular mental health days (once per quarter). The Software Engineer Role Daybreak's engineering team is small but growing. You will contribute in a major way to building a new application for everyone we serve, shaping a psychologically safe and inclusive culture of excellence, and have fun and learn along the way. Daybreak will put you in a position to learn, grow, make an impact, and have fun along the way. We are looking for fullstack developers and generalists but we're open to being flexible depending on fit and experience. What we're building: We are building the next iteration of Daybreak's application and system, largely a greenfield undertaking. The application we are building serves kids, parents, clinicians, school staff, and internal daybreak staff. Part of the fun and challenge is designing and building an application that has to be flexible enough to serve different such different users. The possibilities for innovation in this space are endless, and our goal is to make therapy accessible and effective for any kid that needs it. You Will: Be a part of building a growing engineering team, helping shape our culture and ways of working Work closely with other engineers, product managers, and other team members to ideate solutions to user problems Contribute to the development, testing, and rolling out of a new application Contribute to the development of our API (built with Ruby on Rails) Contribute to our web frontend (built with React) You Have: 2-4 years of professional development experience Experience with Ruby on Rails and/or React Not a strict requirement if you have some experience with an analogous framework Strong communication skills, low ego, and high empathy Desire and ability to work autonomously and drive your work. Bonus points for experience with… GraphQL, NextJS, DevOps, Healthtech Equal Employment Opportunity At Daybreak Health, we believe in fostering an inclusive and diverse workplace where every individual's unique background and perspective is celebrated and valued. We are committed to promoting equality, equity, and opportunity for all. We actively encourage individuals from diverse communities, including but not limited to race, ethnicity, gender identity, sexual orientation, ability, age, religion, and socioeconomic background, to apply and join our team.",
        "url": "https://www.linkedin.com/jobs/view/3900215845"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3957773250,
        "company": "Rachel Paul Recruiting",
        "title": "Software Engineer",
        "created_on": 1720636955.7732697,
        "description": "My Client a top firm in the art world is looking for a .Net Developer! They are seeking a motivated and skilled .NET Developer with 3+ years of experience to join their development team. In this role, you will work closely with senior developers and other team members to develop, maintain, and improve their software applications. This is a great opportunity for someone looking to further their career in a supportive and fast-paced environment. You will be involved in design, development, coding, customization, configuration, testing, and deployment in support of enterprise packaged solutions. With a strong focus on our system services layer, you will need strong understanding of .NET Framework and .NET Core, Web API and WCF as well as support and enhance existing legacy code. DUTIES AND RESPONSIBILITIES -Assist in the design, development, and maintenance of software applications using the .NET framework. -Write clean, efficient, and maintainable code following best practices and coding standards. -Collaborate with cross-functional teams to understand and gather requirements. -Conduct unit testing and debugging to ensure application quality and performance. -Participate in code reviews and contribute to continuous improvement initiatives. -Troubleshoot and resolve software defects and issues in a timely manner. -Stay updated with the latest industry trends and technologies to enhance your skills and knowledge. PROFESSIONAL SKILLS AND EXPERIENCE -Minimum of 3 years of experience as a .NET Developer or similar role. -Proficiency in C#, ASP.NET, and the .NET framework. -Experience with front-end technologies such as HTML, CSS, and JavaScript. -Solid understanding of SQL and experience with relational databases (e.g., SQL Server). -Familiarity with version control systems (e.g., Git). -Strong problem-solving skills and attention to detail. -Good communication and teamwork skills. -Experience with JIRA and Confluence a plus -Understanding of Software Development Life Cycle and Agile methodologies. -Ability to work under pressure -Experience with cloud platforms (e.g., Azure, AWS).",
        "url": "https://www.linkedin.com/jobs/view/3957773250"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brooklyn, NY",
        "job_id": 3819938826,
        "company": "Five Cubes",
        "title": "Senior Data Solution and Delivery Engineer",
        "created_on": 1720636957.5856552,
        "description": "Job Title: Senior Data Solution and Delivery Engineer Location: B rooklyn, NY Duration: 12+ Months Direct Client Job Description The MyCity Portal will streamline the public's interaction with NYC government in applying for services and benefits. The Portal is envisioned to create a unified digital platform to easily search, find, and apply for services and benefits. It will allow users to create an online profile that will provide status updates and notifications. This platform will enable information sharing and streamline business processes between agencies to improve customer experience. The MWBE resource will support the Office of Data Analytics (ODA) with NYC's Office of Technology and Innovation (OTI) to implement its data management strategy. This will include strategic input in delivery, development and integration of the City's Master Data Management (MDM) platform as a foundational component of MyCity, as well as the build of analytic products and data integration platforms. SCOPE OF SERVICES OTI's Office of Data Analytics (ODA) works with Cityagencies and their data to help serve New Yorkers more equitably and effectively. This work takes three main forms: analyzing data to improve City agency operations; making Open Data more accessible to all New Yorkers; and advancing citywide data infrastructure, integration, and sharing. ODA seeks a Senior Data Solution and Delivery Engineer role to ensure the efficient and successful implementation and support of complex data engineering solutions for City agencies. This resource should demonstrate a solid understanding of industry-standard implementation methodologies using data engineering technologies, tools, and processes. Tasks Support ODA implement a new MDM Business Domain that will integrate multiple sources of data and accompanying web services and APIs. Develop architectural blueprints that leverage the MDM as a foundational service of MyCity that will, among other things, support the creation of unified profiles that can be used for such activities as linking business transactions relevant to a business owner. With guidance from ODA's Technical Leads, coordinate the work of senior-level data engineers tasked with building pipelines to the MDM and selected ODA data platforms. Support the development of analytics tools that utilize the data pipeline to provide actionable insights into customer engagement and experience, operational efficiency, and other key business performance metrics. Review Extraction, Transformation, Load strategies (ETL) for data from a wide variety of data sources using SQL, cloud, and 'big data' technologies. Create, update, and maintain system documentation; Manage the development of APIs, for data access or landing data as output for further downstream consumption in theappropriate target data store; Coordinate appropriate security scan accreditations. Perform special projects and initiatives as assigned. MANDATORY SKILLS/EXPERIENCE Note 8+ years managing the development and implementation of large technology projects with at least 3+ years involving an MDM implementation. 8+ years of experience in writing SQL; 8+ years of experience in copying, transferring, manipulating, and automating data operations that were manual processes; Experience with tools and components of data architecture such as Informatica Power Center, IICS, SSIS, or similar ETL tools; Experience working with Amazon Web Services or Microsoft Azure cloud computing platform and services; In-depth knowledge of SQL and other database solutions; Knowledge of modeling database schemas for large datasets; Experience developing cloud-ready applications; Experience working with programming languages like Python, Java, and Perl DESIRABLE SKILLS/EXPERIENCE: 5+ years hands-on experience in development with the suite of tools from Informatica PowerCenter and B2B Data Transformation; Experience using Oracle 10g/11g, SQL Server and/or a database appliance; Knowledge of metadata-driven enterprise reporting platforms; SPECIAL REQUIREMENTS: Strong hands-on experience with a Master Data Management (MDM) implementation that serves a large enterprise Prior experience working on complex data integration projects for the City of New York. Benefits: $84.39 - $94.39 DOE Onsite Role Any Visa",
        "url": "https://www.linkedin.com/jobs/view/3819938826"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963453211,
        "company": "DKMRBH Inc",
        "title": "Software Engineer || Full-Time",
        "created_on": 1720636959.2215562,
        "description": "Position: Software Engineer Location: Remote (Preference - NYC, Boston or SF) Employment Type: Full-Time (US Citizen) Strong preference if they're in NYC, Boston or SF but open to anywhere else but needs to be rockstar. Please target candidates who were previously worked for good startups bcs startup experience is a must. Candidate Requirements The ideal candidate will have experience shipping products, working with cloud platforms, and have familiarity with containerization tools. Additionally, experience with prompting tools, NLP packages, and cybersecurity is a plus. Minimum Requirements a Candidate Must Meet Had ownership over aspects of product development in both small and large organizations at differing points in your career. Have used Langchain, LangGraph, or other prompting tools in production or for personal projects. Familiarity with NLP packages such as Spacy, Stanza, PyTorch, and/or Tensorflow. Shipped a working product to users, either as part of a team or on your own. 5+ years of experience as a software engineer Nice-to-haves What could make your candidate stand out. Experience with cybersecurity.",
        "url": "https://www.linkedin.com/jobs/view/3963453211"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3925195064,
        "company": "Ramp",
        "title": "Senior Software Engineer | Data Platform",
        "created_on": 1720636963.3467834,
        "description": "About Ramp Ramp is the ultimate platform for modern finance teams. Combining corporate cards with expense management, bill payments, vendor management, accounting automation and more, Ramp's all-in-one solution is designed to save businesses time and money, and free finance teams to do the best work of their lives. Our mission is to help build healthier businesses, and it’s working: over 25,000 businesses on Ramp to save an average 5% and close their books 8x faster. Founded in 2019, Ramp powers the fastest-growing corporate card and bill payment platform in America, and enables tens of billions of dollars in purchases each year. Ramp's investors include Founders Fund, Stripe, Citi, Goldman Sachs, Coatue Management, D1 Capital Partners, Redpoint Ventures, General Catalyst, and Thrive Capital, as well as over 100 angel investors who were founders or executives of leading companies. The Ramp team comprises talented leaders from leading financial services and fintech companies—Stripe, Affirm, Goldman Sachs, American Express, Mastercard, Visa, Capital One—as well as technology companies such as Meta, Uber, Netflix, Twitter, Dropbox, and Instacart. In 2023, Ramp was named Fast Company’s #1 Most Innovative Company in North America, LinkedIn’s #1 Top Startup in the U.S., a CNBC Disruptor, and a TIME100 Most Influential Company. About The Role The Data Platform team develops and owns the systems that enable Ramp's reporting and strategic decision-making and integrate machine learning models into our operational systems and the product itself. As a member of the Data Platform team, you’ll build and maintain the infrastructure that enables Ramp to realize value from data. You’ll also partner with Ramp’s analytics engineers, applied scientists, software engineers, and other data professionals to build internally and externally-facing data infrastructure & products. Our ideal candidate is excited about building systems for data collection, processing, storage, and retrieval, and is also passionate about making these systems observable, reliable, scalable, and highly automated. What You’ll Do Build and integrate the components of Ramp's Analytics Platform and Machine Learning Platform. Build tools that improve the agility and data experience of Ramp's Data Scientists, Analytics Engineers, Engineers, and Operations teams. Build the batch and streaming data pipelines critical to Ramp’s daily operations using Airflow, Snowflake, ClickHouse, Kafka, and other data processing technologies. Collaborate with stakeholder teams on building and productionizing analytical products and machine learning systems. Build reliable, scalable, maintainable, and cost-efficient systems across the stack. What You Need Experience with workflow orchestrators like Airflow, Dagster, or Prefect. Experience building infrastructure on AWS, GCP, or Azure. Knowledge of SQL and experience with Snowflake, Redshift, BigQuery, or similar databases. Intuition around analytics and machine learning. Strong Python programming skills. Track record of building highly reliable infrastructure for data storage and processing. Nice-to-Haves Expertise with AWS Previous experience building online machine learning systems. Previous experience building a feature store. Experience with Terraform and Datadog Experience building streaming systems. Benefits (for U.S.-based full-time employees) 100% medical, dental & vision insurance coverage for you Partially covered for your dependents One Medical annual membership 401k (including employer match on contributions made while employed by Ramp) Flexible PTO Fertility HRA (up to $5,000 per year) WFH stipend to support your home office needs Wellness stipend Parental Leave Relocation support for NY Pet insurance Other notices Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",
        "url": "https://www.linkedin.com/jobs/view/3925195064"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3796700910,
        "company": "MERU",
        "title": "Analytics Engineer, Data Insights",
        "created_on": 1720636965.3743017,
        "description": "Meet The Company We are MERU. A values-driven, impact-oriented team dedicated to fixing companies. We provide advisory services and data analytics support to middle-market companies ($50M - $2B in annual sales), and our clients include private equity firms, credit funds, investment banks, and law firms. We bring deep turnaround experience, a group of veteran operators, and an incentive-aligned approach to any situation. MERU was founded by professionals from Alvarez & Marsal and McKinsey and has seen rapid growth in the five-plus years since its founding. The MERU Way & Valuing Our Team We're Partners, not consultants. When you join MERU, you will help our clients solve their most pressing problems, supported by a team of people who will challenge you, support you, and inspire you. In order to be Partners, we don't silo people into just one functional area of the business, instead advancing our team's capabilities by providing training for every service that MERU offers . Additionally, we don't just focus on technical skills but also leadership style and soft skills, so MERU team members not only know what it means to manage a client engagement but to lead a team to success. In training team members to be well-rounded individuals, we can deliver an overall higher impact to clients , allowing the ability to gain experience in diligence, turnarounds, interim management, data science, and more. To aid this career advancement and development, MERU provides an internal Coach to each team member in order to guide and maintain their professional development plan goals. Unlike most Firms, we actually focus on the achievement of those goals for each individual team member, providing opportunities that would not usually be offered. Finally, MERU values personal time, only traveling when necessary in order to celebrate and respect your personal life . We believe that by encouraging and mandating balance, it will lead to happier and longer-tenured team members. When you come to MERU, you come to further your career and maintain your entrepreneurial spirit, never losing sight of the desire to provide meaningful impact, solutions, and value to clients . Learn more about our colleagues’ core characteristics and culture here: https://wearemeru.com/meru-way/ Analytics Engineer Responsibilities Demonstrates ownership of individual workstreams with minimal supervision from senior team members, with the ability to coach junior team members on the engagement Complete ownership for the end-to-end process of engaging stakeholders for design sessions and requirements gathering and solution build Produces high quality, production level code balances on-time delivery with long-term sustainability Proactively communicates progress and roadblocks to senior team members on an ongoing basis; proactively develops solutions to the roadblocks Contributes to proposal development (i.e., assistance with analysis/presentation, etc.) and proactively identifies ways to improve the proposal quality (i.e., research, package case studies, etc.) Assists Partners in preparation for pitches and attends as required Proactively identifies ways to improve proposal quality Supports in the development of Firm Contribution areas, such as Recruiting, Professional Development, Marketing, etc. Analytics Engineer Qualifications Bachelor’s degree from a top university, required 3+ years of business intelligence or data analytics experience Previous experience in data and analytics consulting or a client-facing role Strong knowledge and delivery experience with Tableau, Power BI, Qlik, or any other data visualization tools Working knowledge of ETL tools like Power Query, Azure Data Factory, FiveTran, Stitch, Alteryx, and languages like SQL, Python, or R Relevant certifications associated with business intelligence tools, and enthusiasm to learn new tools and technologies and attain certifications Experience in mentoring junior analysts and leading cross-functional teams to deliver data products Demonstrated ability to interact and work collaboratively with junior and senior team members, senior management, and other stakeholders or professionals Experience in independently managing deliverables with little oversight Effective communication skills to explain technical concepts to a non-technical audience or senior executives “Roll up your sleeves” mentality and willingness to complete any task if needed, no matter the role Ability to assist with internal firm initiatives (e.g., marketing, client pitches) Willingness to travel up to 20% Ability to work full time in an office and remote environment; physically able to sit/stand at a computer and work in front of a computer screen for significant portions of the workday Authorization to work in the United States Commitment to living MERU’s values and core characteristics $105,000 - $155,000 a year In addition to benefits, MERU also offers an extremely competitive bonus program that is based on firm contribution efforts and performance. Overview of MERU Service Offerings: Performance Improvement Help companies identify and achieve their full potential by leveraging a value-focused approach to driving sustainable margin expansion impact. Services include MERU 360° Assessment, Transformation Plan Development, Chief Transformation Officer placement, Cash Cycle and Working Capital Optimization, and Implementation Performance Management. Turnaround & Restructuring Partner with clients during uncertain times to help stabilize operations and rapidly triage the causes of financial distress, charting a path back to long-term sustainability. Services include Interim Management, Turnaround Plan Development and Execution, Liquidity Management, Stakeholder Negotiations, Strategic Alternatives Assessment, Bankruptcy, Insolvency, and Case Management. Transaction Services Partner with private equity firms across the investment lifecycle, from due diligence to portfolio value creation and exit planning. Services include Due Diligence, Pre-Close Planning, Post-Close Implementation, and Exit Planning. Data Insights Work with companies at all stages of their digital transformation journey to automate reporting processes, build scalable data platforms, and leverage predictive analytics to transform data from a liability into an asset. Services include Data Discovery and Analysis, Data Prep and Integration, Self-Service Analytics, Data Visualization and Reporting, Data Science and Advanced Analytics, and Strategy Enablement. Voluntary Inclusion It is MERU’s policy to provide and promote equal opportunity in employment, compensation, and other terms and conditions of employment without discrimination because of race, color, sex, sexual orientation, family medical history or genetic information, political affiliation, military service, pregnancy, marital status, family status, religion, national origin, age or disability or any other non-merit based factor in accordance with all applicable laws and regulations. Unsolicited Resumes From Third-Party Recruiters Please note that we do not accept unsolicited resumes from third-party recruiters unless such recruiters are engaged to provide candidates for a specified opening. Any employment agency, person, or entity that submits an unsolicited resume does so with the understanding that MERU will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person, or entity.",
        "url": "https://www.linkedin.com/jobs/view/3796700910"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brooklyn, NY",
        "job_id": 3948812672,
        "company": "Kalder",
        "title": "Founding Software Engineer (Crypto)",
        "created_on": 1720636967.2523146,
        "description": "About Kalder Kalder is reimagining the future of brand engagement with web3. Brands 3.0. It has never been more expensive to acquire customers or challenging to retain them. Existing marketing and engagement channels are, at best, saturated and, at worst, actively deteriorating. Kalder is building the next layer of engagement infrastructure to solve brands’ and creators to solve customer acquisition and retention problems – mobilizing communities and creating engagement beyond products. We are creating a suite of no-code web3 tools that empower brands and creators to efficiently onboard new consumers, reward loyal customers, and build composable digital asset ecosystems that create enduring community engagement. For more information, visit Kalder.app What you’ll do at Kalder? Contribute to our centralized & decentralized (web 3.0 / blockchain) platform and architecture Write and maintain smart contract protocols underlying our no-code tooling for brands, loyalty tokens, NFTs, and other applications Work with the full-stack development team to build connective infrastructure between web2 and on-chain data Experiment with and implement new on-chain product ideas to drive value for brands Work with the founding team to drive and maintain token design for our platform Maintain a technical standard that attracts a team of stellar engineers Continuously improve the design, development, testing, deployment and monitoring of our platforms Archetype Experience building blockchain projects in Solidity Experience in backend development Loves brands / art / music and has hypotheses about how web3 will change ecomm, brands, and consumer tech Passion for building robust, scalable infrastructure Ownership mentality Comfortable creating something from nothing Requirements & Expectations Track record of building blockchain projects or backend systems Excellent communication skills - writing clear documentation, running meetings, and speaking clearly Excitement for working with some of the biggest brands and creators in the world Passion for web3",
        "url": "https://www.linkedin.com/jobs/view/3948812672"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Albany, NY",
        "job_id": 3884686804,
        "company": "ACS Consultancy Services, Inc",
        "title": "Oracle data warehouse developer",
        "created_on": 1720636968.9763336,
        "description": "Job Title: Oracle Data Warehouse Developer Location: Albany, NY (Hybrid) We are currently seeking candidates who meet the following qualifications: Key Responsibilities Reverse engineer OWB ETL processes and develop new replacement ODI processes. Perform data modeling, process improvement, and normalization/de-normalization tasks. Work in an Oracle Data Warehouse environment, primarily utilizing PL/SQL for development. Implement advanced Extract/Transform/Load techniques such as bulk select, bulk insert, arrays, and dynamic SQL. Develop and test maps, perform source-to-target mappings, and plan storage capacity. Engage in the full Software Development Life Cycle (SDLC), including requirement gathering, development, testing, debugging, deployment, documentation, and production support. Handle load issue resolutions, inquiries, and 2nd level testing of issues and code fixes. Participate in infrastructure upgrades and enhancements, particularly Oracle upgrades. Utilize Unix or Linux environments for Unix Shell Scripting and sftp protocols. Build database schemas, tables, views, indexes, and stored procedures. Requirements Bachelor’s Degree. Proven experience in Oracle Data Warehouse development. Strong proficiency in PL/SQL and Oracle Data Integrator (ODI). Familiarity with Unix or Linux environments. Excellent problem-solving and communication skills. Ability to work independently and collaboratively in a hybrid work setting. If you meet these qualifications, please submit your application via link provided in Linkedin. Kindly do not call the general line to submit your application.",
        "url": "https://www.linkedin.com/jobs/view/3884686804"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3950763495,
        "company": "Unusual Ventures",
        "title": "Senior Software Engineer - AirOps",
        "created_on": 1720636970.5337424,
        "description": "About AirOps: AirOps is the platform teams use to build scalable AI growth engines. With AirOps, teams launch AI workflows that use the best AI models, techniques, and data sources to drive profitable growth. Teams use AirOps to: Create automated content engines that generate organic traffic at scale Personalize landing pages for paid ads and lifecycle to drive improvements in CVR and ROAS Build and orchestrate AI workflows that improve CX and sales efficiency Our founding team has owned growth, product, and engineering at MasterClass, Bungalow, and Teespring, driving over $1B in ARR growth. We’re backed by awesome investors, including Wing VC, Founder Collective, XFund, Village Global, and Alt Capital. We are a proudly global organization with team members located across the world, with in-person hubs in San Francisco, New York, and Montevideo, Uruguay. About The Role As a Senior Software Engineer at AirOps, you will play a critical role in the development and maintenance of our software products. You will be responsible for designing, developing, testing, and deploying software solutions that meet the needs of our customers. In this role, you will combine software development, data, and Generative AI techniques to build innovative AI solutions that automate processes and improve user experience. In addition to the technical skills and expertise, we are seeking a Senior Software Engineer who can also demonstrate strong adaptability, versatility, and cross-team communication. As the software industry evolves at a rapid pace, it is critical that our team members can quickly learn and apply new technologies and methodologies. Key Responsibilities: Collaborate on the development and deployment of solutions that meet the needs of our customers Implement and maintain the core product experience Take an active role in code reviews and Quality Assurance to ensure that our software products meet high standards of quality, scalability, and reliability Organize and plan tasks, working closely with the rest of the team to ensure that project milestones and deadlines are met Innovate in the AI space, staying up-to-date with the latest AI trends and identifying opportunities for integrating them into our software products Qualifications: Must have 6+ years of experience working on full-stack application development Must have 3+ years working with Ruby on Rails 1+ years working with React Experience with or interest in Generative AI or Natural Language Processing Demonstrated ability to lead engineering teams in an organization Demonstrated initiative and aptitude to make independent decisions and resolve complex challenges in a remote-first environment Experience working with Figma Bachelor's degree or equivalent experience Benefits: Highly competitive Equity Annual team offsite Macbook Pro Paid Time Off + sick days off Montevideo or NYC office (optional) A fun-loving and (just a bit) nerdy team that loves to move fast! 🤓 🚀",
        "url": "https://www.linkedin.com/jobs/view/3950763495"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3713179127,
        "company": "Ramp",
        "title": "New Grad 2024: Software Engineer - Frontend",
        "created_on": 1720636972.3297307,
        "description": "About Ramp Ramp is the ultimate platform for modern finance teams. Combining corporate cards with expense management, bill payments, vendor management, accounting automation and more, Ramp's all-in-one solution is designed to save businesses time and money, and free finance teams to do the best work of their lives. Our mission is to help build healthier businesses, and it’s working: over 25,000 businesses on Ramp to save an average 5% and close their books 8x faster. Founded in 2019, Ramp powers the fastest-growing corporate card and bill payment platform in America, and enables tens of billions of dollars in purchases each year. Ramp's investors include Founders Fund, Stripe, Citi, Goldman Sachs, Coatue Management, D1 Capital Partners, Redpoint Ventures, General Catalyst, and Thrive Capital, as well as over 100 angel investors who were founders or executives of leading companies. The Ramp team comprises talented leaders from leading financial services and fintech companies—Stripe, Affirm, Goldman Sachs, American Express, Mastercard, Visa, Capital One—as well as technology companies such as Meta, Uber, Netflix, Twitter, Dropbox, and Instacart. In 2023, Ramp was named Fast Company’s #1 Most Innovative Company in North America, LinkedIn’s #1 Top Startup in the U.S., a CNBC Disruptor, and a TIME100 Most Influential Company. Check out our Engineering Blog for more on our tech stack, mission and values! About The Role Ramp is, at its core, an engineering company, and is on a mission to build the best engineering team in the US! We are looking for frontend and full stack engineers who are excited to be part of our early story and help us build a diverse and vibrant tech community. We hire engineers with a broad set of technical skills, who are highly cross-functional, and eager to solve a wide range of engineering challenges. Our ideal candidate has a strong sense of ownership and enjoys owning projects from inception to scaling it in production. We value people who take pride in their work, and show an aptitude for learning quickly whether they’re familiar with our stack or not. As an early employee, you'll be working with a nimble team of committed and talented engineers and having a large, long-term impact on technical design and engineering culture. What You'll Do Build performant, beautiful, and usable interfaces that solve for growing businesses with complex needs Ship products and services in cross-functional teams Work with sales and business teams to incorporate and productize customer feedback Help establish engineering process, tools, and systems that will allow us to scale the code base, productivity, and the team What You'll Need Graduating with a B.S. (or higher) in Computer Science or a related technical field; this role is ideal for a candidate with an expected graduation date in or around May 2024 given the deferred start date in Summer/Fall 2024 Proficiency in JavaScript, with a knack for getting the visuals right Experience with one or more object-oriented programming languages Track record of shipping high quality products and features or a portfolio of side projects Ability to turn business and product ideas into engineering solutions Desire to work in a fast-paced environment, continuously grow, and master your craft Alignment with Ramp’s core values of enabling businesses to grow more by spending less Nice to Haves Proficiency in React v16+ Familiarity with or desire to learn our tech stack which includes, but not limited to: Flask (Python), Elixir, AWS, RabbitMQ, PostgreSQL Passion for, or curiosity to learn, financial technology Compensation The annual salary/OTE range for the target level for this role is $127,500-$150,000 + target equity + benefits (including medical, dental, vision, and 401(k) Benefits (for U.S.-based full-time employees) 100% medical, dental & vision insurance coverage for you Partially covered for your dependents One Medical annual membership 401k (including employer match on contributions made while employed by Ramp) Flexible PTO Fertility HRA (up to $5,000 per year) WFH stipend to support your home office needs Wellness stipend Parental Leave Relocation support for NY Pet insurance Other notices Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",
        "url": "https://www.linkedin.com/jobs/view/3713179127"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3801582324,
        "company": "CreditSights",
        "title": "Senior Software Engineer - Data & Analytics",
        "created_on": 1720636974.012226,
        "description": "Senior Software Engineer CreditSights is seeking a Senior Software Engineer - Data & Analytics development who will be responsible for building and expanding CreditSights Data engineering and analytical needs. This role will be responsible to conceptualize, design and develop serverless architecture driven data-pipelines, highly scalable API, high-performance analytics capability to suffice critical product and platform needs. The ideal candidate should be experienced in building and implementation of data intensive derived content in the Fixed Income and Equity Domain and knowledge of market and fundamental data. The position demands an innovative, full-stack hands-on technology leader who will help conceptualize and innovate ideas to support our next generation of products and data initiatives. What We Offer Exceptional opportunity for growth for a rapidly growing platform and capabilities build to cater customers globally with specialized qualitative and quantitative contents. Opportunity to build high performance global teams. Exposure to latest cloud-native technology to build for scale in all facets of a platform. We’ll Count On You To Partner with business stake holders to identify, innovate, design, and implement capabilities in core platform and data with high level of automation for greater scalability using message, event and API driven architectures. Develop projects since inception and build complex data-pipelines, highly scalable API’s with core data infrastructure. Design and assemble complex data sets that meet functional /non-functional business requirements. Develop highly interactive UI/UX systems using latest UI frameworks, persistent and in-memory cache that integrates with our core data infrastructure. Build highly optimized and high-performance systems since inception. Build cloud native containerized infrastructure to scale platform on-demand. Build systems that deals with high volume and complex financial data. Build a support structure and respond to and resolve to production issues for operational rigor. Act as a coach /mentor to share knowledge and enable team members to succeed in a rapidly evolving technology and application platform. What You Need To Have A bachelor’s degree and 5 or more years of practical experience as a product and platform developer for large financial services platform A minimum of 4 to 5 years of experience in software development in JS Frameworks (React a must) , Python, SQL, Core Java and/or C#, Restful API’s, RDBMS and/or NoSQL is a must Required technical skills: Python, SQL (PostgreSQL preferred), NoSQL (Elastic and or any document database preferred), Messaging system (SQS/Kafka), Restful API (Fast API/Flask preferred), Container technology like docker or AWS Elastic container servic Experienced working in Cloud environment (AWS preferred) for development and production. Strong understanding of system architecture, object-oriented design, functional constructs, and distributed architectures Experience with software development lifecycle (SDLC) methodologies (Agile preferred) Proficiency in the development environment, including IDE, source control system, unit-testing tool and defect management tool using automated build and deployment (CI/CD) Excellent communication skills are essential, with strong verbal and writing proficiencies. What Would Make You Stand Out Knowledge of building Portfolio based analytical system; market Data & entity data is an added advantage. Why Fitch? At Fitch Group, the combined power of our global perspectives is what differentiates us. Our global network of colleagues comes together to accomplish things greater than they ever could alone. Every team member is essential to our business and each perspective is critical to our success. We embrace a diverse culture that encourages a free exchange of ideas, guaranteeing your voice will be heard and your work will have an impact, regardless of seniority. We are building incredible things at Fitch and we invite you to join us on our journey. Fitch Group is a global leader in financial information services with operations in more than 30 countries. Wholly owned by the Hearst Corporation, we are comprised of three main businesses: Fitch Ratings | Fitch Solutions | Fitch Learning. For More Information Please Visit Our Websites www.fitchratings.com | www.fitchsolutions.com | www.fitchlearning.com Fitch is committed to providing global securities markets with objective, timely, independent and forward-looking credit opinions. To protect Fitch’s credibility and reputation, our employees must take every precaution to avoid conflicts of interests or any appearance of a conflict of interest. Should you be successful in the recruitment process at Fitch Ratings you will be asked to declare any securities holdings and other potential conflicts prior to commencing employment. If you, or your immediate family, have any holdings that may conflict with your work responsibilities, you may be asked to divest yourself of them before beginning work. Fitch Group is proud to be an Equal Opportunity and Affirmative Action Employer. We evaluate qualified applicants without regard to race, color, national origin, religion, sex, sexual orientation, gender identity, disability, protected veteran status, and other statuses protected by law. CreditSights, Covenant Review and LevFin Insights are becoming one, bringing together best in class research, covenant analysis and news on a new platform, with a unified interface and login. Now more than ever before, we give our clients the ability to KNOW MORE, RISK BETTER. CreditSights was founded over 20 years ago with the goal of producing insightful, impartial research that would allow our clients to make prudent, profitable investment decisions in the global credit markets. CreditSights is a Fitch Solutions Company. Our global institutional client base includes banks, investment advisors, mutual funds, pension managers, insurance companies, hedge funds, private equity investors and corporations. The independent research we provide is a leading voice in global credit markets, with our experts contributing to market news in Bloomberg, The Wall Street Journal, Forbes, Financial Times, Business Insider, Barron’s and many more.” FOR NEW YORK ROLES ONLY: Expected base pay rates for the role will be between $150,000/per annum and $160,000/per annum. Actual salaries will be determined on an individualized basis and may vary based on factors including but not limited to education, training, experience, past performance, and other job-related factors. Base pay is one part of Fitch’s total compensation package, which, depending on the position, may also include commission earnings, discretionary bonuses, long-term incentives, and other benefits sponsored by Fitch. This is a hybrid role, with 2 days onsite and 3 days remote.",
        "url": "https://www.linkedin.com/jobs/view/3801582324"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3807760323,
        "company": "Arlo",
        "title": "Lead Data Science Engineer",
        "created_on": 1720636976.1729605,
        "description": "About Arlo Arlo powers healthcare innovation through modern underwriting technology. Small and medium-sized businesses have long seen little innovation in their health plan options and are hit with ever-increasing healthcare costs. As a technology-forward MGU (managing general underwriter), we use modern data science techniques to help health plan architects design novel health plans and leverage value-based care. Our mission is to bring affordable, value-based health benefits to employees of small and medium-sized businesses nationwide. Arlo’s founding team has extensive experience in claims analytics, data science, benefits administration systems, and health plan underwriting. Arlo’s team members previously worked at Palantir, Willis Towers Watson, McKinsey, and a Y-Combinator startup. Arlo has raised a $4M seed round from Upfront Ventures, 8VC, and General Catalyst. At Arlo, we value diverse opinions and debate. We are team-focused learners and seek to understand the missing perspective. Our team is collaborative, ambitious, and passionate about advancing the future of healthcare. We are looking for a motivated team member to join us locally in NYC. Team Overview & Role Impact As a Data Science Engineer, you will own the next iterations of the Arlo underwriting API from modeling to deployment. You will partner closely with our head actuary to refine our model and ideate novel underwriting strategies. Responsibilities Define and manage the architecture of the Arlo data and machine learning deployment pipelines Setup a system to manage and maintain the Arlo underwriting models Design and implement reporting tools from quote data and in-force business Support the next development iterations of the Arlo underwriting approach Deploy the Arlo underwriting models into our production environment Evaluate new data sources for health underwriting and use SDOH features to predict health outcomes Required Qualifications & Experience 2+ years working as a data scientist or engineer Experience setting up and managing large data pipelines Experience working with standard machine learning techniques Experience setting up production-ready API services for model evaluations An interest in using the best tool for the job. Our current favorites are Python, Sklearn, SQL, PySpark, SparkML, Snowpark, Python API frameworks, AWS, Docker Nice to Haves Familiarity with health insurance industry and financial terminology Experience working with medical and prescription drug claims data Experience working with probabilistic modeling techniques Experience working with social determinants of health data sources Our Culture We cultivate a high-performance culture. We greatly care about the work we do and have a passion for solving the “unsexy” parts of healthcare infrastructure. We strongly believe that addressing these problems is a key enabler for unlocking affordable, high-quality care. We value collaboration, a high sense of ownership for every team member's work, and getting things done quickly and efficiently. We are curious and love to learn as we push the boundaries in an industry often devoid of first-principle thinking. We are ambitious and are on a mission to build an industry-defining company. Location NYC onsite Be aware: this is NOT a remote position Equal Employer Opportunity Statement At Arlo, we’re challenging the status quo with the power of diversity, inclusion, and collaboration. When we connect different perspectives, we can imagine new possibilities, inspire innovation, and release our people's full potential. We’re building an employee experience that includes appreciation, belonging, growth, and purpose for everyone. Compensation & Benefits We offer a competitive base salary and meaningful equity in Arlo. We also offer medical coverage, unlimited paid time off, free lunches on workdays in the office, a stipend for professional development, company-wide off-sites, 16 weeks of fully paid parental leave, and biannual performance reviews with 360° feedback. Please send your application to team@joinarlo.com or apply via the form.",
        "url": "https://www.linkedin.com/jobs/view/3807760323"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brewster, NY",
        "job_id": 3970378545,
        "company": "Alliant - The Audience Company",
        "title": "Senior Data Analyst",
        "created_on": 1720636978.058777,
        "description": "Overview Alliant has developed an enviable reputation for innovative, data-driven solutions that optimize profitability in marketing campaigns. At the core of these accomplishments is a strong team with a passion for analytic innovation. To strengthen our Data Analytics Team and increase the pace of revenue growth, Alliant requires a Senior Data Analyst. Alliant is always looking for great talent in Data Analysis and Engineering. this position has the responsibility for data manipulation, data analysis and data engineering. Qualified candidates will have experience in large-scale databases, data processing, quality control, SAS programming, and MS Excel. The successful candidate will have well-developed and highly organized work habits.. Principal Responsibilities: Import, examine, clean and transform data for model development and analysis using SAS Independently generate model development samples to meet the business requirements of direct and digital marketers Conduct thorough quality assurance for model development samples, ensuring reliability and accuracy Diagnose and solve problems with data, layouts, and dictionaries Extract relevant information from complex transactional datasets independently Utilize multi-channel marketing industry expertise to evaluate and diagnose campaign data Identify data issues and potential problems with statistical samples and communicate directly with Data Scientists, Sales and Client Engagement to resolve issues Provide summaries of data assets for internal and external clients Participate in client meetings to explain data, ask for clarification, and request additional assets Understand Alliant's statistical models as they relate to the company's production scoring system; Provide quality assurance review of production scoring of statistical models Maintain and update model production schedule to assure adequate and precise timing of samples to Data Scientists Perform code reviews for teammates to foster a system of checks and balances.ob Required Qualifications & Skills: Master’s degree in a quantitative field preferred 5+ years’ experience with data cleaning and manipulation preferred Advanced SAS experience, including SAS macro preferred; advanced SQL experience will also be considered Must have 3+ years’ experience with large scale databases and Unix Knowledge of Linux or Hadoop a plus Must have strong quantitative skills and extensive attention to detail with the ability to investigate and resolve issues with raw data Advanced Excel, PowerPoint, report building skills Ability to lead ad-hoc projects to optimize processes and improve the quality of the datasets Ability to think critically and creatively about new ways our data can add value to our clients Ability to handle and prioritize multiple client queries and projects simultaneously Excellent written and verbal communication skills, especially when articulating your ideas to diverse audiences Experience working on data projects, querying large databases and using analytical tools such as Excel, SQL, or Python Ability to understand the best path to extract, cleanse, manipulate, and analyze data and gain required insights Ability to utilize segmentation tools and predictive models using logistic regression, decision trees, machine learning models in SAS, R and Python to gather insights Must be highly self-motivated with the ability to work on multiple projects independently in a fast-paced environment Excellent communication skills and the ability to build strong relationships with various teams across the organization. Must be a flexible team player who is committed to having a good time while doing a great job The base salary for this role is between $80,0000 and $100,000 plus a corporate bonus. Alliant considers a number of factors when determining compensation, including, but not limited to, education, years of experience, levels of experience, competency levels and other relevant skills and qualifications. This role requires working on-site in our headquarter office in northern Westchester County, New York. to foster close collaboration and team interaction. About Alliant Alliant is trusted by thousands of brands and agencies as an independent partner bringing a human element to modern data solutions. The Alliant DataHub — built on billions of consumer transactions, an expansive identity map, advanced data science and high-performance technology — enables marketers to execute omnichannel campaigns with responsive consumers at the center. Data security and privacy have been core values since day one, and Alliant continually validates people, processes, and data through meaningful certifications such as SOC2, IAB Tech Lab Data Transparency, NQI certification from Neutronian, and quarterly quality scoring with Truthset. For more information, visit: alliantdata.com. The position is based in Alliant’s offices in northern Westchester County, New York. For consideration, please forward your resume and salary requirements to recruiting@alliantdata.com, Subject Line: Senior Data Analyst. Alliant is an equal opportunity employer.",
        "url": "https://www.linkedin.com/jobs/view/3970378545"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911167773,
        "company": "Extend Information Systems Inc.",
        "title": "Looking for Sr. Data Engineer - NYC, NY, USA (Onsite)- Contract",
        "created_on": 1720636979.8758495,
        "description": "Hi, I hope you are doing well! We have an opportunity for Sr. Data Engineer with one of our clients for NYC, NY, USA (Onsite) Please see the job details below and let me know if you would be interested in this role. If interested, please send me a copy of your resume, contact details, availability, and a good time to connect with you. Title: Sr. Data Engineer Location: NYC, NY, USA (Onsite) Terms: Contract Job Details 8+ years of data engineering experience Experience building streaming pipelines using Scala, Spark, and SQL Must have good exposure in AWS technology Excellent communication and ownership skills Thanks & Regards Monika Singh Extend Information System Inc Email: monika@extendinfosys.com 44258 Mercure Circle, UNIT 102 A, Sterling VA, USA 20166",
        "url": "https://www.linkedin.com/jobs/view/3911167773"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Rochester, NY",
        "job_id": 3967785408,
        "company": "Wegmans Food Markets",
        "title": "Software Engineer",
        "created_on": 1720636981.6824436,
        "description": "Note to applicant: This position is fully remote. This role is responsible for understanding requirements to successfully design and deliver software solutions. You’ll write high quality code and create release pipelines and infrastructure code, while proactively identifying and executing continuous improvement opportunities. What will I do? Collaborate with team members and stakeholders to understand functional and non-functional requirements to successfully design and deliver solutions that meet business objectives Write high-quality code that satisfies customer needs and strives for simplicity, clarity, and testability Provide effective code review feedback and use collaborative software development techniques to promote high quality business outcomes Use critical thinking to architect software that improves performance, reliability and outcomes Configure and maintain commercial software packages Create and maintain release pipelines and infrastructure code to ensure replication of environments are repeated processes Adhere to architecture, design, implementation, and security standards and best practices, while proactively identifying and executing continuous improvement opportunities Improve performance of existing software by diagnosing and resolving critical issues in participation of on-call support rotation Required Qualifications 2 or more years of software engineering experience including .net coding and delivering a project end-to-end Strong proficiency in one or more coding languages (C#, C++, Java, JavaScript, Python, Swift, Kotlin, etc.- depending on focus area of opening) Experience in cloud storage options and relational databases (Oracle/SQL Server) Experience with cloud platforms Experience in building and/or consuming APIs using Open API Experience with DevOps and CI/CD principles and practices Working knowledge with security practices such as RBAC and OAuth Understanding of the agile software development methodology Critical thinking skills Preferred Qualifications Experience with Microsoft Cloud or comparable platforms Bachelor’s Degree in Computer Science, Statistics, Math Full time",
        "url": "https://www.linkedin.com/jobs/view/3967785408"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911836835,
        "company": "Unreal Staffing, Inc",
        "title": "Full Stack Software Engineer",
        "created_on": 1720636983.5254402,
        "description": "Company Overview: We are a dynamic tech company committed to revolutionizing web applications. Our team is dedicated to building innovative solutions that redefine user experiences. Join us in creating cutting-edge software that pushes the boundaries of technology. Role Overview: As a Full Stack Engineer, you will be instrumental in the development and maintenance of our web applications. Your primary focus will be on crafting seamless user experiences by leveraging React for the frontend and Nest.js for the backend. You will collaborate closely with our team to ensure optimal performance, scalability, and security across the entire tech stack. Requirements Responsibilities: Take ownership of our company's frontend development, driving innovation and excellence in user interface design Develop and optimize server-side applications using Nest.js and Node.js, prioritizing performance, scalability, and security Troubleshoot and debug issues across the stack, from frontend UI elements to backend services, ensuring smooth operation Write comprehensive unit and integration tests to maintain code quality and reliability Requirements: Bachelor's degree in Computer Science, Engineering, or related field, or equivalent practical experience Extensive expertise in React, JavaScript, HTML, and CSS, with a minimum of 8 years of hands-on experience Proficiency in server-side technologies, particularly Node.js, along with frameworks like Express or Fastify Strong understanding of RESTful API design principles and best practices Solid grasp of version control systems, especially Git Experience working with database systems, including SQL or NoSQL databases Preferred Qualifications: While not strictly required, the following qualifications are highly valued: Experience developing high-scale data pipelines Familiarity with cloud data warehouses, such as AWS Understanding of cloud computing principles and services Benefits Competitive salary and performance-based bonuses Comprehensive health, dental, and vision insurance plans Flexible work hours and remote work options Continuous learning and professional development opportunities Vibrant company culture with regular team events and outings",
        "url": "https://www.linkedin.com/jobs/view/3911836835"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3928980176,
        "company": "Intuit",
        "title": "Senior Software Engineer, Customer Data Platform (Mailchimp)",
        "created_on": 1720636985.1508095,
        "description": "Overview Intuit is a global technology platform that helps consumers and small businesses to overcome their most important financial challenges. Serving more than 100 million customers worldwide with TurboTax, Credit Karma, QuickBooks, and Mailchimp. We believe that everyone should have the opportunity to prosper. We never stop working to find new, innovative ways to make that possible. Intuit Mailchimp is a leading marketing platform for small businesses. We empower millions of customers around the world to build their brands and grow their companies with a suite of marketing automation, multi channel campaigns, CRM, and analytics tools. Join the Customer Data Platform (CDP) group as a Senior Backend Software Engineer developing the core of customers insights for analytics, reports, GenAI and much more. If you love having stretch goals, real world challenges, and making customers incredibly happy whilst fostering your obsessive need for perfect code and user experience, this is the job for you. Join our new innovative team to help build the next generation platform of awesome products and experiences using cutting edge technology. You will collaborate with many teams in Intuit. We love engineers who lead the change, understanding the customers needs and delivering the most beautiful and intuitive applications. What you'll bring 5+ years’ experience developing web applications in Experience with: Experience with large-volume data pipelines At least one big data tech - > kafka, flink, cassandra, redshift, bigquery. web services (consuming or creating) with REST Backend software development using Kotlin, Java Spring or Spring-Boot to expose and consume RESTful web services Unit testing frameworks & mocking NoSQL and relational databases Kubernetes & Docker Microservices architecture A lead - not just technically skilled, but able to drive a project E2E and deliver it. Having a direct impact on the end-product Self-starter with a strong work ethic and a passion for problem-solving Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences Experience working with cross-functional teams while maintaining effective working relationships How you will lead You need to be self-motivated, proactive and a contributor of code Guide engineers on how they can best utilize the data streaming platform to gain confidence that their services are performing as expected Automate processes, create tools, and build features that will improve everyone's experience with our data pipeline infrastructure Be able to read any code in an existing codebase and change it Build and maintain strong cross-functional relationships / alignment with partners across the business Gathering functional requirements, developing technical specifications, and project & test planning Ability to work effectively in a fast paced, complex technical environment with high adaptability and flexibility Communicates clearly and persuasively to all levels of employees, customers and management. Identify gaps and build a roadmap how we can improve, keep a day one",
        "url": "https://www.linkedin.com/jobs/view/3928980176"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3915607466,
        "company": "Warner Bros. Discovery",
        "title": "Staff Analytics Engineer",
        "created_on": 1720636986.8600843,
        "description": "Welcome to Warner Bros. Discovery… the stuff dreams are made of. Who We Are… When we say, “the stuff dreams are made of,” we’re not just referring to the world of wizards, dragons and superheroes, or even to the wonders of Planet Earth. Behind WBD’s vast portfolio of iconic content and beloved brands, are the storytellers bringing our characters to life, the creators bringing them to your living rooms and the dreamers creating what’s next… From brilliant creatives, to technology trailblazers, across the globe, WBD offers career defining opportunities, thoughtfully curated benefits, and the tools to explore and grow into your best selves. Here you are supported, here you are celebrated, here you can thrive. The Role As a Staff Analytics Engineer, you will lead data pipeline, data strategy, and data visualization-related efforts for the Global Product Analytics team at Max. You’re an engineer who not only understands how to use big data in answering complex business questions but also how to design semantic layers to best support self-service vehicles. You will manage projects from requirements gathering to planning to implementation of full-stack data solutions (pipelines to data tables to visualizations). You will work closely with cross-functional partners to ensure that business logic is properly represented in the semantic layer and production environments, where it can be used by the wider Product Analytics team to drive business insights and strategy. Meet Our Team The Data & Analytics organization is at the forefront of developing and maintaining frameworks, tools, and data products vital to WBD, including flagship streaming product Max and non-streaming products such as Films Group, Sports, News and overall WBD eco-system. Our mission is to foster unified analytics and drive data-driven use cases by leveraging a robust multi-tenant platform and semantic layer. We are committed to delivering innovative solutions that empower teams across the company to catalyze subscriber growth, amplify engagement, and execute timely, informed decisions, ensuring our continued success in an ever-evolving digital landscape. Job Responsibilities Design and implement data models that support flexible querying and data visualization. Partner with Product stakeholders to understand business questions and build out advanced analytical solutions. Advance automation efforts that help the team spend less time manipulating & validating data and more time analyzing. Mentor fellow engineers and help others act as successful stewards of our tools. Build frameworks that multiply the productivity of the team and are intuitive for other data teams to leverage. Guide the Analytics Engineering roadmap, communicate timelines, and manage development cycles/sprints to deliver value. Participate in the creation and support of analytics development standards and best practices. Create systematic solutions for solving data anomalies: identifying, alerting, and root cause analysis. Work proactively with stakeholders to ready data solutions for new product and/or feature releases, with a keen eye for uncovering and troubleshooting any data quality issues or nuances. Identify and explore new opportunities through creative analytical and engineering methods. Skillset & Experience Bachelor's degree, MS or greater in a quantitative field of study (Computer/Data Science, Engineering, Mathematics, Statistics, etc.) 7+ years of relevant experience in advanced analytics/analytics engineering Expertise in writing SQL (clean, fast code is a must) Experience working with complex stakeholders; dissecting vague asks and outputting digestible strategic insights from data Advanced ability to build reports and dashboards with BI tools (such as Looker and Tableau) Experience in transforming flawed/changing data into consistent, trustworthy datasets, and in developing DAGs to batch-process millions of records Experience in data-warehousing concepts such as star schemas, slowly changing dimensions, ELT/ETL, and MPP databases Experience with general-purpose programming (e.g. Python, Java, Go), dealing with a variety of data structures, algorithms, & statistical analysis etc. Experience with big-data technologies (e.g. Spark, Kafka, Hive) Proficiency with Git (or similar version control) and CI/CD best practices Experience in managing workflows using Agile practices Ability to write clear, concise documentation and to communicate generally with a high degree of precision Ability to solve ambiguous problems independently, while prioritizing the quality of the input data and how the processed data is ultimately interpreted and used by stakeholders Ability to manage multiple projects and time constraints simultaneously Experience with digital products, streaming services, or subscription products is preferred Strong written and verbal communication skills, especially with senior level stakeholders How We Get Things Done… This last bit is probably the most important! Here at WBD, our guiding principles are the core values by which we operate and are central to how we get things done. You can find them at www.wbd.com/guiding-principles/ along with some insights from the team on what they mean and how they show up in their day to day. We hope they resonate with you and look forward to discussing them during your interview. Championing Inclusion at WBD Warner Bros. Discovery embraces the opportunity to build a workforce that reflects the diversity of our society and the world around us. Being an equal opportunity employer means that we take seriously our responsibility to consider qualified candidates on the basis of merit, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, and genetic information, marital status, citizenship status, military status, protected veteran status or any other category protected by law. If you’re a qualified candidate and you require adjustments or accommodations to search for a job opening or apply for a position, please contact us at recruitadmin@wbd.com. In compliance with local law, we are disclosing the compensation, or a range thereof, for roles in locations where legally required. Actual salaries will vary based on several factors, including but not limited to external market data, internal equity, location, skill set, experience, and/or performance. Base pay is just one component of Warner Bros. Discovery’s total compensation package for employees. Pay Range: $131,600.00 - $244,400.00 salary per year. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Warner Bros. Discovery provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and sick time and vacation.",
        "url": "https://www.linkedin.com/jobs/view/3915607466"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911740364,
        "company": "Unreal Staffing, Inc",
        "title": "Fullstack Software Engineer",
        "created_on": 1720636988.534542,
        "description": "Join Our Growing Team We're a small but dynamic engineering team driving rapid growth. With exciting challenges ahead, we're looking for passionate individuals to join us on our journey. Your contributions will be instrumental in fueling the continued success of our platform. While we prefer candidates based in NYC or willing to relocate for hybrid work, we're currently fully remote, with plans to explore 2 days/week in our NYC office. Requirements What You'll Do Collaborate closely with the CTO and engineering team to pioneer the first construction permit application and management platform for builders Define the product and engineering roadmap in collaboration with founders and users Lead end-to-end feature development, from inception to implementation Create robust workflow tooling for permitting, iterating based on user feedback Design intuitive user experiences for seamless permit application, tracking, and management Mentor fellow engineers to foster a culture of technical excellence Our Tech Stack React TypeScript Node.js Postgres Qualifications & Fit Proven experience in full-stack development, particularly within startup environments Proficiency in our tech stack, including React, TypeScript, Node.js, and Postgres Meticulous attention to detail and a commitment to excellence Track record of successfully leading technically challenging cross-functional projects Customer-centric mindset with a willingness to engage directly with users Reflective practitioner with a keen understanding of personal success factors Benefits Competitive salary and equity packages Home office & equipment stipend to support your remote setup Flexible working hours and unlimited PTO for work-life balance Health, dental, and vision insurance for peace of mind",
        "url": "https://www.linkedin.com/jobs/view/3911740364"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3962789850,
        "company": "Palantir Technologies",
        "title": "Software Engineer, New Grad - US Government",
        "created_on": 1720636990.2594743,
        "description": "A World-Changing Company Palantir builds the world’s leading software for data-driven decisions and operations. By bringing the right data to the people who need it, our platforms empower our partners to develop lifesaving drugs, forecast supply chain disruptions, locate missing children, and more. The Role Software Engineers at Palantir build software at scale to transform how organizations around the world use data. In this role, you’ll have an opportunity to grow more quickly than you ever envisioned as you contribute high-quality code directly to Palantir Gotham, Palantir Apollo, or Palantir Foundry: products that are deployed at some of the most important institutions across the public and private sectors. You'll create features used by research scientists, aerospace engineers, intelligence analysts, and economic forecasters in countries around the world. Palantir's Product Development organization is made up of small teams of Software Engineers, each focusing on a specific aspect of a product. For example, you might join a team that builds a Foundry front-end application, or a component of the Gotham release infrastructure. We encourage communication and collaboration among teams to share context, skills, and experience, so you'll also have the opportunity to learn about other business areas. Core Responsibilities As a Software Engineer, you are involved throughout the product lifecycle - from idea generation, design, and prototyping, to execution and shipping, all while also being paired with a mentor dedicated to your growth and success. You'll collaborate closely with technical and non-technical counterparts to understand our customers' problems and build products that tackle them. One of the most effective ways to understand what our users need is to meet them. You may receive an opportunity to tour the assembly line at an auto-manufacturer or join a counter-terror analyst at their desk to really understand their mission and difficulties. SWE Principles Include Ownership: We see projects through from beginning to end in spite of obstacles we may encounter. Collaboration: We work internally with people from a variety of backgrounds — such as other Software Engineers, Product Managers, Designers and Product Reliability Engineers. We also partner with our business development teams (Forward Deployed Engineers, Deployment Strategists) in order to understand and solve our customers' problems. Trust: We trust each other to effectively handle time and priorities, and don't micromanage. We want people to have the space to think for themselves, while feeling supported by their team. Technologies We Use Skills It doesn’t matter what languages you know when you join us; what matters is that you can write clean, effective code and learn new languages quickly. Our software is constantly evolving, so we need engineers who can do the same. Alongside peers that bring diverse experience - whether you’re a former university Teaching Assistant, switched to computer science recently, or are a hackathon enthusiast — you'll build your skills to apply the best technology to solve a given problem. Right now, we use: A variety of languages, including Java and Go for backend and Typescript for frontend Open-source technologies like Cassandra, Spark, Elasticsearch, React, and Redux Industry-standard build tooling, including Gradle, Webpack, and GitHub What We Value Ability to communicate and collaborate with a variety of individuals, including engineers, users and non-technical team members. Willingness to learn and make decisions independently, and the ability to ask questions effectively. What We Require Active US Security clearance or eligibility and willingness to obtain a US Security clearance. Engineering background in fields such as Computer Science, Mathematics, Software Engineering, and Physics. Familiarity with data structures, storage systems, cloud infrastructure, front-end frameworks, and other technical tools. Experience coding in programming languages, such as Java, C++, Python, JavaScript, or similar languages. To Apply, Please Submit The Following An updated resume / CV - please do so in PDF format. Thoughtful responses to our application questions Our benefits aim to promote health and wellbeing across all areas of Palantirians’ lives. We work to continuously improve our offerings and listen to our community as we design and update them. The list below details our available benefits and some of the perks that can be enjoyed as an employee of Palantir Technologies. Benefits Medical, dental, and vision insurance Life and disability coverage Paid leave for new parents and emergency back-up care for all parents Family planning support, including fertility, adoption, and surrogacy assistance Stipend to help with expenses that come with a new child Commuter benefits Relocation assistance Unlimited paid time off 2 weeks paid time off built into the end of each year Salary The estimated salary range for this position is estimated to be $135,000 - $145,000/year. Total compensation for this position may also include Restricted Stock units, sign-on bonus and other potential future incentives. Further note that total compensation for this position will be determined by each individual’s relevant qualifications, work experience, skills, and other factors. This estimate excludes the value of any potential sign-on bonus; the value of any benefits offered; and the potential future value of any long-term incentives. Offer Deadline In an effort to build more transparency into our recruitment process, we’d like to share our offer deadline expectations. By applying to this position, you commit to confirming your decision within two weeks of receiving your written offer. Life at Palantir We want every Palantirian to achieve their best outcomes, that’s why we celebrate individuals’ strengths, skills, and interests, from your first interview to your longterm growth, rather than rely on traditional career ladders. Paying attention to the needs of our community enables us to optimize our opportunities to grow and helps ensure many pathways to success at Palantir. Promoting health and well-being across all areas of Palantirians’ lives is just one of the ways we’re investing in our community. Learn more at Life at Palantir and note that our offerings may vary by region. In keeping consistent with Palantir’s values and culture, we believe employees are “better together” and in-person work affords the opportunity for more creative outcomes. Therefore, we encourage employees to work from our offices to foster connectivity and innovation. Many teams do offer hybrid options (WFH a day or two a week), allowing our employees to strike the right trade-off for their personal productivity. Based on business need, there are a few roles that allow for “Remote” work on an exceptional basis. If you are applying for one of these roles, you must work from the state in which you are employed. If the posting is specified as Onsite, you are required to work from an office. Palantir is committed to promoting a culture of diversity, equity, and inclusion and is proud to be an Equal Employment Opportunity and Affirmative Action employer. We believe that all Palantirians share the responsibility of upholding our commitment to these values and encourage candidates from a wide range of backgrounds, perspectives, and lived experiences to join us in solving the world’s hardest problems. Palantir does not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. Palantir is committed to working with and providing reasonable accommodations to qualified individuals with physical and mental disabilities. Please see the United States Department of Labor’s EEO poster , EEO poster supplement and Pay Transparency Notice for additional information. Palantir is committed to making the job application process accessible to everyone. If you are living with a disability (visible or not visible) and need to request a reasonable accommodation for any part of the application or hiring process, please reach out and let us know how we can help.",
        "url": "https://www.linkedin.com/jobs/view/3962789850"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3956579832,
        "company": "Diverse Lynx",
        "title": "Databricks and Pyspark � Data Engineer",
        "created_on": 1720636991.8594677,
        "description": "\" Primary Skills:o Pysparko AWS Cloudo Airflowo SQLo Databricks\" Secondary Skills:o Snowflakeo GCP Cloud Digital : Databricks, Digital : PySpark 6-8 \" Minimum 5 years + working exp as Databricks Developer\" Minimum 3 years + working exp on PySpark and AWS \" Minimum 5 years + working exp as Databricks Developer\" Minimum 3 years + working exp on PySpark and AWS Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.",
        "url": "https://www.linkedin.com/jobs/view/3956579832"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3965550728,
        "company": "The Walt Disney Company",
        "title": "Software Engineer II",
        "created_on": 1720636993.8141522,
        "description": "Overview: On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world. Building the future of Disney’s media business: DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come. Reach & Scale: The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more. Innovation: We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news. Disney+ is the Disney-branded streaming service featuring an outstanding collection of content from its brands and franchises recognized and respected all over the world including Star Wars, Marvel, Pixar, Disney, and NatGeo. Hulu is a premium streaming service that offers premium originals, current season TV, a massive library of hit series and movies, and live television. The Growth Fraud and Security team is responsible for protecting our customers and our services from bad actors. Our team is looking for an Application Security Engineer to help validate that our services are designed and implemented to the highest security standards. You will be responsible for analyzing the security of our services, testing, identify and addressing security issues. A successful candidate will need a combination of troubleshooting, technical, and communication skills, as well as the ability to handle a mix of disparate tasks which may include project and software development work. You will work on mitigating risk by building solutions to identify, prevent and catch payment fraud. You will also build fraud prevention services powered by machine learning and other global data sets. This role is highly multi-functional and gives the opportunity to work with Product, Information Security, Data, Analytics, Business Operations, Finance, and various other functions across the company as we seek fraud throughout our systems. You take pride in being responsible for your features, focusing on quality, reliability, and scale, and are mindful of maintainability. Responsibilities: Build sophisticated and highly impactful systems. Write code in Kotlin, Java, or Scala. Use AWS products and services (EC2, S3, Lambda, DynamoDB, SQS, RDS, ElastiCache, CloudFront, etc.) Develop RESTful services. Work with SQL and NoSQL. Basic Requirements: Bachelor’s degree in Computer Science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience. 3+ years of experience in a technical field. Previous experience creating well tested services. Excellent written and verbal communication skills. Experience with integrating with 3rd party services and other team’s services. Ability to investigate any technical component as well as understand and contribute to overall systems architecture. The hiring range for this position in New York is $118,000 to $158,200 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",
        "url": "https://www.linkedin.com/jobs/view/3965550728"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Yonkers, NY",
        "job_id": 3948612067,
        "company": "Anatomy IT",
        "title": "System Engineer 2",
        "created_on": 1720636995.6689126,
        "description": "THE COMPANY: Anatomy IT helps healthcare providers deliver exceptional patient care through technology and cybersecurity solutions. With 30+ years of experience, we understand healthcare organizations' unique risks, opportunities, and challenges. Anatomy IT is one of the largest and fastest-growing healthcare IT companies, partnering with over 1,100 clients serving 32,000 healthcare staff nationwide, including ASCs, physician groups, and hospitals RESPONSIBILITIES: We are looking to hire a full-time onsite, experienced Systems Engineer 2. Do you have the knowledge and experience to provide IT support to end-users? Do you enjoy promptly identifying and resolving issues proactively? The Systems Engineer 2 role will help support in the successful delivery and escalation of incidents remotely for our clients. You will be involved in the prep, configuration, repair, and maintenance of the client's infrastructure, as well as interacting with vendor support on a regular basis to identify and resolve issues. Full-time dedicated onsite position at client location Provide service and customer support Troubleshoot and determine root cause for ongoing issues Assist customers remotely for post hardware or software implementations Produce timely and detailed service reports Collaborate with other departments to solve complex issues Tasks assigned by their Pod leader. EDUCATION & EXPERTISE: We need people who don’t mind working in a flexible manner based on the needs of the business and who will provide solid customer service and clear communication to our clients. We encourage you to apply if you can easily adapt to a rapidly changing environment, shift priorities, and meet tight deadlines. This position will require the following qualifications: High School diploma, Bachelor’s Degree a plus Minimum of 3-4 years work experience in a Help Desk or Field Services role CompTIA A+/Network+ or equivalent experience Complete technical understanding and expertise in the following: Public and private DNS functionality File server support RDS environment support Active Directory support Solid customer service, communication, and organizational skills Ability to work under tight deadlines and shifting priorities Occasionally work past scheduled work hours to complete work tasks Including occasional nights and weekend work as needed Ability to participate in a rotating on-call schedule Reliable and punctual WHY AnatomyIT? AnatomyIT embraces those that demonstrate a deep passion for solving the problems of healthcare with enthusiasm for building positive working relationships and winning as a team. We believe in putting our customers first, empowering our people to drive growth, being technologically innovative, simplifying the complex, delivering results to our commitments with a sense of urgency while embracing diversity, equity, and inclusion. BENEFITS: We love collaborating and working together as a team. Our benefits include healthcare (medical, dental & vision), 401K fund contribution, paid-time-off, short & long-term disability, and a family atmosphere of caring and concern for each team member. EQUAL OPPORTUNITY EMPLOYER We're proud to be an equal opportunity employer - and celebrate our employees' differences, regardless of race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability, or Veteran status. Different makes us better. **The above statements are intended to describe the general nature and level of work being performed by individuals assigned to this position. They are not intended to be a comprehensive list of all responsibilities, and skills required of employees.",
        "url": "https://www.linkedin.com/jobs/view/3948612067"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963975058,
        "company": "Metropolitan Transportation Authority",
        "title": "specialist Data Engineer",
        "created_on": 1720636999.1708648,
        "description": "JOB TITLE: Specialist Data Engineer SALARY RANGE: $110,748 - $130,719 HAY POINTS: P4/ 451 DEPT/DIV: Information Technology / Products SUPERVISOR: Deputy Chief Information and Warehouse Management LOCATION: Various/ 2 Broadway New York, NY 10004 HOURS OF WORK: 9:00 am - 5:30 pm/7.5 hrs. or as required. DEADLINE: Open Until filled This position is eligible for telework which is currently two days per week. New hires are eligible to apply 30 days after their effective date of hire. SUMMARY : This role is responsible for the design, deployment, development, and maintenance of data solutions. The Data Engineer will participate in a variety of data-related projects and work closely with Data analysts, data scientists, Business users, and other stakeholders to gather requirements and build data pipelines that meet the organizations’ needs. The Data Engineer will deploy and support Data platforms that process and store data. They will contribute to software development methods, tools, and techniques and apply agreed standards and tools to achieve well-engineered outcomes. RESPONSIBILITIES Design, develop, and implement data solutions to meet business requirements and data ingestion needs facilitating accurate and timely data availability for analysis and decision-making. Extract, load, and Transform (ELT/ETL) data from various sources, including on-premises and cloud-based systems, APIs, databases, and files. Write well-designed, efficient code that adheres to security standards. Monitor and troubleshoot data pipelines to identify and resolve issues promptly to minimize disruptions in data processing for on-premises and cloud environments. Implement data quality checks and validation processes to ensure accuracy and completeness of data. collaborate with the data team to resolve them. Writes complex queries and scripts to efficiently manipulate, transform, and process raw data. Creates and executes data validation processes to ensure the reliability and consistency of incoming data. Build processes to monitor data quality. Continuously optimize data pipelines for performance, scalability, and reliability. Create and maintain technical documentation. Contribute to building and maintaining data catalog and lineage. Design and develop CI/CD processes that ensure high availability and agility. Develop cloud data services provisioning automation with integrated capabilities of IAM, network, security policies as code, and observability. Build tools and services to support data discovery, lineage, resiliency, and privacy compliance across the data platform. Stay updated with the latest trends and best practices in data engineering, cloud computing, and Azure services to suggest innovative solutions to continually improve the organization's data intelligence capabilities. Monitors and reports on supplier performance, customer satisfaction, adherence to security requirements and market intelligence. May mentor less experienced staff Performs other duties and tasks. May need to work outside of normal work hours (i.e., evenings and weekends) Travel may be required to other MTA locations or external sites. KNOWLEDGE, SKILLS, AND ABILITIES Strong knowledge of Big Data architectures, large data warehouses, and Data Lake solutions. Experience designing and implementing Modern Data and Analytics solutions including Lakehouse architecture and medallion architecture. Proficient in cloud services including Azure Databricks. Azure Synapse Analytics, Azure Data Factory, Azure Data Lake Store, Microsoft Purview, and Power BI. Experience deploying and running cloud-based data solutions and infrastructure-as-code frameworks like Terraform. Proficient in cloud deployments (MS Azure preferred) in an agile SDLC environment, leveraging modern programming languages, and DevOps. Experience with major database platforms including Oracle, SQL Server as well as Cloud databases and NOSQL Databases. Strong understanding of data engineering concepts, ELT/ETL principles, and data modeling. Experience with data integration techniques for both structured and unstructured data. Solid programming skills in languages such as Python, Pyspark, and SQL. Experience with Airflow. Experience in DevOps, Git Repos, and CI/CD pipelines for code deployment. Experience deploying and administering cloud-based data solutions using infrastructure-as-code and infra-automation tools like Terraform, Ansible, etc. Experience with Microsoft Purview is a plus. Strong knowledge of Microsoft Azure Cloud. AWS and GCP are desirable. Functional knowledge of Microsoft Power BI Experience with Jira, Confluence. Demonstrated ability to work independently and navigate organizational ambiguity. Effective written and verbal communication skills Hands-on programming experience in a business setting. Proficiency in at least one software engineering methodology, including but not limited to Agile, Scrum, DevOps, Extreme Programming (XP), Kanban, Lean, and Rapid Application Development (RAD). Experience applying structured validation and testing methods, including but not limited to Unit Testing, Integration Testing, System Testing, Acceptance Testing, and Regression Testing. Demonstrated ability to work independently and navigate organizational ambiguity. Effective written and verbal communication skills EDUCATION AND EXPERIENCE Qualifications: Education: Bachelor’s Degree Experience: At least 3 years of relevant experience. An equivalent combination of education and experience may be considered instead of a degree. Preferred Qualifications: Microsoft Certified: Azure Enterprise Data Engineer Associate Microsoft Certified: Azure Data Fundamentals Preferred Technical Skills: Data Structures and Algorithms (Thorough Knowledge/Fully Proficient) Cloud Computing (Thorough Knowledge/Fully Proficient) Soft Skills: Active Listening, Attention to Detail, Customer Service, Prioritization, Problem-Solving, Effective Verbal and Written Communication Competencies: Collaborates Building partnerships and working collaboratively with others to meet shared objectives. Cultivates Innovation Creating new and better ways for the organization to be successful. Customer Focus Building strong customer relationships and delivering customer-centric solutions. Values Diversity Recognizing the value that different perspectives and cultures bring to an organization. Communicates Effectively Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences. Tech Savvy Anticipating and adopting innovations in business-building digital and technology applications. OTHER INFORMATION: Under the New York State Public Officers Law & the MTA Code of Ethics, all employees who hold a policymaking position must file an Annual Statement of Financial Disclosure (FDS) with the NYS Commission on Ethics and Lobbying in Government (the “Commission”). Equal Employment Opportunity MTA and its subsidiary and affiliated agencies are Equal Opportunity Employers, including those concerning veteran status and individuals with disabilities. The MTA encourages qualified applicants from diverse backgrounds, experiences, and abilities, including military service members, to apply.",
        "url": "https://www.linkedin.com/jobs/view/3963975058"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Brooklyn, NY",
        "job_id": 3959124596,
        "company": "AppliedXL",
        "title": "Senior Software Engineer",
        "created_on": 1720637001.0613904,
        "description": "About AppliedXL : The standards of a newsroom with the scale of a tech platform. We believe in holding AI to a higher standard, representing information with focus and clarity, while finding meaning with human context. AppliedXL detects early signals in data before they become news. Our intelligence platform combines machine learning with the principles of investigative journalism to anticipate events prior to their public announcement, if at all. We call this “pre-news”. We are a team of computational journalists, engineers and data scientists who have high standards for data and represent information with focus and clarity, while finding meaning with human context. We are analytical, we are transparent and we care. If you’re looking for a change and want to work on the complex problems within scaling AI-generated content with human domain experts at the helm, we’d love for you to join us on our mission. About the Role : As our Senior Software Engineer, you'll assume a critical role in shaping our vision of delivering high quality, AI-generated content to our users through bespoke user experiences. You will take charge of our client web application, ensuring it remains responsive, intuitive, and flexible to allow for rapid product development. Your expertise will extend to integrating essential third-party services, including payment and authentication systems, which are vital for a seamless user experience. Additionally, you'll oversee the development of our internal content management and quality assurance systems, which are pivotal for teaching LLMs, fostering a symbiotic relationship between AI and human editorial expertise. Your responsibilities will also extend to our Django-based backend, where your continued development will ensure scalable and efficient data handling. Your role is key to facilitating our mission: to distill complex, voluminous data into clear, impactful insights, supporting our commitment to precision and clarity in an era of information overload. Our motto is “no data vomit,” and believe big data doesn’t have to reveal itself to provide meaningful insights. We are looking for a candidate who is not just technically proficient but also aligns with our ethos of blending technology with human insight, someone who understands the value of data integrity and the impact of our work in computational journalism that drives real-time decision making. We do not want our client-facing platform to become just another news wire or reader, but instead we aim to develop user experiences that enable seamless engagement with dense AI-driven content, and your experience as a front end engineer and your eye for good design are essential in getting us there. As our team continues to grow, the Senior Software Engineer will be in a natural position to become a leader at Applied XL and one day lead a team of their own. Responsibilities : Lead the development, optimization, and maintenance of our client-facing web application, ensuring robust, clean, and efficient user experiences both on desktop and mobile. Implement responsive, accessible, and aesthetically intuitive user interfaces with React, HTML and CSS, adhering to the best practices and latest web standards. Assume ownership of our Django backend and help optimize microservices to ensure highly reactive user experiences as our content catalog across data domains continues to grow. Integrate and manage a suite of AWS services to enhance application performance, scalability, and reliability, ensuring seamless deployment and operation. Rapidly deploy internal tooling that streamlines the improvement of internal processes, such as managing taxonomies, improving LLMs, and content management & quality assurance; ensuring they support the dynamic needs of computational journalism. Collaborate with cross-functional teams to define, design, and deploy new features, while also identifying and resolving performance bottlenecks and ensuring the technical feasibility of UI/UX designs with roles including but not limited to designers, data scientists, support engineers, and content editors. Oversee the integration of third-party services such as payment gateways and authentication systems, ensuring secure, efficient, and seamless user interactions. Advocate for and implement best practices in software engineering, including code reviews, continuous integration, and automated testing, to maintain high code quality and facilitate agile development. What we’re looking for: Demonstrated ability to work independently and make informed, strategic decisions. Proven track record of taking existing systems and elevating their performance, demonstrating clear improvements in efficiency and output. Proficient in at least Javascript and Python as well as React, Redux, Django and lightweight API frameworks. Proficiency building cloud-first systems using AWS or GCP-equivalent cloud services, such as ECS/kubernetes, RDS, DynamoDB, lambda, messaging queues, logging/observability solutions and more. Experience with AI services is certainly a plus. Proven experience as a Software Engineer with a strong portfolio demonstrating expertise in React, Redux, HTML, and CSS. (we’d love to see it!) Fluent in SQL as well as experience with no-SQL and vector databases. Experience with graph databases is a plus. Experience in integrating and customizing third-party APIs, payment systems, and authentication platforms within a full-stack environment. Adept at working in an agile environment, demonstrating a proactive attitude and the ability to thrive in a fast-paced setting. Excellent communication skills, with the ability to articulate complex technical concepts to non-technical team members and stakeholders. A strong commitment to continuous learning and staying in the loop with the latest web development trends and technologies. CI/CD mindset. Experience developing test suites with Jest and Cypress or other front end frameworks that test functionality, integration, end-to-end, performance and cross browser compatibility. Some experience in UI/UX design with an eye for user efficiency, information distillation and accessibility. Applied XL Engineers Are strong communicators who can articulate complex concepts to audiences of all technical backgrounds. Do not engage in “trigger-happy data science” where standardized metrics often fail to inform complex problems. Our engineers understand data is nuanced and empathize with the real world that data represents. Thrive in cross-functional environments and are eager to learn and grow their skills outside of their core responsibilities. Have empathy for both our users and the data we serve to them. Are comfortable with some ambiguity in a fast-paced environment and enjoy prototyping as a means of validation. Work in agile SDLC environments and with issue tracking software like Jira. Enjoy building modern cloud services and are comfortable with relevant AWS services or comparable from other cloud service providers. Have at least a high-level understanding of the machine learning life cycle. Work with all kinds of databases: relational, document, search and key-value stores. Deploy rapidly and work with CI/CD tools such as CircleCI, Jenkins or others. Take pride in quality and are familiar with relevant testing frameworks. Are opinionated and strive to evolve our engineering culture. Benefits: Competitive salary and equity ownership package Comprehensive health and dental insurance Unlimited PTO",
        "url": "https://www.linkedin.com/jobs/view/3959124596"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3912843092,
        "company": "Lyft",
        "title": "Senior Software Engineer - Routing",
        "created_on": 1720637002.679739,
        "description": "At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization. We are hiring a Software Engineer to join our Routing Infrastructure team that builds and maintains Lyft’s navigation system that powers millions of Lyft rides by generating routes and etas for each ride request on our platform. To serve these needs, we need to suggest the fastest, most affordable and safest routes in realtime. We achieve this by processing millions of rides, taking into account the latest traffic information, road network data and real time events . We are looking for an engineer with proven expertise in system architecture, big-data processing and graph algorithms and experience in building scalable solutions in the cloud environments. Our technology stack runs on AWS, Kubernetes, Spark and Apache Airflow. In this role, you will work with incredibly passionate and talented colleagues from software engineering, machine learning and data science on building rideshare experiences that delight millions of riders and drivers. Responsibilities Drive high-impact projects and innovate new solutions to provide the best routing experience. Build and deploy mission critical algorithms and services that can scale well to serve millions of requests per day (routing engine: C++, backend services: Go, Python) Drive cross-team initiatives and mentor junior engineers Lead large projects from ideation to launch. Understand customer needs, write tech-specs to communicate system design, drive cross-functional collaboration and own project deliverables. Participate in code reviews, design reviews, production on-call support and incident triaging process. Write well-crafted, well-tested, readable, maintainable code Experience 5+ years of professional software engineering experience Extensive experience in object-oriented programming (ideally C++ or Go) Hands-on experience with cloud computing using AWS, GCP or Azure Experience with Linux Benefits: Great medical, dental, and vision insurance options Mental health benefits Family building benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. The expected range of pay for this position in the New York City area is $ 144,000 - $180,000 . Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.m",
        "url": "https://www.linkedin.com/jobs/view/3912843092"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3885980933,
        "company": "DoubleVerify",
        "title": "Full Stack Software Engineer",
        "created_on": 1720637004.3178568,
        "description": "Position Overview As a Full Stack Developer, you will be working with a talented team responsible for enabling clients to successfully setup and operate DoubleVerify’s rich suite of products. You will be responsible for developing client facing screens and components and the back-end services handling the business logic of those products. You will need to emphasize UI and UX flawless experience in terms of responsiveness, ease of use and functionality. You will be closely coordinating and working with multiple development, product and Client Services teams. This position is full-time and located in our New York City headquarters office. What You’ll Do Build applications utilizing backend and frontend development. Develop client side visualizations for UI driven products using Angular framework. Develop client side code in Javascript, Typescript, and NodeJs to integrate the client visualization with the business logic. Style client components using Material, CSS and SCSS Design, develop and document APIs to be used by partners and other development teams. Design and develop robust microservices built with .NET Core and Java. The services are integrated with various systems including Salesforce, databases and internal APIs. Design and create relational databases along with the applications accessing them. Test and optimize code developed both by you and by other team members. Work in continuous development and integration cycles by utilizing a micro-frontend and microservices backend architectures with automated packaging and deployments. Work in a fast paced, agile environment, collaborating with team members and Product Managers on a daily basis and participating in product meetings. Analyze data to study the usage patterns and effectiveness of client facing systems in the ongoing effort to provide the most user friendly experience. Who You Are At least 3 years of total programming experience. At least 2 years of experience in Angular. At least 1 year of experience programming in C#, Java or C++. At least 1 year of experience in relational databases like MySQL or SQL Server. At least 1 year of experience Node.js, JavaScript, TypeScript, HTML, and CSS. Familiarity with modern microservice architecture, and web-based/REST API’s. Collaborates with team members and participates in Production Support. Salesforce experience is a plus. ReactJS experience is a plus. Excited to be a part of an inclusive culture where everyone brings the aspects of themselves to the workplace that they need to thrive. The successful candidate’s starting salary will be determined based on a number of non-discriminating factors, including qualifications for the role, level, skills, experience, location, and balancing internal equity relative to peers at DV. The estimated salary range for this role based on the qualifications set forth in the job description is between [$79,000- $139,000]. This role will also be eligible for bonus/commission (as applicable), equity, and benefits. The range above is for the expectations as laid out in the job description; however, we are often open to a wide variety of profiles, and recognize that the person we hire may be more or less experienced than this job description as posted. Not-so-fun fact: Research shows that while men apply to jobs when they meet an average of 60% of job criteria, women and other marginalized groups tend to only apply when they check every box. So if you think you have what it takes but you’re not sure that you check every box, apply anyway!",
        "url": "https://www.linkedin.com/jobs/view/3885980933"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3874928107,
        "company": "AppCard, Inc.",
        "title": "Senior Software Engineer",
        "created_on": 1720637005.9275472,
        "description": "Senior Software Engineer – On Site: New York, NY Company Profile AppCard builds software used by millions of shoppers every day. We let the independent retailer compete with the largest big box stores by providing them with a top tier suite of analytics and marketing tools that help grow and power their business. We’re a small agile team that lets our engineers take ownership of their code. We believe in doing things the right way, and aren’t afraid to try new things. AppCard is rapidly growing with leadership comprising seasoned tech entrepreneurs and loyalty marketing pioneers, alongside investors such as Founders Fund and Innovation Endeavors with backers behind giants like Facebook and AirBnB. Join us early in our journey to reshape retail! Objective of this Role As AppCard expands its services and integration efforts, we&#39;re seeking a seasoned Senior Software Engineer to join our NYC-based team. This role is pivotal in developing and enhancing our platform, ensuring we continue to deliver exceptional value to our users and clients. If you&#39;re passionate about leveraging your extensive engineering expertise to drive innovation and scale cutting-edge solutions, we&#39;d love to have you on board. Responsibilities Design, develop, and maintain scalable software solutions in collaboration with your engineering peers. Lead technical architecture discussions and guide the development of complex scalable systems with distributed edge devices. Mentor engineers and lead knowledge building initiatives, fostering a culture of technical transparency and accountability. Troubleshoot, identify, and resolve high-level systemic issues across platforms. Collaborate cross-functionally with customer success, support, and business teams to deliver on company goals. Stay abreast of emerging technologies and propose adopting new solutions that can enhance AppCard&#39;s offerings. Work on new designs and refactor old systems to meet new business needs and scale. Contribute to technical roadmapping and influence new features. Bring in new technologies and frameworks as you see fit. Skills and Qualifications A Rich Background: 5+ years of hands-on experience in developing high-performance distributed systems. Your journey has equipped you with expert coding practices and a proven track record in a senior role. Technical Mastery: A solid foundation in computer science principles, excelling in software design, and an appreciation for both monolithic and distributed architectures. Experienced in Python and Java with a keen ability to identify, adopt, and champion the right tools for the task at hand. Experienced in cloud services (e.g., AWS) and CI/CD pipelines. A Proactive Approach: Demonstrated capability in developing and implementing efficient tools, processes, and methodologies to address challenges and enhance efficiency. You&#39;re skilled at identifying and resolving potential bottlenecks efficiently. Whenever you raise issues you bring along possible solutions as well. Independence and Initiative: The ability to lead projects from inception to delivery, demonstrating your capacity to work autonomously and produce solutions that meet or exceed project expectations. A Commitment to Excellence: An unwavering belief in the importance of documentation, recognizing that clear, comprehensive documentation is as crucial as the code itself. Your Role and Responsibilities Will Include: Hands-On Leadership: Direct engagement with your team and partners to develop and deploy secure, industry-standard code that&#39;s robust and ready for production. Culture of Quality: Championing a culture of quality in every aspect of the development process, ensuring that the products we deliver are of the highest standard. Clean Code: Advocating for clean code practices, ensuring that our codebase remains manageable and efficient. You&#39;ll take a proactive stance on controlling technical debt, making strategic decisions that balance immediate needs with long-term maintainability. Mentorship: Actively mentoring engineers, contributing to their skill growth and career development, sharing your expertise and insights to enhance team capability and performance. Effective Communication: Facilitating clear and effective communication across various teams and stakeholders, ensuring transparency and efficiency in all project phases. Things that Will Make You Happy A leadership team that values innovation and promotes a culture of transparency and support. Competitive compensation package, including stock options and comprehensive benefits. A casual and inclusive office environment with a focus on results, not politics. Opportunities for professional growth and development in a growing sector. Flexible working arrangements to accommodate life’s opportunities and challenges. An empathetic manager who cares about you and will invest in your professional development. Stock options. Competitive salary and incentives. Choice of health, dental and vision benefits. Life Insurance Coverage, 401(k) plan, vacation/sick leave, paid company holidays. Flexible Spending Account (FSA). Health Savings Account (HSA). Commuter benefits. Join AppCard in transforming the retail landscape and strengthening shopper experience through technology. Apply now to become a part of our mission-driven team as a Senior Software Engineer. **This role is from our NY office**",
        "url": "https://www.linkedin.com/jobs/view/3874928107"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Hawthorne, NY",
        "job_id": 3914812798,
        "company": "Wimmer Solutions",
        "title": "Senior Data Engineer",
        "created_on": 1720637007.7371893,
        "description": "SENIOR DATA ENGINEER JOB ID: 22848 As a member of our Software Engineering Group, we look first and foremost for people passionate about solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle and partner continuously with your many stakeholders daily to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally. A successful candidate is an active listener with good interpersonal communication and can ask for and give feedback to others. The Sr. Data Engineer is someone who constantly communicates with different internal and external stakeholders and business owners. What You Get To Do Work with management and internal stakeholders to define business requirements and analytical needs and execute against them. Develop a deep understanding of existing eCommerce performance, customer, brands, and productivity metrics, and develop new KPIs, metrics, and measures to gauge eCommerce performance. Own regular and ad-hoc analysis on operational performance and projects to continuously improve and scale company's eCommerce operations. Work to define and structure eCommerce customer and operational data and ensure the reliability and integrity of data sources. Perform data modeling using/modifying existing models. Build automated data flows on AWS by extracting and transforming data from existing e-commerce systems, log files, and API sources. WHAT YOU BRING Expert-level skills in writing and optimizing SQL. Experience operating very large data warehouses or data lakes. Expertise in ETL optimization, designing, coding, and data ingestion from Rest and GraphQL API. Experience with building data pipelines and applications to stream and process datasets at low latencies. Show efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data. Sound knowledge of distributed systems and data architecture utilizing Lambda, Python, and Jupyter. Experience in AWS Data Analytics platform and related services - S3, AWS Glue, Redshift, Athena, Lake Formation, Lambda, etc. Experience in building data pipelines using Spark/Glue Good understanding of Data Warehousing and Data Modelling concepts on AWS Redshift Experience in designing and optimizing Redshift Workloads Good knowledge of defining data access roles and permission for Redshift Capable of learning and adapting to new technologies along with good Analytical skills Experience working on Visualization tools like AWS QuickSight, Tableau, or Sigma is a plus. Experience in Java, IntelliJ, Bitbucket, Gradle is plus. 4-year degree (Economics, Statistics, Mathematics, Computer Science, MIS, or similar focus) and 3-5 years of relevant work experience. 5+ years of experience in ETL, Data warehousing, Data pipelines, Data Analytics, in Microsoft or Amazon cloud. AWS Data Stack is preferred. Must be able to work for a US based company without requiring visa sponsorship. Compensation Base salary range of $100,000 to $110,000, based on experience and qualifications, as well as geographical market and business considerations. MORE ABOUT WIMMER SOLUTIONS Wimmer Solutions is proud to be an equal-opportunity employer. All applicants will be considered for employment regardless of race, color, religion or belief, age, gender identity, sexual orientation, national origin, parental status, veteran, or disability status. Wimmer Solutions is committed to achieving a diverse employee network through all aspects of the hiring process and we welcome all applicants. If you are passionate about what you do and want to join a diverse team dedicated to diversity, equity, and inclusion in the workplace, we would love to hear from you. Get the job you have always wanted. You will join a broad team of professionals who are energized about their careers as well as their community. For more career opportunities or to refer a friend, please visit http://wimmersolutions.com/careers and talk to a recruiter today.",
        "url": "https://www.linkedin.com/jobs/view/3914812798"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888428406,
        "company": "Stellent IT",
        "title": "Full Stack Software Engineer (Python/JavaScript)",
        "created_on": 1720637009.5344586,
        "description": "New York, New York 1 year Hybrid (2 Days Onsite/3 Days Remote) The Opportunity Full Stack Development, Design, & Implementation of complex MBS (Mortgage-Backed Securities), Front & Mid-Office Applications, Trading, Risk Management, Collateral Management, or Securities Processing Applications. Proficient in translating business requirements to easy to use and Primary Skills: Python, JavaScript, Automation Requirements & Responsibilities Bachelors' degree in Computer Science or Equivalent professional experience. 10-20 years of Hands-on Software Development experience in Python, JavaScript, and SQL (additional programming language experience a definite plus) Full Stack Developer role, strength in both Front-end & backend development experience required. Experience with financial, banking systems preferred, ideally Fixed Income - MBS (Mortgage-Backed Securities), Front & Mid-Office Applications, Trading, Risk Management, Collateral Management, or Securities Processing. Experience on caching frameworks. Experience on distributed computing using Grid. Good understanding on OOP fundamentals, Data structures, Design patterns. Ability to analyze, design, develop and troubleshoot new and existing applications. Experience on Risk systems in financial industry is added advantage. Good Communication Skills, Experience Dealing With Global Team Members Pankaj IT Technical Recruiter Phone : (201) 584-1186 Email: ************* Gtalk: ************* LinkedIn : https://www.linkedin.com/in/pankaj-sharma-63510b241/",
        "url": "https://www.linkedin.com/jobs/view/3888428406"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3944618708,
        "company": "L'Oréal",
        "title": "Senior Manager, Custom Data Analytics Engineer",
        "created_on": 1720637013.1055205,
        "description": "Job Title Senior Manager, Custom Analytics Engineer Division: IT, Data Location: Hudson Yards Who We Are For more than a century, L’Oréal has devoted its energy, innovation, and scientific excellence solely to one business: Beauty. Our goal is to offer each and every person around the world the best of beauty in terms of quality, efficacy, safety, sincerity and responsibility to satisfy all beauty needs and desires in their infinite diversity. At L'Oréal, our IT teams design and build solutions to ensure high performance for all our business sectors by imagining new ways of doing things, from designing websites to building algorithms and predicting new trends. They can be found leading teams towards a more connected and digitalized future in IT retail, e-commerce, CRM, data, AI, cybersecurity, Cloud and E-Marketing. You never stop learning at L'Oréal IT because things change at the speed of light! Come join our dynamic team! What You Will Do We are seeking a Custom Analytics Engineer to join our team and help us develop cutting-edge data and analytics solutions. This role resides within the Data & Analytics group and the ideal candidate will have a deep understanding of business intelligence (BI). The successful candidate will have the ability to develop innovative solutions that help our business gain valuable insights from their data. While technical prowess is essential, the incumbent must also possess a business-oriented mindset, collaborating effectively with key stakeholders, including upper management. This role is at the forefront of driving the Enterprise BI transformation by modernizing our Business Intelligence suite. Develop and deploy BI and analytics solutions to extract actionable insights from data Design and implement architectures for data collection, storage, and analysis Design and implement advanced analytics solutions, such as predictive analytics and forecasting Provide thought leadership, strategic direction, and vision for the business intelligence program. Formulate and communicate a comprehensive business intelligence strategy, collaborating with senior leadership to identify and address key business opportunities through data analysis. Ensure governance for Enterprise BI deployments. Design, construct, and deploy Power BI solutions, including dashboards and reports, adhering to best practices for information communication. Create clean and efficient data sets, modeling data in a manner that empowers end-users to answer their own questions. Collaborate with business owners and business analysts to understand requirements and translate them into insightful visualizations. Research and stay current on new trends and technologies in data and analytics Required Qualifications What We Are Looking For: Over 7 years of experience in Business Intelligence and/or Data Analytics, with a track record of leading BI initiatives and projects, particularly involving Power BI. Proficiency in developing, maintaining, and enhancing dashboards using Power BI and other BI tools. Extensive experience in Data Visualization, multiple DBMS, and Data Warehouses. Self-reliant, capable of managing projects end-to-end, particularly those with medium-term issues. Skilled in collecting, organizing, and tracking requirements. Strong analytical skills, particularly in data analysis. Familiarity with relational database concepts and data warehousing principles. Background in using a Git-based code repository. Exceptional project management skills with keen attention to detail, accuracy, and deadlines. Proficient in analytical, problem-solving, and critical-thinking skills, with the ability to translate data insights into actionable business recommendations. Excellent communication and interpersonal skills, capable of collaborating with cross-functional teams and presenting complex ideas to non-technical stakeholders. Proven ability to generate reports from existing databases, data lakes, data marts, and non-relational data sources, reconciling data across multiple source systems. Comfortable in a dynamic, fast-paced, Agile, and matrix work environment. Experience with Analytics/Visualization tools such as PowerBI, Looker, Tableau. Knowledge of implementing security and Identity and Access Management (IAM) requirements. Experience in developing proof of concepts and prototypes with Generative AI capabilities and innovative virtual agent solutions, utilizing large language model capabilities to facilitate digital transformation for customers and partners. Join us in shaping the future of beauty through cutting-edge technology and analytics. Be part of a dynamic team dedicated to innovation and excellence in every facet of our business. What’s In It For You Salary Range: $119,900-$170,800 (The actual compensation will depend on a variety of job-related factors which may include geographic location, work experience, education, and skill level) Competitive Benefit Package (Medical, Dental, Vision, 401K, Pension Plan) Hybrid Work Policy (3 Days in Office, 2 Days Work from Home) Flexible Time Off (Paid Company Holidays, Paid Vacation, Vacation Buy Program, Volunteer Time, Summer Fridays & More!) Access to Company Perks (VIP Access to L’Oréal’s Internal Shop for Discounted Products, Monthly Mobile Allowance) Learning & Development Opportunities (Unlimited Access to E-learnings, Lunch & Learn Sessions, Mentorship Programs, & More!) Employee Resource Groups (Think Tanks and Innovation Squads) Access to Mental Health & Wellness Programs Don’t meet every single requirement? At L'Oréal, we are dedicated to building a diverse, inclusive, and innovative workplace. If you’re excited about this role but your past experience doesn’t align perfectly with the qualifications listed in the job description, we encourage you to apply anyways! You may just be the right candidate for this or other roles! We are an Equal Opportunity Employer and take pride in a diverse environment. We would love to find out more about you as a candidate and do not discriminate in recruitment, hiring, training, promotion, or other employment practices for reasons of race, color, religion, gender, sexual orientation, national origin, age, marital or veteran status, medical condition or disability, or any other legally protected status. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to access job openings or apply for a job on this site as a result of your disability. You can request reasonable accommodations by contacting USApplicationAccommodation@support.lorealusa.com. If you need assistance to accommodate a disability, you may request an accommodation at any time. Our Safe Together Plan: Your safety is our highest priority. We will proceed with caution and adhere to enhanced protection standards to ensure our sites are safe for all employees. We must all operate with the shared responsibility for each other’s health & safety in mind. LI_USA_CORP",
        "url": "https://www.linkedin.com/jobs/view/3944618708"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3927314395,
        "company": "Ekho (YC S22)",
        "title": "Full-Stack Software Engineer",
        "created_on": 1720637014.8607213,
        "description": "Who are we looking for? We’re looking for a full-stack generalist excited about learning new tools, overseeing the end-to-end development process for new features and products, and joining a small (but growing!), fast-paced team. In our product, we have to solve for a wide variety of complex, independent tasks including - but not limited to - automated financing, insurance, titling and registration, identity verification, delivery coordination, e-signatures, etc. Building a singular, cohesive product accomplishing this huge variety of tasks is a big undertaking and requires close communication and collaboration across our entire team. While different areas of the codebase are owned and predominately maintained by certain engineers, we’re still small enough that projects will often take you across the entire tech stack. In this role, you’ll be in constant communication with clients - both manufacturers (our customers) and the end users of the platform (vehicle buyers) - and will be expected to leverage feedback quickly and turn them into product improvements. While you’ll predominately be working on the core parts of our product (our checkout and buyer portal web apps and associated Node.js backend), from time to time we’ll have projects and tasks associated with automating internal (and external) processes, improving our dev infrastructure, fighting fires, and integrating new tools. You’ll be given a significant amount of autonomy in this role. On the features and products that you build out, you will serve as the de facto owner with the loudest voice in the room on feature improvements and implementation design. You’ll have the power to advocate and fight for the projects you want to work on and you think should be prioritized; this will directly contribute towards our strategy decisions. Things are changing quickly on our side; if you expect long-term roadmaps with tasks defined months in advance, then this role probably doesn’t make sense for you. Core Infra Front end: React web apps Back end: Node.js (serverless) backend using express.js and a NoSQL db VC + CI/CD: Github / GH actions SaaS tools: GCP + Firebase, Retool, Stripe, Segment, Mixpanel, Notion, Zapier, Cypress, and many more... You certainly don't need to be experienced in all of these areas; but you should be excited to learn new skill sets & tools as you need them. We also expect you to bring some new knowledge and experiences you can share to help level-up the rest of the team. Responsibilities Lead key architecture decisions for the platform Designing core, backend software components Crafting and optimizing smooth front-end interfaces that thousands of users will use Scoping and integrating with third-party APIs, including direct communication with all stakeholders (vendors, customers, etc) involved Diagnosing and addressing bugs and performance issues Producing high-quality, production-ready, readable, and maintainable code Collaborating towards dev ops improvements to increase engineering team scalability and code reliability Unblocking and supporting team members and customers Please note: that this role is in-person with at least 4 days per week in the office in NYC! Qualifications Generality and ability to move across the stack: Backend: experience and proficient in Node.js + Express.js Frontend: proficient in javascript, React, a good eye for design (a nice-to-have and not strictly required), and (ideally) mobile design experience Excellent communication skills: you’ll be working closely with other engineers on our team and with external customers, vendors, and end-users on a daily basis. Demonstrated ability to thrive in ambiguous environments with competing priorities and tight deadlines Product-driven engineering approach: a keen awareness towards the impact your code has on the user experience High energy & motivated to work long hours to build an incredible product and revolutionize the vehicle sales industry Benefits Annual Salary Range: $115,000—$190,000 USD Your offer will include a competitive salary, employee-friendly equity grant, and the following: Healthcare and dental coverage Paid lunch during the work week Regular team events, off-sites, and team-travel paid for by the company (we recently spent a few weeks in Maine, Norway, and South Africa!) Unlimited paid time off",
        "url": "https://www.linkedin.com/jobs/view/3927314395"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3887037969,
        "company": "Vatic Labs",
        "title": "Software Engineer (Full Time)",
        "created_on": 1720637018.2915611,
        "description": "As a Software Engineer at Vatic Investments, you will develop innovative software solutions that drive our trading and research efforts. While performance is a critical component of our systems, we are also focused on building massively scalable, flexible, and forward-looking software. Our Software Engineers develop code that enables rapid testing and application of our trading models. Collaborating across teams, you will play a key role in engineering cutting edge, ultra-low latency, high throughput trading systems from conception to deployment. You will drive innovation for the frameworks upon which our trading applications are based, as well as benchmarking and tuning critical software services to achieve optimum performance. The nature of the problems we work on are challenging, hence we hire some of the world's top computer scientists and researchers to develop novel AI methods and trading strategies. Our team of talented technologists have been recognized as leaders in their field. We are passionate about hiring the best and the brightest, empowering them with the tools and mentorship needed to be successful. Our environment is highly collaborative, fostering innovation and growth. If you possess the following, we would love to explore what is available for you with our team: Earned or will earn an undergraduate or graduate degree in Computer Science, Electrical Engineering, Mathematics or related quantitative field. Demonstrable experience with C/C++ or Python in a Linux environment with an emphasis on low latency and distributed computing Ability to design fast algorithms and optimize complex data structures Strong understanding of hardware stack and hardware architecture from a latency perspective Strong understanding of network protocols Experience writing assembly code Knowledge of operating system internals and Linux kernel Have interest and enthusiasm for learning about financial markets (previous experience not required) While we are serious about our work at Vatic, we also promote a fun environment! You can expect: Ping pong and poker games Fun team outings Unlimited office snacks Free breakfast, lunch, and dinner Gym membership Full health insurance coverage for employees and dependents The base salary range for this role is between $150,000 and $200,000. The base salary range does not include any other form of compensation, such as any bonus amounts, or any benefits. Factors that may impact the agreed upon base salary within the range for a particular candidate include years of experience, level of education obtained, skill set, and other factors.",
        "url": "https://www.linkedin.com/jobs/view/3887037969"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3950745527,
        "company": "Salvo Health",
        "title": "Software Engineer",
        "created_on": 1720637020.366083,
        "description": "Salvo is a new approach to help millions of Americans facing chronic health conditions, centered on chronic gut health and metabolic conditions from IBS to obesity. Our patients are assigned a “whole patient” care team and have seven day a week access to app-based care, using Remote Patient Monitoring (“RPM”) to bill under the patient’s insurance. This is a major step forward to go beyond episodic appointments to continuous care at home, and deliver interdisciplinary wraparound care in partnership with the patient’s existing local doctor. Salvo is backed by leading health care investors from innovators like Livongo, Ro, Ginger, Forward, Brightline, Tia, and others. Salvo care draws on expertise from Board-certified specialty physicians, registered dietitians, nurses, psychologists, and therapists who have developed our evidence-based protocols, for a personalized, multi-month journey to better health. Salvo is the first to bring a scalable and tech-enabled, more integrative approach to these chronic conditions, going beyond treating only the symptoms in order to identify and address the root causes of chronic illness. As a Software Engineer, you will contribute to frontend, backend, and mobile applications up and down the stack. As a small team, we highly value the ability to learn quickly and participate in a shared responsibility for all the elements of our product. You will report to the Head of Engineering. We work remotely, but have a small hybrid presence of folks in and around New York, NY. Please note that we cannot provide visa sponsorship for this role. What you will do: Contribute to the development of our web, mobile, and backend applications Partner with Product and Design to guide the direction of our products, integrations, and technology. Your participation in the product development process is essential! Integrate third-party technologies including medical devices and EHRs into our platform Build mobile features and experiences with React Native Participate in code review Requirements: 2+ years of professional experience engineering data-rich consumer applications Experience designing and building APIs for applications, consuming APIs in applications, and opinions about what makes a quality API Excitement about working in a dynamic environment with unanswered questions Bachelor's Degree in Computer Science or similar field, or equivalent experience Authorization to work in the United States Nice to have: Experience with React web development Experience with React Native or mobile app development in general Experience with healthcare technology Tools we use Typescript, Vite+React, React Native, Fastify AWS including RDS Postgres, ECS, StepFunctions Honeycomb, Sentry, LaunchDarkly Linear, Coda Salvo believes that the most inclusive and equitable culture makes for a better business, so we welcome diverse candidates for this role. We are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates. A core mission is to increase access to better and more convenient care for patients, especially among Millennial and GenZ women whose complaints are often not taken seriously by the existing medical system. Many of our patients struggle to get access to the right doctor given the shortage of specialists, and often their doctors are not trained in the relevant areas of behavioral medicine, nor have the financial incentives to give daily support for follow-up care. Salvo aims to offer a comprehensive benefits package to support our employees. Aside from a competitive salary and a remote-first environment, we offer medical/dental/vision insurance, membership to One Medical, a 401k program, generous PTO, and more!",
        "url": "https://www.linkedin.com/jobs/view/3950745527"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3966040952,
        "company": "Rogo",
        "title": "Software Engineer (Backend)",
        "created_on": 1720637024.3045154,
        "description": "About Rogo Rogo is a generative AI platform reinventing how people work, starting with financial services. Our team is lean, smart, and enormously ambitious. We're growing fast, and we work in person at our beautiful office in NYC. Our mission is to make people smarter by giving everyone an AI analyst. We're unabashedly ambitious, and we're dead set on building the biggest Financial AI company in the world. Why join? Exceptional traction: strong PMF with the world's largest investment banks, hedge funds, and private equity firms. World-class team: we take talent density seriously. We like working with incredibly smart, driven people. Crazy velocity: we work fast, which means you learn a lot and constantly take on new challenges. Frontier technology: we're developing cutting-edge AI systems, pushing the boundaries of published research, redefining what's possible, and inventing the future. N-of-1 Product: Our platform is state-of-the-art and crazily powerful. We're creating tools that make people smarter, reinventing how you discover, create, and share knowledge. About The Role As a backend engineer at Rogo, you'll be at the cutting edge of AI research and application development, playing a crucial role in creating a category-defining product and scaling it to massive enterprises. Responsibilities Architect and lead the development of our applications, APIs, and distributed systems Architect & document our tech platform and advise key product & infrastructure decisions Implement our CI/CD workflows, using Docker & Github Build analytics & monitoring to help understand our user experience & application health Contribute in a ton of other ways to a scrappy founding team building the future of flexible light industrial staffing! Qualifications Requirements You write amazing code, fast. 5+ years of experience building and scaling distributed systems. A deep understanding of how infrastructure-layer (Kubernetes, Database, OS, Cloud Storage etc) software systems work. Strong attention to detail and spidey sense for where and when things could go wrong. Track record of shipping high-quality products. Strong programming skills and general Computer Science knowledge. Bonus Experience with a strongly typed language (e.g., Rust) Early engineer at a hyper-growth startup. Experience in world-class product organizations (e.g., Notion, Figma). Financial services experience. You'll fit in at Rogo if... You have fun solving problems that others think are impossible You are high-intensity and care a lot about what you do You are ecstatic to work at a start-up You're innately curious and find joy in learning about AI and finance You are autonomous, self-directed, and comfortable working with ambiguity You have eclectic interests",
        "url": "https://www.linkedin.com/jobs/view/3966040952"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959298054,
        "company": "EliseAI",
        "title": "Founding Software Engineer - Healthcare",
        "created_on": 1720637026.2042716,
        "description": "About EliseAI EliseAI develops cutting-edge conversational AI technology for industries fundamental to our lives: housing and healthcare. Everything is built on the foundation of health and home. Broken systems or ineffective processes in these domains have a disproportionate impact on our quality of life and society’s overall wellbeing. Conversely, any solution or technology that solves problems in these areas will have an impact that ripples far beyond them. That’s the only kind of impact we are interested in having at EliseAI. If you get excited by the thought of working really hard on these kinds of problems, then EliseAI is the right place for you Why choose EliseAI? EliseAI is breaking into a new vertical: healthcare. We are looking to hire a Founding Software Engineer to play an essential role in building up our new business unit. You’ll work at a startup within a startup, driving transformative change in healthcare. As a Software Engineer in our healthcare division, you won't just write code; you'll create the playbook. Every single day, you will be challenged to identify how we can scale and execute on it. Working alongside other talented engineers, you'll have the opportunity to take on significant ownership, lead projects, and see your ideas come to life. Here Are Your Core Objectives Contribute rapidly to our core software platform that automates the patient experience and helps our customers operate their practice more efficiently. Develop and own new features that increase value for our customers. Propose meaningful improvements to our software architecture and design patterns. Learn and drive engineering best practices. Leverage automating testing and continuous integration / continuous delivery in order to rapidly iterate on our product. What we're seeking: We’re much more interested in someone who is hungry to learn and perform at a fast growing startup than someone whose resume checks all the boxes. Ambitious Innovators: We're in search of individuals who share our excitement for AI's potential to drive positive change. Your passion will fuel our mission to transform industries and improve lives. If you're motivated by challenges and ready to make your mark, you're exactly who we're looking for. Collaborative Contributors: Collaboration is central to our success. We're seeking team players who thrive in a collaborative environment, communicate effectively, and are enthusiastic about learning from their peers. Someone who also: Has a startup mindset, ownership, and a proper balance of quality and sense of urgency Is great at solving problems with little guidance Has strong bias for action Has strong system design knowledge Has 2+ years of Java, C#, Go or Python experience Is willing to work in person at NYC headquarters with their team 4-5 days per week Nice to haves include: Understanding of microservices architecture and event-driven distributed systems Understanding of machine learning and data AWS experience Benefits Benefits In addition to the growth and impact you’ll have at EliseAI, we offer competitive salaries along with the following benefits: Equity in the company in the form of stock options Medical, Dental and Vision premiums covered at 100% Fully paid parental leave Commuter benefits 401k benefits Monthly fitness stipend Our brand new Midtown south office with an open floor plan, fully stocked kitchen, and company paid lunch Fun company social events through our Elise and the City program Unlimited vacation and paid holidays We'll cover relocation packages from outside of the Greater NYC metro area - we'll make the move exciting, not painful. Job Compensation Range The salary range for this role is $210,000 - $260,000. EliseAI offers a competitive total rewards package which includes base salary, equity, and a comprehensive benefits & perks package. Exact compensation inclusive of salary and any bonuses is determined based on a number of factors including experience and skill level, location and qualifications which are assessed during the interview process. Additional details about total compensation and benefits will be provided by our Recruiting Team during the hiring process. EliseAI provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at HR@eliseai.com",
        "url": "https://www.linkedin.com/jobs/view/3959298054"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3971228543,
        "company": "Selby Jennings",
        "title": "Multi-Strat Hedge Fund | Staff Software Engineer",
        "created_on": 1720637027.870705,
        "description": "Multi-Strat Hedge Fund | Staff Software Engineer Selby Jennings is working with one of the most successful hedge funds in the world. This firm has stood the test of time for decades bringing consistent, high returns to their investors. They have been able to accomplish this by leveraging state-of-the-art technology, hiring exceptional engineers, and driving a highly collaborative culture. Currently, they are seeking a quantitative software engineer to join one of their most high-performing teams. Essentially, this team is like a startup within the firm and tackles the business objectives of the highest priority. This candidate must come from a quantitative finance background as they will build and scale one of the largest equities portfolios in the market by optimizing various aspects of the investment, risk management, portfolio construction, and trade execution lifecycle. Qualifications & Requirements: 7-12 years of professional experience 5+ years of Python programming experience including scientific libraries (Pandas, NumPy, SciPy, etc) Experience with a least two languages other than Python Analytical skills – Ability to troubleshoot and logically assess problems and determine solutions Degree in Computer Science, or other related fields (MS or PhD is a plus!) Great-to-haves: Startup experience Big tech experience using machine learning in a recommendations team Basic knowledge of statistics Experience with financial modeling and pricing Experience acquiring, analyzing, and organizing time-series, financial data, and fundamental data",
        "url": "https://www.linkedin.com/jobs/view/3971228543"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3926131505,
        "company": "UBS",
        "title": "Evidence Lab Data & Analytics Software Engineer",
        "created_on": 1720637029.4563868,
        "description": "Job Reference # 296162BR Job Type Full Time Your role Do you have a passion for building technology platforms? Do you have strong Python and SQL development experience? Do you long for a challenging environment where you can leverage your problem-solving skills? Evidence Lab Data and Analytics provides data access and analysis platforms to internal Research Analysts as well as external Fundamental and Quant clients. We are looking for someone who can: co-develop and deliver along our API and data distribution product vision, strategy and roadmap covering the full product development lifecycle write clean, efficient and maintainable code in Python and SQL (Java experience helpful) support new products and product changes iteratively and continuously together with cross-functional team members in the pod participate in software development life cycle activities including requirements analysis, design, coding, testing and deployment drive pod Objective and Key Results (OKRs) and provide relevant product measurements and metrics to meet overall business goals ensure the product is being tested together with business partners and IT to gain insights and ensure readiness to launch before rollout support end to end business operations for a successful implementation (e.g. conducting training, updating documentation, providing product support, resolving incidents and remediating the root cause of risks and issues) ensure continued high data quality and reliability by proposing and implementing data quality checks Your team Based in New York, you’ll be working within Evidence Lab as part of a global team. Your expertise strong industry experience in Python development – can demonstrate all OOP concepts, Pandas, NumPy, DuckDB strong database experience including expertise in writing SQL (ideally Oracle and/or Postgres) exposure to cloud (ideally Azure), ADLS, Terraform, AKV and migration of applications from on-premise to cloud experience with source code management, Gitlab, build pipelines, CI/CD experience with JupyterHub, kernels, Docker, Kubernetes, etc. proven understanding of data integration, architecture, data quality, performance, monitoring, and reporting experience in analyzing and capturing technical requirements as stories with acceptance criteria fulfilling a Definition of Ready proven ability to write unit and integration tests experience working in agile environments with understanding of agile delivery frameworks About Us UBS is the world’s largest and the only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal & Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors.. We have a presence in all major financial centers in more than 50 countries. Join us At UBS, we embrace flexible ways of working when the role permits. We offer different working arrangements like part-time, job-sharing and hybrid (office and home) working. Our purpose-led culture and global infrastructure help us connect, collaborate, and work together in agile ways to meet all our business needs. From gaining new experiences in different roles to acquiring fresh knowledge and skills, we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact? Disclaimer / Policy Statements UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. Your Career Comeback We are open to applications from career returners. Find out more about our program on ubs.com/careercomeback. Salary Information CA, CO, WA and NY based roles: The salary range for this role is $127,500 to $145,000 based on experience, education, and skill level. This role may be eligible for discretionary incentive compensation. For benefits information: ubs.com/usbenefits.",
        "url": "https://www.linkedin.com/jobs/view/3926131505"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3970195567,
        "company": "myGwork - LGBTQ+ Business Community",
        "title": "Lead AWS Data Engineer",
        "created_on": 1720637031.211847,
        "description": "This inclusive employer is a member of myGwork – the largest global platform for the LGBTQ+ business community. We are At Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron's progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honored with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,000+, and has 55 offices in 20 countries within key global markets. Our challenge We are looking for an experienced Data Visualization and Migration Specialist with a strong background in AWS QuickSight, AWS Redshift, and Amazon Q. The ideal candidate will have a proven track record of working with data visualization tools, as well as extensive experience in data migration activities, specifically moving data from on-premises data stores to Amazon Redshift. Additional Information* The base salary for this position will vary based on geography and other factors. In accordance with law, the base salary for this role if filled within New York, NY is $130k - $150k/year & benefits (see below). The Role Responsibilities Design, develop, and maintain interactive dashboards and reports using AWS QuickSight. Leverage Amazon Q for natural language query capabilities to enhance data accessibility and usability. Manage and optimize AWS Redshift data warehouses, ensuring data integrity and performance. Conduct data migration from on-premises data stores to AWS Redshift, including planning, execution, and validation. Collaborate with cross-functional teams to understand business requirements and translate them into effective data visualizations and reporting solutions. Implement best practices for data management, data quality, and data governance. Troubleshoot and resolve issues related to data visualization and data migration. Provide training and support to end-users on using AWS QuickSight and Amazon Q. Stay updated with the latest trends and technologies in data visualization and data migration. Requirements You are: Bachelor's degree in Computer Science, Information Systems, Data Science, or a related field. Strong SQL Development skill is a must Strong data modelling skills is mandatory 4-5 years of experience working with data visualization tools, specifically AWS QuickSight. Strong expertise in AWS Redshift, including data warehousing and performance optimization. Experience with Amazon Q for enhancing data accessibility. Proven experience with data migration activities, particularly moving data from on-premises data stores to Amazon Redshift. Proficient in SQL and database management. Strong analytical and problem-solving skills. Excellent communication and collaboration skills. Ability to work independently and manage multiple projects simultaneously. It Would Be Great If You Also Had AWS Certification in any of the following: AWS Certified Solutions Architect, AWS Certified Data Analytics, AWS Certified Big Data. Experience with other data visualization tools like Tableau or Power BI. Knowledge of ETL processes and tools. Experience with scripting languages such as Python or R. Cloud technologies (Quicksight, Redshift, S3, RDS, Kafka streaming, Glue, Lambda) Reporting tools (PowerBI, Cognos, Tableau) We Can Offer You A highly competitive compensation and benefits package A multinational organization with 55 offices in 20 countries and the possibility to work abroad Laptop and a mobile phone 10 days of paid annual leave (plus sick leave and national holidays) Maternity & Paternity leave plans A comprehensive insurance plan including: medical, dental, vision, life insurance, and long-/short-term disability (plans vary by region) Retirement savings plans A higher education certification policy Commuter benefits (varies by region) Extensive training opportunities, focused on skills, substantive knowledge, and personal development. On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups Cutting edge projects at the world's leading tier-one banks, financial institutions and insurance firms A flat and approachable organization A truly diverse, fun-loving and global work culture S YNECHRON'S DIVERSITY & INCLUSION STATEMENT Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference' is committed to fostering an inclusive culture - promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant's gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. Candidate Application Notice",
        "url": "https://www.linkedin.com/jobs/view/3970195567"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3930741184,
        "company": "First Derivative",
        "title": "Senior Software Engineer",
        "created_on": 1720637033.3593564,
        "description": "Are you a technologist who has a hunger to dig deep and get involved in providing first-class solutions to real-world problems? Senior Software Engineer - New York First Derivative is a people-first company. We are powered by our ever-growing teams of specialist problem-solvers and process-evolvers. Our extensive capabilities offer agile solutions and exciting career opportunities – whether you're in the early stages of your career, looking for a new direction, or wanting to continue in a position of leadership. Joining the world’s largest Capital Markets dedicated consultancy, you will have the opportunity to gain exposure to a range of mission-critical projects, tech stacks, clients and a company that prides itself on career development, variety, and flexibility. We have opportunities for Mid-Senior Software Engineers who will work shoulder to shoulder with Tier 1 investment banks, including Morgan Stanley, UBS, Citigroup, JP Morgan and Credit Suisse to name a few. What will you do? You will be responsible for the ownership of key projects, working across all phases of the SDLC, including analysis, design, development, testing and deployment. As a Senior Developer, you will be accountable for issuing technical guidance to Junior Developers, including overseeing their deliverables and providing architectural guidance. You will work on cutting-edge technology on a variety of projects across Greenfield, Front Office, Data/ Cloud Migration, Regulatory Reporting, Trade Reconciliation and more! Our main tech stack includes: Core Java (version 8 or higher) Spring Framework/ Spring Boot Object Oriented design principles and patterns CI/ CD tools such as Jenkins Microservices architecture, including containers and serverless implementation e.g., Kubernetes, Docker, OpenShift, AWS Lambda, Cloud Functions, etc. JPA frameworks such as Hibernate and SQL Agile methodologies What experience will you need? Hands on knowledge of Core Java, Collections, Concurrency, Spring Framework Front-end development with TypeScript, JavaScript, using React and Angular frameworks. Understanding of Microservice architecture, developed using Spring Boot. Experience using development and build tools, ideally: Maven, Gradle, Git, IntelliJ and Eclipse Experience of fast paced Agile working environments Understanding of TDD and proficient in writing JUnit testcases Highly motivated with the desire to explore and learn new technologies and frameworks Capacity to work efficiently both independently and within a team Critical thinking and problem-solving skills Strong written and spoken English. What's in it for you? You will embark upon a career with life-long learning at its core, facilitating rapid professional and personal development and the opportunity to design your own career path. Benefits: Hybrid and Flexible Working Extensive Private Healthcare Package Private Pension Employee Assistance Programme Enhanced Maternity/ Paternity policies Group Life Protection Benefit Employee Referral Bonus Scheme Access to a range of skills and certifications such as GCP, AWS, Azure and more! Additional Perks: FD Internal Network and Sports & Social Calendar, who host monthly and quarterly socials at each office. Aspiring LeadershipProgramme – a programme which provides a structured and practical pathway to fast-track talented individuals into leadership roles. STEP-up Awards - employee led awards designed to acknowledge excellence in four areas that are quintessential to us. TechSmiths Guild – helping employees get to grips with everything cloud computing and data storage (which are integral to the future of business and risk management). STRIVE Initiative and IMPACT Programme – development programmes put in place to support women in tech and financial services. Investment Club - employees learn the basics of investment and trading via workshops and competitions, mirroring real-life scenarios. Food Club – the opportunity to try out new cuisines together as a team Sports Club – a bit of healthy competition! Getting involved in 5k fun runs, JPM challenge and SCB challenge.",
        "url": "https://www.linkedin.com/jobs/view/3930741184"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3811303619,
        "company": "Meta",
        "title": "Software Engineer, Infrastructure",
        "created_on": 1720637035.075503,
        "description": "We are the teams who create all of Meta's products used by billions of people around the world. Want to build new features and improve existing products like Messenger, Video, Groups, News Feed, Search and more? Want to solve unique, large scale, highly complex technical problems? Meta is seeking experienced full-stack Software Engineers to join our product teams. You can help build products that help us connect the next billion people, create new features that have billions of interactions per day and be a part of a team that’s working to help people connect with each other around the globe. Join us! Software Engineer, Infrastructure Responsibilities: Design core, backend software components Code using primarily C/C++, Java, PHP and Hack Interface with other teams to incorporate their innovations and vice versa Conduct design and code reviews Analyze and improve efficiency, scalability, and stability of various system resources Set direction and goals for the team regarding project impact, product quality and engineering efficiency Lead major initiatives, projects, teams, roll-outs and phased-releases Helps onboard new team members, provides mentorship and enables successful ramp up on your team's code bases Minimum Qualifications: 7+ years of programming experience in a relevant programming language 7+ years relevant experience building large-scale infrastructure applications or similar experience Experience with scripting languages such as Python, Javascript or Hack Experience leading major initiatives successfully Experience leading projects and teams accordingly Experience building and shipping high quality work and achieving high reliability Experience improving quality through thoughtful code reviews, appropriate testing, proper rollout, monitoring, and proactive changes Experienced in utilizing data and analysis to explain technical problems and providing detailed feedback and solutions Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience Preferred Qualifications: Experience in programming languages such as C, C++, Java About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com. $85.10/hour to $251,000/year + bonus + equity + benefits Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about  benefits  at Meta.",
        "url": "https://www.linkedin.com/jobs/view/3811303619"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3914075525,
        "company": "American Express",
        "title": "Senior Data Engineer - Postgres/Oracle",
        "created_on": 1720637036.7077992,
        "description": "You Lead the Way. We’ve Got Your Back. With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally. At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong. Join Team Amex and let's lead the way together. As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives.  Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems.  American Express offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source.  And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development.  Find your place in technology of #TeamAmex. American Express is looking for Senior Engineers to contribute to the company’s focus on building products, like @Work, to support our large and global corporate clients. @Work helps our clients manage their Corporate Card and Corporate Purchasing Card programs more efficiently online. From performing everyday administrative tasks and account maintenance, to accessing reports and utilizing reconciliation solutions, @Work enables fast, efficient, and effective program management resulting in time and cost savings for our clients. In this role, you will oversee all technical aspects of our databases that power our global @work application. This role requires a deep understanding of database architectures and hands-on experience with database technologies. The successful candidate will ensure optimal database performance, security, resiliency, integrity, and availability, along with implementing innovative solutions such as the Point of Arrival (POA) system for our data layer. Scope of Impact/Influence: Leads and mentors teams of engineers through ongoing development efforts. Ensures engineers adhere to team standards. Accountable for accurate completion and quality of all documentation and work produced by engineering team. Accountable for delivering a quality product that meets the customers’ needs. Key Responsibilities: Performs all technical aspects of data architecture and database management for assigned applications, including developing prototypes, developing new database structures and APIs as applicable. Performs transformation of logical data architectures into physical data designs, according to database design best practices and standards Provides database administration services to projects crafting, extending or maintaining databases, data warehouses and datamarts Debugs database components, identifies, fixes and verifies remediation of design and/or performance defects. Performs ongoing refactoring of database design and continuously improves product to follow data placement procedures and re-use of existing databases as appropriate. Ensure optimal data replication, performance, High Availability, backup and recovery processes exists to meet requirements, reduce cost and adhere to standards. Leads in development of plans and strategies, best practices, and standards related to data management processes, data products, data security and programs. Functions as Senior member of an agile team and leads data assets as per the enterprise standards, guidelines and policies. Typically spends 50% of time in database development and testing and remainder of time collaborating with partners through ongoing product/platform releases. Communicates and works collaboratively with business and product teams to support changes and implementation. Works with product team to prioritize features for ongoing sprints and leading a list of data requirements based on industry trends, new technologies, known defects, and issues. Partner with delivery architects and engineers to design optional data tier solutions to meet enterprise platform objectives and goals. Stays abreast of new DBMS features and functions and drive adoption across Amex to use product capabilities. Active member of the vendor product development strategy that will enable vendors to provide solutions and features to meet Amex needs. Contributes to decisions about tools, methods and approaches. Finds opportunities to embrace innovative technologies. Works closely with product owners on blueprints and annual planning of feature sets that impact multiple platforms and products Knowledge/Skills Strong analytical skills with a proven ability to understand and document business data requirements in complete, accurate, extensible and flexible logical data models, data modeling tools. Able to facilitate discussions between Technology and business people, recognize issues of conflict and inconsistency between data requirements and pursue a resolution of these issues Evaluates and undertakes impact analysis on major design options for databases and assesses and leads associated risks Expert in XML and schema development/reuse, RDBMS databases, Open Source. Expertise in NoSQL will be an added advantage. Leads modification and maintenance of data structures and associated components according to logical and physical design structures for large or complex systems. Mastered Metadata Management and Database Management Partners with Sr. Data Engineers and Sr. Data architects to build complex company platform level data models and database designs. Takes technical responsibility for all stages in the database development process. Crafts and/or uses System-of-Records (SORs) and identify data reuse. Deep Technical knowledge of DBMS products and ecosystem – e.g. storage formats, access algorithms, data management processes, administration, data maintenance, replication, high availability, encryption, etc. Ability to monitor and tune databases and DBMSs to reach high performance – e.g. use data monitoring and analysis tools, tune configuration parameters, alter physical designs, benchmark, etc. Takes part in reviews of own work and leads reviews of colleagues' work. Has working knowledge of the range of tools used in the planning, analyzing, crafting, building, testing, configuring, and maintaining of assigned application(s) Able to participate in assigned team’s Agile delivery methodology. Understands and has practical experience with infrastructure technologies and components like servers, jvms and networking concepts. Application of industry best practices, processes, and standards Identifies a number of ways to do things differently that will continuously improve the product. Understands the complete vertical platform environment (technical stack) Tech Stack Db2, Couchbase, Postgres, Oracle Primarily React via OneApp and Java via OneData Cucumber, Gatlin, Karate, Jest AWS, GCP Terraform GitHub Actions GitHub Enterprise Jenkins Education & Experience 6+ years of database development experience in a professional environment and/or comparable experience such as: Demonstrated experience leading teams of Data Engineers and Data Architects Hands on expertise with design and development across one or more database management systems (e.g., DB2, Couchbase, Oracle, Postgres) as appropriate Experience with distributed (multi-tiered) systems, algorithms, and application development. Experience with database development and support of OLTP and/or OLAP systems. Demonstrated experience with big data technologies and NOSQL design and coding with variety of data stores (document, column family, graph, etc.) Bachelor’s degree in computer science, computer science engineering, or related field required; advanced degree preferred. 3+ years Java. 3+ years Postgres/Oracle. Salary Range: $110,000.00 to $190,000.00 annually + bonus + benefits The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors. We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include: Competitive base salaries Bonus incentives 6% Company Match on retirement savings plan Free financial coaching and financial well-being support Comprehensive medical, dental, vision, life insurance, and disability benefits Flexible working model with hybrid, onsite or virtual arrangements depending on role and business need 20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy Free access to global on-site wellness centers staffed with nurses and doctors (depending on location) Free and confidential counseling support through our Healthy Minds program Career development and training opportunities For a full list of Team Amex benefits, visit our Colleague Benefits Site. American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law. We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually. US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and the Pay Transparency Policy Statement. If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters. Employment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.",
        "url": "https://www.linkedin.com/jobs/view/3914075525"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3950850841,
        "company": "Goldman Sachs",
        "title": "Senior Software Engineer, Transaction Banking, Data & Analytics Platform",
        "created_on": 1720637039.8879642,
        "description": "Job Description What We Do At Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets . Goldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment. Want to push the limit of digital possibilities? Start here. Transaction Banking (TxB) aims to bring innovative solutions to traditional banking and lending activities. We are a global team of lenders, investors, risk managers, skilled marketers, web experts and banking specialists. We provide a suite of solutions to help our customers meet their financial goals. We make direct investments in and manage risk for a portfolio of corporate loans and securities. We help transform distressed communities through investments and loans of private capital. Within TxB, Data & Analytics Platform is a global engineering team with pods across New York, London, Bengaluru, and Dallas. We are responsible for detailed technical design and development of data-intensive capabilities using existing and emerging technologies. Who We Look For In this role, your responsibilities will include development, test, and rollout of data platform features. Our platform is made of Java and Python services that inter-operate with Airflow, Flink, Kafka, GraphQL, REST, various AWS services, as well as vendor and external systems. You will be able to contribute to our vision, roadmap, and world-class engineering culture, while integrating business value and client experience within the team. This initiative is of critical importance to the success of the organization and our roadmap. Services like liquidity analytics, billing, client onboarding, reporting and others will rely on the data platform. Accurate, granular, complete and timely data is a key differentiator and competitive advantage in the market. We expect a successful candidate to have excellent communication skills, deliver high quality software and to be passionate about cutting edge data engineering. Basic Qualifications Minimum 6 years of hands on experience using a modern processing frameworks (Hadoop, Spark, Airflow, Flink) and programming languages (Java/Scala/Python) Minimum 5-year production experience with Kafka, Kinesis or equivalent Experience in REST and/or GraphQL Experience in working with data-bases – NoSQL and/or Relational. BS. or higher in Computer Science (or equivalent work experience) Preferred Qualifications Experience with microservice architecture Experience with PostgreSQL Experience with AWS Experience with Snowflake Experience with Terraform Experience in Financial Services or Fintech About Goldman Sachs At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world. We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers. We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html © The Goldman Sachs Group, Inc., 2023. All rights reserved. Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",
        "url": "https://www.linkedin.com/jobs/view/3950850841"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3960207253,
        "company": "Net2Source Inc.",
        "title": "Senior Data Engineer",
        "created_on": 1720637041.5391073,
        "description": "Net2Source Inc. is an award-winning total workforce solutions company recognized by Staffing Industry Analysts for our accelerated growth of 300% in the last 3 years with over 5500+ employees globally, with over 30+ locations in the US and global operations in 32 countries. We believe in providing staffing solutions to address the current talent gap - Right Talent - Right Time - Right Place - Right Price and acting as a Career Coach to our consultants. Job Title: Data Engineer Location: NEW YORK NY 10019 (2 days onsite) Duration: 6+ Months Contract (possibility of Extension) Job Description As a Senior Data Engineer, you will be responsible for the full development life cycle of complex data projects requiring integrations and transformations including analysis, design, development, and support of complex data pipelines in cloud environments. You will also assist in the design and configuration of data management tools that extract and manipulate data from various sources, including in-house and external databases. Required Skills Experience in creating scalable and secure data pipelines that enable the ingestion, transformation, and transfer of large quantities of structured and unstructured data from various databases and sources. Experience in building complex database logic and API’s to automatically fetch and store data in various forms. Extensive experience with programming languages (Python or related), ETL tools and their administration, as well as relational and non-relational databases. Experience in architecting and developing efficient and reusable modularized components that drive complex applications. Experience in implementing data quality, security, and governance standards and best practices across different cloud environments. Experience in the design and build of the integration between data management tools. Experience in the design, development, and maintenance of data solutions across different cloud platforms, such as AWS or Google Cloud. Extensive understanding of data structures, algorithms, and software architecture as well as the design, detailed testing, and documentation of complex systems. Experience with the secure movement and storage of PHI, PII, and PCI data. Experience with scaling up or increasing application resiliency and assuring that code meets required performance standards. Ability to work and collaborate with data analysts, data scientists and IT operations to install and build tools transforming data to be used in building a new generation of data and artificial intelligence products. Experience in providing technical leadership for development projects and providing consultation and guidance to other team members. Ability to provide innovative solutions when presented with complex business or production issues. Experience with modern DevSecOps practices and tools. Experience with Agile methodologies and tools (i.e. Jira, Scrum, Kanban). Nice to have Experience in directing a team of data engineers and analysts in the creation of complex software and data pipelines. Experience with data governance processes. Experience with data classification and taxonomy tools. Why work with us - At Net2Source, we believe everyone has an opportunity to lead. We see the importance of your perspective and your ability to create value. We want you to fit in—with an inclusive culture, focus on work-life fit and well-being, and a supportive, connected environment; but we also want you to stand out—with opportunities to have a strategic impact, innovate, and take necessary steps to make your mark. We help clients with new skilling, talent strategy, leadership development, employee experience, transformational change management and beyond. Equal Employment Opportunity Statement Net2Source is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation. Our rich diversity makes us more innovative, more competitive, and more creative, which helps us better serve our clients and our communities. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Awards And Accolades America's Most Honored Businesses (Top 10%) Awarded by USPAAC for Fastest Growing Business in the US 12th Fastest Growing Staffing Company in USA by Staffing industry Analysts in the US (2020, 2019, 2020) Fastest 50 by NJ Biz (2020, 2019, 2020) INC 5000 Fastest growing for 8 consecutive years in a row (only 1.26% companies make it to this list) Top 100 by Dallas Business Journal (2020 and 2019) Proven Supplier of the Year by Workforce Logiq (2020 and 2019) 2019 Spirit of Alliance Award by Agile1 2018 Best of the Best Platinum Award by Agile1 2018 TechServe Alliance Excellence Awards Winner 2017 Best of the Best Gold Award by Agile1(Act1 Group) Regards, Kapil Sharma Manager: Client Delivery Services Net2Source Inc. Corp. HQ’S: 270 Davidson Ave., Suite 704, Somerset, NJ 08873, USA T: (201) 340.8700 Ext. 440 | D: (201) 479 2141 | F: (201) 221.8131 Email: Kapil.sharma@net2source.com | Web: www.net2source.com LinkedIn: http:// www.linkedin.com/in/kapil-sharma-2b1519b2/ To unsubscribe from Net2Source mailing list, click here #ITC",
        "url": "https://www.linkedin.com/jobs/view/3960207253"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Commack, NY",
        "job_id": 3949729727,
        "company": "IntelliShift",
        "title": "Software QA Engineer",
        "created_on": 1720637043.3706095,
        "description": "We are IntelliShift, a rapidly growing B2B SaaS company with more than 20 years of expertise in fleet management technology. IntelliShift is the fleet intelligence platform for safety and operations teams, and we empower construction, utilities, field services, and last mile delivery businesses to make the intelligent shift from siloed data using point solutions, to one simple, powerful platform. IntelliShift provides these customers with a level of insight they've never had before to improve safety, establish next generation operational efficiency, and make intelligent decisions. We are looking for an experienced Software QA Engineer to develop and execute automated tests to ensure product quality. You will play a critical role in ensuring the quality and reliability of our software products. The ideal candidate will be responsible for designing and implementing tests, debugging and defining corrective actions, and providing feedback to the development team during the entire software development lifecycle. This role demands a thorough understanding of the Scrum methodology and active participation in all Scrum activities. While this is a remote position, you must be able to work Eastern Time Zone hours. What you will do: Develop and execute comprehensive test plans and test cases Identify, record, document thoroughly, and track bugs Perform functional, regression, integration, and performance testing Execute test cases (manual or automated) and analyze results Evaluate product code according to specifications Conduct post-release/post-implementation testing Collaborate with product management and development teams to understand product requirements and design appropriate tests Participate actively in all Scrum ceremonies (daily stand-ups, sprint planning, sprint reviews, and retrospectives) Develop and apply testing processes for new and existing products to meet client needs Continuously improve testing strategies, tools, and processes What you bring: Familiarity of software QA methodologies, tools, and processes Familiarity with software development lifecycle (SDLC) and software testing lifecycle (STLC) Strong analytical and problem-solving skills Working knowledge of test management software such as TestRail, Test King, JIRA, DevOps, and/or TestLink Excellent communication and teamwork abilities Experience with Behavior Driven Development (Cucumber or SpecFlow) Familiarity with Jira or other Agile project management tools Experience with version control systems (e.g., Git) Knowledge of continuous integration/continuous deployment (CI/CD) tools and practices Experience in performance and security testing Proven experience as a QA engineer or in a similar role, with a strong background in agile/scrum methodology Experience with mobile application testing Experience in testing B2B software ELD application experience a plus The values you'll live by as part of the team: Always Put the Customer First - with the customer experience in mind, build trust and loyalty Embrace and Drive Change - have an innovative mindset and embrace the change Think Bigger - commit to growing the organization and grow as an individual. Be a Good Human - treat everybody with respect and always do what is best Execute with Passion and Urgency - we need to be the very best at what we do. Drive Trust and Transparency - open and honest communication, trust each other and take risks Benefits We offer competitive compensation, commensurate with experience $75,000- $85,000. We also offer outstanding benefits to simplify the lives of our employees and show them how much we appreciate their contributions. IntelliShift provides company-subsidized medical, dental, and vision insurance for all full-time employees and 401K with a 4% company contribution. For more information on our company visit www.IntelliShift.com.",
        "url": "https://www.linkedin.com/jobs/view/3949729727"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3931300350,
        "company": "S&P Global",
        "title": "Lead Data Engineer",
        "created_on": 1720637045.0092094,
        "description": "About The Role Grade Level (for internal use): 11 Title: Lead Data Engineer The Team The Data Lake team is responsible for data ingestion from internal source systems in batch/real-time modes, curation and governance of the data assets created in the platform. The team also works towards adopting the new features of the Databricks product and optimizing the operational aspects of the platform to enhance the user community experience. The team has a broad and expert knowledge on Ratings organization’s critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy. Responsibilities And Impact Design & Build data pipelines with an emphasis on scale, performance and reliability. Provide technical expertise in the areas of design and implementation of Data Lake solution powered by Databricks on AWS cloud. Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the data Partner with the data teams, enterprise architecture organization to ensure best use of standards for the key data domains and use cases Continuous learner with an eye on emerging trends around data lake architecture and enterprise data solutions. Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards Compensation/Benefits Information S&P Global states that the anticipated base salary range for this position is 97,497 USD to 195,800 USD. Final base salary for this role will be based on the individual’s geographic location, as well as experience level, skill set, training, licenses and certifications. In addition to base compensation, this role is eligible for an annual incentive plan. This role is not eligible for additional compensation such as an annual incentive bonus or sales commission plan. This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, please click here. What We’re Looking For Basic Required Qualifications: Bachelors or Masters degree in Computer Science or Information Technology 8+ years of experience building solutions in big data technologies. Strong experience programming with more than one of Java, Scala, Python, Spark. Hands-on experience designing and building streaming data pipelines using Kafka, Confluent etc. Strongly prefer experience building Data Lake & Data warehouse solutions using ETL,ELT pipelines on Databricks, Snowflake, Azure Data Lake etc. Strong understanding of database and analytical technologies in the industry including MPP and NoSQL databases Strong understanding of cloud platforms like AWS, Azure, or GCP, and their services (e.g., EC2, S3, AKS, EKS, etc.). AWS or any public cloud certification is a must. Additional Preferred Qualifications Experience in continuous delivery through CI/CD pipelines, containers and orchestration technologies. Experience With Machine Learning Libraries and Frameworks (TensorFlow, MLlib) is an added advantage. Expert knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally. Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners Ability to prioritize and manage work to critical project timelines in a fast-paced environment Financial services industry experience is an added advantage. Databricks experience or certifications is an added advantage. Return To Work Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative, Restart, we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. About S&P Global Ratings At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions. S&P Global Ratings is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today. For more information, visit www.spglobal.com/ratings What’s In It For You? Our Purpose Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our Benefits Include Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, And Inclusion At S&P Global At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy. Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning) Job ID: 298495 Posted On: 2024-05-21 Location: New York, New York, United States",
        "url": "https://www.linkedin.com/jobs/view/3931300350"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911738422,
        "company": "Unreal Staffing, Inc",
        "title": "Senior Software Engineer",
        "created_on": 1720637046.7262118,
        "description": "We're seeking a senior/principal software engineer to take ownership of our core user-facing app. You'll thrive in a small team environment, making decisions on thoughtful development versus rapid deployment. With autonomy and responsibility, you'll shape the direction and architecture of our app and backend data infrastructure. Requirements Responsibilities: Collaborate with the engineering team on Narrator's main user-facing app Design and execute solutions across frontend to backend, leveraging autonomy and responsibility Contribute to refining coding standards, processes, and overall software development improvement Experience: 6+ years as a professional software engineer, specializing in frontend or full-stack development 3+ years of hands-on experience with React or similar frontend frameworks (Angular, Vue, etc.) Proficiency in building backend APIs to support frontend requirements Track record of building, designing, or maintaining sizable and complex systems (either frontend or backend) Experience in mentoring junior engineers Ideal Requirements: Passion for crafting functional and visually appealing frontend experiences Understanding of code maintainability, refactoring, testing, and tech debt management Ability to navigate ambiguity, make independent decisions, and tackle business problems with technology Preferred Skills: Eye for design, with the ability to create aesthetically pleasing interfaces Previous startup experience or familiarity with our tech stack: React, TypeScript, Kubernetes, XState, GraphQL, Python Benefits Competitive salary and performance bonuses Comprehensive health, dental, and vision insurance Flexible work hours and remote work options Opportunities for professional growth and development Collaborative and supportive team environment Contribution to shaping the future of our product and technology Work-life balance and emphasis on employee well-being Salary Range: $120,000 - $180,000 USD",
        "url": "https://www.linkedin.com/jobs/view/3911738422"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3867824954,
        "company": "Gynger",
        "title": "Senior Full-Stack Software Engineer (US - 100% Remote)",
        "created_on": 1720637048.441886,
        "description": "About Us: We are the first embedded financing platform built for buyers and sellers of technology. Our mission is to combine software with capital to enable businesses to scale with the technology they need and love. Our vision is to simplify and optimize the end-to-end technology purchasing process. Our platform enables businesses to pay, finance, and manage all of their technology expenses from one dashboard. For tech vendors, we provide an opportunity to extend flexible payment options to their customers while still getting paid upfront. We are building a fully automated, seamless, embedded financing platform built for both buyers and sellers of technology, that will truly revolutionize the way technology transactions are made today. Gynger was incubated out of m]x[v Capital and founded in 2021 and is based in New York. We’re seeking to hire top-notch talent to conquer this category. Are you up for the challenge? The Opportunity: We are seeking a full-time Senior Full Stack Engineer to join our growing remote engineering team here in the US. In this role you will be crucial in building high-performance, web-based SaaS and FinTech software. This is a unique opportunity to play a critical role in a category-creating startup of global scale and to get in close to the ground floor. In this position you will... Be actively involved in the build, deployment, and continuous improvement of our software platform as it relates to both front-end and back-end web development. Participate in code reviews and thoughtfully provide constructive feedback. Use your knowledge of current industry coding standards, tools, and best practices to write clean and efficient code. Collaborate effectively with other teams and architects to solve complex problems. Work with designers and PMs to create delightful products. Believe in a culture of experimentation while developing production-grade products and platforms. You have... Bachelor’s degree or equivalent practical experience. 3+ years professional experience working with Typescript (React on the front-end and Node.js on the backend). Experience releasing apps in a cloud environment like GCP or AWS. Ability to build UI components from concept designs and wireframes. Ideal: Experience working in the Fintech space Ideal: Experience working with backend policies, data flows, and building business logic. Our tech stack includes... React Typescript Node.js Google Cloud Platform PostgreSQL Firestore We Offer: Endless career growth opportunities by joining our team at the ground floor. A tight-knit team of like-minded people who are passionate about building startups. Ability to work remotely, or a hybrid between our NYC office and remote. Equity, a competitive salary, and robust benefits. Flexible PTO. Our Values: Win Together - Move, grow, and win as a team. Be Accountable - Be true to yourself, to your team and to your customers. Stay Curious - Dig deep and always thirst for knowledge. Listen to Understand - Uncover what is really being communicated. Go Above & Beyond - Go the extra mile and unlock the thrill of being a pioneer. >> Our Series A is officially complete with $20 Million led by PayPal Ventures , plus up to $100 Million in debt facility to expand our embedded financing technology. >> Gynger is a 2024 Built-In \"Best Places to Work\" - check us out! We’re focused on building and fostering a diverse, flexible, and inclusive space that allows our team members to thrive. We’re an Equal Opportunity Employer and consider applicants without regard to race, color, national origin, gender, sexual orientation, genetics, age, marital status, veteran status, disability status or any other basis forbidden under federal, state, or local law.",
        "url": "https://www.linkedin.com/jobs/view/3867824954"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Buffalo, NY",
        "job_id": 3959942445,
        "company": "Imagine Staffing Technology, An Imagine Company",
        "title": "Software Engineer",
        "created_on": 1720637050.2140372,
        "description": "Software Engineer II Location: Buffalo, NY Hire Type: Contingent Hourly: $43.68-88.82/hr Work Model: Remote No C2C or sponsorship offered Positional Overview Are you a passionate software engineer looking to make a significant impact in the world of technology? Our client is seeking talented individuals to join their dynamic team and play a pivotal role in shaping the future of their innovative projects. At their company, you'll have the opportunity to work on cutting-edge technologies, collaborate with brilliant minds, and contribute to groundbreaking solutions that will redefine industry standards. We value creativity, expertise, and a strong drive for excellence. If you're ready to unleash your full potential and be part of a forward-thinking organization that values innovation and teamwork, we invite you to apply! Role & Responsibility: Complete and oversee basic to complex systems analysis, design and development. Play a key role as an individual contributor on complex projects. Maintain an excellent functional understanding of the supported application(s). Direct and monitor less experienced resources and coordinate development tasks on small to large scope projects. Prepare and manage the technical component of project plans. Participate with other Development, operations and Technology staff in overall systems development direction from technical analysis to user acceptance testing. Prepare and review test data and execute detailed test plans. Complete any required debugging. Evaluate and understand complex interrelationships and effects among programs, interfacing applications and platforms. Provide highly analytical consulting and leadership in identifying and implementing new uses of information technologies to assist business units in meeting strategic objectives. Prepare thorough, clear technical and functional specifications and update systems documentation. Prepare charts, tables, and diagrams to assist in analyzing problems. Review documentation prepared by less experienced staff. Prepare and review assessments to include required tasks, estimated time frames and effort for any scope project. Maintain efficient operation and effectiveness of supported applications. Recommend new technology, policies, or processes to benefit the organization and improve deficiencies. May lead or participate in technical evaluations of vendor software. Skills & Experience: Minimum of an Associate’s degree and 5 years systems analysis/application development experience, or in lieu of a degree, a combined minimum of 7 years higher education and/or work experience, including a minimum of 5 years systems analysis/application development experience. Must have experience with SSIS package management, stored procedures, and SQL. Prior experience with GitLab, Oracle, and general server maintenance on Linux or Windows servers is preferred. Familiar with application development software and hardware platforms. Proficiency with personal computers as well as pertinent project management, word processing and spreadsheet software. Capable of working on multiple projects of a complex nature. Excellent problem-solving skills to assist in issue resolution. Strong verbal and written communication skills, with prior experience presenting to the target audience. Strong organizational and time management skills. Detail-oriented. Strong lateral thinking skills. Experience coordinating between Applications and business units, implementing systems solutions and driving project milestones and delivery dates.",
        "url": "https://www.linkedin.com/jobs/view/3959942445"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3950983203,
        "company": "Capital One",
        "title": "Sr. Data Engineer",
        "created_on": 1720637052.0015705,
        "description": "Plano 3 (31063), United States of America, Plano, TexasSr. Data Engineer We are looking for driven individuals to join our team of passionate data engineers in creating Capital One’s next generation of data products and capabilities. You will build data pipeline frameworks to automate high-volume and real-time data delivery for our Hadoop and streaming data hub You will build data APIs and data delivery services that support critical operational and analytical applications for our internal business operations, customers and partners You will transform complex analytical models into scalable, production-ready solutions You will continuously integrate and ship code into our on premise and cloud Production environments You will develop applications from ground up using a modern technology stack such as Scala, Spark, Postgres, Angular JS, and NoSQL You will work directly with Product Owners and customers to deliver data products in a collaborative and agile environment Responsibilities: Develop sustainable data driven solutions with current new gen data technologies to meet the needs of our organization and business customers Master new technologies rapidly as needed to progress varied initiatives Break down complex data issues and resolve them Builds robust systems with an eye on the long term maintenance and support of the application Broader knowledge sharing Understands complex multi-tier, multi-platform systems Basic Qualifications: Bachelor’s Degree At least 4 years of experience in application development (Internship experience does not apply) At least 1 year of experience in big data technologies Preferred Qualifications: Master's Degree 6+ years of experience in application development (Python, SQL, Scala, or Java) 4+ years of experience in big data technologies 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) 4+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL) 4+ year experience working on real-time data and streaming applications 4+ years of experience with NoSQL implementation (Mongo, Cassandra) 4+ years of data warehousing experience (Redshift or Snowflake) 4+ years of experience with UNIX/Linux including basic commands and shell scripting 4+ years of experience with Agile engineering practices At this time, Capital One will not sponsor a new applicant for employment authorization for this position. The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. New York City (Hybrid On-Site): $165,100 - $188,500 for Senior Data Engineer Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter. This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
        "url": "https://www.linkedin.com/jobs/view/3950983203"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3951915748,
        "company": "Goldman Sachs",
        "title": "Software Engineer, Corporate Planning & Management, Spend Platform",
        "created_on": 1720637053.6781528,
        "description": "Responsibilities JOB DESCRIPTION Software engineers primarily focus on software design and development. This is meant to cover most programming positions in Engineering, and include positions that were previously considered business software engineers, platform engineers, and quality assurance engineers. Combine the best open source software, databases, cloud solutions, and programming languages, to solve problems and provide accurate, complex, scalable applications that help our business and clients gain new insights. As a software engineer, you are the change agents that transform Goldman Sachs by applying your technical know-how.Be a part of our embedded engineering teams, that work as a unit with our business partners. Collaborate with trading, sales, asset management, banking, finance and others, to build and automate solutions to keep our firm’s position on the cutting edge. Or, join our core engineering teams, and elevate all of our businesses by providing reliable, scalable platforms for data engineering, machine learning, networking, developer tooling, collaboration and more. Innovate with UI/UX designers, data scientists, cloud engineers, and more in a collaborative, agile environment where your enthusiasm to take on new problems and learn will have an immediate impact. Basic Qualifications Bachelor’s Degree 0-5 years of prior work experience in a relevant field. Proficient to advanced skills with MS Office (Excel, PowerPoint, Word, Outlook) Highly organized with exceptional attention to detail and follow-through Strong ability to manage multiple projects with competing deadlines Team player with positive attitude and strong work ethic Strong communication skills (written and verbal) Ability to work in a fast-paced environment Ability to adapt quickly to a variety of industries and businesses Ability to self-direct, analyze and evaluate and form independent judgments Ability to effectively interact and build relationships with senior management and global stakeholders Commercially savvy with ability to exercise discretion with respect to highly confidential/sensitive information Integrity, ethical standards and sound judgment Expert Knowledge in One Or More Of Programming in a complied language such as Java, or C++ or an interpreted language such as Python and experience with concurrency and memory management. Responsive web development, with professional React/Angular/Redux experience and advanced JavaScript proficiency. NoSQL databases such as MongoDb and Elastic Search. Preferred Qualifications Knowledge or interest in trading technologies in the front-office of a trading organization B.S. or M.S. Computer Science or Related field. About Goldman Sachs At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world. We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers. We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html © The Goldman Sachs Group, Inc., 2023. All rights reserved. Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity Salary Range The expected base salary for this New York, New York, United States-based position is $110000-$130000. In addition, you may be eligible for a discretionary bonus if you are an active employee as of fiscal year-end. Benefits Goldman Sachs is committed to providing our people with valuable and competitive benefits and wellness offerings, as it is a core part of providing a strong overall employee experience. A summary of these offerings, which are generally available to active, non-temporary, full-time and part-time US employees who work at least 20 hours per week, can be found here .",
        "url": "https://www.linkedin.com/jobs/view/3951915748"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3673088661,
        "company": "Explo",
        "title": "Senior Software Engineer, Backend",
        "created_on": 1720637055.4116092,
        "description": "We are hiring our next software engineer to join the team! We're looking for talented Backend Engineers who will be creating and improving key backend features for our product. You will own large parts of the product architecture, speak directly with customers, work with design to define the product, and help the business meet its goals. As a member of our team, you will be expected to help drive decisions outside of engineering as well. From defining our product roadmap, to contributing to our go-to-market strategy, Explo is a great opportunity for you to learn what it takes to turn a product into a business. What you will do: You will help define lasting process and own very important parts of our product. This is an opportunity to have real ownership on high priority projects. You will primarily spend your time improving existing products and creating new ones, providing a great deal of value for our customers. You will create team-wide systems from the ground up that. You will have a direct impact on best practices and shaping our engineering team's processes and culture. You'll be building things that people love, and you'll interact with our users every day to get feedback on your work and help troubleshoot issues. You will work directly with our product designer, product manager, and business team to scope large projects and execute against them. You'll be a part of a dynamic engineering team and greater company culture, that values collaboration, transparency and autonomy. What are we looking for? 4+ years software engineering experience. Excitement to tackle hard technical problems: scaling infrastructure, data engineering as a service, opening PRs in open source libraries, resilient testing infrastructure, etc. Experience with Django and Python is preferred. Benefits + Perks Unlimited PTO Monthly lunch stipend One Medical membership 401k Comprehensive health, vision and dental insurance Competitive salary range from $170k to $210k dependent on years of experience and skill level About Explo: Explo makes it easy for companies to build customer-facing dashboards, replacing the need for a full-fledged analytics team. We're a well funded, early stage start up, that's rapidly growing with no signs of slowing down. We're looking for growth minded people who are interested in an opportunity with real ownership in an all-star team. If this role doesn't sound like the right fit, let's chat! We have multiple openings across departments and are always on the hunt for great talent.",
        "url": "https://www.linkedin.com/jobs/view/3673088661"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3910787374,
        "company": "Kustomer",
        "title": "Software Engineer, Infrastructure",
        "created_on": 1720637057.1315384,
        "description": "About Kustomer Kustomer is the industry leading conversational CRM platform perfecting every customer experience. Built with intelligent tools such as AI and Automation, no code-configuration and a connected data platform that unifies data from multiple sources through a single timeline, Kustomer empowers businesses to operate with greater efficiency and deliver more personalized service to customers across any channel, making every interaction more meaningful and memorable. Today, Kustomer is the core platform for some of the leading customer service brands like Ring, Glovo, Away Travel, Priceline and Sweetgreen. Kustomer was founded in 2015 by serial entrepreneurs Brad Birnbaum and Jeremy Suriel and has raised over $200M in funding backed by leading VCs. Meta announced its intention to acquire Kustomer in 2020 and completed the transaction in 2022. Kustomer joined Meta’s Business Messaging Group to transform the way people and businesses communicate through modern messaging channels. In 2023, Kustomer spun out from Meta as a standalone company backed by original partners, Battery, Redpoint and Boldstart Ventures, who have invested $60M in capital, ensuring Kustomer’s growth and success for many years to come. Our Krew is made up of passionate and collaborative people who really care about what they do and the people they help. We look for people who are passionate about enhancing the customer service experience for everyone involved, as it's the core of what we do. We're growing our business with no plans of slowing down. We actively seek individuals who want to learn and be challenged every day. We have also transitioned to a remote friendly company, with Krew members located throughout the U.S. coming together for Kamp Kustomer each year. About The Role As an Infrastructure Engineer specializing in cost optimization and disaster recovery at Kustomer, you will be tasked with enhancing the financial efficiency and resilience of our infrastructure. This role is integral to the Foundation team, which underpins the data model, core features, and critical systems of our platform. You will collaborate closely with a team of skilled engineers, taking ownership of projects that directly impact our platform's robustness and cost-effectiveness. What You’ll Do: Analyze current infrastructure usage and performance to identify cost-saving opportunities Design and implement cost-optimization strategies across the platform and infrastructure to reduce expenditure without compromising on performance and scalability. Conduct regular cost audits and reviews of infrastructure to ensure continuous optimization of resources. Lead initiatives to optimize data storage and compute resources to achieve cost-effective scalability and maintain regulatory compliance. Develop and automate disaster recovery processes to minimize impact and downtime Respond to critical incidents as part of an on-call rotation, applying disaster recovery protocols to restore system functionality swiftly. Contribute and maintain documentation on disaster recovery procedures, cost optimization strategies, and operational best practices. Design and implement robust backup solutions, ensuring data integrity and availability across distributed environments. Participate in cross-team initiatives to drive engineering best-practices Conduct code, architecture, and infrastructure reviews across the platform Train and support engineering teams in adopting cost-effective practices in their daily operations and system design. Staying involved in initiatives around on-call rotations, application performance monitoring, development environments, and continuous integration and delivery pipelines. Lead various scalability initiatives across the platform and infrastructure Our Tech Stack: Javascript (React/node.js), Go AWS Cloud, MongoDB, Redis, Elasticsearch Minimum requirements: Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience 8+ years experience building and managing large scale, highly available, distributed web applications A working understanding of a high-level programming language like Go, Python, JavaScript, etc. Strong AWS experience managing infrastructure in a secure, highly available, automated fashion (VPC, ELB, Containers, Auto Scaling) Strong background in Linux/Unix administration, networking, HTTP/2, DNS, REST, etc Experience leading large projects to achieve financial and operational efficiency Experience with designing applications and architecture optimized for multi-region disaster recovery Experience with infrastructure as code and managing Terraform configurations in a sustainable and scalable way Experience with observability tools (Datadog/ELK/Distributed tracing) Nice To Have: You have Github activity showing thoughtful, relevant contributions You have a working knowledge of writing code and scripts in more than one language You have experience designing sharding configurations for databases You have experience developing internal tools for others You have experience creating SLAs, SLOs, SLIs HIPAA Compliance All roles at Kustomer may involve handling sensitive personal data. Benefits Kustomer offers an array of benefits including competitive salaries, stock options, 100% healthcare coverage, 401K, WiFi and Mobile reimbursement, and a generous vacation policy. Diversity & Inclusion at Kustomer Kustomer is committed to bringing together individuals from different backgrounds and perspectives. We strive to create an inclusive environment where everyone can thrive, feel a sense of belonging, and do great work together.We are proud to be an equal opportunity employer open to all qualified applicants regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, Veteran status, or any other legally protected status. Disclaimer: Kustomer only contacts candidates from company email addresses ending in kustomer.com and does not seek funds from candidates in any circumstances.",
        "url": "https://www.linkedin.com/jobs/view/3910787374"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3909841148,
        "company": "Meta",
        "title": "Software Engineer - Language",
        "created_on": 1720637059.0861092,
        "description": "Reality Labs at Meta is building products that make it easier for people to connect with the ones they love most, enjoy top-notch, wire-free VR, and push the future of computing platforms. We are a team of world-class experts developing and shipping products at the intersection of hardware, software and content.As a Language Software Engineer on the Reality Labs team at Meta, you can help build new, innovative hardware and software that radically redefine the way people work, play and connect. What we build today could one day be the norm. So to be here today is to truly be at the heart of change and the frontier of what's to come. We're the people helping to define the metaverse. We may not have all the answers. But together, we're getting closer.Meta is seeking AI Software Engineers to join our Research & Development teams. The ideal candidate will have industry experience working on a range of problems. The position will involve taking these skills and applying them to some of the most exciting and massive social data and prediction problems that exist on the web. We are hiring in multiple locations. Software Engineer - Language Responsibilities: Apply relevant AI and machine learning techniques to build intelligent systems that improve Facebook products and experiences Develop novel, accurate AI algorithms and advanced systems for resource constrained applications Define use cases and develop methodology and benchmarks to evaluate different approaches Minimum Qualifications: Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta. Experience in one or more of the following areas: ASR, TTS, NLP, Conversational AI, Machine Learning or Artificial Intelligence Experience developing machine learning algorithms or machine learning infrastructure in C/C++ or Python Preferred Qualifications: Experience with on-device algorithm or distributed systems development About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com. $56.25/hour to $173,000/year + bonus + equity + benefits Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about  benefits  at Meta.",
        "url": "https://www.linkedin.com/jobs/view/3909841148"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3824350730,
        "company": "Capstone Investment Advisors",
        "title": "Software Engineer",
        "created_on": 1720637060.894194,
        "description": "Overview Capstone is looking for a Software Engineer to join their multifaceted Technology division. The team is responsible for partnering with industry leading experts to build sophisticated solutions across front office, middle office, risk, and enterprise functions. They are seeking a highly motivated engineer with a passion for technology and a drive to excel in a dynamic environment. The ideal candidate possesses exceptional problem-solving skills, a collaborative mentality, and an ability to bring innovative ideas to life. The role offers great exposure to the many and varied areas of the hedge fund. Responsibilities Create state-of-the-art software that propel risk management, enable operational efficiencies, and empower decision making across various investment strategies Design, build and maintain the firm’s global trading platform while focusing on performance, scalability, and reliability Own the end-to-end development process by working closely with stakeholders to understand problems, creating a strategy of execution, and delivering thoroughly tested and elegant solutions Collaborate with other highly skilled engineers across the technology team and the firm to tackle complex technical challenges Skills And Qualifications Minimum Bachelor’s degree in Computer Science or related field Experience in building production level software in at least two of the following languages: Java, Python, C# Experience with SQL databases Strong analytical and problem solving skills Collaborative team player with strong verbal communication skills 6+ years working experience in the financial industry (buy or sell-side) Bonus Skills And Qualifications Experience building enterprise solutions in C++ Direct experience working with at least one financial asset class Strong quantitative skills and experience in statistical analysis Capstone is committed to creating an inclusive environment where we welcome people of different backgrounds. Capstone considers applications for employment without regard to all applicable protected characteristics, including race, color, religion, ethnicity, national origin, gender, sexual orientation, gender identity or expression, age, parental status, veteran status, or disability status. BASE SALARY RANGE $170,000 - $190,000 (depending on years of experience) USD",
        "url": "https://www.linkedin.com/jobs/view/3824350730"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961275688,
        "company": "Charlie Health",
        "title": "Software Engineer, Full Stack",
        "created_on": 1720637062.7490351,
        "description": "Why Charlie Health? Young people across the nation are grappling with a mental health crisis characterized by escalating rates of depression, anxiety, trauma, substance use disorders, and suicide. Individuals who seek support are met by geographical and financial barriers, driving increased urgency for a new approach to behavioral health treatment. At Charlie Health, our mission is to connect the world to life-saving mental health treatment. Our treatment programs combine curated peer groups, individual therapy, and family therapy into personalized, evidence-based treatment plans to provide long-term healing from home. By prioritizing connections among young people with shared mental health experiences and goals, Charlie Health fosters sustainable healing and achieves industry-leading clinical outcomes, with over 90% of our clients seeing improvement in their most severe mental health symptoms. Every member of the Charlie Health team is fueled by an unwavering passion for our mission. If you share this commitment, we invite you to join us in making a tangible impact on the mental health landscape. About the Role As an early member of Charlie Health's Engineering Team, you will play a big part in building our applications from the ground up. We're looking for someone who enjoys partnering closely with the rest of the product development team to make durable contributions and technical decisions as we race toward product launches. You'll thrive here if you find greenfield work energizing, have a high quality bar, and prefer to iterate to success. This is a unique opportunity to impact millions of lives while building something from scratch, so we're looking for someone who is inspired by our mission and as excited about this opportunity as we are. Responsibilities Develop and deliver high quality, performant, maintainable features that drive meaningful business value using our core technology stack: React, Python, and PostgreSQL. Partner with teammates across the organization to understand our business. Leverage that understanding to drive data modeling discussions and decisions. Be an owner. Collaborate with product and design to iterate to top notch product solutions. Identify bottlenecks and implement improvements to engineering processes, tools, and procedures. We're early and the expectation of folks joining at this stage is that you'll play a huge part in setting and improving how we work. Promote a culture of collaboration and learning across engineering, product, and design team via mentoring, documentation, presentations, or other knowledge sharing methods. Ensure our clients can always access the care they need by participating in our on-call rotation Requirements Professional experience developing user facing web or mobile applications that deliver meaningful business value. Hands on production experience with an application programming language, preferably Python. Ability to break down ambiguous problems into smaller parts with tractable solutions. Growth mindset and a sense of humor. You welcome feedback and when you stumble you get back up. You adapt quickly in a fast-paced environment and you enjoy fostering an environment that prioritizes fun, learning, and growth. 2+ years experience as an engineer Please note: candidates located within 75 minutes' commuting distance of our NYC office are expected to come to office 4 days/week Charlie Health does not provide visa sponsorship. Benefits Charlie Health is pleased to offer comprehensive benefits to all full-time, exempt employees. Read more about our benefits here. Note to Colorado applicants: applications will be accepted and reviewed on a rolling basis. Our Values Connection Care deeply We care personally about every single person in the Charlie Health ecosystem: our clients, providers, and team members alike. Inspire hope We inspire hope with every interaction, reminding our clients that we truly and unconditionally believe in them. Congruence Stay curious We ask \"why\" five times before we're satisfied with the answer. We don't stick to the status quo; we challenge our assumptions and remain humble. Heed the evidence Above all, we're results-oriented. When we find data that calls our original plan into question, we modify or pivot. Commitment Act with urgency We work as swiftly as possible. The mental health crisis is relentless, and so are we. Don't give up Our clients don't give up and neither do we. Persistence is our superpower. Please do not call our public clinical admissions line in regard to this or any other job posting. Please be cautious of potential recruitment fraud. If you are interested in exploring opportunities at Charlie Health, please go directly to our Careers Page: https://www.charliehealth.com/careers/current-openings. Charlie Health will never ask you to pay a fee or download software as part of the interview process with our company. In addition, Charlie Health will not ask for your personal banking information until you have signed an offer of employment and completed onboarding paperwork that is provided by our People Operations team. All communications with Charlie Health Talent and People Operations professionals will only be sent from @charliehealth.com email addresses. Legitimate emails will never originate from gmail.com, yahoo.com, or other commercial email services. Recruiting agencies, please do not submit unsolicited referrals for this or any open role. We have a roster of agencies with whom we partner, and we will not pay any fee associated with unsolicited referrals. At Charlie Health, we value being an Equal Opportunity Employer. We strive to cultivate an environment where individuals can be their authentic selves. Being an Equal Opportunity Employer means every member of our team feels as though they are supported and belong. We value diverse perspectives to help us provide essential mental health and substance use disorder treatments to all young people. Charlie Health applicants are assessed solely on their qualifications for the role, without regard to disability or need for accommodation.",
        "url": "https://www.linkedin.com/jobs/view/3961275688"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3926632833,
        "company": "PeopleSERVE, Inc.",
        "title": "Backend Engineer",
        "created_on": 1720637064.4087036,
        "description": "Description We are looking for a very data-oriented backend engineer with strong Java and SQL skills with experience in Scala and Bigquery. Our team works on Cost Engineering efforts. We build tools that enable engineers to analyze their cloud spending and surface inefficiencies, as well as take action on cost-saving opportunities. What You'll Do Good experience with Google Cloud Platform Build large-scale batch and real-time data pipelines with data processing frameworks like Scio, Storm, Spark, and Google Cloud Platform Write distributed, high-volume services in Java or Scala Use best practices in continuous integration and delivery Work in a multi-functional agile team to continuously experiment, iterate, and deliver on product objectives",
        "url": "https://www.linkedin.com/jobs/view/3926632833"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3969085532,
        "company": "Calibrate",
        "title": "Staff Software Engineer",
        "created_on": 1720637066.0753586,
        "description": "OUR MISSION Calibrate is on a mission to change the way the world treats weight. We’re defining a new category in metabolic health that mirrors what the research shows—that weight reflects our biology, not our willpower. Our program was designed by world leaders in obesity and nutrition science to improve metabolic health and drive long-term weight loss that’s impactful, realistic, and sustainable. Obesity is America’s underlying pandemic and largest category of chronic disease, and Calibrate is closing the gap in care for 175mm adults in a $600bn market where we spend millions of dollars each year and do not lose millions of pounds. To bring Calibrate to everyone who needs it, we’re building the first value-based model in obesity treatment, aligning incentives for patients, providers, payors, and pharmaceutical companies. We’ve built a suite of products that combine medication with our proprietary intensive lifestyle intervention to deliver results that last.Calibrate launched in 2020 direct-to-consumer and has since expanded into enterprise channels to increase access to effective obesity treatment. Calibrate’s programs bring decades of clinical research directly to consumers, immersing members in a biweekly 1:1 coaching program and curriculum that educates and encourages them to build enduring healthy habits across the four areas essential to lasting metabolic health: food, sleep, exercise, and emotional health. A purpose-built app enables daily tracking of food, energy levels, weight, and bi-weekly goals and helps members interact with their Coaching and Medical teams, while a members’ group and events calendar create additional opportunities to engage with the Calibrate community. KEY RESPONSIBILITIES Design services and systems with a focus on iterative development, reliability, and simplicity. Build, test, deploy, maintain, and enhance software solutions to address dynamic business needs. Partner closely with product and design on discovery and experimentation to release solutions for impactful user and business problems. Lead by example, demonstrating technical excellence, and providing mentorship to help team members grow. Assist your team in making decisions that align with organizational objectives, supporting these decisions, and taking accountability for their outcomes. Foster collaboration within the engineering team through consistent communication and building robust relationships with teammates, managers, and stakeholders across the organization. Manage technical dependencies, timelines and deliverables for projects Participate in rotating on-call duties, including incident management. BACKGROUND AND EXPERIENCE Experience with PostgreSQL and other SQL-based databases Experience with AWS (or other cloud services), infrastructure as code, and CI/CD 8+ years of software development experience, with strong skills in Python (or equivalent high-level programming language) Experience with mobile development is a plus. Strong strategic thinking, with the ability to align team efforts with organizational goals. Extensive experience in software engineering, with a proven track record of technical leadership and mentoring. Strong expertise in designing and developing scalable and maintainable software systems. Proficiency in systematic debugging, incident management, and operational monitoring. Excellent communication skills, with the ability to foster a culture of effective communication and collaboration. Deep understanding of security principles and practices, with experience in driving security initiatives. Ability to manage risk, change, and uncertainty in a dynamic environment. The salary range for this role is $200,000-225,000. BENEFITS At Calibrate, we’re committed to our vision of putting our members and our teammates in control of their health. Some of our benefits for 2024 include: Competitive salary with opportunity for equity in an early stage, high growth business Generous paid time off, including an all-company holiday over Thanksgiving week Calibrate-funded health benefits (medical, dental, vision) - starting at zero cost to you Calibrate-paid disability and basic life insurance to give you peace of mind during unforeseen events Therapy on your time with free access to Headspace and HeadspaceCare An employee assistance program through Guardian to provide counseling across a range of personal topics Remote-first team Competitive Paid Parental Leave for parents OUR VALUES We’re in it together : We have an audacious mission, and we’re building a lot of things for the first time — from the first DTC pharma business within the healthcare ecosystem to the data infrastructure for providing real-world evidence in the largest category of chronic disease. It takes superpowers to build something simple and intuitive within the complex healthcare market, so we identify and work as a team from our individual points of strength. Not everyone has to be good at everything, but we know that when we harness what we’re each great at, we’re unstoppable. Small wins create big wins : We ground every experience in optimism, recognizing and celebrating successes along the way. We break projects down into smaller components. And we focus on where we have momentum. We always plan for larger goals with the knowledge that our plans will evolve as we achieve smaller milestones. You’re in control : We don’t let location stand in the way of the best talent — and from coaches to engineers, we are a remote-first team. Our business is multi-faceted, so each Calibrater is hired to be an expert in their piece of it — in control of their own initiatives, in control of their own impact, and in control of driving their own (real) results. Real results matter : We’re obsessed with outcomes because when our members win, we win, and the data proves that we’ve built the best metabolic health program on the market. We’re purposeful, optimistic, and relentlessly confident that we can solve the biggest medical issue of the 21st century. Calibrate is proud to be an equal opportunity workplace, providing equal employment and advancement opportunities to all team members. To achieve our mission of changing the way the world treats weight, we are building an environment where every Calibrater can thrive, feel a sense of belonging, and do the best work of their careers. We value diversity and recruit, hire, and promote individuals solely based on talent, qualifications, competence, and merit. We evaluate candidates without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other protected characteristics as required by law and as a matter of our company values.",
        "url": "https://www.linkedin.com/jobs/view/3969085532"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3888465059,
        "company": "TekIntegral",
        "title": "SR ANALYTICS DEVELOPER/ Data Engineer----ONLY LOCALS TO NY-PA-NJ",
        "created_on": 1720637068.0729535,
        "description": "Senior Analytics Developer/ Data Engineer Work Location: 2 MTC Brooklyn/Remote an option with onsite visits for critical meetings as needed. ONLY LOCALS TO NY-PA-NJ Visa: USC and GC only SCOPE OF SERVICES Develop and maintain highly efficient and interactive reports, dashboards, and data models to meet business requirements. Collaborate with data scientists and business stakeholders to understand data analysis needs and translate them into technical requirements. Design and implement data engineering pipelines to extract, transform, and load data from various sources into the analytics platform. Perform data validation, cleansing, and transformation to ensure accuracy and consistency. Optimize database queries and data retrieval processes to enhance performance and scalability. Conduct data profiling and analysis to identify data quality issues and provide recommendations for improvement. Stay up to date with industry best practices and emerging trends in analytics, data engineering, and visualization tools. Mandatory Skills 13+ years of experience as an Analytics Developer, Data Engineer, or similar role, with a focus on developing reports, dashboards, and data models. Strong experience designing and implementing data models and schemas in Snowflake. Define Snowflake databases objects to support efficient data storage and retrieval. Expertise with data visualization tools such as Power BI, Looker, Tableau, or similar. Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL, Oracle). Proficiency in data modeling concepts and techniques (e.g., dimensional modeling, star schema). Solid understanding of data engineering principles and experience with data integration and ETL processes. Familiarity with cloud platforms, preferably Azure, and experience with integration tools like IICS (Informatica Intelligent Cloud Services). Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills to work effectively in cross-functional teams. Desirable Skills Proficiency in programming languages such as Python, R, or Java. Familiarity with big data technologies (e.g., Hadoop, Spark) is a plus. Experience with data integration tools such as Informatica Intelligent Cloud Services and Mulesoft. Experience using Azure services for Security, Blob Storage, Data Lake, Databricks, Data Factory etc. Experience with Azure Monitoring services Microsoft Certified Azure Solutions Architect Expert or a Snowpro Certification or a similar one Manish Pratap Yadav Technical Recruiter TekIntegral Inc. 500 N Central Expwy #500G Plano, TX USA 75074 (214) 432- 9763 myadav@tekintegral.com www.tekintegral.com",
        "url": "https://www.linkedin.com/jobs/view/3888465059"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3817554592,
        "company": "Genius Sports",
        "title": "Senior Software Engineer (Data Platform)",
        "created_on": 1720637069.6800215,
        "description": "A Bit About Us Do you want to join one of the world’s fastest growing sports technology companies? Genius Sports is at the epicentre of the global network connecting sports, brands and fans through official live data. Our mission is simple. We champion a more sustainable sports data ecosystem that benefits all parties. We’re looking for enthusiastic and ambitious people to join our talented team. If you see yourself becoming part of a global family building the future of sports entertainment together, then come and grow with us. We put trust in our people to deliver the difference for our clients around the world. It’s why many of the world’s largest leagues & federations such as the NFL, English Premier League, FIBA and NCAA choose to work with Genius Sports. How You’ll Work Forming part of a multi-disciplinary team of Software Engineers, DevSecOps Engineers, Data Scientists and QA Engineers, you will work closely to the fundamental principles of continuous delivery and empowered, high-performing teams. If you are looking to work on a smart solution, collaborate with astute engineers and deliver high calibre code with an autonomous & performance focused approach that supports success, delivery & quality, then this is for you. About Your Role Normally as a Senior Platform Engineer, you'll have at least five years of professional engineering experience. However, we value aptitude over experience and encourage you to apply if you have the relevant skills. In this role you’ll be part of a team building highly distributed, real-time, dynamically scaling systems using modern CI/CD pipelines & cloud infrastructure. You will play an important part in innovating, architecting, delivering & maintaining an industry-revolutionising product. This role requires a data-driven, evidence-based approach, using the principles of continuous experimentation and validation. Senior Software Engineers excel at seeing beyond the immediate spec, developing innovative, cost-effective solutions that balance capability with the need to build in measured increments. At this level you will demonstrate high levels of ownership and think about the bigger picture, investing time mentoring more junior engineers and encouraging curiosity in your team. Skills You’ll Have An expert understanding of at least one object-oriented programming language (C#, Java, JS, Kotlin, Python, PHP, Golang, C++) and the ability to effectively build production-ready code for higher-complexity tasks. Proficiency in the design and development of REST APIs. Experience working with low-latency stream-processing technologies such as Kafka, Flink or Pulsar. Technical breadth with select areas of deeper experience. Broader software architecture skills and detailed knowledge of architectural patterns and applying them to scalable, fault-tolerant, observable microservices and systems. Detailed knowledge of testing methodology and designing high-quality testing suites resilient to changes in implementation. The ability to provide technical guidance and expertise to more junior engineers, supporting their development and the wider team goals. Other Advantageous Skills Interest in Sports Experience building GraphQL APIs What we expect from our co- workers Curiosity and strong desire to learn and improve. Social skills, being able to act as a facilitator, can balance enabling others with individual contributions. Time management and asynchronous communication skills relevant for a remote-first engineering organization. Enthusiasm and ability to work collaboratively within a team. Excellent spoken and written English. Adherence to our core engineering principles of Aligned Autonomy, Psychological Safety and Continuous Improvement. What’s In It For You As well as a competitive salary and annual leave allowance, our benefits include health insurance, skills training and much more, depending on the location. The base salary range for this role is $180,000 - $200,000. We also offer a host of softer benefits, including many social events throughout the year such as summer and winter holiday parties, monthly team building events, sports tournaments, charity days and wellbeing activities. How We Work We have adapted a forward-thinking ‘Ways of Working’ framework, which sets out (amongst other things) the opportunities for Geniuses to work flexibly, remotely and on working holidays. It affects different teams and locations differently, so please ask for further information in how it would work with this role. Our employees are empowered to stretch the boundaries of what’s achievable, always reaching further and pushing the edges to see what gives. We collaborate, we innovate, and we celebrate. We will continue to grow as an organisation and continue to invest in our highly talented and diverse team of Geniuses. Genius Sports Group is proud to be an equal opportunities employer. We recognize and celebrate the benefits that a diverse and inclusive workforce bring to our business, our customers and our staff. We welcome and will consider all applications regardless of age, different abilities or disability, gender re-assignment, marriage, pregnancy, maternity, race or nationality, religion or belief, sex and sexual orientation (and any other applicable status). Please let us know when you apply if you need any assistance during the recruiting process due to a disability.",
        "url": "https://www.linkedin.com/jobs/view/3817554592"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3839311991,
        "company": "PermitFlow",
        "title": "Fullstack Software Engineer",
        "created_on": 1720637071.5727675,
        "description": "🚀 About PermitFlow PermitFlow’s mission is to streamline and simplify construction permitting in the $1.6 trillion United States construction market. Our software reduces time to permit, supporting permitting end-to-end including permit research, application preparation, submission, and monitoring. We’ve raised a $31m Series A led by Kleiner Perkins with participation from Initialized Capital, Y Combinator, Felicis Ventures, Altos Ventures, and the founders and executives from Zillow, PlanGrid, Thumbtack, Bluebeam, Uber, Procore, and more. Our team consists of architects, structural engineers, permitting experts, and workflow software specialists, all who have personally experienced the pain of permitting. 📌About The Team We have a lean but mighty engineering team. We’ve done a lot with a little, but there’s much more work to be done to continue our fast-paced growth and we want you to be a part of that growth. You’ll help us get there by owning end-to-end projects, talking with customers, and ultimately supporting the growth of PermitFlow. Ideally, you’re based in NYC or willing to relocate for hybrid work. We’re currently hybrid in-person 3 days/week in our NYC office. ✅ What You’ll Do You'll work alongside the CTO and engineering team to develop the first construction permit application and management platform for builders. Our current team consists of engineers from Uber, Amazon, NerdWallet, OnDeck, Harvard, Stanford, and more. We are background and experience agnostic, and we encourage anyone to apply if they are passionate about joining a small team and working to solve a real-world pain point. Working directly with the founders and users to define the product and engineering roadmap. Owning and shipping features from inception to implementation. Developing, iterating, and refining extensible and flexible workflow tooling for permitting. Build exceptional user experiences that allow users to easily apply, track, and manage their permitting. Mentoring engineers and others around you to build a culture of technical excellence. Our Tech Stack React Typescript Node.js Postgres 🙌 Qualifications & Fit Strong experience in professional fullstack development, ideally some of which you’ve spent in startups Significant experience working within our tech stack, which is listed above You sweat the important details and strive for excellence in your work Experience owning technically challenging and demanding cross-functional projects A record of identifying valuable projects, communicating the strategy for them, and executing on them autonomously A customer-first mindset and an interest in talking with customers to make sure what we’re building is a polished product meets their needs Habit of introspection and understanding what’s helped you be successful in the past 💙 Benefits 📈 Equity packages 💰 Competitive Salary 🩺 100% Paid health, dental & vision coverage 💻 Home office & equipment stipend 🍽️ Lunch & Dinner provided via UberEats w/ a fully stocked kitchen 🚍 Commuter benefits 🎤 Team building events 🌴 Unlimited PTO",
        "url": "https://www.linkedin.com/jobs/view/3839311991"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3915077872,
        "company": "The Walt Disney Company",
        "title": "Software Engineer II",
        "created_on": 1720637073.0459986,
        "description": "Disney Entertainment & ESPN Technology On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming our media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to enhance flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world. A few reasons why we believe you’d love working here: Building the future of Disney’s media: DE&E Technologists are designing and building the infrastructure that will power our media, advertising, and distribution businesses for years to come. Reach & Scale: The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more. Innovation: We develop and implement groundbreaking products and techniques that shape industry norms and improve how audiences experience sports, entertainment & news. The Product & Data Engineering teams are responsible for end to end development for Disney’s extraordinary consumer-facing products, including streaming platforms Disney+, Hulu, and ESPN+, and digital products & experiences across ESPN, Marvel, Disney Studios, NatGeo, and ABC News. The team drives innovation at scale for millions of consumers around the world across Apple, Android, Smart TVs, game consoles, and the web, with our platforms powering core experiences like personalization, search. The User Foundations team builds critical User Capabilities that are shared across all experiences on the streaming services: Disney+, Hulu, ESPN+ and Star+. We implement reliable, high-throughput services and pipelines for capturing information about our users, and delivering personalized experiences. We're a fast-paced, multifaceted, collaborative and fun team, and are looking for someone who can slot right in and start delivering from day 1. Responsibilities Collaborates closely with engineering teams to identify goals and translates them into technical specifications, projects, or fixes that scale and perform. Leads by example to write, maintain, follow and enforce code quality through test driven development. Contributes to project needs and the evolution of the team's practices, recommending changes in development, coding, maintenance and system standards. Efficiently supports software throughout the lifecycle. Performs technical maintenance and fixing for components while maintaining clear documentation. Applies experiences and exercises judgment in selecting methods and techniques to identify, resolve, and develop solutions to a variety of complex tasks involving architectural application changes. Supports and mentors' developers through code reviews, knowledge-sharing, and technical leadership. Implements reusable architecture and patterns that set the direction for backend service development across DE&ET. Basic Qualifications: 3+ years of software engineering experience Understanding of message based distributed, scalable, and resilient systems Desire to work in a start-up, fast-growth, or rapid-change environment Experience working on diverse teams Problem-solving skills to identify the root cause Solid communication skills – written, and oral Ability to be flexible, adapting to changing priorities Java and/or Scala Build tools like Maven and/or sbt SpringBoot and related Spring projects BDD/Integration testing using cucumber WebService. REST + swagger Preferred Qualifications: Big data frameworks. Flink and/or Spark AWS EMR, ElastiCache, Aurora, S3, IAM, EKS Apache Kafka and/or Kinesis Terraform, Docker and Kubernetes Experience building, testing, and tuning distributed systems Required Education: Bachelor’s degree in Computer Science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience The hiring range for this position in Santa Monica is $112,600-$151,000 per year and in Seattle is $142,516- $191,180 per year and in NYC is $118,000-$158,200 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",
        "url": "https://www.linkedin.com/jobs/view/3915077872"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3966204831,
        "company": "RemoteWorker US",
        "title": "Senior Data Engineer - hybrid remote",
        "created_on": 1720637074.9514248,
        "description": "Job Description Job Description Kunai is a fast-growing digital consultancy focused on banking, payments, and fintech powered by a global network that attracts the best and brightest people from all backgrounds and cultures, driven by innovation and experimentation, spread across almost every single continent. Over the past decade, we've shipped over 150 products for clients that include Visa, American Express, Capital One, WEX, Wells Fargo, Ernst & Young, and TOMS Shoes. Our founders built a previous agency (Monsoon) that was acquired by Capital One in 2015. Requires 4 days/ week on premises in the NYC office (M-Th) What will you do? You will design and build a strategic risk platform supporting various credit and risk areas, consuming data from multiple sources and vendors. You will develop complex dashboards to visualize multiple risk metrics and design workflows and approval processes. You will collaborate with cross-functional teams to analyze and integrate diverse data sources, ensuring data quality and consistency. You will develop and optimize data pipelines, support advanced data modeling, and provide insight through reporting tools. Could this be you? Must Haves: 10+ years experience as a software developer (tech agnostic) 5+ years of experience using common BI tools (Tableau, Alteryx, Power BI etc.) 5+ years experience with public cloud providers (preferably Azure) 5+ years experience with Data Warehousing (Redshift or Snowflake) Advanced SQL knowledge and experience working with a variety of databases. Technical expertise with data models, data mining, and segmentation techniques Bachelor's degree in computer science or related field or equivalent work experience Nice to Haves: 5+ years of hands-on experience with SQL database design Strong analytic skills related to working with unstructured datasets. Working knowledge of message queuing, stream processing, and 'big data' At Kunai, we have built deep relationships with our clients. Our bar is high, and our mission is to always exceed our client's expectations. If you are fanatical about customer success and driven to work on and solve tough technical challenges, we would love to chat with you!",
        "url": "https://www.linkedin.com/jobs/view/3966204831"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959601816,
        "company": "Microsoft",
        "title": "Senior Software Engineer, Big Data Systems",
        "created_on": 1720637076.6451056,
        "description": "Microsoft Advertising is an online advertising platform, where advertisers bid to display brief ads, service offers, product listings and videos to web users. Our data-enabled technology platform, encompassing Invest, Monetize, and Curate, optimize return on investment for both buyers and sellers, while maintaining a commitment to an open marketplace and empowering the open web globally. As a Senior Software Engineer, Big Data Systems, you will operate and support our diverse Big Data Platform. This platform consists of large Hadoop, HBase, and Kafka clusters in an all Linux environment. The platform currently ingests 300TB of new data and runs 20,000 ETL jobs every day across 14 Hadoop, HBase, and 6 Kafka Clusters. This growing team consists of curious, passionate, talented technologists who enjoy working on complex, large scale data stores. Our team members thrive in a learning and teaching environment. Each team member is encouraged to explore solutions and efficiencies to support, optimize, and maintain our systems. We are enthusiastic about automation and optimization. Your primary responsibilities will involve supporting and enhancing data stores for extremely intricate, high-availability, low-latency, business-critical real-time systems. This will entail utilizing contemporary open-source tools and architectural approaches, working closely with other highly skilled engineering teams, honing your problem-solving abilities in complex scenarios, and becoming proficient in managing large-scale data stores. About We anticipate exponential growth in data and transactions on our platform and so we are seeking an engineer who is excited about this opportunity and would love to: Work on large-scale, distributed systems Learn new technologies, tools and applications Your primary responsibilities will involve coding, support, upgrades, troubleshooting, performance tuning, maintenance and automation. This will entail utilizing contemporary open-source tools and architectural approaches, working closely with other highly skilled engineering teams, honing your problem-solving abilities in complex scenarios and becoming proficient in managing large-scale data stores. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Support a complex Data Pipeline Platform by monitoring, maintaining, provisioning, and upgrading Hadoop, HBase, Kafka, Trino, Cassandra/ScyllaDB, IRONdb, Druid, QFS, Metrics, and ETL systems using proprietary automation tools. Develop new tools to automate routine day-to-day tasks, such as security patching, software upgrades, and hardware allocation. Utilize automated system monitoring tools to verify the integrity and availability of all hardware, server resources, and critical processes. Code scripts to automate and optimize operational processes. Troubleshoot and analyze hardware or software failures and provide solutions for recovery. Identify and resolve faults, inconsistencies, and systemic issues. Collaborate with engineering team partners to resolve complex system performance issues. Prepare documentation for standard operating procedures. Effective with time management and ability to manage priority tasks and requests. Provide production support and participate in on call rotation. Embody our Culture and Values Qualifications Required Qualifications: Bachelor's Degree in Computer Science or related technical field AND 4+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python OR equivalent experience 4+ years of relevant experience in implementing, troubleshooting, and supporting distributed systems such as Hadoop. 4+ years of relevant experience in scripting/writing/modifying code for monitoring/deployment/automation in one of the following (or comparable): Python, Shell, C#, Java. 4+ years of relevant experience in implementing, troubleshooting, and supporting the Unix/Linux operating system with concrete knowledge of system administration/internals. Other Requirements Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. Preferred Qualifications 5+ years of relevant experience with any of the following technologies: Hadoop-HDFS, Yarn-MapReduce, HBase, Kafka, Trino, Cassandra/ScyllaDB, IRONdb, Druid, QFS. 5+ years of relevant experience with any of the following technologies: Puppet or equivalent configuration management tool. 5+ years of relevant experience with any of the following container technologies: Kubernetes or Docker. Experience with Cloud Computing such as Azure, AWS or Google Cloud Platform. Experience with Nagios or similar monitoring tools. Experience with data collection/graphing tools like Graphite and Grafana. Understanding of code versioning tools such as git. Software Engineering IC4 - The typical base pay range for this role across the U.S. is USD $117,200 - $229,200 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $153,600 - $250,200 per year. Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay Microsoft will accept applications for the role until July 13, 2024. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
        "url": "https://www.linkedin.com/jobs/view/3959601816"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3930772252,
        "company": "Cockroach Labs",
        "title": "Manager, Data Engineering - New York, NY",
        "created_on": 1720637078.3745794,
        "description": "Databases are the beating heart of every business in the world. Cockroach Labs is the creator of CockroachDB, the most highly evolved cloud-native, distributed SQL database on the planet that scales fast, survives anything, and thrives anywhere. We created CockroachDB to unshackle teams from the constraints of their database. Join us on our mission to enable every developer to build world-changing applications! About The Role We are looking for an experienced Data Engineer to lead the data engineering team at Cockroach Labs. As a member of the data organization, you’ll help power data science, ETLs, self-service data, and tools to make us efficient and facilitate scalable decision-making. You will be responsible for defining, developing and managing curated datasets, key business metrics and reporting across functional units at Cockroach Labs. You will also manage a small team of Data Engineers and provide mentorship and guidance in their career goals. You Will Lead the design, build, and scaling of our backend data infrastructure (across data acquisition, pipelines, and warehousing) using the latest data engineering technologies to ensure the data platform is reliable, extendable, and performant Conceptualize, develop and own the data architecture, data pipelines and centralized data warehouse with trustworthy curated datasets and standardized metrics and business definitions to empower data access and self-service Collaborate with engineering, product, design, and operations teams to build best-in-class data applications that will support Cockroach Labs’s missions and goals Provide strategic and tactical recommendations for Product, Sales and Marketing Augment our systems to create a modern data architecture using best practices for data democracy and self-service analysis Create data tools to translate data questions into flexible methodologies that scale to improve operational efficiency and other key business performance metrics The Expectations In your first month, you will go through the Cockroach Labs onboarding process and start to build relationships with stakeholders across the company. You will understand our current data architecture and the internal and external resources we use to maintain it. You will start to prioritize the current backlog of data requests. After 30 days, you will have a grasp on the major questions the product management team needs to answer, as well as the executive-level questions that require coordination between disparate data sets. You will update the roadmap priorities and put in place key processes for building out this function. You will develop a point of view on the direction we need to take our data platform to support our product operations. After 90 days, you will be fully integrated into the team. You will put in place the major processes for supporting Product and the broader organization, and make incremental improvements to our data platform that demonstrably improve our ability to make decisions. You will socialize a strategy for data in the Product team and how this will support the needs of other departments in the future. You Have 8+ years of experience as a Data Engineer using Python, Java, Scala or any other programming language Experience designing and developing data collecting and processing systems to handle large data sets 3+ years of experience and knowledge of modern data warehouse, building scalable pipelines and reporting/analytic techniques 3+ years of people management experience in leading analytics teams. Experience with a geographically distributed team is a plus Deep expertise in tools such as Spark, Airflow, Presto/Hive, Spark, or any other streaming technologies to process incredible volumes of data, Looker, Tableau or other reporting tools Demonstrated ability in designing and implementing centralized modern data warehousing/platforms (snowflake/looker/segment/etc) that support self-service analytics Strong knowledge of data architecture, data modeling, statistics, data science and data infrastructure ecosystems Effective communication skills: Able to work with cross-functional stakeholders and present ideas in a non-technical way Experience in establishing data engineering best practices and methodologies to ensure data transformations and computations are accurate, efficient, and tested The Team Reporting to Veera Ilamurugu, Head of Data Veera Ilamurugu heads up the Data Analytics team at Cockroach Labs. He is responsible for our Product data strategy and passionate about building and scaling businesses with data. Before joining Cockroach Labs, Veera was a Head of Analytics at Stitchfix, Leading analytics team covering internal company strategy When not at work, he enjoys watching Netflix,trying out new recipes in the kitchen and listening to music. Our Benefits 100% health insurance coverage (for you and your dependents!) Paid parental leave (with baby bucks) Flex Fridays Flexible time off & flexible hours Education reimbursement Relocation support Cockroach Labs is proud to be an Equal Opportunity Employer building a diverse and inclusive workforce. If you need additional accommodations to feel comfortable during your interview process, please email us at accessibility@cockroachlabs.com. The annual anticipated base salary range for U.S. candidates for this role is USD $185,000 - $230,000 plus commission if a sales role. We set standard ranges for all U.S.-based roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location. Actual salaries may vary and fall outside of this range depending on factors such as a candidate’s qualifications, geographic location, skills, experience, and competencies. In addition, we are often open to a wide variety of profiles, and recognize that the person we hire may be less experienced (or more senior) than this job description as posted. Salary is one component of the Cockroach Labs’ total rewards package, which includes stock options, health insurance, life and disability insurance, funds towards professional development resources, flexible PTO, paid holidays, and parental leave, to name a few! Salaries for candidates outside the U.S. will vary based on local compensation structures.",
        "url": "https://www.linkedin.com/jobs/view/3930772252"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3911126045,
        "company": "Courier Health",
        "title": "Senior Software Engineer, Backend",
        "created_on": 1720637080.0280654,
        "description": "Courier Health is on a mission to solve one of the biggest and most meaningful opportunities in healthcare: reinvent how people living with chronic and rare diseases are supported . We are building the future of patient engagement for life sciences companies. Our software is leveraged by biopharma companies to support patients in their complex journey from diagnosis to initiating and remaining on therapy to achieve optimal health outcomes. We are looking for talented individuals who are motivated by the opportunity to have an outsized impact on not just their company, but the healthcare industry at large. What You'll Do Play a lead role designing and building new features for our core products Improve the speed and reliability of existing applications Work with other employees to find new product opportunities Help us scale the company, the culture, and our products Qualifications BS or MS in computer science or related field 8+ years professional experience Experience with object oriented programming and a high bar for code quality Experience with AWS services Passionate about solving technical challenges and architecting infrastructure that is both sustainable and scalable Inspired by our mission to improve healthcare through technology Seek simple approaches to complex problems Proven track record of being an independent self-starter Bonus Points Experience with AWS Lambda or AppSync Experience with Webpack or Parcel Experience building healthcare applications Have taken a leading role in delivering complex software systems all the way to production Benefits Highly competitive pay, including equity Top notch health benefits Flexible PTO Paid parental leave Monthly healthy lifestyle stipend Team events and bi-annual off-sites Career coaching opportunities Open office with unlimited coffee, snacks, etc. The annual salary range for the target level for this role is $170,000 - $195,000 + equity + benefits, including medical, dental, and vision. Courier Health is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",
        "url": "https://www.linkedin.com/jobs/view/3911126045"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3841634982,
        "company": "Stagwell",
        "title": "Data Analyst",
        "created_on": 1720637081.7021365,
        "description": "Stagwell Marketing Cloud (SMC) is a suite of data-driven SaaS solutions built for the modern in-house marketer. Born out of Stagwell’s network of award-winning agencies, SMC’s products empower marketers to drive business and brand impact by giving them intuitive tools equipped with actionable proprietary data. SMC’s portfolio of solutions powers strategic customer research, communications, and media activation for brands worldwide. Get your head in the cloud at www.stagwellglobal.com/smc. The Data Analyst will work alongside internal customers to conduct data investigation, research, data management and data reporting. The Data Analyst is responsible for building automated reports that allow for self-service data exploration. This person will also assist in conducting ad hoc analysis to answer specific business questions that may eventually require automated report development. You will be instrumental in analyzing data discrepancies and data lineage in our data asset acquisition life cycle and assist with solving data problems. This is a terrific opportunity for someone who is interested in joining a lean, innovative group with the possibility of tremendous career development in data engineering and data asset management. Responsibilities Build tabular and/or visualization reports in the Business Intelligence tool that help to articulate answer business questions that drive actions that improve the bottom line Provide teams and individual stakeholders with actionable insights based on data to support decision making efforts Design analytics dashboards and KPI (Key Performance Indicator) reports for internal teams to identify critical data points and translate data into clear and coherent visualizations and reports for non-technical teams Collaborate with and offer insights into different internal teams from Data Warehouse and Engineering to Operations, Sales, Marketing and Finance Communicate and present on technical information with non-technical team members and stakeholders Troubleshoot and resolve data issues using critical thinking Organize and lead meetings with business and operational data owners to collect business requirements and iterate through designs after receiving feedback from end users Coordinate and communicate between business users and the data warehouse organization, balancing requirements, and resources to solve business problems Work closely with engineering and operations to document business processes that have an impact on data quality Identify data discrepancies and data quality issues and work with other analytic team members and SMEs to ensure data consistency and integrity. Proactively identify opportunities to improve existing BI processes, communicating these opportunities to internal teams. Work independently and with team members to understand and document database structure and business processes Extract raw data from numerous data sources and aggregate it into cohesive data sets via ETL (extracting, transforming and loading) to ensure data is accurate and stable Note: These statements are intended to describe the essential functions of the job and are not intended to be an exhaustive list of all responsibilities. Skills and duties may vary dependent upon your department or unit. Other duties may be assigned as required. Qualifications Skills/Qualifications: Bachelor’s degree or the equivalent experience in statistics, math, computer science, physics, finance, business administration, economics or a related field Minimum 5 years of professional experience in technical data analysis, data warehousing, and data governance processes with proven business analysis experience Experience with MS SQL Server and writing TSQL views, stored procedures, and functions Passionate about data and analyzing business needs Excellent computer skills and highly proficient in the use of MS Word, MS Excel, PowerPoint Experience creating visually and verbally engaging presentations, for key stakeholders that tell a clear story using data and concepts Comfortable working in a collaborative setting with business senior executives Self-motivated requiring minimal supervision with a positive can-do attitude Additional Preferred Qualifications Experience with designing reports and dashboards in, Tableau, SSRS, or PowerBI Experience with Microsoft Dynamics CRM (Customer Relationship Management) or AX Experience maintaining a data dictionary via any tool or custom application In order to comply with equal pay and salary transparency laws in various locations, we believe the target range of base compensation in New York City for this role is $104,000 - $130,000. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and location. In addition to medical, dental and vision coverage, we offer a generous PTO plan, 401k program, comprehensive family planning benefits (including paid parental leave), tuition reimbursement, and pre-tax commuter benefits. Benefits/perks may vary depending on the nature of your employment with Stagwell and the location where you work. Follow Stagwell On Social Media Instgram: @stagwellglobal Threads: @Stagwellglobal X: @Stagwell Youtube: @stagwell Link tree: stagwellglobal | Instagram | Linktree",
        "url": "https://www.linkedin.com/jobs/view/3841634982"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Buffalo-Niagara Falls Area",
        "job_id": 3901374472,
        "company": "DataAnnotation",
        "title": "Software Engineer",
        "created_on": 1720637083.5281107,
        "description": "DataAnnotation is committed to creating quality AI. Join our team to help train AI chatbots while gaining the flexibility of remote work and choosing your own schedule. We are looking for a proficient Software Engineer to join our team to train our AI chatbots to code. You will work with the chatbots that we are building in order to measure their progress, as well as write and evaluate code. In this role you will need to be proficient in at least one programming language (Python, JavaScript, HTML, C++, C#, Swift and SQL) and able to solve coding problems (think LeetCode, HackerRank, etc). For each coding problem, you must be able to explain how your solution solves the problem. Benefits: This is a full-time or part-time REMOTE position You’ll be able to choose which projects you want to work on You can work on your own schedule Projects are paid hourly, starting at $40+ USD per hour, with bonuses for high-quality and high-volume work Responsibilities: Come up with diverse problems and solutions for a coding chatbot Write high-quality answers and code snippets Evaluate code quality produced by AI models for correctness and performance Qualifications: Fluency in English (native or bilingual level) Proficient in at least one programming language (Python, JavaScript, HTML, C++, C#, Swift and SQL) Excellent writing and grammar skills A bachelor's degree (completed or in progress) Previous experience as a Software Developer, Coder, Software Engineer, or Programmer",
        "url": "https://www.linkedin.com/jobs/view/3901374472"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3933456875,
        "company": "ATLAS SP Partners",
        "title": "Senior Data Developer",
        "created_on": 1720637085.2465055,
        "description": "About ATLAS SP ATLAS SP Partners is a global investment firm that seeks to provide stable funding and capital markets services to companies seeking innovative and bespoke structured credit and asset-backed finance solutions. ATLAS SP's tenured experts work with clients to determine the best approach to optimize their capital and achieve their goals, across a broad range of capabilities. Our integrated platform encompasses a holistic suite of capabilities, including asset/portfolio advisory solutions, warehouse/acquisition financing solutions, whole loan purchase/sale and securitization/distribution. Our Culture ATLAS SP is \"one team\" where everyone makes an impact – we grow together, win together, and embrace change together. From advancing the markets to supporting our communities, everything we do serves to make a difference. Our people are industry leaders with a passion for client service, complex problem solving, and innovation. We provide our talent with the pathways to grow professionally and personally in a collaborative and inclusive environment. We're proud to build upon a legacy of excellence anchored in deep expertise and client service across the asset management landscape. Position Overview ATLAS SP is seeking a senior data developer to help build out a data ecosystem that enables us to scale our business. The individual will design and build a foundation to strengthen and scale the existing data model. The individual will be responsible for collaborating with cross-functional teams to analyze and integrate diverse data sources, ensuring data quality and consistency. The individual will leverage your expertise in database management, data processing, and analytics to develop and optimize data pipelines, support advanced data modeling, and provide actionable insights through sophisticated reporting tools. Primary Responsibilities Analyze complex ecosystem of legacy systems Architect and scale a modern data platform that consumes data from multiple internal sources and vendors Enhance the data model taking into account industry best practices Build and maintain scalable ETL pipelines to efficiently process large volumes of data Work with engineering teams to ensure robust instrumentation across multiple systems Partner with business stakeholders to understand and deliver business requirements Implement monitoring systems to ensure data quality Participate in company-wide Data Governance Create data tools for analytics and data scientist team members that assist them in building and optimizing the product. Qualification and Experience Bachelor's degree in computer science or related field or equivalent work experience 10+ years of proven experience as a senior software developer, including crafting and implementing sophisticated systems from scratch 5+ years of proven experience working with cloud technology (preferably Azure), data models, API design, API development 5+ years of data warehousing experience (Redshift or Snowflake) 10+ years of hands-on experience with SQL database design Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Technical expertise with data models, data mining, and segmentation techniques 10+ years of extensive development experience with technologies like: Python, JSON, Java, .NET 5+ years of experience using common BI tools including Tableau, Alteryx, Microsoft Power BI etc. Experience building and optimizing 'big data' data pipelines, architectures and data sets. Agile development experience Experience supporting and working with cross-functional teams in a dynamic environment. Strong analytic skills related to working with unstructured datasets. Base Salary Range $200,000 to $250,000 The base salary range for this position is listed above. This position is also eligible for a discretionary annual bonus based on personal, team, and Firm performance. Compensation ranges are based on several factors including job function, level, and geographic location. Final offer amounts are determined by multiple factors including candidate experience and expertise and may vary from the amounts listed here. ATLAS SP is an equal opportunity employer. The firm and its affiliates do not discriminate in employment because of race, color, religion, gender, national origin, veteran status, disability, age, citizenship, marital or domestic/civil partnership status, sexual orientation, gender identity or expression or because of any other criteria prohibited under controlling federal, state or local law.",
        "url": "https://www.linkedin.com/jobs/view/3933456875"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959628526,
        "company": "Resource Logistics Inc.",
        "title": "System Engineer",
        "created_on": 1720637086.971804,
        "description": "Technologies - WINDOWS + VMWare, AD, Office Rubric & LINUX (good to have) Relevant certifications/degree in Computer Science, Engineering or a related subject Proven working experience in installing, configuring and troubleshooting Windows (UNIX /Linux - good to have) based environments. Solid experience in the administration and performance tuning of application stacks Cloud experience, preferably in Clienture Experience with virtualization and containerization (eg., VMware, Virtual Box) Experience with monitoring systems Experience with automation software Solid scripting skills Solid networking knowledge Responsibilities Manage and monitor all installed systems and infrastructure Install, configure, test and maintain operating systems, application software and system management tools Proactively ensure the highest levels of systems and infrastructure availability Monitor and test application performance for potential bottlenecks, identify possible solutions, and work with developers to implement those fixes Maintain security, backup, and redundancy strategies Write and maintain custom scripts to increase system efficiency and lower the human intervention time on any tasks Participate in the design of information and operational support systems Provide 2nd and 3rd level support Liaise with vendors and other IT personnel for problem resolution",
        "url": "https://www.linkedin.com/jobs/view/3959628526"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3746693490,
        "company": "Figma",
        "title": "Software Engineer - Teamwork",
        "created_on": 1720637088.7509744,
        "description": "Figma is growing our team of passionate people on a mission to make design accessible to all. Born on the Web, Figma helps entire product teams brainstorm, design and build better products — from start to finish. Whether it’s consolidating tools, simplifying workflows, or collaborating across teams and time zones, Figma makes the design process faster, more efficient, and fun while keeping everyone on the same page. From great products to long-lasting companies, we believe that nothing great is made alone—come make with us! Teamwork is a full stack web engineering group building the features that enable companies of all sizes to successfully adopt, manage, collaborate, and create in Figma Design and FigJam, from two-person teams to the Fortune 500. This includes (but is not limited to) ownership of core surface areas like our search and file browsing capability, security and access platform, customer lifecycle (billing and payments) systems, and/or in-product notifications. As an engineer on Teamwork, the work you’ll do will have lasting and outsized impact on Figma as a successful business, and you’ll have plenty of opportunities to both leverage your existing strengths and learn new skills as the team grows and takes on new challenges. This is a full time role that can be held from one of our US hubs or remotely in the United States. What you'll do at Figma: Regularly collaborate with designers, PMs, and other engineers on and beyond your team (or org) to plan features that unblock adoption across new categories of customers, and to break down high level goals into tasks and timelines Build, document, and maintain tests, features, and infrastructure Regularly communicate and document architectural designs and requirements Provide thoughtful feedback to others on the team and facilitate spaces of learning, belonging, and growth Help interview and recruit more talented engineers to Figma We’d love to hear from you if you have: 2+ years of professional experience shipping features and/or products as a full-stack developer Demonstrated coding fluency with one or more programming languages in a working context, including but not limited to: Typescript/Javascript, React, Ruby, Java, Python, Go, or Rust Experience communicating and collaborating regularly and effectively with designers, PMs, engineers, and stakeholders beyond your team (or org) to plan features and break down high level goals into tasks and timelines, A growth mindset and experience investing in the learning, development, belonging, and impact of your peers A passion for and experience with driving B2B and/or B2C product direction and developing product platforms Experience with crafting delightful user facing product experiences that enable customization and categorization While it’s not required, it’s an added plus if you also have: 2+ years of experience operating in a technical lead capacity working on collaboration tools or B2B/B2C SaaS products Advanced education in Computer Science, Computer Engineering, or a relevant technical field Experience iterating on core aspects of a product’s identity, authentication, and permissions infrastructure Experiencing redesigning a product’s main home feed/UI Experience standardizing information architecture and core product frameworks Experience building for the SaaS product customer lifecycle via new pricing tiers or more flexible billing models At Figma, one of our values is Grow as you go. We believe in hiring smart, curious people who are excited to learn and develop their skills. If you’re excited about this role but your past experience doesn’t align perfectly with the points outlined in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles. Read more about our team Inside Figma: enterprise explained Figma’s engineering values Investing in Figma: The Decade of Design How work is changing at Figma Figma's next product is a multiplayer whiteboard called FigJam Software Design Startup Figma Is Now Worth $10 Billion Pay Transparency Disclosure If based in Figma’s San Francisco or New York hub offices, this role has the annual base salary range stated below. Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), market demands, and specific work location. The listed range is a guideline, and the range for this role may be modified. For roles that are available to be filled remotely, the pay range is localized according to employee work location by a factor of between 80% and 100% of range. Please discuss your specific work location with your recruiter for more information. Figma offers equity to employees, as well a competitive package of additional benefits, including health, dental & vision, retirement with company contribution, parental leave & reproductive or family planning support, mental health & wellness benefits, generous PTO, company recharge days, a learning & development stipend, a work from home stipend, and cell phone reimbursement. Figma also offers sales incentive pay for most sales roles. Figma’s compensation and benefits are subject to change and may be modified in the future. You may view our Pay Transparency Policy by clicking on the corresponding link. Annual Base Salary Range (SF/NY Hub): $149,000—$350,000 USD At Figma we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our product and our community to flourish. Figma is an equal opportunity workplace - we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity/expression, veteran status , or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. We will work to ensure individuals with disabilities are provided reasonable accommodation to apply for a role, participate in the interview process, perform essential job functions, and receive other benefits and privileges of employment. If you require accommodation, please reach out to accommodations-ext@figma.com. These modifications enable an individual with a disability to have an equal opportunity not only to get a job, but successfully perform their job tasks to the same extent as people without disabilities. Examples of accommodations include but are not limited to: Holding interviews in an accessible location Enabling closed captioning on video conferencing Ensuring all written communication be compatible with screen readers Changing the mode or format of interviews By applying for this job, the candidate acknowledges and agrees that any personal data contained in their application or supporting materials will be processed in accordance with the applicable candidate section of Figma's Privacy Policy.",
        "url": "https://www.linkedin.com/jobs/view/3746693490"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3968739498,
        "company": "CareerAddict",
        "title": "Quant/Quantitative/Financial Engineer/Developer/Software Engineer/Programmer/Fixed Income/Pricing",
        "created_on": 1720637090.7685874,
        "description": "Remote working conditions: Mon and Fri - Remote/Tue, Web and Thu - Onsite New York Valuations and Risk Developer Required Experience And Skills Experience working as desk quant or in a valuation support capacity Familiarity with Fixed Income and Derivative products Proficiency in Python OR C++ (only one of these having experience in BOTH of these languages is not essential) programming and object-oriented coding/design principles and object-oriented coding/design principles Job Role Investigate pricing and risk queries from Portfolio Managers, Middle Office and Risk team Maintain and extend Real Time and EOD P&L and risk infrastructure Develop new and extend existing pricing models and calculators Develop new columns and reports for portfolios managers and risk managers Partner with QM and Market Data teams when building support for new products or markets Develop tools for Middle Office and application support to assist them with supporting daily valuation cycle Develop integration and unit tests for all new code Provide day-to-day operational support, including handling/mitigating critical severity issues Working for a well established organization Flexible start date (ie immediate to 3 months notice) (If this position do not fit within your experience or is of no interest to you we offer a recommendation fee for any consultant you refer we successfully make a placement with).",
        "url": "https://www.linkedin.com/jobs/view/3968739498"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3952446036,
        "company": "Chartbeat",
        "title": "Software Engineer III - Front End",
        "created_on": 1720637092.5229707,
        "description": "Tubular and Lineup have partnered with Chartbeat to help you grow reach and revenue for your content. Chartbeat's (www.chartbeat.com) mission is to help content creators around the world better connect with their audiences. In 2023, Chartbeat joined forces with Tubular, the leader in global social video intelligence and measurement, and Lineup Systems, the leading global provider of media sales technology. Together, we're expanding the ecosystem of insights we provide to enterprise content creators who are developing audiences and revenue streams across channels. We now serve more than 1,000 brands globally, including The New York Times, the BBC, ESPN, Gannett, Vox, BuzzFeed, Paramount, WB, Mediahuis, Hearst, McClatchy, and GQ . You'll be joining a diverse group of focused, hard-working people who are passionate about doing work that's challenging and fun—and who strive to maintain a healthy work/life balance. Chartbeat's intuitive and powerful software has long empowered media brands to use their own data to build loyal audiences across desktop, social, and mobile platforms. With easy-to-use real-time and historical analytics, in-page optimization and testing tools, and unique insights into audience engagement, Chartbeat's products bring value to editorial, product, and business teams. Earlier this year, Chartbeat joined forces with Tubular, the leader in global social video intelligence and measurement. Tubular provides a unified view of the shifting values and interests of audiences across YouTube, Instagram, Facebook, Twitch, and more. Together, we're expanding the ecosystem of insights we provide to enterprise content creators who are developing audiences and revenue streams across channels. By joining two comprehensive network-level datasets, we'll help our partners understand and measure a larger proportion of audience interactions and, in turn, make smarter decisions that grow reach and revenue. We now serve more than 1,000 brands globally, including influential content publishers like The New York Times, the BBC, ESPN, Gannett, Vox, BuzzFeed, Paramount, WB, Mediahuis, Hearst, McClatchy, and GQ . The Team Chartbeat's frontend applications use an exciting array of technologies. Project stacks typically include modern libraries like React, Redux, Victory, Chart.js and D3 for data visualization, and a development environment based on npm, Webpack, and Babel for strong modularity and the latest Javascript language features. Our codebase also includes legacy systems that use Angular and Django. We are seeking a curious frontend engineer to join us on this adventure by helping build the components, systems, and dashboards that newsrooms use to learn about and grow their audiences. Responsibilities As a frontend engineer at Chartbeat, you'll spend the bulk of your time building single-page web applications in Javascript and React. You will be on a small cross-functional project team (typically, a few engineers, a designer, a data scientist, and a product manager) that will define your day-to-day activity — your team will collaborate to plan sprint goals and execute on those goals. You will also represent the frontend team to diagnose and squash bugs as they arise. As a member of the larger engineering organization, you'll participate in team meetings, discussions and learning/teaching opportunities. About You Experience working with React Experience working with the browser environment: HTML, CSS, modern Javascript, TypeScript Bonus: Experience working React Native Bonus: Experience with Angular, D3, Django Excellent verbal and written communication skills and a commitment to building an inclusive and collaborative working environment An interest in designing technical solutions to open-ended product problems Passion and enthusiasm about learning and teaching new technologies The salary range for this role is $165k-180k Diversity, Equity, and Inclusion Statement At Chartbeat we strive to create and continually grow as a company where all employees are able to be their authentic selves. We are committed to recruiting, hiring, and retaining employees from different backgrounds, viewpoints, and experiences. Our strength is our diversity and we are dedicated to continuously reflect upon, and evolve our efforts to maintain a diverse, equitable and inclusive ecosystem. Equal Opportunity Employment Statement Chartbeat is an Equal Opportunity Employer and does not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, religion, disability, national origin, protected veteran status, age, or any other status protected by applicable national, federal, state, or local law. Chartbeat's CCPA disclosure notice can be found here.",
        "url": "https://www.linkedin.com/jobs/view/3952446036"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3953941986,
        "company": "Snap Inc.",
        "title": "Software Engineer",
        "created_on": 1720637094.2128708,
        "description": "Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles. Snap Engineering teams build fun and technically sophisticated products that reach hundreds of millions of Snapchatters around the world, every day. We’re deeply committed to the well-being of everyone in our global community, which is why our values are at the root of everything we do. We move fast, with precision, and always execute with privacy at the forefront. We’re looking for a Backend Engineer - Music to join Snap Inc! What you’ll do: Design, implement, and operate our most critical and scalable services - ranging from user identity services, friend graph, and our core persistence layer Work across teams to understand product requirements, evaluate trade-offs, and deliver the solutions needed to build innovative products You evaluate, appropriately test, and debug your work, striving for high quality Advocate for and apply best practices when it comes to availability, scalability, operational excellence, and cost management Work on systems both ingesting and serving music within the Snapchat ecosystem Contribute to ranking problems across the content space with an emphasis on music Knowledge, Skills & Abilities: Experience with backend services or distributed systems Proven track record of operating highly-available systems at significant scale You can independently execute on medium sized features, taking a few weeks and multiple PRs to complete You understand the operational aspects of your system and may participate in incident or hotfix investigation and resolution Ability to collaborate and work well with others Experience in at least one of the following areas: Large-scale microservices and distributed systems Cloud computing and storage systems Infrastructure and large-scale system design Security Networking and data storage Machine learning and natural language processing tools Minimum Qualifications: BS/BA degree in a technical field such as Computer Science or equivalent years of experience 3+ years of software development experience Experience with Music Ingestion and Delivery System Experiencing working with ContentID Music Systems Experience with ranking problems especially content ranking Music copyright software compliance Preferred Qualifications: Experience with Java, Go Experience with NoSQL solutions, Memcache/Redis, Kubernetes, or Google/AWS services If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information. \"Default Together\" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week. At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success! Compensation In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future. Zone A (CA, WA, NYC): The base salary range for this position is $152,000-$228,000 annually. Zone B: The base salary range for this position is $144,000-$217,000 annually. Zone C: The base salary range for this position is $129,000-$194,000 annually. This position is eligible for equity in the form of RSUs.",
        "url": "https://www.linkedin.com/jobs/view/3953941986"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3952720912,
        "company": "Robinhood",
        "title": "Software Engineer, Credit Cards",
        "created_on": 1720637095.913496,
        "description": "Join a leading fintech company that’s democratizing finance for all. Robinhood Markets was founded on a simple idea: that our financial markets should be accessible to all. With customers at the heart of our decisions, Robinhood and its subsidiaries and affiliates are lowering barriers and providing greater access to financial information. Together, we are building products and services that help create a financial system everyone can participate in. With growth as the top priority... The business is seeking curious, growth-minded thinkers to help shape our vision, structures and systems; playing a key-role as we launch into our ambitious future. If you’re invigorated by our mission, values, and drive to change the world — we’d love to have you apply. About the team + role Robinhood’s Credit Card Product team conceptualizes, designs and builds our entire client-facing product: from mobile application to underlying core libraries. Full stack-capable and blazingly fast, Money team members are trusted with full ownership over our innovative features and drive them from design to launch. Join us, and be part of delivering Robinhood’s brand new, standalone Credit Card application. You will have exceptional peers, autonomy and ownership over product features in a dynamic and sophisticated environment, and an opportunity to deliver immediate impact to millions of potential customers as we scale. The role is located in the office location(s) listed on this job description which will align with our in-office working environment. Please connect with your recruiter for more information regarding our in-office philosophy and expectations. What You’ll Do Ship new code to production on Day 1 Build innovative core features for our world-class credit application Join an exclusive A+ team of software developers Collaborate with Designers, Product Managers and Engineering Leadership to shape and deliver our next generation credit card products Help to architect and implement core engineering systems that support our products as we prepare to scale What You Bring You have at least three years of software engineering experience You have a mix of Frontend and Backend experience, including strong experience with React and/or React Native You are a top-tier developer, passionate about both excellence and execution You love to move fast and you bring a sense of urgency to your team You have high standards and a strong work ethic - you always bring your best and expect your colleagues to do the same You take delight in bringing innovation and impact to customers You are energized by reaching for scope and defining challenging milestones for yourself You have superb product sense and excellent communication skills What We Offer Market competitive and pay equity-focused compensation structure 100% paid health insurance for employees with 90% coverage for dependents Annual lifestyle wallet for personal wellness, learning and development, and more! Lifetime maximum benefit for family forming and fertility benefits Dedicated mental health support for employees and eligible dependents Generous time away including company holidays, paid time off, sick time, parental leave, and more! Lively office environment with catered meals, fully stocked kitchens, and geo-specific commuter benefits Click here to learn more about available Benefits, which vary by region and Robinhood entity. We’re looking for more growth-minded and collaborative people to be a part of our journey in democratizing finance for all. If you’re ready to give 100% in helping us achieve our mission—we’d love to have you apply even if you feel unsure about whether you meet every single requirement in this posting. At Robinhood, we're looking for people invigorated by our mission, values, and drive to change the world, not just those who simply check off all the boxes. Robinhood embraces a diversity of backgrounds and experiences and provides equal opportunity for all applicants and employees. We are dedicated to building a company that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work (and work environment) will be for everyone. Additionally, Robinhood provides reasonable accommodations for candidates on request and respects applicants' privacy rights. Please review the specific Robinhood Privacy Policy applicable to the country where you are applying.",
        "url": "https://www.linkedin.com/jobs/view/3952720912"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Melville, NY",
        "job_id": 3945824193,
        "company": "Norgate Technology",
        "title": "DevOps Engineer",
        "created_on": 1720637097.5206778,
        "description": "Full Time Position in Melville, NY. In-person Interview Required. Hybrid Position. Local candidates are highly preferred. Candidates will need to have on prem data center experience and building out services on them. As the Lead DevOps Engineer you will be a part of a team that’s responsible for the overall architecture, building, design, monitoring and support of our cloud infrastructure. What you will bring 5+ years of experience deploying or managing mid to large scale, distributed, customer-facing, OLTP Linux environments spanning hundreds of servers 5+ years of experience designing, configuring, scaling, and supporting a 24x7x365 hosted SaaS environment Deep knowledge of modern monitoring and alerting tools and practices including Open Telemetry standards and open-source tools such as Prometheus, influx dB, Grafana, ELK, Telegraf, fluent, etc… Experience building and maintaining hybrid infrastructures and on-premise data centers 5+ years with infrastructure automation / configuration management / IaC (Infrastructure as Code) tools such as Ansible, Chef, Puppet, Bicep, Terraform 3+ years implementing and supporting modern infrastructure services such as consul, vault, Kubernetes, application load balancers and integrating these with both monolithic and service-based applications 5+ years administering Solaris, Linux & Windows platforms 3+ years supporting complex routing/switching environments including VPN and dynamic routing protocols. Experience with Oracle VM on SPARC hardware is a plus 3+ years administering enterprise block and file storage platforms 3+ years administering MySQL platform (replication experience highly desirable) & Java application s",
        "url": "https://www.linkedin.com/jobs/view/3945824193"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3818039611,
        "company": "AirPay",
        "title": "Senior Software Engineer",
        "created_on": 1720637099.2638538,
        "description": "We are looking for a prolific Senior Developer to join our team and help pioneer a new type of healthcare platform. The ideal candidate has excelled on a team, built and scaled web applications with NodeJS, VueJS, Express and MySQL or similar technologies. They must have experience working on an application that has scaled to a large number of users and be able to deliver quicker than most people think is possible. Top notch verbal and written communications skills are essential. We are a hybrid team with a mix of remote and NYC based people working very closely with customers on groundbreaking products. Expect to work with talented, motivated, intense and interesting colleagues. Compensation is competitive and includes equity. Senior Developers Role model in the organization where others desire input or follow their lead in technical matters Comes up with new ideas, sees them implemented, encourages adoption and contributions Promotes quality, leads refactoring efforts and reviews all pull requests Learns new technology, advocates for new approaches, and embraces all challenges Tasks and projects done with no surprises, nothing is left dangling Clearly takes leadership when dealing with operational issues Responsibilities Develop web applications and deploy them to AWS Write technical documentation and peer review team mates code Analyze, maintain and test applications and databases Design scalable, performant and secure solutions Discover, triage and fix programming bugs Skills Expertise with Javascript, NodeJS and related frameworks SQL database relational database design skills Performance, caching and document storage with Redis/Eliasticache CI pipelines and deployment automation AWS cloud and infrastructure as code",
        "url": "https://www.linkedin.com/jobs/view/3818039611"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3641789550,
        "company": "Saturn",
        "title": "Senior Software Engineer, Backend",
        "created_on": 1720637101.3773775,
        "description": "Saturn Technologies - Senior Software Engineer, Backend At Saturn, we're on a mission to build a community around the calendar. We're starting in high school and helping tens of thousands of users manage their time and stay better connected with friends. The majority of our users are active daily. We've raised more than $44 million in funding from General Catalyst, Insight Partners, Coatue, Jeff Bezos, Marc Benioff, and other top venture investors. Come join us if you want to drive a major impact on an energetic and ambitious team! To learn more about Saturn's products on iOS, Android, and Web, visit joinsaturn.com. Your Responsibilities Will Include: Working on a cross-functional team, utilizing your extensive knowledge and experience in building complex applications. Collaborating with Product Managers and Designers from the beginning of projects to create user-friendly experiences. Communicating and managing relationships with client engineers on iOS and Web to ensure seamless integration. Promoting a disciplined approach to development, testing, documentation, and code structure in a team setting. Leading the development and ownership of large user-facing features/epics, from design to implementation and launch. Guiding the app architecture to align with industry best practices and engineering excellence. Playing a crucial role in elevating the team's technical skills and efficiency. Being hands-on, writing automated tests, and providing thorough feedback in code reviews - no task is too small. You Should Have: 5+ years of relevant backend development experience A strong understanding of best practices for modern web apps, APIs, and microservices Strong leadership and organizational skills with the ability to mentor team-mates Experience working with and scaling relational databases such as Postgres or experience with NoSQL databases such as DynamoDB Experience with concurrency theories and implementations Nice to have: Python web development experience is a plus (FastAPI, Flask, Django, etc) Experience scaling high-growth systems and diagnosing performance bottlenecks Experience with AWS (EC2, S3, Lambda, Elastic Beanstalk, RDS, ElastiCache) Experience working with and scaling multi-container Docker in production environments Experience working with background jobs (Celery with Redis, etc) Experience working with real-time communication (websockets preferred) This position has an estimated annual salary range of $165,000 to $210,000, not including bonus, commission, and equity. This position also comes with full benefits and stock options. Actual compensation packages are based on a wide array of factors unique to each candidate, including but not limited to demonstrated skill set, years and depth of relevant experience, and some role-dependent factors. We welcome direct conversations with each candidate about compensation in all of our initial calls. Saturn celebrates and embraces having a diverse team. We are committed to building a team that represents a variety of experiences, backgrounds, and skills. We do not discriminate on the basis of race, color, religion, marital status, age, gender identity, gender expression, sexual orientation, non-disqualifying physical or mental disability, national origin, veteran status, or other applicable legally protected characteristics.",
        "url": "https://www.linkedin.com/jobs/view/3641789550"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3963466081,
        "company": "Beyond Identity",
        "title": "Software Engineer",
        "created_on": 1720637103.0140324,
        "description": "The Opportunity As a Software Engineer at Beyond Identity, you will be an integral part of building the enhanced Integrations solution for our next-generation Secure Access product, which is core to Beyond Identity's mission to protect the world's access to digital assets. It will be designed with a security-first mindset and zero shared secrets architecture. In the Integrations team, you will contribute to developing a user-friendly platform that prioritizes an expansive integration offering, continuous device security, and seamless policy management, all without compromising on security. We are a fast-paced organization solving technical challenges at an exponential scale. We have a strong company culture of committing to goals and delivering on timelines. We are looking for a Software Engineer with the highest levels of technical talent, soft skills, and desire to deeply understand our product. This position is hybrid and requires a regular presence at our New York City office a few days each week. What You Can Expect to Do: Build APIs and distributed systems that enhance our security products' value propositions to our customers. Work closely with an experienced, highly motivated team of backend, frontend, and data engineers. Communicate progress, blockers, and issues with your team regularly. Build and support contemporary cloud-native application architectures using modern concepts and the cloud technologies used therein. Code actively in Rust and Golang to create scalable and performant backend systems. Participate in systems design and align business needs with the appropriate technology. Work with design partners and product managers to implement easy-to-use workflows for our customers. What We Hope You'll Bring: 4-5 years of software development experience focused on building and supporting backend systems and frontend platforms with a focus on authentication, authorization, and security. Experience building and deploying production code written in modern programming languages, with expertise in Rust and Go. Production experience with microservices architecture, distributed system design, and cloud engineering best practices. Experience developing and maintaining software in an end-user-facing production environment. Understanding of modern CI/CD tools like Terraform, Docker, Kubernetes, and Helm. Experience working in a startup environment. Strong communication skills with the ability to articulate technical concepts to both technical and non-technical audiences. Experience with database management, design, and optimization, including relational and NoSQL databases. Perks at Beyond Identity: Unlimited PTO plus 13 Paid Company Holidays Generous Medical, Dental, and Vision Plans HRA Account - An additional $3500 (for employee only) or $6000 (for employee and dependent(s) per year to help offset some out of pocket expenses Paid Parental Leave 401K Plan Convenient Office Locations, if you prefer to go into an office - New York and Dallas Fun Company Events Competitive Salary + Equity Compensation Packages Weekly company meetings led by our CEO promoting transparency and communicating company news Beyond Identity, Inc. is committed to fair and equitable compensation practices. For Applicants in New York, NY, the salary range is $133,000 - $175,000 per year + equity + benefits. A candidate's salary is determined by various factors including, but not limited to, relevant work experience, skills, and certifications. The salary range may differ in other states. Beyond Identity Inc. is an equal opportunity employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences within our workforce. About Company Beyond Identity is revolutionizing digital access for organizations looking to improve protection against cyber attacks and deliver the highest levels of security for their workforces, customers, and developers. Its suite of passwordless, phishing-resistant, and Zero Trust Authentication solutions improves security and user experience. The platform delivers continuous risk-based authentication incorporating security telemetry from the zero trust ecosystem to ensure only valid users and secure devices gain or maintain access to critical resources. Organizations like Snowflake, Cornell University, and World Wide Technology rely on Beyond Identity's highly available cloud-native platform to thwart attacks and advance their zero trust strategies. To learn more about Beyond Identity's FIDO2 certified multi-factor authentication (MFA) solutions, visit beyondidentity.com and stay connected with us on LinkedIn, X, and YouTube.",
        "url": "https://www.linkedin.com/jobs/view/3963466081"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3971251174,
        "company": "Talan",
        "title": "Front Office Developer (VBA, Excel, Python)",
        "created_on": 1720637104.7849474,
        "description": "Talan is an international consulting group in innovation and transformation through technology. For 20 years, Talan has been advising companies and administrations. The group supports them and implements their transformation and innovation projects internationally. Present on five continents, the group achieved a turnover of 600 million euros in 2023 for more than 6,000 consultants and aims to exceed the one billion € turnover mark by 2025. The group puts innovation at the heart of its development and intervenes in areas related to the technological changes of large groups, such as Artificial Intelligence, Data Intelligence, Web3, Metaverse, Blockchain or IoT. Job Description We are seeking a talented Software Engineer to join our team and work on the Repo Trading Desk of our client in the investment banking industry. The ideal candidate will have expertise in VBA, Excel, SQL and be passionate about developing new features for trading desks. Role and responsibilities Reviewing gathered requirements. Analyzing and designing applications efficiently to ensure that customers’ needs are met respecting due dates. Modifying or creating new user interfaces in Excel as well as creating and modifying SQL queries. Troubleshooting VBA code and stored procedures Participating in the application testing process. As a member of our team, you will have the opportunity to work on cutting-edge technology and collaborate with a dynamic group of professionals dedicated to excellence. You will have the chance to contribute to developing our Finance engineering team and grow your career in a stimulating environment. Qualifications Bachelor's degree in Computer science, Engineering, Finance, or Quantitative Finance 4+ years of experience in writing Excel, VBA, and SQL code, developing and troubleshooting Ability to work independently and as a team player in fast-paced dynamic software development/support environments. Strong analytical skills for problem-solving Basic Finance knowledge Experience in working on a trading floor Knowledge of Python is a plus The salary range for this role is US$90,000 - US$140,000 Company’s Benefits At Talan, we invest in our employees' well-being and empower them with benefits, including: 💵 Competitive salary 💸401(k) retirement plan with company matching 🌴15 days of paid vacation per year at hire and up to 27 according to seniority (annual untaken vacation days are cashed out) 📴8 paid holidays + 5 sick days + 2 personal days per year ❤️‍🩹Company health, dental, and vision insurance plans + FSA 🦺Voluntary STD and LTD 🚍 Commuter/transit benefits All your information will be kept confidential according to EEO guidelines. Additional Information Excel, VBA, SQL, Python, Swaps, Bonds, Inflation, Option",
        "url": "https://www.linkedin.com/jobs/view/3971251174"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Manhattan, NY",
        "job_id": 3826772958,
        "company": "New York City Campaign Finance Board",
        "title": "SOFTWARE ENGINEER",
        "created_on": 1720637106.3008218,
        "description": "The New York City Campaign Finance Board manages New York City’s small donor democracy program and educates and engages voters via NYC Votes. The CFB has enjoyed a tremendous arc of progress over its 30-year history, and our updated flagship small donor democracy program is the centerpiece of this progress. We eliminate barriers to participation by providing access to the resources New Yorkers need to vote or run for office and amplify the voices of small donors with New York City’s small donor democracy program. We are dedicated to making New York City’s local democracy more open, transparent, and equitable. You would be working with a team that is mission-driven and committed to continuous improvement. The technology unit is responsible for custom software development, networking, technical support, and cybersecurity. The unit works to develop and maintain software systems tailored to the organization's needs, manage, and secure the organization's network infrastructure, and protect against potential cyber threats. CFB’s technology unit seeks an experienced full-stack software engineer. Under general supervision, with a broad scope for the exercise of independent initiative and judgment, this engineer is responsible for the system analysis, technical design, development, testing, enhancement, and maintenance of various applications that support the Agency’s business functions. The selected candidate will be required to perform tasks related to the development of software applications and data transformation activities for the Agency. Responsibilities include, but are not limited to: Collaborate with cross-functional teams to identify software requirements and develop solutions. Develop software solutions using the .NET framework, including C#, ASP.NET, JavaScript, SQL, etc. Design software architecture and develop technical specifications based on requirements. Analyze and improve software performance by conducting tests and debugging issues. Collaborate with QA engineers to ensure software meets quality standards and user requirements. Document software designs, code, and tests for future reference. Participate in code reviews to maintain code quality and identify areas for improvement. Stay up to date with emerging trends and technologies in software development and incorporate new practices into current projects. Proficiency in writing unit tests and using unit testing frameworks. Knowledge of performance tuning, security, and scalability. Experience with Dependency Injection frameworks (built-in .NET Core, Ninject, Unity). Experience with Microservices. Experience with NoSQL databases. Experience with Salesforce integration. Bachelor’s degree or above in Computer Science or related discipline. Essential Skills 3+ Years of hands-on C#, .net software design and development experience. 3+ years of strong demonstrable experience in service-oriented architecture, N-tier application development using Microsoft’s web technology stack (.NET, ASP.NET, C#, MVC, ADO.NET, Entity Framework, Web API, HTML/CSS/JavaScript). 3+ years of experience with the ability to build/create/maintain application databases utilizing MS SQL Server/Azure SQL, including SSIS, TSQL, stored procedures, views, and functions. 3+ years of experience in Object-Oriented Design (OOD) - should be familiar with terms like Abstraction, Encapsulation, Inheritance, and Polymorphism. Experience working with a team of engineers. Proven track record of becoming a subject matter expert in areas related to current assignments. Ability to collaborate and partner across a diverse team tapping the strength and unique skills of every team member. 2+ years of experience with Azure, AWS, GCP, or other cloud providers. Experience with Microsoft Azure DevOps CI/CD. Experience with working in an Agile environment. Tools – MS Visual Studio, SQL Server Management Studio (SSMS), Azure DevOps with Git, and cloud services in Azure. Ability to speak and write clearly and succinctly in a variety of communication settings and styles. Experience solving complex problems using logical thinking first and coding second. Additional Information New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview. As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at StudentAid.gov/PSLF. The CFB is an equal opportunity employer firmly committed to diversity. All individuals are encouraged to apply. If you anticipate needing any type of reasonable accommodation to apply for an employment opportunity, please contact access@nyccfb.info or (212) 409-1800. The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy. TO APPLY All applicants must apply through NYC Government Jobs | Explore Careers | City of New York Please search and apply to the job ID number listed above. Resume and cover letter are required for consideration. Note that only applicants under consideration will be contacted. For more information on careers with the NYC Campaign Finance Board visit our website at https://www.nyccfb.info/ to access the full listing of job opportunities and to learn more about our agency. Minimum Qualifications A baccalaureate degree from an accredited college and one year of satisfactory full-time experience in computer programming and applications, computer systems analysis and development, or a closely related area; or An associate degree from an accredited college with a major in computer science and two years of experience as described in \"1\" above; or A four-year high school diploma or its educational equivalent and four years of experience as described in \"1\" above; or Education and/or experience equivalent to \"1\", \"2\", or \"3\" above. Public Service Loan Forgiveness As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/. Residency Requirement New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview. Additional Information The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.",
        "url": "https://www.linkedin.com/jobs/view/3826772958"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961911806,
        "company": "Dexian",
        "title": "Software Engineer IV",
        "created_on": 1720637109.6337051,
        "description": "Job Title : UX Engineer Location: Hybrid, NY Pay Range: $85-$95/hr. on W2 Job Description: Overall Responsibilities: Work closely with the core team of Engineers and UXers to build high quality responsive web components. Gather requirements, write detailed documents, and escalate issues in a timely manner. Align closely with stakeholders to gather requirements, provide reasonable timelines, and updates as the project progresses. Refine architectural design to ensure high performance and cross-browser capabilities. Write clean & understandable code to ensure incorporation of all UX, engineering and functional requirements. Build a thorough understanding of an internal platform including workflows, best practices, documentation and build patterns. Mandatory Skills/Qualification/Experience: Bachelor's degree in computer science, Human Computer Interaction (HCI) or equivalent practical experience. 5 years of experience with web application development in JS/TS, HTML, CSS/SASS, and with data structures/algorithms. 1+ year of experience with software design and architecture. 3+ years of experience working with Web Services Frameworks like Firebase, GCP, and/or AWS. Familiarity with modern web development frameworks such as Angular, React, Lit, Vue and/or Svelte. Familiarity with Design Systems, such as Material UI, especially Material 3 design system Desired Skills and Experience Overall Responsibilities: * Work closely with the core team of Engineers and UXers to build high quality responsive web components. * Gather requirements, write detailed documents, and escalate issues in a timely manner. * Align closely with stakeholders to gather requirements, provide reasonable timelines, and updates as the project progresses. * Refine architectural design to ensure high performance and cross-browser capabilities. * Write clean & understandable code to ensure incorporation of all UX, engineering and functional requirements. * Build a thorough understanding of an internal platform including workflows, best practices, documentation and build patterns. ------------------------------------------------------------------------------------------ Mandatory Skills/Qualification/Experience: * Bachelor's degree in computer science, Human Computer Interaction (HCI) or equivalent practical experience. * 5 years of experience with web application development in JS/TS, HTML, CSS/SASS, and with data structures/algorithms. * 1+ year of experience with software design and architecture. * 3+ years of experience working with Web Services Frameworks like Firebase, GCP, and/or AWS. * Familiarity with modern web development frameworks such as Angular, React, Lit, Vue and/or Svelte. * Familiarity with Design Systems, such as Material UI, especially Material 3 design system Dexian is a leading provider of staffing, IT, and workforce solutions with over 12,000 employees and 70 locations worldwide. As one of the largest IT staffing companies and the 2nd largest minority-owned staffing company in the U.S., Dexian was formed in 2023 through the merger of DISYS and Signature Consultants. Combining the best elements of its core companies, Dexian's platform connects talent, technology, and organizations to produce game-changing results that help everyone achieve their ambitions and goals. Dexian's brands include Dexian DISYS, Dexian Signature Consultants, Dexian Government Solutions, Dexian Talent Development and Dexian IT Solutions. Visit https://dexian.com/ to learn more. Dexian is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.",
        "url": "https://www.linkedin.com/jobs/view/3961911806"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3964431038,
        "company": "Lightci (Light Consulting)",
        "title": "Senior Software Engineer, Full-Stack (On-site)",
        "created_on": 1720637111.2258792,
        "description": "Note: We're representing an external client in search of qualified candidates for a role within their organization. This position offers a chance to be a part of our client's team and contribute to their objectives. As our client's search partner, we facilitate the initial stages of the selection process on their behalf. Please read on for more details about this opportunity. About Our Client Our client is transforming business expense management by partnering with leading industry associations to offer customized rewards platforms. Backed by notable investors, they aim to create the premier financial operating system tailored to the unique needs of different industries. Their innovative approach ensures that businesses receive solutions specifically designed for their operational models. Deliverables Develop and maintain both front-end and back-end components using React, Node.js, and Express Architecting complex back-end systems from 0 to 1 Design, implement, and manage PostgreSQL database Implement and maintain DevOps practices for seamless integration and deployment Work with GCP and AWS to optimize cloud infrastructure for scalability and performance Collaborate with engineering team and attend daily standup meetings About you Minimum 3 years of professional experience in software development Degree in Computer Science, or Engineering from a top-tier engineering school Proficient in JavaScript, TypeScript, and Python Strong expertise in back-end development with Node.js and Express Solid understanding of front-end technologies, particularly React and Next.js Experience with PostgreSQL for database management Experience with GCP and AWS for cloud infrastructure and DevOps Professionally proficient in English Have built products end-to-end (full-stack) Nice to have Experience in FinTech — specifically credit cards Proven experience working in an elite startup environment Note: Only candidates who meet the specified criteria and qualifications will be contacted for further consideration. Thank you for your understanding.",
        "url": "https://www.linkedin.com/jobs/view/3964431038"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Burlingame, CA",
        "job_id": 3811303618,
        "company": "Meta",
        "title": "Software Engineer, Product",
        "created_on": 1720637112.909709,
        "description": "We are the teams who create all of Meta's products used by billions of people around the world. Want to build new features and improve existing products like Messenger, Video, Groups, News Feed, Search and more? Want to solve unique, large scale, highly complex technical problems? Meta is seeking experienced full-stack Software Engineers to join our product teams. You can help build products that help us connect the next billion people, create new features that have billions of interactions per day and be a part of a team that’s working to help people connect with each other around the globe. Join us! Software Engineer, Product Responsibilities: Full stack web/mobile application development with a variety of coding languages Create consumer products and features using internal programming language Hack Implement web or mobile interfaces using XHTML, CSS, and JavaScript Work closely with our PM and design teams to define feature specifications and build products leveraging frameworks such as React & React Native Work closely with operations and infrastructure to build and scale back-end services Build report interfaces and data feeds Sets direction and goals for the team regarding project impact, product quality and engineering efficiency Leads major initiatives, projects, teams, rollouts and phased-releases Helps to onboard new team members, provides mentorship and enables successful ramp up on your team's code bases Minimum Qualifications: 7+ years of programming experience in a relevant programming language 7+ years relevant experience building large-scale applications or similar experience Experience with scripting languages such as Python, Javascript or Hack Experience leading major initiatives successfully Experience leading projects and teams accordingly Experience building and shipping high quality work and achieving high reliability Experience improving quality through thoughtful code reviews, appropriate testing, proper rollout, monitoring, and proactive changes Experienced in utilizing data and analysis to explain technical problems and providing detailed feedback and solutions Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience Preferred Qualifications: Experience in programming languages such as C, C++, Java, Swift, or Kotlin About Meta: Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics. Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com. $85.10/hour to $251,000/year + bonus + equity + benefits Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about  benefits  at Meta.",
        "url": "https://www.linkedin.com/jobs/view/3811303618"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3953462948,
        "company": "Fortuna Health",
        "title": "Senior Software Engineer",
        "created_on": 1720637114.4472537,
        "description": "WHO YOU ARE As an early engineering hire at Fortuna, you'll play a huge role in shaping the direction and culture of the company. Your primary duty will be to build the product, which will mostly entail fast-paced engineering work. However, you'll wear a number of different hats as we iterate including design, marketing, operations, and customer experience. You'll join a team that's ex-Oscar Health, McKinsey, Bloomberg, Twitch, Uber, and Bain. And backed by great consumer health advisors and investors like a16z and the founders of Zocdoc, Pillpack (acq. Amazon), and Cityblock. WHAT WE'RE LOOKING FOR Product Mindset Our philosophy is that engineers should lead product. Further, we are fundamentally building a consumer product for the masses. As such, we are looking for an engineer who is more motivated by building a great consumer-first product than by deeply exploring interesting technology. Ownership There's plenty of greenfield, exploratory work to be done. We need someone to be able to take an ambiguous problem and run with it. As we gain traction with specific product ideas, we would want you to truly own the whole product, not just the code. Technical Velocity We are looking for a rockstar full-stack engineer, someone who is nimble and can move fast while maintaining a sufficiently high level of code quality so that things don't fall apart. It's important to understand best practices and technical end goals so that trade-offs can be appropriately weighed as we are building. Respectful Disagreement We believe it's crucial to be able to openly disagree with anyone on the team. We are looking for someone who doesn't shy away from conflict, but is respectful and empathetic in their approach and always open to different ideas. Humility It's important to be able to admit when you're wrong. We are looking for a low-ego teammate who is able to take failures in stride and grow from them. WHAT WE OFFER Competitive salary and equity ownership in the company Platinum health insurance plans Free lunch every day All commuter expenses covered $100/month wellness benefit Unlimited PTO WHO WE ARE Fortuna Health is redefining the consumer experience for Medicaid. We're building \"TurboTax\" for Medicaid, helping millions navigate eligibility, enrollment, and renewing coverage. Our vision is to become the digital infrastructure that powers the $900B+ ecosystem.",
        "url": "https://www.linkedin.com/jobs/view/3953462948"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Utica-Rome Area",
        "job_id": 3971551847,
        "company": "Signify Health",
        "title": "Software Engineer",
        "created_on": 1720637116.2164452,
        "description": "How will this role have an impact? We are looking for Tech Savvy individuals interested in New / emerging technologies such as MicroServices, Azure and AWS. The Software Engineer will be part of an agile development team, building and working on enterprise grade software systems leveraging .Net to build MicroServices and Angular to build world class front end experiences. The Software Engineer will provide technical expertise to projects by: Actively participating in the recommendation of and setting of the Project’s technical direction and vision Contributing at an individual level in the completion of design, development, and implementation tasks Assisting and guiding Associate Developers in the completion of project related tasks This role will report to our Software Engineer Team Lead What will you do? Maintain high standards of software quality by writing high-quality code and following established standards and best practices Ensure cross team collaboration with other Software Engineers, Business Analysts and Architects in the planning, design, development, testing, and maintenance of web- and desktop-based business applications is occurring Work with the Product Team in the refinement of user stories that are developer-ready, easy to understand, and testable Provide estimates at a User Story level and provide input to work plans Participate in peer-reviews of solution designs and related code Package and support deployment of code releases Analyze and resolve technical and application problems Assess opportunities for application and process improvement and prepare documentation of rationale to share with team members and other affected parties Provide third-level support to business users Proactively reviews the Performance and Capacity of all aspects of production: code, infrastructure, data, and message processing Develop technical documents to accurately represent application design and code Mentor junior software developers on design patterns, development best practices and DevOps trade-offs Perform unit and integration testing before launch Responsible for the security and privacy of any and all protected health information that may be accessed during normal work activities We Are Looking For Someone With Bachelor’s degree in Computer Science or a related field or equivalent work experience 3+ years of work experience in .NET framework, .Net Core, C#, TypeScript, JavaScript Experience writing and maintaining frontend client applications, Angular preferred Experience writing and maintaining RESTful web services for backend, .Net core preferred Strong database experience with both SQL and NoSQL architectures Experience with unit testing frameworks and development techniques that support writing well tested and testable code: TDD experience a strong plus Experience with version control software such as Git, TFVC, or Mercurial Working knowledge of Kubernetes configuration files and command line tools Experience with Continuous Integration Continuous Deployment (CI/CD) such as TeamCity, Octopus, GitHub Actions, or Jenkins. Azure DevOps is a plus Familiarity with messaging technologies Azure Service-Bus and Apache Kafka a plus Experience with multi-layer architecture, microservices, and Dependency Injection frameworks Familiarity with Mediator pattern, Domain Driven Design and ORMs Demonstrable understanding of service oriented architecture principles and techniques, object-oriented design principles, and database design and implementation Experience with Scrum/Agile development methodologies Experience brainstorming new ideas, building and testing prototypes, and pushing MVP applications into production Experience with Machine Learning The base salary hiring range for this position is $92,300.00 - $160,800.00. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, and benefits. In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. Eligible employees may enroll in a full range of medical, dental, and vision benefits, 401(k) retirement savings plan, and an Employee Stock Purchase Plan. We also offer education assistance, free development courses, paid time off programs, paid holidays, a CVS store discount, and discount programs with participating partners. About Us Signify Health is helping build the healthcare system we all want to experience by transforming the home into the healthcare hub. We coordinate care holistically across individuals’ clinical, social, and behavioral needs so they can enjoy more healthy days at home. By building strong connections to primary care providers and community resources, we’re able to close critical care and social gaps, as well as manage risk for individuals who need help the most. This leads to better outcomes and a better experience for everyone involved. Our high-performance networks are powered by more than 9,000 mobile doctors and nurses covering every county in the U.S., 3,500 healthcare providers and facilities in value-based arrangements, and hundreds of community-based organizations. Signify’s intelligent technology and decision-support services enable these resources to radically simplify care coordination for more than 1.5 million individuals each year while helping payers and providers more effectively implement value-based care programs. To learn more about how we’re driving outcomes and making healthcare work better, please visit us at www.signifyhealth.com. #SignifyHealth",
        "url": "https://www.linkedin.com/jobs/view/3971551847"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3971242751,
        "company": "Loom",
        "title": "Software Engineer, Integrations at Loom",
        "created_on": 1720637117.7988558,
        "description": "Overview Atlassian acquired Loom to lead in remote first, asynchronous work. With Loom's async video expertise and Atlassian's team collaboration understanding, we aim to innovate and empower customers for richer collaboration. Join us on our mission to make the impossible possible. Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company. Your future team Loom is on a mission to empower everyone at work to communicate more effectively, wherever they are. We are looking for a Software Engineer to help us build out our integrations within the Atlassian product suite, reaching millions of people inside the Loom and Atlassian products they already use. You will report to the Integration Lead. Responsibilities What You’ll Do Participate in the design and implementation of new features and systems with security, performance, and reliability in mind. Lead complex tasks and small to medium sized projects autonomously. Collaborate with product, design, data, and marketing to build features supporting the product and content strategy. Contribute to code reviews, documentation, and mentor your teammates by sharing your expertise. Qualifications Qualifications 3+ years of industry experience working as a Full Stack Engineer with JavaScript/TypeScript and supporting libraries (ex. React, Node). Experience contributing to the overall design and implementation of features and systems, involving collaboration with other engineers, product, and design. Enthusiasm for high-quality code that is documented and well-tested. Compensation At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: Zone A: $147,400 - $196,600 Zone B: $132,700 - $176,900 Zone C: $122,400 - $163,100 This role may also be eligible for benefits, bonuses, commissions, and equity. Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter. Our Perks & Benefits Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more. About Atlassian At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together. We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines. To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them. To learn more about our culture and hiring process, visit go.atlassian.com/crh .",
        "url": "https://www.linkedin.com/jobs/view/3971242751"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3959341455,
        "company": "Resource Logistics Inc.",
        "title": "System Engineer",
        "created_on": 1720637119.48492,
        "description": "ole : System Engineer Location: New York city, NY (hybrid) Hire Type: fulltime Skills Technologies - WINDOWS + VMWare, AD, Office Rubric & LINUX (good to have) Relevant certifications/degree in Computer Science, Engineering or a related subject Proven working experience in installing, configuring and troubleshooting Windows (UNIX /Linux - good to have) based environments. Solid experience in the administration and performance tuning of application stacks Cloud experience, preferably in Clienture Experience with virtualization and containerization (eg., VMware, Virtual Box) Experience with monitoring systems Experience with automation software Solid scripting skills Solid networking knowledge Responsibilities Manage and monitor all installed systems and infrastructure Install, configure, test and maintain operating systems, application software and system management tools Proactively ensure the highest levels of systems and infrastructure availability Monitor and test application performance for potential bottlenecks, identify possible solutions, and work with developers to implement those fixes Maintain security, backup, and redundancy strategies Write and maintain custom scripts to increase system efficiency and lower the human intervention time on any tasks Participate in the design of information and operational support systems Provide 2nd and 3rd level support Liaise with vendors and other IT personnel for problem resolution",
        "url": "https://www.linkedin.com/jobs/view/3959341455"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3840715379,
        "company": "Lyft",
        "title": "Staff Software Engineer, Lyft Media",
        "created_on": 1720637121.1426482,
        "description": "At Lyft, our mission is to improve people’s lives with the world’s best transportation. To accomplish this, we start with our own community by creating an open, inclusive, and diverse organization. As a software engineer at Lyft, you'll collaborate with other software engineers and cross functions like product, data science and analytics to lead and execute large projects from idea to efficient execution. We're looking for a motivated Software Engineer who is passionate about solving challenging technical problems and is excited about working in a fast-paced, innovative and cross-functional environment where they will take on some of the most interesting and impactful problems in ridesharing. For this role on Lyft Media, you will be working on one of the most profitable and fastest growing revenue centers in our company. We are the team that brings delightful ad experiences in the Lyft app and in out-of-home displays such as tablets mounted behind driver seats or on displays mounted on the top of the cars. We're looking for a motivated and results-oriented Software Engineer with experience in advertising to join our growing team! In this role, you will be responsible for guiding the architecture and design, quality and best practices for the digital ads platform. We have doubly lofty goals for 2024. You must be able to work fast and independently, and possess excellent teamwork and communication skills. The ideal candidate will also have an excitement for solving data-driven marketing problems and relevant experience in the ads space. Responsibilities: Define technical roadmap for team, identifying areas that need improvement and leading cross-team solutions Identify, architect, and build the right systems or products to improve the business Write well-crafted, well-tested, readable, maintainable code Have a good grasp and ability to explain the various trade offs made in decisions Participate in code reviews to ensure code quality and distribute knowledge Proactively participate in resolving ongoing incidents Enable collaboration across multiple teams to deliver on cross-team initiatives, while delegating ownership and uplifting those around them Share your knowledge by giving brown bags, tech talks, and evangelizing appropriate tech and engineering best practices Experience: BS/MS or equivalent in Computer Engineering, Computer Science, or related field or relevant work experience 5+ years of software engineering ad industry experience Proficiency in object-oriented programming Experience designing, debugging and running fault-tolerant, highly available, large-scale distributed systems Experience working with public cloud platforms (e.g., AWS, GCP, Microsoft Azure, etc.) Proficiency in scripting languages to use APIs to automate manual processes Experience with common CI tools (Jenkins, Buildkite, CircleCI, TeamCity), and proficiency in at least one of those tools Solid knowledge of distributed systems, relational and NoSQL databases Ability to communicate in English in writing, meeting and presentations Benefits: Great medical, dental, and vision insurance options Mental health benefits Family building benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. The expected range of pay for this position in the New York City area is $172,000 - $215,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",
        "url": "https://www.linkedin.com/jobs/view/3840715379"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3866889532,
        "company": "Candid Health",
        "title": "Senior Software Engineer",
        "created_on": 1720637124.854571,
        "description": "What You’ll Be Doing You’ll conceptualize, design, build, and maintain complex services/platforms/features and develop ownership over large swaths of our product + infrastructure. You’ll interact closely with our current + prospective customers, developing intuition around their biggest pain points and thinking of creative ways to address them. You’ll play a critical role in shaping our engineering + broader company culture and help make this the best place we’ve ever worked. Who You Are You have Bachelors of Science or Bachelors of Art in Computer Science, Computer Engineering, Math or other similar degree. You have 6+ years of experience in a Software Engineering position. Experience with the technologies we currently use is a plus, but by no means required: Python, PostgreSQL, Docker, Kubernetes, React, Typescript, Google Cloud Platform, Auth0, Terraform. You enjoy building high-quality software, but you also anchor on outcomes and have good intuition around which corners are worth cutting and which aren’t. You enjoy owning features end-to-end and are comfortable learning new tools or moving across the stack to do so. You have a customer-first and learner’s mindset, and value teaching others. You’re a clear and concise communicator; you enjoy the challenge of explaining complicated ideas in simple terms, both in-person and in writing. Pay Transparency The estimated starting annual salary range for this position is $135,000 to $230,000 USD. The listed range is a guideline from Pave data, and the actual base salary may be modified based on factors including job-related skills, experience/qualifications, interview performance, market data, etc. Total compensation for this position may also include equity, sales incentives (for sales roles), and employee benefits. Given Candid Health’s funding and size, we heavily value the potential upside from equity in our compensation package. Further note that Candid Health has minimal hierarchy and titles, but has broad ranges of experience represented within roles.",
        "url": "https://www.linkedin.com/jobs/view/3866889532"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "Yonkers, NY",
        "job_id": 3811063087,
        "company": "Steneral Consulting",
        "title": "Software Engineer-locals",
        "created_on": 1720637126.613774,
        "description": "Note: Need 10+ years of candidates Title: Software Engineer Location: Yonkers, NY Duration: Contract Creates commercial software products by utilizing the latest programming languages and technologies. Adheres to software development lifecycle and analyzes and designs, programs, debugs, and modifies software. Utilize current programming languages and technologies to develop and write computer programs for the development of commercialized products. Participate in beta testing of new tools and technologies. Modify/upgrade existing versions of software products. Develop automated unit test programs within software. Work with Business Systems Analysts or work directly with users to gather information regarding application requirements and specifications. Improve other quality of service requirements such as usability, availability and security. Work with QA Engineers to reproduce and resolve defects at the system level. Conduct technology research and share findings with peers. Adhere to software development best practices and lifecycle models such as RUP or Scrum. Convert project specifications and statements of problems and procedures into detailed software models that comply with standards. Build deployment packages to ensure the quality of installation of new applications, service packs and/or upgrades. Build scripts and use tools to automate application and database builds, deployment, unit tests and system tests in various QA environments. Skill Required / Desired Amount Of Experience Java Required C++ Required Python Required Javascript Required JSon Required Perl Required WebUI Required Interface development Required ITSM platforms such as Broadcom Service Management and ServiceNow Required",
        "url": "https://www.linkedin.com/jobs/view/3811063087"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3837053619,
        "company": "Ploomber",
        "title": "Senior Software Engineer (Backend)",
        "created_on": 1720637128.6424158,
        "description": "About Us Ploomber (YC W22) is the Heroku for AI. We are building a platform to help companies deploy and scale AI applications. From LLM-powered chatbots to geospatial analysis, our platform allows our customers (ranging from small startups to big enterprises) to rapidly ship applications without worrying about infrastructure. Our AWS bill is on fire, and our customers are demanding more features, so we’re growing our small team! We're a well-funded startup (4.5M seed round in April 2022) with several years of runway. What To Expect High-speed development cycle: we often go from idea to production on the same day We have a low meeting culture. We keep meetings to a minimum, trust our team, and let them do their work independently (but we’re always ready to help!) Customer-driven culture: we make decisions based on what our customers (and prospective customers) need. Satisfying our customers and growing our customer base is our number one priority Work with the founders on a daily basis Responsibilities Lead the design of new features in our cloud platform Maintain our cloud platform (performance optimization, bug fixes, database migrations) Communicate across the team to ensure alignment Our Stack Our backend is written in Python (FastAPI) Platform built on top of AWS (some services we use: S3, ECS, ECR, EC2) We use GitHub and deploy via a CD pipeline What We Look For 3+ years of proficiency with Python (preferred) or another high-level language 2+ years of experience contributing to the architecture and design of cloud infrastructure 2+ years of experience as a mentor, tech lead, OR leading an engineering team 1+ years of experience with DevOps technologies such as CI/CD, Docker, Git, and AWS Must be willing to go outside their area of expertise (e.g., write some frontend code, learn new technologies quickly) Must have authorization to work in the United States. We cannot sponsor work visas. Must be willing to relocate to New York City (this is a hybrid role, we expect you to go to the office 2-3 times a week)",
        "url": "https://www.linkedin.com/jobs/view/3837053619"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3575819583,
        "company": "Cherre",
        "title": "Senior Database Performance Engineer",
        "created_on": 1720637130.2891567,
        "description": "Cherre is the real estate industry's leading data management platform, powering more than $3 trillion AUM globally. Our end-to-end platform helps clients connect, transform, analyze, and act on trusted data to increase efficiencies, reduce risks, gain visibility into market trends, and make strategic moves in response to changing market conditions. Cherre's platform combines transaction and analytical data and makes it available through multiple interfaces and APIs. We need an expert who can improve query performance and contribute towards architectural decisions, taking into consideration the constraints created by the different use cases for data and the complexities introduced by Microservices, containers and container orchestration. You will Optimize the existing data platform for both performance and reliability Optimize SQL/NoSQL database queries, stored procedures, triggers, user defined functions, analytic functions, etc Read and Optimize Query Plans You have 7-10 years experience in engineering BS in CS or related field or equivalent experience Experience with both large scale transaction and analytical database technologies Experience with service oriented architecture and good understanding of distributed systems, data stores, data modeling, and indexing (especially with Event Sourcing and/or CQRS) Hands on experience with SQL and large-scale distributed storage and database systems Ability to deal with ambiguity and communicate well with both technical and non-technical teams Strong Candidates will Have Python Hasura PostgreSQL GraphQL BigQuery Kubernetes Hands on experience developing APIs and SDKs Benefits Equity Range of Healthcare Plans Paid Parental Leave Unlimited Vacation Flexible Work Schedule Compensation Range: $165,000-220,000 / year If this opportunity sounds interesting, apply or reach out to our internal talent team. We are happy to tell you more about Cherre: the technology we work with, the problems we solve, the team we are assembling, and the culture we all contribute to. We are excited you are considering working with us and look forward to hearing from you! “At the top of the mountain we are all snow leopards.” - Hunter S. Thompson Cherre is an equal opportunity employer. We pride ourselves on hiring the best people for the job no matter their race, sex, orientation, nationality, religion, disability, or age.",
        "url": "https://www.linkedin.com/jobs/view/3575819583"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3966552501,
        "company": "Nillion",
        "title": "Senior DevOps Engineer (Remote, AMER)",
        "created_on": 1720637132.0177288,
        "description": "Nillion is humanity's first Blind Computer. It is powered by a decentralized network of nodes that enables \"Blind Computation\" through the coordination and orchestration of privacy enhancing technologies (PETs) such as multi-party computation (MPC) and homomorphic encryption (HE). Nillion believes Blind Computation will become the internet's base layer for all private data as PETs continue to mature. Nillion has attracted a notable initial cohort of Blind Computation builders across AI, DeFi, medical data, custody, wallets, global identity, messaging and much more. As reported by TechCrunch, Nillion in the midst of the bear market of 2022 raised the highest valuation for a Seed Round reported in Q4-2022. The project has attracted some of the top talent in tech, including the Founder of Indiegogo (Slava Rubin), Associate General Counsel of Coinbase (Lindsay Danas Cohen), Co-Founder of Hedera Hashgraph (Andrew Masanto) and several other high profile team members. As a Senior DevOps Engineer at Nillion, you will work on internally focused cloud infrastructure and externally focused deployment kits for node operators.This role at Nillion will play a critical role in bringing to life a new security, storage and computation model for sensitive data across a decentralized publicly accessible network. Expertise across all areas of computer science will thus be needed. Requirements 7+ years of experience working as a DevOps Engineer with experience in Containerisation (Docker, AWS & Kubernetes) preferably with a focus on Distributed Systems and Decentralised Computing 5+ years experience with DevOps tooling and automated infrastructure management within Terraform, Cloud Storage and Infrastructure As Code. Experience building high-functioning production grade code to support a wide range of users for our upcoming milestones Experience Designing and implementing robust system and cloud architectures, ensuring scalability, resilience, and optimal performance. Deploy and maintain both web 2.0 and web 3.0 infrastructure in a cloud environment via Infrastructure as Code Ability to collaborate with cross-functional teams to ensure seamless deployment and integration of applications, as well as strategic DevOps initiatives that align with the product goals Participate in deployment of services with strict availability requirements on a large-scale environment and working together with other Engineers to ensure our systems meet current and future demand Nice to have: Strong experience with communicating with developers and senior technical leadership to tailor the solutions effectively Strong understanding of DevOps principles and technologies, including CI/CD, Infrastructure as Code, monitoring, and Cloud Computing Have an experience and passion for Blockchain Technology, Web3.0 or Confidential Computing Experience with high-level programming languages such as Python, Rust, Golang & node.js Experience with building large scale systems and communicating priorities with a degree of open transparency and understanding. Benefits We offer the following perks as part of employment with Nillion: Flexible working hours to accommodate lifestyles and a globally distributed team Competitive compensation package Make a big impact as an early contributor to an incredible founding team Work on new problems in an incredible emerging and dynamic field Learn from systems engineering, cryptography and product domain experts in a mentorship-oriented work culture You don't need to be in an office or at a desk to have an impact anymore! We are fully remote, but value regular meet-ups In summary, if you are interested in web3 infrastructure, innovation, new technology, and are interested in working with a high-caliber team, please apply. Nillion is committed to shaping a better world in all that they do. Our global team is built based on respect, inclusivity, diversity and excellence. For more information on either the technology or company, there are several lectures at leading universities about the project such as Oxford University, Cambridge University, New York University, Columbia, and MIT. You can also visit Nillion's early website at www.nillion.com. Apply for this job",
        "url": "https://www.linkedin.com/jobs/view/3966552501"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3943504407,
        "company": "Building Service 32BJ Benefit Funds",
        "title": "Azure Data Integration Engineer",
        "created_on": 1720637136.063922,
        "description": "About Us: Building Services 32BJ Benefit Funds (“the Funds”) is the umbrella organization responsible for administering Health, Pension, Retirement Savings, Training, and Legal Services benefits to over 100,000 SEIU 32BJ members. Our mission is to make significant contributions to the lives of our members by providing high quality benefits and services. Through our commitment, we embody five core values: F lexibility, I nitiative, R espect, S ustainability, and T eamwork ( FIRST). By following our core values, employees are open to different and new ways of doing things, take active steps to improve the organization, create an environment of trust and respect, approach their work with the intent of a positive outcome, and work collaboratively with colleagues. For 2023 and beyond, 32BJ Benefit Funds will continue to drive innovation, equity, and technology insights to further help the lives of our hard-working members and their families. We use cutting edge technology such as: M365, Dynamics 365 CRM, Dynamics 365 F&O, Azure, AWS, SQL, Snowflake, QlikView, and more. Through this technology investment, we have gathered and analyzed thousands of data insights to influence health insurance legislation and propose new health policy. Our efforts have galvanized many leaders and the consensus is there is plenty more work to be done. Please take a moment to watch our video to learn more about our culture and contributions to our members: youtu.be/hYNdMGLn19A Summary: Under the supervision of the Team Lead, Data Integration, the Azure Data Integration Engineer will be for designing, developing, implementing, and maintaining data integration solutions using Azure Data Factory, Azure Databricks, and SQL Server Integration Services. The Azure Data Integration Engineer will collaborate with cross-functional teams to understand data requirements, extract, transform data from various sources, and load it into the data warehouse for analysis, application integration, and reporting purposes. TheAzure Data Integration Engineer should have a strong background in data integration, data engineering, data analysis, and various Azure technologies with best practices. Essential Duties and Responsibilities: Design, develop, and implement data integration solutions using Azure Data Factory to meet business requirements and data ingestion needs. Collaborate with data architects, business analysts and developers to understand data requirements and ensure data pipelines are optimized for performance, scalability, and reliability. Extract, transform, and load (ETL) data from various sources, including on-premises and cloud-based systems, APIs, databases, and files. Monitor and troubleshoot data pipelines to identify and resolve issues in a timely manner to minimize disruptions in data processing for on premise and cloud environments. Implement data quality checks and validation processes to ensure accuracy and completeness of data. Work with DevOps teams to manage CI/CD pipelines for deploying and managing data integration solutions. Optimize data integration processes for performance and cost-effectiveness, making use of Azure Data Factory features and capabilities. Optimize performance for SQL query, stored procedures, and table index. Maintain documentation for data pipelines, configurations, and data flow diagrams. Collaborate with data scientists, data analysts, and other stakeholders to understand data usage patterns and provide recommendations for data optimization and improvements. Stay updated with the latest trends and best practices in data engineering, cloud computing, and Azure services to suggest innovative solutions. Develop and design database schema, SQL queries and tuning, and stored procedures. Write well designed, testable, efficient code, that adheres to security standards. Ensure designs follow specifications. Production and End User Support Activities including developing documentation and assistance tools. Perform other relevant tasks as required by management/supervisory staff. Provide support after hours, on weekends for emergency issues and production releases as required. Qualifications : To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Proven experience in designing, developing, and deploying data integration solutions using Azure Data Factory and Azure Databricks. Strong understanding of data engineering concepts, ETL principles, and data modeling. Strong experience in SQL server includes T-SQL, stored procedures, CTE, functions, SSIS and SQL agent jobs. Proficiency in Azure cloud services, including Azure Blob Storage, Azure SQL, Azure Data Lake, Azure Service Bus, and Azure Data Factory. Experience with data integration techniques for both structured and unstructured data. Solid programming skills in languages such as Python, PowerShell, and C# Experience with Rest API for data integration. Familiarity withdata governance, data catalog & profiling, data security, data encryption (RSA, PGP), and compliance in the context of cloud-based data solutions. Knowledge of Azure DevOps, Git Repos and CI/CD pipelines for code deployment is a plus. Excellent problem-solving skills and attention to detail. Strong communication and interpersonal skills to work effectively in a collaborative team environment. Knowledge inPython,PySpark/Ray framework, Prefect Workflows, and Healthcare data domain experience preferred. Familiarity with Dynamics CRM and Dynamics F&O is a plus. Interpersonal Skills: Detail oriented with excellent organization and analytical skills. Ability to plan and take initiatives to accomplish objectives in a timely fashion. Ability to prioritize work and meet deadlines. Ability to establish and maintain effective working relationships with project team members, supervisors, and employees from other departments. Education and/or Experience: Bachelor’s degree in Computer Science, or a related discipline. Language Skills: Speak, read, write and understand English. Reasoning Ability: High Certificates, Licenses, Registrations: None Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodation may be made to enable individuals to perform the essential functions. Under 1/3 of the time: Standing, Walking, Climbing or Balancing, Stooping, Kneeling, Crouching, or Crawling 1/2 to 2/3 of the time: Sitting, Reaching with Hands & Arms Over 2/3 of the time: Talking or Hearing 100% of the time: Using Hands Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. 1/3 to 2/3 of the time: Work near moving or mechanical parts, exposure to radiation, moderate noise. Salary Range: $120000.00 To 140000.00 (USD) Annually",
        "url": "https://www.linkedin.com/jobs/view/3943504407"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3958826048,
        "company": "Eventual",
        "title": "Founding Software Engineer",
        "created_on": 1720637137.6791751,
        "description": "About Eventual Eventual is an NYC-based climate finance company. We combine software, climate science and finance to make markets enabling commercial real estate investors to hedge novel climate risks. We've raised several million dollars from prominent venture funds and are now looking for our fourth team member. About our team Our team comprises talent from Yale, Princeton, Blackstone and Jane Street. We’re hiring a founding software engineer to join us in-person at our Tribeca office. Things you might work on immediately Build a full-stack, web-based financial derivatives pricing tool from the ground up Design, build and update our landing page as we exit semi-stealth Rapidly iterate a wide range of MVPs for customer demos integrating climate data (assembled by our technical co-founder) and financial algorithms (guided by our quant finance analyst) Who you are Full-stack software engineer with experience building beautiful, functional products at early-stage startups Able to complete large-scale technical tasks efficiently and independently Able to write high-quality, readable, maintainable, and testable code that will be foundational for future products and teams Experienced in building with a focus on security and financial data protection How we work Given the early stage of the business, our standards for productivity are extremely high; we work hard We spend our days at the intersection of climate / real estate / technology, so it’s important that each member of our team is deeply passionate about two or more of these topics We operate in a collaborative, positive and energetic environment despite the uncertain, high-pressure stakes that often exist at an early-stage startup Eventual is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3958826048"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3961899978,
        "company": "Metropolitan Transportation Authority",
        "title": "Associate Software Engineer",
        "created_on": 1720637139.3562472,
        "description": "Description Job Title: Associate Software Engineer Salary Range: $99,673 - $117,647 Hay Points: P3 / 393 Dept/Div: Information Technology/Corporate IT Products Location: 2 Broadway, New York, NY 10004 or other locations as required Hours of Work: 9:00 AM - 5:30 PM (7.5 work hours/day) or various as required Application Deadline: July 15, 2024 ABOUT US The MTA transportation network has very large systems and infrastructure for financial, business, automated train, transportation, power, and physical security.  MTA IT Department is centrally responsible for providing a full range of Information and Operational Technology services to the MTA agencies and administrative units through its operating and support units.  Services are provided on a 7/24/365 basis in support of the MTA organization and its ridership.      MTA IT’s Product Development group is empowered, multi-functional teams focused on the end-to-end management of development products from strategy to delivery. Using innovative processes and tools, the teams are responsible for developing and maintaining highly effective, secure, and innovative transportation, operational and back-end information systems to support MTA goals and priorities. SUMMARY This role elicits and documents requirements for small-scale software development and change initiatives. Codes, tests, and documents low-complexity software programs/scripts within a supplied design. Conducts agreed software maintenance tasks, maintains documentation, and applies procedures to identify and resolve routine software issues. RESPONSIBILTIES Demonstrates fundamental awareness of agreed models, methods, and tools for requirements management, software development, and testing.  Elicits and documents requirements for small-scale changes and assists with more complex change initiatives. Codes, tests, and documents low-complexity software programs/scripts within a supplied design. Demonstrates fundamental awareness of IT project and product frameworks, methodologies, and tools.    Completes assigned project tasks using agreed tools and process and develops simple plans for a specific aspect of a project. Capable of conducting agreed software maintenance tasks, maintains documentation, and applies procedures to identify and resolve routine software issues. Designs simple test cases, test scripts and test data, and automates repeatable tasks working to specified requirements. Executes and reports on testing activities in accordance with test plans. Creates storyboards, wireframes, and functional prototypes using agreed tools and techniques. Capable of applying established process and tools to administer, log, and report on configuration items. Audits low-complexity software systems for adherence to configuration standards. Examines software systems to verify that defined quality and safety assurance activities have been conducted. Collects evidence for formal system audits. Assists with routine communication between the organization and suppliers, and the collection of supplier performance data. Continuously develops and maintains fundamental knowledge of agreed models, methods, and tools for requirements management, software development, and testing. Travel may be required to other MTA locations or other external sites. May need to work outside of normal work hours supporting 24/7 operations (i.e., evenings and weekends). Performs other duties and tasks as assigned. Observing the work performed by the contractor. Regular and reliable attendance is expected and required. Reviewing invoices and approving them if the work had contractual standards Addressing performance issues with the contractor when possible Escalating issues to other parties as needed KNOWLEDGE, SKILLS AND ABILTIES Technical Skills: Fundamental knowledge of employing a set of rules and syntax that define how code is written, organized, and interpreted or compiled. Fundamental knowledge of executing a program or system with the intent of finding defects and ensuring that it meets the specified requirements. Fundamental programming experience with language(s), including but not limited to Ruby, Python, Java, C, C++, C#, COBOL, SQL, Net, DBA, JavaScript. Fundamental Awareness with the Oracle platform. Fundamental familiarity with the following vendor-specific platforms: including but not limited to: Azure, AWS, Windows Server platforms, RESTful APIs, or Linux). Fundamental experience administering and developing work flows and specialized UIs. Fundamental awareness of data structures and algorithms, database management. Fundamental awareness of cybersecurity, including encryption and authentication. Fundamental awareness of cloud computing. Fundamental awareness in coding software alerting & notifications. Fundamental experience resolving code defects & developing small enhancements. Fundamental awareness in continuous delivery processes, distributed monitoring & logging, distributed tracing & analysis, operation response automation, and product telemetry. Fundamental awareness in development techniques (e.g., OOO), DevOps engineering practices, DevSecOps Lifecycle (Secure SDLC), and the Agile framework. Fundamental awareness in full-stack development, mobile development, web development, site reliability engineering, technology-specific frameworks and solution design. EDUCATION AND EXPERIENCE Qualifications: Education: Bachelor’s Degree and minimum of 1 year of relevant experience. An equivalent combination of education and experience may be considered in lieu of a degree. Experience: 1 year COMPETENCIES: Core Competency  Proficiency Level  Competency Definition  Collaborates  Adept  Building partnerships and working collaboratively with others to meet shared objectives  Cultivates Innovation   Capable  Creating new and better ways for the organization to be successful  Customer Focus  Capable  Building strong customer relationships and delivering customer-centric solutions  Communicates Effectively   Capable  Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences  Tech Savvy  Fundamental Awareness  Anticipating and adopting innovations in business-building digital   and technology applications  Technical Skills  Fundamental Awareness  Specialized knowledge and expertise on tools, programs, domains, platforms, and products used for specific tasks  Values Diversity  Adept  Recognizing the value that different perspectives and cultures bring to an organization Other Information Pursuant to the New York State Public Officers Law & the MTA Code of Ethics, all employees who hold a policymaking position must file an Annual Statement of Financial Disclosure (FDS) with the NYS Commission on Ethics and Lobbying in Government (the “Commission”). Equal Employment Opportunity MTA and its subsidiary and affiliated agencies are Equal Opportunity Employers, including with respect to veteran status and individuals with disabilities.     The MTA encourages qualified applicants from diverse backgrounds, experiences, and abilities, including military service members, to apply.",
        "url": "https://www.linkedin.com/jobs/view/3961899978"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3855644868,
        "company": "K Health",
        "title": "Senior Software Engineer",
        "created_on": 1720637140.9305282,
        "description": "Who we are: K Health is venture-backed, fast-growing startup with a mission to use the power of Artificial Intelligence (AI) to get everyone access to higher quality healthcare at more affordable costs. We’re looking for mission driven individuals to join our team and help us eliminate healthcare inequalities to build a better and healthier future. Featured most recently in Forbes and Business Insider as a leading AI startup, K Health is a telehealth company that harnesses the power of technology to help provide the smartest digital healthcare platform to patients, hospital systems, and providers across the United States. Our AI powered application helps bring together the knowledge of thousands of doctors and anonymous medical data to provide the highest quality care to our patients. We offer a free symptom checker, 24/7 access to board-certified doctors, ability to refill prescriptions from your phone, and more. All within one application - no insurance or preauthorization required. K Health was founded in 2016, and has partnered with visionary and leading hospital systems and providers such as Cedars-Sinai, Mayo Clinic, and Elevance Health. Join us on our mission to help provide better healthcare for less. About the role: Join our mission as a Senior Software Engineer that will lead development and delivery of new features aimed at revolutionizing healthcare for the better. You will directly and meaningfully impact the experience of millions of people. With an engaged community of users, you'll then have opportunities to improve your work based on the feedback and data you've collected to help measure your success. We believe in constantly evolving and improving through user research, testing, iteration, and experimentation. K Health is seeking engineers who have significant experience working on highly-scalable, distributed systems, building robust services that interface with internal and external service providers, and consuming/instrumenting big data for analytics and reporting. As an experienced engineer seeking an opportunity to help shape the future of one of the world's largest digital healthcare platforms, we hope you'll consider joining K Health! What you'll be doing: Lead design and implementation of technical solutions for various initiatives, ensuring the system design meets scalability, performance, and security requirements Collaborate with product designers, product managers, and other software engineers to deliver customer facing features with high quality Work with team members to investigate design approaches, prototype technology and evaluate technical feasibility Make critical engineering decisions considering risks, trade offs, and alternative solutions Drive continuous improvement in our software and development process within an agile development team Write automated unit and integrations test as appropriate to support our continuous integration pipelines, with a focus on DevOps and robust automation Spearhead investigations, production issues and bugs Identify tech debt before it becomes an issue and work with team to prioritize it appropriately Mentor other engineers and improve engineering processes to increase team effectiveness What we're looking for: 5+ years of software engineering experience building backend systems Experience in designing and developing services with APIs that are efficient, well-tested, and easy to maintain Experience with building APIs using GraphQL and Apollo Federation Proficiency in NodeJS and Typescript, experience with modern service frameworks such as NestJS and ExpressJS Experience with modern cloud technologies such as Docker, Kubernetes, Kafka, GCP/AWS suite Knowledge of full software development life cycle best practices, including coding standards, code reviews, source control management, continuous deployments, testing and operations Strong problem solving and analytical/reasoning skills, excellent verbal and written communication skills Self-driven, ability to thrive in a fast-paced startup environment Ability to deliver with little supervision Benefits & Perks: Hybrid work schedule with weekly lunches and stocked fridges Monthly social committees for company events 20 paid vacation days, 5 sick days per year, and 10+ holidays Stock options for every full-time employee Paid parental leave 401k benefit Commuter Benefits Competitive health, dental, and vision insurance options Compensation: $175,000—$205,000 USD We offer competitive compensation packages based on industry benchmarks for function, level, and geographic location. Offer amounts are determined by multiple factors such as a candidate's experience and expertise. We are proud to be an Equal Opportunity Employer and consider applicants for employment regardless of race, ethnicity, religion, color, national origin, ancestry, disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, sexual orientation, pregnancy, childbirth and breastfeeding, age, citizenship, military or veteran status, or any other class protected by applicable federal, state, and local laws. We’re deeply committed to building teams as diverse as the patients we serve and strive to cultivate an environment where everyone can bring their most authentic self to work. We depend on our differences to make our team stronger, our workplace more dynamic, and our product accessible to all of our users. We are committed to maintaining the integrity of our hiring process and ensuring a safe environment for all candidates. All communication for job offers from K Health will come from email addresses ending in @khealth.com. K Health will never ask you to provide financial information about yourself during the recruitment process. We will never use personal email accounts or other domains for official correspondence. Our official job postings are only listed on our official website and reputable job boards. Be cautious of job offers from sources other than these platforms.",
        "url": "https://www.linkedin.com/jobs/view/3855644868"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3380626435,
        "company": "Freestar",
        "title": "Principal Data Engineer",
        "created_on": 1720637142.656799,
        "description": "Principal Engineer - Data Platform (Remote - US /Canada based W2 position) You will be owning the entire data strategy and Data Platform of Freestar that interfaces with multiple products such as Pubfig, Prebid Server and Mediation Platform. At Freestar, the Data Platform team manages real time streaming for event processing and batch processing for aggregation (roll-up) and data ingestion using google managed technologies such as PubSub, Cloud dataflow, Cloud Composer, Bigquery, etc. You will be mentoring and leading a 6-8 member team and closely working with an engineering manager to deliver the data engineering technical roadmaps and supporting data system monitoring, cost optimization and performance. Pathway to Success Take the needs and challenges of the business requirements and formulate the technical roadmap and technology solution that will support their business strategies and goals. Provide architectural recommendations, solution and approach given tradeoffs and ability to communicate that to the business. Quickly gain an understanding of the landscape of tools and data frameworks so as to recommend next steps, approach (such as real-time streaming, batch, workflows, etc.) Credentialize roadmap and architecture Enhance Data Engineering capability through coaching, mentoring and leadership Co-create and shape strategy and approach to engagements to achieve the desired business outcomes Collaborate with cross departmental team in the org to learn and share best practices and techniques Provide technical leadership in an enterprise environment to ensure delivery of exceptional technical solutions. Mentor on approach and execution of solutions, coach on technologies and establishing a team-wide comprehension of solution capabilities and direction. Ensure technical expectations of deliverables are met. Maintaining strong expertise and knowledge of current and emerging technologies and products. Qualifications * You are equally happy coding as leading a team to implement a solution! You have a track record of innovation and execution in Data Engineering You have a deep understanding of data modeling and experience with data engineering and have built large-scale data pipelines and data-centric applications using Big Data tooling platforms such as Kafka, Pub/Sub, and Cloud Dataflow, Apache Airflow, Apache Beam, Hadoop, Spark, Hive, Kinesis, Redshift, S3 and/or HDFS, BigQuery, Dataprep, Composer, etc. You have demonstrated experience designing and implementing complex data pipelines in a cloud environment such as GCP, AWS or Azure. Hands-on experience with event streaming with modern event streaming tooling like Google Dataflow, Pub/Sub, Kafka, Kinesis, Glue, etc Understanding of when streaming vs. batch processing is appropriate, and tradeoffs in a given context Hands-on experience with MPP query engines like Presto, BigQuery, and Spark SQL. You are comfortable applying data security strategy to solve business problems You are able to contrast the use of managed services vs custom built ones \"Good to Have\" experience Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Big Table, etc) Experience with schema design, dimensional data modeling and data engineering concepts. Experience with analytics stacks include Looker, Tableau, Redash, etc Experience designing, building, and maintaining data processing systems Previous background in the ad tech or media landscape (linear, digital, or social) is a plus What You Can Expect In Return Full-Time, Salaried Position Working remotely Generous Medical, Dental, and Vision benefits 401K with company match, vested immediately The opportunity to be part of something high value, high impact, and high growth...Who doesn't love that! Freestar is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.",
        "url": "https://www.linkedin.com/jobs/view/3380626435"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3852363260,
        "company": "Kavyos Consulting",
        "title": "Software Engineer",
        "created_on": 1720637144.5614793,
        "description": "Responsibilities Determines technical feasibility by evaluating requirements and analysis as well as proposed solutions Prepares and installs solutions by determining and designing system specifications, standards and programming Enhances existing solutions to match client requirements by configuring and customizing software using Actimize software, SQL and other technologies Tests and approves software solutions, configurations and customizations Provides information by collecting, analyzing, and summarizing development and service issues. Utilizes software engineering tools such as configuration management systems, build processes, and debuggers in the software development process Collaborates and adds value through participation in peer code reviews, providing comments and suggestions Provides reliable solutions to a variety of problems using sound problem solving techniques Performs technical root cause analysis and outlines corrective action for given problems Serve as a mentor to less experienced software engineers Estimate level of effort, evaluate new options of similar technology, offer suggestions to improve processes, and provide comments on some design aspects Apply a sense of urgency, commitment and focus on the right priorities in developing technical solutions in a timely fashion Review product and/or application information including manuals and brochures for technical accuracy Documents and demonstrates solutions by developing documentation, diagrams, clear code and comments Qualifications Databases: MS SQL and Oracle . Cassandra is a plus Knowledge of ETL tools is a plus Operating systems: Windows and Linux Web Technologies: HTML, XML, XSL, Javascript Web App servers: Tomcat or WebSphere Prior Actimize solution experience is a big plus Integration experience using APIs, DB, files, queues is a big plus AWS and Container experience is a plus Tableau knowledge is a plus Java is a plus Financial industries experience is a plus Excellent communication and problem solving skills Excellent written and spoken English Pro-active and Team Oriented approach",
        "url": "https://www.linkedin.com/jobs/view/3852363260"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3919494369,
        "company": "S&P Global",
        "title": "Lead Data Engineer",
        "created_on": 1720637146.3561485,
        "description": "About The Role Grade Level (for internal use): 11 The Team S&P Global Ratings’ data services group is a team of data and technology professionals who define and execute the strategic data roadmap. This team builds and manages a series of carefully curated enterprise data stores, data services, data analytics and BI products that are collectively used by global ratings business to create & publish world class credit ratings, high quality research, thought leadership and related content across more than 90 global economies. This team has broad knowledge on Ratings organization’s data domains, technology stacks, architectural patterns and applies them to foster collaboration and knowledge sharing resulting in unified strategy and innovative ways to support our business goals. The team follows a flexible hybrid working model with a mix of in-person days and virtual days. Responsibilities And Impact As a Lead Data Engineer at Ratings division, you will be responsible for Being a hands-on problem solver and developer helping to extend and manage the data platforms. Design and development of enterprise systems, specializing in data loading, data pipelines, distribution, management & integration technologies. Partnering with other engineering teams and Product owners, including stakeholders in the Ratings organization to achieve business and technology goals. Provide inputs to technical leadership for data architecture, design, implementation of new features and iterations of core products. Compensation/Benefits Information S&P Global states that the anticipated base salary range for this position is $97,497 to $195,800. Final base salary for this role will be based on the individual’s geographic location, as well as experience level, skill set, training, licenses and certifications. In addition to base compensation, this role is eligible for an annual incentive plan. This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, please click here. What We’re Looking For Basic Required Qualifications: BS or MS degree in Computer Science or Information Technology 5+ years of Information Technology experience with data/application architecture & designs, software/enterprise integration design patterns, data modeling, database technologies Experience in microservices and API design and implementation, with service-oriented architectures, SOAP and RESTful APIs Hands-on experience in developing scalable data pipeline using technologies like Kafka, Databricks, Spark and Scala applying ETL and ELT concepts. Deep Experience with three or more technologies of Java/J2EE, C#, AWS, Spark, Python, Scala, Informatica, PL/SQL, Oracle, PostgreSQL, Kafka, Informatica, MongoDB, Angular/ReactJS, Databricks, Kubernetes Experience with Continuous integration and deployment tools like Jenkins and Azure DevOps Experience working in UNIX/Linux environment including shell scripting. Additional Preferred Qualifications Quick learner who is highly motivated and willing to tackle new and established technologies while being able to work collaboratively as part of a team or independently. Experience in implementing data lake systems using cloud native technologies such as S3, Redshift, EMR, Hive, Presto, Spark. Strong understanding of cloud native architectures, design patterns and best practices. Container implementations using Docker, Kubernetes is a plus. Knowledgeable in technology and industry trends with ability to develop and present substantive technical solutions. Knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally. Quality first mindset with a strong background and experience developing products for a global audience at scale. Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners. Financial services industry experience would be a plus. Return To Work Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative, Restart, we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. About S&P Global Ratings At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions. S&P Global Ratings is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today. For more information, visit www.spglobal.com/ratings What’s In It For You? Our Purpose Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our Benefits Include Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, And Inclusion At S&P Global At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy. Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning) Job ID: 298449 Posted On: 2024-05-07 Location: New York, New York, United States",
        "url": "https://www.linkedin.com/jobs/view/3919494369"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3950543845,
        "company": "hackajob",
        "title": "Java Software Engineer",
        "created_on": 1720637148.0345037,
        "description": "hackajob has partnered with a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry. We are looking for software engineers to join our teams in New York. Role: Software Engineer -Data Location: New York, USA Work Set-up: Onsite Salary: $100K - $170K depending on experience + benefits package What You’ll Do: Develop, construct, and integrate solutions for our data platform to improve reporting capabilities. Oversee the full software development lifecycle, including hands-on coding, code reviews, testing, deployment, and documentation. Collaborate with the Product team and other stakeholders to understand and gather both business and technical requirements, design data models, and develop solutions, including API development. Who You Are and What You Have: Bachelor’s degree in Computer Science or a related STEM field. Over 5 years of experience in data modeling, relational databases, and complex SQL. More than 3 years of hands-on experience with Python and Apache Spark. At least 3 years of data warehouse experience, with a preference for Databricks. 3+ years of experience with Java Spring/API. Familiarity with basic cloud architecture and services from AWS or GCP. Bonus Points: Experience with Java in Apache Spark. Proficiency with Data Build Tool (DBT) and Semantic Modeling. Experience in developing Java microservices. Expertise in big data and data pipeline development. Background in AdTech. Experience with Looker. Full-stack experience across APIs and ETL pipelines to deliver data to clients. This is a full time role and we currently don't have C2C/C2H roles. Kindly let me know if you are interested. Please share your CV, current location and visa status and I will schedule you for a quick call to discuss this further. hackajob is a recruitment platform that will match you with relevant roles based on your preferences and in order to be matched with the roles you need to create an account with us. *This role requires you to be based in the US*",
        "url": "https://www.linkedin.com/jobs/view/3950543845"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3947096965,
        "company": "Betterment",
        "title": "Software Engineer, Backend",
        "created_on": 1720637149.824903,
        "description": "About Betterment Betterment is a leading, technology-driven financial services company that offers investing and retirement solutions for retail investors and investment advisors as well as financial wellness solutions, including a 401(k) for small and medium-sized businesses. Our team is passionate about our mission: making people’s lives better. We’re headquartered in NYC, and offer hybrid NY-based (three days/ week in-office) and select, non-NY-based remote positions. About The Role Custody is the core of the Betterment platform. On a busy day, we need to securely move millions of dollars through the Betterment system. At the same time, every transaction must flow through a complicated series of risk checks to ensure strict regulatory compliance. Every ounce of efficiency and intelligence we pour into this system translates into more value for our customers. We’re looking for engineers to help us answer some of our most difficult backend scaling, software design, and optimization questions. As a Backend Engineer on our Custody Team, you'll help balance on-time delivery of new platform features alongside system stability and scale. This role is based out of our NYC office. Below we've reflected the base salary range we would offer for this position. Actual salaries may vary depending on factors including but not limited to location, experience, and performance. The range listed is just one component of Betterment’s total compensation package for employees. New York City: $140,000 - $155,000 We offer a competitive equity package, health, dental and vision benefits, life and AD&D, short-term and long-term disability insurance, EAP, commuter and parking benefits FSA/HSA, and 401(k) with employer match as well as a flexible PTO policy. This job may also be eligible for variable compensation in the form of a company incentive bonus. For jobs based out of our NYC HQ, we require in office attendance Tuesday through Thursday, weekly. A day in the life Build innovative trading and money-movement technology that empowers people to make the most of their money so they can live better Solve “impossible” problems. Take your ideas to the next level right away. We experiment, iterate, learn, and repeat Uphold a standard of excellence in your work, continuously seeking improvement and welcoming guidance from more experienced engineers Collaborate with purpose. You’ll work in small groups with other talented thinkers and figure out how to make Betterment’s software even better Gain trust through transparency. We believe in taking the guesswork out of investing. That means a consistent experience for our customers — you’ll build the tools to make it possible Create efficiency. Our software helps customers save time and money. We maintain it through clean code, pragmatic programming, and lean engineering Contribute to an environment of open communication where engineers feel empowered to share ideas and take initiative to solve problems that achieve company objectives What We’re Looking For 3+ years professional experience in at least one object-oriented language, preferably Java 3+ years professional experience with SQL and relational databases A strong command of fundamental algorithms and data structures Demonstrated ability to contribute to complex projects and independently deliver small features in established codebases Appreciation for agility and pragmatism in software development What Being At Betterment Means For You We change lives Join a community of innovators working to transform financial outcomes for real people. Your work will make an impact, always laddering up to our mission: making people's lives better. We set audacious goals We set them for the company, our customers, and ourselves—and we won’t stop until we reach them. We don’t just show up; we give our all, then celebrate our wins. We value all perspectives When we collaborate, we're at our best. We believe diverse perspectives lead to better outcomes and strive to uphold our supportive and inclusive community. We Invest In You With A competitive suite of benefits, including: medical, dental, and vision insurance; life and AD&D insurance; STD and LTD benefits, including infertility support and World Professional Association for Transgender Health approved benefits; and generous parental leave. Flexible paid time off (and encouragement to use it!) Meaningful opportunity for community building through our 7 Employee Resource Groups Empowerment to own and lead change and affect the business Dedicated professional development opportunities Lunch from our in-house chef three days a week at our NYC headquarters What Happens Next We’ll take a few weeks to review all applications. If we’d like to spend more time with you, we’ll reach out to arrange next steps, which will include 3-4 sets of meetings with your future colleagues. In the interview process, we’ll look to learn more about your skills, experiences, capabilities, and motivators. Many of our questions will be aimed at understanding how you might operate here at Betterment. Depending on the role, we may ask you to complete a case study exercise or technical assessments, as we want to collect a robust set of data points to better inform our decisions. On average, it takes us around 3-5 weeks to make a hiring decision, depending on your availability and sense of urgency. As a best practice, we aim to interview at least 2-3 final round candidates before making a hiring decision. Please note that, as we usually receive an overwhelming number of applications for open positions, we’re unable to offer individual feedback during the interview process. We recognize that interviewing for a new role is a big deal. We appreciate you considering Betterment as the next step in your career, and our Recruiting Team is here to support and advocate for you through the interview process! Please note that Betterment is dedicated to providing accommodations to candidates upon request. If you need accommodations at any point throughout the interview process, please reach out to your recruiter. Come join us! We’re an equal opportunity employer and comply with all applicable federal, state, and local fair employment practices laws. We strictly prohibit and do not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex, gender (including gender nonconformity and status as a transgender or transsexual individual), sexual orientation, marital status, age, physical or mental disability, citizenship, past, current or prospective service in the uniformed services, predisposing genetic characteristic, domestic violence victim status, arrest records, or any other characteristic protected under applicable federal, state or local law. E-Verify Statement Betterment participates in E-Verify. We will provide the Social Security Administration, and if necessary, the Department of Homeland Security, with information from each new employee’s Form I-9 to confirm work authorization. Please note that we do not use this information to pre-screen job applicants. E-Verify Notice E-Verify Notice (Spanish) Right to Work Notice Right to Work Notice (Spanish) CPRA Language - CA Applicants ONLY We collect and store personal information for the purposes of candidate tracking (for this role and future opportunities). The information you provide in the course of completing your application will be kept for up to 24 months. We use tools provided by third-party service providers but do not share candidate information for any purpose other than for recruiting. To access the data that is collected, request deletion or to make updates to your candidate profile, please email team.hire@betterment.com .",
        "url": "https://www.linkedin.com/jobs/view/3947096965"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, United States",
        "job_id": 3945671854,
        "company": "Lattice",
        "title": "Software Engineer, HRIS Admin",
        "created_on": 1720637153.1819935,
        "description": "This is Engineering at Lattice Lattice’s Engineering team is continuously working to better both our product and our craft. We use a modern, cutting-edge tech stack and love experimenting with new technologies. We strive for maintainable, robust, and performant code. We’re highly collaborative and continuously iterative and work closely with designers and product managers. We prioritize not only great technical architecture, but also an amazing product experience. Lattice is enhancing its platform so that every organization can manage its people efficiently and strategically. The HRIS admin team is focused on building the core experience for HR administrators to leverage Lattice as an HRIS. The team’s vision is to empower HR administrators with unprecedented data configurability and highlight actionable insights for strategic decision-making. What You Will Do You’ll be responsible for building software to help companies build cultures in which their employees thrive. You’ll partner with other engineers to build and own products across a modern tech stack. Our current stack includes Typescript, React, Relay Modern, GraphQL, Node.js, PostgreSQL, and AWS. You’ll drive forward the execution of complex projects, many of which require tight cross-functional collaboration with product managers and designers as well as cross-team collaboration between engineers. You will make contributions to our engineering practices, identifying and evangelizing improvements to improve our team output. You will create and update high-quality technical documentation based on feedback from relevant stakeholders. You will focus on improving our user experience and find creative ways to reduce user pain points. What You Will Bring To The Table You are passionate about software development and have 2+ years of professional experience writing and maintaining production-level applications. You have production-level experience in TypeScript, React, GraphQL, Node.js, and are passionate about learning and using any new technologies that are required at the job. Prior experience within B2B SaaS is a plus, not a requirement. You are efficient in SQL and know how to model data and write performant queries in a relational database like PostgreSQL. You love to work on challenging projects that require coordination with multiple teams and multiple engineers. You are able to seek out the root cause when debugging software defects, and champion improvements that prevent future issues. You are always striving towards understanding the codebase inside and out. You have the ability to understand the nuances of product requirements and translate them into code. You take care to write code that your colleagues will also own, comprehend, and maintain. You are clear and concise in explaining your thought process and in enumerating the tradeoffs made in your work. The estimated annual cash salary for this role is $112,000 - $164,500. This position is also eligible for incentive stock options, subject to the terms of Lattice’s applicable plans. Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: Medical insurance; Dental insurance; Vision insurance; Life, AD&D, and Disability Insurance; Emergency Weather Support; Wellness Apps; Paid Parental Leave, Paid Time off inclusive of holidays and sick time; Commuter & Parking Accounts; Lunches in the Office; Workplace Amenities Stipend, Internet and Phone Stipend; One time WFH Office Set-Up Stipend; 401(k) retirement plan; Financial Planning; Learning & Development Budget; Sabbatical Program; and Invest in Your People Fund Note on Pay Transparency: Lattice provides an estimate of the compensation for roles that may be hired as required by state regulations. Compensation may vary based on (a) location, as Lattice factors in specific location when benchmarking compensation for most roles; (b) individual candidate skills and qualifications; and (c) individual candidate experience. Additionally, Lattice leverages current market data to determine compensation, so posted compensation figures are subject to change as new market data becomes available. The salary, other compensation, and benefits information is accurate as of the date of this posting. Lattice reserves the right to modify this information at any time, subject to applicable law. About Lattice Lattice is on a mission to build cultures where employees and their companies thrive. In an age where employees have more choices than ever before, businesses that put employees first are winning 🏅– and Lattice is building the tools to empower those people-centric companies. Lattice is a people success platform that offers performance reviews, employee engagement surveys, real-time feedback, weekly check-ins, goal setting, and career planning in a way that allows companies to focus on employee development, growth, and engagement – yielding stronger employee retention, performance, and impact to the bottom line 📈. Since launching in 2016, we have grown to over 5,000+ customers globally, including brands like Slack, Robinhood, and Gusto. Lattice is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Lattice is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation. By clicking the \"Submit Application\" button below, you consent to Lattice processing your personal information for the purpose of assessing your candidacy for this position in accordance with Lattice's Job Applicant Privacy Policy .",
        "url": "https://www.linkedin.com/jobs/view/3945671854"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3946676320,
        "company": "Cedar",
        "title": "Software Engineer II (Payments)",
        "created_on": 1720637155.0685766,
        "description": "Our healthcare system is the leading cause of personal bankruptcy in the U.S. Every year, over 50 million Americans suffer adverse financial consequences as a result of seeking care, from lower credit scores to garnished wages. The challenge is only getting worse, as high deductible health plans are the fastest growing plan design in the U.S. Cedar’s mission is to leverage data science, smart product design and personalization to make healthcare more affordable and accessible. Today, healthcare providers still engage with its consumers in a “one-size-fits-all” approach; and Cedar is excited to leverage consumer best practices to deliver a superior experience. The Role As we continue to grow our client base rapidly, we are seeking a Software Engineer II to join the Payments Platform team . The team is core to Cedar’s business to process bill pay from patients and support Cedar’s expansion with integrations with various payment processors and gateways. Besides, We build and maintain functionality, features, and workflows as part of a sprawling payments platform that supports all Cedar applications (i.e. Cedar Pay, Cedar Pre, and Operator). Responsibilities Build, test, and maintain features to enhance the payment system Collaborate with our counterparts on the product, and client success teams to solve problems, and improve patient and client experience Develop a deep understanding of payment processing life cycle, and gateway/processor integrations. What We Look For In a Candidate 2+ years of professional experience building production software, especially backend services. experience with at least one major coding language Strong computer science fundamentals - a degree in computer science, engineering, or a related field, or similar experience Compensation Range And Benefits Salary/Hourly Rate Range*: $145,000 - $161,625 This role is equity eligible This role offers a competitive benefits and wellness package Subject to location, experience, and education What do we offer to the ideal candidate? A chance to improve the U.S. healthcare system at a high-growth company! Our leading healthcare financial platform is scaling rapidly, helping millions of patients per year Unless stated otherwise, most roles have flexibility to work from home or in the office, depending on what works best for you For exempt employees: Unlimited PTO for vacation, sick and mental health days–we encourage everyone to take at least 20 days of PTO per year to ensure dedicated time to spend with loved ones, explore, rest and recharge 16 weeks paid parental leave with health benefits for all parents, plus flexible re-entry schedules for returning to work Diversity initiatives that encourage Cedarians to bring their whole selves to work, including the Cedarian Advisory Group (a cross-functional cohort focused on increasing internal inclusiveness at Cedar) and three employee resource groups: be@cedar (for BIPOC-identifying Cedarians and their allies), Pridecones (for LGBTQIA+ Cedarians and their allies) and Cedar Women+ (for female-identifying Cedarians) Competitive pay, equity (for qualifying roles) and health benefits that start on the first of the month following your start date (or on your start date if your start date coincides with the first of the month) Cedar matches 100% of your 401(k) contributions, up to 3% of your annual compensation Access to hands-on mentorship, employee and management coaching, and a team discretionary budget for learning and development resources to help you grow both professionally and personally About Us Cedar was co-founded by Florian Otto and Arel Lidow in 2016 after a negative medical billing experience inspired them to help improve our healthcare system. With a commitment to solving billing and patient experience issues, Cedar has become a leading healthcare technology company fueled by remarkable growth. Over the past several years, we’ve raised more than $350 million in funding from investors such as Andreessen Horowitz and Tiger Global, bringing Cedar’s valuation to $3.2 billion. As of December 2023, Cedar is engaging with 25 million patients on an annualized basis, and is on target to process $2.6 billion in patient payments annually. Cedar’s ambition is to serve 50-60 million Americans by 2025, about half of the U.S. population that makes medical payments annually. Cedar partners with more than 55 leading healthcare providers and payers including Highmark Inc., Allegheny Health Network, Novant Health, Allina Health and Providence.",
        "url": "https://www.linkedin.com/jobs/view/3946676320"
    },
    {
        "task_id": "5aa4a6e6b2404c0eba5ec2fee67b0a2b",
        "keyword": "Data Engineer",
        "location": "New York, NY",
        "job_id": 3933892749,
        "company": "Lyft",
        "title": "Senior Software Engineer, Developer Console",
        "created_on": 1720637159.2981753,
        "description": "At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization. Lyft’s Infrastructure engineering team is growing rapidly, and we are looking for engineers to help us scale. We are responsible for building the foundational systems that engineers rely on in order to build stable, scalable, and efficient services. We build standardized infrastructure that helps software developers move fast, while still providing them with the flexibility they need to innovate within their teams. We are looking for an engineer to create an exceptional development experience for all of Lyft that will have a multiplicative effect across Engineering, and contribute directly to Lyft’s overall stability and productivity. As an Senior Engineer on the Developer Console team in Infrastructure, you will be responsible for delivering critical, large scoped projects that will be used by all the software engineers at Lyft. You will build and simplify infrastructure management for internal engineering teams through the Clutch platform and the systems that power it and help steward features and the platform that drives Continuous Deployment and Infrastructure as Code at Lyft, working cross functionally with product team stakeholders and other infrastructure leaders to deliver on our roadmap and longer term vision for the team. Responsibilities: Build and deploy an orchestration platform powered by Atlantis, creating Lyft specific extensions and supporting tools to manage our cloud infrastructure reliably. Design, build and maintain tooling to improve efficiency and reliability of our orchestration platform, enabling our users to provision infrastructure safely. Partner with our adjacent Infrastructure engineering teams to understand their use cases, debug problems, and design and build scalable infrastructure to solve for their needs. Build and develop partnerships across the organization to provide great customer experience. Drive incident responses to conclusion by mentoring the team on operational best practice and identifying long-term systemic fixes. Develop and improve testing and automation processes in order to reduce operational burden. Work with and contribute back to open source communities (Atlantis, Terraform) to build infrastructure that scales. Participate in our teams on-call rotations, respond to incidents and support other teams mitigate customer impacting events Experience: 5+ years experience working on teams responsible for software development, automation and systems engineering You have experience orchestrating platforms at scale with Terraform and/or Atlantis. You have experience developing policy enforcement systems with Sentinel or Open Policy Agent. Bachelor’s Degree or equivalent experience in Computer Science or relevant discipline Ability to create production ready code in one or more high level languages, such as Go Lang, Python, Rust and C/C++ for in large scale distributed systems Experience operating large scale infrastructure in public cloud environments, such as AWS, Google Cloud or Microsoft Azure Benefits: Great medical, dental, and vision insurance options Mental health benefits Family building benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid The expected base pay range for this position in the New York City area is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",
        "url": "https://www.linkedin.com/jobs/view/3933892749"
    }
]