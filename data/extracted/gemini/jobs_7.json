[
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3965988095,
        "company": "Amazon",
        "title": "Senior Data Scientist, Tech Deployment Modeling",
        "created_on": 1720587035.8024738,
        "description": "Description Amazon is building the next generation software, hardware, and processes that will run the global network of fulfillment, ground, and air centers that move many millions of units of inventory, and ensure that customers get what they want when we promised. We are constantly innovating in the ways we are automating and accelerating the planning and delivery of products and packages. Not only does this involve custom hardware, robotics, supply chain optimization, machine learning, etc. but now also includes modeling, data analysis, and project management optimization in how we deploy technology into our fulfillment centers. Our team is passionate about solving the toughest industrial engineering challenges in the at scale deployment of advanced technology in Amazon’s global network. We are seeking a highly skilled and experienced Senior Data Scientist, with a strong background in Industrial Engineering to join our team. You will play a crucial role in developing advanced analytical models and solutions to drive excellence in field execution as Amazon prepares for robotic deployments at scale. You will collaborate closely with our team of engineers, data scientists, process experts, and operations personnel to identify opportunities for optimization, process improvements, and efficiency gains. You will develop and implement data-driven solutions, leveraging cutting-edge techniques in simulation and optimization. You will be a modeler and a builder, working with customers across Amazon Robotics global organization. Key job responsibilities Design and implement sophisticated analytical models, including queuing models (e.g., M/M/1, M/G/1, G/G/c) to analyze and optimize deployment operations. Lead the development of deterministic optimization models, such as linear programming (LP) and mixed-integer programming (MIP), to optimize resource allocation, scheduling, and planning Develop stock and flow models to simulate inventory management, supply chain dynamics, and resource allocation. Build network models (e.g., transportation models, assignment models, and network flow models) to optimize routing, scheduling, and resource allocation in logistics and distribution networks. Construct financial models (e.g., Monte Carlo simulations, option pricing models, and portfolio optimization models) to support decision-making in investment planning, risk management, and resource allocation. Implement and integrate developed models into existing systems and workflows to streamline processes, resource allocation, and improve operational efficiency. Leverage statistical techniques, machine learning algorithms, and optimization methods to extract insights (patterns, trends, correlations) from large, structured and unstructured datasets. Collaborate with engineering teams to validate model assumptions, calibrate models based on real-world performance, and refine models to account for dynamic industrial conditions. Participate in the ideation and development of new data science initiatives, contributing to the organization's strategic goals in optimizing industrial processes. Basic Qualifications 5+ years of data scientist or similar role involving data extraction, analysis, statistical modeling and communication experience 5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience Master's degree in a quantitative field such as statistics, mathematics, data science, business analytics, economics, finance, engineering, or computer science, or Bachelor's degree and 8+ years of professional or military experience Experience with statistical models e.g. multinomial logistic regression Experience in modeling and simulating complex systems that involve interdependencies, feedback loops, and dynamic interactions between various components. Preferred Qualifications Master's degree in econometrics, statistics, industrial engineering, operations research, optimization, data mining, analytics, or equivalent quantitative field Experience as a leader and mentor on a data science team Experience working with scientists, economists, software developers, or product managers Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon.com Services LLC Job ID: A2690225",
        "url": "https://www.linkedin.com/jobs/view/3965988095",
        "summary": "Amazon seeks a Senior Data Scientist with industrial engineering expertise to develop analytical models and solutions for optimizing robotic deployments at scale in their global fulfillment network. This role involves designing queuing models, deterministic optimization models, stock and flow models, network models, and financial models to improve efficiency, resource allocation, and operational excellence. The candidate will collaborate with engineers, data scientists, and operations personnel to implement data-driven solutions and contribute to strategic goals.",
        "industries": [
            "E-commerce",
            "Logistics",
            "Supply Chain",
            "Robotics",
            "Data Science",
            "Industrial Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Leadership",
            "Mentorship",
            "Project Management"
        ],
        "hard_skills": [
            "Queuing Models",
            "M/M/1",
            "M/G/1",
            "G/G/c",
            "Linear Programming",
            "Mixed-Integer Programming",
            "Stock and Flow Modeling",
            "Inventory Management",
            "Supply Chain Dynamics",
            "Resource Allocation",
            "Network Models",
            "Transportation Models",
            "Assignment Models",
            "Network Flow Models",
            "Routing",
            "Scheduling",
            "Financial Modeling",
            "Monte Carlo Simulations",
            "Option Pricing Models",
            "Portfolio Optimization Models",
            "Investment Planning",
            "Risk Management",
            "SQL",
            "Python",
            "R",
            "SAS",
            "Matlab",
            "Statistical Modeling",
            "Machine Learning",
            "Optimization Methods",
            "Data Analysis",
            "Data Extraction",
            "Multinomial Logistic Regression",
            "Simulation",
            "Model Calibration",
            "Ideation"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "R",
            "SAS",
            "Matlab",
            "Simulation",
            "Optimization Methods"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R",
            "SAS",
            "Matlab"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's degree",
            "fields": [
                "Statistics",
                "Mathematics",
                "Data Science",
                "Business Analytics",
                "Economics",
                "Finance",
                "Engineering",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 247600,
            "min": 143300
        },
        "benefits": [
            "Medical",
            "Financial",
            "Equity",
            "Sign-on Payments"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3931718715,
        "company": "Accenture Federal Services",
        "title": "Data Engineer/Scientist",
        "created_on": 1720587037.3560574,
        "description": "At Accenture Federal Services, nothing matters more than helping the US federal government make the nation stronger and safer and life better for people. Our 13,000+ people are united in a shared purpose to pursue the limitless potential of technology and ingenuity for clients across defense, national security, public safety, civilian, and military health organizations. Join Accenture Federal Services to do the work you love in an inclusive, collaborative, and caring community, where you can be empowered to grow, learn and thrive through hands-on experience, certifications, industry training and more. Join us to drive positive, lasting change that moves missions and the government forward! Job Description: Develop new tools, code, and services to execute data engineering activities. Responsibilities: Movement of structure and unstructured data using approved methods. Execute data ingestion activities for storing data in a local or enterprise level location. View data in its source format. Develop code to format data that supports exploration. Analyze source data formats and work with Data Scientists and partners to determine the formats and transforms that best meet mission objectives. Develop code and tools to provide one-time and on-going data formatting and transformations into enterprise or standalone data models. Implement existing ETL code and best practices/standards. Develop an ETL Code Transition Plan. Develop and deliver documentation for each project including ETL mappings, code use guide, code location and access instructions. Facilitate Code Reviews. Provide consulting services to support data transport Must have: 2 years of experience in data/business analysis, data engineering or data science Experience with Python, AWS, SQL, or APIs Bachelors degree Bonus points if: Experience with Extract, Transform and Load (ETL) tools and processes Docker/Kubernetes Hadoop/Spark NiFi ELK stack Security Clearance: Active TS/SCI with polygraph As required by local law, Accenture Federal Services provides reasonable ranges of compensation for hired roles based on labor costs in the states of California, Colorado, Hawaii, New York, Washington, and the District of Columbia . The base pay range for this position in these locations is shown below. Compensation for roles at Accenture Federal Services varies depending on a wide array of factors, including but not limited to office location, role, skill set and level of experience. Accenture Federal Services offers a wide variety of benefits. You can find more information on benefits here. We accept applications on an on-going basis and there is no fixed deadline to apply. The pay range for the states of California, Colorado, Hawaii, New York, Washington, and the District of Columbia is: $108,500—$214,300 USD What We Believe We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture Federal Services has the responsibility to create and sustain an inclusive environment. Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here Equal Employment Opportunity Statement Accenture Federal Services is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Accenture is committed to providing veteran employment opportunities to our service men and women. For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement . Requesting An Accommodation Accenture Federal Services is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture Federal Services and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired. If you are being considered for employment opportunities with Accenture Federal Services and need an accommodation for a disability or religious observance during the interview process or for the job you are interviewing for, please speak with your recruiter. Other Employment Statements Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States. Candidates who are currently employed by a client of Accenture Federal Services or an affiliated Accenture business may not be eligible for consideration. Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",
        "url": "https://www.linkedin.com/jobs/view/3931718715",
        "summary": "Accenture Federal Services seeks a Data Engineer to develop new tools, code, and services for data engineering activities. Responsibilities include data movement, ingestion, formatting, transformation, ETL code implementation, code review, and documentation. The role requires 2 years of experience with Python, AWS, SQL, and APIs. Bonus points for experience with ETL tools, Docker/Kubernetes, Hadoop/Spark, NiFi, ELK stack, and a TS/SCI security clearance.",
        "industries": [
            "Information Technology",
            "Government",
            "Defense",
            "National Security",
            "Public Safety",
            "Healthcare"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Skills",
            "Teamwork",
            "Collaboration",
            "Documentation",
            "Consulting",
            "Time Management"
        ],
        "hard_skills": [
            "Python",
            "AWS",
            "SQL",
            "APIs",
            "ETL",
            "Docker",
            "Kubernetes",
            "Hadoop",
            "Spark",
            "NiFi",
            "ELK"
        ],
        "tech_stack": [
            "Python",
            "AWS",
            "SQL",
            "APIs",
            "ETL",
            "Docker",
            "Kubernetes",
            "Hadoop",
            "Spark",
            "NiFi",
            "ELK"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": []
        },
        "salary": {
            "max": 214300,
            "min": 108500
        },
        "benefits": [
            "Health Insurance",
            "Retirement Plan",
            "Paid Time Off",
            "Life Insurance",
            "Disability Insurance",
            "Employee Assistance Program",
            "Tuition Reimbursement",
            "Professional Development"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3677451461,
        "company": "LMI",
        "title": "Data Scientist - Clearance Required",
        "created_on": 1720587038.9500177,
        "description": "Overview This position is embedded within our Data Analytics practice. Leverage your curiosity and problem-solving skills to explore, discover, and predict patterns contained within data sets for a wide range of government clients. This includes the derivation of clear narratives that help our clients understand their data and how those insights address their research questions. LMI is a consultancy dedicated to powering a future-ready, high-performing government, drawing from expertise in digital and analytic solutions, logistics, and management advisory services. We deliver integrated capabilities that incorporate emerging technologies and are tailored to customers’ unique mission needs, backed by objective research and data analysis. Founded in 1961 to help the Department of Defense resolve complex logistics management challenges, LMI continues to enable growth and transformation, enhance operational readiness and resiliency, and ensure mission success for federal civilian and defense agencies. Responsibilities Demonstrate the ability to frame and scale data problems to analyze, visualize, and find data solutions. Manipulate common data formats, including comma-delimited, text files, and JSON. Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available tools. Derive insights and analytic narratives from data and visualizations for effective storytelling and clear communication in response to client research questions. Work in a fast-paced, solutions-oriented environment focused on client deliverables, analysis, and reporting. Qualifications Active DoD Secret clearance required Bachelor’s degree in data science, mathematics, statistics, economics, computer science, engineering, or a related business or quantitative discipline Experience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn) Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js to communicate findings and relate them back to how your insights create business impact Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections At least 5–10 years of experience in the field Superior communication skills, both oral and written Preferred experience in the following areas: DoD experience preferred Data science methods related to data architecture, data munging, data and feature engineering, and predictive analytics Unstructured text and natural language processing R, Python, SAS, or MATLAB Anaconda, IBM Blue, and Oracle Big Data to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations Developing machine learning, data mining, statistical network, natural language processing, text analytics, and graph-based algorithms to analyze massive data sets Supervising algorithm implementation in on-premise and cloud-based computing environments Developing software to generate reports and visualizations that summarize data sets and provide data-driven insights Developing and implementing statistical, machine learning, and heuristic techniques to create descriptive, predictive, and prescriptive analytics as well as to develop statistical tests to make data-driven recommendations and decisions EEO Statement LMI is an Equal Opportunity Employer-all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.",
        "url": "https://www.linkedin.com/jobs/view/3677451461",
        "summary": "LMI, a consultancy focused on government solutions, seeks a Data Analyst with 5-10 years of experience.  You'll analyze data, create visualizations and dashboards, and communicate insights to government clients.  This role involves data manipulation, storytelling, and working with various tools and technologies.",
        "industries": [
            "Government",
            "Consulting",
            "Data Analytics",
            "Defense"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Storytelling",
            "Data Visualization"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Manipulation",
            "Data Visualization",
            "Data Storytelling",
            "Python",
            "Java",
            "R",
            "MATLAB",
            "Tableau",
            "Qlik",
            "Power BI",
            "RShiny",
            "Plotly",
            "D3.js",
            "SQL",
            "Data Architecture",
            "Data Munging",
            "Data and Feature Engineering",
            "Predictive Analytics",
            "Unstructured Text",
            "Natural Language Processing",
            "SAS",
            "Anaconda",
            "IBM Blue",
            "Oracle Big Data",
            "Machine Learning",
            "Data Mining",
            "Statistical Network",
            "Text Analytics",
            "Graph-based Algorithms",
            "Algorithm Implementation",
            "Cloud Computing",
            "Software Development",
            "Statistical Techniques",
            "Heuristic Techniques",
            "Descriptive Analytics",
            "Predictive Analytics",
            "Prescriptive Analytics",
            "Statistical Testing"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "R",
            "MATLAB",
            "Tableau",
            "Qlik",
            "Power BI",
            "RShiny",
            "Plotly",
            "D3.js",
            "SQL",
            "Anaconda",
            "IBM Blue",
            "Oracle Big Data"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "R",
            "MATLAB",
            "SAS"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Mathematics",
                "Statistics",
                "Economics",
                "Computer Science",
                "Engineering",
                "Business",
                "Quantitative Disciplines"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3971299219,
        "company": "Smoothstack",
        "title": "TS SCI Software Engineer - Entry Level",
        "created_on": 1720587041.9509544,
        "description": "Training & Career Opportunity for Entry Level Software Engineer ***Minimum TS SCI clearance required*** Are you looking to join an elite team of Software Developers, trained by the best, creating the products and services that transform our world for the better? The path to a successful technology career can be confusing and unclear. You bring the talent and the motivation, and Smoothstack will provide the training, mentorship, network, and access to extremely desirable roles to launch your career! Once selected and hired as a W-2 employee of Smoothstack, you will receive 12-14 weeks of paid, remote training in an Agile environment, complete with scrum masters, product owners, code reviewers, and more. Trainees will be paid a biweekly stipend (plus benefits) to train and will start at $60,000+/year while working on client projects. Successful Applicants Must: Pass a Coding Challenge Be legally authorized to work in the U.S., without employer sponsorship Be willing to relocate anywhere in the United States***** Must have minimum TS SCI clearance Qualifications: Must have hands-on coding experience, equivalent training or course work. No prior professional experience required. Excitement, eagerness, and ability to learn new technologies quickly. Benefits: Paid Training Health Insurance including Vision and Dental Matching 401K Voluntary Life Insurance Relocation Reimbursement 11 paid days off a year (Federal holidays and PTO) Industry Certifications Certification Reimbursement assistance Amazing company culture Entry Level Software Engineer Responsibilities: Development in Java, Spring Boot, Microservices, API while providing expertise in the full software development lifecycle, from concept and design to testing, designing, developing and delivering high-volume, low-latency applications for mission-critical systems. Participate in technical solution and design discussions. Perform proofs of concept and comprehensive solutions throughout the development lifecycle. Add new features while improving efficiency, reliability, and scalability to address client needs. Our internal training is designed to prepare you to get valuable hands-on field experience in simulated environments that mimic client environments. Smoothstack is 100% technology-focused. We specialize in Full Stack Java development, Cloud, DevSecOps, Networking, Cyber Security, Artificial Intelligence (AI), Business Intelligence (BI), Data Science, and Machine Learning related initiatives. Smoothstack is dedicated to removing bias in hiring and increasing representation and diversity in IT. Smoothstack is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Principles only. Recruiters please do not contact this job poster. Do NOT contact us with unsolicited services or offers.",
        "url": "https://www.linkedin.com/jobs/view/3971299219",
        "summary": "Entry-level Software Engineer role at Smoothstack, offering 12-14 weeks of paid training in Java, Spring Boot, Microservices, API development. Requires a TS SCI security clearance and relocation to any location in the US. ",
        "industries": [
            "Software Development",
            "Technology",
            "IT",
            "Cybersecurity",
            "Artificial Intelligence",
            "Business Intelligence",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem Solving",
            "Critical Thinking",
            "Adaptability",
            "Learning Agility",
            "Eagerness",
            "Motivation",
            "Time Management"
        ],
        "hard_skills": [
            "Java",
            "Spring Boot",
            "Microservices",
            "API",
            "Agile",
            "Scrum",
            "Code Review",
            "Full Stack Development",
            "Cloud",
            "DevSecOps",
            "Networking",
            "Cyber Security",
            "Artificial Intelligence",
            "Business Intelligence",
            "Data Science",
            "Machine Learning"
        ],
        "tech_stack": [
            "Java",
            "Spring Boot",
            "Microservices",
            "API",
            "Agile",
            "Scrum",
            "Cloud",
            "DevSecOps",
            "Networking",
            "Cyber Security",
            "Artificial Intelligence",
            "Business Intelligence",
            "Data Science",
            "Machine Learning"
        ],
        "programming_languages": [
            "Java"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 60000,
            "min": 60000
        },
        "benefits": [
            "Paid Training",
            "Health Insurance",
            "Vision",
            "Dental",
            "Matching 401K",
            "Voluntary Life Insurance",
            "Relocation Reimbursement",
            "Paid Time Off",
            "Industry Certifications",
            "Certification Reimbursement"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3932613079,
        "company": "Booz Allen Hamilton",
        "title": "Analytics Data Scientist, Senior",
        "created_on": 1720587043.7283874,
        "description": "Job Number: R0198563 Analytics Data Scientist, Senior The Opportunity: As an experienced data scientist, machine learning engineer, and visualization specialist, you’re excited at the prospect of unlocking the secrets held by a data set and developing informative and compelling visualizations to communicate complex information and insight. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. At Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, we need you to help find the answers in the data. In this role on our team supporting a Department of Defense (DoD) client, you’ll use your data science, machine learning, and data visualization expertise to create real-world impact. You’ll work closely with our DoD clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. You’ll develop rich visualizations to convey complex multi-dimensional information. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used. Work with us as we use data science for good. Join us. The world can’t wait. You Have: 8+ years of experience in a professional work environment 5+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining, with both structured and unstructured data sources 5+ years of experience developing complex visualizations and assessing visualization quality and information density with business intelligence tools, such as Qlik or Tableau 5+ years of experience with statistical and general-purpose programming languages for data analysis, such as R, Python, SQL, or NoSQL 3+ years of experience with natural language processing (NLP), artificial intelligence (AI), and machine learning (ML) techniques Ability to articulate workflows, processes, and technical concepts to non-technical audiences Secret clearance Bachelor’s degree Nice If You Have: Experience with visualization packages, including Plotly, Seaborn, or ggplot2 Knowledge of DoD acquisition processes or general program management concepts relating to cost and schedule Possession of excellent verbal and written communication skills TS/SCI clearance Bachelor’s degree in a technical field preferred; Master’s degree in Data Science, Computer Science, Mathematics, Statistics, or a related field a plus Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $96,600.00 to $220,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "url": "https://www.linkedin.com/jobs/view/3932613079",
        "summary": "Booz Allen Hamilton is seeking a Senior Analytics Data Scientist with 8+ years of experience in data exploration, data cleaning, analysis, visualization, and mining. The role involves using data science, machine learning, and visualization expertise to create real-world impact for DoD clients. Responsibilities include understanding client needs, analyzing data, developing algorithms, and creating compelling visualizations. The ideal candidate will have experience with statistical programming languages, NLP, AI, and ML techniques, as well as visualization packages like Plotly, Seaborn, or ggplot2.  The position requires a Secret clearance and a Bachelor's degree.",
        "industries": [
            "Defense",
            "Government",
            "Technology",
            "Analytics",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Skills",
            "Collaboration",
            "Leadership",
            "Teamwork",
            "Presentation Skills",
            "Data Storytelling"
        ],
        "hard_skills": [
            "Data Exploration",
            "Data Cleaning",
            "Data Analysis",
            "Data Visualization",
            "Data Mining",
            "Machine Learning",
            "Artificial Intelligence",
            "Natural Language Processing",
            "Statistical Programming",
            "R",
            "Python",
            "SQL",
            "NoSQL",
            "Qlik",
            "Tableau",
            "Plotly",
            "Seaborn",
            "ggplot2",
            "DoD Acquisition Processes",
            "Program Management"
        ],
        "tech_stack": [
            "Qlik",
            "Tableau",
            "Plotly",
            "Seaborn",
            "ggplot2",
            "R",
            "Python",
            "SQL",
            "NoSQL"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL",
            "NoSQL"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Mathematics",
                "Statistics",
                "Technical Fields"
            ]
        },
        "salary": {
            "max": 220000,
            "min": 96600
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Dependent Care",
            "Recognition Awards",
            "Flexible Schedules",
            "Remote Work",
            "Hybrid Work"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3923769493,
        "company": "Boeing",
        "title": "Software Engineer - Entry Level",
        "created_on": 1720587045.1534958,
        "description": "Job Description At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us. Software Engineer - Entry Level Why This is an Exciting Role: As a Software Engineer - Entry Level at Boeing Intelligence & Analytics you will be responsible for Analyzing user requirements to derive software design and performance requirements Debugging existing software and correct defects Providing recommendations for improving documentation and software development process standards Designing and code new software or modify existing software to add new features Integrating existing software into new or modified systems or operating environments Developing simple data queries for existing or proposed databases or data repositories Writing or review software and system documentation Designing or implement complex database or data repository interfaces/queries Developing or implement algorithms to meet or exceed system performance and functional standards Assisting with developing and executing test procedures for software components Develop software solutions by analyzing system performance standards, confer with users or system engineers; analyze systems flow, data usage and work processes; and investigate problem areas Modifying existing software to correct errors, to adapt to new hardware, or to improve its performance Designing, developing and modifying software systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design Designing or implement complex algorithms requiring adherence to strict timing, system resource, or interface constraints; Perform quality control on team products Implementing recommendations for improving documentation and software development process standards Conferring with system engineers and hardware engineers to derive software requirements and to obtain information on project limitations and capabilities, performance requirements and interfaces Coordinating software system installation and monitor equipment functioning to ensure operational specifications are met Recommend new technologies and processes for complex software projects Serving as the technical lead of multiple software development teams Selecting the software development process in coordination with the customer and system engineering Ensuring quality control of all developed and modified software What Makes BI&A Different: As a fully owned subsidiary of The Boeing Company, BI&A offers an optimal mix of a small company environment with exceptional opportunities supported by a large corporation. Every day, Boeing Intelligence & Analytics supports global missions by building and delivering intelligence, analytics, and cyber solutions that enable users to advance national security. From hardware and software engineering solutions to analytics that keep this nation safe, we create value that meets users’ needs. With vibrant partnerships and innovative approaches, we serve the Intelligence Community through innovation and vision. We have provided our customers with the tools needed to counter evolve global and cyber threats, and to improve wartime decision-making. Our talented employees bring software development, systems engineering, and advanced analytics expertise. We offer numerous prime contract opportunities with customers headquartered in Maryland, Virginia, and the District of Columbia, as well as subcontract opportunities that align with our areas of focus and additional opportunities nationwide through our parent company. We have current open positions on awarded programs across diverse customer sets and are anticipating upcoming contract awards with a 5-year life cycle and an additional 5 option years. Our diverse portfolio allows our employees to move to other projects and teams as they gain further proficiency in their current skill set and learn new skill sets along the way. We offer hands-on access to cutting-edge technologies and a culture of technical excellence. Experience and Qualifications: To be eligible for this demanding position, the ideal candidate should demonstrate the following experience and qualifications: Required Education and Years of Experience: Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) or an equivalent combination of technical education and experience. Required Qualifications: Active TS/SCI with Polygraph Experience with consuming and writing web services Experience assisting with development & execution of test procedures for software components Experience in ensuring software development adheres to 508 Compliance standards for accessibility Experience with generating & reviewing software/technical documentation Experience working in an Agile software development environment Experience using with Jira and Confluence Ensuring quality control of all developed and modified software Experience with the following software development skills: Git React Java Spring Boot JavaScript Node.js JQuery AngularJS/Angular 2+ MongoDB Desired Qualifications: Docker/Kubernetes HAProxy Nginx Elastic Stack Telework Availability: Hybrid model approved, up to 16-hours per week (dependent on team) Work Location: Annapolis Junction, MD Summary Pay Range: Please note that the information shown below is a general guideline only. Pay is based upon candidate experience and qualifications, as well as market and business considerations. $82,000 - $97,000 BI&A is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race,color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. Equal Employment Opportunity is the Law (PDF) Equal Opportunity Employer: We are an equal opportunity employer. We do not accept unlawful discrimination in our recruitment or employment practices on any grounds including but not limited to; race, color, ethnicity, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military and veteran status, or other characteristics covered by applicable law. We have teams in more than 65 countries, and each person plays a role in helping us become one of the world’s most innovative, diverse and inclusive companies. We are proud members of the Valuable 500  and welcome applications from candidates with disabilities. Applicants are encouraged to share with our recruitment team any accommodations required during the recruitment process. Accommodations may include but are not limited to: conducting interviews in accessible locations that accommodate mobility needs, encouraging candidates to bring and use any existing assistive technology such as screen readers and offering flexible interview formats such as virtual or phone interviews.",
        "url": "https://www.linkedin.com/jobs/view/3923769493",
        "summary": "Boeing Intelligence & Analytics (BI&A) is looking for an entry-level Software Engineer to analyze user requirements, debug software, improve documentation, design and code new features, integrate software, develop data queries, write documentation, design complex database interfaces, implement algorithms, develop and execute test procedures, and assist with software development solutions. The ideal candidate will have experience with web services, software testing, 508 compliance, documentation, Agile development, Jira and Confluence, Git, React, Java, Spring Boot, JavaScript, Node.js, JQuery, AngularJS/Angular 2+, and MongoDB.",
        "industries": [
            "Aerospace",
            "Defense",
            "Intelligence",
            "Cybersecurity",
            "Software Development",
            "Analytics"
        ],
        "soft_skills": [
            "Analytical",
            "Problem-solving",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Documentation",
            "Organization",
            "Time management",
            "Quality control",
            "Technical leadership"
        ],
        "hard_skills": [
            "Web services",
            "Software testing",
            "508 compliance",
            "Documentation",
            "Agile development",
            "Jira",
            "Confluence",
            "Git",
            "React",
            "Java",
            "Spring Boot",
            "JavaScript",
            "Node.js",
            "JQuery",
            "AngularJS",
            "Angular 2+",
            "MongoDB",
            "Docker",
            "Kubernetes",
            "HAProxy",
            "Nginx",
            "Elastic Stack"
        ],
        "tech_stack": [
            "Git",
            "React",
            "Java",
            "Spring Boot",
            "JavaScript",
            "Node.js",
            "JQuery",
            "AngularJS",
            "Angular 2+",
            "MongoDB",
            "Docker",
            "Kubernetes",
            "HAProxy",
            "Nginx",
            "Elastic Stack"
        ],
        "programming_languages": [
            "Java",
            "JavaScript",
            "React",
            "Node.js",
            "Angular",
            "JQuery"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor",
            "fields": [
                "Engineering",
                "Computer Science",
                "Mathematics",
                "Physics",
                "Chemistry"
            ]
        },
        "salary": {
            "max": 97000,
            "min": 82000
        },
        "benefits": [
            "Telework",
            "Hybrid model",
            "Equal opportunity employer"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3954419139,
        "company": "MicroStrategy",
        "title": "Software Engineer",
        "created_on": 1720587046.7061465,
        "description": "Company Description Leading Products – Innovative Ideas – Exceptional People ….MicroStrategy, A Dynamic Place to Work! At MicroStrategy, we are passionate about creating powerful, disruptive technologies that transform how companies do business. Innovative products and ultimately our success are rooted in one driving force—our people. Our casual and flexible environment encourages creativity and collaboration, so you’ll have the opportunity to initiate and contribute to challenging projects, while pursuing your interests and developing, both professionally and personally. Bring us your passion, curiosity, and fresh ideas, and be a part of technology innovation at its best! Job Description Job Duties: Write program code to develop new functionality for MicroStrategy applications for Web and Mobile Android. Produce detailed engineering designs for new features of MicroStrategy applications. Troubleshoot and write root cause analysis of defects found by both customers and internal testers. Support automated testing of all MicroStrategy applications by writing test scripts to ensure functional quality. Participate in code reviews as well as engineering design reviews. Support product documentation and technology knowledge sharing in the organization. May be assigned to various, unanticipated worksites throughout the United States. Telecommuting is an option. Some travel to MicroStrategy, Inc.’s Tysons Corner, VA office is required. Minimum Requirements: Master’s degree, or foreign equivalent, in Computer Science, Computer Information Systems, Engineering (any field) or closely related quantitative discipline, and one (1) year of experience in job offered or in any occupation in a related field. Special Skill Requirements: (1) Java (2) Kotlin (3) C/C++ (4) JavaScript (5) Shell (6) Android App Development (7) Docker and Kubernetes (8) React (9) Web Front End Technologies (HTML, CSS, SaaS) (10) Operating Systems (11) Python. Any suitable combination of education, training and experience is acceptable. MicroStrategy is an Equal Opportunity & Affirmative Action Employer. Education, experience and criminal background checks will be conducted. May be assigned to various, unanticipated worksites throughout the United States. Telecommuting is an option. Some travel to MicroStrategy, Inc.’s Tysons Corner, VA office is required. Submit a resume with references using the apply button on this posting or by email to: Req.# 22-128059 at onlinejobpostings@microstrategy.com. MicroStrategy is an Equal Opportunity & Affirmative Action Employer. Education, experience and criminal background checks will be conducted. Additional Information MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at application_accommodations@microstrategy.com. MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at application_accommodations@microstrategy.com.",
        "url": "https://www.linkedin.com/jobs/view/3954419139",
        "summary": "MicroStrategy is seeking a Software Engineer to develop and maintain web and mobile applications for their business intelligence platform. The role involves writing code in various languages (Java, Kotlin, C/C++, JavaScript, etc.), designing new features, troubleshooting defects, and participating in code reviews. The ideal candidate will have a Master's degree in a related field and 1 year of experience in software development.",
        "industries": [
            "Software Development",
            "Business Intelligence",
            "Analytics"
        ],
        "soft_skills": [
            "Problem Solving",
            "Troubleshooting",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Analytical Skills"
        ],
        "hard_skills": [
            "Java",
            "Kotlin",
            "C/C++",
            "JavaScript",
            "Shell",
            "Android App Development",
            "Docker",
            "Kubernetes",
            "React",
            "HTML",
            "CSS",
            "SaaS",
            "Operating Systems",
            "Python"
        ],
        "tech_stack": [
            "Java",
            "Kotlin",
            "C/C++",
            "JavaScript",
            "Shell",
            "Android App Development",
            "Docker",
            "Kubernetes",
            "React",
            "HTML",
            "CSS",
            "SaaS",
            "Python"
        ],
        "programming_languages": [
            "Java",
            "Kotlin",
            "C/C++",
            "JavaScript",
            "Shell",
            "Python"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Computer Information Systems",
                "Engineering",
                "Quantitative Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3958440330,
        "company": "CACI International Inc",
        "title": "Junior Software Developer (Agile)",
        "created_on": 1720587048.282076,
        "description": "Job Category: Information Technology Time Type: Full time Minimum Clearance Required to Start: Secret Employee Type: Regular Percentage of Travel Required: Up to 25% Type of Travel: Local * * * What You’ll Get to Do Ready for the next step in your career for some real-world business and technical experience with one of Fortune’s World’s Most Admired Company ? Consider joining our team as a .NET Software Developer supporting financial management applications that help our Department of Defense customers plan and budget resources to support our country. We continue to develop and implement exciting and complex solutions to support the evolving needs of our customers. We are looking for a self-starter with the desire to be a critical member of our growing team in an Agile Scrum environment. We value team members who strive to produce high quality work through collaboration with the team while making a difference through individual contributions to ensure project success for our team and our clients. As a .NET Software Developer you will get to work on all aspects of the application, including writing SQL and altering the data model, developing state of the art .NET code in the mid-tier, and implementing complex and modern solutions utilizing the latest JavaScript libraries in the presentation tier. You will work closely with a team of dedicated developers and business systems analysts to implement the most accurate and high-quality solutions possible. Additionally, you will learn to troubleshoot production issues and may be asked to interact with users remotely during periods of peak system use. The team works in a remote setting that will require you to communicate effectively, focus and self-motivate. You must be able to work collaboratively with our team and remain flexible and adaptable to changing priorities and deadlines in a fast-paced environment. This position is a great opportunity for an up-and-coming developer who enjoys interacting with people and has a desire to take on greater technical knowledge and responsibility. Your contributions will directly impact the success of the customers' mission, our team, and ultimately CACI. In return, CACI will provide you with a company that fosters a culture based on integrity, strong ethics, quality work, and professionalism. More About This Role As a Junior developer, you will be responsible for estimating effort, code/development, and testing of application solutions within an object-oriented environment. Assignments involve knowledge of .NET 4.5/5.0, MVC 4, LINQ, Entity Framework, C#.NET, Telerik/Kendo, T-SQL, HTML, JavaScript and CSS, or other equivalent technologies. Following the software development life cycle for each development task. Following the Agile Scrum methodology by brainstorming the technical approach, developing code, and unit testing according to the development schedule and team processes. Assisting leads and management in researching and learning new technologies that improve current systems and provide vision for future technology and infrastructure. Continuously self-improving and staying current with cutting-edge technologies to modernize existing applications' functionality, performance, and UI. Help team in preparing technical documentation or requirements when needed. Work closely with the functional team to determine feasibility of requirements and collaborate on design ideas and improvements. Participates in sprints, backlog grooming, estimation, and other Agile Scrum ceremonies. Your Will Bring These Qualifications Bachelor's degree or equivalent and 1 year of work or educational experience. Familiarity with Agile software development methodology, processes, and techniques. Ability to communicate effectively and collaboratively in a team environment. Familiarity with Git and/or other source control technologies. Familiarity with at least one object-oriented language. Ability to learn at a fast pace and be able to rapidly learn and leverage third-party tools, SDKs, and APIs. U.S. Citizen eligible to obtain a clearance. Must have the ability to work on computer for long periods, and communicate with individuals by telephone, email and face to face. Limited travel to the Pentagon may be necessary These Qualifications Will Be Nice To Have Experience with simple Database Administration techniques a plus. Understanding of designing, developing, and deploying software in a cloud environment (AWS is a plus). Demonstrated experience creating/maintaining unit tests. Knowledge of interface design and user experience. Experience working with React. Experience working with Postgres. What We Can Offer You We’ve been named a Best Place to Work by the Washington Post. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive benefits and learning and development opportunities. We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities. For over 60 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success. _____________________________________________________________________________ What You Can Expect A culture of integrity. At CACI, we place character and innovation at the center of everything we do. As a valued team member, you’ll be part of a high-performing group dedicated to our customer’s missions and driven by a higher purpose – to ensure the safety of our nation. An environment of trust. CACI takes pride in fostering a diverse and accessible culture where every individual feels supported to chart their own path. You’ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality. A focus on continuous growth. Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground — in your career and in our legacy. Your potential is limitless. So is ours. Learn more about CACI here. _____________________________________________________________________________ Pay Range : There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here. Since this position can be worked in more than one location, the range shown is the national average for the position. The Proposed Salary Range For This Position Is $48,300-$96,600 CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic.",
        "url": "https://www.linkedin.com/jobs/view/3958440330",
        "summary": "CACI is looking for a .NET Software Developer to support financial management applications for the Department of Defense. The role involves developing and implementing solutions in an Agile Scrum environment, working on all aspects of the application, and collaborating with a team of developers and business systems analysts. The ideal candidate will have experience with .NET 4.5/5.0, MVC 4, LINQ, Entity Framework, C#.NET, Telerik/Kendo, T-SQL, HTML, JavaScript, and CSS. The position requires strong communication, collaboration, and problem-solving skills.",
        "industries": [
            "Information Technology",
            "Defense",
            "Government",
            "Software Development",
            "Financial Management"
        ],
        "soft_skills": [
            "Self-starter",
            "Teamwork",
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Flexibility",
            "Adaptability",
            "Time Management",
            "Organization",
            "Detail-oriented"
        ],
        "hard_skills": [
            ".NET",
            "MVC",
            "LINQ",
            "Entity Framework",
            "C#",
            "Telerik/Kendo",
            "T-SQL",
            "HTML",
            "JavaScript",
            "CSS",
            "Agile",
            "Scrum",
            "Git",
            "Database Administration",
            "AWS",
            "Unit Testing",
            "React",
            "Postgres"
        ],
        "tech_stack": [
            ".NET",
            "MVC",
            "LINQ",
            "Entity Framework",
            "C#",
            "Telerik/Kendo",
            "T-SQL",
            "HTML",
            "JavaScript",
            "CSS",
            "Agile",
            "Scrum",
            "Git",
            "AWS",
            "React",
            "Postgres"
        ],
        "programming_languages": [
            ".NET",
            "C#",
            "JavaScript",
            "SQL"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Information Technology",
                "Software Engineering",
                "Related Field"
            ]
        },
        "salary": {
            "max": 96600,
            "min": 48300
        },
        "benefits": [
            "Flexible Time Off",
            "Competitive Compensation",
            "Healthcare",
            "Wellness",
            "Financial",
            "Retirement",
            "Family Support",
            "Continuing Education",
            "Time Off"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Northern Virginia, VA",
        "job_id": 3937903863,
        "company": "Acuity, Inc.",
        "title": "Machine Learning Ops Engineer",
        "created_on": 1720587049.254983,
        "description": "Overview Acuity is growing and looking to hire a Machine Learning ( ML) Ops Engineer to support one of our premier federal clients.  Acuity, Inc. seeks a dynamic, self-motivated individual with experience, knowledge and technical skills. In return, Acuity Inc offers a great company culture with wonderful work/life balance and a robust compensation package which includes Health/Dental/Vision, up to $6K training & professional development benefit annually, 401K matching, corporate events/team-building and more! Acuity was awarded \"Best Places to Work\" by the Washington Business Journal for over 8 years(2010 - 2014, 2015, 2017-2021, 2023) and \"Top Workplaces\" by Washington Post (2022, 2023). www.myacuity.com Responsibilities What you 'll be doing: You 'll support a mission office with infrastructure and related services for a data / ML environment. Your duties will include implementation of infrastructure as code with CI/CD and UI components, automation of deployments of new and updated elements of the data pipeline, performance monitoring, auto-scaling, support for integration of new tools and capabilities, disaster recovery and CoOP planning, documentation, and INFOSEC processes. Elements of the environment are to be increasingly containerized and deployed on GPUs. Qualifications Required Skills: 5 years of experience and bachelor's degree or 10 years of experience. Experience with advanced Python programming for data science and analytics. Experience with Linux and Bash. Experience with Docker & use of command line interface to orchestrate containerization. Experience creating unit tests, documentation, and participating in code reviews. Experience with ML models. Experience with developing CI/CD workflows across multiple environments. Experience with management of non-person entities in multiple environments. Desired Skills Experience with ELK stack, AWS, and Nvidia Triton. Experience with OAuth 2.0 open standard protocol. Experience with at least some of: NLP, computer vision, times series, cyber / network analysis. Ability to obtain Nutanix certification or Kubernetes certification within 3 months of start. Clearance Requirements TS/SCI w/Poly About Acuity Inc Acuity is a leading management and technology consulting firm that specializes in serving the federal government. Our innovative, collaborative and rewarding work environment has earned repeat honors from the Washington Business Journal’s Best Places to Work and SmartCEO Corporate Culture awards. We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law.",
        "url": "https://www.linkedin.com/jobs/view/3937903863",
        "summary": "Acuity Inc. seeks a Machine Learning (ML) Ops Engineer to support a federal client. The role involves building and maintaining a data/ML environment with infrastructure as code, CI/CD, automation, performance monitoring, auto-scaling, integration of new tools, disaster recovery, documentation, and INFOSEC processes. The environment is increasingly containerized and deployed on GPUs.",
        "industries": [
            "Management Consulting",
            "Technology Consulting",
            "Federal Government"
        ],
        "soft_skills": [
            "Self-motivated",
            "Dynamic"
        ],
        "hard_skills": [
            "Python",
            "Linux",
            "Bash",
            "Docker",
            "CI/CD",
            "Unit Testing",
            "Documentation",
            "Code Reviews",
            "ML Models",
            "ELK Stack",
            "AWS",
            "Nvidia Triton",
            "OAuth 2.0",
            "NLP",
            "Computer Vision",
            "Time Series",
            "Cyber/Network Analysis",
            "Kubernetes",
            "Nutanix"
        ],
        "tech_stack": [
            "Python",
            "Linux",
            "Bash",
            "Docker",
            "CI/CD",
            "ELK Stack",
            "AWS",
            "Nvidia Triton",
            "Kubernetes",
            "Nutanix"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health/Dental/Vision",
            "Training & Professional Development Benefit",
            "401K Matching",
            "Corporate Events/Team-building"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3948894004,
        "company": "Battelle",
        "title": "Language -Enabled Data Scientist III",
        "created_on": 1720587050.694276,
        "description": "Battelle delivers when others can’t. We conduct research and development, manage national laboratories, design and manufacture products and deliver critical services for our clients—whether they are a multi-national corporation, a small start-up or a government agency. We recognize and appreciate the value and contributions of individuals with diverse backgrounds and experiences and welcome all qualified individuals to apply. Job Summary Battelle’s Cyber Solutions Division (CSD) is seeking mid-leve l Data-focused Linguist to work in our Columbus, Ohio offices . The position reports to the Division Manager of Cyber Solutions. CSD is responsible for ideating, developing, and deploying advanced technical solutions to solve the most challenging national security problems. This position is contingent upon award . “From Silicon to Systems” – Battelle cyber is an elite, multi-disciplinary team, bringing together the brightest minds from physics, computer science, electrical engineering, data science, and mathematics to develop unique cyber solutions for government and commercial customers. Battelle has been trusted by elite government clients to solve some of the world’s hardest cyber problems. We work in small agile teams to push the bounds of computing technology. Our high-powered labs include specialized software and hardware, so our engineers have everything they need to invent new cyber solutions. We especially want people with national security experience, an enthusiasm for learning and problem solving, and who can implement technical solutions with direct application to client S&T mission areas. Battelle Cyber Online GitHub: https://github.com/Battelle Battelle Cyber Challenge: https://battellecyberchallenge.org/ Battelle Cyber: https://www.youtube.com/watch?v=XqMuKsqH9wc Battelle Cyber Solutions Division: Cyber Solutions | Battelle Solution Responsibilities As a Language-Enabled Data Scientist III, you will collaborate with other linguists, data scientists, engineers, and technical subject matter experts to collect, translate, and analyze science and technology (S&T) information. You will be responsible for foreign language translation and analysis of advanced S&T data involving complex and esoteric materials. Your timely insights on evolving S&T issues will support execution of client missions. We welcome your unique knowledge in data exploitation, technical translation, open-source techniques, and cultural knowledge. This includes suggestions to develop and improve cyber and data science tools. Language translation and science and technology assessments. Collecting, organizing, and analyzing foreign language information from multiple sources to author reports and quick-turn tasks. Technical proficiency applying foreign language to S&T mission areas. Using data science tools, where appropriate. Working in a multi-disciplinary environment while working independently and leading tasks on time and on budget. Providing thorough and completed products that require minor revisions and/or editing. Proactively managing expectations and meeting deadlines in a fast-moving, agile environment. Maintaining excellent communication and interaction with both co-located and geographically diverse team members. Key Qualifications Level II in Defense Language Proficiency Test (DLPT) or equivalent American Council on the Teaching of Foreign Languages (ACTFL) level for the following languages: Arabic, Chinese, French, Korean, Persian Farsi, Russian, Spanish. Experience may be substituted for DLPT or ACTFL level with verification of language proficiency. Experience with collecting, assembling, interpreting, translating, and analyzing open-source data, such as scientific publications, social media, and databases, and synthesizing knowledge into actionable intelligence. Experience with assessing and technical reporting on technologies and scientific topics, (i.e., technology readiness levels (TRL) and critical technology elements (CTE), etc.). Experience with diverse media and advanced S&T data. BS and (52) years of relevant experience; MS and (21) years of relevant experience; PhD in relevant field or an equivalent combination of education/experience in a relevant field. Must be a US citizen with an active TS/SCI. Excitement about learning new technical subject areas and curiosity about S&T missions. Experience in national security, defense, and/or intelligence communities. Preferred Qualifications Master’s Degree in the above areas in political science, data science, foreign language, international relations, or similar. Five years of experience as a linguist, technical expert, intelligence analyst, or equivalent to fulfill the job requirements. Expertise in data science and/or in manipulating and analyzing large/diverse data (e.g., exploratory analysis, model fitting, and visualization). Experience creating, interfacing with, or optimizing databases (e.g., SQL, PostgreSQL, NoSQL). Strong course work or experience demonstrating algorithmic programming and data visualization skills. Programming experience (e.g., Python, R). Experience applying supervised and unsupervised machine learning techniques against real world problems. Support on client sites. Full scope polygraph. SOME OF THE EXTRAS THAT MAKE WORKING HERE GREAT Learn (tuition assistance, paid training) and teach (get published, speak at a conference) Software and Intellectual Property development royalty sharing Mentorship and learning culture Internally funded and guided research projects with large amounts of individual autonomy WORK ENVIRONMENT Battelle has been trusted by elite government clients to solve some of the world’s hardest security problems. We work in small agile teams to push the bounds of computing technology. Our high-powered labs include specialized software and hardware, so our engineers have everything they need to invent new Cyber solutions. Team members can work flexible hours, and Battelle maintains a 9/80 schedule meaning employees have a chance to take every other Friday off depending on client needs. We encourage new ideas with our large Independent Research and Development (IRAD) program where engineers work on projects they are passionate about. Inventors and innovators are rewarded by our industry-leading IP compensation program. Our group works collaboratively with many parts of Battelle’s larger organization on projects ranging from genomics to robotics. Benefits: Live an Extraordinary Life We care about your well-being, not just on the job. Battelle offers comprehensive and competitive benefits to help you live your best life. Balance life through a compressed work schedule: Most of our team follows a flexible, compressed work schedule that allows for every other Friday off—giving you a dedicated day to accomplish things in your personal life without using vacation time. Take time to recharge: You get paid time off to support work-life balance and keep motivated. Prioritize wellness: Stay healthy with medical, dental, and vision coverage with wellness incentives and benefits plus a variety of optional supplemental benefits. Better together: Coverage for partners, gender-affirming care and health support, and family formation support. Build your financial future: Build financial stability with an industry-leading 401(k) retirement savings plan. For most employees, we put in 5 percent whether you contribute or not, and match your contributions on top of that. Advance your education: Tuition assistance is available to pursue higher education. Flexible work arrangements: You have options for where you work and when you work. A Work Environment Where You Succeed For brilliant minds in science, technology, engineering and business operations, Battelle is the place to do the greatest good by solving humanity’s most pressing challenges and creating a safer, healthier and more secure world. You will have the opportunity to thrive in a culture that inspires you to: Apply your talent to challenging and meaningful projects Receive select funding to pursue ideas in scientific and technological discovery Collaborate with world-class experts in an inclusive environment Nurture and develop the next generation of scientific leaders Give back to and improve our communities Vaccinations & Safety Protocols Battelle may require employees, based on job duties, work location, and/or its clients’ requirements to follow certain safety protocols and to be vaccinated against a variety of viruses, bacteria, and diseases as a condition of employment and continued employment and to provide documentation that they are fully vaccinated. If applicable, Battelle will provide reasonable accommodations based on a qualified disability or medical condition through the Americans with Disabilities Act or the Rehabilitation Act or for a sincerely held religious belief under Title VII of the Civil Rights Act of 1964 (and related state laws). Battelle is an equal opportunity employer. We provide employment and opportunities for advancement, compensation, training, and growth according to individual merit, without regard to race, color, religion, sex (including pregnancy), national origin, sexual orientation, gender identity or expression, marital status, age, genetic information, disability, veteran-status veteran or military status, or any other characteristic protected under applicable Federal, state, or local law. Our goal is for each staff member to have the opportunity to grow to the limits of their abilities and to achieve personal and organizational objectives. We will support positive programs for equal treatment of all staff and full utilization of all qualified employees at all levels within Battelle. The above statements are intended to describe the nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, activities and skills required of staff members. No statement herein is intended to imply any authorities to commit Battelle unless special written permission is granted by Battelle's Legal Department. For more information about our other openings, please visit www.battelle.org/careers",
        "url": "https://www.linkedin.com/jobs/view/3948894004",
        "summary": "Battelle's Cyber Solutions Division (CSD) is seeking a Data-focused Linguist to work in their Columbus, Ohio offices. The position reports to the Division Manager of Cyber Solutions and is responsible for collecting, translating, and analyzing science and technology (S&T) information in foreign languages. The successful candidate will have a Level II Defense Language Proficiency Test (DLPT) or equivalent, experience with open-source data analysis, and a strong technical background in science and technology. They will also possess data science skills, experience working in a multi-disciplinary environment, and excellent communication skills.",
        "industries": [
            "National Security",
            "Cybersecurity",
            "Data Science",
            "Intelligence",
            "Defense",
            "Research and Development",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Time Management",
            "Leadership",
            "Analytical Thinking",
            "Attention to Detail",
            "Teamwork",
            "Independent Work",
            "Proactive",
            "Flexibility",
            "Adaptability",
            "Enthusiasm",
            "Curiosity"
        ],
        "hard_skills": [
            "Data Analysis",
            "Translation",
            "Open-Source Intelligence",
            "Scientific Publications",
            "Social Media",
            "Databases",
            "Technology Readiness Levels (TRL)",
            "Critical Technology Elements (CTE)",
            "Data Science Tools",
            "Data Exploitation",
            "Technical Reporting",
            "Algorithmic Programming",
            "Data Visualization",
            "Machine Learning",
            "Python",
            "R",
            "SQL",
            "PostgreSQL",
            "NoSQL"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "PostgreSQL",
            "NoSQL"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Political Science",
                "Data Science",
                "Foreign Language",
                "International Relations"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Tuition Assistance",
            "Paid Training",
            "Software and Intellectual Property Development Royalty Sharing",
            "Mentorship",
            "Internally Funded Research Projects",
            "Flexible Work Schedule",
            "Paid Time Off",
            "Medical, Dental, and Vision Coverage",
            "Wellness Incentives",
            "Supplemental Benefits",
            "Partner Coverage",
            "Gender-Affirming Care",
            "Family Formation Support",
            "401(k) Retirement Savings Plan",
            "Tuition Assistance",
            "Flexible Work Arrangements"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3939727078,
        "company": "GeoYeti, a division of Bcore",
        "title": "Mid Geospatial Data Scientist",
        "created_on": 1720587052.135068,
        "description": "GeoYeti focuses on advanced analytics, data science, development of the applications that support such work. We seek a mid-level Geospatial Data Scientist to support a client in Reston, VA . We support a broad range of IC and DoD clients, though a common theme across our portfolio is that our team members, regardless of their role, interact with the end users around the globe. GeoYeti offers competitive pay, a sign-on or relo bonus, and amazing benefits, to include up to 10 percent company contribution into your 401k; 100 percent company paid premiums for medical (to include 100 percent of your medical deductible), dental, vision, life, and short- and long-term disabilities; tuition reimbursement; gym stipend; commuter stipend ($10/day after tax); automatic enrollment in the GeoYeti 360 Bonus Program; and many others. Assist senior data scientist with model evaluations and with the evaluation of ML model effectiveness. Minimum Top Secret clearance required to start; active TS/SCI preferred Proficiency with Python, including understanding for storage formats and methodologies for ML models. Ideally a proficiency with spatial data formats and processing libraries in Python. GeoYeti is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. GeoYeti does not have a vaccination mandate applicable to team members. Vaccination requirements will depend on the status of the federal contractor mandate and customer site requirements. Regardless of vaccination status , personnel are required to wear masks while indoors when the CDC COVID-19 Community Level is High.",
        "url": "https://www.linkedin.com/jobs/view/3939727078",
        "summary": "GeoYeti is seeking a mid-level Geospatial Data Scientist to assist senior data scientists with model evaluations and ML model effectiveness assessments. The role requires proficiency in Python, including understanding of storage formats and methodologies for ML models, and ideally proficiency with spatial data formats and processing libraries in Python. Minimum Top Secret clearance is required, with active TS/SCI preferred. ",
        "industries": [
            "Data Science",
            "Analytics",
            "Geospatial",
            "Defense",
            "Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking"
        ],
        "hard_skills": [
            "Python",
            "ML Model Evaluation",
            "Spatial Data Formats",
            "Spatial Data Processing Libraries",
            "Data Storage Formats",
            "Model Effectiveness Evaluation"
        ],
        "tech_stack": [
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Pay",
            "Sign-On Bonus",
            "Relocation Bonus",
            "401k with Company Contribution",
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Life Insurance",
            "Short-Term Disability",
            "Long-Term Disability",
            "Tuition Reimbursement",
            "Gym Stipend",
            "Commuter Stipend",
            "Bonus Program"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3910566846,
        "company": "ClearanceJobs",
        "title": "Junior Data Scientist with Security Clearance",
        "created_on": 1720587057.6596134,
        "description": "Overview At LMI, we're reimagining the path from insight to outcome at The New Speed of Possible™. Combining a legacy of over 60 years of federal expertise with our innovation ecosystem, we minimize time to value and accelerate mission success. We energize the brightest minds with emerging technologies to inspire creative solutioning and push the boundaries of capability. LMI advances the pace of progress, enabling our customers to thrive while adapting to evolving mission needs. Responsibilities Frame and scale data problems to analyze, visualize, and find data solutions. Manipulate common data formats, including comma-delimited, text files, and JSON. Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available visualization and dashboard tools. Derive insights and analytic narratives from data and visualizations for effective storytelling and clear communication in response to research questions. Work in a fast-paced, solutions-oriented environment focused on client deliverables, analysis, and reporting. Qualifications Pursuit of a bachelor's degree in data science, mathematics, statistics, economics, computer science, engineering, or a related business or quantitative discipline Experience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn) Experience creating meaningful data visualizations and interactive dashboards such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js to communicate findings and relate them back to how your insights create business impact Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections Preferred experience with data science methods related to data architecture, data munging, data and feature engineering, and predictive analytics; additional preferred qualifications include working with unstructured text and natural language processing Superior communication skills, both oral and written Applicants for this position may be subject to a government security investigation and must meet eligibility requirements for access to classified information. Please note that only US citizens are eligible to obtain security clearances.",
        "url": "https://www.linkedin.com/jobs/view/3910566846",
        "summary": "LMI seeks a data scientist to analyze, visualize, and find data solutions. Responsibilities include data manipulation, visualization, and creating informative dashboards using open-source and commercial tools. The ideal candidate will have experience with Python, Java, R, MATLAB, scikit-learn, Tableau, Qlik, Power BI, RShiny, plotly, d3.js, SQL, and data science methods like data architecture, data munging, data and feature engineering, and predictive analytics. Excellent communication skills are essential.",
        "industries": [
            "Data Science",
            "Analytics",
            "Consulting",
            "Technology",
            "Federal Government"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Storytelling",
            "Data Visualization",
            "Collaboration",
            "Time Management",
            "Client Focus"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "R",
            "MATLAB",
            "scikit-learn",
            "Tableau",
            "Qlik",
            "Power BI",
            "RShiny",
            "plotly",
            "d3.js",
            "SQL",
            "Data Architecture",
            "Data Munging",
            "Data Engineering",
            "Feature Engineering",
            "Predictive Analytics",
            "Natural Language Processing",
            "Data Visualization",
            "Dashboard Development"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "R",
            "MATLAB",
            "scikit-learn",
            "Tableau",
            "Qlik",
            "Power BI",
            "RShiny",
            "plotly",
            "d3.js",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "R",
            "MATLAB"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Mathematics",
                "Statistics",
                "Economics",
                "Computer Science",
                "Engineering",
                "Business",
                "Quantitative Disciplines"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3919090819,
        "company": "ManTech",
        "title": "Data Scientist - Cloud",
        "created_on": 1720587059.3020747,
        "description": "Secure our Nation, Ignite your Future Join the top Information Technology and Analytic professionals in the industry to make invaluable contributions to our national security on a daily basis. In this innovative, self-contained, Big Data environment, the ManTech team is responsible for everything from infrastructure, to application development, to data science, to advanced analytics and beyond. The team is diverse, the questions are thought-provoking, and the opportunities for growth and advancement are numerous. The successful candidate will possess a diverse range of data-focused skills and experience, both technical and analytical. They will have a strong desire and capability for problem solving, data analysis and troubleshooting, analytical thinking, and experimentation, with a particular interest or aptitude in the Cloud arena. Duties, Tasks & Responsibilities Working with large, complex, and disparate data sets Designing and implementing innovative ways to analyze and exploit the Sponsor’s data holdings, particularly Cloud-related data holdings Researching and reporting on a wide variety of Sponsor inquiries Raising proactive inquiries to the Sponsor based on observations and proposed data analysis/exploitation Solving difficult, non-routine problems by applying advanced analytical methodologies, and improving analytic methodologies Developing custom searches Communicating and coordinating with internal and external partners as needed Required Experience, Skills, & Technologies Thorough knowledge of appropriate analytic tools and methodologies in one or more of the following: Applied mathematics (e.g. probability and statistics, formal modeling, computational social sciences) Computer programming (e.g. programming languages, math/statistics packages, computer science, machine learning, scientific computing) Ability to code or script in one or more general programming language 7+ years experience with, and understanding of, algorithms for classification, regression, clustering, and anomaly detection Knowledge of relational databases, including SQL and large-scale distributed systems (e.g. Hadoop) 7+ years hands on experience/expertise with statistical data analysis (e.g. linear models, multivariate analysis, stochastic models, sampling methods) Demonstrated effectiveness in collecting information and accurately representing/visualizing it to non-technical third parties High School Diploma or GED Security Clearance Required TS SCI with Polygraph Desired Experience, Skills & Technologies Understanding of, and/or hands-on experience with, Cloud technologies, such as AWS, Microsoft Azure, etc. Experience working in a mission environment and/or with many different types of data Physical Requirements Use hands to operate a computer and other office productivity machinery, such as a calculator, copy machine and computer printer. The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, etc. Must be able to remain in a stationary position 50% of the time Constantly positions self to maintain computers in the lab, including under the desks and in the server closet , #joinmantechd #joinmantechaa For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.",
        "url": "https://www.linkedin.com/jobs/view/3919090819",
        "summary": "ManTech seeks a data analyst with strong technical and analytical skills to contribute to national security initiatives. The role involves working with large, complex datasets, designing and implementing data analysis methods, researching and reporting on inquiries, and developing custom searches. The ideal candidate will possess expertise in applied mathematics, computer programming, and statistical data analysis, along with hands-on experience with Cloud technologies.",
        "industries": [
            "National Security",
            "Defense",
            "Intelligence",
            "Data Analytics",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Problem Solving",
            "Data Analysis",
            "Troubleshooting",
            "Analytical Thinking",
            "Experimentation",
            "Communication",
            "Coordination"
        ],
        "hard_skills": [
            "Applied Mathematics",
            "Probability and Statistics",
            "Formal Modeling",
            "Computational Social Sciences",
            "Computer Programming",
            "Programming Languages",
            "Math/Statistics Packages",
            "Computer Science",
            "Machine Learning",
            "Scientific Computing",
            "Classification",
            "Regression",
            "Clustering",
            "Anomaly Detection",
            "SQL",
            "Hadoop",
            "Statistical Data Analysis",
            "Linear Models",
            "Multivariate Analysis",
            "Stochastic Models",
            "Sampling Methods",
            "Information Collection",
            "Data Visualization"
        ],
        "tech_stack": [
            "AWS",
            "Microsoft Azure",
            "Hadoop",
            "SQL"
        ],
        "programming_languages": [],
        "experience": 7,
        "education": {
            "min_degree": "High School Diploma or GED",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3954416476,
        "company": "MicroStrategy",
        "title": "Software Engineer",
        "created_on": 1720587060.725262,
        "description": "Company Description Leading Products – Innovative Ideas – Exceptional People ….MicroStrategy, A Dynamic Place to Work! At MicroStrategy, we are passionate about creating powerful, disruptive technologies that transform how companies do business. Innovative products and ultimately our success are rooted in one driving force—our people. Our casual and flexible environment encourages creativity and collaboration, so you’ll have the opportunity to initiate and contribute to challenging projects, while pursuing your interests and developing, both professionally and personally. Bring us your passion, curiosity, and fresh ideas, and be a part of technology innovation at its best! Job Description Job Duties: Utilize Cloud Platform knowledge to build solutions and automate the backend process to reduce the overall time and increase efficiency for customers environments on MicroStrategy cloud platform. Lead the design, architect and implement enterprise level application and features for multi-tier highly available and scalable solutions by ensuring quality, robustness, and performance of the product with common principles, patterns, and best practices. Proactively participate in every aspect of the entire software development lifecycle of cloud feature development, including input on requirement specifications, designs, implementation, test design, test implementation, optimization, and delivery. Identify and drive opportunities for improving the MicroStrategy Cloud platform service and infrastructure maintenance/management and develop the proof of concept for the feasibility of new feature for the customers. Collaborate with and support engineers and cross-functional teams globally across three main sites in the United States, Poland and China for troubleshooting quick resolutions for high-level and escalated customer issues. Design Software Design documents and deliver guideline documents to promote code re-use and effective usage of cloud solutions. Participate in peer code reviews, knowledge sharing, and SCRUM meetings and learn a broad array of new technologies, make enhancements and improvements to software products and development processes. Leverage my coding/scripting skills in python and YAML to effectively initiate the enterprise level cloud environment creation on MicroStrategy Cloud offering. May be assigned to various, unanticipated worksites throughout the United States. Telecommuting is an option. Some travel to MicroStrategy, Inc.’s Tysons Corner, VA office is required. Minimum Requirements: Master’s degree, or foreign equivalent, in Computer Science, Information Management, Engineering, or closely related quantitative discipline and one (1) year of experience in the job offered or in any occupation in a related field. Special Skill Requirements: (1) AWS; (2) Azure; (3) GCP; (4) Kubernetes; (5) Coding; (6) Scripting; (7) Code Review; and (8) Software Development Lifecyle. Any suitable combination of education, training and experience is acceptable. MicroStrategy is an Equal Opportunity & Affirmative Action Employer. Education, experience, and criminal background checks will be conducted. May be assigned to various, unanticipated worksites throughout the United States. Telecommuting is an option. Some travel to MicroStrategy, Inc.’s Tysons Corner, VA office is required. Submit a resume with references using the apply button on this posting or by email to: Req.# 20-1106 at onlinejobpostings@microstrategy.com. MicroStrategy is an Equal Opportunity & Affirmative Action Employer. Education, experience and criminal background checks will be conducted. Additional Information MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at application_accommodations@microstrategy.com. MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at application_accommodations@microstrategy.com.",
        "url": "https://www.linkedin.com/jobs/view/3954416476",
        "summary": "MicroStrategy is seeking a Cloud Platform Engineer to build solutions and automate backend processes for customers on the MicroStrategy cloud platform. The ideal candidate will have experience with AWS, Azure, GCP, Kubernetes, and coding/scripting in Python and YAML. They will be responsible for designing, architecting, and implementing enterprise-level applications and features for multi-tier, highly available and scalable solutions. The role also involves participating in the software development lifecycle, collaborating with cross-functional teams globally, and contributing to the improvement of the MicroStrategy Cloud platform.",
        "industries": [
            "Technology",
            "Software",
            "Cloud Computing",
            "Data Analytics",
            "Business Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Skills",
            "Teamwork",
            "Time Management",
            "Organization",
            "Leadership",
            "Proactive",
            "Attention to Detail",
            "Critical Thinking",
            "Decision Making"
        ],
        "hard_skills": [
            "AWS",
            "Azure",
            "GCP",
            "Kubernetes",
            "Python",
            "YAML",
            "Code Review",
            "Software Development Lifecycle"
        ],
        "tech_stack": [
            "AWS",
            "Azure",
            "GCP",
            "Kubernetes",
            "Python",
            "YAML"
        ],
        "programming_languages": [
            "Python",
            "YAML"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Computer Science",
                "Information Management",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3953811239,
        "company": "Motion Recruitment",
        "title": "Applied Machine Learning Scientist / NLP / Remote",
        "created_on": 1720587062.5736609,
        "description": "Job Description: Our client is an iconic American newspaper renowned for its comprehensive news coverage, investigative journalism, and political reporting. Based in Washington, D.C., it has played a pivotal role in major historical events and continues today to influence public discourse with its digital-first approach and commitment to high-quality journalism. As a Staff Applied Machine Learning Scientist, you will develop innovative solutions to enhance the future of journalism. This team drives AI initiatives to create intelligent, personalized news experiences and business solutions for the world's leading digital media platform. This role combines scientific research, statistical analysis, and software development. The role is remote with preference to candidates based out of the local DMV area. Responsibilities: - Identify data science projects that add value for site visitors, the newsroom, and the advertising team. Present findings to technical communities locally and at various research and business conferences. Communicate complex information with internal and external peers and managers. Document projects thoroughly, from business objectives and data processing to final algorithms and results. Create materials to effectively communicate findings to business audiences. Evaluate commercial and open-source techniques in machine learning, data mining, NLP, and analytics. Develop scalable and high-performance machine learning and data mining algorithms. Test hypotheses rapidly through prototype development, offline experiments, and online A/B tests. Generate actionable insights through rigorous data analysis, including predictive modeling, cluster analysis, temporal analysis, and social network analysis. Produce reports and visualizations to provide insights into production systems. Mentor less experienced team members. Qualifications: - Master’s degree or higher in Computer Science, Statistics, Mathematics, or a related field with a focus on data mining, NLP, or machine learning. Over 6 years of professional experience in NLP systems, predictive modeling, recommendations/personalization, clustering, classification, sentiment analysis, time series, and deep learning. Over 5 years of programming experience in Python, TensorFlow, PyTorch, or Keras. Over 5 years of experience with cloud technologies such as AWS. Over 3 years of experience in developing and applying language models. Benefits: -Competitive medical, dental and vision coverage Company-paid pension and 401(k) match Three weeks of vacation and up to three weeks of paid sick leave Nine paid holidays and two personal days 20 weeks paid parental leave for any new parent Robust mental health resources Backup care and caregiver concierge services Gender affirming services Pet insurance Free digital subscription Leadership and career development programs Applicants must be currently authorized to work in the US on a full-time basis now and in the future.** Posted By: Lindsay Troyer",
        "url": "https://www.linkedin.com/jobs/view/3953811239",
        "summary": "This role is for a Staff Applied Machine Learning Scientist at a renowned American newspaper. You will develop AI solutions to enhance news experiences and business solutions, combining research, analysis, and software development. The role is remote, preferably within the DMV area.",
        "industries": [
            "Media",
            "News",
            "Journalism",
            "Digital Media",
            "Publishing",
            "Information Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Problem Solving",
            "Collaboration",
            "Leadership",
            "Mentorship",
            "Time Management",
            "Organization",
            "Critical Thinking",
            "Analytical Skills"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Natural Language Processing (NLP)",
            "Data Mining",
            "Predictive Modeling",
            "Clustering",
            "Classification",
            "Sentiment Analysis",
            "Time Series Analysis",
            "Deep Learning",
            "Python",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "AWS",
            "A/B Testing",
            "Data Analysis",
            "Report Generation",
            "Visualization"
        ],
        "tech_stack": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "AWS"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Data Mining",
                "NLP",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Pension",
            "401(k) Match",
            "Vacation",
            "Sick Leave",
            "Holidays",
            "Personal Days",
            "Parental Leave",
            "Mental Health Resources",
            "Backup Care",
            "Caregiver Concierge Services",
            "Gender Affirming Services",
            "Pet Insurance",
            "Digital Subscription",
            "Leadership Development",
            "Career Development Programs"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3971516071,
        "company": "CACI International Inc",
        "title": "Data Scientist – CMDB Authoritative Sources",
        "created_on": 1720587066.3502097,
        "description": "Job Category: Information Technology Time Type: Full time Minimum Clearance Required to Start: Secret Employee Type: Regular Percentage of Travel Required: Up to 10% Type of Travel: Continental US * * * CACI is seeking a Data Analyst in support of the Enterprise Information Technology as a Service (EITaaS) contract with the Department of the Air Force. The EITaaS program supports our customer to provide a common set of required EIT services across 187 bases to implement a consistent, high-quality experience for users across all mission environments and enable USAF to transition focus from network operations to mission operations. CACI is leading the way in transforming IT services from an in-house, base-centric delivery model to an advanced enterprise service delivery model. General Description In this role you will participate in authoritative source workshops with Government stakeholders to validate authoritative sources and attributes. You will then work with those sources to determine the integration approach, understand the data schema, and develop thirteen integrations between those sources and Axonius. This includes configuring data mapping between authoritative source and the Configuration Management Database (CMDB) as required and documenting the integration to train POC(s) on actions to take when they change their system. You will analyze the imported data and deconflict discrepancies across the various sources. You will also contribute to contract deliverables including test plans, CMDB Solution Strategy, Data Management Plan, Architecture Plan, Interface Control Documents (ICDs), training, and a security assessment. The Ideal Candidate Will Bring Experience analyzing data and data relationships across an organization’s business areas. A strong understanding of ITSM, ITIL, and CMDB. A proven track record in ITSM technologies and comfortable in the dynamic atmosphere of a technical organization with a rapidly expanding customer base. Experience implementing business processes, capability needs, business requirements, and business information models. Working knowledge of all elements of the software development life cycle, including planning, development, requirements management, CM, quality assurance, and release management. Strong skills with MS Office tools (Excel, Word, Project, Visio) and SharePoint Qualifications DoD Secret Clearance. Must be IAT Level II certified (i.e. CompTIA Security+) within 30 calendar days of hire. 10+ Years experience and a Bachelor’s Degree in applicable field. Experience with SQL code and implementing SQL code. Experience with Axonius and ServiceNow CMDB– including extracting and analyzing data relating to Cybersecurity. Experience with deploying and integrating the Axonius Cyber Asset Management Platform. Experience with Application Programming Interfaces (APIs). Experience with Data Analysis and Data Analytics tools such as Power BI, Tableau and/or Python. Understanding of and experience with administering servers and solutions in Microsoft Azure. Experience with any of the following: Git, Microsoft SQL Server, MDM Solutions, Ansible, SCCM Familiarity with common cybersecurity tools. Experience working as part of a project team using Agile, Scrum, Kanban, or SAFe processes. Experience with customer interactions, including presenting, answering questions, proactively resolving issues. Familiarity with Agile Scrum methodologies. Effective communicator at all levels, both written and verbal Desired Skills An active DoD Top Secret or higher clearance Azure GovCloud Experience including Cosmos DB Cloud certifications such as Azure Solutions Architect, Azure Security Engineer, or Azure DevOps Engineer. Agile or Scrum Master Certification Experience with Data Analysis and Data Analytic skills (Python, Elastic). Experience with Data Modelling skills (such as Power BI service, SQL Server Analysis Services (SSAS), XMLA). Jupiter Notebooks Experience working with Large Language Models (LLMs) Artificial Intelligence (AI) Experience Current advanced Security certifications such as CISSP, CCSP, CompTIA CASP+. ITIL 4 Foundation or higher certification. Acts independently to expose and resolve problems Experience working in the Department of Defense What We Can Offer You We’ve been named a Best Place to Work by the Washington Post Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive benefits and learning and development opportunities. We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities. For over 60 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success. ______________________________________________________________________________ What You Can Expect A culture of integrity. At CACI, we place character and innovation at the center of everything we do. As a valued team member, you’ll be part of a high-performing group dedicated to our customer’s missions and driven by a higher purpose – to ensure the safety of our nation. An environment of trust. CACI takes pride in fostering a diverse and accessible culture where every individual feels supported to chart their own path. You’ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality. A focus on continuous growth. Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground — in your career and in our legacy. Your potential is limitless. So is ours. Learn more about CACI here. ______________________________________________________________________________ Pay Range : There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here. The Proposed Salary Range For This Position Is $94,400 - $198,300 CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic.",
        "url": "https://www.linkedin.com/jobs/view/3971516071",
        "summary": "CACI is seeking a Data Analyst to support the Enterprise Information Technology as a Service (EITaaS) contract with the Department of the Air Force. The EITaaS program supports the customer to provide a common set of required EIT services across 187 bases. The ideal candidate will have experience analyzing data, strong understanding of ITSM, ITIL, and CMDB, experience with Axonius and ServiceNow CMDB, experience with SQL code and implementing SQL code, experience with Application Programming Interfaces (APIs) and Data Analysis and Data Analytics tools such as Power BI, Tableau and/or Python, understanding of and experience with administering servers and solutions in Microsoft Azure, experience with common cybersecurity tools, experience working as part of a project team using Agile, Scrum, Kanban, or SAFe processes and experience with customer interactions.",
        "industries": [
            "Information Technology",
            "Government",
            "Defense"
        ],
        "soft_skills": [
            "Analytical",
            "Communication",
            "Problem-Solving",
            "Teamwork",
            "Collaboration",
            "Presentation",
            "Time Management"
        ],
        "hard_skills": [
            "ITSM",
            "ITIL",
            "CMDB",
            "Axonius",
            "ServiceNow",
            "SQL",
            "Power BI",
            "Tableau",
            "Python",
            "Azure",
            "Cybersecurity",
            "API",
            "Agile",
            "Scrum",
            "Kanban",
            "SAFe",
            "Git",
            "Microsoft SQL Server",
            "MDM Solutions",
            "Ansible",
            "SCCM"
        ],
        "tech_stack": [
            "Axonius",
            "ServiceNow CMDB",
            "SQL",
            "Power BI",
            "Tableau",
            "Python",
            "Azure",
            "Git",
            "Microsoft SQL Server",
            "MDM Solutions",
            "Ansible",
            "SCCM"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Applicable field"
            ]
        },
        "salary": {
            "max": 198300,
            "min": 94400
        },
        "benefits": [
            "Healthcare",
            "Wellness",
            "Financial",
            "Retirement",
            "Family Support",
            "Continuing Education",
            "Time Off"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Sterling, VA",
        "job_id": 3952362854,
        "company": "Northstrat Incorporated",
        "title": "Software Engineer/Developer",
        "created_on": 1720587067.8772447,
        "description": "Software Engineer / Developer Job Type: Full time, On-Site, potential for Hybrid Clearance Requirements: Existing TS/SCI clearances are strongly desired, ability to be cleared to Top Secret workable. Northstrat has various positions available, such as front-end, back-end, and full stack software engineering. You will be responsible for designing, developing, testing, deploying, and maintaining software solutions.. As a Northstrat software engineer, you will have the opportunity to join amazing teams that deliver strategic IT solutions for meaningful problems in the defense and intelligence sectors. You will tackle unique and complex challenges, using cutting-edge technologies to build scalable and secure solutions with DevSecOps and Agile methods. Duties and Responsibilities: Develop and implement software enhancements to mission systems in Federal Government agencies Integrate multiple applications and systems to streamline process workflows Design, develop, document, test, and debug software that contains logical and mathematical solutions to mission problems Use diagrams to document software functionality Build scalable and secure solutions to mission problems Communicate effectively when writing and/or contributing to end user instructions or manuals Perform code reviews and provide feedback to your peers Apply research and development techniques to progress product from an idea into production Common Tech Stacks at Northstrat: React, Angular, Vue.js, Javascript Java, NodeJS, Ruby, Clojure, Python Docker, Kubernetes, Redis, Kafka, SciPy, NumPy, Pandas CM processes/tools: GIT, JIRA, Confluence Soft Skills Teamwork Communication Skills Self-Motivated Time Management Skills Adaptability to an agile work environment Requirements Required Skills Creative problem-solving using innovative analytical solutions Software Development with modern languages Desired Skills Enterprise system development Rapid prototyping and Agile based software development methodologies Understanding of web application development concepts Understanding DevSecOps pipelines for enterprise systems Understanding of Frontend/Backend development Working with modern databases Developing automated testing Working with Configuration Management software such as GIT Understanding APIs and web service interfaces such as REST and GraphQL Linux operating systems NiFi automation Development in microservice-based architectures AWS APIs and deployment Understanding of machine learning concepts Education and Certifications: Bachelors or Pursuing Bachelor's or Master's degree Certifications preferred but not required based upon customer requirements: AWS Certification (Developer, DevOps and/or, Architect, etc.) and Security+ Certification Benefits Work/Life Balance Northstrat values true work life balance. We offer power of choice benefits designed to best meet the needs of you and your lifestyle. Our benefits programs are designed to support and encourage wellness, healthy living, retirement investment, and lifetime learning. Flex Time Northstrat does not mandate specific working hours. Although project requirements may dictate schedules, a Northstrat employee is only required to work an average of 8 hours per weekday over the course of a month. For example: John worked 12 hours on June 1st to meet a project deadline. On June 15th, John only worked 4 hours because he left early for a long weekend. John's IBA was not debited for time off because flex time allowed him to carry over those 4 hours from June 1st. Individual Benefits Account (IBA) To attract and retain the highest quality staff, Northstrat provides a unique and versatile benefits package, the Individual Benefit Account (IBA), which places the power of choice in the hands of our greatest asset - the employee. The purpose of the IBA is to provide attractive benefits to all full-time employees of Northstrat on a flexible basis that enables each covered employee to select a package that best suits his or her needs. Whether those needs are paid time off, medical expenses, prescription drug expenses, cash disbursement, or a combination of any of these, the IBA provides flexibility to help you meet your specific goals. The IBA can be used for such things as: Medical and Vision Insurance through United Health Care; Dental insurance through Delta Dental 100% Medical Reimbursement Time Off with Pay Profit Sharing Plan 401k Educational Benefits Additional Income IBA Benefits accrue each month in the amount equivalent to 50% of the employee's monthly compensation rate. That is, the effective dollar amount of this accrual is in addition to an employee's salary. Profit Sharing Plan (PSP) The PSP is a qualified retirement plan that Northstrat funds semi-annually on the employee's behalf through the IBA in the amount equivalent to 25% (up to the IRS contribution limit) of the employee's compensation. That is, of the 50% accrual in the IBA, half of the amount accrued is applied to the PSP. Stock Options Because Northstrat is an employee-owned company, all new employees are offered stock options. Employees have the opportunity to receive additional stock options based on accomplishment of individual performance goals. Stock owners elect the Board of Directors and are directly impacted by the success of the company. Lifelong Learning Our culture promotes and nurtures a growth environment. We hire and scale rapidly to meet the needs of our partner customers. Through the use of company provided online learning opportunities, periodic company sponsored training events, and the ability to use IBA funds for reimbursement of work-related education expenses you will have the opportunity to continually grow your skills and abilities. Bring Your True Self We embrace diversity and encourage inclusion. We support employee led interest groups and challenge our employees to support others and be their best self. We are so true to our beliefs that we offer employee referral incentives. When you like it here, your friends and family will too! Northstrat is an Equal Opportunity Employer We are committed to fostering an inclusive, diverse workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other legally protected status.",
        "url": "https://www.linkedin.com/jobs/view/3952362854",
        "summary": "Northstrat is seeking software engineers with TS/SCI clearance (or the ability to obtain it) for full-time, on-site positions with potential for hybrid work. They offer various roles like front-end, back-end, and full-stack development.  The company focuses on delivering strategic IT solutions for the defense and intelligence sectors, tackling complex challenges with cutting-edge technologies like DevSecOps and Agile methodologies. Responsibilities include developing software enhancements, integrating applications, designing and debugging software, documenting functionality, building scalable and secure solutions, and collaborating with peers through code reviews.  They offer a unique benefits package including flex time, an Individual Benefits Account (IBA) for various expenses, profit sharing, stock options, and a focus on lifelong learning. Northstrat is an Equal Opportunity Employer and values diversity.",
        "industries": [
            "Defense",
            "Intelligence",
            "IT",
            "Software Development"
        ],
        "soft_skills": [
            "Teamwork",
            "Communication Skills",
            "Self-Motivated",
            "Time Management Skills",
            "Adaptability"
        ],
        "hard_skills": [
            "Software Development",
            "Modern Languages",
            "Enterprise System Development",
            "Rapid Prototyping",
            "Agile Methodologies",
            "Web Application Development",
            "DevSecOps",
            "Frontend/Backend Development",
            "Databases",
            "Automated Testing",
            "Configuration Management",
            "GIT",
            "APIs",
            "REST",
            "GraphQL",
            "Linux",
            "NiFi",
            "Microservices",
            "AWS APIs",
            "Deployment",
            "Machine Learning"
        ],
        "tech_stack": [
            "React",
            "Angular",
            "Vue.js",
            "Javascript",
            "Java",
            "NodeJS",
            "Ruby",
            "Clojure",
            "Python",
            "Docker",
            "Kubernetes",
            "Redis",
            "Kafka",
            "SciPy",
            "NumPy",
            "Pandas",
            "GIT",
            "JIRA",
            "Confluence"
        ],
        "programming_languages": [
            "React",
            "Angular",
            "Vue.js",
            "Javascript",
            "Java",
            "NodeJS",
            "Ruby",
            "Clojure",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Software Engineering",
                "Information Technology",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Work/Life Balance",
            "Flex Time",
            "Individual Benefits Account (IBA)",
            "Medical and Vision Insurance",
            "Dental Insurance",
            "100% Medical Reimbursement",
            "Time Off with Pay",
            "Profit Sharing Plan",
            "401k",
            "Educational Benefits",
            "Additional Income",
            "Stock Options",
            "Lifelong Learning",
            "Employee Referral Incentives"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3950781493,
        "company": "Mission Box Solutions",
        "title": "4215 - Senior Data Scientist (TS/SCI -FSP)",
        "created_on": 1720587069.395088,
        "description": "We are seeking a highly experienced Senior Data Scientist to join our team. The ideal candidate will have a passion for data science and a strong background in designing and implementing machine learning models and advanced analytical algorithms. The successful candidate will have excellent communication skills and the ability to work effectively in a collaborative team environment. Our Client focuses on Software Engineering in the Cloud and Cyber Security domains. Our client's specialties include implementing real-time solutions and analytics through the use of interactive applications and the integration of industry-standard software stacks for both enterprise data intelligence and cyber security protection against network threats and exploits. Responsibilities: Design and implement machine learning models and advanced analytical algorithms to solve complex business problems Collaborate with cross-functional teams to identify opportunities to apply data science techniques to business problems Develop and implement data mining and statistical models to analyze large and complex datasets Lead projects to develop data-driven insights that can be used to make business decisions Develop and maintain data pipelines and ensure data quality and integrity Work with stakeholders to identify key performance metrics and develop dashboards to monitor and report on those metrics Must-Have: Active TS/SCI FSP clearance BS in Computer Science or related technical discipline (Higher level degrees can reduce the Yrs of Exp Needed) 7+ years of relevant experience in designing/implementing machine learning, data science, advanced analytical algorithms, programming, data mining, advanced statistical analysis, advanced mathematical foundations, artificial intelligence, workflow and reproductibility, data management and curation, data modeling and assessment, experience as a data scientist working to support a single or multiple domain areas, and/or software engineering Strong programming skills in at least one high-level language (e.g., Python) and at least one mid-level language (e.g., C) Experience in leading projects and managing junior team members Strong problem-solving and analytical skills Excellent communication and collaboration skills Nice to Have: Master's or PhD in Computer Science or related technical discipline Experience in developing and implementing deep learning models Experience in developing and deploying data products in production environments Experience with big data technologies such as Hadoop, Spark, and NoSQL databases Benefits: Paid time off Retirement / 401k Health, Dental, and Vision insurance Disability insurance Life insurance, AD/D, STD/LTD Professional Development Certification Award / Bonus Company Sponsored Activities Salary: $140,000 - $200,000 Mission Box Solutions is an Equal Opportunity Employer. We value the benefits of diversity in our workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity and expression, national origin, disability, protected Veteran status, or any other attribute or protected characteristic by law. Applicants selected may be subject to a government security investigation and must meet eligibility requirements for potential access to classified information. Accordingly, US Citizenship is required. Our strategic partner is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities, duties, and skills required of personnel so classified. Furthermore, they do not establish a contract of employment and are subject to change at the discretion of our strategic partner. Powered by JazzHR HWWYlleh1o",
        "url": "https://www.linkedin.com/jobs/view/3950781493",
        "summary": "Seeking a Senior Data Scientist with 7+ years of experience in machine learning, data science, and advanced analytics. Responsibilities include designing and implementing machine learning models, collaborating with cross-functional teams, developing data pipelines, and working with stakeholders to identify key performance metrics. Requires active TS/SCI FSP clearance and strong programming skills in Python and C. Experience with big data technologies such as Hadoop, Spark, and NoSQL databases is a plus.",
        "industries": [
            "Software Engineering",
            "Cloud Computing",
            "Cyber Security",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Science",
            "Advanced Analytics",
            "Data Mining",
            "Statistical Analysis",
            "Artificial Intelligence",
            "Workflow Management",
            "Reproducibility",
            "Data Management",
            "Data Curation",
            "Data Modeling",
            "Assessment",
            "Python",
            "C",
            "Hadoop",
            "Spark",
            "NoSQL Databases",
            "Deep Learning"
        ],
        "tech_stack": [
            "Python",
            "C",
            "Hadoop",
            "Spark",
            "NoSQL Databases"
        ],
        "programming_languages": [
            "Python",
            "C"
        ],
        "experience": 7,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Computer Science",
                "Related Technical Discipline"
            ]
        },
        "salary": {
            "max": 200000,
            "min": 140000
        },
        "benefits": [
            "Paid Time Off",
            "Retirement / 401k",
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Disability Insurance",
            "Life Insurance",
            "AD/D",
            "STD/LTD",
            "Professional Development",
            "Certification Award / Bonus",
            "Company Sponsored Activities"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3868960515,
        "company": "Tecolote Research",
        "title": "Senior Data Scientist",
        "created_on": 1720587071.0100362,
        "description": "Overview The Senior Data Scientist will support our customers initiatives by developing/maintaining/analyzing data sets in order to create models and determinate potential outcomes. The position is immediately available for qualified candidates with the appropriate clearance. Responsibilities Technical Duties May Include: Mine and analyze data from databases to drive optimization Assess the effectiveness and accuracy of new data sources and data gathering techniques Develop custom data models and algorithms to apply to data sets Coordinate with different functional teams to implement models and monitor outcomes Develop processes and tools to monitor and analyze model performance and data accuracy Perform the planning, processing, implementation, and documentation of Data Discovery, Management, Integration, and Mining Perform Modeling and Simulation activities, including, but not limited to linear and nonlinear Modeling Provide Data Analytics Software Tool Support and guidance, including formal and informal training Research and propose the use of tools, techniques, methods, and models Maintain and update handbooks, manuals, job aides, dictionaries, and other centralized documentation which contain approved methods, sources, data sets, and techniques Develop prototype datasets that integrate data across databases Follow an agile Analytic Development Life Cycle, to include requirements gathering, transparent development, testing, and peer review Design, develop, and brief analytical reports including ad-hoc, descriptive, predictive and prescriptive tables and visualizations Skills Required SQL and Python Tableau and Power-Bi Education: Bachelor’s Degree in Mathematics, Machine Learning, Data Science, Operations Research, or Computer Science is required. A degree in a related field may be considered if 5 or more classes in advanced math and/or computer science have been taken Minimum 6 years experience in the Field of Data Analytics/Data Science, with at least 3 of the 6 years in DoD/IC Security Clearance - REQUIRED Active TS/SCI and CI Polygraph Benefits We offer competitive salaries commensurate with education and experience. We have an excellent benefits package that includes: Comprehensive health, dental, life, long and short-term disability insurance 100% Company funded Retirement Plans Generous vacation, holiday and sick pay plans Tuition assistance About Tecolote Research Tecolote Research is a private, employee-owned corporation where people are our primary resource. Our investments in technology and training give our employees the tools to ensure our clients are provided the solutions they need, and our very high employee retention rate and stable workforce is an added value to our customers. Apply now to connect with a company that invests in you. View all career opportunities: www.tecolote.com Follow us on social media: LinkedIn | X @TecoloteInc | Facebook [EOE/M/F/Disability/Veterans]",
        "url": "https://www.linkedin.com/jobs/view/3868960515",
        "summary": "Tecolote Research is seeking a Senior Data Scientist to support customer initiatives by developing, maintaining, and analyzing data sets to create models and predict outcomes. This position requires a strong background in data analytics, including SQL, Python, Tableau, and Power BI, as well as a TS/SCI security clearance with a CI Polygraph. The successful candidate will have at least 6 years of experience in data analytics, with at least 3 years in DoD/IC.",
        "industries": [
            "Defense",
            "Intelligence",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical",
            "Time Management",
            "Organization",
            "Presentation",
            "Technical Writing"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "Tableau",
            "Power BI",
            "Data Mining",
            "Data Modeling",
            "Algorithm Development",
            "Model Performance Monitoring",
            "Data Accuracy Analysis",
            "Data Discovery",
            "Data Management",
            "Data Integration",
            "Linear and Nonlinear Modeling",
            "Data Analytics Software Tool Support",
            "Data Visualization",
            "Report Writing",
            "Agile Development Life Cycle",
            "Requirements Gathering",
            "Testing",
            "Peer Review"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "Tableau",
            "Power BI"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Mathematics",
                "Machine Learning",
                "Data Science",
                "Operations Research",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive health, dental, life, long and short-term disability insurance",
            "100% Company funded Retirement Plans",
            "Generous vacation, holiday and sick pay plans",
            "Tuition assistance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3939070383,
        "company": "Deloitte",
        "title": "Data Scientist Manager",
        "created_on": 1720587072.4015775,
        "description": "Do you want to build your brand by working for a leading consulting firm that drives eminence in the marketplace? Are you interested in leveraging your analytical skills and strategic ideas to improve mission execution? If so, Deloitte could be the place for you! Our Government and Public Services (GPS) Strategy and Analytics team brings deep industry expertise, rigorous analytical capabilities and a pragmatic mindset to help solve our client's most complex business problems. Join our team and play a key role in helping to design our clients' roadmap to the future and help transform the public sector marketplace. Work You'll Do In this role, the Data Scientist Manager will work directly with our federal clients to define strategy, drive technical development, and create the next generation of AI tools and services that include state-of-the-art methodologies in computer vision, natural language processing, time series analysis, preventative maintenance, signal processing, and automation of analyst workflows. The Data Scientist Manager will: Design, develop and apply state-of-the-art methods within AI and machine learning, including the utilization of GANs, CNNs, RNNs, LSTMs, BERT, and other models to solve complex problems Act as an AI thought leader, including the creation of whitepapers, presentations, executive briefings, reports, and other materials to support AI solutions and services Guide federal clients with high autonomy in AI strategy and development, including understanding agency needs, performing exploratory data analysis, building and validating models, and deploying models into both on-prem and cloud environments Act as a subject matter expert to GPS clients and global AI partner ecosystem Iterate on and/or create repeatable, reusable processes and scalable data systems that meet technical and deployment challenges Maintain and uphold data science best practices on new methodologies, technologies, industry trends, and open source packages Work cross-functionally with other scientists & data engineers, federal account manager and leadership to help ensure project delivery and success The team SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in machine learning and AI technologies. We are looking for a senior data scientist to design and build end-to-end AI solutions within Government & Public Services (GPS). The candidate will be responsible for the development of AI systems through leveraging large and complex data streams derived from the world's most advanced aerospace, defense, intelligence, and energy systems. Qualifications Required: Master's or Ph.D. preferred in a STEM field, high proficiency in Artificial Intelligence and related engineering technologies 8+ years of experience in AI/ML algorithm development and data analysis (NLP, time-series analysis, computer vision) 5+ years of experience in in core programming languages and data science packages (Python, Keras, Tensorflow, PyTorch, Pandas, Scikit-learn, Jupyter, etc.) 5+ years of experience with deployment and optimization-Kubernetes, Docker, NVIDIA TensorRT/Triton, RAPIDs, Kubeflow, MLflow etc. Ability to obtain and maintain a government security clearance Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future Willingness to travel up to 5% Experience coaching or mentoring junior staff Preferred: 3+ years of Experience with cloud deployment (AWS, Azure, GCP), such as building and scaling in AWS SageMaker Strong problem solving and troubleshooting skills with experience exercising mature judgment Active Security clearance Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html #engcamp2024",
        "url": "https://www.linkedin.com/jobs/view/3939070383",
        "summary": "Deloitte's Government and Public Services (GPS) Strategy and Analytics team seeks a Data Scientist Manager to design, develop and apply state-of-the-art AI and machine learning methods, including GANs, CNNs, RNNs, LSTMs, BERT, and other models to solve complex problems for federal clients. The role involves guiding clients in AI strategy and development, building and deploying models, acting as a subject matter expert, and iterating on data systems.",
        "industries": [
            "Consulting",
            "Government",
            "Public Sector",
            "Aerospace",
            "Defense",
            "Intelligence",
            "Energy"
        ],
        "soft_skills": [
            "Analytical",
            "Strategic",
            "Problem Solving",
            "Troubleshooting",
            "Leadership",
            "Mentorship",
            "Communication",
            "Presentation"
        ],
        "hard_skills": [
            "AI",
            "Machine Learning",
            "Computer Vision",
            "Natural Language Processing",
            "Time Series Analysis",
            "Preventative Maintenance",
            "Signal Processing",
            "Automation",
            "GANs",
            "CNNs",
            "RNNs",
            "LSTMs",
            "BERT",
            "Python",
            "Keras",
            "Tensorflow",
            "PyTorch",
            "Pandas",
            "Scikit-learn",
            "Jupyter",
            "Kubernetes",
            "Docker",
            "NVIDIA TensorRT",
            "Triton",
            "RAPIDs",
            "Kubeflow",
            "MLflow",
            "AWS SageMaker",
            "AWS",
            "Azure",
            "GCP"
        ],
        "tech_stack": [
            "AI",
            "Machine Learning",
            "GANs",
            "CNNs",
            "RNNs",
            "LSTMs",
            "BERT",
            "Python",
            "Keras",
            "Tensorflow",
            "PyTorch",
            "Pandas",
            "Scikit-learn",
            "Jupyter",
            "Kubernetes",
            "Docker",
            "NVIDIA TensorRT",
            "Triton",
            "RAPIDs",
            "Kubeflow",
            "MLflow",
            "AWS SageMaker",
            "AWS",
            "Azure",
            "GCP"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "STEM"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3826849050,
        "company": "Motion Recruitment",
        "title": "Data Scientist (TS/SCI Full-Scope Poly)",
        "created_on": 1720587074.129249,
        "description": "A provider of analytics and software services for the intelligence and defense communities is seeking a Data scientist. You would be at the forefront of designing, developing, and validating AI/ML solutions. In summary, this position offer a unique opportunity to shape data-driven transformation. Responsibilities include discovering datasets that could help in solution development; curating data, analyzing, and performing quantitative modeling; validating the quality of data, models, and results; deploying and implementing solutions in collaboration with product team; and interacting with the product team on current and upcoming user requirements. Required Skills & Experience Bachelors in Sciences, Mathematics or Engineering At least 4 years of professional experience in a Data Scientist position Significant experience using Python, including use of modern data science and machine learning packages and frameworks (Java, c++, Scala may be considered) Experience with SQL and architecting data schemas Active government clearance TS/SCI Full-Scope Poly (TS/SCI ci poly may be considered) Nice-To-Have Advanced working SQL knowledge, primarily for relational databased. Experience building and optimizing data pipelines, including big data tools with Spark, Kafka Data warehouse with Snowflake Backing with Geospatial data What You Will Be Doing Daily Responsibilities 75% Hands On 25% Team Collaboration The Offer Bonus eligible You Will Receive The Following Benefits Full medical, dental, vision coverage for employee and dependents 401k matching program PTO and Holidays Bonus and other incentive programs Access to mental health program Access to Flexible Spending Accounts for Health Care, Dependent and Commuter Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Possession of at minimum a TS/SCI ci poly government clearance is required.** LI#-DP1 Posted By: Derek Progin",
        "url": "https://www.linkedin.com/jobs/view/3826849050",
        "summary": "Data Scientist role focused on designing, developing, and validating AI/ML solutions for intelligence and defense communities. Involves data discovery, curation, analysis, modeling, validation, deployment, and collaboration with product teams.",
        "industries": [
            "Intelligence",
            "Defense",
            "Analytics",
            "Software"
        ],
        "soft_skills": [
            "Collaboration",
            "Problem-Solving",
            "Analytical Skills",
            "Communication",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Machine Learning",
            "Data Science",
            "Data Curation",
            "Quantitative Modeling",
            "Data Validation",
            "Model Validation",
            "Deployment",
            "Data Pipelines",
            "Big Data",
            "Spark",
            "Kafka",
            "Snowflake",
            "Geospatial Data"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Spark",
            "Kafka",
            "Snowflake"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C++",
            "Scala"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Sciences",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401k Matching",
            "PTO",
            "Holidays",
            "Bonus",
            "Incentive Programs",
            "Mental Health Program",
            "Flexible Spending Accounts"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3960168976,
        "company": "The Aerospace Corporation",
        "title": "Data Science and Artificial Intelligence Department Director",
        "created_on": 1720587077.0972672,
        "description": "The Aerospace Corporation is the trusted partner to the nation’s space programs, solving the hardest problems and providing unmatched technical expertise. As the operator of a federally funded research and development center (FFRDC), we are broadly engaged across all aspects of space— delivering innovative solutions that span satellite, launch, ground, and cyber systems for defense, civil and commercial customers. When you join our team, you’ll be part of a special collection of problem solvers, thought leaders, and innovators. Join us and take your place in space. At Aerospace, we are committed to providing an inclusive and diverse workplace for all employees to share in our common passion and aspiration – to carry out a mission much bigger than ourselves. Information Systems and Cyber Division (ISCD) staff couple the latest in information system technologies, such as elastic compute clouds, containerization, microservices, real-time operating systems, and visualization frameworks, with expertise in cyber security, software architecture, software engineering, data science, Artificial Intelligence, process improvement, and software development to deliver responsive, resilient, high-performance software intensive systems to our IC, DoD, and civilian customers. The Data Science and Artificial Intelligence Department (DSAID) seeks a creative and enthusiastic Director (Department Director – Data Science and AI) to lead a diverse team of engineers, data scientists, and programmers with a passion for researching, prototyping, understanding, and building AI and data enabled tools across the space enterprise. We are an innovative and collaborative department that makes meaningful contributions across National Security Space (AF, NRO, etc.) and Civil and Commercial customers (NASA, MDA, DHS, commercial space, autonomous vehicles, etc.). An ideal candidate is a community-focused leader, focused on setting department strategy and priorities, aligning with corporate and customer priorities, developing staff, and furthering efforts spanning internally funded R&D and customer support for mission-critical space systems. Work Model This is a full-time position based in El Segundo, CA, Chantilly, VA, or Colorado Springs, CO, offering a hybrid work model that combines 4 regular onsite workdays and remote flexibility as the business needs allow. What You’ll Be Doing Lead technical teams and contribute to technical tasks in data science, machine learning engineering, and AI research Lead DSAID management team to recruit, develop and manage technical staff in data science, machine learning engineering, and AI research aligned with corporate priorities Coordinate between DSAID and Aerospace customer facing organizations to understand mission needs, determine tasking, report progress, resolve technical issues, and deliver/review results Discover opportunities for additional, expanded, or new business. Aid in the evaluation and pursuit of new business opportunities and propose technical efforts aligned with customer needs Assess and execute staffing needs, reassignments, transfers, terminations, performance improvements, career development, and promotional actions Ensure team compliance with security monitoring, processes, and corporate policies Communicate activities, accomplishments, and recommendations to leadership and staff Participate in technical exchanges, team building, and education across organizational boundaries Duties, responsibilities and activities may change, or new ones may be assigned as needed. What You Need to be Successful – Department Director – Data Science and AI Minimum Requirements Bachelors degree from an accredited program in Computer Science, Electrical or Computer Engineering, Physics, Applied Mathematics, or related field(s) 10 or more years of progressively responsible professional engineering/scientific experience Demonstrated ability to efficiently manage teams to deliver analysis and insights from data that is large, unstructured, or unprocessed Demonstrated written and oral communication skills, with ability to establish and maintain positive working relationships with customers and management/staff across organizations Experience with at least two different programming languages (e.g. Java, Python, C/C++), including familiarity with machine learning and deep learning libraries in Python Some travel may be required This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance. How You Can Stand Out It would be impressive if you have one or more of these: An advanced degree from an accredited program in Computer Science, Data Science, Electrical or Computer Engineering, or related field(s) History of effective cross-disciplinary leadership and teaming Experience implementing and guiding teams toward software and machine learning development best practices (e.g. code, model, and data set version control, experiment tracking and reproduction) Demonstrated contributions to open source software repositories (github, kaggle, etc), publication record in machine learning conferences/journals Familiarity deploying ML models within applications or on cloud platforms (AWS, Azure, etc.) Active TS/SCI security clearance Leadership Competencies Our leadership philosophy is simple: every employee, regardless of level and role, can demonstrate leadership. At Aerospace, our commitment is our people. To cultivate our talent and ensure that we have a strong pipeline of future leaders, we want individuals who: Operate Strategically Lead Change Engage with Impact Foster Innovation Deliver Results We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. The grade-based pay range for this job is listed below. Individual salaries within that range are determined through a wide variety of factors including but not limited to education, experience, knowledge and skills. (Min - Max) $185,100 - $277,600 Pay Basis: Annual Leadership Competencies Our leadership philosophy is simple: every employee, regardless of level and role, can demonstrate leadership. At Aerospace, our commitment is our people. To cultivate our talent and ensure that we have a strong pipeline of future leaders, we want individuals who: Operate Strategically Lead Change Engage with Impact Foster Innovation Deliver Results Ways We Reward Our Employees During your interview process, our team will provide details of our industry-leading benefits. Benefits vary and are applicable based on Job Type. A few highlights include: Comprehensive health care and wellness plans Paid holidays, sick time, and vacation Standard and alternate work schedules, including telework options 401(k) Plan — Employees receive a total company-paid benefit of 8%, 10%, or 12% of eligible compensation based on years of service and matching contributions; employees are immediately eligible and vested in the plan upon hire Flexible spending accounts Variable pay program for exceptional contributions Relocation assistance Professional growth and development programs to help advance your career Education assistance programs An inclusive work environment built on teamwork, flexibility, and respect We are all unique, from diverse backgrounds and all walks of life, yet one thing bonds all of us to each other—the belief that we can make a difference. This core belief empowers us to do our best work at The Aerospace Corporation. Equal Opportunity Commitment The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, age, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender, gender identity or expression, color, religion, genetic information, marital status, ancestry, national origin, protected veteran status, physical disability, medical condition, mental disability, or disability status and any other characteristic protected by state or federal law. If you’re an individual with a disability or a disabled veteran who needs assistance using our online job search and application tools or need reasonable accommodation to complete the job application process, please contact us by phone at 310.336.5432 or by email at ieo.mailbox@aero.org. You can also review Know Your Rights: Workplace Discrimination is Illegal, as well as the Pay Transparency Policy Statement.",
        "url": "https://www.linkedin.com/jobs/view/3960168976",
        "summary": "The Aerospace Corporation's Data Science and Artificial Intelligence Department (DSAID) seeks a Director to lead a team of engineers, data scientists, and programmers. This position requires a minimum of 10 years of experience in data science, machine learning, and AI research. The ideal candidate will have a background in leading cross-disciplinary teams, implementing software and machine learning development best practices, and contributing to open source software repositories. The Director will be responsible for setting department strategy and priorities, recruiting and developing staff, and furthering efforts spanning internally funded R&D and customer support for mission-critical space systems.",
        "industries": [
            "Aerospace",
            "Defense",
            "National Security",
            "Space",
            "Research and Development",
            "Cybersecurity",
            "Software Development",
            "Data Science",
            "Artificial Intelligence",
            "Information Technology"
        ],
        "soft_skills": [
            "Leadership",
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Strategic Thinking",
            "Teamwork",
            "Innovation",
            "Flexibility",
            "Community Focus",
            "Customer Focus",
            "Relationship Building",
            "Problem-Solving",
            "Decision-Making",
            "Results-Oriented",
            "Analytical",
            "Strategic Thinking",
            "Teamwork",
            "Cross-Functional Collaboration",
            "Interpersonal"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "AI Research",
            "Python",
            "Java",
            "C/C++",
            "Machine Learning Libraries",
            "Deep Learning Libraries",
            "Software Engineering",
            "Software Development",
            "Data Analysis",
            "Data Visualization",
            "Cloud Platforms",
            "AWS",
            "Azure",
            "Software Development Best Practices",
            "Code Version Control",
            "Experiment Tracking",
            "Model Version Control",
            "Data Set Version Control",
            "Deployment",
            "Security Clearance"
        ],
        "tech_stack": [
            "Elastic Compute Clouds",
            "Containerization",
            "Microservices",
            "Real-Time Operating Systems",
            "Visualization Frameworks",
            "AWS",
            "Azure",
            "GitHub",
            "Kaggle"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C/C++"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Electrical or Computer Engineering",
                "Physics",
                "Applied Mathematics",
                "Data Science"
            ]
        },
        "salary": {
            "max": 277600,
            "min": 185100
        },
        "benefits": [
            "Comprehensive health care and wellness plans",
            "Paid holidays",
            "Sick time",
            "Vacation",
            "Standard and alternate work schedules",
            "Telework options",
            "401(k) Plan",
            "Flexible spending accounts",
            "Variable pay program",
            "Relocation assistance",
            "Professional growth and development programs",
            "Education assistance programs",
            "Inclusive work environment",
            "Teamwork",
            "Flexibility",
            "Respect"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3922045762,
        "company": "MITRE",
        "title": "Principal Data Scientist",
        "created_on": 1720587078.5718377,
        "description": "Why choose between doing meaningful work and having a fulfilling life? At MITRE, you can have both. That's because MITRE people are committed to tackling our nation's toughest challenges—and we're committed to the long-term well-being of our employees. MITRE is different from most technology companies. We are a not-for-profit corporation chartered to work for the public interest, with no commercial conflicts to influence what we do. The R&D centers we operate for the government create lasting impact in fields as diverse as cybersecurity, healthcare, aviation, defense, and enterprise transformation. We're making a difference every day—working for a safer, healthier, and more secure nation and world. Our workplace reflects our values. We offer competitive benefits, exceptional professional development opportunities, and a culture of innovation that embraces diversity, inclusion, flexibility, collaboration, and career growth. If this sounds like the choice you want to make, then choose MITRE—and make a difference with us. Department Summary: As part of the Center for Integrated Transportation, the Operational Safety Mitigations Department (P231) identifies emerging risks and develops mitigations in the aviation and surface transportation domains. Comprised of safety experts, software engineers, and data scientists, P231 leverages proprietary and public datasets to promote collaboration among a variety of stakeholders and drive proactive mitigation of safety risks in aviation and surface transportation. Roles and Responsibilities: Lead a team of multi-disciplinary engineers, including software developers, data scientists, and subject matter experts in a diverse set of projects focused on aviation risk mitigation Proactively liaise with other teams across MITRE and industry partners to enhance the department’s technological capability, and lead the adoption of the latest advances in data science and machine learning Advance aviation safety by establishing standardized methods for ingesting and fusing various aviation datasets, developing derived analytics, and developing capabilities that directly impact sponsor and stakeholder missions to enable efficient data-driven analysis by sponsors and stakeholders Apply innovative analysis techniques to uncover anomalous characteristics or precursors to aviation safety risks Develop safety analytics and data visualization products that enable data-driven decision making for sponsors involved in safety monitoring and mitigation Develop innovative data and software products in a collaborative aviation data ecosystem, including within AWS, to enable efficient safety mitigation development Develop sponsor relationships and engage across industry to drive mission impact and cultivate new business opportunities Develop efficient and repeatable data pipelines for data transfers, extractions, culling, manipulation, and preparation for input into analyses and machine learning models Basic Qualifications: Typically requires a minimum of 10 years of related experience with a Bachelor’s degree; or 8 years and a Master’s degree; or a PhD with 5 years’ experience; or equivalent combination of related education and work experience. Ability to obtain and maintain FAA Suitability within the first 12 months Self-starter capable of working in a dynamic environment Expertise in one of the following: data engineering, statistical modeling, predictive analytics, artificial intelligence or machine learning Expertise using software languages such as Java, Python, and R Experience using common web development frameworks such as Vue and Angular Experience building large-scale data processing pipelines Experience using AWS tools and tailoring them for effective use in project work Demonstrated leadership of multi-disciplinary technical teams and implementation of software development best practices Critical thinking, including demonstrated ability to understand a complex engineering problem, and follow through with proposing and executing on novel solutions Demonstrated ability to lead a project team in development of impactful data and software products in a fast-paced environment Strong problem-solving skills and engagement with technical experts to develop and vet solutions Excellent technical writing and presentation skills Strong motivation to expand knowledge and skills of the organization Excellent verbal and written communication skills, and the ability to convey complex ideas or analyses in a clear and organized manner This position requires a minimum of 50% hybrid on-site Preferred Qualifications: FAA – Suitability (Preferred) Advanced degree in Data Science, Computer Science, Applied Mathematics, Statistics, or related subjects Expertise in big data processing, analysis, and visualization using aviation or transportation data Experience training and deploying machine learning models at scale Demonstrated ability to learn and apply knowledge of a technical domain to software development, particularly in aviation safety Expertise in aviation operations and safety management Strong interpersonal skills and significant experience leading multi-disciplinary teams This requisition requires the candidate to have a minimum of the following clearance(s): Suitability - FAA This requisition requires the hired candidate to have or obtain, within one year from the date of hire, the following clearance(s): None Work Location Type: Hybrid MITRE is proud to be an equal opportunity employer. MITRE recruits, employs, trains, compensates, and promotes regardless of age; ancestry; color; family medical or genetic information; gender identity and expression; marital, military, or veteran status; national and ethnic origin; physical or mental disability; political affiliation; pregnancy; race; religion; sex; sexual orientation; and any other protected characteristics. For further information please visit the Equal Employment Opportunity Commission website EEO is the Law Poster and Pay Transparency. MITRE intends to maintain a website that is fully accessible to all individuals. If you are unable to search or apply for jobs and would like to request a reasonable accommodation for any part of MITRE’s employment process, please email recruitinghelp@mitre.org. Copyright © 2024, The MITRE Corporation. All rights reserved. MITRE is a registered trademark of The MITRE Corporation. Material on this site may be copied and distributed with permission only. Benefits information may be found here",
        "url": "https://www.linkedin.com/jobs/view/3922045762",
        "summary": "MITRE's Operational Safety Mitigations Department (P231) is seeking a leader to spearhead aviation risk mitigation efforts. This role involves leading a team of engineers, data scientists, and subject matter experts in developing data-driven solutions for enhancing aviation safety. Responsibilities include collaborating with industry partners, leveraging data science and machine learning, and building large-scale data processing pipelines within AWS to identify and mitigate safety risks.",
        "industries": [
            "Aviation",
            "Transportation",
            "Aerospace",
            "Cybersecurity",
            "Healthcare",
            "Defense",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Leadership",
            "Communication",
            "Problem-solving",
            "Collaboration",
            "Critical Thinking",
            "Project Management",
            "Interpersonal Skills",
            "Presentation Skills",
            "Teamwork",
            "Self-Motivation",
            "Time Management"
        ],
        "hard_skills": [
            "Data Engineering",
            "Statistical Modeling",
            "Predictive Analytics",
            "Artificial Intelligence",
            "Machine Learning",
            "Java",
            "Python",
            "R",
            "Vue",
            "Angular",
            "AWS",
            "Data Pipelines",
            "Software Development Best Practices",
            "Data Visualization",
            "Technical Writing",
            "Big Data Processing",
            "Aviation Data Analysis",
            "Aviation Operations",
            "Safety Management",
            "Data Fusion"
        ],
        "tech_stack": [
            "Java",
            "Python",
            "R",
            "Vue",
            "Angular",
            "AWS"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "R"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Applied Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Benefits",
            "Professional Development Opportunities",
            "Flexible Work Arrangements",
            "Culture of Innovation",
            "Diversity and Inclusion"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Vienna, VA",
        "job_id": 3969218903,
        "company": "Steneral Consulting",
        "title": "Hybrid Work - Need Sr DevSecOps Engineer in Vienna VA",
        "created_on": 1720587079.9937122,
        "description": "Job Title - Sr DevSecOps Engineer -Azure Kubernetes Type - Hybrid ( 2 days onsite in aweek) Location - Vienna, VA Should be local to VA or from NC Description - Design & manage CICD pipelines, templates, and workflows providing a self-service and seamless developer experience. Provide guidance on CI/CD Toolchain, frameworks, strategies, and processes. Must be subject matter expert on container orchestration, Kubernetes, Docker. Responsibilities Design & architect CI/CD pipelines and workflows in accordance with standardized toolchain and frameworks Build, publish, manage, and enhance internal common libraries, templates, and workflows in support of CICD frameworks Onboard product teams to CI/CD framework simplifying the developer experience, promoting standards & methodologies Actively participate in the DevOps Center of Excellence (COE) to drive the creation of good governance and standards for CI/CD adoption across product and platforms teams Establish operational CI/CD Pipeline Quality Gates based on best practices and maturity level to which the software engineers are required to adhere to Review and enhance guardrails and best practices required to transform to a CICD framework Perform analysis of CI/CD practices, identify gaps and impediments for continuous improvement Support developers through source control, build automation, merge resolution, CI, test automation, and deployment based on CICD framework Provide thought leadership on DevSecOps architecture and technology matters Evaluate the quality of existing pipelines and provide recommendations Perform other related duties as assigned Qualifications Advanced experience with container orchestration, Kubernetes, Docker Hands on experience with Microsoft Azure Strong knowledge of CICD framework and DevOps methodologies hands on experience in designing and building pipelines Experience with agile delivery, SAFe, and DevOps frameworks Desired - Microsoft® Certified: Azure DevOps Engineer Desired – Certified Kubernetes Administrator",
        "url": "https://www.linkedin.com/jobs/view/3969218903",
        "summary": "Senior DevSecOps Engineer specializing in Azure Kubernetes.  Design and manage CI/CD pipelines, templates, and workflows for a seamless developer experience.  Focus on container orchestration, Kubernetes, Docker, and Microsoft Azure.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Leadership",
            "Teamwork",
            "Analytical",
            "Critical Thinking",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "CI/CD",
            "Kubernetes",
            "Docker",
            "Azure",
            "DevOps",
            "Agile",
            "SAFe",
            "Git",
            "Source Control",
            "Build Automation",
            "Test Automation",
            "Deployment",
            "Python",
            "Bash",
            "PowerShell"
        ],
        "tech_stack": [
            "Azure Kubernetes",
            "CI/CD",
            "Docker",
            "Kubernetes",
            "Azure DevOps",
            "SAFe",
            "Git",
            "Jenkins",
            "Terraform",
            "Ansible"
        ],
        "programming_languages": [
            "Python",
            "Bash",
            "PowerShell"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Hybrid Work",
            "Health Insurance",
            "Paid Time Off",
            "Retirement Plan"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3962234524,
        "company": "BTI360",
        "title": "ML Ops Engineer",
        "created_on": 1720587081.582511,
        "description": "Are you a DevOps guru who enjoys bringing simplicity to complex builds and deployments? Do you have a passion for leveraging machine learning to solve users’ tough problems? Do you do a fist pump when code commits get auto deployed? If you said yes, Yes, YES, then we may have a home for you. Our ML teams are focused on building, deploying, and scaling ML models. We're looking for an MLOps engineer with experience in cloud infrastructure, deployment pipelines, and hosting ML models. You will work with our team to turn custom ML models into valuable enrichment services with web APIs. You will be a part of an exciting program that serves the core operational mission of our Sponsor. This mid-sized, high-visibility program is paving the way for next-generation search, access control, and content curation capabilities at the heart of what our customer does. We are truly transforming the way our Sponsor does business and we need your help! Our program's high-performance development teams leverage modern technologies and practices including Lean Agile, Clean Code, and DevOps. In this role you’ll be supporting the team to build systems to catalog, evaluate, monitor, and publish new ML capabilities. You should be comfortable working in teams. Additionally, you should demonstrate a strong desire to continue learning, make an impact, and play a crucial role in expanding our AI/ML expertise. ABOUT US Here at BTI360, we’ve built a culture that’s passionate about developing software engineers. Software doesn't build itself. People do. In fact, teams of people do. That's why our primary focus is on developing better craftsmen, better teammates, and better technical leaders. By putting people first, we're not just giving our teammates more opportunities to grow, we're also raising the bar of the software we ship. BTI360 was voted 10 years in a row as a TOP Place to Work by the Washington Business Journal. Required: Must be US Citizen Bachelor’s degree in computer science, Computer Engineering, or equivalent experience 3+ years of Software Engineering experience Proficient in: Python, Java, YAML Familiar with ML model hosting environments (SageMaker, NVidia Triton) Familiar with ML model packaging, hosting, and deploying Familiar with AWS ecosystem of services (i.e., S3, RDS, DynamoDB, Lambda, Sagemaker) Familiar with CI/CD automation tools such as Jenkins, GitOps, CodePipeline Desired: Active TS clearance with Polygraph. Familiar with Kubeflow, Metaflow, mlflow, Flyte, Seldon Core, ArgoCD for ML models or similar Familiar with ML model evaluating AWS Cloud Certified (Cloud Practitioner, Solutions Architect) Familiar with LLMs like: Llama2, Amazon Titan, Claude 2, Hugging Face, or similar Familiar with Kubernetes or other container orchestration tools Experience using the latest Generative AI Technologies Experience working with Large Language Models (LLMs) - prompt engineering, prompt chaining, retrieval-augmented generation (RAG), hallucination mitigation BTI360 also offers a great benefits package that includes: Fully paid healthcare premiums Competitive salaries with Performance Bonuses Career Development and In-house training Continuing Education: Annual Reimbursement Towards Education and Training 5 Weeks of PTO plus 10 Federal Holidays 401K Dollar for Dollar Matching up to 6% Annually - Vested immediately on day 1. Giving Back: Serving communities locally and across the globe. Social Events (i.e., Annual Golf Tournament, Family Festival, Cooking Classes) BTI360 is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class. BTI360 is a drug-free workplace.",
        "url": "https://www.linkedin.com/jobs/view/3962234524",
        "summary": "BTI360 is seeking an MLOps engineer to join their ML team and build, deploy, and scale ML models. The role involves turning custom ML models into valuable enrichment services with web APIs, working with high-performance development teams leveraging modern technologies and practices, and supporting the team to build systems for cataloging, evaluating, monitoring, and publishing new ML capabilities. This position offers a competitive salary, benefits, and opportunities for career development.",
        "industries": [
            "Software Engineering",
            "Machine Learning",
            "Artificial Intelligence",
            "Cloud Computing",
            "DevOps",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem-solving",
            "Learning",
            "Passion",
            "Initiative",
            "Organization",
            "Time Management"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "YAML",
            "ML Model Hosting",
            "ML Model Packaging",
            "AWS Services",
            "CI/CD Automation",
            "Kubernetes",
            "Prompt Engineering",
            "Prompt Chaining",
            "RAG",
            "Hallucination Mitigation"
        ],
        "tech_stack": [
            "SageMaker",
            "NVidia Triton",
            "S3",
            "RDS",
            "DynamoDB",
            "Lambda",
            "Jenkins",
            "GitOps",
            "CodePipeline",
            "Kubeflow",
            "Metaflow",
            "mlflow",
            "Flyte",
            "Seldon Core",
            "ArgoCD",
            "Kubernetes",
            "Llama2",
            "Amazon Titan",
            "Claude 2",
            "Hugging Face"
        ],
        "programming_languages": [
            "Python",
            "Java"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Computer Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Fully paid healthcare premiums",
            "Competitive salaries with Performance Bonuses",
            "Career Development and In-house training",
            "Continuing Education: Annual Reimbursement Towards Education and Training",
            "5 Weeks of PTO plus 10 Federal Holidays",
            "401K Dollar for Dollar Matching up to 6% Annually - Vested immediately on day 1.",
            "Giving Back: Serving communities locally and across the globe.",
            "Social Events (i.e., Annual Golf Tournament, Family Festival, Cooking Classes)"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3954414720,
        "company": "MicroStrategy",
        "title": "Software Engineer",
        "created_on": 1720587083.1272564,
        "description": "Company Description Leading Products – Innovative Ideas – Exceptional People ….MicroStrategy, A Dynamic Place to Work! At MicroStrategy, we are passionate about creating powerful, disruptive technologies that transform how companies do business. Innovative products and ultimately our success are rooted in one driving force—our people. Our casual and flexible environment encourages creativity and collaboration, so you’ll have the opportunity to initiate and contribute to challenging projects, while pursuing your interests and developing, both professionally and personally. Bring us your passion, curiosity, and fresh ideas, and be a part of technology innovation at its best! Job Description Job Duties: Work within an agile development team and lead at an engineering level the design, development, testing, and debugging of software components and products. Proactively participate in every aspect of the entire life cycle of feature development, including input on requirements, designs, implementation, test design, test implementation, optimization, and delivery. Participate in peer code reviews, knowledge sharing, and SCRUM meetings. Take ownership of cross-team issues and product delivery issues including pro-actively communicating across teams to coordinate activities. Telecommuting is an option. Some travel to MicroStrategy, Inc.’s Tysons Corner, VA office is required. Minimum Requirements: Bachelor’s degree, or foreign equivalent, in Computer Science, Engineering, or closely related quantitative discipline, and six (6) months of experience in the job offered, or in any occupation in a related field. Special Skill Requirements: (1) JavaScript; (2) TypeScript; (3) Java; (4) C# & C++; (5) Jasmine; (6) Objective C; (7) Front-end Web Technologies; (8) Ruby; (9) CSS & HTML; (10) Gradle; (11) PostgreSQL; (12) React; (13) Python; (14) SAAS; (15) Ant; (15) Maven; and (16) Protractor. Any suitable combination of education, training and experience is acceptable. MicroStrategy is an Equal Opportunity & Affirmative Action Employer. Education, experience and criminal background checks will be conducted. Telecommuting is an option. Some travel to MicroStrategy, Inc.’s Tysons Corner, VA office is required. Submit a resume with references using the apply button on this posting or by email to: Req.# 20-1194 at onlinejobpostings@microstrategy.com. MicroStrategy is an Equal Opportunity & Affirmative Action Employer. Education, experience and criminal background checks will be conducted. Additional Information MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at application_accommodations@microstrategy.com. MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at application_accommodations@microstrategy.com.",
        "url": "https://www.linkedin.com/jobs/view/3954414720",
        "summary": "MicroStrategy is seeking a Software Engineer to lead the design, development, testing, and debugging of software components and products. This role requires experience in Agile development, cross-team communication, and ownership of product delivery. Telecommuting is an option, but some travel to Tysons Corner, VA is required.",
        "industries": [
            "Software Development",
            "Technology",
            "Business Intelligence",
            "Data Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Leadership",
            "Teamwork",
            "Ownership",
            "Proactive"
        ],
        "hard_skills": [
            "JavaScript",
            "TypeScript",
            "Java",
            "C#",
            "C++",
            "Jasmine",
            "Objective C",
            "Ruby",
            "CSS",
            "HTML",
            "Gradle",
            "PostgreSQL",
            "React",
            "Python",
            "SAAS",
            "Ant",
            "Maven",
            "Protractor"
        ],
        "tech_stack": [
            "JavaScript",
            "TypeScript",
            "Java",
            "C#",
            "C++",
            "Jasmine",
            "Objective C",
            "Ruby",
            "CSS",
            "HTML",
            "Gradle",
            "PostgreSQL",
            "React",
            "Python",
            "SAAS",
            "Ant",
            "Maven",
            "Protractor"
        ],
        "programming_languages": [
            "JavaScript",
            "TypeScript",
            "Java",
            "C#",
            "C++",
            "Objective C",
            "Ruby",
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Engineering",
                "Quantitative discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "District of Columbia, United States",
        "job_id": 3966750297,
        "company": "Harnham",
        "title": "Senior Data Scientist - TS/SCI Clearance",
        "created_on": 1720587084.528335,
        "description": "Job Title: Senior Data Scientist Location: Washington, DC Salary: $180-220k base + equity Eligibility: Must hold an active TS/SCI clearance Are you ready to make an impact in a pioneering AI start-up? We are seeking a talented Senior Data Scientist to join this dynamic team. About the Role: AI Platform Deployment: Utilize our advanced AI platform to deploy cutting-edge production solutions for clients. End-to-End Development: Manage the full lifecycle of AI solutions, from ideation to production, working closely with customer data. Big Data Integration: Develop customer solutions by integrating with big data frameworks like Databricks. Your Skills and Experience: Degree in Computer Science or a related field. Over 3 years of experience writing production-ready code in Python. 3+ years with the Python Data Stack including pandas, NumPy, scikit-learn, TensorFlow, PyTorch, and Matplotlib. At least 1 year of experience deploying machine learning models in production environments. 1-2 years of experience with SQL/NoSQL or other database systems (Elasticsearch, graph databases, etc.). 3 years of experience with Git or similar version control tools. 1 year of experience with Docker and/or Kubernetes. Exceptional written and verbal communication skills in English.",
        "url": "https://www.linkedin.com/jobs/view/3966750297",
        "summary": "Senior Data Scientist needed for an AI startup in Washington, DC.  This role involves deploying AI solutions for clients using the company's platform, managing the full AI solution lifecycle, and integrating with big data frameworks like Databricks. ",
        "industries": [
            "Artificial Intelligence",
            "Data Science",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Analytical Thinking",
            "Time Management"
        ],
        "hard_skills": [
            "Python",
            "Pandas",
            "NumPy",
            "Scikit-Learn",
            "TensorFlow",
            "PyTorch",
            "Matplotlib",
            "SQL",
            "NoSQL",
            "Elasticsearch",
            "Graph Databases",
            "Git",
            "Docker",
            "Kubernetes"
        ],
        "tech_stack": [
            "Databricks",
            "TensorFlow",
            "PyTorch",
            "Docker",
            "Kubernetes",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 220000,
            "min": 180000
        },
        "benefits": [
            "Equity"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3944679807,
        "company": "Belay Technologies",
        "title": "Junior Software Engineer",
        "created_on": 1720587086.086311,
        "description": "Belay Technologies has been voted Baltimore Business Journal's (BBJ) Best Places to Work 2019, runner up in 2020 and a finalist in 2021! Belay Technologies is seeking a Junior Software Engineer to join our intel team. As a member of a cross-functional team responsible for the development and maintenance of test cases; creation, execution and documentation of manual and automated tests; and working with software engineers, system engineers, platform engineers, system administrators, and other test engineers to validate development and maintenance activities. Duties include but are not limited to: Collaborating with software engineers to develop effective strategies and test cases Creating automated testing frameworks and test harnesses Discovering, reporting, and tracking testing defects Analyzing test results and reporting performance, load, and other issues using issues management tool Developing, executing, and maintaining acceptance, integration, and system tests Conduct post-release/ post-implementation testing Work with cross-functional teams to ensure quality throughout the software development life-cycle Perform continuous functional and regression testing. Candidates should have the following qualifications: TS/SCI Clearance with polygraph Bachelor's Degree or higher in computer engineering or in a field related to the computer engineering or computer science disciplines. An additional 4 years of Software Engineering experience may be substituted for the degree for a total of 7 years 3+ years of Software Engineering experience Candidates are desired to have the following skills: Experience designing, creating, and executing manual and automated testing solutions including analysis of results to determine adequacy of testing Experience testing in Windows and Linux/CentOS environments Working knowledge of test management software (e.g. behave!, SoapUI, Selenium, JUnit, JRunner, etc.) Experience with: Web communication protocols, i.e. JSON, REST, SOAP Scripting languages such as Goovy, Perl, Python,or Ruby Creating and managing cronjobs Working knowledge of: JAVA, Lightweight Directory Access Protocol, Public Key Infrastructure, version repositories (such as Git, SVN, CVS, etc.), and SQL Ability to work independently and as part of an Agile development team using superior time management to triage issues and prioritize tasks. Able to clearly communicate technical issues and ideas orally and written to superiors and subordinates across all engineering disciplines Perks and Benefits: 8 weeks paid leave - 4 weeks of personal leave, 3 Yay! days, take off on your birthday,11 paid holidays and optional leave up to 6 days through Belay's volunteer program 10% matching in 401(k) contributions vested on day one $5,000 annual training/tuition Student Loan Repayment Program 100% company-funded HSA Rich medical coverage (100% coinsurance) Dental coverage including orthodontia Up to $420,000 in life insurance, premiums 100% company funded Amazon Prime, gym reimbursement, monthly lunches, games and prizes Pet adoption program, generous referral bonus program, fun events, and more! Belay Technologies is a certified Service-Disabled Veteran-Owned Small Business located in Columbia, Maryland (Baltimore/Washington area). Belay Technologies specializes in systems automation and full stack development. Belay Technologies provides leading technology and engineering solutions to the DoD, as well as state-of-the-art commercial products. We hire software engineers, web designers, test engineers, systems engineers, systems administrators, database engineers and other tech services. We are an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law. Powered by JazzHR xjczpraXT6",
        "url": "https://www.linkedin.com/jobs/view/3944679807",
        "summary": "Belay Technologies seeks a Junior Software Engineer to join their intel team in developing and maintaining test cases. Responsibilities include collaborating with engineers, creating automated testing frameworks, discovering and reporting defects, analyzing results, and performing continuous testing. The ideal candidate possesses TS/SCI clearance with polygraph, a Bachelor's Degree or equivalent experience, 3+ years of Software Engineering experience, and strong skills in designing, creating, and executing manual and automated testing solutions. The company offers a comprehensive benefits package, including paid leave, 401(k) matching, training/tuition assistance, student loan repayment, HSA, medical/dental coverage, life insurance, and other perks.",
        "industries": [
            "Software Development",
            "Technology",
            "Engineering",
            "Defense",
            "Government",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Time Management",
            "Problem Solving",
            "Analytical Skills",
            "Teamwork",
            "Organization"
        ],
        "hard_skills": [
            "Manual Testing",
            "Automated Testing",
            "Test Case Development",
            "Test Management",
            "Defect Reporting",
            "Performance Testing",
            "Load Testing",
            "Regression Testing",
            "Integration Testing",
            "System Testing",
            "Acceptance Testing",
            "Post-Release Testing",
            "Windows",
            "Linux",
            "CentOS",
            "JSON",
            "REST",
            "SOAP",
            "Groovy",
            "Perl",
            "Python",
            "Ruby",
            "Cronjobs",
            "Java",
            "LDAP",
            "PKI",
            "Git",
            "SVN",
            "CVS",
            "SQL",
            "Agile Development"
        ],
        "tech_stack": [
            "Behave!",
            "SoapUI",
            "Selenium",
            "JUnit",
            "JRunner",
            "Git",
            "SVN",
            "CVS",
            "SQL",
            "Java",
            "LDAP",
            "PKI",
            "JSON",
            "REST",
            "SOAP",
            "Groovy",
            "Perl",
            "Python",
            "Ruby"
        ],
        "programming_languages": [
            "Java",
            "Groovy",
            "Perl",
            "Python",
            "Ruby",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Engineering",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "8 weeks paid leave",
            "4 weeks of personal leave",
            "3 Yay! days",
            "Take off on birthday",
            "11 paid holidays",
            "Optional leave",
            "Volunteer program",
            "10% 401(k) matching",
            "$5,000 annual training/tuition",
            "Student Loan Repayment Program",
            "100% company-funded HSA",
            "Rich medical coverage",
            "Dental coverage including orthodontia",
            "Up to $420,000 in life insurance",
            "Amazon Prime",
            "Gym reimbursement",
            "Monthly lunches",
            "Games and prizes",
            "Pet adoption program",
            "Generous referral bonus program",
            "Fun events"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3969060225,
        "company": "Jobot",
        "title": "Computer Vision/Robotics Engineer",
        "created_on": 1720587087.5826578,
        "description": "Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page! Job details Computer Vision/Robotics Engineer - $140k+ This Jobot Job is hosted by Charles Simmons Are you a fit? Easy Apply now by clicking the \"Easy Apply\" button and sending us your resume. Salary $110,000 - $140,000 per year A Bit About Us Well established Robotics/Manufacturing company is looking for a Robotics/Computer Vision Engineer. They will develop a variety of innovative computer vision detection, classification, localization, and tracking solutions for defense and commercial applications. Why join us? Competitive salary Great benefits Cutting edge technology Well established industry R&D Environment Job Details Computer vision Robotics C++/C Interested in hearing more? Easy Apply now by clicking the \"Easy Apply\" button. Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!",
        "url": "https://www.linkedin.com/jobs/view/3969060225",
        "summary": "Well established Robotics/Manufacturing company is looking for a Robotics/Computer Vision Engineer to develop a variety of innovative computer vision detection, classification, localization, and tracking solutions for defense and commercial applications.",
        "industries": [
            "Robotics",
            "Manufacturing",
            "Defense",
            "Technology"
        ],
        "soft_skills": [],
        "hard_skills": [
            "Computer Vision",
            "Robotics",
            "C++",
            "C"
        ],
        "tech_stack": [
            "Computer Vision",
            "Robotics"
        ],
        "programming_languages": [
            "C++",
            "C"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 140000,
            "min": 110000
        },
        "benefits": [
            "Competitive salary",
            "Great benefits",
            "Cutting edge technology",
            "Well established industry",
            "R&D Environment"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3926912790,
        "company": "Job Impulse, Inc.",
        "title": "Software Developer",
        "created_on": 1720587089.192338,
        "description": "ABOUT US Job Impulse, Inc. is an international recruitment company that focuses on upgrading the career opportunities of our candidates. We strive to create a professional partnership between our clients and contractors looking for their next career move. We have over 9,000 employees working in locations across twelve countries in fields ranging from industrial to office, marketing to engineering, technology, aerospace, medical, and more. JOB DESCRIPTION Job Impulse, Inc. has an immediate opening for a dedicated Software Developer to join our client's team of highly skilled engineers in Tysons Corner, VA . Our client is a leading provider of innovative analytics solutions, empowering federal agencies with actionable insights for informed decision-making and digital transformation. In this role, you will contribute to the development of AI applications, collaborating closely with teammates to solve complex problems. The selected candidate will receive comprehensive training and continuous professional development opportunities. Responsibilities includes : Collaborate with developers, staff, and leadership to design innovative solutions that address customer needs. Design, develop, and maintain technical solutions in alignment with project objectives. Enhance tools for users to analyze large-scale data effectively. Conduct debugging, troubleshooting, and modifications to software and solutions as needed. Develop technical documentation and user support guides to facilitate product understanding. Job Requirements : Top Secret SCI w/ CI Scope Poly Clearance or higher. Proficiency in JavaScript, Java, or other object-oriented programming languages. Hands-on experience and strong understanding of object-oriented programming, data structures, algorithms, profiling & optimization. Demonstrated passion for developing collaborative solutions to complex engineering challenges. REQUIRED Experience and Education: Demonstrated passion for developing collaborative solutions to complex engineering challenges. Bachelor’s degree in computer science or related field. **For immediate consideration, our Technical Specialist can be called at 864-509-6920 ext. 108 or texted at 864-565-7530. You can also email your resume directly to brandon.goodwin@job-impulse.us.com Conducting (drug screening and/or background check) report inquiries may be necessary for employment purposes. Job Impulse, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status Please be sure to carefully read through all requirements for the Software Developer as only serious applicants will be contacted. Unfortunately, not all candidates can be contacted who respond to this job, however we will reach out to you directly if your experience is determined match to the desired requirements. Thank you.",
        "url": "https://www.linkedin.com/jobs/view/3926912790",
        "summary": "Job Impulse, Inc. is seeking a Software Developer with Top Secret SCI w/ CI Scope Poly Clearance to join a leading provider of analytics solutions in Tysons Corner, VA. The role involves developing AI applications, collaborating with engineers, and enhancing tools for data analysis. The ideal candidate will have proficiency in JavaScript, Java, or other object-oriented languages, experience with data structures, algorithms, and optimization, and a passion for solving complex engineering problems.",
        "industries": [
            "Recruitment",
            "Technology",
            "Analytics",
            "Federal Government"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Passion for Development",
            "Teamwork"
        ],
        "hard_skills": [
            "JavaScript",
            "Java",
            "Object-Oriented Programming",
            "Data Structures",
            "Algorithms",
            "Profiling",
            "Optimization",
            "Debugging",
            "Troubleshooting",
            "Technical Documentation",
            "User Support"
        ],
        "tech_stack": [
            "AI Applications",
            "Analytics Solutions",
            "Data Analysis Tools",
            "Large-Scale Data"
        ],
        "programming_languages": [
            "JavaScript",
            "Java"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3907667786,
        "company": "Steneral Consulting",
        "title": "Hybrid Work - Need Sagemaker AI developer in Washington DC",
        "created_on": 1720587090.6083462,
        "description": "Sagemaker AI developer Location : Hybrid – DC facility near Union Station – could come to Fairfax, or MD other on site options Remote with biweekly meeting in DC currently – in future could move to 2 days a week on site Duration: 12+ mos Local candidates to DC Metro only PLEASE YOUR 1 BEST CANDIDATE MUST HAVE : Machine Learning, Sagemaker, SQL, AWS services AWS Services Preferred Such As Lambda, S3, And AppFlow Use Java Python Snoflake etc Responsibilities Develop AI and Generative AI models and solutions using AWS Sagemaker. Evaluate, select, implement, and support an enterprise data science toolkit, ensure that systems are reliable, scalable, and maintainable Build consensus around standards and best practices while ensuring alignment with enterprise principles Use statistical and machine learning techniques to analyze data and develop predictive models Communicate insights and findings to both technical and non-technical audiences Develop and deploy processes to automate data ingestion, preparation, model training, predictions, and data delivery Monitor the performance of machine learning models and make improvements as needed Discover the information hidden in vast amounts of data, and help with making smarter decisions to deliver even better products. Apply data mining techniques, perform statistical analysis, and build high quality prediction systems integrated with products. Explore, promote, and implement semantic data capabilities through Natural Language Processing, text analysis and Machine Learning techniques. Attend status and projects meetings to discuss, schedule, prioritize tasks, and report progress of projects Requirements Bachelor’s Degree in Computer Science or related field 3 years of experience in a Data Scientist or Machine Learning Engineer role required Must have more than one year of AWS Sagemaker experience. Experience with implementation of AWS Services preferred such as Lambda, S3, and AppFlow. Knowledge of SQL. Experience with Snowflake desirable. Proven track record of supporting high quality data science processes or applications Highly developed problem-solving and troubleshooting skills Ability to interact effectively with peers in a transparent manner Ability to perform various data sourcing, transformation, and storage tasks Knowledge of statistical based data analysis and developing machine learning models Extensive Python usage Experience with deploying and monitoring machine learning models",
        "url": "https://www.linkedin.com/jobs/view/3907667786",
        "summary": "This is a 12+ month contract position for a Sagemaker AI developer based in the DC metro area. The role involves building and deploying AI and Generative AI models using AWS Sagemaker, working with various AWS services like Lambda, S3, and AppFlow, and using technologies like Java, Python, and Snowflake. Ideal candidates will have 3+ years of experience as a Data Scientist or Machine Learning Engineer, with at least 1 year of AWS Sagemaker experience, strong SQL skills, and a proven track record in data science.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Cloud Computing",
            "Consulting"
        ],
        "soft_skills": [
            "Problem-solving",
            "Troubleshooting",
            "Communication",
            "Collaboration",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "Sagemaker",
            "SQL",
            "AWS",
            "Lambda",
            "S3",
            "AppFlow",
            "Java",
            "Python",
            "Snowflake",
            "Data Analysis",
            "Statistical Analysis",
            "Data Mining",
            "Natural Language Processing",
            "Text Analysis",
            "Data Ingestion",
            "Data Preparation",
            "Model Training",
            "Predictions",
            "Data Delivery",
            "Model Monitoring"
        ],
        "tech_stack": [
            "AWS Sagemaker",
            "AWS",
            "Lambda",
            "S3",
            "AppFlow",
            "Java",
            "Python",
            "Snowflake",
            "SQL"
        ],
        "programming_languages": [
            "Java",
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3943584451,
        "company": "Booz Allen Hamilton",
        "title": "Advanced Data Scientist, Lead",
        "created_on": 1720587091.89907,
        "description": "Job Number: R0199087 Advanced Data Scientist, Lead The Opportunity: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, you know the answers are in the data. We have an opportunity for you to use your analytical skills to conduct active surveillance of trends in different civil sector data, and assist the clients in their efforts to identify and assess exposure to fraud, waste, and abuse (FWA), and the impact of initiatives aimed at preventing or recovering improper payment. You’ll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You’ll build predictive analytics, use automation, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help senior leadership make informed decisions. You’ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us. The world can't wait. You Have: 6+ years of experience performing or leading data exploration, data cleaning, data analysis, machine learning, or data mining Experience using Python, R, and SQL Experience with data modeling, machine learning, data mining, statistics, or graph algorithms in academic or professional environments Experience conducting independent and collaborative research, summarizing your study, and applying your findings to client missions Ability to convey complex ideas clearly and concisely to various audiences Ability to obtain a security clearance Bachelor's degree Nice If You Have: Experience with identification, assessment, or remediation of FWA and program integrity initiatives for CMS Experience analyzing health plan data Knowledge of various CMS environments or systems such as One PI, Fraud Prevention System (FPS), Medicare Provider Enrollment, Chain, and Ownership System (PECOS), Integrated Data Repository (IDR), Chronic Conditions Warehouse (CCW), and CMS AWS Enclave Knowledge of Git and GitHub Knowledge of fraud modeling techniques Ability to rapidly evaluate scientific research on new and emerging technologies Possession of excellent verbal and written communication skills Possession of excellent client-facing or consulting skills Master's degree preferred, Doctorate degree a plus Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $110,100.00 to $250,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "url": "https://www.linkedin.com/jobs/view/3943584451",
        "summary": "Booz Allen Hamilton is seeking an Advanced Data Scientist, Lead to conduct active surveillance of trends in different civil sector data, and assist clients in identifying and assessing exposure to fraud, waste, and abuse (FWA). The ideal candidate will have 6+ years of experience in data exploration, data cleaning, data analysis, machine learning, and data mining, with experience using Python, R, and SQL.  They will also possess experience with data modeling, machine learning, data mining, statistics, or graph algorithms in academic or professional environments. This role offers competitive compensation, a variety of benefits, and opportunities for professional growth.",
        "industries": [
            "Data Science",
            "Analytics",
            "Consulting",
            "Government",
            "Healthcare"
        ],
        "soft_skills": [
            "Analytical Skills",
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Research",
            "Presentation",
            "Leadership",
            "Client-Facing",
            "Consulting"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Data Modeling",
            "Machine Learning",
            "Data Mining",
            "Statistics",
            "Graph Algorithms",
            "Git",
            "GitHub",
            "Fraud Modeling"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Machine Learning",
            "Data Mining",
            "Data Modeling",
            "Graph Algorithms",
            "Git",
            "GitHub",
            "Fraud Modeling",
            "AWS"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 250000,
            "min": 110100
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Dependent Care",
            "Recognition Awards",
            "Flexible Schedules",
            "Remote and Hybrid Work Locations"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3921571093,
        "company": "Booz Allen Hamilton",
        "title": "Supply Chain User Experience Data Scientist",
        "created_on": 1720587095.8721678,
        "description": "Job Number: R0197443 Supply Chain User Experience Data Scientist The Opportunity: As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, we need a seasoned data scientist like you to help find the answers in the data. On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide and mentor your team as you oversee the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. As a technical leader, you’ll identify new opportunities to use data science solutions to help your clients meet their toughest challenges. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used. Work with us as we use data science for good. Join us. The world can’t wait. You Have: 10+ years of experience with User Interface and User Experience (UI/UX) data science 10+ years of experience with the design of user-centric interfaces that align with DoD objectives for data-driven, predictive analysis 10+ years of experience with Agile methodologies to integrate UI/UX design processes within iterative development cycles 8+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining 8+ years of experience with statistical and general-purpose programming languages for data analysis, and analyzing structured and unstructured data sources Experience developing predictive data models, quantitative analyses, and visualization of targeted data sources Experience leading a team, including projects and deliverables, and leading the development of solutions to complex programs Experience with natural language processing, text mining, or machine learning techniques Top Secret clearance Bachelor’s degree Nice If You Have: Experience with the development of algorithms leveraging R, Python, or SQL/NoSQL Experience with distributed data or computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL Experience with machine learning, AI, or NLP Experience with visualization packages, including Plotly, Seaborn, or ggplot2 Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Top Secret clearance is required. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $110,100.00 to $250,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "url": "https://www.linkedin.com/jobs/view/3921571093",
        "summary": "Booz Allen Hamilton is seeking a Data Scientist with 10+ years of experience in UI/UX data science, user-centric interface design aligned with DoD objectives, and Agile methodologies. The ideal candidate will possess strong data exploration, cleaning, analysis, visualization, and mining skills, along with experience in statistical and general-purpose programming languages. Experience with predictive data models, quantitative analyses, natural language processing, and machine learning techniques is also required. Top Secret clearance is mandatory.",
        "industries": [
            "Government",
            "Defense",
            "Consulting",
            "Technology",
            "Data Science",
            "User Experience",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Leadership",
            "Communication",
            "Problem-solving",
            "Collaboration",
            "Mentoring",
            "Analytical",
            "Decision-making",
            "Strategic thinking",
            "Client-facing"
        ],
        "hard_skills": [
            "UI/UX Data Science",
            "User-Centric Interface Design",
            "Agile Methodologies",
            "Data Exploration",
            "Data Cleaning",
            "Data Analysis",
            "Data Visualization",
            "Data Mining",
            "Statistical Programming",
            "General-Purpose Programming",
            "Predictive Data Modeling",
            "Quantitative Analysis",
            "Natural Language Processing",
            "Text Mining",
            "Machine Learning",
            "R",
            "Python",
            "SQL/NoSQL",
            "MapReduce",
            "Hadoop",
            "Hive",
            "EMR",
            "Kafka",
            "Spark",
            "Gurobi",
            "MySQL",
            "Plotly",
            "Seaborn",
            "ggplot2"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SQL/NoSQL",
            "MapReduce",
            "Hadoop",
            "Hive",
            "EMR",
            "Kafka",
            "Spark",
            "Gurobi",
            "MySQL",
            "Plotly",
            "Seaborn",
            "ggplot2"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 250000,
            "min": 110100
        },
        "benefits": [
            "Health insurance",
            "Life insurance",
            "Disability insurance",
            "Financial benefits",
            "Retirement benefits",
            "Paid leave",
            "Professional development",
            "Tuition assistance",
            "Work-life programs",
            "Dependent care",
            "Flexible schedules",
            "Remote work",
            "Hybrid work"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Dunn Loring, VA",
        "job_id": 3910707758,
        "company": "ClearanceJobs",
        "title": "Data Scientist - All Levels with Security Clearance",
        "created_on": 1720587097.388077,
        "description": "About River Hawk River Hawk is a small business, focused on delivering management and technology consulting capabilities and solutions to the Federal Government. As a small business operating in cleared areas, River Hawk believes in promoting opportunities to drive your own career growth and trajectory. With minimal overhead and surprisingly generous benefits, River Hawk is able to pay at the top of the market. We are constantly looking for seasoned, driven professionals who have the desire to take challenges head on, continue to learn, and serve their clients well. Job Description: River Hawk is seeking a senior data scientists/analysts to help guide clients with strategic decision making: facilitating the collection and positioning of multiple data sets, identifying the customer's analytic needs, and developing the analytic capabilities and cadence. Requirements: Experience conveying complex technical topics to management and non-technical audiences Experience maintaining cooperative working relationships with customers and other employee (**NOTE** We are interested in hiring individuals with all skill levels - if you meet one of the following criteria we are willing to map out a career progression plan to develop skill sets and consequently increase salary over time) Experience modeling and documenting complex data/metadata structures, data flows, and models Experience creating visualizations with Tableau or comparable programs Demonstrated experience writing and modifying SQL Demonstrated experience with Apache Hive, Apache Spark, and HDFS or S3 Demonstrated expertise developing software using Neo4j, Python, or Java Knowledge of development tools such as Git, Jenkins, or Jira Experience/Education Requirements: 5-15 years of experience in a field related to data analysis Bachelors Degree (Preferred) Work Location: WMA Work from Home capability: No GROUP ID: 91122765",
        "url": "https://www.linkedin.com/jobs/view/3910707758",
        "summary": "River Hawk, a small business focused on government consulting, is seeking senior data scientists/analysts to guide clients in strategic decision-making. Responsibilities include data collection, analysis, and developing analytic capabilities.  They are open to hiring individuals with various skill levels and offer career progression plans to develop skills and increase salary.",
        "industries": [
            "Management Consulting",
            "Technology Consulting",
            "Government",
            "Federal Government"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Decision Making",
            "Strategic Thinking",
            "Client Management",
            "Relationship Building"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Modeling",
            "Data Visualization",
            "SQL",
            "Apache Hive",
            "Apache Spark",
            "HDFS",
            "S3",
            "Neo4j",
            "Python",
            "Java",
            "Git",
            "Jenkins",
            "Jira",
            "Tableau"
        ],
        "tech_stack": [
            "Tableau",
            "Apache Hive",
            "Apache Spark",
            "HDFS",
            "S3",
            "Neo4j",
            "Python",
            "Java",
            "Git",
            "Jenkins",
            "Jira"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelors Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Analytics",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Generous Benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3966012244,
        "company": "Cyrten",
        "title": "(Req: 302-24) Python Software Engineer",
        "created_on": 1720587100.4088285,
        "description": "Location: McLean, VA Clearance: TS/SCI Full Scope Polygraph (active) Remote/Hybrid/Onsite: 100% Onsite work (non-negotiable) Type: Full-Time/Direct-Hire Ball Park Salary Figures Skill Level Desired Years Exp Software Engineer Subject Matter Expert $ 250k Software Engineer Expert $ 220k Software Engineer Senior $ 180k Software Engineer Full Performance $ 140k In Bid/Vacant: Vacant Note: Available Immediately & Benefits posted below Seeking a Software Engineer for a long-term program supporting an IC customer in Chantilly, VA. This position requires an active TS/SCI full-scope polygraph clearance. Introduction The Software Engineer will provide development support for a program involving data science, data engineering, and analysts in a cloud computing environment. They will be responsible for designing, developing, coding, testing, and debugging complex new software products and enhancements to existing software. Collaboration with cross-functional teams and providing recommendations for continuous improvement and innovation in an Agile environment are also key aspects of the role. Support the design, development, coding, testing, and debugging of complex new software products Apply software development methodology in an Agile environment Troubleshoot and provide solutions for complex problems in software systems and applications Collaborate cross-functionally with data scientists, data engineers, analysts, and other technical team members Provide recommendations for continuous improvement and innovation in an Agile environment Role Demonstrated experience developing solutions with Python and SQL. Demonstrated experience with AWS Services and Cloud-based development. Experience working in Agile (Sprint or Kanban) development environments. Demonstrated experience developing complex software products. Nice To Have Demonstrated experience developing solutions for data science teams. Demonstrated experience developing code with Visual Studio Code or similar IDE. Demonstrated experience supporting Natural Language Processing (NLP) pipelines. Demonstrated experience supporting information extraction or Named Entity Recognition (NER), including using regular expressions or SpaCy. Demonstrated experience with XML parsing. Demonstrated experience with data labeling with solutions such as Doccano, Skweak, or Snorkel. Demonstrated experience with data science document classification techniques. Demonstrated experience developing solutions with Elasticsearch. Salary The posted salaries are ballpark figures. You know the salary range you are looking for, so let's talk after you fill out the application. Benefits Our client is always looking for TS/SCI FSP Information Technology talent. The standard compensation package includes a competitive salary, 100% company-paid health/dental/vision care benefits, 100% company-paid LTD/STD/Life Insurance benefits, a 401(k) with company match, and a generous holiday/vacation/sick leave policy. Note No 3rd party vendors or candidates US Citizenship Required Active TS/SCI - FSP is Required",
        "url": "https://www.linkedin.com/jobs/view/3966012244",
        "summary": "Seeking a Software Engineer with active TS/SCI full-scope polygraph clearance to support a program involving data science, data engineering, and analytics in a cloud computing environment. Responsibilities include designing, developing, coding, testing, debugging complex new software products and enhancements to existing software. Requires experience with Python, SQL, AWS Services, Cloud-based development, and Agile development.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Data Science",
            "Cloud Computing",
            "Intelligence"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Continuous Improvement",
            "Innovation"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "AWS Services",
            "Cloud-based development",
            "Agile development",
            "Visual Studio Code",
            "Natural Language Processing (NLP)",
            "Information Extraction",
            "Named Entity Recognition (NER)",
            "Regular Expressions",
            "SpaCy",
            "XML Parsing",
            "Data Labeling",
            "Doccano",
            "Skweak",
            "Snorkel",
            "Document Classification",
            "Elasticsearch"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "AWS",
            "Visual Studio Code",
            "NLP",
            "SpaCy",
            "Elasticsearch",
            "Doccano",
            "Skweak",
            "Snorkel"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 250000,
            "min": 140000
        },
        "benefits": [
            "Competitive salary",
            "100% company-paid health/dental/vision care benefits",
            "100% company-paid LTD/STD/Life Insurance benefits",
            "401(k) with company match",
            "Generous holiday/vacation/sick leave policy"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3934828806,
        "company": "DPR Solutions Inc",
        "title": "Python Developer (with strong PL SQL Experience)",
        "created_on": 1720587101.8193865,
        "description": "Role: Python Developer PL/SQL Duration: 6+ months with possibility of extension Location: Arlington VA Skill Set Required 6-10+ Years of experience MS SQL Server. In-depth knowledge in Stored Procedures(development and debugging), Python coding AWS Lambda functions knowledge Greetings !! For More Details & Immediate Response Contact - https://www.linkedin.com/in/saisreenca/",
        "url": "https://www.linkedin.com/jobs/view/3934828806",
        "summary": "Python Developer with PL/SQL expertise needed for a 6+ month contract in Arlington, VA. The role requires 6-10 years of experience, strong MS SQL Server skills, Stored Procedure development and debugging, Python coding, and AWS Lambda function knowledge.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Consulting"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Debugging"
        ],
        "hard_skills": [
            "MS SQL Server",
            "Stored Procedures",
            "Python",
            "AWS Lambda",
            "Debugging"
        ],
        "tech_stack": [
            "MS SQL Server",
            "AWS Lambda",
            "Python"
        ],
        "programming_languages": [
            "Python",
            "PL/SQL"
        ],
        "experience": 6,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3959555390,
        "company": "Noblis",
        "title": "Software Developer (All Levels)",
        "created_on": 1720587103.7269356,
        "description": "Responsibilities Noblis is seeking a technical thinker and doer to work as a Software Developer within a highly dynamic and impactful operating environment located in McLean, VA. The Software Developer Will Design, develop, and maintain applications including new applications development, modifications of existing applications, and transition of legacy applications to new technologies. Analyze user needs and software requirements to determine design feasibility. Ensure for the proper configuration and change management. Collaborate with customers, analysts, engineers, and others to obtain system performance requirements and interfaces. Design and develop database management systems, image processing capabilities, collaborative tools, data manipulation and visualization techniques; and access control services and interfaces. Design and develop tools for operating system platforms; Design and develop tools that integrate with commercial applications. Develop and execute unit and functional test plans; Develop and execute software system testing and validation procedures and programming, and document test results. Modify existing software to correct errors, allow it to adapt to new hardware, or to improve its performance. Perform or direct revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements. Prepare appropriate configuration and change management documentation that provides the detailed workflow and diagrams that describe input, output, and logical operation. Provide database architectural and design capabilities. Provide operations and maintenance of operational systems. Develop or contribute to the development of user instructions or manuals. Required Qualifications Active TS/SCI with Polygraph. Understanding of software testing and quality assurance best practices. Experience with the Software Development Lifecycle (SDLC). Proficient with git, and pull request workflows. Ability to learn and work on different parts of a software stack. Familiar with Agile development methodologies and working in an agile setting. Experience with scripting, including PowerShell, Bash, or Python Experience with relational databases and administration, including SQL Server or PostgreSQL Experience working in cloud environments and leveraging various computing resources such as GPU clusters and cloud-based compute servers. Experience with database schema design, query optimization, scaling, and backups. Programming knowledge in languages such as Python, SQL, Java. Experience working with Docker, Kubernetes Experience performing extract, transform, load (ETL) development for data pipelines. Ability to perform API service development. Demonstrated experience working with IC Agencies. Knowledge of IC systems, processes, data, and policies. Knowledge and application of agile techniques and methodologies. Experience mentoring or training (through formal or informal means) members of the team. Skill Levels Senior Expert (SME): Bachelor’s Degree in associated field and 14+ years of relevant experience; Master’s Degree in associated field and 11+ years of relevant experience; PhD and 10+years of relevant experience. Compensatoin $151,700 - $237,050 Expert: Bachelor’s Degree in associated field and has 10+ years of relevant experience; Master’s Degree and 9+ years of relevant experience; PhD and 8+ years of relevant experience. Compensation $125,500 - $196,075 Senior: Bachelor’s Degree in associated field and has 6+ years of relevant experience; Master’s Degree and 5+ years of relevant experience; PhD and 4+ years of relevant experience. Compensation $114,100 - $178,300 Junior: Bachelor’s Degree in associated field and 1+ years of relevant experience. Compensation $70,800 - $133,750 Desired Qualifications Strong communication skills, written and verbal. Overview Noblis and our wholly owned subsidiaries, Noblis ESI , and Noblis MSD tackle the nation's toughest problems and apply advanced solutions to our clients' most critical missions. We bring the best of scientific thought, management, and engineering expertise together in an environment of independence and objectivity to deliver enduring impact on federal missions. Noblis works with a wide range of government clients in the defense, intelligence and federal civil sectors. Learn more at Noblis -About Us Why work at a Noblis company? Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public. Noblis has won numerous workplace awards . Noblis maintains a drug-free workplace. Salary Range Explanation At Noblis we recognize and reward your contributions, provide you with growth opportunities, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, and work-life programs. Our award programs acknowledge employees for exceptional performance and superior demonstration of our service standards. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in our benefit programs. Other offerings may be provided for employees not within this category. We encourage you to learn more about our total benefits by visiting the Benefits page on our Careers site. Salary at Noblis is determined by various factors, including but not limited to, the combination of education, certifications, knowledge, skills, competencies, and experience, internal and external equity, location, and clearance level, as well as contract-specific affordability and organizational requirements and applicable employment laws. The projected compensation range for this position is provided within the posting and are based on full time status. Part time staff receive a prorated salary based on regularly scheduled hours. The estimated minimum and maximum displayed represents the broadest range for this position (inclusive of high geographic and high clearance requirements), and is just one component of Noblis’ total compensation package for employees. Posted Salary Range USD $70,800.00 - USD $237,050.00 /Yr. Equal Employment Opportunity Noblis is an Equal Opportunity Employer. Employment decisions are made without regard to race (as well as because of or on the basis of traits historically associated with race, including hair texture, hair type, and protective hairstyles such as braids, locks, and twists), color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, pregnancy, childbirth, lactation and related medical conditions, genetic factors, military/veteran status, or other characteristics protected by law. Noblis is committed to the full inclusion of all qualified individuals. As part of this commitment, Noblis will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact employee-relations@noblis.org .",
        "url": "https://www.linkedin.com/jobs/view/3959555390",
        "summary": "Noblis is seeking a Software Developer with a TS/SCI security clearance to work in McLean, VA. The role involves designing, developing, and maintaining applications, analyzing user needs, collaborating with various teams, and ensuring proper configuration and change management. Experience with Agile methodologies, scripting languages, relational databases, cloud environments, and various technologies like Docker, Kubernetes, and ETL is required. This is a senior-level position with a salary range of $70,800 to $237,050 depending on experience and qualifications.",
        "industries": [
            "Defense",
            "Intelligence",
            "Federal Civil"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem Solving",
            "Analytical Skills",
            "Collaboration",
            "Self-Motivation",
            "Adaptability",
            "Organizational Skills",
            "Time Management"
        ],
        "hard_skills": [
            "Software Development",
            "Application Development",
            "Software Testing",
            "Quality Assurance",
            "Software Development Lifecycle",
            "Git",
            "Agile Methodologies",
            "PowerShell",
            "Bash",
            "Python",
            "Relational Databases",
            "SQL Server",
            "PostgreSQL",
            "Cloud Environments",
            "GPU Clusters",
            "Cloud-Based Compute Servers",
            "Database Schema Design",
            "Query Optimization",
            "Scaling",
            "Backups",
            "Docker",
            "Kubernetes",
            "ETL Development",
            "API Development",
            "IC Systems",
            "IC Processes",
            "IC Data",
            "IC Policies",
            "Agile Techniques",
            "Mentoring",
            "Training"
        ],
        "tech_stack": [
            "Git",
            "PowerShell",
            "Bash",
            "Python",
            "SQL Server",
            "PostgreSQL",
            "Docker",
            "Kubernetes",
            "ETL"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "Java"
        ],
        "experience": 14,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Computer Science",
                "Software Engineering",
                "Information Technology",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 237050,
            "min": 70800
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Award Programs",
            "Drug-Free Workplace"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3940396011,
        "company": "Cynet Systems",
        "title": "Data Scientist Lead - Remote / Telecommute",
        "created_on": 1720587105.6850395,
        "description": "Job Description: Essential Function: 20% Leads all data mining and extraction activities and applies algorithms to derive insights. 15% Synthesizes analytical findings for consumption by the teams and senior executives. 15% Leads proliferation of machine learning and artificial intelligence solutions. 15% Applies artificial intelligence techniques to achieve concrete business goals while managing limited resources and constraints around data. 15% Mentors and develops junior data scientists for advanced data analysis. 10% Translates business priorities and creates data science deliverables. 10% Leads implementation of Client/AI/DS best practices for new data products and builds robust and scalable software. Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Bachelor's Degree. Statistics, Mathematics, Computer Science or related field. Experience: 8 years of relevant work experience. In lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience. Knowledge, Skills and Abilities (KSAs): Ability to communicate effectively and document objectives and procedures., Expert Ability to leverage a wide variety of data science tools and frameworks., Expert Ability to support data exploration and data analysis tasks in support of analytics objectives., Expert Knowledge in model evaluation, tuning and performance, operationalization, and scalability of scientific techniques., Expert Proficiency in statistical modeling applications., Expert Proficiency in advanced SQL in multiple syntaxes., Expert Proficiency in AWS Ecosystem and tools. Experience working as an AI/Client Engineer.",
        "url": "https://www.linkedin.com/jobs/view/3940396011",
        "summary": "This role leads all data mining and extraction activities, applies algorithms to derive insights, synthesizes analytical findings, leads machine learning and AI solutions, and translates business priorities into data science deliverables. Requires 8 years of experience and proficiency in data science tools, frameworks, and statistical modeling.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Leadership",
            "Mentoring",
            "Problem Solving",
            "Collaboration",
            "Strategic Thinking",
            "Presentation",
            "Project Management"
        ],
        "hard_skills": [
            "Data Mining",
            "Data Extraction",
            "Algorithm Development",
            "Machine Learning",
            "Artificial Intelligence",
            "Statistical Modeling",
            "Model Evaluation",
            "Model Tuning",
            "Model Performance",
            "Model Operationalization",
            "Model Scalability",
            "SQL",
            "AWS",
            "AI/Client Engineering"
        ],
        "tech_stack": [
            "AWS"
        ],
        "programming_languages": [
            "SQL"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Statistics",
                "Mathematics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3959297100,
        "company": "ICF",
        "title": "Software Developer - AI/Machine Learning - Remote",
        "created_on": 1720587109.6216986,
        "description": "We are seeking an experienced mid-level software developer who is passionate about artificial intelligence, machine learning, and large language models. As a software developer, you will be responsible for designing and implementing innovative solutions that address complex problems using cutting-edge technologies. You will work with a team of experts in AI, machine learning, and natural language processing to develop and implement solutions that meet the needs of our ICF employees. The ideal candidate will have a strong background in both .NET and Python, with experience in developing and deploying scalable applications. You will be expected to have a deep understanding of these programming languages and be able to use them effectively to develop, optimize, and deploy AI and machine learning models and processes. Additionally, you should have experience with cloud-based platforms such as AWS, Azure, or GCP, and be familiar with containerization technologies such as Docker and Kubernetes. At our organization, we value continuous learning and encourage our team members to stay up-to-date with the latest advancements in AI and machine learning. As such, we are looking for someone who is passionate about learning new technologies and exploring new ways to solve complex problems. ICF has deep relationships with commercial businesses that will get you up to speed with the most cutting-edge technologies re: AI/ML and LLMs. If you are a self-starter with a strong work ethic and a desire to make a meaningful impact, we encourage you to apply for this exciting opportunity. A Day in the Life at ICF This position will be part of the Corporate IT department and the AI Engineer will be expected to: Interact with ICF employees to understand processes, pain points, etc. Understand the ICF landscape and be able to recommend solutions that are in ICF’s best interest Create functional requirements based on user interviews Translate functional requirements into technical requirements Work with a team of analysts, BI engineers, infrastructure engineers, InfoSec and other IT experts. Participate in Scrum process to implement solutions in an agile manner Create user stories and tasks that break down technical requirements Estimate LOE for tasks Report out on daily status updates and roadblocks Languages .NET - Core, Framework (mid-level expertise) Python - LangChain, Pinecone, OpenAI (mid-senior level expertise in Python in general) JavaScript - Angular, React, Vue (junior-mid level expertise in some flavor/vanilla) Database - SQL, mongo, cosmos (or some combination of structured and unstructured) Azure - Web Apps, Containers, Storage, OpenAI, Cognitive Services (or comparable AWS/GCP) Basic Qualifications 5+ years hands-on experience in .NET solutions and/or other enterprise development language(s) 3+ years hand-on experience in Python, Jupyter or Restful API. 3+ years hands-on experience with neural networks, machine learning algorithms, etc. 3+ years hands-on experience with structured/unstructured databases 1+ years hands-on experience with Large Language Models (OpenAI, LaMDA, StableLM, LLaMA, PaLM, or related large language model.) Preferred Qualifications B.S. in Computer Science or equivalent technical field Experience with MS Power Platform, Azure. Experience working with MS SQL, Stored Procedures, data extraction, data transformation, and data loading. Strong initiative, solid judgment, and a desire to continually grow their technical knowledge. Experience with technology skills including .NET framework/core, JavaScript/jQuery, and PowerShell scripting. Strong understanding of SDLC concepts and experience in Agile/Scrum project methodologies Professional Skills Excellent written and verbal communication skills. Work well independently as well as part of a team. Strong analytical and problem-solving skills. Self-motivated, with the ability to work efficiently and productively. Qualified candidates may be asked to provide samples of their work. Working at ICF ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future. We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO & AA policy. Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email icfcareercenter@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about workplace discrimination rights, the Pay Transparency Statement, or our benefit offerings which are included in the Transparency in (Benefits) Coverage Act. Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position based on full-time employment is: $102,285.00 - $173,884.00 Nationwide Remote Office (US99)",
        "url": "https://www.linkedin.com/jobs/view/3959297100",
        "summary": "ICF is seeking an experienced mid-level software developer with expertise in AI, machine learning, and large language models to design and implement innovative solutions. The ideal candidate will have strong .NET and Python skills, experience with cloud platforms (AWS, Azure, GCP), containerization technologies (Docker, Kubernetes), and a passion for continuous learning in AI and ML. They will work with a team of experts to develop solutions for ICF employees.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Analytical",
            "Collaboration",
            "Self-motivation",
            "Work Ethic",
            "Passionate about Learning",
            "Continuous Learning",
            "Initiative",
            "Judgment",
            "Teamwork"
        ],
        "hard_skills": [
            ".NET",
            "Python",
            "LangChain",
            "Pinecone",
            "OpenAI",
            "JavaScript",
            "Angular",
            "React",
            "Vue",
            "SQL",
            "MongoDB",
            "Cosmos",
            "Azure",
            "Web Apps",
            "Containers",
            "Storage",
            "Cognitive Services",
            "AWS",
            "GCP",
            "Docker",
            "Kubernetes",
            "Neural Networks",
            "Machine Learning Algorithms",
            "Large Language Models",
            "OpenAI",
            "LaMDA",
            "StableLM",
            "LLaMA",
            "PaLM",
            "MS Power Platform",
            "MS SQL",
            "Stored Procedures",
            "Data Extraction",
            "Data Transformation",
            "Data Loading",
            "PowerShell"
        ],
        "tech_stack": [
            ".NET",
            "Python",
            "LangChain",
            "Pinecone",
            "OpenAI",
            "JavaScript",
            "Angular",
            "React",
            "Vue",
            "SQL",
            "MongoDB",
            "Cosmos",
            "Azure",
            "Web Apps",
            "Containers",
            "Storage",
            "OpenAI",
            "Cognitive Services",
            "AWS",
            "GCP",
            "Docker",
            "Kubernetes"
        ],
        "programming_languages": [
            ".NET",
            "Python",
            "JavaScript"
        ],
        "experience": 5,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Computer Science",
                "Technical"
            ]
        },
        "salary": {
            "max": 173884,
            "min": 102285
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Bethesda, MD",
        "job_id": 3914280106,
        "company": "SAIC",
        "title": "AI Engineer",
        "created_on": 1720587111.1511075,
        "description": "Job ID 2406042 Location BETHESDA, MD, US Date Posted 2024-06-04 Category Information Technology Subcategory Data Scientist Schedule Full-time Shift Day Job Travel No Minimum Clearance Required TS/SCI With Poly Clearance Level Must Be Able to Obtain None Potential for Remote Work No Description SAIC, a leading provider of systems development & deployment, targeting & intelligence analysis, systems engineering & integration, and training capabilities and solutions for the Intelligence Community, is seeking creative and dedicated professionals to fulfill their career goals and objectives while delivering mission excellence on programs of national importance. SAIC is seeking a Artificial Intelligence Engineer to support a fast-paced, dynamic environment supporting the development of AI Policy and capabilities. In this role, you will work closely with Intel government customers and IT developers to create artifacts for IA Architecture and IA Security based on experience and real world considerations. This position will be a subject matter expert, creating and translating trend analyses, and facilitate stakeholder decision-making, policy, and governance pertaining to current and emerging AI technology. The ideal candidate will Be an expert in the field of artificial intelligence (AI) with an in depth knowledge of AI architecture and development. Translate highly technical concepts into policy and governance documents. Have in depth experience with collaborating with various IC Partners on policy and governance. Have an expertise in one or more o the following subfields, or similar subfield AI engineering, data engineering, or emerging technology. Be forward-leaning, recommending necessary improvements to achieve the customer’s vision. Qualifications Required Active TS/SCI with CI Polygraph. Bachelors and fourteen (14) years or more of related experience; Masters and twelve (12) years or more experience; PhD or JD and nine (9) years or more experience. Experience creating documentation around AI governance for existing and emerging AI technology. 5+ years collaborating with various Intel Community (IC) partners including non-DoD IC elements on information sharing. Experience creating high-level and highly technical documents on AI Policy and governance. Experience in at least one of the following fields AI development, AI architecture, AI policy, data engineering, AI legal policy and emerging technology, data architecture, and/or library science. Experience with AI Assurance, AI security, and/or AI Privacy. Desired Skills Power BI or other BI software. Experience with Python development. Experience with R, Tableau, or other data visualization/analytical software. SAIC accepts applications on an ongoing basis and there is no deadline. Covid Policy SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.",
        "url": "https://www.linkedin.com/jobs/view/3914280106",
        "summary": "SAIC is seeking an Artificial Intelligence Engineer to support the development of AI Policy and capabilities. The role involves working with Intel government customers and IT developers to create artifacts for IA Architecture and IA Security. The ideal candidate will be an expert in AI with experience in AI architecture and development, translating technical concepts into policy and governance documents, and collaborating with IC partners on policy and governance. Expertise in AI engineering, data engineering, or emerging technology is desired. The position requires a TS/SCI with CI Polygraph and experience in AI governance, IC collaboration, and AI development or related fields.",
        "industries": [
            "Information Technology",
            "Intelligence",
            "Government",
            "Defense",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Decision Making",
            "Leadership",
            "Analytical Thinking",
            "Strategic Thinking",
            "Policy Analysis",
            "Technical Writing",
            "Presentation Skills",
            "Project Management",
            "Time Management",
            "Teamwork"
        ],
        "hard_skills": [
            "Artificial Intelligence (AI)",
            "AI Architecture",
            "AI Development",
            "AI Governance",
            "AI Policy",
            "Data Engineering",
            "Emerging Technology",
            "Information Sharing",
            "Documentation",
            "AI Assurance",
            "AI Security",
            "AI Privacy",
            "Power BI",
            "Python Development",
            "R",
            "Tableau",
            "Data Visualization",
            "Data Analysis"
        ],
        "tech_stack": [
            "Python",
            "Power BI",
            "R",
            "Tableau"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 14,
        "education": {
            "min_degree": "Bachelors",
            "fields": [
                "Computer Science",
                "Engineering",
                "Information Technology",
                "Data Science",
                "Policy",
                "Law"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3913970667,
        "company": "SAIC",
        "title": "AI Engineer",
        "created_on": 1720587112.5591638,
        "description": "Job ID 2406005 Location CHANTILLY, VA, US Date Posted 2024-07-01 Category Information Technology Subcategory Cloud Comp Engr Schedule Full-time Shift Day Job Travel Yes, 10 % of the Time Minimum Clearance Required TS/SCI With Poly Clearance Level Must Be Able to Obtain None Potential for Remote Work No Description SAIC is seeking a AI/ Artificial intelligence Engineer Subject Matter Expert to provide SETA support to SAIC’s Program, Landmark in Chantilly, VA. Landmark is a large SETA program, supporting the NRO’s Ground Enterprise Directorate (GED), responsible for the acquisition of systems over the complete end-to-end life cycle. Active Top Secret/SCI with CI Poly is required for this role. As a AI/ Artificial intelligence Engineer Subject Matter Expert, you will you will develop and deploy machine learning models and have a strong programming background. You will also work closely with data scientists and software engineers to implement AI solutions that meet program requirements. We are seeking candidates with experience in AI development and deployment. Responsibilities include, but are not limited to the following Develop AI algorithms and models to support project objectives. Collaborate with data scientists and software engineers on AI projects. Conduct data analysis and prepare reports on AI performance. Stay updated on AI trends and technologies to drive innovation. Qualifications Required Education and Experience Bachelors and five (5) years or more experience; Masters and three (3) years or more experience; PhD and 0 years related experience. Relevant experience to be substituted in lieu of degree. Active Top Secret/SCI with Poly Experience in AI development and deployment. Experience with Python, Java, C++, R, or similar for AI development. Proficiency in machine learning frameworks such as TensorFlow or PyTorch. Strong analytical and problem-solving skills. Ability to communicate technical concepts to non-technical stakeholders. SAIC accepts applications on an ongoing basis and there is no deadline. Covid Policy SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.",
        "url": "https://www.linkedin.com/jobs/view/3913970667",
        "summary": "SAIC seeks an AI/Artificial intelligence Engineer Subject Matter Expert to support the NRO’s Ground Enterprise Directorate (GED). This role involves developing and deploying machine learning models, collaborating with data scientists and software engineers, and staying updated on AI trends. Active Top Secret/SCI with CI Poly is required. The ideal candidate has experience in AI development and deployment, programming languages like Python, Java, C++, R, and familiarity with frameworks like TensorFlow or PyTorch.",
        "industries": [
            "Aerospace & Defense",
            "Information Technology",
            "Government"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Analytical"
        ],
        "hard_skills": [
            "Machine Learning",
            "AI Development",
            "AI Deployment",
            "Data Analysis",
            "TensorFlow",
            "PyTorch",
            "Python",
            "Java",
            "C++",
            "R"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "Python",
            "Java",
            "C++",
            "R"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C++",
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelors",
            "fields": [
                "Computer Science",
                "Data Science",
                "Artificial Intelligence",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Springfield, VA",
        "job_id": 3889627258,
        "company": "Guidehouse",
        "title": "Senior Data Scientist (Geospatial Focus)",
        "created_on": 1720587116.5949466,
        "description": "Job Family Data Science Consulting Travel Required None Clearance Required Active Top Secret SCI (TS/SCI) What You Will Do Work with a team to support an IC Agency office with exploitation and production activities and process/data optimization. Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data Develop and implement strategies for optimizing data processes and databases, including the exposure of new datasets, migration of legacy datasets, visualization of data, or faster querying of data Build custom tools/solutions to automate analytic endeavors Develop best practice tradecraft techniques that are repeatable and can be explained to users What You Will Need An ACTIVE and CURRENT TOP SECRET/SCI federal security clearance Bachelor's Degree THREE (3)+ years' of experience supporting Department of Defense (DoD), Intel Community (IC), or federal customers Experience with Python, R, or Visual Basic Experience with more than one (1) of the following tools to visualize data: ArcGIS, SPSS, SAS, MatLab, R Experience with more than one(1) of the following tools to maintain and manipulate data: SQL databases, ArcServer, NoSQL DBMS, Tableau, Insights, Oracle Understanding of concepts associated with structured data and relationship databases What Would Be Nice To Have Familiarity with IC, CENTCOM, and PACOM missions Experience using mathematical concepts and techniques to solve complex GEOINT analysis problem sets Military experience Professional certifications or advanced degrees What We Offer Guidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace. Benefits Include Medical, Rx, Dental & Vision Insurance Personal and Family Sick Time & Company Paid Holidays Position may be eligible for a discretionary variable incentive bonus Parental Leave and Adoption Assistance 401(k) Retirement Plan Basic Life & Supplemental Life Health Savings Account, Dental/Vision & Dependent Care Flexible Spending Accounts Short-Term & Long-Term Disability Student Loan PayDown Tuition Reimbursement, Personal Development & Learning Opportunities Skills Development & Certifications Employee Referral Program Corporate Sponsored Events & Community Outreach Emergency Back-Up Childcare Program Mobility Stipend About Guidehouse Guidehouse is an Equal Employment Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender, gender identity or expression, age, genetic information, or any other basis protected by law, ordinance, or regulation. Guidehouse will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law or ordinance including the Fair Chance Ordinance of Los Angeles and San Francisco. If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting at 1-571-633-1711 or via email at RecruitingAccommodation@guidehouse.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation. Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.",
        "url": "https://www.linkedin.com/jobs/view/3889627258",
        "summary": "Data Scientist consultant at Guidehouse supporting an IC Agency office with data exploitation and production activities, optimizing processes and databases. Responsibilities include querying, visualizing, aggregating, correlating, analyzing big data, building custom tools, and developing best practice tradecraft techniques.",
        "industries": [
            "Consulting",
            "Data Science",
            "Intelligence",
            "Defense",
            "Federal Government"
        ],
        "soft_skills": [
            "Teamwork",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Data Analysis",
            "Data Visualization",
            "Process Optimization"
        ],
        "hard_skills": [
            "Python",
            "R",
            "Visual Basic",
            "SQL",
            "ArcGIS",
            "SPSS",
            "SAS",
            "MatLab",
            "ArcServer",
            "NoSQL",
            "Tableau",
            "Insights",
            "Oracle"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Visual Basic",
            "SQL",
            "ArcGIS",
            "SPSS",
            "SAS",
            "MatLab",
            "ArcServer",
            "NoSQL",
            "Tableau",
            "Insights",
            "Oracle"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Visual Basic"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Rx",
            "Dental",
            "Vision Insurance",
            "Sick Time",
            "Holidays",
            "Variable Incentive Bonus",
            "Parental Leave",
            "Adoption Assistance",
            "401(k)",
            "Life Insurance",
            "Health Savings Account",
            "Flexible Spending Accounts",
            "Short-Term & Long-Term Disability",
            "Student Loan PayDown",
            "Tuition Reimbursement",
            "Skills Development",
            "Certifications",
            "Employee Referral Program",
            "Corporate Sponsored Events",
            "Community Outreach",
            "Emergency Back-Up Childcare Program",
            "Mobility Stipend"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3940060391,
        "company": "E-volve Technology Systems",
        "title": "Application Developer",
        "created_on": 1720587118.0185778,
        "description": "Reston, VA 20190 Security Clearance Requirement: TS/SCI CI Poly Location Note: On-Site Support Required Position Description: E-volve Technology Systems is hiring a junior-mid level Developer to work in support of an Intelligence Community program. The Developer will join a small team supporting web database development, testing, and modernization with heavy scripting and a back-end focus. Qualified candidates will have prior experience supporting one or more modernization/upgrade efforts and the ability to untangle the codes from earlier iterations. The Developer will support scalable architecture, code complexity, and object-oriented languages for high reusability and maintainability. This is a dynamic work environment providing an ambitious developer with an opportunity to collaborate with teammates and solve unique challenges. Duties and Responsibilities: Develop scalable applications and backend services using appropriate software design patterns to attain high reusability and maintainability Create and monitor system design patterns and tiered architecture Testing of products, system architecture and design Solve complex problems by applying best practices to: Provide direction Work with project business and systems Analyze requirements and execute Participate in code reviews Enforce standards and best practices Education and qualifications: U.S. citizenship Current TS/SCI security clearance Current CI polygraph or ability to obtain CI polygraph Bachelor's degree in a related discipline preferred; additional years of related experience will be considered in lieu of a degree 3+ years of object-oriented programming including: PHP development experience SQL and relational database experience Effective written and verbal communication skills DoD 8570.1 compliance at IAT Level I (Security+ or similar) Excellent customer service skills and interest in working in a fast-paced environment Ability to implement design patterns and coding best practices Experience with PostgreSQL relational databases Experience with Python and Perl is a plus Ability to read scripts and analyze an application for modernization Experience supporting the front end and middle layers with emphasis on the back end Availability to support on-site schedule in Reston E-volve Technology Systems, Inc. provides Mission Operations, Information Technology Management, and Intelligence Analysis support services to advance National Security and other Federal Government programs within the Department of Defense (DoD), Intelligence, and Civilian government agencies. For more information please visit us at www.e-volvetechsystems.com. E-volve Technology Systems, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. We comply with Form I-9 identity and legal work authorization requirements for Employment Eligibility Verification in accordance the Immigration Reform and Control Act of 1986 (IRCA). E-volve Technology Systems, Inc. offers fair and competitive compensation and benefits to all eligible employees. Salaries are dependent upon a wide range of factors including position requirements, customer/program needs, individual qualifications, education, experience, certification and/or training, location, and other job-related factors. Please email any questions to: recruiting@e-volvetechsystems.com Powered by JazzHR Mk5H9RQFcq",
        "url": "https://www.linkedin.com/jobs/view/3940060391",
        "summary": "E-volve Technology Systems is seeking a Junior-Mid level Developer to support an Intelligence Community program. The role involves web database development, testing, and modernization with a heavy focus on scripting and back-end development. The ideal candidate will have experience in modernization/upgrade efforts, understanding complex codebases, and implementing scalable architecture using object-oriented languages. Responsibilities include developing applications and backend services, creating and monitoring system design patterns, testing products and systems, solving complex problems, participating in code reviews, and enforcing standards and best practices.",
        "industries": [
            "Information Technology",
            "Intelligence",
            "Government",
            "Defense",
            "National Security"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Customer Service",
            "Teamwork",
            "Analytical"
        ],
        "hard_skills": [
            "PHP",
            "SQL",
            "PostgreSQL",
            "Python",
            "Perl",
            "Object-Oriented Programming",
            "Scalable Architecture",
            "System Design",
            "Code Review",
            "Testing",
            "Design Patterns",
            "Coding Best Practices",
            "Script Analysis",
            "Database Development",
            "Modernization"
        ],
        "tech_stack": [
            "PHP",
            "SQL",
            "PostgreSQL",
            "Python",
            "Perl"
        ],
        "programming_languages": [
            "PHP",
            "SQL",
            "Python",
            "Perl"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Related Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Compensation",
            "Benefits Package"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3959124271,
        "company": "NiSUS Technologies Corporation",
        "title": "TS007SWE0 - Entry Software Engineer - Cleared",
        "created_on": 1720587119.4929981,
        "description": "Analyze user requirements to derive software design and performance requirements Debug existing software and correct defects Provide recommendations for improving documentation and software development process standards Design and code new software or modify existing software to add new features Integrate existing software into new or modified systems or operating environments Develop simple data queries for existing or proposed databases or data repositories Requirements TS/SCI with poly required No demonstrated experience is required Bachelor's degree in Computer Science or related discipline from an accredited college or university is required Four (4) years of SWE experience on projects with similar software processes may be substituted for a bachelor's degree One (1) or more years of JavaScript programming experience and development of presentation tiers Familiarity with Java and Spring desired Experience designing and writing REST-ful applications Experience writing Interface Control Documents (ICDs) Experience with Microsoft office tools (Word, Excel, Powerpoint) Experience programming on Linux platforms Experience using one or more of the following revision control applications: git, Subversion (SVN), CVS, ClearCase Experience with test driven development Benefits Health & Life Insurance Dental Insurance Disability Insurance 401K Retirement Plan with Matching Tuition Assistance Vacation and Sick Leave Hiring Bonuses Referral Recruitment Program",
        "url": "https://www.linkedin.com/jobs/view/3959124271",
        "summary": "This job posting is for a Software Engineer with experience in JavaScript, Java, Spring, and RESTful applications. The role involves analyzing user requirements, debugging software, providing recommendations for improvements, designing and coding new features, integrating software, developing data queries, and working on projects with similar software processes. The candidate will be working on Linux platforms and using revision control applications like Git, SVN, CVS, or ClearCase.",
        "industries": [
            "Software Development",
            "Information Technology",
            "Engineering"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Analytical Thinking",
            "Time Management",
            "Attention to Detail",
            "Critical Thinking"
        ],
        "hard_skills": [
            "JavaScript",
            "Java",
            "Spring",
            "RESTful Applications",
            "Linux",
            "Git",
            "SVN",
            "CVS",
            "ClearCase",
            "Test Driven Development",
            "Microsoft Office",
            "Word",
            "Excel",
            "PowerPoint"
        ],
        "tech_stack": [
            "JavaScript",
            "Java",
            "Spring",
            "RESTful APIs",
            "Linux",
            "Git",
            "SVN",
            "CVS",
            "ClearCase"
        ],
        "programming_languages": [
            "JavaScript",
            "Java"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Related discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health & Life Insurance",
            "Dental Insurance",
            "Disability Insurance",
            "401K Retirement Plan with Matching",
            "Tuition Assistance",
            "Vacation and Sick Leave",
            "Hiring Bonuses",
            "Referral Recruitment Program"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Alexandria, VA",
        "job_id": 3922255528,
        "company": "Motion Recruitment",
        "title": "Data Scientist (TS/SCI Full-Scope Poly)",
        "created_on": 1720587120.932013,
        "description": "A large federal consulting company in Washington, DC that just won a multi-year engagement is looking to add a Senior Data Scientist who can help with researching LLM and help implement them within their environment. Ideal candidates must have an active FSP and come from a Data Science background. Required Skills & Experience Active TS/SCI Full-Scope Poly Python (ML Libraries) SQL Modeling and simulation Algorithm development LLM and NLP The Offer Competitive Salary Full-Health Benefits You Will Receive The Following Benefits Medical Insurance Dental Benefits Vision Benefits Paid Time Off (PTO) 401(k) Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Posted By: Derek Progin",
        "url": "https://www.linkedin.com/jobs/view/3922255528",
        "summary": "A large federal consulting firm in Washington, DC is seeking a Senior Data Scientist with an active TS/SCI Full-Scope Poly clearance. The role involves researching and implementing Large Language Models (LLMs) within their environment. Candidates must have a strong Data Science background with expertise in Python (ML Libraries), SQL, modeling, simulation, algorithm development, and LLM/NLP.",
        "industries": [
            "Consulting",
            "Federal Government",
            "Data Science",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [],
        "hard_skills": [
            "Python",
            "SQL",
            "Modeling",
            "Simulation",
            "Algorithm Development",
            "LLM",
            "NLP"
        ],
        "tech_stack": [
            "Python (ML Libraries)",
            "SQL",
            "LLM",
            "NLP"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental Benefits",
            "Vision Benefits",
            "Paid Time Off (PTO)",
            "401(k)"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3951451384,
        "company": "Arcfield",
        "title": "Data Scientist/Architect",
        "created_on": 1720587122.6618178,
        "description": "Overview Arcfield is a leading provider of full lifecycle, mission-focused systems engineering and integration capabilities to the U.S. government and its allies. The company has more than 60 years of proven experience providing advanced engineering and analysis, IT and C5ISR capabilities to support our nation’s most critical national security missions. Headquartered in Chantilly, VA and with 16 offices around the world, Arcfield employs approximately 1,200 engineers, analysts, IT specialists, and other professionals who put our customers’ missions first, helping them solve their most complex challenges through innovations in modeling, simulation and analysis, digital transformation and C5ISR. Visit arcfield.com for more details. Responsibilities The Data Scientist/Architect will support the Sponsor’s Program Management Office (PMO), responsible for championing data management, governance, accessibility, and quality. The selected candidate will be responsible for providing technical leadership, integration, and programmatic engineering support across multiple fabrics and IC Partner infrastructures, as well as collaborating with NRESP Architect lead and engineering team in designing the modernization of legacy systems. The Data Scientist/Architect will support the Customer in organizing, analyzing, and storing data in compatible formats to enable solutions, which can be repeatedly designed and deployed in a consistent, high-quality, and supportable fashion. This will consist of working with multiple stakeholders in various groups to define, develop, and institutionalize a strategic data framework across multi-fabric information environments. The individual will also be responsible for working with Internal and External stakeholders in supporting a highly visible and highly paced project that leverages engineering management principles. Analyzing, defining, and documenting requirements for data, workflow, logical processes, hardware and operating system environment, and network connectivity, other systems interfaces, internal and external checks and controls, and outputs Developing architectural guidance for applications developers, defining target platforms, interface designs, development patterns and styles, and development languages and tools. Develops and presents substantive technical recommendations to senior management. Providing technical expertise in systems architecture; participates in the formulation of network engineering practices; assesses feasibility of system plans; collaborates with varying IC Partners to establish priorities and implement plans that adhere to established strategic business and system objectives Developing and presenting complex technical documents, procedures, reports, and briefings Providing enterprise-wide perspective into IT-related decisions. Providing systems architecture knowledge and consultation to Sponsor components, and assist in technical reviews and architecture designs, assessment of technical solutions to business needs. Development of technical concepts of system operations for Sponsor components’ requirements, system designs, and system architectures Defining system architectures, developing roadmaps, and identifying planned changes that impact the system. Identifying gaps in capabilities and strategic needs in relation to the strategic direction Identifying opportunities for strengthening, streamlining, and standardizing the architecture Working with multiple stakeholders in defining requirements and resolving discrepancies between proposed IT systems and enterprise quality and security standards. Demonstrated knowledge of and experience with C2S/AWS services and Agile methodologies Knowledge of Oracle databases and their migration Experience with design/implementation of APIs Knowledge of Cataloging capabilities Experience with development of architecture artifacts. Familiarity with/awareness of ontologies, benefits/constraints. Familiarity with Cloud Service Providers (CSPs) network architecture Familiarity with ServiceNow, SharePoint (Creative Cloud), JIRA. Qualifications Required Qualifications: Must possess and be able to maintain a TS/SCI with a polygraph BS 12-15, MS 10-13, PhD 8-10 (or equivalent experience) in Computer Science, Information Systems, Engineering, Business, or a scientific or technical discipline Knowledge of industry data standards and architectures. Examples may include: Knowledge of complex databases, circuit boards, processors, chips, electronic equipment, and computer hardware and software, including applications and programming Knowledge of design and integration principles for complex databases Experience in identifying measures or indicators of system performance and the actions needed to improve or correct performance, relative to the goals of the system Ability to evaluate and make recommendations regarding data integrity Ability to recommend data management policies, standards, practices, and security measures Desired Qualifications A Master's degree (or equivalent experience) in a field related to the position 15 years of experience 3 years of experience in the Intelligence Community Knowledge of Intelligence Community missions, needs, and information sharing requirements Ability to work in a dynamic and challenging environment Strong oral and written communications and interpersonal skills Ability to convey technical information to non-technical individuals EEO Statement EEO Arcfield proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active-Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.",
        "url": "https://www.linkedin.com/jobs/view/3951451384",
        "summary": "Arcfield is seeking a Data Scientist/Architect to support the Sponsor’s Program Management Office (PMO). The candidate will be responsible for providing technical leadership, integration, and programmatic engineering support across multiple fabrics and IC Partner infrastructures. They will also be responsible for working with stakeholders to define, develop, and institutionalize a strategic data framework across multi-fabric information environments. The candidate will have experience with C2S/AWS services, Agile methodologies, Oracle databases, API design/implementation, cataloging capabilities, and cloud service providers (CSPs). ",
        "industries": [
            "Government",
            "Defense",
            "Intelligence"
        ],
        "soft_skills": [
            "Technical Leadership",
            "Communication",
            "Interpersonal Skills",
            "Problem-Solving",
            "Collaboration",
            "Teamwork",
            "Presentation Skills",
            "Organizational Skills",
            "Analytical Skills",
            "Decision Making"
        ],
        "hard_skills": [
            "Data Management",
            "Data Governance",
            "Data Accessibility",
            "Data Quality",
            "Systems Integration",
            "Programmatic Engineering",
            "Data Architecture",
            "Data Modeling",
            "Data Analysis",
            "Data Storage",
            "Data Standardization",
            "C2S/AWS Services",
            "Agile Methodologies",
            "Oracle Databases",
            "API Design",
            "API Implementation",
            "Cataloging Capabilities",
            "Cloud Service Providers",
            "Network Architecture",
            "ServiceNow",
            "SharePoint",
            "JIRA"
        ],
        "tech_stack": [
            "C2S/AWS Services",
            "Oracle Databases",
            "APIs",
            "ServiceNow",
            "SharePoint",
            "JIRA",
            "Agile Methodologies"
        ],
        "programming_languages": [],
        "experience": 15,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Computer Science",
                "Information Systems",
                "Engineering",
                "Business",
                "Scientific or Technical Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3857149116,
        "company": "SAIC",
        "title": "CBRN Defense Data Scientist",
        "created_on": 1720587124.123029,
        "description": "Job ID 2403875 Location WASHINGTON, DC, US Date Posted 2024-03-13 Category Information Technology Subcategory Data Scientist Schedule Full-time Shift Day Job Travel Yes, 10 % of the Time Minimum Clearance Required Secret Clearance Level Must Be Able to Obtain Top Secret Potential for Remote Work No Description SAIC has an immediate opening for a Chemical, Biological, Radiological, and Nuclear (CBRN) Defense Data Scientist supporting the Headquarters Air Force Deputy Chief of Staff for Strategic Deterrence and Nuclear Integration (AF/A10), Countering Weapons of Mass Destruction (CWMD) Division (AF/A10S), Operational Analysis Branch (AF/A10SA), on behalf of Air Force Installation Management Support Center (AFIMSC) and United States Air Force Europe-Air Force Africa (USAFE-AFAFRICA). Work will be performed onsite at the Pentagon or Joint Base Anacostia-Bolling. Responsibilities include Serve as a CWMD (and nuclear effects when required) modeler to model complex systems which include CBRN agent effects and attributes in different situations (i.e., varying weather, release mechanisms and parameters) overlaid over differing major combat operations (MCO) related operational environments. Extracting data from CBRN-related modeling programs through post processing utilities to provide analysts user-friendly data tables and graphics to depict complexities such as toxicity effects over time, degradation of agent strength, and contaminated area coverage as a function of time. Develop and use batch programs that enable HAF/A10SA to complete thousands of CBRN-related hazard runs (HPAC, VLSTRACK, HOTSPOT, etc.) without having to execute each run on a one-by-one basis. Use computer modeling to support technical analysis to address questions that arise in the CWMD operations (non-proliferation, targeting, interdiction, strike, counter-air/space actions) arena of USAFE-AFAFRICA ability to survive and operate (ATSO), and CBRN defense technical domains. Use computer modeling to support technical research and operational evaluations to assess, interpret, shape, and help advise AF/A10S, on behalf of AFIMSC and USAFE-AFAFRICA, regarding what operational and scientific testing results mean to operators (e.g., pilot, navigator, aircrew, loadmasters, maintainers, defenders). Qualifications Required Skills Top Secret clearance with the ability to obtain an SCI Subject matter expert in computer programming for MCO-related modeling of CBRN materials (HPAC, VLSTRACK, HOTSPOT, etc.) and analyzing complex systems (Python, C++, Visual Basic, etc.). Specialized expertise in providing modeling support for technical analysis of CBRN threats. Excellent oral and written communication skills. Proficiency with MS Office products. Ability to work from alternate, off-site locations as required. Desired Experience/Skills History of incorporating results of lab or field analysis of CBRN-related tests into modeling programs to support CBRN-related studies. History of developing unique tools to assist analysts interpret and utilize raw data within analytical projects. Typical Education And Experience Bachelors and fourteen (14) years or more experience; Masters and twelve (12) years or more experience; PhD or JD and nine (9) years or more experience. Target salary range $150,001 - $175,000. The estimate displayed represents the typical salary range for this position based on experience and other factors. SAIC accepts applications on an ongoing basis and there is no deadline. Covid Policy SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.",
        "url": "https://www.linkedin.com/jobs/view/3857149116",
        "summary": "SAIC seeks a Data Scientist with expertise in Chemical, Biological, Radiological, and Nuclear (CBRN) defense modeling for the Headquarters Air Force. You'll model complex CBRN systems, extract data for analysis, develop automated programs, and support technical research and operational evaluations. This position requires a Top Secret clearance with SCI eligibility and experience with CBRN modeling programs like HPAC, VLSTRACK, and HOTSPOT. Strong programming skills (Python, C++, Visual Basic) are essential, along with excellent communication and proficiency with MS Office products.",
        "industries": [
            "Defense",
            "Aerospace",
            "Military",
            "Government",
            "Information Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Decision Making",
            "Research",
            "Collaboration",
            "Teamwork"
        ],
        "hard_skills": [
            "CBRN",
            "Modeling",
            "HPAC",
            "VLSTRACK",
            "HOTSPOT",
            "Python",
            "C++",
            "Visual Basic",
            "Data Analysis",
            "Technical Writing",
            "MS Office",
            "Data Visualization"
        ],
        "tech_stack": [
            "HPAC",
            "VLSTRACK",
            "HOTSPOT",
            "Python",
            "C++",
            "Visual Basic"
        ],
        "programming_languages": [
            "Python",
            "C++",
            "Visual Basic"
        ],
        "experience": 14,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering",
                "Mathematics",
                "Physics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 175000,
            "min": 150001
        },
        "benefits": [
            "Secret Clearance",
            "Top Secret Clearance",
            "SCI",
            "Travel",
            "Remote Work"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Springfield, VA",
        "job_id": 3924293393,
        "company": "TENICA Global Solutions",
        "title": "Senior Data Scientist TS/SCI CI poly",
        "created_on": 1720587125.9370036,
        "description": "TENICA is looking to hire a Senior Data Scientist in Springfield, VA. MUST HAVE TS/SCI with CI poly. Develop and conduct algorithm quality trade studies related to synthetic aperture radar imagery, identifying best use cases for selected algorithms, and characterizing performance of algorithms when used outside the best use case scenarios. Prototype an analytical procedure that will generate confidence values based on algorithm outputs. Refine the verification and validation process for analytics. Enhance existing models to leverage analytic output for driving automated tasking. Develop scripts for running and testing the algorithms and analytics, using programs such as Databricks, Python, and Jupyter Notebook. Make presentations and reports at the request of the government in addition to a task kick off, midpoint review, and final report and presentation. Experience in at least two of the following areas is required: Mathematics/Statistics; Computer Science; Domain Expertise/ Analysis; and Presentation.9 years of experience and a MA/MS degree. In place of the degree, may substitute 19 years of relevant work experience. Desirable skills and experience include synthetic aperture radar image science or analysis; other remote sensing imaging such as multispectral; programming and script development; data science; Python, Databricks, Jupyter Notebook; Intelligence Community analytical workflows.",
        "url": "https://www.linkedin.com/jobs/view/3924293393",
        "summary": "TENICA seeks a Senior Data Scientist with TS/SCI with CI poly clearance to conduct algorithm quality trade studies on synthetic aperture radar imagery, prototype confidence value generation, refine analytics V&V, enhance models for automated tasking, and develop scripts using Databricks, Python, and Jupyter Notebook.  Experience in Mathematics/Statistics, Computer Science, Domain Expertise/Analysis, and Presentation is required. 9 years of experience and a MA/MS degree (or 19 years of experience) are needed. Desirable skills include SAR image science, other remote sensing, programming, data science, Python, Databricks, Jupyter Notebook, and IC analytical workflows.",
        "industries": [
            "Aerospace",
            "Defense",
            "Intelligence",
            "Government",
            "Data Science",
            "Remote Sensing",
            "Software Development"
        ],
        "soft_skills": [
            "Presentation",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Teamwork",
            "Collaboration"
        ],
        "hard_skills": [
            "Synthetic Aperture Radar (SAR)",
            "Algorithm Development",
            "Algorithm Evaluation",
            "Confidence Value Generation",
            "Verification and Validation (V&V)",
            "Model Enhancement",
            "Automated Tasking",
            "Scripting",
            "Databricks",
            "Python",
            "Jupyter Notebook",
            "Mathematics",
            "Statistics",
            "Computer Science",
            "Domain Expertise"
        ],
        "tech_stack": [
            "Databricks",
            "Python",
            "Jupyter Notebook"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 9,
        "education": {
            "min_degree": "MA/MS",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Domain Expertise"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Gaithersburg, MD",
        "job_id": 3944342549,
        "company": "GeneDx",
        "title": "Staff Machine Learning Engineer",
        "created_on": 1720587127.5187001,
        "description": "GeneDx is seeking an exceptional Staff Machine Learning Engineer / AI Engineer to spearhead the development of generative AI applications to automate aspects of genetic testing business. In this role, you will leverage your expertise in Large Language Models (LLMs), machine learning, and product development to create a generative AI system for automating genetic test writing, insurance claim reports, clinical document understanding, and/or literature mining and recommendations. Responsibilities: Independent Project Leadership : Take the lead in architecting and developing a state-of-the-art ML pipeline or agent-based system that utilizes LLMs and context-aware tools to generate genetic test reports. Project Management : Manage small project-specific teams to develop and maintain data preprocessing, feature engineering, and model training pipelines. Research and Development : Research, evaluate, and implement various LLMs and ML techniques to optimize the system's performance and output quality independently. Collaboration : Collaborate with the clinical staff to incorporate domain-specific knowledge and ensure the accuracy and relevance of the generated reports. NLP Techniques Implementation : Independently implement advanced NLP techniques such as named entity recognition, sentiment analysis, and text summarization to enhance report generation. Performance Monitoring and Improvement : Independently monitor, analyze, and improve the system's performance based on user feedback and advancements in ML and LLM technologies. ML Infrastructure Development : Contribute independently to the development of a robust, scalable, and secure ML infrastructure. Other Duties : Independently handle other duties as assigned. Requirements: Advanced Degree : Advanced degree in Computer Science, Machine Learning, or a related field. Experience : Extensive experience in developing and deploying ML/AI-based systems independently. Technical Skills : Strong independent expertise in Python, natural language processing (NLP), and large language models (LLMs). LLM Libraries : Experience with LLM libraries such as LangChain, Llama Index, Instructor, DsPy, Outlines, or Instructor. Vector Databases : Experience with Vector Databases such as Chroma, Weaviate, PineCone. Deep Learning Frameworks : Proficiency in deep learning frameworks such as TensorFlow, PyTorch, Keras, HuggingFace. Additional Skills : Experience with fine-tuning LLMs, Kubernetes, model serving technologies, ML experiment tracking (e.g., CometML, Weights and Biases). Soft Skills : Excellent problem-solving, analytical, and communication skills. Ability to work independently in a fast-paced, innovative environment. Domain Knowledge : Knowledge of genetics or experience in the healthcare domain is a plus. Pay Transparency, Budgeted Range $229,581—$275,494 USD ~ Science - Minded, Patient - Focused. At GeneDx, we create, follow, and are informed by cutting-edge science. With over 20 years of expertise in diagnosing rare disorders and diseases, and pioneering work in the identification of new disease-causing genes, our commitment to genetic disease detection, discovery, and diagnosis is based on sound science and is focused on enhancing patient care. Experts in what matters most. With hundreds of genetic counselors, MD/PhD scientists, and clinical and molecular genomics specialists on staff, we are the industry's genetic testing experts and proud of it. We share the same goal as healthcare providers, patients, and families: to provide clear, accurate, and meaningful answers we all can trust. SEQUENCING HAS THE POWER TO SOLVE DIAGNOSTIC CHALLENGES. From sequencing to reporting and beyond, our technical and clinical experts are providing guidance every step of the way: TECHNICAL EXPERTISE High-quality testing: Our laboratory is CLIA certified and CAP accredited and most of our tests are also New York State approved. Advanced detection: By interrogating genes for complex variants, we can identify the underlying causes of conditions that may otherwise be missed. CLINICAL EXPERTISE Thorough analysis: We classify variants according to our custom adaptation of the most recent guidelines. We then leverage our rich internal database for additional interpretation evidence. Customized care: Our experts review all test results and write reports in a clear, concise, and personalized way. We also include information for research studies in specific clinical situations. Impactful discovery: Our researchers continue working to find answers even after testing is complete. Through both internal research efforts and global collaborations, we have identified and published hundreds of new disease-gene relationships and developed novel tools for genomic data analysis. These efforts ultimately deliver more diagnostic findings to individuals. Learn more About Us here. ~ Benefits include: Paid Time Off (PTO) Health, Dental, Vision and Life insurance 401k Retirement Savings Plan Employee Discounts Voluntary benefits GeneDx is an Equal Opportunity Employer. All privacy policy information can be found here.",
        "url": "https://www.linkedin.com/jobs/view/3944342549",
        "summary": "GeneDx seeks a Staff Machine Learning Engineer to develop generative AI applications for automating genetic testing processes. Responsibilities include building an ML pipeline using LLMs to generate test reports, managing project teams, researching and implementing ML techniques, collaborating with clinical staff, and monitoring system performance. Ideal candidate has an advanced degree in CS/ML, extensive experience in developing and deploying ML/AI systems, expertise in Python, NLP, and LLMs, and familiarity with LLM libraries (LangChain, Llama Index, etc.), vector databases (Chroma, Weaviate, etc.), deep learning frameworks (TensorFlow, PyTorch, etc.), fine-tuning LLMs, Kubernetes, model serving technologies, and ML experiment tracking tools. Additional skills include problem-solving, analytical, and communication skills. Domain knowledge of genetics or healthcare is a plus. Salary range: $229,581 - $275,494 USD.",
        "industries": [
            "Healthcare",
            "Biotechnology",
            "Genetics",
            "Artificial Intelligence",
            "Machine Learning",
            "Software Development"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Communication",
            "Collaboration",
            "Independent work",
            "Project management"
        ],
        "hard_skills": [
            "Python",
            "Natural language processing (NLP)",
            "Large language models (LLMs)",
            "LangChain",
            "Llama Index",
            "Instructor",
            "DsPy",
            "Outlines",
            "Chroma",
            "Weaviate",
            "PineCone",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "HuggingFace",
            "Fine-tuning LLMs",
            "Kubernetes",
            "Model serving technologies",
            "ML experiment tracking"
        ],
        "tech_stack": [
            "LLMs",
            "Generative AI",
            "Machine learning",
            "Natural language processing (NLP)",
            "Python",
            "LangChain",
            "Llama Index",
            "Instructor",
            "DsPy",
            "Outlines",
            "Chroma",
            "Weaviate",
            "PineCone",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "HuggingFace",
            "Kubernetes",
            "Model serving technologies",
            "ML experiment tracking"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's degree",
            "fields": [
                "Computer Science",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 275494,
            "min": 229581
        },
        "benefits": [
            "Paid Time Off (PTO)",
            "Health, Dental, Vision and Life insurance",
            "401k Retirement Savings Plan",
            "Employee Discounts",
            "Voluntary benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3735358028,
        "company": "Executive Staff Recruiters / ESR Healthcare",
        "title": "Data scientist ft Meade md",
        "created_on": 1720587128.9567697,
        "description": "Company Profile esrhealthcare.com.mysmartjobboard.com Data scientist ft Meade md Experience level: Mid-senior Experience required: 15 Years Education level: Bachelor’s degree Job function: Information Technology Industry: Information Technology and Services Compensation: $151,000 - $180,000 Total position: 1 Relocation assistance: Yes Visa sponsorship eligibility: No Security Clearance: Active TS/SCI Full Scope Poly is required at the time of hire. a Data Science consulting firm specialized in providing analytic solutions to clients in Commercial and Government industries. Providing analytic solutions to hundreds of companies across numerous industries, our team enjoys a great variety in the type of work they do and exposure to a wide range of techniques and tools. We are trusted advisors to our clients, building lasting relationships and partnering as preferred analytics providers. We use a variety of programming languages and tools to create analytic solutions, often fitting within our clients’ environment and needs. Join our team and find great opportunities to hone your analytic skills, work on complex problems with amazing teammates, and gain valuable analytics consulting experience. Summary of Position: The Data Scientist produces high quality, professional, and innovative solutions to complex and technologically advanced AI problems. Recognized as an AI expert by peers and customers. Works on the forefront of new AI technologies. Job Specifications/Requirements: Develops and executes cutting-edge research programs to create and then experimentally prove innovative and effective solutions to complex AI technical problems. Directs a team of engineers and/or scientists to implement solutions to complex AI technical problems. U) Fifteen (15) years' experience and a Bachelor's degree in Engineering, Computer Science, or Science, Technology, Engineering, or Mathematics (STEM) or thirteen (13) years' and a Master's degree or ten (10) years' and a PhD. Powered by Webbtree",
        "url": "https://www.linkedin.com/jobs/view/3735358028",
        "summary": "Data Scientist with 15+ years of experience to develop and execute research programs, create innovative solutions to complex AI problems, and direct a team of engineers and scientists.",
        "industries": [
            "Information Technology and Services",
            "Consulting",
            "Government"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Leadership"
        ],
        "hard_skills": [
            "AI",
            "Machine Learning",
            "Deep Learning",
            "Data Analysis",
            "Research",
            "Modeling",
            "Algorithm Development",
            "Software Development"
        ],
        "tech_stack": [
            "AI",
            "Machine Learning",
            "Deep Learning"
        ],
        "programming_languages": [],
        "experience": 15,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Engineering",
                "Computer Science",
                "STEM"
            ]
        },
        "salary": {
            "max": 180000,
            "min": 151000
        },
        "benefits": [
            "Relocation Assistance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3965630716,
        "company": "Alldus",
        "title": "ML Ops Engineer",
        "created_on": 1720587130.6198912,
        "description": "Our client are an AI-driven company based in Virginia and they are hiring a ML Ops Engineer to join their team on a remote basis. The successful candidate will play a pivotal role in building, deploying and maintaining the company’s advanced AI infrastructure. Responsibilities: As the ML Ops Engineer, you will work alongside data scientists, software engineers and subject matter experts to develop top-tier AI solutions for the government relations sector. You will design, deploy and maintain a robust ML infrastructure, ensuring seamless delivery of AI solutions for complex challenges. Continuously enhance and optimize their AI systems, keeping pace with the latest advancements in technology. Qualifications: Master’s degree in computer science, statistics or similar. At least 3 years of experience in AI deployment, MLOps, DevOps or data engineering, working on large-scale projects in AWS. Proficiency in containerized applications or microservices using Docker and Kubernetes. Extensive experience deploying AI solutions using frameworks like TensorFlow, PyTorch or Transformers. Familiarity with CI/CD or DevOps frameworks such as Jenkins, GitHub Actions, and Argo CD. Knowledge of cloud infrastructure provisioning or configuration tools like CloudFormation, Terraform, Pulumi and Ansible. Strong programming skills in Python, TypeScript and SQL. Experience integrating DevSecOps practices throughout the project lifecycle. TS/SCI Clearance is a plus. Experience working in a hypergrowth startup. Salary: $220k – $300k DOE Interested? Apply now! Simply uploaded your resume through the link below and one of our recruiters will be in touch if you’re a match. 45620",
        "url": "https://www.linkedin.com/jobs/view/3965630716",
        "summary": "This role involves designing, deploying, and maintaining AI infrastructure for a government relations company, working with data scientists and engineers to deliver top-tier AI solutions. The ideal candidate has 3+ years of experience in AI deployment, MLOps, DevOps, or data engineering using AWS, along with expertise in containerization, AI frameworks, CI/CD tools, cloud infrastructure, and programming languages like Python, TypeScript, and SQL.  TS/SCI clearance and experience in a hypergrowth startup are considered a plus.",
        "industries": [
            "Artificial Intelligence",
            "Government Relations",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Continuous Improvement",
            "Adaptability"
        ],
        "hard_skills": [
            "AI Deployment",
            "MLOps",
            "DevOps",
            "Data Engineering",
            "AWS",
            "Docker",
            "Kubernetes",
            "TensorFlow",
            "PyTorch",
            "Transformers",
            "Jenkins",
            "GitHub Actions",
            "Argo CD",
            "CloudFormation",
            "Terraform",
            "Pulumi",
            "Ansible",
            "Python",
            "TypeScript",
            "SQL",
            "DevSecOps"
        ],
        "tech_stack": [
            "AWS",
            "Docker",
            "Kubernetes",
            "TensorFlow",
            "PyTorch",
            "Transformers",
            "Jenkins",
            "GitHub Actions",
            "Argo CD",
            "CloudFormation",
            "Terraform",
            "Pulumi",
            "Ansible",
            "Python",
            "TypeScript",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "TypeScript",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's Degree",
            "fields": [
                "Computer Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 300000,
            "min": 220000
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Sterling, VA",
        "job_id": 3955655368,
        "company": "Molg",
        "title": "Computer Vision Engineer",
        "created_on": 1720587132.0946894,
        "description": "Hours: Full-time Location: Molg HQ in Chantilly, VA (Northern Virginia) Salary: Competitive compensation, including salary, equity, and full healthcare benefits OUR MISSION Tackle the fast growing e-waste problem by making electronics manufacturing circular. Molg builds robotics microfactories and software to autonomously assemble and disassemble complex electronic products like laptop PCs, servers, and battery packs. Working with some of the leading computer + server manufacturers as well as industrial companies like Stanley Black and Decker, we are building the circular manufacturing technology to recover existing in-market devices for reuse and recycling as well as helping develop the next generation of circular-focused devices at the design level. IN THIS ROLE YOU WILL: Work with a talented cross-functional team of software, mechanical, electrical, and robotics engineers to develop our core technologies in computer vision as it relates to our robotics and microfactories. As a Computer Vision Engineer, you will be responsible for: Continuous design, development, testing, and deployment of 2D and 3D vision capabilities incorporated into the Molg Microfactories. Testing and verifying accuracy and precision of off-the-shelf and novel in-house vision feedback systems as it relates to robotic motion planning and grasping. Collaborating with robotic, mechanical, and software engineers on design and packaging of vision systems inside Molg Microfactory designs. WHO YOU ARE: 3+ years of industry experience in computer vision, machine vision, or image processing in manufacturing environments Proficient in modern software development (e.g. python, ROS, github, docker, etc) Passionate about robotics, automation, and control systems Ability to communicate effectively and efficiently both verbally and in writing WHO WE ARE: We spend our days building robotic systems, developing complex assembly intelligence software, and designing the next generation of circular products for our customers. Given the importance of working hands-on with physical systems, we are a 100% in-person team collaboratively working in our industrial space in Chantilly, VA, down the road from the largest data center market in the world. Our facility includes a variety of robots, CNC milling machines, 3D printers, and all the tools needed to build and test our products. It is important to us that anyone on our team that is interested in learning how to use our various pieces of equipment and machinery is taught and can gain the skills and appreciation for making physical things. While we are primarily funded by our work with Fortune 100 companies, we are also supported by amazing backers like Elemental Excelerator and Techstars. THINGS TO KNOW: We’re a small collaborative team with big ambitions, and there’s a good amount of context-switching. We expect people to be autonomous and drive their own work to completion. We are a profitable business that is primarily funded from customer revenue, which means we are scrappy and looking to build a great sustainable company for years to come. As a growing company and startup, priorities may shift as customer or business requirements change. We strive to empower individuals with context and decision-making power to meet this need.",
        "url": "https://www.linkedin.com/jobs/view/3955655368",
        "summary": "Molg is seeking a Computer Vision Engineer to develop 2D and 3D vision capabilities for their robotic microfactories. This role involves designing, testing, and deploying vision systems for robotic motion planning and grasping, and collaborating with other engineers on system integration. Ideal candidates will have 3+ years of experience in computer vision in manufacturing environments, proficiency in Python and ROS, and a passion for robotics and automation.",
        "industries": [
            "Robotics",
            "Manufacturing",
            "Computer Hardware",
            "Software Development",
            "Recycling",
            "Electronics",
            "Automation",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Autonomous",
            "Self-Driven",
            "Adaptability",
            "Teamwork",
            "Passionate",
            "Detail Oriented",
            "Analytical"
        ],
        "hard_skills": [
            "Computer Vision",
            "Machine Vision",
            "Image Processing",
            "Python",
            "ROS",
            "Github",
            "Docker",
            "Robotics",
            "Automation",
            "Control Systems",
            "2D Vision",
            "3D Vision"
        ],
        "tech_stack": [
            "Python",
            "ROS",
            "Github",
            "Docker"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": null,
            "fields": [
                "Computer Science",
                "Robotics",
                "Electrical Engineering",
                "Mechanical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Equity",
            "Full Healthcare Benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "District of Columbia, United States",
        "job_id": 3958866411,
        "company": "HCL Global Systems Inc",
        "title": "Python Developer",
        "created_on": 1720587134.77919,
        "description": "Top skills: Please have candidates provide a write up of their experience At least 5 years software development experience with 1-2 years in Python - need to know network protocols and Docker. Important to have had experience developing web services - 40 million web services that go off within 24 hours so need enterprise experience. How to analyze run times, look files, etc. Server development is critical! Django is not necessary. Experience with framework GRPC - need to know what this, okay if professional experience is limited. Experience with Asyncio - okay if professional experience is limited. Experience with DevOps - debug programs and use tools like Docker Nice to have - machine learning experience and background - understand basic Client skills like algorithms and modeling. AWS knowledge is a nice to have but not required. Docker is important Culturally - self-motivated, take initiative, open minded - someone who comes in and wants to make a lot of changes and not open to ideas will not work up Evp Cutting edge Client work this is the team that handles the technology allowing customers to talk to their TV system Extendable past 2024",
        "url": "https://www.linkedin.com/jobs/view/3958866411",
        "summary": "Software development role focused on building and maintaining web services for a client-facing TV system.  Requires strong Python skills, experience with network protocols, Docker, GRPC, and Asyncio.  Experience with DevOps and familiarity with machine learning concepts are desirable.  Candidate should be self-motivated, take initiative, and be open to new ideas.",
        "industries": [
            "Software Development",
            "Technology",
            "Entertainment",
            "Media",
            "Telecommunications",
            "Internet",
            "Consumer Electronics",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Self-motivation",
            "Initiative",
            "Open-mindedness",
            "Problem-solving",
            "Analytical",
            "Communication",
            "Collaboration",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "Network protocols",
            "Docker",
            "Web services",
            "Server development",
            "GRPC",
            "Asyncio",
            "DevOps",
            "Debugging",
            "Machine learning",
            "Algorithms",
            "Modeling",
            "AWS"
        ],
        "tech_stack": [
            "Python",
            "Docker",
            "GRPC",
            "Asyncio",
            "AWS"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3965750668,
        "company": "Belay Technologies",
        "title": "Junior Software Engineer",
        "created_on": 1720587136.2648885,
        "description": "Belay Technologies has been voted Baltimore Business Journal's (BBJ) Best Places to Work 2019, runner up in 2020 and a finalist in 2021! Belay Technologies is seeking a Software Engineer to join our intel team. You will act as a back-end software engineer, helping to design and develop an entirely new graph analysis platform that is, for the very first time, allowing our mission customers to visualize, analyze, and traverse their expansive and complex mission data in a graph format and in near-real-time. This project offers a tremendous opportunity for junior engineers to learn from senior CNO software engineers while working independently to build a product that is transforming core customer workflows. You may be asked to speak with analysts and operators to gain first-person insight into their missions, workflows, and perspectives, then utilize that knowledge to inform the platform's design. Core technical tasks include: REST API development in Java, working within Kafka streams to process and transform data, and general Java development to build and maintain the product. Responsibilities: Contribute to the development of enterprise-grade software solutions. Build and maintain Java-based REST APIs. Adhere to leading design patterns to ensure the product's scalability and maintainability. Work regularly with stakeholders to understand the domain, elicit requirements, and devise solutions. Develop and optimize various extract/transform/load (ETL) services. Become proficient with the project's graph database and develop complex database queries Candidates should have the following qualifications: TS/SCI Clearance with polygraph 3 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S Candidates are desired to have the following skills: Experience using Java to build enterprise products and applications. Knowledge of streaming analytic platforms like Kafka, RabbitMQ, Spark, etc. Familiarity with Extract, Transform, Load (ETL) software patterns to ingest large and complex datasets. Familiarity with Git and GitLab CI/CD. Understanding of common Enterprise Integration Patterns (EIP) and how to apply them Nice to Haves: Experience with graph databases such as Neo4j. Experience building real-time data processing applications using streaming libraries like Kafka Streams. Experience modeling data and relationships in graph databases. Experience with networking concepts, protocols, and analysis (routers, switches, etc.). Knowledge of SIGINT collection and analysis systems Experience with production CNO capabilities and operations Perks and Benefits: 8 weeks paid leave - 4 weeks of personal leave, 3 Yay! days, take off on your birthday,11 paid holidays and optional leave up to 6 days through Belay's volunteer program 10% matching in 401(k) contributions vested on day one $5,000 annual training/tuition Student Loan Repayment Program 100% company-funded HSA Rich medical coverage (100% coinsurance) Dental coverage including orthodontia Up to $420,000 in life insurance, premiums 100% company funded Amazon Prime, gym reimbursement, monthly lunches, games and prizes Pet adoption program, generous referral bonus program, fun events, and more! Belay Technologies is a certified Service-Disabled Veteran-Owned Small Business located in Columbia, Maryland (Baltimore/Washington area). Belay Technologies specializes in systems automation and full stack development. Belay Technologies provides leading technology and engineering solutions to the DoD, as well as state-of-the-art commercial products. We hire software engineers, web designers, test engineers, systems engineers, systems administrators, database engineers and other tech services. We are an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law. Powered by JazzHR A9G5H5oSHc",
        "url": "https://www.linkedin.com/jobs/view/3965750668",
        "summary": "Belay Technologies is seeking a Software Engineer to join their intel team and build a graph analysis platform for mission customers. This role involves back-end development using Java, REST APIs, Kafka streams, and graph databases. The ideal candidate will have experience with Java, streaming analytics platforms (Kafka, RabbitMQ, Spark), ETL software patterns, Git, and Enterprise Integration Patterns. Bonus points for experience with Neo4j, Kafka Streams, real-time data processing, graph database modeling, networking concepts, SIGINT collection and analysis, and CNO capabilities.",
        "industries": [
            "Information Technology",
            "Defense",
            "Intelligence",
            "Software Development",
            "Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Teamwork",
            "Analytical Thinking",
            "Detail-Oriented",
            "Customer Focus",
            "Adaptability",
            "Initiative"
        ],
        "hard_skills": [
            "Java",
            "REST API",
            "Kafka Streams",
            "Graph Databases",
            "ETL",
            "Git",
            "Enterprise Integration Patterns",
            "Neo4j",
            "Streaming Libraries",
            "Data Modeling",
            "Networking Concepts",
            "SIGINT",
            "CNO"
        ],
        "tech_stack": [
            "Java",
            "REST API",
            "Kafka",
            "RabbitMQ",
            "Spark",
            "Git",
            "GitLab CI/CD",
            "Neo4j",
            "Kafka Streams"
        ],
        "programming_languages": [
            "Java"
        ],
        "experience": 3,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Technical Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Paid Leave",
            "401(k) Matching",
            "Training/Tuition Reimbursement",
            "Student Loan Repayment",
            "HSA",
            "Health Insurance",
            "Dental Insurance",
            "Life Insurance",
            "Amazon Prime",
            "Gym Reimbursement",
            "Monthly Lunches",
            "Pet Adoption Program",
            "Referral Bonus",
            "Fun Events"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3929727062,
        "company": "Capital One",
        "title": "Manager Data Scientist",
        "created_on": 1720587137.763278,
        "description": "Locations: VA - McLean, United States of America, McLean, VirginiaManager Data Scientist Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. Role Description In this role, you will: Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation Flex your interpersonal skills to translate the complexity of your work into tangible business goals The Ideal Candidate is: Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers. Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them. Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea. A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You’re passionate about talent development for your own team and beyond. Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms. Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning. A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science. Basic Qualifications: Currently has, or is in the process of obtaining a Bachelor’s Degree plus 6 years of experience in data analytics, or currently has, or is in the process of obtaining a Master’s Degree plus 4 years of experience in data analytics, or currently has, or is in the process of obtaining PhD plus 1 year of experience in data analytics, with an expectation that required degree will be obtained on or before the scheduled start date At least 2 years’ experience in open source programming languages for large scale data analysis At least 2 years’ experience with machine learning At least 2 years’ experience with relational databases Preferred Qualifications: PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics At least 1 year of experience working with AWS At least 4 years’ experience in Python, Scala, or R for large scale data analysis At least 4 years’ experience with machine learning At least 4 years’ experience with SQL Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
        "url": "https://www.linkedin.com/jobs/view/3929727062",
        "summary": "Capital One is seeking a Data Scientist to join their team in McLean, VA. The ideal candidate will have a strong background in data analytics, machine learning, and open-source programming languages. They will be responsible for partnering with cross-functional teams to deliver products, leveraging a range of technologies to uncover insights from large data sets, and building machine learning models. The role requires strong analytical, technical, and interpersonal skills. Preferred qualifications include a PhD in STEM, experience with AWS, and proficiency in Python, Scala, or R.",
        "industries": [
            "Finance",
            "Technology",
            "Financial Services",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Creativity",
            "Leadership",
            "Customer Focus",
            "Innovation",
            "Teamwork",
            "Interpersonal Skills"
        ],
        "hard_skills": [
            "Python",
            "Conda",
            "AWS",
            "H2O",
            "Spark",
            "SQL",
            "Machine Learning",
            "Data Analysis",
            "Statistical Modeling",
            "Data Visualization",
            "Clustering",
            "Classification",
            "Sentiment Analysis",
            "Time Series",
            "Deep Learning"
        ],
        "tech_stack": [
            "Python",
            "Conda",
            "AWS",
            "H2O",
            "Spark",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "Scala",
            "R"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Analytics",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Financial Benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3944486311,
        "company": "FedTec",
        "title": "Software Developer",
        "created_on": 1720587139.2284825,
        "description": "FedTec Overview: FedTec is a Woman-Owned Small Business with headquarters in Reston, VA. However, FedTec is more than just a company – we are a dedicated team of visionary individuals who understand the power of transformation. With our unwavering commitment to innovative technology and forward-focused methods, we empower government agencies to fulfill their missions successfully with our capabilities in Digital Transformation, and Cyber Security. Our strategy is rooted in in-depth advising and a unique shoulder-to-shoulder mission experience, all geared towards enabling our clients, their agencies, and every American to thrive. We use the same approach as our employees, building meaningful and lasting relationships to meet their evolving needs and help them grow. We are excited to welcome you to our family. About the Opportunity: FedTec is looking for talented and motivated Software Developers with 1-5 years of experience to join our Innovation Lab. As a key member of our team, you will work on exciting projects that drive innovation and create impactful solutions. Your role will involve collaborating with cross-functional teams to design, develop, and deploy software applications and systems. Position: Software Developer (1-5 Years Experience) Work Location: Reston, VA US Citizenship Required Primary Responsibilities Collaborate with team members to design, code, test, and debug software applications and systems. Participate in innovative projects from conception to deployment, ensuring high-quality and scalable solutions. Analyze complex problems, identify innovative solutions, and implement them effectively. Work closely with product managers, designers, and other developers to deliver seamless and functional software. Stay up-to-date with emerging technologies, industry trends, and best practices to drive continuous improvement in our development processes. Participate in code reviews to maintain code quality and share knowledge with the team. Create and maintain technical documentation for developed software. Basic Qualifications 1-5 years of professional software development experience. College Graduates are Encouraged to apply as well. Bachelor’s degree in Computer Science, Engineering, or a related field (or equivalent practical experience). Proficiency in one or more programming languages such as Python, Java, JavaScript, or C++. Experience with web development frameworks (e.g., React, Angular, Django). Familiarity with version control systems (e.g., Git). Understanding of software development methodologies (Agile, Scrum). Knowledge of databases (SQL, NoSQL) and cloud services (AWS, Azure, GCP) is a plus. Strong analytical and problem-solving skills. Excellent verbal and written communication skills. Ability to work effectively in a collaborative team environment. Preferred Qualifications: Experience with machine learning, artificial intelligence, or data science projects. Knowledge of DevOps practices and tools (Docker, Kubernetes, CI/CD). Familiarity with IoT, blockchain, or other emerging technologies. Contribution to open-source projects or participation in hackathons. When You Join FedTec, You Are Joining a Family! We take pride in our work and the true and transparent relationships we build with our employees and partners. We believe that positive energy attracts like-minded individuals, which is why we have such exceptional people on our team. Just as you'd do for your own family, we prioritize your safety, health, and happiness. That's why we've created the FedTec Total Well-Being program, offering benefits like: Comprehensive medical, dental, and vision plans. These plans encompass a range of beneficial features, such as Telehealth virtual care programs, and access to resources to support your physical and mental well-being. Generous paid time off for relaxation and rejuvenation. Financial security through 401k, company-paid short and long-term disability, life insurance, and additional voluntary coverage. Support for your life and family with access to an Employee Assistance Program, Pet Insurance, and Prepaid Legal services. Recognition and growth opportunities through our Rewards & Recognition and Learning & Development programs. Our newest addition, the FedTec Fit Program, features an on-staff Fitness Coach who provides personal and group sessions, company fitness challenges, and ongoing support for your fitness goals. At FedTec we embrace the power of diversity, fostering a culture where varied thoughts, ideas, and perspectives empower our employees and partners to thrive. We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, disability, or status as a protected veteran and we maintain a drug-free workplace to ensure a safe and healthy environment for all. If you are a self-driving professional with a confident personality and a proven track record, we encourage you to apply!!!",
        "url": "https://www.linkedin.com/jobs/view/3944486311",
        "summary": "FedTec, a Woman-Owned Small Business, is seeking a Software Developer with 1-5 years of experience to join their Innovation Lab in Reston, VA. The role involves collaborating with cross-functional teams to design, develop, and deploy software applications and systems.  Responsibilities include coding, testing, debugging, participating in innovative projects, analyzing complex problems, and staying up-to-date with emerging technologies.  The ideal candidate will have proficiency in programming languages like Python, Java, JavaScript, or C++, experience with web development frameworks, knowledge of databases and cloud services, and strong analytical and communication skills.  FedTec offers a comprehensive benefits package including medical, dental, vision, generous paid time off, 401k, and a Total Well-Being program.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Cybersecurity",
            "Government",
            "Digital Transformation"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "JavaScript",
            "C++",
            "React",
            "Angular",
            "Django",
            "Git",
            "SQL",
            "NoSQL",
            "AWS",
            "Azure",
            "GCP",
            "Agile",
            "Scrum",
            "Machine Learning",
            "Artificial Intelligence",
            "Data Science",
            "Docker",
            "Kubernetes",
            "CI/CD",
            "IoT",
            "Blockchain"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "JavaScript",
            "C++",
            "React",
            "Angular",
            "Django",
            "Git",
            "SQL",
            "NoSQL",
            "AWS",
            "Azure",
            "GCP",
            "Docker",
            "Kubernetes",
            "CI/CD",
            "Machine Learning",
            "Artificial Intelligence",
            "Data Science",
            "IoT",
            "Blockchain"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "JavaScript",
            "C++"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Telehealth",
            "Paid Time Off",
            "401k",
            "Disability Insurance",
            "Life Insurance",
            "Employee Assistance Program",
            "Pet Insurance",
            "Prepaid Legal Services",
            "Rewards & Recognition",
            "Learning & Development",
            "Fitness Coach",
            "On-site Fitness"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Bethesda, MD",
        "job_id": 3960917403,
        "company": "The National Institutes of Health",
        "title": "Supervisory Data Scientist (Expression of Interest)",
        "created_on": 1720587140.933354,
        "description": "Overview: Lead transformative data science and artificial intelligence initiatives as the Chief of the Data Science and Artificial Intelligence Application Branch (DSAIAB) at the Division of Technical Resources (DTR) at NIH. DSAIAB manages over 350 million live data points daily and performs approximately 1 million advanced calculations per day to support DTR’s decision-making processes. DSAIAB supports NIH’s Aseptic Facilities and the Central Utility Plant, which is one of the largest and most technologically advanced utility plants in the US. The branch uses artificial neural networks, gradient-boosted models, Bayesian optimization, and other machine learning/artificial intelligence software to generate over 175,000 data points daily for approximately 12,500 variables, optimizing operations. Key Responsibilities: Leadership and Strategic Oversight: Supervise a team of 10 data scientists and AI specialists, providing strategic direction and technical guidance. Lead their work on data analysis, model development, and implementation, ensuring alignment with organizational goals and operational efficiency. Manage an annual budget of approximately $5 million to support operational and analytical needs, making informed decisions on resource allocation and project prioritization. Data Governance and Management: Establish and maintain a robust Data Governance framework for data lifecycle management, ensuring data integrity, security, and regulatory compliance. Implement strategies to uphold high standards for data quality and reliability across all data-driven initiatives. Ideal Candidate Profile: Knowledge: Expertise in machine learning algorithms, including RNN (Recurrent Neural Networks), LSTM (Long Short-Term Memory), and model optimization techniques, with practical troubleshooting skills. Proficiency in advanced analytical methods such as Functional Principal Component Analysis (FPCA), Bayesian optimization, Nonlinear Autoregressive Exogenous (NARX) models, and Monte Carlo simulation, with a strong grasp of both theory and practical application. Familiarity with diverse statistical methods relevant to data analysis and model validation, enabling robust interpretation and enhancement of predictive models. Experience: Minimum 10 years in data science, with at least 5 years in a supervisory or leadership role, demonstrating successful team management and project execution. Background in utilities engineering or large-scale production facilities, with hands-on experience deploying AI and machine learning solutions to enhance operational efficiencies. Proven track record of leading and delivering complex AI and machine learning projects in environments similar to NIH’s critical infrastructure. Education and Certifications: Degree in Data Science, Mathematics, Engineering, Computer Science, or related field, providing a solid academic foundation in advanced data analytics and AI. Certifications in machine learning, AI, or data governance preferred, indicating ongoing professional development and expertise in cutting-edge technologies. Highly desirable: Certification in cloud platforms (AWS, Azure, GCP), facilitating effective utilization of scalable cloud infrastructure for data-intensive applications. Growth Potential: Opportunity for significant career advancement in a leadership role offering autonomy and influence, shaping the future of data-driven decision-making within NIH’s critical infrastructure. Professional development in a dynamic environment that fosters innovation and pushes the boundaries of healthcare technology, contributing positively to public health and scientific research. *Please Note: This is an expression of interest and not an official announcement. The official announcement will be posted on USAJob.gov (https://www.usajobs.gov/job/798218400).",
        "url": "https://www.linkedin.com/jobs/view/3960917403",
        "summary": "The Chief of the Data Science and Artificial Intelligence Application Branch (DSAIAB) at NIH leads data science and AI initiatives, managing over 350 million live data points daily to support decision-making and optimize operations at the Central Utility Plant.",
        "industries": [
            "Healthcare",
            "Biotechnology",
            "Research",
            "Data Science",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Leadership",
            "Strategic Thinking",
            "Team Management",
            "Communication",
            "Problem-Solving",
            "Decision-Making",
            "Data Governance",
            "Compliance"
        ],
        "hard_skills": [
            "Machine Learning",
            "Artificial Intelligence",
            "RNN",
            "LSTM",
            "Model Optimization",
            "Functional Principal Component Analysis (FPCA)",
            "Bayesian Optimization",
            "Nonlinear Autoregressive Exogenous (NARX) Models",
            "Monte Carlo Simulation",
            "Data Analysis",
            "Model Validation",
            "Statistical Methods",
            "Data Governance",
            "Cloud Platforms (AWS, Azure, GCP)"
        ],
        "tech_stack": [
            "Artificial Neural Networks",
            "Gradient-Boosted Models",
            "Bayesian Optimization",
            "Machine Learning",
            "Artificial Intelligence",
            "RNN (Recurrent Neural Networks)",
            "LSTM (Long Short-Term Memory)",
            "FPCA (Functional Principal Component Analysis)",
            "NARX (Nonlinear Autoregressive Exogenous) Models",
            "Monte Carlo Simulation",
            "AWS",
            "Azure",
            "GCP"
        ],
        "programming_languages": [],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Mathematics",
                "Engineering",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "District of Columbia, United States",
        "job_id": 3966747313,
        "company": "Harnham",
        "title": "Senior Software Engineer - Machine Learning",
        "created_on": 1720587147.622452,
        "description": "Job Title: Senior Software Engineer – Machine Learning Salary: $180-220k base + equity Eligibility: Must be able to obtain US Security Clearance Join a cutting-edge AI start-up! We're looking for a skilled ML Software Engineer to bridge the gap between machine learning, data engineering, and software development, enhancing our AI data applications. About the Role: Design, develop, and maintain scalable software solutions to process and analyze large datasets using their advanced AI SDK. Architect and implement efficient data pipelines and workflows for data collection, processing, and storage. Improve data access patterns for enhanced AI solution performance. Address runtime performance issues, ensuring application responsiveness and stability. Write clean, efficient, and maintainable code following best practices. Work closely with Technical Product Managers to enhance application usability and meet user expectations. Build robust, scalable, and user-friendly applications considering current trends and future growth. Create and manage dynamic dashboards using our AI Platform Python SDK, transforming data into intuitive visuals for decision-making. Stay updated with the latest in software engineering and data science, applying new advancements to improve existing solutions. Your Skills and Experience: A degree in Computer Science or related field, or 4 years of software engineering experience. Willingness to obtain and maintain a U.S. government security clearance. Strong knowledge of Python and the Python Data Stack (pandas, NumPy, scikit-learn, PyTorch, Matplotlib, etc.). Proven experience deploying software into production environments. Familiarity with Docker, Kubernetes, and Git. Exceptional problem-solving skills and a strong sense of ownership. Excellent written and verbal communication skills in English.",
        "url": "https://www.linkedin.com/jobs/view/3966747313",
        "summary": "This role involves designing, developing, and maintaining scalable software solutions for analyzing large datasets using AI. Responsibilities include building data pipelines, improving data access, ensuring application performance, collaborating with product managers, and creating dashboards using the company's AI Platform Python SDK.",
        "industries": [
            "Artificial Intelligence",
            "Software Development",
            "Data Science",
            "Machine Learning",
            "Technology"
        ],
        "soft_skills": [
            "Problem-solving",
            "Ownership",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "Pandas",
            "NumPy",
            "Scikit-learn",
            "PyTorch",
            "Matplotlib",
            "Docker",
            "Kubernetes",
            "Git"
        ],
        "tech_stack": [
            "Python",
            "Pandas",
            "NumPy",
            "Scikit-learn",
            "PyTorch",
            "Matplotlib",
            "Docker",
            "Kubernetes",
            "Git"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related"
            ]
        },
        "salary": {
            "max": 220000,
            "min": 180000
        },
        "benefits": [
            "Equity"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3944467605,
        "company": "Georgia Tech Research Institute",
        "title": "AI/ML Engineer - GTRI-ICL",
        "created_on": 1720587149.0959163,
        "description": "Overview The Georgia Tech Research Institute (GTRI) is the nonprofit, applied research division of the Georgia Institute of Technology (Georgia Tech). Founded in 1934 as the Engineering Experiment Station, GTRI has grown to more than 2,900 employees, supporting eight laboratories in over 20 locations around the country and performing more than $940 million of problem-solving research annually for government and industry. GTRI's renowned researchers combine science, engineering, economics, policy, and technical expertise to solve complex problems for the U.S. federal government, state, and industry. Georgia Tech's Mission and Values Georgia Tech's Mission Is To Develop Leaders Who Advance Technology And Improve The Human Condition. The Institute Has Nine Key Values That Are Foundational To Everything We Do Students are our top priority. We strive for excellence. We thrive on diversity. We celebrate collaboration. We champion innovation. We safeguard freedom of inquiry and expression. We nurture the wellbeing of our community. We act ethically. We are responsible stewards. Over the next decade, Georgia Tech will become an example of inclusive innovation, a leading technological research university of unmatched scale, relentlessly committed to serving the public good; breaking new ground in addressing the biggest local, national, and global challenges and opportunities of our time; making technology broadly accessible; and developing exceptional, principled leaders from all backgrounds ready to produce novel ideas and create solutions with real human impact. Project/Unit Description The Advanced Research in Computing and Artificial Intelligence Division (ARCAID) within the ICL Lab is seeking an Experienced AI/ML Research Engineer to join our team of passionate researchers. We seek an experienced Engineer who can develop AI and ML solutions in support AI research efforts leveraging the latest tools and techniques to realize solutions for the nation’s most challenging problems. The ideal candidate will have broad experience and expertise in applied of AI/ML. A strong candidate will have a passion for researching novel solutions for a wide range of research domains to include DoD, DOE and Healthcare industry. This position will focus on the design, development and deployment of AI/ML models. The candidate will work closely with staff members in a collaborative working environment. This is an excellent opportunity for a motivated, results-oriented professional. We are seeking people who get excited about working with data developing novel AI/ML solutions. The ARCAID Division works with a diverse group of organizations and agencies in National Security and the public health space. The ideal candidate must be able to communicate complex technical material clearly to a wide variety of audiences including academia, conference proceedings, management, business development leads, prospective and existing customers. Job Purpose The Artificial Intelligence/Machine Learning (AI/ML) Engineer develops AI/ML algorithms, cloud computing, and/or heterogeneous distributed computing infrastructures to support the deployment of AI/ML applications. The AI/ML Engineer also researches the mathematical foundations and frameworks for nonlinear systems characterized by time-varying and emerging dynamics of evolving or adaptive systems. The AI/ML Engineer develops technical solutions at the leading edge of Artificial Intelligence, Machine Learning, Genetic Programming, Computer Vision, and advanced data processing, filtering, and fusion techniques in high-performance computing and distributed heterogeneous computing environments. The AI/ML Engineer writes parallel processing programs to deploy ML models developed by data scientists into more complex systems. The AI/ML Engineer has familiarity with state-of-the-art, open-source software frameworks and high-performance computing accelerators for machine learning. When conducting research, the AI/ML Engineer leverages the most recent advances in statistical analysis of large data sets to advance state-of-the-art automated sensor and data processing for a broad range of intelligent and sensor-enabled systems. Key Responsibilities Apply tools and frameworks to deploy machine learning models Conduct data conditioning, processing, filtering, and fusion to support the creation of automated algorithms Make decisions regarding implementation based on available hardware (e.g., embedded systems, cloud, server infrastructure) Design application logging capabilities and perform debugging with available logs Additional Responsibilities Architecting, developing and deploying AI pipeline solutions on AWS, Microsoft Azure or on premise solutions Database system design and query development for SQL and NoSQL systems to include; MS SQL Server, PostGres DB, MariaDB, Nero4J and MongoDB Independently conducting exploratory data analysis, documenting and presenting findings to senior leadership and decision makers Independently applying of Machine Learning techniques such as supervised, unsupervised and semi-supervised learning Develop Machine Learning operation guidance, architectures and deployment in production Developing and applying Natural Language Processing techniques Performing as a main contributor to small AI/ML development teams Experience leveraging geospatial application tools such as OpenStreetMap, Nominatim and PostGIS Required Minimum Qualifications MS or equivalent degree in Computer Science, Computer Security, Computer Engineering, Cybersecurity, or related field with 4+ years of work experience Machine Learning modeling experience Decision Trees, Random Forest, Support Vector Machines, Logistic Regression, Neural Network Architecture, K-Means and dimensionality reduction techniques Basic cloud development experience in AWS and/or Microsoft Azure Experience building data sets from SQL based systems such as PostGres and MariaDB Experience working with Data Science IDEs such as JupyterLab, JupyterHub and Anaconda environments Coding experience with Python, R and GitHub/GitLab Working experience with Linux based systems RHEL, Rocky Linux, Ubuntu other Debian operating systems Ability to work well with a variety of teams with diverse skill sets Preferred Qualifications Master’s degree or pursing in Analytics, Machine Learning or Computer Science Experience developing and deploying AI pipeline designs Fundamental programming skills languages such as Python, Java and JavaScript Experience modeling data in JSON and Entity Relational Diagraming (ERD) design Experience working with cloud-based analytics environment, such as Databricks, Azure ML and AWS Experience working with databases (i.e. configuring, deploying, securing and maintaining) Experience working with government systems Currently possess or can obtain a DoD Top Secret Security clearance Travel Requirements 10% - 25% travel Education And Length Of Experience This position vacancy is an open-rank announcement. The final job offer will be dependent on candidate qualifications in alignment with Research Faculty Extension Professional ranks as outlined in section 3.2.1 of the Georgia Tech Faculty Handbook 2 years of related experience with a Bachelor’s degree in Computer Science, Computer Security, Industrial and Systems Engineering, Analytics, Computing or related degree field 0 years of related experience with a Masters’ degree in Computer Science, Computer Security, Industrial and Systems Engineering, Analytics, Computing or related degree field U.S. Citizenship Requirements Due to our research contracts with the U.S. federal government, candidates for this position must be U.S. Citizens. Clearance Type Required Candidates must be able to obtain and maintain an active security clearance. Benefits At GTRI Comprehensive information on currently offered GTRI benefits, including Health & Welfare, Retirement Plans, Tuition Reimbursement, Time Off, and Professional Development, can be found through this link: https://hr.gatech.edu/benefits Equal Employment Opportunity The Georgia Institute of Technology (Georgia Tech) is an Equal Employment Opportunity Employer. The University is committed to maintaining a fair and respectful environment for all. To that end, and in accordance with federal and state law, Board of Regents policy, and University policy, Georgia Tech provides equal opportunity to all faculty, staff, students, and all other members of the Georgia Tech community, including applicants for admission and/or employment, contractors, volunteers, and participants in institutional programs, activities, or services. Georgia Tech complies with all applicable laws and regulations governing equal opportunity in the workplace and in educational activities. Georgia Tech prohibits discrimination, including discriminatory harassment, on the basis of race, ethnicity, ancestry, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, national origin, age, disability, genetics, or veteran status in its programs, activities, employment, and admissions. This prohibition applies to faculty, staff, students, and all other members of the Georgia Tech community, including affiliates, invitees, and guests. Further, Georgia Tech prohibits citizenship status, immigration status, and national origin discrimination in hiring, firing, and recruitment, except where such restrictions are required in order to comply with law, regulation, executive order, or Attorney General directive, or where they are required by Federal, State, or local government contract. USG Core Values Statement The University System of Georgia is comprised of our 26 institutions of higher education and learning as well as the System Office. Our USG Statement of Core Values are Integrity, Excellence, Accountability, and Respect. These values serve as the foundation for all that we do as an organization, and each USG community member is responsible for demonstrating and upholding these standards. More details on the USG Statement of Core Values and Code of Conduct are available in USG Board Policy 8.2.18.1.2 and can be found on-line at https://www.usg.edu/policymanual/section8/C224/#p8.2.18_personnel_conduct. Additionally, USG supports Freedom of Expression as stated in Board Policy 6.5 Freedom of Expression and Academic Freedom found on-line at https://www.usg.edu/policymanual/section6/C2653.",
        "url": "https://www.linkedin.com/jobs/view/3944467605",
        "summary": "GTRI is seeking an Experienced AI/ML Research Engineer to develop AI and ML solutions in support of AI research efforts, leveraging the latest tools and techniques to realize solutions for the nation's most challenging problems. The ideal candidate will have broad experience and expertise in applied AI/ML. This position will focus on the design, development, and deployment of AI/ML models.",
        "industries": [
            "Research",
            "National Security",
            "Public Health",
            "Healthcare",
            "DoD",
            "DOE"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Research",
            "Analytical",
            "Leadership",
            "Decision Making",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "AI",
            "Cloud Computing",
            "Distributed Computing",
            "Data Processing",
            "Data Filtering",
            "Data Fusion",
            "Statistical Analysis",
            "Python",
            "R",
            "SQL",
            "NoSQL",
            "AWS",
            "Azure",
            "JupyterLab",
            "JupyterHub",
            "Anaconda",
            "Linux",
            "GitHub",
            "GitLab",
            "OpenStreetMap",
            "Nominatim",
            "PostGIS",
            "Decision Trees",
            "Random Forest",
            "Support Vector Machines",
            "Logistic Regression",
            "Neural Network Architecture",
            "K-Means",
            "Dimensionality Reduction",
            "JSON",
            "Entity Relational Diagraming (ERD)",
            "Databricks",
            "Azure ML",
            "Data Science"
        ],
        "tech_stack": [
            "AWS",
            "Azure",
            "JupyterLab",
            "JupyterHub",
            "Anaconda",
            "Linux",
            "GitHub",
            "GitLab",
            "OpenStreetMap",
            "Nominatim",
            "PostGIS",
            "Databricks",
            "Azure ML"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL",
            "Java",
            "JavaScript"
        ],
        "experience": 4,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Computer Science",
                "Computer Security",
                "Computer Engineering",
                "Cybersecurity",
                "Analytics",
                "Machine Learning",
                "Computing"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health & Welfare",
            "Retirement Plans",
            "Tuition Reimbursement",
            "Time Off",
            "Professional Development"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3960947102,
        "company": "Booz Allen Hamilton",
        "title": "AI and ML Engineer, Senior",
        "created_on": 1720587157.7814295,
        "description": "Job Number: R0200540 AI and ML Engineer, Senior The Opportunity: As an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on business processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support high impact client focused solutions to solve operational challenges. As a machine learning engineer on our national security team, you’ll train, test, deploy, and maintain models that learn from data. In this role, you’ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You’ll be part of a large community of machine learning engineers across the firm and collaborate with analysts, data engineers, data scientists, solutions architects, and product owners to deliver world class solutions to real-world problems, processing data and information at a massive scale, developing pipelines that optimize the use of infrastructure, and integrating critical technologies into efficient user experiences. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. Work with us to solve real-world challenges and define ML strategy for our national missions clients. Join us. The world can’t wait. You Have: 5+ years of experience with artificial intelligence (AI), data science, ML engineering, data research, software engineering, or data analytics Experience with software and artificial intelligence projects Experience with the Python programming language Knowledge of methodologies for deep learning, computer vision, NLP, or signal processing machine learning development Knowledge of modern software design patterns, including microservice design or edge computing TS/SCI clearance with a polygraph Bachelor's degree Nice If You Have: Experience with embedded systems programming in C, C++, or Rust Experience with GPU programming, including CUDA or RAPIDs Experience with modern Cloud computing technologies, including Docker and Kubernetes Ability to gather requirements from customers and lead Agile teams Master's degree in Computer Science or Statistics preferred; Doctorate degree in Computer Science or Statistics a plus Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $96,600.00 to $220,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "url": "https://www.linkedin.com/jobs/view/3960947102",
        "summary": "Booz Allen Hamilton is seeking a Senior AI and ML Engineer with 5+ years of experience to join their National Security team. The role involves developing, deploying, and maintaining machine learning models for mission-critical solutions. The ideal candidate will have expertise in Python, deep learning, computer vision, NLP, and signal processing, as well as experience with modern software design patterns and cloud computing technologies. TS/SCI clearance with a polygraph is required.",
        "industries": [
            "National Security",
            "Defense",
            "Intelligence",
            "Consulting"
        ],
        "soft_skills": [
            "Problem-solving",
            "Collaboration",
            "Communication",
            "Leadership",
            "Customer Focus"
        ],
        "hard_skills": [
            "Machine Learning",
            "Artificial Intelligence",
            "Data Science",
            "Python",
            "Deep Learning",
            "Computer Vision",
            "NLP",
            "Signal Processing",
            "Microservice Design",
            "Edge Computing",
            "Cloud Computing",
            "Docker",
            "Kubernetes",
            "C",
            "C++",
            "Rust",
            "CUDA",
            "RAPIDS",
            "Agile"
        ],
        "tech_stack": [
            "Python",
            "Deep Learning",
            "Computer Vision",
            "NLP",
            "Signal Processing",
            "Microservices",
            "Edge Computing",
            "Docker",
            "Kubernetes",
            "CUDA",
            "RAPIDS"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++",
            "Rust"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 220000,
            "min": 96600
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Dependent Care",
            "Recognition Awards",
            "Flexible Schedules",
            "Remote Work",
            "Hybrid Work"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3926370608,
        "company": "Amazon Web Services (AWS)",
        "title": "Applied Scientist",
        "created_on": 1720587159.404239,
        "description": "Description Amazon is looking for a passionate, talented, and inventive Applied Scientist with a strong machine learning background to help build industry-leading language technology. Our mission is to provide a delightful experience to Amazon’s customers by pushing the envelope in Natural Language Processing (NLP), Generative AI, Large Language Model (LLM), Natural Language Understanding (NLU), Machine Learning (ML), Retrieval-Augmented Generation, Responsible AI, Agent, Evaluation, and Model Adaptation. As part of our AI team in Amazon AWS, you will work alongside internationally recognized experts to develop novel algorithms and modeling techniques to advance the state-of-the-art in human language technology. Your work will directly impact millions of our customers in the form of products and services, as well as contributing to the wider research community. You will gain hands on experience with Amazon’s heterogeneous text and structured data sources, and large-scale computing resources to accelerate advances in language understanding. The Science team at AWS Bedrock builds science foundations of Bedrock, which is a fully managed service that makes high-performing foundation models available for use through a unified API. We are adamant about continuously learning state-of-the-art NLP/ML/LLM technology and exploring creative ways to delight our customers. In our daily job we are exposed to large scale NLP needs and we apply rigorous research methods to respond to them with efficient and scalable innovative solutions. At AWS Bedrock, you’ll experience the benefits of working in a dynamic, entrepreneurial environment, while leveraging AWS resources, one of the world’s leading cloud companies and you’ll be able to publish your work in top tier conferences and journals. We are building a brand new team to help develop a new NLP service for AWS. You will have the opportunity to conduct novel research and influence the science roadmap and direction of the team. Come join this greenfield opportunity! AWS Bedrock Science Team is a part of AWS Utility Computing AWS Utility Computing (UC) provides product innovations — from foundational services such as Amazon’s Simple Storage Service (S3) and Amazon Elastic Compute Cloud (EC2), to consistently released new product innovations that continue to set AWS’s services and features apart in the industry. As a member of the UC organization, you’ll support the development and management of Compute, Database, Storage, Internet of Things (Iot), Platform, and Productivity Apps services in AWS, including support for customers who require specialized security solutions for their cloud services. About The Team Diverse Experiences AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship & Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud. Hybrid Work We value innovation and recognize this sometimes requires uninterrupted time to focus on a build. We also value in-person collaboration and time spent face-to-face. Our team affords employees options to work in the office every day or in a flexible, hybrid work model near one of our U.S. Amazon offices. Basic Qualifications PhD, or Master's degree and 4+ years of CS, CE, ML or related field experience Experience in patents or publications at top-tier peer-reviewed conferences or journals Experience programming in Java, C++, Python or related language Preferred Qualifications Experience in professional software development 3+ years of building machine learning models or developing algorithms for business application experience Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $136,000/year in our lowest geographic market up to $222,200/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon Development Center U.S., Inc. Job ID: A2620406",
        "url": "https://www.linkedin.com/jobs/view/3926370608",
        "summary": "Amazon seeks an Applied Scientist with a strong machine learning background to contribute to the development of industry-leading language technology for AWS Bedrock, a fully managed service offering high-performing foundation models. The role involves building novel algorithms, advancing state-of-the-art NLP, and collaborating with experts to impact millions of customers. This is a greenfield opportunity within a dynamic, entrepreneurial environment with opportunities for publication and research.",
        "industries": [
            "Technology",
            "Cloud Computing",
            "Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing"
        ],
        "soft_skills": [
            "Passionate",
            "Talented",
            "Inventive",
            "Strong communication",
            "Collaboration",
            "Problem-solving",
            "Research",
            "Creativity",
            "Innovation"
        ],
        "hard_skills": [
            "Machine Learning",
            "Natural Language Processing",
            "Generative AI",
            "Large Language Models",
            "Natural Language Understanding",
            "Retrieval-Augmented Generation",
            "Responsible AI",
            "Agent",
            "Evaluation",
            "Model Adaptation",
            "Java",
            "C++",
            "Python"
        ],
        "tech_stack": [
            "AWS Bedrock",
            "AWS",
            "Amazon S3",
            "Amazon EC2"
        ],
        "programming_languages": [
            "Java",
            "C++",
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Master's degree",
            "fields": [
                "Computer Science",
                "Computer Engineering",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 222200,
            "min": 136000
        },
        "benefits": [
            "Equity",
            "Sign-on payments",
            "Medical",
            "Financial",
            "Other benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chevy Chase, MD",
        "job_id": 3920117364,
        "company": "GEICO",
        "title": "Principal Machine Learning Scientist/Engineer - AI Services",
        "created_on": 1720587162.5201814,
        "description": "GEICO is seeking an experienced lead machine learning scientist to join the AI Solutions org. In this role, you will be a key contributor in building durable services & systems that connects complex data ecosystems and AI/ML models to solve real-world challenges. You will be collaborating with a dynamic team of data scientists and AI-ML experts in crafting and implementing AI solutions that not only enhance our operational efficiencies in measurable ways but also set new benchmarks in industry innovation. Responsibilities: AI Systems: Work with Data Scientists and ML Engineers to gather requirements, architect, design, and implement a variety of data-driven systems and platforms ensuring scalability, efficiency, and robustness. Leverage open-source technologies for rapid prototyping & experimentation. Be creative with design but also hands-on with practical concerns. Examples of systems that we develop/enhance include Model orchestration, AB testing, Feature store, Semantic search, GenAI/LLM services, image/document understanding, dashboard & UI services, etc. Feature/Data Engineering: Develop and maintain efficient data pipelines that source structured and unstructured data from various locations, ensuring feature integrity, availability, and optimization. Utilize NLP and generative AI capabilities to extract features from unstructured data for model development. Service Integration: Collaborate with Data Scientists and engineering teams to ensure seamless integration and deployment of AI/ML models into production applications. Work with Product/Engineering leaders to come up with integration designs and project plans and ensure on-time releases. MLOPs: establish SDLC and SRE best practices to ensure stable operations of production AI systems. Lead the evaluation, procurement, and deployment of specialized AI infrastructure components such as GPU clusters and vector databases, balancing cost effectiveness, architectural simplicity, scalability, extensibility, etc. Technical Leadership: Collaborate with cross-functional teams to ensure alignment, efficacy, and timeliness. Define project roadmaps, establish feature backlogs, and delegate to a small team of junior and mid-level ML scientists for implementation. Provide guidance on provisioning of environments, rapid deployment of services and application, and monitoring and triage of large-scale production applications. Communication: Translate complex findings into understandable insights and present them to peers, leadership, and business stakeholders. R&D: Stay abreast of the latest developments in AI/ML systems, generative AI, etc. Incorporating new techniques and methodologies into our processes to keep us ahead in the insurance industry. Minimum Qualifications A master’s/PhD degree in data science, Computer Science, Statistics, Mathematics, or a related field and at least 6 years of relevant work experience or a Bachelor’s Degree in these fields with at least 8 years of relevant work experience High proficiency (5+ years) in Python and Java, or similar programming languages Track record (5+ years) of key/principal contributor roles in design and implementation of large-scale data-driven productions systems, preferably customer-facing 4+ years’ experience with data orchestration workflow tools such as DBT, Airflow etc. 4+ years’ experience working with big-data technologies/databases, e.g. Spark, Mongodb, Elastic search, Snowflake, Neo4j, etc. 4+ years’ experience working with cloud providers such as AWS and Azure, esp. AI/ML related capabilities such as Aure ML, AWS Sage Maker, Azure OpenAI, AWS Bedrock, etc. Preferred Qualifications 3+ years’ experience in building, deploying, and maintaining AI-ML pipelines and API services on both CPU and GPU-based infrastructure. 3+ years’ experience in processing unstructured data. Experience in designing and building metrics dashboard and UI applications for AI/ML systems, using frameworks such as Streamlit, Dash, Shiny, etc. Experience with building GenAI services & platforms. Domain knowledge on insurance or financial service/fintech sectors. Working knowledge of machine learning techniques and predictive modeling Key Competencies Creativity: Able to think outside the box to find innovative solutions to complex problems. Intellectual Curiosity: Passionate about learning and staying updated with the latest developments in the field. Strategic Thinking: Can envision long-term strategies and align day-to-day activities towards achieving them. Decision-Making: Makes sound decisions based on data, analysis, and experience. Adaptability: Thrives in a fast-paced environment, adapting to changing business needs. Make bold experiments and not be afraid of some failures Attention to Detail: Ensures precision and accuracy in all tasks and projects. Interpersonal Sensitivity: Works effectively in team settings, valuing and respecting the views and roles of others. At this time, GEICO will not sponsor a new applicant for employment authorization for this position. Benefits: As an Associate, you’ll enjoy our Total Rewards Program* to help secure your financial future and preserve your health and well-being, including: Premier Medical, Dental and Vision Insurance with no waiting period** Paid Vacation, Sick and Parental Leave 401(k) Plan Tuition Reimbursement Paid Training and Licensures Benefits may be different by location. Benefit eligibility requirements vary and may include length of service. Coverage begins on the date of hire. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect. The equal employment opportunity policy of the GEICO Companies provides for a fair and equal employment opportunity for all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO hires and promotes individuals solely on the basis of their qualifications for the job to be filled. GEICO reasonably accommodates qualified individuals with disabilities to enable them to receive equal employment opportunity and/or perform the essential functions of the job, unless the accommodation would impose an undue hardship to the Company. This applies to all applicants and associates. GEICO also provides a work environment in which each associate is able to be productive and work to the best of their ability. We do not condone or tolerate an atmosphere of intimidation or harassment. We expect and require the cooperation of all associates in maintaining an atmosphere free from discrimination and harassment with mutual respect by and for all associates and applicants.",
        "url": "https://www.linkedin.com/jobs/view/3920117364",
        "summary": "GEICO seeks a lead machine learning scientist to build durable AI/ML systems and services for operational efficiency and industry innovation. Responsibilities include AI system architecture, feature/data engineering, service integration, MLOps, technical leadership, communication, and R&D. Requires strong programming skills, experience with large-scale data-driven systems, cloud providers, and big data technologies. Preferred qualifications include GenAI experience and insurance domain knowledge.",
        "industries": [
            "Insurance",
            "Financial Services",
            "Fintech",
            "Technology"
        ],
        "soft_skills": [
            "Creativity",
            "Intellectual Curiosity",
            "Strategic Thinking",
            "Decision-Making",
            "Adaptability",
            "Attention to Detail",
            "Interpersonal Sensitivity"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "DBT",
            "Airflow",
            "Spark",
            "Mongodb",
            "Elastic Search",
            "Snowflake",
            "Neo4j",
            "AWS",
            "Azure",
            "Azure ML",
            "AWS SageMaker",
            "Azure OpenAI",
            "AWS Bedrock",
            "Streamlit",
            "Dash",
            "Shiny",
            "Machine Learning",
            "Predictive Modeling",
            "NLP",
            "Generative AI"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "DBT",
            "Airflow",
            "Spark",
            "Mongodb",
            "Elastic Search",
            "Snowflake",
            "Neo4j",
            "AWS",
            "Azure",
            "Azure ML",
            "AWS SageMaker",
            "Azure OpenAI",
            "AWS Bedrock",
            "Streamlit",
            "Dash",
            "Shiny"
        ],
        "programming_languages": [
            "Python",
            "Java"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Master’s",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Paid Vacation",
            "Sick Leave",
            "Parental Leave",
            "401(k) Plan",
            "Tuition Reimbursement",
            "Paid Training",
            "Licensures"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3963700600,
        "company": "TENICA Global Solutions",
        "title": "Senior Data Scientist - TS/SCI CI poly",
        "created_on": 1720587168.9832413,
        "description": "Senior Data Scientist TS/SCI CI poly Department : Govt Customer-Chantilly Location : Chantilly, VA TENICA is looking to hire a Senior Data Scientist in Chantilly, VA. MUST HAVE TS/SCI with CI poly. Develop and conduct algorithm quality trade studies related to synthetic aperture radar imagery, identifying best use cases for selected algorithms, and characterizing performance of algorithms when used outside the best use case scenarios. Prototype analytical processes and toolbox for exercising algorithms, that will generate confidence values based on algorithm outputs. Refine the verification and validation process for analytics. Develop software/scripts for running and testing the algorithms and analytics, leveraging languages and programs such as Databricks, Python, and Jupyter Notebook. Make presentations and reports at the request of the government in addition to a task kick off, midpoint review, and final report and presentation. Experience in in Mathematics/Statistics and Computer Science is desired. 10 years of experience with a BA/BS degree (or 6 years with a MA/MS degree.) Required skills and experience include programming and script development in Python, understanding software development process in a CI/CD pipeline leveraging github, and algorithm implementation and training; Desire experience in DevOps, synthetic aperture radar image science or analysis or other remote sensing imaging such as multispectral. TENICA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",
        "url": "https://www.linkedin.com/jobs/view/3963700600",
        "summary": "TENICA is seeking a Senior Data Scientist with TS/SCI with CI poly clearance to develop and evaluate algorithms for synthetic aperture radar imagery. The role involves prototyping analytical processes, refining verification and validation methods, and developing software/scripts using Python and Databricks. Experience in mathematics/statistics, computer science, DevOps, and remote sensing imaging is desired.  ",
        "industries": [
            "Defense",
            "Government",
            "Technology",
            "Data Science",
            "Remote Sensing"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Reporting",
            "Problem Solving",
            "Collaboration"
        ],
        "hard_skills": [
            "Python",
            "Databricks",
            "Jupyter Notebook",
            "Synthetic Aperture Radar",
            "Algorithm Development",
            "Algorithm Evaluation",
            "Data Analysis",
            "Software Development",
            "CI/CD Pipeline",
            "GitHub",
            "DevOps",
            "Remote Sensing"
        ],
        "tech_stack": [
            "Python",
            "Databricks",
            "Jupyter Notebook",
            "GitHub",
            "CI/CD Pipeline"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 10,
        "education": {
            "min_degree": "BA/BS",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Equal Opportunity Employer"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3945735010,
        "company": "Elder Research",
        "title": "Software Engineer",
        "created_on": 1720587170.7174706,
        "description": "Location: Hybrid On-Site in DC Metro Area (2-3 days per week on client site Pentagon, Alexandria, Falls Church, Arlington) Clearance Required: Secret People Centered. Data Driven Elder Research Inc. is a Data Science consulting firm specialized in providing analytic solutions to clients in Commercial and Government industries. Providing analytic solutions to hundreds of companies across numerous industries, our team enjoys a great variety in the type of work they do and exposure to a wide range of techniques and tools. We are trusted advisors to our clients, building lasting relationships and partnering as preferred analytics providers. We use a variety of programming languages and tools to create analytic solutions, often fitting within our clients’ environment and needs. Join our team and find great opportunities to hone your analytic skills, work on complex problems with amazing teammates, and gain valuable analytics consulting experience. Required Education Bachelor’s degree plus 7-10 years experience, or a Masters Degree plus 5 years of experience. Required Skills Programming experience with Python, JavaScript, and at least one more programming language (Java is preferred). Experience with front end frameworks like React or Vue. Experience with backend runtimes and frameworks like Node.js, Spring, Spring Boot, Django, Flask, etc. Experience with Agile software development methodologies and tools. Well versed in modern software architectures like micro-services as well as front-end frameworks. DevSecOps experience is optional but preferred. Strong communications skills: you will be required to proactively engage fellow CDAO members both inside and outside of your team. Ability to synthesize requirements underlying feature requests, recommend alternative technical and business approaches, and facilitate engineering efforts to meet aggressive timelines. DODD 8140 IAT Level III is optional but preferred. Major Duties/Tasks Designs and develops software requirements for multiple Artificial Intelligence based support capabilities including the software architectures, APIs, frameworks, and libraries. Develops front end and backend of software prototypes, components, and tooling that can be leveraged to speed prototyping process. Maintains and guides the development of common libraries and tools used by multiple teams. Aids in formulating a strategy on how to achieve rapid prototyping of AI capabilities, including Generative AI. Works with data scientists, UX designers, cognitive scientists, developers, and testers to compose cohesive and sound software designs that form the basis of scalable AI solutions. Documents requirements and specifications and reviews documentation provided by other teams and vendors. Optimizes software designs and architectures to deliver desired performance targets and devises tooling and methodologies to profile execution and capture performance metrics. Stays informed on latest AI system and software architectures and trends from design patterns to DevSecOps and systems architecture patterns. Works closely with clients and requirements owners to build out product lines. Develops plans, road maps, software design strategies. Analyze and decomposes activities and requirements to software designs that are allocated across systems components/sub-components. Captures, develops, and reports reference architectures and documenting compliance standards. About Elder Research, Inc Elder Research is a fast growing consulting firm specializing in predictive analytics. Being in the data mining business over 20 years, we pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately. Our team members are passionate, curious, life-long learners. We value humility, servant-leadership, teamwork, and integrity. We seek to serve our clients and our teammates to the best of our abilities. In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work. Elder Research believes in continuous learning; each week the entire company attends a “Tech Talk” followed by an office lunch. Elder Research provides a supportive work environment with established parental, bereavement, and PTO policies. By prioritizing a healthy work-life balance - with reasonable hours, solid pay, low travel, and extremely flexible time off - Elder Research enables and encourages its employees to serve others. Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Elder Research is a Government contractor and our positions require US Citizenship.",
        "url": "https://www.linkedin.com/jobs/view/3945735010",
        "summary": "Elder Research Inc. is seeking a Data Scientist with 7-10 years of experience to design and develop software requirements for multiple Artificial Intelligence based support capabilities. This role involves working with data scientists, UX designers, cognitive scientists, developers, and testers to compose cohesive and sound software designs that form the basis of scalable AI solutions.",
        "industries": [
            "Consulting",
            "Data Science",
            "Artificial Intelligence",
            "Government"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem Solving",
            "Analytical",
            "Leadership",
            "Humility"
        ],
        "hard_skills": [
            "Python",
            "JavaScript",
            "Java",
            "React",
            "Vue",
            "Node.js",
            "Spring",
            "Spring Boot",
            "Django",
            "Flask",
            "Agile",
            "Microservices",
            "DevSecOps",
            "DODD 8140 IAT Level III",
            "AI",
            "Generative AI",
            "UX Design",
            "Software Architecture",
            "Software Development",
            "API Development",
            "Performance Optimization",
            "System Architecture",
            "Requirements Analysis",
            "Documentation",
            "Compliance"
        ],
        "tech_stack": [
            "Python",
            "JavaScript",
            "Java",
            "React",
            "Vue",
            "Node.js",
            "Spring",
            "Spring Boot",
            "Django",
            "Flask",
            "Agile",
            "Microservices",
            "DevSecOps",
            "AI",
            "Generative AI",
            "API Development"
        ],
        "programming_languages": [
            "Python",
            "JavaScript",
            "Java"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Paid Time Off",
            "Parental Leave",
            "Bereavement Leave",
            "Tech Talks",
            "Office Lunch",
            "Flexible Time Off",
            "Reasonable Hours",
            "Low Travel",
            "Solid Pay"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort George G. Meade, MD",
        "job_id": 3908684064,
        "company": "The Josef Group Inc.",
        "title": "Lead Data Scientist",
        "created_on": 1720587172.445076,
        "description": "Senior Data Scientist – ACTIVE TS/SCI/CI Poly Clearance Prime Contract Backfill Opportunity/ Cutting Edge AI /ML Ten plus years of experience as a Senior Data Scientist – (Active TS/ SCI/CI Poly Clearance ) Prime Opportunity. Ten plus years of experience as a Data Scientist with Python, ML/AI, agile Direct Customer Relations Experience. Experience Leading a team. Desired Skills Background in AI research and solutions development. Project Management Cyber Security Engineering Designing/Implementing Machine-Learning",
        "url": "https://www.linkedin.com/jobs/view/3908684064",
        "summary": "Seeking a Senior Data Scientist with a Top Secret/SCI/CI Polygraph clearance and 10+ years of experience in data science, Python, ML/AI, and agile methodologies. The role involves direct customer relations, team leadership, and designing/implementing machine learning solutions.  Experience in AI research, project management, and cybersecurity engineering is preferred.",
        "industries": [
            "Information Technology",
            "Cybersecurity",
            "Government",
            "Defense"
        ],
        "soft_skills": [
            "Leadership",
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Customer Service"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "AI",
            "Agile",
            "Project Management",
            "Cyber Security Engineering",
            "Data Science"
        ],
        "tech_stack": [
            "Python",
            "ML/AI",
            "Agile"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3940940997,
        "company": "GA-CCRi",
        "title": "Cleared Junior Software Engineer, Computer Vision, Federal",
        "created_on": 1720587173.88721,
        "description": "GA-CCRi maintains and deploys production systems for users across the Intelligence Community, Department of Defense, and commercial industry. We build and develop best-in-class all domain and globally focused situational awareness capabilities, including THRESHER and DRAGONSPELL, that process petabytes of data from numerous streaming data sources in near real time. Our systems apply state-of-the-art algorithms and machine learning techniques to extract features and fuse data from multiple phenomenologies to form a rich live view of objects in the sky, on the sea, and on the ground. These analytics are designed to determine not just where something is, but what it is, where it's been and what it's doing. All of this \"data to knowledge\" is made available to end users in our own browser-based application for visualization, analysis, and understanding. We always want to do more, and that's where you come in! GA-CCRi is looking for a Software Engineer to join our federal team to develop scalable, high-performant cloud-based computer vision systems focused on the automated detection of objects in satellite imagery. State of the art Convolutional Neural Networks (CNNs) are used in AI/ML pipelines to process large volumes of satellite imagery. Object detections from the platform are used by the community to search for objects, maintain object custody, and in Multi-INT analytics. Duties And Responsibilities Under general supervision, develop, integrate, and maintain cloud-based image processing pipelines and infrastructure that process satellite imagery at scale in a cloud environment Develop test scripts and frameworks to verify and validate functionality Maintain existing capabilities deployed to customer facilities and cloud environments including debugging and updating to keep pace with the evolving environment and technology Understand customer, user, and operational requirements and implement new functionality into software products Document and communicate highly technical concepts effectively to technical and non-technical audiences in a clear and effective manner Communicate with management, customers, developers, and users Work directly with internal and external developers to transition applications into the computer vision platform Maintain the strict confidentiality of sensitive information Observe all laws, regulations and other applicable obligations wherever and whenever business is conducted on behalf of the Company Work in a safe manner in accordance with established operating procedures and practices Perform other duties as assigned Requirements Ability to transfer and maintain a Top Secret security clearance with SCI eligibility and a CI poly is required Bachelor's degree in Computer Science, Information Systems, or related discipline. May substitute equivalent experience in lieu of education. Strong experience with cloud-based technologies, including AWS or Azure Experience with software development lifecycle and use of associated tools Linux Proficient programming skills in languages such as Java, Python, Scala, Go, Rust An understanding of formal software engineering principles including design, documentation, ticketing systems, version control and Agile methodologies Must possess the ability to understand new concepts quickly and apply them accurately throughout an evolving requirement Good analytical skills and problem-solving skills High level of self-initiative and self-motivation Ability to work effectively in small steam settings to solve complex problems Good organization, communication, decision making, presentation, and interpersonal skills Customer focused, formulates plans based on the development of innovative new designs in resolving advanced software development problems CompTIA Security+ or willingness to get certified Desired Skills And Experience Curious and excited to learn new technologies Excited about understanding our customer's needs and mission Interested in maintaining and adapting existing codebases Satellite image processing and computer vision applications Image processing libraries such as GDAL, OpenCV Understanding of full lifecycle development Able to build and deploy working prototypes GEOINT AI/ML pipelines Geospatial data processing Cloud technologies such as Kubernetes, Helm Data brokers such as Kafka and RabbitMQ Knative CI/CD pipelines and tooling (Gitlab CI/CD, ArgoCD, CircleCI, Jenkins) RESTful APIs Databases technologies (PostgreSQL, Redis, or other DBs) Travel Percentage Required 0-10% Relocation Assistance Provided Yes US Citizenship Required? Yes Clearance Required? Yes Clearance Level Ability to transfer and maintain a Top Secret security clearance with SCI eligibility and a CI poly is required. Pay Range $84,000-$120,000 Benefits Casual Work Environment Intellectually Challenging Work Health Insurance including FSA, HSA and Tricare Supplement options Short/Long Term Disability Insurance Generous Defined Retirement Benefit, including both a 401K match and pension plan. Very Flexible Vacation Policy The job description above is not intended to be comprehensive list. Responsibilities, activities, duties, and/or tasks may change or be assigned at any time. CCRi is committed to a diverse and inclusive workforce because we know that our differences benefit our employees, our customers, and our community. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, color, religion, age, sex, sexual orientation, gender identity, national origin, status as a an individual with a disability, status as a protected veteran, or any other applicable legally protected characteristics.",
        "url": "https://www.linkedin.com/jobs/view/3940940997",
        "summary": "GA-CCRi is seeking a Software Engineer to develop scalable, cloud-based computer vision systems for automated object detection in satellite imagery. Responsibilities include developing image processing pipelines, testing functionality, maintaining existing capabilities, and understanding customer requirements. The role requires strong experience with cloud technologies (AWS or Azure), software development lifecycle, and programming languages such as Java, Python, Scala, Go, or Rust. Knowledge of image processing libraries (GDAL, OpenCV), GEOINT AI/ML pipelines, and cloud technologies like Kubernetes, Helm, and Knative are desirable.",
        "industries": [
            "Intelligence",
            "Defense",
            "Aerospace",
            "Computer Vision",
            "Software Development",
            "Cloud Computing",
            "Satellite Imagery"
        ],
        "soft_skills": [
            "Communication",
            "Analytical Skills",
            "Problem Solving",
            "Self-Initiative",
            "Self-Motivation",
            "Teamwork",
            "Organization",
            "Decision Making",
            "Presentation",
            "Interpersonal",
            "Customer Focus",
            "Innovation"
        ],
        "hard_skills": [
            "Cloud Technologies",
            "AWS",
            "Azure",
            "Software Development Lifecycle",
            "Linux",
            "Java",
            "Python",
            "Scala",
            "Go",
            "Rust",
            "Design",
            "Documentation",
            "Ticketing Systems",
            "Version Control",
            "Agile Methodologies",
            "GDAL",
            "OpenCV",
            "GEOINT AI/ML",
            "Geospatial Data Processing",
            "Kubernetes",
            "Helm",
            "Knative",
            "Kafka",
            "RabbitMQ",
            "CI/CD",
            "Gitlab CI/CD",
            "ArgoCD",
            "CircleCI",
            "Jenkins",
            "RESTful APIs",
            "PostgreSQL",
            "Redis"
        ],
        "tech_stack": [
            "AWS",
            "Azure",
            "Linux",
            "Java",
            "Python",
            "Scala",
            "Go",
            "Rust",
            "GDAL",
            "OpenCV",
            "Kubernetes",
            "Helm",
            "Knative",
            "Kafka",
            "RabbitMQ",
            "Gitlab CI/CD",
            "ArgoCD",
            "CircleCI",
            "Jenkins",
            "RESTful APIs",
            "PostgreSQL",
            "Redis"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "Scala",
            "Go",
            "Rust"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Information Systems"
            ]
        },
        "salary": {
            "max": 120000,
            "min": 84000
        },
        "benefits": [
            "Casual Work Environment",
            "Intellectually Challenging Work",
            "Health Insurance",
            "FSA",
            "HSA",
            "Tricare Supplement",
            "Short/Long Term Disability Insurance",
            "Retirement Benefit",
            "401K match",
            "Pension Plan",
            "Flexible Vacation Policy"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Silver Spring, MD",
        "job_id": 3921456256,
        "company": "Motion Recruitment",
        "title": "Senior Data Scientist / Fintech / Remote",
        "created_on": 1720587175.5514228,
        "description": "Our client is a dynamic and innovative fintech company dedicated to revolutionizing the financial landscape and improving personal financial wellness through cutting-edge technology and data-driven solutions. Their mission is to empower individuals to make smarter financial decisions by harnessing the power of financial literacy and data science. The company is seeking a highly skilled Senior Data Scientist to join their growing team. As a Senior Data Scientist, you will play a pivotal role in driving data science initiatives, leveraging your expertise to extract valuable insights from complex datasets and develop predictive models. The ideal candidate will have a proven track record of success in a startup or small-scale company environment, possessing the agility and adaptability to thrive in a fast-paced and collaborative setting. Responsibilities Data Exploration and Analysis: Lead the exploration and analysis of large, complex datasets to uncover actionable insights and identify opportunities for optimization. Model Development: Develop advanced machine learning models and algorithms to address business challenges, such as customer segmentation, risk assessment, and fraud detection. Prototype Development: Rapidly prototype and iterate on data-driven solutions, working closely with cross-functional teams to translate business requirements into technical specifications. Model Deployment: Collaborate with software engineers to deploy models into production environments, ensuring scalability, reliability, and performance. Performance Monitoring and Optimization: Continuously monitor model performance and iterate on methodologies to improve predictive accuracy and efficiency. Cross-functional Collaboration: Work closely with stakeholders across the organization, including product managers, engineers, and executives, to align data science initiatives with strategic objectives. Mentorship and Leadership: Provide guidance and mentorship to junior members of the data science team, fostering a culture of continuous learning and professional development. Qualifications Advanced Degree: Master's or Ph.D. in Computer Science, Statistics, Mathematics, or a related field. Experience: 5+ years of experience in data science, with a focus on machine learning, predictive modeling, and statistical analysis. Technical Proficiency: Proficiency in Python, as well as experience with libraries such as TensorFlow, PyTorch, scikit-learn, and pandas. Startup Experience: Demonstrated experience working in a startup or small-scale company environment, with the ability to thrive in a fast-paced and dynamic setting. Team Collaboration: Strong interpersonal and communication skills, with the ability to collaborate effectively with cross-functional teams and stakeholders. Preferred Qualifications Financial Services Experience: Previous experience working in the fintech or financial services industry, with knowledge of financial products, markets, and regulations. Cloud Computing: Experience with cloud computing platforms such as AWS, Azure, or Google Cloud Platform, including knowledge of services such as AWS SageMaker or Google Cloud AI Platform. Big Data Technologies: Familiarity with big data technologies such as Hadoop, Spark, or Kafka, as well as experience working with large-scale distributed systems. Benefits Competitive Salary Medical Insurance Dental Benefits Vision Benefits Paid Time Off (PTO) 401(k) Applicants must be currently authorized to work in the US on a full-time basis now and in the future.** Posted By: Lindsay Troyer",
        "url": "https://www.linkedin.com/jobs/view/3921456256",
        "summary": "A dynamic fintech company is looking for a Senior Data Scientist to join their growing team. You will be responsible for data exploration, model development, prototyping, deployment, performance monitoring, and cross-functional collaboration. You will also mentor junior data scientists and help foster a culture of continuous learning.",
        "industries": [
            "Fintech",
            "Financial Services",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Leadership",
            "Mentorship"
        ],
        "hard_skills": [
            "Data Exploration",
            "Data Analysis",
            "Machine Learning",
            "Predictive Modeling",
            "Statistical Analysis",
            "Python",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Pandas",
            "Cloud Computing",
            "AWS",
            "Azure",
            "Google Cloud Platform",
            "AWS SageMaker",
            "Google Cloud AI Platform",
            "Big Data Technologies",
            "Hadoop",
            "Spark",
            "Kafka"
        ],
        "tech_stack": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "pandas",
            "AWS",
            "Azure",
            "Google Cloud Platform",
            "AWS SageMaker",
            "Google Cloud AI Platform",
            "Hadoop",
            "Spark",
            "Kafka"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Medical Insurance",
            "Dental Benefits",
            "Vision Benefits",
            "Paid Time Off (PTO)",
            "401(k)"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3966373030,
        "company": "Brillient Corporation",
        "title": "Data Scientist Sr",
        "created_on": 1720587178.5552385,
        "description": "What makes Brillient a GREAT fit for you? When you join Brillient, you become part of an award-winning Full Spectrum Digital Transformation company focused on helping agencies in the continuum of analog, to digital, to analytics, leading to insight-driven decision making and mission execution. About Our mission is to provide value to our clients and our people, operate with the highest integrity as a trusted business partner, adopt a workstyle that is flexible allowing us to effectively collaborate while being agile and nimble, and be innovative in everything we do. We are passionate about ensuring our employees experience a work environment that is inclusive, professional, and supportive. In addition to these core values, the Brillient team is driven by: Focus on Sustainability- Being an environmentally conscious, green company with sustainable practices. Impact on the Community- Social responsibility to the communities we live and work in. At Brillient, we achieve our purpose by hiring brilliant people with passion, drive, capabilities, and experience to help our clients achieve their mission goals through innovation in processes and technologies. Brillient is a client-centric , employee-focused company with a vibrant culture. What We Offer (See Our Career Page for Further Details): An engaging and supportive work environment where every employee is valued, a rewarding career, and outstanding benefits which currently include: Ample paid time off Medical, Dental, & Vision Plans Company Sponsored Wellness Programs Paid Life Insurance and STD Paid Employee Assistance Program Voluntary Life & TD coverage 401(k) w. Company Match Competitive wages Quarterly Performance Development Company Discounts Continuing Education Support Who You Are Value based, High Integrity, Flexible, & Innovative What You Will Do Possess a degree in statistics, mathematics, computer science or related degree. Previous experience in applying various machine learning technologies including supervised, unsupervised and reinforcing learning techniques. Previous experience working with cloud based analytic environments. Previous experience working with synthetic data models and cohorts. Previous experience with developing and analyzing data models and cohorts specific to the healthcare field. May support projects and activities related to Artificial Intelligence and Machine Learning. What You Will Need (Qualifications) Masters Degree 8 years experience US Citizen Able to obtain and maintain Public Trust security clearance Diversity, Inclusion, & Engagement At Brillient At Brillient, we not only accept difference, we promote it, we embrace it, and we thrive on it for the betterment of our patients, our employees, and our culture. We are proud to be an equal opportunity workplace and an affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any other status protected under applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3966373030",
        "summary": "Brillient is a digital transformation company focused on helping agencies with data analytics and insight-driven decision making. They value integrity, flexibility, and innovation in their work. They are looking for a data scientist with experience in machine learning, cloud-based analytics, synthetic data models, and healthcare data analysis. The position requires a Master's degree, 8 years of experience, US citizenship, and the ability to obtain a Public Trust security clearance.",
        "industries": [
            "Digital Transformation",
            "Data Analytics",
            "Healthcare",
            "Technology",
            "Government"
        ],
        "soft_skills": [
            "Integrity",
            "Flexibility",
            "Innovation",
            "Collaboration",
            "Teamwork",
            "Passion",
            "Drive",
            "Problem-Solving",
            "Analytical",
            "Communication",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "Supervised Learning",
            "Unsupervised Learning",
            "Reinforcement Learning",
            "Cloud-Based Analytics",
            "Synthetic Data Models",
            "Data Modeling",
            "Data Analysis",
            "Healthcare Data Analysis",
            "Artificial Intelligence",
            "Statistics",
            "Mathematics",
            "Computer Science"
        ],
        "tech_stack": [
            "Cloud-Based Analytics",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "programming_languages": [],
        "experience": 8,
        "education": {
            "min_degree": "Master's Degree",
            "fields": [
                "Statistics",
                "Mathematics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Ample paid time off",
            "Medical, Dental, & Vision Plans",
            "Company Sponsored Wellness Programs",
            "Paid Life Insurance and STD",
            "Paid Employee Assistance Program",
            "Voluntary Life & TD coverage",
            "401(k) w. Company Match",
            "Competitive wages",
            "Quarterly Performance Development",
            "Company Discounts",
            "Continuing Education Support"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3967757997,
        "company": "Extend Information Systems Inc.",
        "title": "Python Developer (W2/1099 Only)",
        "created_on": 1720587181.8377879,
        "description": "Hi Jobseekers, Hope You are doing good. Position: Python Developer Location: McLean /Richmond (VA) /Plano(TX)/ NYC, NY (Hybrid Model) Duration: 6-12+ Months Required Qualifications: • Min 5 years of hands on experience in Python • Python, Spark, AWS • Data/Backend Software Developer Nice to have: • Certifications - AWS Solutions architect • Financial Domain Thanks & Regards Shankar Kr Singh Extend Information Systems Email: shankar@extendinfosys.com Address: 44355 Premier Plaza UNIT 220, Ashburn, VA, USA - 20147 Web: WWW.extendinfosys.com",
        "url": "https://www.linkedin.com/jobs/view/3967757997",
        "summary": "Python Developer with 5+ years of experience in Python, Spark, and AWS. Experience in data/backend software development and AWS Solutions Architect certification is a plus. Hybrid work model in McLean/Richmond (VA), Plano (TX), or NYC.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Finance"
        ],
        "soft_skills": [],
        "hard_skills": [
            "Python",
            "Spark",
            "AWS",
            "Data/Backend Software Development"
        ],
        "tech_stack": [
            "Python",
            "Spark",
            "AWS"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3962225701,
        "company": "SAIC",
        "title": "Data Scientist Principal to work in Reston, VA",
        "created_on": 1720587183.2729833,
        "description": "Job ID 2408727 Location RESTON, VA, US Date Posted 2024-06-26 Category Information Technology Subcategory Data Scientist Schedule Full-time Shift Day Job Travel No Minimum Clearance Required None Clearance Level Must Be Able to Obtain None Potential for Remote Work No Description Data Scientist Principal to work in Reston, VA. Responsibilities And Duties Conduct exploratory data analysis. Maintain predictive analytical models utilizing a variety of AI tools. Conduct proactive research into opportunities to add advanced analytic capabilities to current data products. Perform data visualization in order to simply the impact of the analysis. Assist in data science libraries/methods to best add value to the team. Develop and document data flows and statistical methods in the data science pipeline. Utilize Python and Databricks to provide support for data engineering pipeline tasks. Assist code to systems that collect, manage, and convert raw data into usable information for business analysts to interpret. Collaborate with business stakeholders, business operations, and product teams. Qualifications Requires a Bachelor’s degree in Business Analytics (or equivalent based on evaluation of academic credentials, training and/or experience) as well as twenty-four (24) months in job or job related experience to include conduct exploratory data analysis; develop and document data flows and statistical methods for data analysis; collect, manage, and convert raw data into usable information for business analysts to interpret; and collaborate with business stakeholders, business operations, and product teams. Opportunity to work from home. Apply online at https//jobs.saic.com/. Must ref job code #2408727. SAIC accepts applications on an ongoing basis and there is no deadline. Covid Policy SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.",
        "url": "https://www.linkedin.com/jobs/view/3962225701",
        "summary": "SAIC is seeking a Data Scientist Principal to work in Reston, VA. The candidate will conduct exploratory data analysis, maintain predictive analytical models using AI tools, research opportunities for advanced analytics, perform data visualization, develop data science libraries/methods, document data flows and statistical methods, utilize Python and Databricks for data engineering pipeline tasks, convert raw data into usable information for business analysts, and collaborate with business stakeholders. Requires a Bachelor's degree in Business Analytics or equivalent and 24 months of relevant experience.",
        "industries": [
            "Information Technology",
            "Data Science",
            "Business Analytics",
            "AI",
            "Data Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Research",
            "Analytical Thinking",
            "Teamwork",
            "Stakeholder Management"
        ],
        "hard_skills": [
            "Exploratory Data Analysis",
            "Predictive Modeling",
            "AI Tools",
            "Data Visualization",
            "Data Science Libraries",
            "Statistical Methods",
            "Python",
            "Databricks",
            "Data Engineering",
            "Data Collection",
            "Data Management",
            "Data Conversion"
        ],
        "tech_stack": [
            "Python",
            "Databricks"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 24,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Business Analytics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3959698011,
        "company": "ManTech",
        "title": "Data Scientist Engineer",
        "created_on": 1720587184.6791337,
        "description": "Secure our Nation, Ignite your Future Become an integral part of a diverse team while working at an Industry Leading Organization, where our employees come first. At ManTech International Corporation, you’ll help protect our national security while working on innovative projects that offer opportunities for advancement. Currently, ManTech is seeking a motivated, career and customer-oriented Data Scientist Engineer to join our team in the Washington Navy Yard. Job Summary: The Data Scientist Engineer analyzes engineering and technical data and advises on how to build the architecture to layout that technical data in databases, Product Lifecycle Management (PLM) tools, and models to allow the engineering workforce to easily search for needed information. This position directly supports the Nimitz (CVN68) and Ford (CVN78) Class Aircraft Carrier Engineering Team. Responsibilities include but not limited to: Analyze engineering/technical data and work with the collective government-industry team to recommend innovative strategies on organizing the data in PLM type tools Apply knowledge of engineering architecture/interfaces to work with engineers on processes to organize the engineering design of carriers into logical breakouts (leveraging existing WBS, system lists, etc.) Assess and model system and component operational data to quantify performance Work with government management to develop business cases for required software and tools needed to perform required duties Manage projects and work within a team to solve complex problems May lead teams or projects with varying degrees of resource requirements, risk, and/or complexity Review ship, procurement, and systems specifications and submit proposals for changes Minimum Qualifications: Bachelor’s degree in Engineering, Computer Science, or a related discipline from an accredited college or university 7+ years of relevant experience to include data management Must have extensive experience using Microsoft Power Platform preferably in the Flank Speed environment Preferred Qualifications: Experience and understanding of naval ship acquisition and maintenance Experience and understanding of ship construction Experience working at a shipyard, Naval Surface/Undersea Warfare Center (NSWC/NUWC), Supervisor of Shipbuilding Command (SUPSHIP), Regional Maintenance Center (RMC), and/or Type Commander (TYCOM) supporting construction, operation, maintenance, modernization, and/or repair of shipboard systems Experience with shipboard networks and systems Open to occasional local travel Security Clearance Requirements: Must possess a currently active U.S. Government Secret Security clearance Physical Requirements: Must be able to remain in a stationary position 50% The person in this position frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer The projected compensation range for this position is $122,600-$204,200. There are differentiating factors that can impact a final salary/hourly rate, including, but not limited to, Contract Wage Determination, relevant work experience, skills and competencies that align to the specified role, geographic location (For Remote Opportunities), education and certifications as well as Federal Government Contract Labor categories. In addition, ManTech invests in it’s employees beyond just compensation. ManTech’s benefits offerings include, dependent upon position, Health Insurance, Life Insurance, Paid Time Off, Holiday Pay, Short Term and Long Term Disability, Retirement and Savings, Learning and Development opportunities, wellness programs as well as other optional benefit elections. For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.",
        "url": "https://www.linkedin.com/jobs/view/3959698011",
        "summary": "Data Scientist Engineer analyzes engineering and technical data to build architecture for organizing data in databases, PLM tools, and models. Works with government-industry team to recommend innovative strategies for data organization, assesses and models system/component data, develops business cases for software and tools, manages projects, and reviews ship/procurement specifications.",
        "industries": [
            "Defense",
            "Aerospace",
            "Government",
            "Engineering",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Analytical",
            "Problem-Solving",
            "Communication",
            "Teamwork",
            "Leadership",
            "Project Management"
        ],
        "hard_skills": [
            "Data Management",
            "Microsoft Power Platform",
            "Engineering Architecture",
            "Data Modeling",
            "Business Case Development",
            "Project Management",
            "Ship Systems",
            "Ship Acquisition",
            "Ship Construction",
            "Ship Maintenance",
            "Shipboard Networks",
            "Shipboard Systems"
        ],
        "tech_stack": [
            "Microsoft Power Platform",
            "PLM Tools",
            "Databases",
            "Engineering Data Models",
            "Shipboard Systems"
        ],
        "programming_languages": [],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Engineering",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 204200,
            "min": 122600
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Paid Time Off",
            "Holiday Pay",
            "Short Term and Long Term Disability",
            "Retirement and Savings",
            "Learning and Development opportunities",
            "Wellness programs"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3969265238,
        "company": "Exostar",
        "title": "Solutions Engineer",
        "created_on": 1720587186.22056,
        "description": "Title: Solutions Engineer Location: Herndon, VA or remote from: VA, MD, DC, NC, SC, GA, PA, NJ, FL, TX, IL, WA Terms: Full-Time/Permanent Responsibilities Your day, if you join us (essential functions): Support the Sales team in helping customers understand what they can achieve with the Exostar Platform. Understand customer requirements and communicate the business value of solving technology problems using a SaaS solution. Execute the delivery of POCs for customers, collaborating with Services, Operations, Engineering, and the Product Team as necessary. Craft Solutions documents to show prospects and customers how to implement specific use cases across the Exostar Platform. Prepare demos and proof of concepts with success criteria to demonstrate various use cases for Exostar’s Platform. Distill and communicate customer needs and product feedback to Product Management, Engineering, Marketing and Sales. You meet our “must haves” for this role if: 5+ years of pre-sales engineering, solutions architect, or related experience. Experience in other customer facing roles such as Services, Support, or Customer Success. Ability to whiteboard solutions quickly and explain them for both technical and non-technical audiences. Use your understanding of SAML, WS-FED, OIDC and other protocols to craft customer and prospect solutions. Understand government and industry requirements and regulations along with their impact on processes and solutions in particular ITAR, NIST 800-171and CMMC when working with vendors and external service providers. An understanding of core security concerns within a typical application and in SAAS applications and their hosting (password hashing, SSL/TLS, encryption at rest, XSS, XSRF). Writing sample and demonstration example will be required. Bachelor's degree in Engineering, Computer Science, MIS or a comparable field is preferred. Preferred Qualifications: You have a Bachelor’s degree in Computer Science, Engineering or another technical degree and/or 5 years of experience in a Sales Engineering or equivalent technical customer facing capacity. You are a strong team player with intense focus on customer success. You are detail oriented, flexible and have a commitment to deadlines. You have experience with technical documentation and strong analytical skills. You have experience developing demonstrations and leading Proof of Concept projects. You have experience with SaaS or Cloud services. You enjoy collaborating with others for creative problem solving. You have the ability to take initiative and be proactive. Exostar is an Equal Opportunities Employer. The Company provides equal employment opportunities to all applicants without regard to race, color, religion, sex, national origin, age, marital status, disability status or genetic information. Exostar is committed to providing equal employment opportunities for all persons in all facets of employment including recruiting, hiring, compensation, promotion, training, benefits, transfers and working conditions.",
        "url": "https://www.linkedin.com/jobs/view/3969265238",
        "summary": "Exostar is seeking a Solutions Engineer to join their team. The role involves supporting the Sales team in helping customers understand the Exostar Platform, crafting solutions documents, and preparing demos and proofs of concept. The ideal candidate will have 5+ years of pre-sales engineering or related experience, strong communication skills, and experience with SAML, WS-FED, OIDC, and other protocols.",
        "industries": [
            "Software",
            "Information Technology",
            "Security",
            "Cybersecurity",
            "SaaS"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Customer Focus",
            "Detail Oriented",
            "Flexibility",
            "Proactive",
            "Analytical",
            "Initiative"
        ],
        "hard_skills": [
            "SAML",
            "WS-FED",
            "OIDC",
            "ITAR",
            "NIST 800-171",
            "CMMC",
            "Password Hashing",
            "SSL/TLS",
            "Encryption at Rest",
            "XSS",
            "XSRF",
            "Technical Documentation"
        ],
        "tech_stack": [
            "Exostar Platform",
            "SaaS",
            "Cloud Services"
        ],
        "programming_languages": [],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Engineering",
                "Computer Science",
                "MIS"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3964333395,
        "company": "TECONICA SOFTWARES",
        "title": "R Shiny Developer",
        "created_on": 1720587187.66285,
        "description": "Company Description TECONICA SOFTWARES is an information technology-based business process management and outsourcing services company. Established in 2016, we provide reliable, consistent, and high-quality solutions to mid and large-sized organizations. With corporate headquarters in the US and India, we serve clients throughout the US with world-class resources and solutions. Our team of certified professionals is dedicated to helping clients enhance their IT initiatives and achieve maximum business value from technology investments. Role Description This is a contract role for a R Shiny Developer. The R Shiny Developer will be responsible for the day-to-day tasks associated with developing R Shiny applications, including designing, coding, testing, and maintaining applications. This is a hybrid role located in the Washington DC-Baltimore Area with flexibility for some remote work. Qualifications Proficiency in R programming language and experience with R Shiny framework Experience in designing, coding, testing, and maintaining R Shiny applications Strong understanding of data visualization principles and experience with data manipulation and analysis Knowledge of web development technologies such as HTML, CSS, and JavaScript Experience with version control systems such as Git Excellent problem-solving and analytical skills Strong communication and collaboration skills Ability to work independently and in a team environment Bachelor's degree in Computer Science, Information Technology, or a related field Experience in the healthcare or pharmaceutical industry is a plus",
        "url": "https://www.linkedin.com/jobs/view/3964333395",
        "summary": "TECONICA SOFTWARES seeks a contract R Shiny Developer to design, code, test, and maintain R Shiny applications. This hybrid role in the Washington DC-Baltimore area involves data visualization, data manipulation, web development, version control, and strong communication skills.",
        "industries": [
            "Information Technology",
            "Business Process Management",
            "Outsourcing",
            "Healthcare",
            "Pharmaceutical"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Communication",
            "Collaboration",
            "Independent Work"
        ],
        "hard_skills": [
            "R Programming",
            "R Shiny",
            "Data Visualization",
            "Data Manipulation",
            "Data Analysis",
            "HTML",
            "CSS",
            "JavaScript",
            "Git"
        ],
        "tech_stack": [
            "R",
            "R Shiny",
            "HTML",
            "CSS",
            "JavaScript",
            "Git"
        ],
        "programming_languages": [
            "R",
            "JavaScript"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Information Technology"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3956946882,
        "company": "SMARTWORK IT SERVICES LLC (SWITS)",
        "title": "SDET Engineer",
        "created_on": 1720587189.0504687,
        "description": "Hello professionals, Positon: SDET Engineer Location: McLean, VA (onsite) Hiring: C2C Main skills:Selenium, Java, BDD, Cucumber. Job Description Design, develop, and maintain automated test frameworks and test suites using Selenium WebDriver, Java, BDD (Behavior Driven Development), and Cucumber. Create and execute automated test scripts to verify end-to-end system functionality, performance, and scalability. Collaborate with cross-functional teams to understand project requirements and develop comprehensive test plans. Identify, record, and track bugs to resolution using bug tracking tools. Participate in Agile ceremonies such as sprint planning, daily stand-ups, and retrospectives. Perform manual testing when necessary to ensure comprehensive test coverage. Contribute to continuous integration and continuous deployment (CI/CD) pipelines to streamline testing and deployment processes. Stay up-to-date with industry best practices and trends in software testing and test automation. Preferred Qualifications Experience with continuous integration tools (e.g., Jenkins, GitLab CI). Familiarity with version control systems such as Git. Knowledge of performance testing tools (e.g., JMeter) is a plus. Experience in testing web services (RESTful APIs).",
        "url": "https://www.linkedin.com/jobs/view/3956946882",
        "summary": "SDET Engineer responsible for designing, developing, and maintaining automated test frameworks using Selenium WebDriver, Java, BDD, and Cucumber. They will create and execute automated test scripts, collaborate with cross-functional teams, identify and track bugs, participate in Agile ceremonies, and perform manual testing when necessary. Experience with CI/CD pipelines, continuous integration tools like Jenkins/GitLab CI, and version control systems like Git is preferred. Familiarity with performance testing tools like JMeter and experience in testing web services (RESTful APIs) is a plus.",
        "industries": [
            "Software Testing",
            "Software Development",
            "Information Technology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Teamwork",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Selenium",
            "Java",
            "BDD",
            "Cucumber",
            "Jenkins",
            "GitLab CI",
            "Git",
            "JMeter",
            "RESTful APIs"
        ],
        "tech_stack": [
            "Selenium",
            "Java",
            "BDD",
            "Cucumber",
            "Jenkins",
            "GitLab CI",
            "Git",
            "JMeter",
            "RESTful APIs"
        ],
        "programming_languages": [
            "Java"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3922484161,
        "company": "Summit Human Capital",
        "title": "100% Remote Software Engineer Generalist",
        "created_on": 1720587190.6461313,
        "description": "Required Skills Summit Human Capital is seeking a highly motivated 100% Remote Software Engineering Generalist to support a fast-growing cyber security start up! This is a customer-facing role, and the ideal candidate will meet the following criteria: Must have 4-5 years of professional experience working with multiple different programming languages like Go, Java, or Python - Go is heavily desired. Experience working in cloud environments such as AWS, Azure, or GCP. Containerization experience with Docker or Kubernetes. Background with .Net Core, Bash, and Linux. Desired Skills JavaScript / NodeJs Experience building CLI or SDK's Experience CI/CD pipelines (Github/Gitlab) Responsibilities Maintaining and developing software components for several different clients Investigate customer bug reports and assist with fixing defined software issues Participate in code, design, and architectural reviews Document requirements and design specifications as well as verification plans and test cases Ability and willingness to learn new programming languages per customer requirements.",
        "url": "https://www.linkedin.com/jobs/view/3922484161",
        "summary": "Summit Human Capital seeks a remote Software Engineering Generalist with 4-5 years of experience in Go, Java, Python, AWS, Azure, GCP, Docker, Kubernetes, .Net Core, Bash, and Linux. The role involves maintaining and developing software components, investigating customer bug reports, participating in code reviews, and documenting requirements.",
        "industries": [
            "Cyber Security",
            "Software Development",
            "Cloud Computing",
            "Information Technology"
        ],
        "soft_skills": [
            "Motivated",
            "Customer-Facing",
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Documentation",
            "Learning"
        ],
        "hard_skills": [
            "Go",
            "Java",
            "Python",
            "AWS",
            "Azure",
            "GCP",
            "Docker",
            "Kubernetes",
            ".Net Core",
            "Bash",
            "Linux",
            "JavaScript",
            "NodeJs",
            "CLI",
            "SDK",
            "CI/CD",
            "GitHub",
            "GitLab"
        ],
        "tech_stack": [
            "Go",
            "Java",
            "Python",
            "AWS",
            "Azure",
            "GCP",
            "Docker",
            "Kubernetes",
            ".Net Core",
            "Bash",
            "Linux",
            "JavaScript",
            "NodeJs",
            "CLI",
            "SDK",
            "GitHub",
            "GitLab"
        ],
        "programming_languages": [
            "Go",
            "Java",
            "Python",
            "JavaScript",
            "NodeJs"
        ],
        "experience": 4,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Vienna, VA",
        "job_id": 3944463577,
        "company": "INSPYR Solutions",
        "title": "SDET",
        "created_on": 1720587192.2373314,
        "description": "Title: IT Engineer (SDET - Automation Testing Engineer) Location: Local candidate or candidates who are ready to relocate will be given priority, if not possible remote is fine. Will need to report to HQ in Vienna, VA Duration: Initial 6 months with extensions Work Requirements: US Citizen, GC Holders or or Authorized to work in US Job Description: The candidate should be well trained and hands on in the automation testing/script areas with focus on Selenium, Maven and Java based project and script models. Good communication skills and experienced with working with complex project will be a good fit 5 to 8 years of automation experience is required Web based application testing knowledge and experience supporting Enterprise level Website will be a required skill Familiarity with Front end technologies and framework are a plus Supporting ADA based application is a plus Experience working with Adobe Experience Manager based website development testing support is a plus. Our benefits package includes: (EXCLUDE on perm placements) Comprehensive medical benefits Competitive pay, 401(k) Retirement plan …and much more! About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com. INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.",
        "url": "https://www.linkedin.com/jobs/view/3944463577",
        "summary": "This is a 6-month contract position for an SDET (Automation Testing Engineer) with 5-8 years of experience in automation testing, focusing on Selenium, Maven, and Java. The ideal candidate will have experience with web-based application testing, enterprise-level websites, front-end technologies, ADA-compliant applications, and Adobe Experience Manager. Excellent communication skills and experience working on complex projects are essential. The position is based in Vienna, VA, with remote options available. ",
        "industries": [
            "Information Technology",
            "Software Development",
            "Testing and Quality Assurance"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Collaboration",
            "Adaptability",
            "Detail-Oriented",
            "Time Management"
        ],
        "hard_skills": [
            "Selenium",
            "Maven",
            "Java",
            "Automation Testing",
            "Web Application Testing",
            "Enterprise Website Testing",
            "Front-End Technologies",
            "ADA Compliance",
            "Adobe Experience Manager"
        ],
        "tech_stack": [
            "Selenium",
            "Maven",
            "Java",
            "Adobe Experience Manager"
        ],
        "programming_languages": [
            "Java"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive medical benefits",
            "Competitive pay",
            "401(k)",
            "Retirement plan"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Rockville, MD",
        "job_id": 3962837374,
        "company": "PharmiWeb.jobs: Global Life Science Jobs",
        "title": "Senior Scientist, Machine Learning & Protein Engineering",
        "created_on": 1720587194.025003,
        "description": "- Permanent - Rockville MD Proclinical is seeking a dedicated Scientist with a focus on machine learning and protein engineering for a senior position. Primary Responsibilities This role is an exciting opportunity to contribute to the development of new cell therapies at a clinical stage immunotherapy company. The ideal candidate will be a pivotal part of the cross-functional teams, leading machine learning-based protein design initiatives and contributing to the development of lead drug candidates. Skills & Requirements PhD in computational biology, biophysics, bioinformatics, computer science or another related field. Proven expertise in AI and deep learning algorithms, frameworks, associated programming languages and systems architecture. The ability to independently design, build and evaluate machine learning models. Expertise in state-of-the-art protein design applications such as Rosetta, AlphaFold2, RoseTTAFold, RFdiffusion, ProteinMPNN, etc. Strong working knowledge of protein developability considerations for therapeutic proteins. Ability to work collaboratively and communicate effectively in interdisciplinary teams. The Senior Scientist, Machine Learning & Protein Engineering' s responsibilities will be: Run and work together on machine learning-based protein design initiatives in the development of new cell therapies. Work as a key member of cross-functional teams to identify and develop lead drug candidates. Lead the design and evaluation of novel proteins and de novo biological systems in support of therapeutic programs. Implement and develop machine learning-based protein design solutions for structure prediction, paratope/epitope analysis, affinity maturation, developability assessment, scaffold optimization, library design, immunogenicity and other protein engineering challenges. If you are having difficulty in applying or if you have any questions, please contact Alex Bero at a.bero@proclinical.com. Proclinical is a specialist employment agency and recruitment business, providing job opportunities within major pharmaceutical, biopharmaceutical, biotechnology and medical device companies. Proclinical Staffing is an equal opportunity employer. INDSCIC",
        "url": "https://www.linkedin.com/jobs/view/3962837374",
        "summary": "Proclinical is looking for a Senior Scientist with expertise in machine learning and protein engineering to develop new cell therapies. The ideal candidate will lead machine learning-based protein design initiatives and contribute to the development of lead drug candidates. Responsibilities include running and collaborating on machine learning-based protein design initiatives, identifying and developing lead drug candidates, designing and evaluating novel proteins and biological systems, and implementing and developing machine learning-based protein design solutions for various protein engineering challenges.",
        "industries": [
            "Biotechnology",
            "Pharmaceutical",
            "Immunotherapy"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Leadership"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Protein Design",
            "Computational Biology",
            "Biophysics",
            "Bioinformatics",
            "Computer Science",
            "Systems Architecture",
            "Protein Developability",
            "Structure Prediction",
            "Paratope/Epitope Analysis",
            "Affinity Maturation",
            "Developability Assessment",
            "Scaffold Optimization",
            "Library Design",
            "Immunogenicity"
        ],
        "tech_stack": [
            "Rosetta",
            "AlphaFold2",
            "RoseTTAFold",
            "RFdiffusion",
            "ProteinMPNN"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Computational Biology",
                "Biophysics",
                "Bioinformatics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Columbia, MD",
        "job_id": 3923411693,
        "company": "Hobbs & Associates, Inc.",
        "title": "Applications Engineer",
        "created_on": 1720587195.5514421,
        "description": "Job Description Applications Engineer Hobbs & Associates is the fastest growing HVAC product and systems provider in the Maryland, Washington, DC and Northern Virginia market. We represent a variety of innovative HVAC equipment and automation systems within the residential, commercial, and industrial markets. Our mission is to provide a strategic group of clients with measurable and valued results that reduce the complexity of construction, improve operating costs and minimize the impact of building systems on the environment. Hobbs & Associates provides a great development path and career opportunity for a creative and driven individual. Summary A successful Applications Engineer is responsible for coordinating and leveraging The Hobbs brand, support groups and product partners to accurately communicate pricing and functional deliverables of all represented products to customers. ESSENTIAL FUNCTIONS AND RESPONSIBILITIES include the following. Other functions may be assigned. Develops general working knowledge of Hobbs & Associates products and solutions. Develops positive relationships with product representatives, Hobbs & Associates leadership and employee teams. Creates partnerships with salespeople and customers to identify and create high-value deliverables. Manages technical questions and communicates accurate and timely client responses. Periodically performs facility walkthroughs Interprets construction plans and design specifications to understand project constraints to product applications Prepares system layout as required Generates timely and accurate product estimates and client proposals Reviews proposals with salespeople and customers Provides best-in-class and on-time project fulfilment support for all products sold. Coordination and delivery of product submittals Communicates responses to questions associated with development of an approved submittal Champion equipment orders and schedule coordination Follow through of product change requirements throughout the fulfilment process Supervisory Responsibilities This position has no supervisory responsibilities. QUALIFICATIONS & MINIMUM REQUIREMENT INCLUDES THE FOLLOWING : Bachelors of Science or Bachelor of Arts Degree in a technical or business related field is preferred Excellent oral/written communication skills Excellent customer relations skills Ability to travel within a locally defined region at least 10% of the time Ability to function independently and has excellent time management skills to meet project deadlines including project bid and submittal schedules. PHYSICAL DEMANDS The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to stand, use hands to finger, handle or feel, and talk or hear. The employee frequently is required to walk; reach with hands and arms; and stoop, kneel, crouch or craw. The employee is occasionally required to sit. The employee must regularly lift and/or move up to 10 pounds, frequently lift and/or move up to 50 pounds. On occasion lift and/or move more than 50 pounds with assistance. Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus. DECLARATION Human resources has sole right and discretion to make changes to this job description. Any employee making changes unauthorized by the president or human resources will be subject to disciplinary action up to and including termination. Benefits: 401(k) Dental insurance Flexible spending account Health insurance Health savings account Life insurance Paid time off Parental leave Vision insurance Schedule: 8 hour shift Ability to commute/relocate: Columbia, MD 21046: Reliably commute or planning to relocate before starting work (Preferred) Experience: HVAC Equipment: 1 year (Required) HVAC Estimating: 1 year (Required) Work Location: In person Company Description Hobbs & Associates provides heating ventilation and air conditioning (HVAC) products and engineering services to commercial and industrial building contractors, architect-design firms, and business owners. We work with our business partners to create enduring community infrastructure such as schools and colleges, hospitals, military and municipal structures, entertainment venues, hotels, and multi-family housing. Hobbs & Associates provides heating ventilation and air conditioning (HVAC) products and engineering services to commercial and industrial building contractors, architect-design firms, and business owners. We work with our business partners to create enduring community infrastructure such as schools and colleges, hospitals, military and municipal structures, entertainment venues, hotels, and multi-family housing.",
        "url": "https://www.linkedin.com/jobs/view/3923411693",
        "summary": "An Applications Engineer at Hobbs & Associates is responsible for coordinating and communicating pricing and functional deliverables of HVAC products to clients. They work with sales teams and customers to identify high-value deliverables, manage technical inquiries, and provide project fulfilment support. They also interpret construction plans, prepare estimates, and review proposals.",
        "industries": [
            "HVAC",
            "Construction",
            "Engineering",
            "Architecture",
            "Commercial Real Estate",
            "Industrial"
        ],
        "soft_skills": [
            "Communication",
            "Customer Relations",
            "Time Management",
            "Relationship Building",
            "Problem Solving",
            "Project Management",
            "Teamwork"
        ],
        "hard_skills": [
            "HVAC Equipment",
            "HVAC Estimating",
            "Construction Plans",
            "Design Specifications",
            "Project Constraints",
            "Product Applications",
            "System Layout",
            "Proposal Writing",
            "Project Fulfilment",
            "Submittal Coordination",
            "Change Management"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Technical",
                "Business"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "401(k)",
            "Dental Insurance",
            "Flexible Spending Account",
            "Health Insurance",
            "Health Savings Account",
            "Life Insurance",
            "Paid Time Off",
            "Parental Leave",
            "Vision Insurance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3910710890,
        "company": "ClearanceJobs",
        "title": "Junior Data Scientist with Security Clearance",
        "created_on": 1720587197.3036973,
        "description": "Overview LMI is seeking a skilled Data Analyst at our headquarters office in Tysons, VA. Successful Data Analysts demonstrate competency in data analysis, data visualization, statistics, programming, project execution, and critical thinking. LMI is a consultancy dedicated to improving the business of government, drawing from deep expertise in advanced analytics, digital services, logistics, and management advisory services. Established as a private, not-for-profit organization in 1961, LMI is a trusted third party to federal civilian and defense agencies, free of commercial and political bias. We operate completely free of political and commercial bias, and we are entirely aligned with the goals of our clients. Our clients value our specialized services in logistics, intelligence, homeland security, health care, and energy and environment markets. We believe government can make a difference, and we seek talented, hardworking people who share that conviction. We offer a generous compensation package with excellent benefits that start the first day of employment. Business casual dress, flex time, and tuition reimbursement are a few of our many work-life benefits available to our employees. Responsibilities This data analyst will work as part of a team of experienced data scientists, data engineers, and data analysts to support advanced analytics projects for the Chief Digital and Artificial Intelligence Office (CDAO) of the Department of Defense. Responsibilities include: Demonstrate the ability to frame and scale data problems to effectively analyze, visualize and find data solutions. Will, with the guidance and support of experienced team members, build robust, scalable data pipelines using big data technologies such as Spark. Transform data and analysis into informative data visualizations and/or interactive dashboards. The analyst will need the ability to work in teams and independently. Qualifications Required: Bachelor's degree in data science, mathematics, statistics, economics, computer science, engineering, or other related business or quantitative discipline is required. Experience working with Python. Experience creating meaningful data visualizations and/or interactive dashboards that communicate your findings and relate them back to how your insights create business impact using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js. Experience with data science methods related to data architecture, data munging, data and feature engineering, and predictive analytics. Superior communication skills, both oral and written This position requires the ability to receive a security clearance at the Secret level. You must be a US citizen. Desired Skills: Master's degree or higher. Working knowledge of Spark or PySpark Experience with Databricks, Qlik, or the Advana analytics platform Previous DOD experience. Previous experience working with supply chain or maintenance data or processes. Active DoD security clearance at the Secret or Top Secret level.",
        "url": "https://www.linkedin.com/jobs/view/3910710890",
        "summary": "LMI is seeking a Data Analyst to work on advanced analytics projects for the Chief Digital and Artificial Intelligence Office (CDAO) of the Department of Defense. Responsibilities include data analysis, visualization, building data pipelines using big data technologies like Spark, and creating interactive dashboards. The ideal candidate will have experience with Python, data science methods, and data visualization tools like Tableau, Qlik, Power BI, RShiny, plotly, and d3.js.  They must be able to communicate their findings effectively and have a background in data architecture, data munging, data and feature engineering, and predictive analytics.",
        "industries": [
            "Government",
            "Defense",
            "Analytics",
            "Consultancy"
        ],
        "soft_skills": [
            "Critical thinking",
            "Communication",
            "Teamwork",
            "Independence"
        ],
        "hard_skills": [
            "Data analysis",
            "Data visualization",
            "Statistics",
            "Programming",
            "Project execution",
            "Data architecture",
            "Data munging",
            "Data and feature engineering",
            "Predictive analytics"
        ],
        "tech_stack": [
            "Spark",
            "PySpark",
            "Tableau",
            "Qlik",
            "Power BI",
            "RShiny",
            "plotly",
            "d3.js",
            "Databricks",
            "Advana",
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data science",
                "Mathematics",
                "Statistics",
                "Economics",
                "Computer science",
                "Engineering",
                "Business",
                "Quantitative discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Compensation package",
            "Excellent benefits",
            "Business casual dress",
            "Flex time",
            "Tuition reimbursement"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3732568036,
        "company": "MITRE",
        "title": "AI Researcher - Autonomous Vehicles",
        "created_on": 1720587198.646994,
        "description": "Why choose between doing meaningful work and having a fulfilling life? At MITRE, you can have both. That's because MITRE people are committed to tackling our nation's toughest challenges—and we're committed to the long-term well-being of our employees. MITRE is different from most technology companies. We are a not-for-profit corporation chartered to work for the public interest, with no commercial conflicts to influence what we do. The R&D centers we operate for the government create lasting impact in fields as diverse as cybersecurity, healthcare, aviation, defense, and enterprise transformation. We're making a difference every day—working for a safer, healthier, and more secure nation and world. Our workplace reflects our values. We offer competitive benefits, exceptional professional development opportunities, and a culture of innovation that embraces diversity, inclusion, flexibility, collaboration, and career growth. If this sounds like the choice you want to make, then choose MITRE—and make a difference with us. MITRE’s Artificial Intelligence and Autonomy Innovation Center is home to an interdisciplinary, diverse, and dynamic team united by a passion to catalyze consequential use of Artificial Intelligence (AI). We are 200 strong and growing! We collaboratively work across government, industry, and academia to address complex AI and Autonomy challenges for the benefit of our nation. We apply our trusted technical expertise to enable the effective, assured, and responsible application of Artificial Intelligence (AI) to critical government missions. MITRE aims to realize the transformative potential of Artificial Intelligence (AI) for public good. Department Summary: MITRE’s Artificial Intelligence Innovation Center's Robotics and Autonomous Systems Department is an innovative team of engineers focused on the development of cutting-edge autonomous systems, robotics capabilities, and AI solutions for a safer world. The Robotics and Autonomous Systems Department has a new opportunity for a strong technical candidate with a STEM degree to join an innovative team of engineers focused on developing Artificial Intelligence and/or Autonomous System solutions for sponsor needs. The right candidate will enjoy a fast-paced team environment and working with groundbreaking technology. We are seeking a self-starter that assists in building robotics and artificial intelligence projects. The candidate for this position will work a wide variety of challenging activities in direct support of sponsor programs and will support MITRE’s AI and autonomy efforts. Roles and Responsibilities: Conducting cutting-edge research in the fields of artificial intelligence, machine learning, and robotics, specifically as they relate to autonomous vehicle technology. Developing and implementing advanced algorithms and models for perception, localization, mapping, planning, control, and decision-making for autonomous vehicles. Collaborating with cross-functional teams to integrate your research into our autonomous vehicle platform and ensure its practical applicability. Staying up-to-date with the latest advancements in AI, machine learning, and autonomous vehicle research, and identifying potential areas of improvement for our existing systems. Publishing research findings in top-tier conferences and journals, and representing the company at industry events and conferences. Minimum Qualifications: Requires a minimum of 5 years of related experience with a Bachelor’s degree; or 3 years and a Master’s degree; or a PhD with relevant experience who can immediately contribute at this job step; or equivalent combination of related education and work experience. Degree in Computer Science, Robotics, Electrical Engineering, or a related field, with a focus on artificial intelligence, machine learning, or robotics. Experience working on real-world applications of autonomous vehicle technology or robotics systems. Familiarity with sensor fusion techniques and the integration of data from various sensors such as LiDAR, cameras, radar, and GPS. Expertise in computer vision, natural language processing, or reinforcement learning as applied to autonomous vehicles. Proven ability to mentor and guide junior researchers, fostering a collaborative and inclusive research environment. Strong problem-solving and analytical skills, with a demonstrated ability to tackle complex technical challenges. Knowledge of robotics software and frameworks, e.g. ROS Knowledge of programming languages such as C++ and python. Knowledge of AI development tools such as Tensor Flow. Preferred Qualifications: Preference given to qualified candidates with active/current DoD Secret Clearance. Advanced degree in technical field of study, preferred. Knowledge of robotics and autonomous systems technologies, techniques, architectures, and algorithms. Experience in artificial intelligence fields, such as computer vision, deep learning, machine learning, planning, human machine teaming, and multi-robot systems. Experience with robotics software and frameworks, e.g. ROS. Experience with programming languages such as C++ and python. Experience with AI development tools such as Tensor Flow, etc. Knowledge of the challenges of developing autonomous and/or AI systems that are robust in real world scenarios. Knowledge of software engineering practices such as continuous integration, source control, software testing. This requisition requires the candidate to have a minimum of the following clearance(s): None This requisition requires the hired candidate to have or obtain, within one year from the date of hire, the following clearance(s): Secret Work Location Type: Hybrid MITRE is proud to be an equal opportunity employer. MITRE recruits, employs, trains, compensates, and promotes regardless of age; ancestry; color; family medical or genetic information; gender identity and expression; marital, military, or veteran status; national and ethnic origin; physical or mental disability; political affiliation; pregnancy; race; religion; sex; sexual orientation; and any other protected characteristics. For further information please visit the Equal Employment Opportunity Commission website EEO is the Law Poster and Pay Transparency. MITRE intends to maintain a website that is fully accessible to all individuals. If you are unable to search or apply for jobs and would like to request a reasonable accommodation for any part of MITRE’s employment process, please email recruitinghelp@mitre.org. Copyright © 2024, The MITRE Corporation. All rights reserved. MITRE is a registered trademark of The MITRE Corporation. Material on this site may be copied and distributed with permission only. Benefits information may be found here",
        "url": "https://www.linkedin.com/jobs/view/3732568036",
        "summary": "MITRE's Artificial Intelligence Innovation Center's Robotics and Autonomous Systems Department is seeking a strong technical candidate with a STEM degree to join a team developing Artificial Intelligence and/or Autonomous System solutions for sponsor needs. The candidate will assist in building robotics and artificial intelligence projects, work on challenging activities in direct support of sponsor programs, and support MITRE’s AI and autonomy efforts.",
        "industries": [
            "Artificial Intelligence",
            "Robotics",
            "Autonomous Systems",
            "Defense",
            "Government",
            "Healthcare",
            "Cybersecurity",
            "Aviation",
            "Enterprise Transformation"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Collaboration",
            "Communication",
            "Teamwork",
            "Mentorship",
            "Leadership"
        ],
        "hard_skills": [
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics",
            "Autonomous Vehicle Technology",
            "Perception",
            "Localization",
            "Mapping",
            "Planning",
            "Control",
            "Decision-Making",
            "Sensor Fusion",
            "LiDAR",
            "Cameras",
            "Radar",
            "GPS",
            "Computer Vision",
            "Natural Language Processing",
            "Reinforcement Learning",
            "C++",
            "Python",
            "Tensor Flow",
            "ROS"
        ],
        "tech_stack": [
            "ROS",
            "Tensor Flow",
            "C++",
            "Python",
            "LiDAR",
            "Cameras",
            "Radar",
            "GPS"
        ],
        "programming_languages": [
            "C++",
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Computer Science",
                "Robotics",
                "Electrical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive benefits",
            "Exceptional professional development opportunities",
            "Culture of innovation",
            "Diversity",
            "Inclusion",
            "Flexibility",
            "Collaboration",
            "Career growth"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3935052254,
        "company": "Amazon Web Services (AWS)",
        "title": "Machine Learning Engineer, Generative AI Innovation Center, AWS",
        "created_on": 1720587201.8421206,
        "description": "Description Amazon launched the Generative AI (GenAI) Innovation Center (GAIIC) in Jun 2023 to help AWS customers accelerate enterprise innovation and success with Generative AI (https://press.aboutamazon.com/2023/6/aws-announces-generative-ai-innovation-center). Customers such as Highspot, Lonely Planet, Ryanair, and Twilio are engaging with the GAI Innovation Center to explore developing generative solutions. GAIIC provides opportunities to innovate in a fast-paced organization that contributes to game-changing projects and technologies that get deployed on devices and in the cloud. As a Machine Learning Engineer in GAIIC, you are proficient in developing and deploying advanced ML models and pipelines to solve diverse customer problems using Gen AI. You will be working alongside scientists with terabytes of text, images, and other types of data and develop Gen AI based solutions to solve real-world problems. You'll design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience. Key job responsibilities Our ML Engineers Collaborate Across Diverse Teams, Projects, And Environments To Have a Firsthand Impact On Our Global Customer Base. You’ll Bring a Passion For The Intersection Of Software Development With Generative AI And Machine Learning. You’ll Also Solve complex technical problems, often ones not solved before, at every layer of the stack. Design, implement, test, deploy and maintain innovative ML solutions to transform service performance, durability, cost, and security. Build high-quality, highly available, always-on products. Research implementations that deliver the best possible experiences for customers. A day in the life As You Design And Code Solutions To Help Our Team Drive Efficiencies In ML Architecture, You’ll Create Metrics, Implement Automation And Other Improvements, And Resolve The Root Cause Of Software Defects. You’ll Also Build high-impact ML solutions to deliver to our large customer base. Participate in design discussions, code review, and communicate with internal and external stakeholders. Work cross-functionally to help drive business solutions with your technical input. Work in a startup-like development environment, where you’re always working on the most important stuff. About The Team Diverse Experiences AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship & Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why flexible work hours and arrangements are part of our culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.\" Sales, Marketing and Global Services (SMGS) AWS Sales, Marketing, and Global Services (SMGS) is responsible for driving revenue, adoption, and growth from the largest and fastest growing small- and mid-market accounts to enterprise-level customers including public sector. The AWS Global Support team interacts with leading companies and believes that world-class support is critical to customer success. AWS Support also partners with a global list of customers that are building mission-critical applications on top of AWS services. We are open to hiring candidates to work out of one of the following locations: Atlanta, GA, USA | Austin, TX, USA | Boston, MA, USA | Chicago, IL, USA | Herndon, VA, USA | Houston, TX, USA | Jersey City, NJ, USA | New York, NY, USA | Santa Clara, CA, USA | Seattle, WA, USA Basic Qualifications 3+ years of non-internship professional software development experience 3+ years of programming with at least one software programming language experience 3+ years of design or architecture (design patterns, reliability and scaling) of new and existing machine learning systems experience 2+ years of relevant experience in developing and deploying large scale machine learning or deep learning models and/ or systems into production, including batch and real time data processing, model containerization, CI/ CD pipelines, API development, model training and productionizing ML models Experience using Python and frameworks such as Pytorch, Tensorflow Preferred Qualifications Experience with large scale machine learning systems such as profiling and debugging and understanding of system performance and scalability Experience in training and fine-tuning of Large Language Models (LLMs), or experience with inference optimization Master’s degree in computer science or equivalent Experiences related to AWS services such as Sagemaker, EMR, S3, DynamoDB and EC2 Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $129,300/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon Web Services, Inc. Job ID: A2658179",
        "url": "https://www.linkedin.com/jobs/view/3935052254",
        "summary": "Amazon's Generative AI Innovation Center (GAIIC) seeks a Machine Learning Engineer to develop and deploy advanced ML models and pipelines for diverse customer problems using Generative AI. You'll collaborate with scientists, design experiments, research algorithms, and optimize risk, profitability, and customer experience. You'll build high-impact ML solutions, participate in design discussions and code reviews, and work cross-functionally to drive business solutions.  The role requires strong experience with machine learning systems, Python, PyTorch, TensorFlow, and AWS services.",
        "industries": [
            "Technology",
            "Cloud Computing",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Collaboration",
            "Problem Solving",
            "Communication",
            "Design",
            "Research",
            "Optimization",
            "Innovation"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Python",
            "PyTorch",
            "TensorFlow",
            "Data Processing",
            "Model Containerization",
            "CI/CD Pipelines",
            "API Development",
            "Model Training",
            "Profiling",
            "Debugging",
            "Large Language Models (LLMs)",
            "Inference Optimization",
            "AWS Sagemaker",
            "EMR",
            "S3",
            "DynamoDB",
            "EC2"
        ],
        "tech_stack": [
            "PyTorch",
            "TensorFlow",
            "AWS Sagemaker",
            "EMR",
            "S3",
            "DynamoDB",
            "EC2"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master’s",
            "fields": [
                "Computer Science"
            ]
        },
        "salary": {
            "max": 223600,
            "min": 129300
        },
        "benefits": [
            "Medical",
            "Financial",
            "Equity",
            "Sign-on Payments"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3945737210,
        "company": "Chelsoft Solutions Co.",
        "title": "Python/Java Data Engineer_W2_local to Virginia",
        "created_on": 1720587205.653579,
        "description": "Position: Data Engineer Location: McLean, VA Python, will accept Java but Python is preferred. Spark, PySpark AWS ,lambda, S3 SQL ETL",
        "url": "https://www.linkedin.com/jobs/view/3945737210",
        "summary": "Data Engineer position in McLean, VA requiring experience with Python, Spark, PySpark, AWS, Lambda, S3, SQL, and ETL.",
        "industries": [
            "Data Engineering",
            "Software Development",
            "Analytics"
        ],
        "soft_skills": [],
        "hard_skills": [
            "Python",
            "Java",
            "Spark",
            "PySpark",
            "AWS",
            "Lambda",
            "S3",
            "SQL",
            "ETL"
        ],
        "tech_stack": [
            "Spark",
            "PySpark",
            "AWS",
            "Lambda",
            "S3",
            "SQL",
            "ETL"
        ],
        "programming_languages": [
            "Python",
            "Java"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3959554393,
        "company": "Noblis",
        "title": "Software Engineer (All Levels)",
        "created_on": 1720587207.1461027,
        "description": "Responsibilities Noblis is seeking a technical thinker and doer to work as a Software Engineer within a highly dynamic and impactful operating environment located in McLean, VA. The Software Engineer Will Analyze user needs and software requirements to determine feasibility of design; Analyze information to determine, recommend, and plan specifications and layouts. Confer with system users, project managers, systems analysts, engineers, and programmers to obtain performance requirements and interfaces and design the system to meet operational needs. Consult with engineering staff to evaluate interfaces between hardware and software, develop specifications and performance requirements and resolve customer problems. Coordinate installation of software and hardware system installation and monitor equipment functionality to ensure specifications are met. Estimate software development costs and schedule and total cost of operations/maintenance. Design, develop and modify software systems, using various methodologies to predict and measure outcome and consequences of design. Design, develop, and maintain software/applications within various network environments, including the cloud environment. Transition legacy applications if requirements dictate. Develop and direct software system testing and validation procedures, programming, and documentation. Obtain and evaluate factors such as reporting formats required, cost constraints, and need for security restrictions to determine hardware configuration. Modify existing software to correct errors, adapt to new hardware, or to improve performance. Prepare reports/metrics/correspondence concerning project specifications, activities and status. Review existing programs and assist in making refinements, reducing operating time, and improve current techniques. Perform maintenance of system software. Required Qualifications Active TS/SCI with Polygraph. Understanding of software testing and quality assurance best practices. Experience with the Software Development Lifecycle (SDLC). Experience designing, developing, testing, and installing software and supporting software products. Experience writing, reviewing, and maintaining technical documentation such as, but not limited to, new or existing software requirements, user manuals, product specifications, and training materials. Experience with git, and pull request workflows. Experience with most or all parts of a software stack. Familiar with Agile development methodologies and working in an agile setting. Experience with scripting, including PowerShell, Bash, or Python Experience with relational databases and administration, including SQL Server or PostgreSQL Experience working in cloud environments and leveraging various computing resources such as GPU clusters and cloud-based compute servers. Experience with database schema design, query optimization, scaling, and backups. Knowledge in languages such as Python, SQL, Java. Experience working with Docker, Kubernetes Experience performing extract, transform, load (ETL) development for data pipelines. Ability to perform API service development. Demonstrated experience working with IC Agencies. Knowledge of IC systems, processes, data, and policies. Knowledge and application of agile techniques and methodologies. Experience mentoring or training (through formal or informal means) members of the team. Skill Levels Senior Expert (SME): Bachelor’s Degree in associated field and 14+ years of relevant experience; Master’s Degree in associated field and 11+ years of relevant experience; PhD and 10+years of relevant experience. Compensatoin $151,700 - $237,050 Expert: Bachelor’s Degree in associated field and has 10+ years of relevant experience; Master’s Degree and 9+ years of relevant experience; PhD and 8+ years of relevant experience. Compensation $125,500 - $196,075 Senior: Bachelor’s Degree in associated field and has 6+ years of relevant experience; Master’s Degree and 5+ years of relevant experience; PhD and 4+ years of relevant experience. Compensation $114,100 - $178,300 Junior: Bachelor’s Degree in associated field and 1+ years of relevant experience. Compensation $70,800 - $133,750 Desired Qualifications Strong communication skills, written and verbal. Overview Noblis and our wholly owned subsidiaries, Noblis ESI , and Noblis MSD tackle the nation's toughest problems and apply advanced solutions to our clients' most critical missions. We bring the best of scientific thought, management, and engineering expertise together in an environment of independence and objectivity to deliver enduring impact on federal missions. Noblis works with a wide range of government clients in the defense, intelligence and federal civil sectors. Learn more at Noblis -About Us Why work at a Noblis company? Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public. Noblis has won numerous workplace awards . Noblis maintains a drug-free workplace. Salary Range Explanation At Noblis we recognize and reward your contributions, provide you with growth opportunities, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, and work-life programs. Our award programs acknowledge employees for exceptional performance and superior demonstration of our service standards. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in our benefit programs. Other offerings may be provided for employees not within this category. We encourage you to learn more about our total benefits by visiting the Benefits page on our Careers site. Salary at Noblis is determined by various factors, including but not limited to, the combination of education, certifications, knowledge, skills, competencies, and experience, internal and external equity, location, and clearance level, as well as contract-specific affordability and organizational requirements and applicable employment laws. The projected compensation range for this position is provided within the posting and are based on full time status. Part time staff receive a prorated salary based on regularly scheduled hours. The estimated minimum and maximum displayed represents the broadest range for this position (inclusive of high geographic and high clearance requirements), and is just one component of Noblis’ total compensation package for employees. Posted Salary Range USD $70,800.00 - USD $237,050.00 /Yr. Equal Employment Opportunity Noblis is an Equal Opportunity Employer. Employment decisions are made without regard to race (as well as because of or on the basis of traits historically associated with race, including hair texture, hair type, and protective hairstyles such as braids, locks, and twists), color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, pregnancy, childbirth, lactation and related medical conditions, genetic factors, military/veteran status, or other characteristics protected by law. Noblis is committed to the full inclusion of all qualified individuals. As part of this commitment, Noblis will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact employee-relations@noblis.org .",
        "url": "https://www.linkedin.com/jobs/view/3959554393",
        "summary": "Noblis is seeking a Software Engineer with expertise in software development, testing, and deployment. The ideal candidate will have experience with a variety of technologies, including cloud environments, agile methodologies, and data pipelines. The role involves analyzing user needs, designing and developing software systems, conducting testing and validation, and maintaining software products. The position offers a competitive salary and benefits package, including health, life, disability, financial, and retirement benefits.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Engineering",
            "Defense",
            "Intelligence",
            "Federal Government"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem-Solving",
            "Analytical",
            "Critical Thinking",
            "Technical",
            "Interpersonal",
            "Mentoring",
            "Training"
        ],
        "hard_skills": [
            "Software Development",
            "Software Testing",
            "Quality Assurance",
            "Software Development Lifecycle (SDLC)",
            "Software Design",
            "Software Installation",
            "Technical Documentation",
            "Git",
            "Agile Development",
            "PowerShell",
            "Bash",
            "Python",
            "Relational Databases",
            "SQL Server",
            "PostgreSQL",
            "Cloud Environments",
            "GPU Clusters",
            "Cloud-Based Compute Servers",
            "Database Schema Design",
            "Query Optimization",
            "Scaling",
            "Backups",
            "SQL",
            "Java",
            "Docker",
            "Kubernetes",
            "ETL Development",
            "API Service Development",
            "IC Systems",
            "IC Processes",
            "IC Data",
            "IC Policies"
        ],
        "tech_stack": [
            "Git",
            "PowerShell",
            "Bash",
            "Python",
            "SQL Server",
            "PostgreSQL",
            "Docker",
            "Kubernetes",
            "ETL"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "Java"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Computer Science",
                "Software Engineering",
                "Information Technology",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 237050,
            "min": 70800
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Award Programs"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3968272308,
        "company": "Stealth",
        "title": "Software Engineer [28190]",
        "created_on": 1720587208.783765,
        "description": "Description: This position is located on-site in Chantilly, VA. This is not a remote position. Required Qualifications: Active TS/SCI Current/Former TS/SCI with FS Poly Previous experience in software development, computer engineering, or other related fields. Willingness to develop in and use C#, javascript, html, AngularJS Desired Qualifications: Knowledge of C#, Java, C++ or other programming languages Knowledge of javascript, html, css, AngularJS and/or related scripting frameworks Familiarity with relational databases such as MySQL, Oracle, and SQL Server Familiarity with Microsoft Visual Studio Deadline and detail-oriented Responsibilities: Analyze user needs and develop software solutions Work with project manager or product owner to meet specification needs Recommend software upgrades to optimize operational efficiency Collaborate with other developers to design and optimize code Document programming tasks and procedures Troubleshoot and fix software bugs and perform routine software maintenance Note: Only candidates currently holding an active Secret level security clearance or greater, will be considered.",
        "url": "https://www.linkedin.com/jobs/view/3968272308",
        "summary": "Software Engineer needed to develop and maintain software solutions in a team environment.  This role requires strong experience in software development and familiarity with C#, JavaScript, HTML, AngularJS, and relational databases like MySQL, Oracle, and SQL Server.  The position is located on-site in Chantilly, VA and requires an active TS/SCI security clearance.",
        "industries": [
            "Software Development",
            "Information Technology",
            "Engineering"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Detail-Oriented",
            "Time Management"
        ],
        "hard_skills": [
            "C#",
            "JavaScript",
            "HTML",
            "AngularJS",
            "MySQL",
            "Oracle",
            "SQL Server",
            "Microsoft Visual Studio",
            "Software Development",
            "Computer Engineering"
        ],
        "tech_stack": [
            "C#",
            "JavaScript",
            "HTML",
            "AngularJS",
            "MySQL",
            "Oracle",
            "SQL Server",
            "Microsoft Visual Studio"
        ],
        "programming_languages": [
            "C#",
            "Java",
            "C++",
            "JavaScript"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3948071314,
        "company": "MicroStrategy",
        "title": "Data Analytics Engineer",
        "created_on": 1720587210.270223,
        "description": "Company Description MicroStrategy transforms organizations into intelligent enterprises through data-driven innovation. We match smart people to dynamic projects and technologies that truly challenge their talents. Curious and creative in outlook, our success is built on the talent and energy of smart and driven people. MicroStrategy (Nasdaq: MSTR) is a worldwide leader in enterprise analytics and mobility software. A pioneer in the BI and analytics space, MicroStrategy delivers innovative software that empowers people to make better decisions and transform the way they do business. We provide our enterprise customers with world-class software and expert services so they can deploy unique intelligence applications. Job Description Job Summary: We are seeking a highly motivated Data Analytics Engineer to join our team. As a Data Analytics Engineer, you will be responsible for designing, developing, and implementing natural language processing (NLP) and AI-based solutions to enhance our products and services. You will work collaboratively with cross-functional teams to identify and solve complex problems using NLP and AI techniques. Responsibilities Design, develop, and implement NLP and AI-based solutions to enhance our products and services. Collaborate with cross-functional teams, including data scientists, software engineers, customer support specialists and product managers, to define and deliver NLP and AI solutions. Conduct data analysis and exploratory research to identify potential areas for improvement. Build and maintain large-scale data pipelines and ETL processes to support NLP and AI workflows. Utilize programming languages such as Python, R, and SQL to develop and deploy NLP and AI models. Leverage and integrate with GPT models. Implement best practices for NLP and AI model training, validation, and deployment to ensure accuracy, scalability, and maintainability. Monitor and evaluate the performance of NLP and AI models, and refine them to improve accuracy and efficiency. Keep up-to-date with the latest NLP and AI research and techniques, and share your knowledge with the team. Qualifications Qualifications: Bachelor's or Master's degree in Computer Science or a related field. Proven experience in developing and deploying NLP and AI-based solutions. Strong programming skills in Python, R, SQL, and React. Experience with NLP and AI frameworks such as NLTK, Spacy, TensorFlow, or PyTorch. Familiarity with data visualization tools such as MicroStrategy preferred. Strong analytical and problem-solving skills. If you are a passionate and driven Data Analytics Engineer who wants to make an impact with cutting-edge technologies, we would love to hear from you! Additional Information MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, national origin, sexual orientation, gender identity, disability, veteran status, sex age, genetic information, or any other legally-protected basis. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at 703-848-8600. MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at application_accommodations@microstrategy.com.",
        "url": "https://www.linkedin.com/jobs/view/3948071314",
        "summary": "MicroStrategy seeks a Data Analytics Engineer to design, develop, and implement NLP and AI solutions using Python, R, SQL, React, NLTK, Spacy, TensorFlow, or PyTorch.  Experience with GPT models and data visualization tools, specifically MicroStrategy, are preferred. The role involves collaborating with data scientists, software engineers, customer support specialists, and product managers to enhance MicroStrategy products and services.",
        "industries": [
            "Software",
            "Technology",
            "Analytics",
            "Artificial Intelligence",
            "Big Data",
            "Business Intelligence",
            "Data Science"
        ],
        "soft_skills": [
            "Highly Motivated",
            "Problem Solving",
            "Analytical Skills",
            "Collaboration",
            "Communication",
            "Passionate",
            "Driven"
        ],
        "hard_skills": [
            "NLP",
            "AI",
            "Python",
            "R",
            "SQL",
            "React",
            "NLTK",
            "Spacy",
            "TensorFlow",
            "PyTorch",
            "GPT Models",
            "MicroStrategy",
            "Data Visualization"
        ],
        "tech_stack": [
            "NLP",
            "AI",
            "Python",
            "R",
            "SQL",
            "React",
            "NLTK",
            "Spacy",
            "TensorFlow",
            "PyTorch",
            "GPT Models",
            "MicroStrategy",
            "Data Visualization"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL",
            "React"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Maryland, United States",
        "job_id": 3938220978,
        "company": "HexaQuEST Global",
        "title": "Python Developer (**with C# experience**)",
        "created_on": 1720587218.879502,
        "description": "100% remote (will be working EST hours) This is a long term contract Pay is 70ish per hour Please let me know if you have any senior level Python Developers with some C# experience …. NEED to have some experience with C# in an enterprise environment… not a lot but at least some.",
        "url": "https://www.linkedin.com/jobs/view/3938220978",
        "summary": "Seeking a senior Python developer with some C# experience for a long-term contract. The ideal candidate will have experience with C# in an enterprise environment. The role is 100% remote and will be working EST hours.",
        "industries": [
            "Software Development",
            "Information Technology"
        ],
        "soft_skills": [],
        "hard_skills": [
            "Python",
            "C#"
        ],
        "tech_stack": [
            "Python",
            "C#"
        ],
        "programming_languages": [
            "Python",
            "C#"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 70,
            "min": 70
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3962404941,
        "company": "Leidos",
        "title": "Artificial Intelligence /Cybersecurity Researcher",
        "created_on": 1720587221.0237656,
        "description": "Description Leidos is seeking an Artificial Intelligence (AI) Cybersecurity Researcher / Engineer to support the Department of Homeland Security (DHS) Office of the Chief Information Security Officer. The AI Cybersecurity Researcher / Engineer will be expected to work with a small team to develop procedures in support of DHS’ Vulnerability Management Branch. This role will have the opportunity to help define, scope, and implement impactful AI and cybersecurity policy at the federal agency level. Primary Responsibilities BS degree and 12 – 15 years of prior relevant experience or Masters with 10 – 13 years of prior relevant experience. STEM related Bachelor of Science, preferably in math and / or cybersecurity. Identify on-going risks / threats to federal and non-federal information systems from AI-driven attacks Assist DHS in development of AI and cybersecurity-related policy Propose strategies and procedures to senior DHS leaders both verbally and in writing Research and develop holistic understanding of AI policy and enforcement across the federal government Build presentations to present complex policy/regulation topics in simplified manner to senior leaders Identify trends and improvement opportunities based on AI and cybersecurity assessment results Required Qualifications 12-15 years of prior relevant AI and Cybersecurity experience Sustained (e.g., at least 10 years), hands-on experience with: data modeling and data engineering, feature engineering, model lifecycle management, and cloud infrastructure; supervised and unsupervised deep learning algorithms Experience working in data analysis, modeling, and visualization packages in TensorFlow, Keras, PyTorch, Caffe, and Theano; and developing or integrating analytics in programming languages such as Python. At a minimum, STEM related Bachelor of Science, preferably in math and / or cybersecurity. Working knowledge of NIST SP 800-171 and NIST SP 800-172, to include one of the following: Federal agency implementation of policy Contractor adherence to policy Assessment of adherence to policy (eg. DoD Cybersecurity Maturity Model Certification, etc.) Experience with modern development software, tools, and methodologies inclusive of: GitLab, Jira Experience with containerization using: AWS ECS, Docker Professional level writer with experience writing public or company-facing documents, or published academic work Ability to establish effective working relationships with senior-level customers, technical staff, managers, and peers Outstanding verbal and written communications skills Strong critical thinking and problem-solving skills Strong analytic and reasoning skills Ability to attain TS/SCI clearance Preferred Qualifications Demonstrated experience with server virtualization technologies such as VMware, VirtualBox, or Hyper-V Hands-on experience with AWS Sagemaker. Any experience with penetration testing, malware analysis, network traffic analysis. Knowledge of basic concepts in statistics Original Posting Date 2024-04-03 While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above. Pay Range Pay Range $122,200.00 - $220,900.00 The Leidos pay range for this job level is a general guideline onlyand not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. #Remote",
        "url": "https://www.linkedin.com/jobs/view/3962404941",
        "summary": "Leidos is seeking an AI Cybersecurity Researcher / Engineer to support the Department of Homeland Security (DHS) Office of the Chief Information Security Officer. The role involves developing procedures for DHS' Vulnerability Management Branch, helping define and implement AI and cybersecurity policy at the federal level, and identifying risks and threats from AI-driven attacks. ",
        "industries": [
            "Cybersecurity",
            "Government",
            "Information Technology",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Critical thinking",
            "Leadership",
            "Teamwork",
            "Analytical",
            "Presentation",
            "Relationship building"
        ],
        "hard_skills": [
            "Data Modeling",
            "Data Engineering",
            "Feature Engineering",
            "Model Lifecycle Management",
            "Cloud Infrastructure",
            "Deep Learning",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Caffe",
            "Theano",
            "Python",
            "NIST SP 800-171",
            "NIST SP 800-172",
            "GitLab",
            "Jira",
            "AWS ECS",
            "Docker",
            "VMware",
            "VirtualBox",
            "Hyper-V",
            "AWS Sagemaker",
            "Penetration Testing",
            "Malware Analysis",
            "Network Traffic Analysis",
            "Statistics"
        ],
        "tech_stack": [
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Caffe",
            "Theano",
            "Python",
            "GitLab",
            "Jira",
            "AWS ECS",
            "Docker",
            "VMware",
            "VirtualBox",
            "Hyper-V",
            "AWS Sagemaker"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 12,
        "education": {
            "min_degree": "Bachelor of Science",
            "fields": [
                "Mathematics",
                "Cybersecurity",
                "STEM"
            ]
        },
        "salary": {
            "max": 220900,
            "min": 122200
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "College Park, MD",
        "job_id": 3796662634,
        "company": "Peraton Labs",
        "title": "Machine Learning Research Scientist (Fully Cleared)",
        "created_on": 1720587222.4823103,
        "description": "About Peraton Peraton is a next-generation national security company that drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted, highly differentiated solutions and technologies to protect our nation and allies. Peraton operates at the critical nexus between traditional and nontraditional threats across all domains: land, sea, space, air, and cyberspace. The company serves as a valued partner to essential government agencies and supports every branch of the U.S. armed forces. Each day, our employees do the can't be done by solving the most daunting challenges facing our customers. Visit peraton.com to learn how we're keeping people around the world safe and secure. Responsibilities With a distinguished heritage tracing back to Bell Labs, Bellcore, and Telcordia, our experts pave the way. Peraton Labs delivers innovative solutions and revolutionary new capabilities to solve the most difficult and complex challenges for government agencies, utilities, and commercial customers. Peraton Lab's cybersecurity research protects mission-critical systems and national cyber infrastructure through a broad range of initiatives in computer network defense, secure-by-design techniques and cyber operations and experimentation platforms. Your expertise and areas of interest may be applied on one or more programs, providing you new opportunities to learn and grow. We are actively seeking an entry to mid-level software engineer with machine learning experience to join our team of software research scientists working on full scope polygraph research within the maryland customer footprint. The perfect candidate for this role is someone with a strong technical prowess, inquisitive and curious nature, and strong desire to learn. Primary responsibilities may include: Designing, developing, and prototyping signal processing algorithms for wireless systems Conducting Radio Frequency (RF) machine learning research Implementing, debugging, and testing wireless application prototypes on third-party software-defined radio (SDR) platforms Communicating the results of research through customer presentations and publications Writing design documents, simulation reports, and system documentation Qualifications Minimum Requirements: 5 years with BS/BA or 3 years with MS/MA or 0 years with PhD within a software engineering focused degree. Experience coding within one or more of the following: Python, C, C++, and/or MATLAB Interest and/or experience in one or more of the following domains: digital signal processing, RF software engineering, algorithm development, software defined radio, and machine learning Experience with modern machine learning development frameworks and platforms (e.g. Keras, TensorFlow, PyTorch) is expected US Citizen with an active TS/SCI and Fully Cleared Poly Great to haves: Familiarity with common software defined radio platforms (e.g. Ettus USRPs) and software (e.g. GNU Radio) Familiarity with Open Air Interface(OAI) or srsLTE software stacks Familiarity with multiple-antenna or distributed signal processing techniques Knowledge of LTE standards Benefits: Our comprehensive Benefits and Beyond package is designed to support every aspect of your health, wealth, self and beyond. Health- Comprehensive medical, dental, and vision plans, HSAs and FSAs, and supplemental health options to keep you and your family healthy all year long. Well-being- We strive to support your overall well-being - including emotional, financial, social/community, and physical wellness programs. PTO & holidays- Our PTO programs helps you take the time in the ways that matter most. With 20 days a year of accrued PTO, 6 paid federal holidays, 4 floating holidays, and a flexible approach, Peraton Labs avidly supports a healthy work/life balance. Retirement- All regular employees are eligible to participate in Peraton's 401(k) retirement savings plan through Fidelity. Peraton will match 100% of the first 4% you contribute, and 50% of the next 2% you contribute. All contributions are 100% vested after two years of service. Career Development- We are invested in your future, and pride ourselves on providing best-in-class training to our team through Skillsoft e-Learning Suite for formal and informal learning, professional and technical certification preparation, and education assistance for career path-related courses at accredited institutions. TA and Student Loan Refinancing- Peraton provides tuition and training assistance for its employees, in addition to access to a student loan refinancing service and 529 plan through tuition.io to support your continued education aspirations. Target Salary Range $146,000 - $234,000. This represents the typical salary range for this position based on experience and other factors. SCA / Union / Intern Rate or Range EEO An Equal Opportunity Employer including Disability/Veteran. Our Values Benefits At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way. Paid Time-Off and Holidays Retirement Life & Disability Insurance Career Development Tuition Assistance and Student Loan Financing Paid Parental Leave Additional Benefits Medical, Dental, & Vision Care",
        "url": "https://www.linkedin.com/jobs/view/3796662634",
        "summary": "Peraton Labs is seeking a software engineer with machine learning experience to join their team of software research scientists working on polygraph research. The role involves designing, developing, and prototyping signal processing algorithms for wireless systems, conducting radio frequency (RF) machine learning research, and implementing and testing wireless application prototypes on software-defined radio (SDR) platforms.  Candidates should have experience with Python, C, C++, MATLAB, and machine learning development frameworks like Keras, TensorFlow, and PyTorch. A US citizenship with an active TS/SCI and Fully Cleared Poly is required.",
        "industries": [
            "National Security",
            "Cybersecurity",
            "Software Development",
            "Research and Development",
            "Telecommunications",
            "Government",
            "Defense"
        ],
        "soft_skills": [
            "Technical Prowess",
            "Inquisitive",
            "Curious",
            "Desire to Learn",
            "Communication",
            "Presentation",
            "Documentation"
        ],
        "hard_skills": [
            "Python",
            "C",
            "C++",
            "MATLAB",
            "Digital Signal Processing",
            "RF Software Engineering",
            "Algorithm Development",
            "Software Defined Radio",
            "Machine Learning",
            "Keras",
            "TensorFlow",
            "PyTorch",
            "Ettus USRPs",
            "GNU Radio",
            "Open Air Interface",
            "srsLTE",
            "Multiple-Antenna Signal Processing",
            "Distributed Signal Processing",
            "LTE Standards"
        ],
        "tech_stack": [
            "Python",
            "C",
            "C++",
            "MATLAB",
            "Keras",
            "TensorFlow",
            "PyTorch",
            "Ettus USRPs",
            "GNU Radio",
            "Open Air Interface",
            "srsLTE"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++",
            "MATLAB"
        ],
        "experience": 5,
        "education": {
            "min_degree": "BS/BA",
            "fields": [
                "Software Engineering"
            ]
        },
        "salary": {
            "max": 234000,
            "min": 146000
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "HSAs",
            "FSAs",
            "Supplemental Health",
            "Emotional Wellness",
            "Financial Wellness",
            "Social/Community Wellness",
            "Physical Wellness",
            "PTO",
            "Federal Holidays",
            "Floating Holidays",
            "Flexible Work",
            "401(k)",
            "Retirement Savings Plan",
            "Matching Contributions",
            "Vesting",
            "Skillsoft e-Learning",
            "Professional Certifications",
            "Technical Certifications",
            "Education Assistance",
            "Tuition Assistance",
            "Training Assistance",
            "Student Loan Refinancing",
            "529 Plan",
            "Paid Parental Leave",
            "Life Insurance",
            "Disability Insurance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Greenbelt, MD",
        "job_id": 3963747869,
        "company": "ORAU",
        "title": "Machine Learning Applications to Planetary Science Datasets",
        "created_on": 1720587223.841135,
        "description": "Organization National Aeronautics and Space Administration (NASA) Reference Code 0257-NPP-NOV24-GSFC-PlanetSci How To Apply All applications must be submitted in Zintellect Please visit the NASA Postdoctoral Program website for application instructions and requirements: How to Apply | NASA Postdoctoral Program (orau.org) A complete application to the NASA Postdoctoral Program includes: Research proposal Three letters of recommendation Official doctoral transcript documents Application Deadline 11/1/2024 6:00:59 PM Eastern Time Zone Description About the NASA Postdoctoral Program The NASA Postdoctoral Program (NPP) offers unique research opportunities to highly-talented U.S. and non-U.S. scientists to engage in ongoing NASA research projects at a NASA Center, NASA Headquarters, or at a NASA-affiliated research institute. These one- to three-year fellowships are competitive and are designed to advance NASA’s missions in space science, Earth science, aeronautics, space operations, exploration systems, and astrobiology. Description: Until recently, returned datasets from planetary science missions beyond Earth orbit have been modest, due to the relatively small numbers of missions, and limitations in downlink bandwidth (e.g. NASA's Deep Space Network). Their sparsity has allowed for multiple generations of researchers to conduct data analysis by detailed inspection, calibration, cataloging and modeling of every byte of data. The future of planetary science bodes to be different, with increasing numbers of missions, instruments that produce vastly larger data rates and volumes, resulting in much larger amounts of data being recorded for analysis. As with Earth remote sensing, this changing exploration landscape requires a paradigm shift in how planetary science is conducted, and most especially making use of advanced computational tools to leverage the expertise of human researchers, and to make rapid analysis of very large datasets tractable. Recent advances in machine learning techniques have opened up a new frontier for tackling the 'big data' problem in planetary sciences. Successful applications so far include feature recognition and semantic segmentation of image data, feature extraction from time series data from plasma and field detection instruments, and real-time decision making on spacecraft such as Perseverance. Together with mentors at NASA GSFC, the researcher will apply machine learning techniques to image and spectroscopic data to produce new scientific results, and to devise new analysis methodologies. Results will be published in journals and presented at conferences. Please contact the project mentor with any questions about project scope, background experience or eligibility. Preferred Qualifications: A post-doctoral researcher is sought with either pre-existing experience in machine learning applications in the geosciences or astronomy; or significant experience in computational techniques applied to scientific problems combined with a desire to quickly learn new techniques in machine learning. Strong computer coding skills are essential, and experience with python-based neural net architectures such as PyTorch, TensorFlow and Keras is preferable. Field of Science: Planetary Science Advisors: Conor Nixon conor.a.nixon@nasa.gov 301-286-6757 Applications with citizens from Designated Countries will not be accepted at this time, unless they are Legal Permanent Residents of the United States. A complete list of Designated Countries can be found at: https://www.nasa.gov/oiir/export-control. Eligibility is currently open to: U.S. Citizens; U.S. Lawful Permanent Residents (LPR); Foreign Nationals eligible for an Exchange Visitor J-1 visa status; and, Applicants for LPR, asylees, or refugees in the U.S. at the time of application with 1) a valid EAD card and 2) I-485 or I-589 forms in pending status Questions about this opportunity? Please email npp@orau.org Eligibility Requirements Degree: Doctoral Degree.",
        "url": "https://www.linkedin.com/jobs/view/3963747869",
        "summary": "NASA Postdoctoral Program opportunity for researchers to apply machine learning techniques to image and spectroscopic data from planetary science missions. The research will involve analyzing large datasets, developing new analysis methodologies, and producing scientific results for publication.",
        "industries": [
            "Aerospace",
            "Research",
            "Science",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Adaptability",
            "Learning"
        ],
        "hard_skills": [
            "Machine Learning",
            "Image Analysis",
            "Spectroscopy",
            "Python",
            "PyTorch",
            "TensorFlow",
            "Keras",
            "Computer Coding",
            "Data Analysis",
            "Scientific Computing"
        ],
        "tech_stack": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Keras"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Doctoral Degree",
            "fields": [
                "Planetary Science",
                "Geosciences",
                "Astronomy",
                "Computer Science",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3929723645,
        "company": "Capital One",
        "title": "Principal Data Scientist",
        "created_on": 1720587225.4094307,
        "description": "Locations: VA - McLean, United States of America, McLean, VirginiaPrincipal Data Scientist Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. Role Description In this role, you will: Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation Flex your interpersonal skills to translate the complexity of your work into tangible business goals The Ideal Candidate is: Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers. Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them. Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea. A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond. Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms. Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning. A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science. Basic Qualifications: Currently has, or is in the process of obtaining a Bachelor’s Degree plus 5 years of experience in data analytics, or currently has, or is in the process of obtaining a Master’s Degree plus 3 years in data analytics, or currently has, or is in the process of obtaining PhD, with an expectation that required degree will be obtained on or before the scheduled start date At least 1 year of experience in open source programming languages for large scale data analysis At least 1 year of experience with machine learning At least 1 year of experience with relational databases Preferred Qualifications: Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) At least 1 year of experience working with AWS At least 3 years’ experience in Python, Scala, or R At least 3 years’ experience with machine learning At least 3 years’ experience with SQL Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
        "url": "https://www.linkedin.com/jobs/view/3929723645",
        "summary": "Capital One is looking for a Data Scientist to join their team in McLean, VA. The ideal candidate is customer-focused, innovative, creative, and a leader. They should have strong technical skills in open-source languages and experience with machine learning, relational databases, and AWS. The role involves partnering with cross-functional teams to deliver products, leverage various technologies for data analysis, and build machine learning models.",
        "industries": [
            "Financial Services",
            "Technology",
            "Data Analytics"
        ],
        "soft_skills": [
            "Customer Focus",
            "Innovation",
            "Creativity",
            "Leadership",
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "Python",
            "Conda",
            "AWS",
            "H2O",
            "Spark",
            "Machine Learning",
            "Relational Databases",
            "SQL",
            "Scala",
            "R",
            "Data Analysis",
            "Statistical Modeling",
            "Clustering",
            "Classification",
            "Sentiment Analysis",
            "Time Series",
            "Deep Learning"
        ],
        "tech_stack": [
            "Python",
            "Conda",
            "AWS",
            "H2O",
            "Spark",
            "SQL",
            "Scala",
            "R"
        ],
        "programming_languages": [
            "Python",
            "Scala",
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Analytics",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Financial Benefits",
            "Total Well-being Support"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3958005138,
        "company": "Garner Health",
        "title": "Senior Software Engineer (Python)",
        "created_on": 1720587227.3109264,
        "description": "Garner's mission is to transform the healthcare economy, delivering high quality and affordable care for all. By helping employers restructure their healthcare benefit to provide clear incentives and data-driven insights, we direct employees to higher quality and lower cost healthcare providers. The result is that patients get better health outcomes while doctors are rewarded for practicing well, not performing more procedures. We are backed by top-tier venture capital firms, are growing rapidly and looking to expand our team. We've recently launched our product. Now we're moving quickly to expand, hone, and enhance its features to help our members find top doctors in their area and have qualifying bills paid as quickly as possible. We are looking for engineers who are excited about our mission, can deliver across the tech stack, and are eager to learn and apply new techniques and technologies. Main Responsibilities: Build and maintain data pipelines that power our business Collaborate across disciplines to provide timely and accurate information Protect our users' privacy and security through best practices Support data pipelines in production Our Tools: Python, AWS, NATS, Terraform, Postgres, ElasticSearch, Redshift, SnowFlake Ideal Qualifications: Strong Computer Science fundamentals 5+ years of industry experience building and maintaining scalable high-quality software 3+ years of hands-on experience building data pipelines Expertise in Python Expertise in SQL Familiarity with data warehousing Experience working with back-end APIs, and distributed event-driven architectures. Experience with one or more database systems, especially PostgreSQL Experience working in a team using Agile methodologies Why You Should Join Our Team: You are mission-driven, have a high sense of ownership, and want to work at a company that can change the healthcare system You are not afraid of challenges and love to learn You design and optimize for the long term while moving fast and iteratively deliver for the short term You love ideating on new features and working with data to find new insights You're excited about researching and working with the latest tools and technologies The target salary range for this position is $155,000 - $190,000 annually. Individual compensation for this role will depend on a variety of factors including qualifications, skills and applicable laws. In addition to base compensation, this role is eligible to participate in our equity incentive and competitive benefits plans. Garner Health is proud to be an Equal Employment Opportunity employer and values diversity in the workplace. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. Garner Health is committed to providing accommodations for qualified individuals with disabilities in our recruiting process. If you need assistance or an accommodation due to a disability, you may contact us at talent@getgarner.com. Beware of job scam fraudsters! Our recruiters use getgarner.com email addresses exclusively. We do not post open roles on Indeed, conduct interviews via text, instant message, or Teams and we do not ask candidates to download software, purchase equipment through us, or to provide sensitive information such as bank account or social security numbers. If you have been contacted by someone claiming to be a Garner recruiter or hiring manager from a different domain about a job offer, please report it as potential job fraud to law enforcement here and to candidateprotection@getgarner.com",
        "url": "https://www.linkedin.com/jobs/view/3958005138",
        "summary": "Garner is a healthcare company that aims to improve healthcare quality and affordability by restructuring employer healthcare benefits and providing data-driven insights to direct employees towards higher quality, lower cost providers. The company is looking for a Data Engineer to build and maintain data pipelines that power their business, collaborating across disciplines to deliver timely and accurate information while ensuring user privacy and security.",
        "industries": [
            "Healthcare",
            "Technology",
            "Data Science",
            "FinTech"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Ownership",
            "Mission-driven",
            "Adaptability",
            "Learning",
            "Creativity",
            "Analytical thinking"
        ],
        "hard_skills": [
            "Python",
            "AWS",
            "NATS",
            "Terraform",
            "Postgres",
            "ElasticSearch",
            "Redshift",
            "Snowflake",
            "SQL",
            "Data Warehousing",
            "API Development",
            "Distributed Event-Driven Architectures",
            "Agile Methodologies"
        ],
        "tech_stack": [
            "Python",
            "AWS",
            "NATS",
            "Terraform",
            "Postgres",
            "ElasticSearch",
            "Redshift",
            "Snowflake"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 190000,
            "min": 155000
        },
        "benefits": [
            "Equity incentive",
            "Competitive benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Gaithersburg, MD",
        "job_id": 3970743486,
        "company": "Proclinical Staffing",
        "title": "Associate Scientist, LC/MS",
        "created_on": 1720587228.6983097,
        "description": "Associate Scientist, LC/MS - Contract - Gaithersburg, MD Proclinical is seeking a dedicated Associate Scientist to join an Analytical Development team. Primary Responsibilities: The ideal candidate will have a strong background in HPLC and Size Separation based methods for the characterization of protein or vaccine products. This role involves supporting the development and qualification of molecular separation assays, conducting investigations, and writing technical reports. A solid understanding of FDA and ICH guidelines and practical knowledge with assay validation is essential. Skills & Requirements: MS in analytical science, chemistry, biochemistry, or related field with industry experience in biopharmaceutical and/or vaccine development. Ability to critically analyze data using statistical tools and to compile and review technical reports. Ability to define priorities and process to get things done. Knowledge and expertise in the principles and practice of current Good Manufacturing Practices (GMPs) is preferred. Excellent record keeping abilities to adequately record, analyze, and document analytical data generated in support of regulatory requirements. Good understanding of statistical tools and knowledge of DOE (Design of Experiments) and QbD (Quality by Design) principles is a plus. Strong communication, presentation, and writing skills. The Associate Scientist's responsibilities will be: Develop HPLC related methods for the separation and identity of related proteins and/or impurities in nanoparticle vaccine products. Lead experimental designs to characterize Drug Substance and Drug Product materials. Test in-process samples using HPLC to support process development and stability studies of nanoparticle vaccines. Draft qualification and/or validation protocols for test methods to evaluate in-process samples. Participate in cross-functional workflows and provide scientific guidance to teams. Apply new technologies to improve throughput for in-process testing and enhance product characterization. Perform method transfers to QC and other groups and external partners. Maintain effective communication within Analytical Development and cross-functional teams. Present scientific findings at internal and external meetings. Compensation: $30 - $35 per hour If you are having difficulty in applying or if you have any questions, please contact Shannon Briggs at s.briggs@proclinical.com Proclinical is a specialist employment agency and recruitment business, providing job opportunities within major pharmaceutical, biopharmaceutical, biotechnology and medical device companies. Proclinical Staffing is an equal opportunity employer. INDSCIC",
        "url": "https://www.linkedin.com/jobs/view/3970743486",
        "summary": "Proclinical is seeking an Associate Scientist for their Analytical Development team in Gaithersburg, MD. The role requires a strong background in HPLC and Size Separation methods for characterizing protein or vaccine products, and experience in biopharmaceutical and/or vaccine development. Responsibilities include developing and validating molecular separation assays, conducting investigations, and writing technical reports. The ideal candidate will have knowledge of FDA and ICH guidelines, GMPs, statistical tools, DOE, and QbD principles. The position offers a competitive hourly rate of $30 - $35.",
        "industries": [
            "Biotechnology",
            "Pharmaceutical",
            "Biopharmaceutical",
            "Medical Device",
            "Vaccine Development",
            "Analytical Science",
            "Chemistry"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Writing",
            "Critical Thinking",
            "Problem Solving",
            "Teamwork",
            "Collaboration",
            "Organization",
            "Time Management",
            "Prioritization",
            "Leadership",
            "Decision Making"
        ],
        "hard_skills": [
            "HPLC",
            "Size Separation",
            "Protein Characterization",
            "Vaccine Characterization",
            "Assay Development",
            "Assay Validation",
            "Data Analysis",
            "Statistical Tools",
            "FDA Guidelines",
            "ICH Guidelines",
            "GMP",
            "QbD",
            "DOE"
        ],
        "tech_stack": [
            "HPLC"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Analytical Science",
                "Chemistry",
                "Biochemistry"
            ]
        },
        "salary": {
            "max": 35,
            "min": 30
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3818345337,
        "company": "Devang Technologies",
        "title": "Data Scientist with Polygraph",
        "created_on": 1720587230.2371445,
        "description": "Job Description The Data Scientist will serve on the intelligence analysis staff for a U.S. Federal Government Agency working with classified media. This position will work with a team of designers, engineers, architects, and data scientists to query and structure data, apply algorithms to develop machine learning models, develop metrics and data visualizations, and deploy visualization products to web-based environments. The Data Scientist will have a strong background in technology, the ability to structure data for reporting, and a strategic view for how to present analytic results to customers. This position will be responsible for presenting and explaining complex results to business users. Responsibilities: Develop intuitive dashboards and data visualization products using Tableau or other data visualization tools; Develop performance metrics, conduct statistical analyses, and apply decision models to address business process challenges; Query databases using SQL with structured data and perform statistical analysis; Gather and process raw data at scale by using statistical packages (e.g., R, SAS) and programming languages (e.g., Python, Java, and Scala); Support business decisions with ad hoc analysis; Think strategically about how to publish data visualizations and present analytic results; Develop a familiarity with machine learning algorithms and advanced statistical methods, such as regression, clustering, decision trees, exploratory data analysis methodology, simulation, scenario analysis, modeling, and neural networks; and Use critical thinking skills to assess how machine learning capabilities can best be applied to complex business situations. Qualifications: Current TS/SCI with FULLSCOPE polygraph Qualifications Develop intuitive dashboards and data visualization products using Tableau or other data visualization tools; Develop performance metrics, conduct statistical analyses, and apply decision models to address business process challenges; Query databases using SQL with structured data and perform statistical analysis; Gather and process raw data at scale by using statistical packages (e.g., R, SAS) and programming languages (e.g., Python, Java, and Scala); Support business decisions with ad hoc analysis; Think strategically about how to publish data visualizations and present analytic results; Develop a familiarity with machine learning algorithms and advanced statistical methods, such as regression, clustering, decision trees, exploratory data analysis methodology, simulation, scenario analysis, modeling, and neural networks; and Use critical thinking skills to assess how machine learning capabilities can best be applied to complex business situations. Qualifications: Current TS/SCI with FULLSCOPE polygraph Why is This a Great Opportunity The Data Scientist will have a strong background in technology, the ability to structure data for reporting, and a strategic view for how to present analytic results to customers. This position will be responsible for presenting and explaining complex results to business users.",
        "url": "https://www.linkedin.com/jobs/view/3818345337",
        "summary": "The Data Scientist will work with a team to query and structure data, apply algorithms to develop machine learning models, develop metrics and data visualizations, and deploy visualization products to web-based environments. The position requires a strong background in technology, data structuring, and presentation skills.  The Data Scientist will be responsible for presenting and explaining complex results to business users.",
        "industries": [
            "Government",
            "Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Strategic Thinking",
            "Problem Solving",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Data Visualization",
            "Tableau",
            "SQL",
            "Data Analysis",
            "Machine Learning",
            "Regression",
            "Clustering",
            "Decision Trees",
            "Exploratory Data Analysis",
            "Simulation",
            "Scenario Analysis",
            "Modeling",
            "Neural Networks"
        ],
        "tech_stack": [
            "Tableau",
            "SQL",
            "R",
            "SAS",
            "Python",
            "Java",
            "Scala"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala",
            "R",
            "SAS"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3969274957,
        "company": "Amazon Web Services (AWS)",
        "title": "Applied Scientist, AWS Generative AI Innovation Center",
        "created_on": 1720587231.8275046,
        "description": "Description The Generative AI Innovation Center at AWS helps AWS customers accelerate the use of Generative AI and realize transformational business opportunities. This is a cross-functional team of ML scientists, engineers, architects, and strategists working step-by-step with customers to build bespoke solutions that harness the power of Generative AI. As an Applied Scientist, you are proficient in designing and developing advanced ML models to solve diverse challenges and opportunities. You will work directly with customers and innovate in a fast-paced organization that contributes to game-changing projects and technologies. You will design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience. We’re looking for ML Applied Scientists capable of using GenAI and other ML/DL techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems. Sales, Marketing, and Global Services (SMGS) is responsible for driving revenue, adoption, and growth from the largest and fastest growing small- and mid-market accounts to enterprise-level customers including public sector. The AWS Global Support team interacts with leading companies and believes that world-class support is critical to customer success. AWS Support also partners with a global list of customers that are building mission-critical applications on top of AWS services. Key job responsibilities As An ML Applied Scientist, You Will Collaborate with ML scientist and architects to research, design, develop, and evaluate cutting-edge generative AI algorithms to address real-world challenges across industries Interact with customers directly to understand the business problem, and help them in defining and implementing generative AI solutions and guide customers on adoption patterns and paths to production Work closely with account teams, research scientist teams, and product engineering teams to drive model implementations and new solution Create and deliver best practice recommendations, scientific artifacts, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholders A day in the life About AWS Diverse Experiences AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship & Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why flexible work hours and arrangements are part of our culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud About The Team The team helps customers imagine and scope the use cases that will create the greatest value for their businesses, select and fine-tune the right models, define paths to navigate technical or business challenges, develop proof-of-concepts, and make plans for launching solutions at scale. The GenAI Innovation Center team provides guidance on best practices for applying generative AI responsibly and cost efficiently. Basic Qualifications PhD, or Master's degree and 4+ years of deep learning, computer vision, human robotic interaction, algorithms implementation experience Experience in patents or publications at top-tier peer-reviewed conferences or journals Experience programming in Java, C++, Python or related language Experience in any of the following areas: algorithms and data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing Preferred Qualifications Experience with generative deep learning models applicable to the creation of synthetic humans like CNNs, GANs, VAEs and NF Experience in building machine learning models for business application Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $136,000/year in our lowest geographic market up to $222,200/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon.com Services LLC Job ID: A2692368",
        "url": "https://www.linkedin.com/jobs/view/3969274957",
        "summary": "Amazon Web Services (AWS) is seeking an Applied Scientist to join the Generative AI Innovation Center, a cross-functional team dedicated to helping customers utilize Generative AI for transformational business opportunities. This role involves designing and developing advanced ML models, collaborating with customers to implement Generative AI solutions, and creating best practice recommendations. The ideal candidate will have a PhD or Master's degree with relevant experience in deep learning, computer vision, and algorithm implementation, along with strong programming skills and a passion for innovation.",
        "industries": [
            "Technology",
            "Cloud Computing",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Customer Focus",
            "Innovation",
            "Research",
            "Presentation Skills",
            "Leadership"
        ],
        "hard_skills": [
            "Deep Learning",
            "Computer Vision",
            "Human Robotic Interaction",
            "Algorithm Implementation",
            "Java",
            "C++",
            "Python",
            "Algorithms and Data Structures",
            "Parsing",
            "Numerical Optimization",
            "Data Mining",
            "Parallel and Distributed Computing",
            "High-Performance Computing",
            "Generative Deep Learning",
            "CNNs",
            "GANs",
            "VAEs",
            "NF",
            "Machine Learning Model Building"
        ],
        "tech_stack": [
            "AWS",
            "Generative AI",
            "Machine Learning (ML)",
            "Deep Learning (DL)",
            "CNNs",
            "GANs",
            "VAEs",
            "NF",
            "Java",
            "C++",
            "Python"
        ],
        "programming_languages": [
            "Java",
            "C++",
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Deep Learning",
                "Computer Vision",
                "Human Robotic Interaction",
                "Algorithms"
            ]
        },
        "salary": {
            "max": 222200,
            "min": 136000
        },
        "benefits": [
            "Health Insurance",
            "Financial Benefits",
            "Equity",
            "Sign-On Payments",
            "Flexible Work Hours"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Bethesda, MD",
        "job_id": 3914466016,
        "company": "Total Wine & More",
        "title": "Lead Machine Learning Engineer",
        "created_on": 1720587233.411375,
        "description": "Description About the Role Total Wine & More is looking for a Lead Machine Learning Engineer with expertise and a proven track record of deploying machine learning models into production, to join our Data Services team in Boca Raton, FL or Bethesda, MD. You will be responsible for enabling, automating, deploying, scaling and monitoring machine learning algorithms built by the data science team. You will work within current DevOps frameworks and make sure the data science teamwork is being deployed in an effective manner for production use. Working closely with software development and support teams, infrastructure, and security staff, you will enjoy learning and problem-solving in a fast-paced environment while being exposed to a diverse set of machine learning problems. As our team continues to grow, you will play an important part of our overall success and contribute to the value of the work produced by the data science team. You will report into the Director of Data Science and Analytics. You will Manage and deploy machine learning models developed by Data Science team into production – integrated with the team through the development process. Support the retraining, monitoring, and measurement of deployed machine learning models – covering a wide spectrum of ML approaches. Create common frameworks for delivering modeling results to systems within TWM. Build out tools to support data scientists – lowering the level of effort to create and prototype machine learning models, such as building a feature data store. In collaboration with the Data Platform team, make sure ML results are published within TWM data warehouse and easily digestible by end users. In collaboration with Engineering and Architecture teams, build and maintain MLOps tools and frameworks – utilizing DevOps tools currently in place at Total Wine & More. In partnership with Data Science team members, maintain documentation and manage the transition of production processes to production support team, when applicable. You will come with Bachelor's degree from four-year College or university in Computer Science, Mathematics, Statistics or related field. Master’s or PhD preferred. 6+ years of experience in data science, computer science or related fields or 5+ years with Master’s degree. 6+ years of experience in software engineering, data engineering, or related fields or 5+ years with Master’s degree. Strong understanding of MLOps principles and practices with experience of supporting a data science team through the ML lifecycle to include deployment and monitoring. Experience with operationalizing, monitoring, and scaling machine learning models and pipelines in cloud ecosystems. Skills in handling and managing large datasets including, data cleaning, preprocessing, and storage. Deep understanding of batch and streaming pipelines as well as orchestrators like Argo and Airflow. Fundamental understanding of machine learning modeling techniques and algorithms. Experience using machine learning frameworks such as scikit-learn, pandas, numpy, xgboost, and pytorch. Solid programming skills in Python and the ability to write clean, efficient, and well-documented code. The ability to work effectively in a team and communicate complex ideas clearly with individuals from diverse technical and non-technical backgrounds. Familiarity with ML serving solutions like Ray, KubeFlow or W&B is a plus. The ability to present technical concepts and results in an audience-appropriate way Retail or similar experience a plus. Understanding of A/B testing We offer Paid Time Off (PTO) Generous store discounts Health care plans (medical, prescription, dental, vision) 401(k), HSA, FSA, Pre-tax commuter benefits Disability & life insurance coverage Paid parental leave Pet insurance Critical illness and accident insurance Discounted home and auto insurance College tuition assistance Career development & product training Consumer classes & More! Grow with us Total Wine & More is the country's largest independent retailer of fine wine, beer and spirits, and we continue to grow our footprint year over year. Total Wine offers exciting and unique career opportunities across the country and in our corporate office. Our strength is our people. We have a commitment to training and career growth, all in an environment that values new ideas and teamwork. If you share our entrepreneurial spirit and a passion for providing best-in-class customer experience, take a moment to apply or learn more at www.TotalWine.com/About-Us/Careers ! Total Wine & More considers several factors when establishing compensation. Estimated salaries determined by third parties have not been validated by Total Wine & More. Total Wine & More is an equal opportunity employer and all qualified applicants will receive consideration for employment without discrimination based on race, color, religion, national origin, sex, sexual orientation, age, marital status, veteran status, disability, or any other characteristic protected by applicable law. Total Wine & More makes reasonable accommodations during all aspects of the employment process, including during the interview process. Total Wine & More is a Drug Free Workplace. The information provided above indicates the general nature and level of work required of the position and is not a comprehensive list of all responsibilities or qualifications. Benefits list is only a highlight of some of the benefits offered to team members; eligibility for certain benefits apply.",
        "url": "https://www.linkedin.com/jobs/view/3914466016",
        "summary": "Total Wine & More is seeking a Lead Machine Learning Engineer to join their Data Services team in Boca Raton, FL or Bethesda, MD. The role involves deploying and managing machine learning models developed by the data science team, supporting their retraining and monitoring, and building frameworks for delivering modeling results. The ideal candidate will have experience with MLOps, cloud ecosystems, data handling, and machine learning frameworks, and strong programming skills in Python. Retail experience, understanding of A/B testing, and familiarity with ML serving solutions are a plus.",
        "industries": [
            "Retail",
            "Wine & Spirits",
            "Data Science",
            "Machine Learning",
            "Software Engineering",
            "Data Engineering",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Teamwork",
            "Collaboration",
            "Documentation",
            "Presentation"
        ],
        "hard_skills": [
            "MLOps",
            "Machine Learning",
            "Cloud Ecosystems",
            "Data Cleaning",
            "Data Preprocessing",
            "Data Storage",
            "Batch Pipelines",
            "Streaming Pipelines",
            "Argo",
            "Airflow",
            "Scikit-learn",
            "Pandas",
            "Numpy",
            "XGBoost",
            "Pytorch",
            "Python",
            "Ray",
            "KubeFlow",
            "W&B",
            "A/B Testing"
        ],
        "tech_stack": [
            "Argo",
            "Airflow",
            "Scikit-learn",
            "Pandas",
            "Numpy",
            "XGBoost",
            "Pytorch",
            "Ray",
            "KubeFlow",
            "W&B"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Paid Time Off (PTO)",
            "Store Discounts",
            "Health Care Plans",
            "401(k)",
            "HSA",
            "FSA",
            "Pre-tax Commuter Benefits",
            "Disability & Life Insurance",
            "Paid Parental Leave",
            "Pet Insurance",
            "Critical Illness and Accident Insurance",
            "Discounted Home and Auto Insurance",
            "College Tuition Assistance",
            "Career Development & Product Training",
            "Consumer Classes"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3842254052,
        "company": "Harnham",
        "title": "Senior Machine Learning Software Engineer - Federal",
        "created_on": 1720587236.7898254,
        "description": "Senior Machine Learning Software Engineer - Federal Washington D.C. $160,000 - $200,000 + Competitive Benefits THE COMPANY COMPANY: An exciting tech start up working with government clients is looking to grow their line of products! TEAM: Work with a team of strong research scientists and machine learning engineers to build out top AI solutions end to end. CULTURE: Casual work environment along with a diverse and inclusive culture. THE ROLE As a Senior Machine Learning Software Engineer you will… Modeling: Build end to end machine learning models from ideation through deployment for problems in anomaly detection and predictive maintenance Deploy models into production and maintain them in production Work with a large amount of data Help with areas of scalability, MLOps, and ML infrastructure YOUR SKILLS AND EXPERIENCE 3+ years of full time industry experience in and machine learning and software engineering Strong software engineering background and a degree in computer science Experience working end to end and deploying models into production Experience working with large data sets and doing feature engineering Experience with MLOps and ML infrastructure Experience working in defense and government Tools: Python, SQL, Tensorflow, Kubeflow, MLFlow, Docker, Kubernetes THE BENEFITS As a Senior Machine Learning Software Engineer, you can expect a base salary between $160,000 to $200,000 (based on experience) plus competitive benefits. HOW TO APPLY Please register your interest by sending your CV to Kristianna Chung via the Apply link on this page",
        "url": "https://www.linkedin.com/jobs/view/3842254052",
        "summary": "A tech startup working with government clients is seeking a Senior Machine Learning Software Engineer to build end-to-end AI solutions, including anomaly detection and predictive maintenance models. The ideal candidate will have 3+ years of experience in machine learning and software engineering, strong software engineering skills, a computer science degree, and experience deploying models into production. Experience with large datasets, feature engineering, MLOps, ML infrastructure, and working in defense/government is also preferred. This role offers a competitive salary between $160,000 and $200,000, along with benefits.",
        "industries": [
            "Technology",
            "Government",
            "Defense",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Collaboration"
        ],
        "hard_skills": [
            "Machine Learning",
            "Software Engineering",
            "Anomaly Detection",
            "Predictive Maintenance",
            "Model Deployment",
            "Data Handling",
            "Feature Engineering",
            "MLOps",
            "ML Infrastructure"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Tensorflow",
            "Kubeflow",
            "MLFlow",
            "Docker",
            "Kubernetes"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science"
            ]
        },
        "salary": {
            "max": 200000,
            "min": 160000
        },
        "benefits": [
            "Competitive Benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3969150209,
        "company": "Lockheed Martin",
        "title": "Software Engineer",
        "created_on": 1720587238.4567194,
        "description": "We’re delivering full-spectrum cyber capabilities and cyber-resilient systems to our defense, intelligence community and global security customers. Lockheed Martin is inspired by their missions, and we’re dedicated to helping governments and militaries around the world protect their platforms, systems, networks and data. In This Role You Will Have The Opportunity To Work on a small team to develop new applications, tools and processes within COTS standalone and web-based software products Be responsible for the successful completion of application development tasks, using various programming languages, to enhance the Sponsor’s data analysis and data visualization capabilities Interface with the application development teams in other parts of the sponsor’s organization in pursuit of existing applications, tools, or custom code that can enable the successful completion of requirements",
        "url": "https://www.linkedin.com/jobs/view/3969150209",
        "summary": "Develop new applications, tools and processes within COTS standalone and web-based software products to enhance data analysis and visualization capabilities. Work with other development teams to leverage existing applications and tools.",
        "industries": [
            "Defense",
            "Intelligence",
            "Cybersecurity",
            "Software Development",
            "Government",
            "Military"
        ],
        "soft_skills": [
            "Teamwork",
            "Problem Solving",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Application Development",
            "Programming Languages",
            "Data Analysis",
            "Data Visualization"
        ],
        "tech_stack": [
            "COTS",
            "Web-Based Software",
            "Data Analysis Tools",
            "Data Visualization Tools"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Sterling, VA",
        "job_id": 3860978959,
        "company": "Dedrone",
        "title": "Computer Vision Research Scientist",
        "created_on": 1720587240.1170037,
        "description": "Company Overview : Dedrone is the world’s most trusted smart airspace security company. Hundreds of commercial, government and military customers around the world rely on Dedrone’s comprehensive, command and control (C2) solution to protect against the persistent and escalating threat from drones while enabling “good” drones to fly. By leveraging AI/ML, Dedrone is the only solution that provides continuous, autonomous interrogation and verification of drones that enables both multi-sensor and multi-mitigation options onto a single fused \"pane-of-glass\". Whether on-premise / air-gapped or in the cloud, Dedrone customers can easily detect, track, identify, analyze, and mitigate drone threats. Dedrone is looking for a team member to research, develop, and train deep-learning computer vision models and advance object-tracking algorithms. Dedrone's global sensor network, data science team, and computing cluster offer an ideal environment for research and development. We seek someone experienced in visual object tracking and modifying neural network training recipes and architectures to solve complex computer vision problems. You will… Research, develop, and train deep-learning computer vision models and advance object-tracking algorithms Work closely with cross-functional teams to identify opportunities to leverage computer vision technology to solve complex business problems. Develop and maintain relationships with external partners, vendors, and research organizations. Develop, implement, and optimize computer vision algorithms for processing and analyzing medical imaging data, You have… Degree in Computer Science, Mathematics, Physics, Electrical Engineering, or a related field. Proficient in PyTorch Skilled in ML experiment creation and analysis of results Good understanding of target tracking concepts such as data association and state estimation. Deep understanding of deep learning object detection models. Able to clearly explain the difference between YOLOV4 and Faster R-CNN. Experience working with academic and industry partners in a collaborative and international environment Proactive problem-solving skills. Willingness to constantly learn and ability to spot and resolve problems in a team setting. At Dedrone, we believe that great ideas come from anywhere. We support a collaborative environment and value open participation from individuals with different ideas, experiences, and perspectives. We believe having a diverse team makes Dedrone a more interesting and innovative place to work, and we strive to make Dedrone a welcoming and inclusive place for all.",
        "url": "https://www.linkedin.com/jobs/view/3860978959",
        "summary": "Dedrone is seeking a skilled computer vision engineer to research, develop, and train deep-learning models for object tracking. The role involves collaborating with cross-functional teams, establishing partnerships, and optimizing algorithms for medical imaging data. The ideal candidate will have a strong understanding of deep learning object detection models, proficient in PyTorch, and experienced in target tracking concepts.",
        "industries": [
            "Computer Software",
            "Artificial Intelligence",
            "Aerospace",
            "Defense",
            "Security",
            "Information Technology",
            "Research",
            "Medical Imaging"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Proactive",
            "Learning",
            "Teamwork"
        ],
        "hard_skills": [
            "Deep Learning",
            "Computer Vision",
            "Object Tracking",
            "PyTorch",
            "ML Experimentation",
            "Data Association",
            "State Estimation",
            "Object Detection",
            "YOLOv4",
            "Faster R-CNN",
            "Medical Imaging"
        ],
        "tech_stack": [
            "PyTorch",
            "YOLOv4",
            "Faster R-CNN"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Physics",
                "Electrical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3912065271,
        "company": "Unreal Staffing, Inc",
        "title": "Front-end Engineer",
        "created_on": 1720587245.7152927,
        "description": "Responsibilities As a founding engineer, you'll play a pivotal role in shaping the future of auditing by developing and owning the front-end of our platform. You'll have the opportunity to work directly with customers, spending time each week to understand their needs and gather feedback to improve their experience. Your insights will directly influence our product strategy, design, and overall user experience. Additionally, you'll contribute to building and fostering Agentive's engineering culture as we continue to grow. Requirements Qualifications Proficiency in our tech stack, including React, Next.js, and TypeScript Prior experience in a startup environment or a fast-paced setting that values initiative and action An entrepreneurial mindset and a desire to make a meaningful impact in the startup ecosystem Familiarity with modern AI and ML technologies, with a keen interest in leveraging them to drive innovation While experience in building financial products is beneficial, it's not required for this role Benefits Competitive salary and equity options Flexible work environment with opportunities for remote work and a healthy work-life balance Health insurance coverage, including medical, dental, and vision plans Professional development stipend to support your continued learning and growth Collaborative and inclusive company culture that values diversity and creativity Opportunity to be a part of a dynamic startup team and make a meaningful impact from day one",
        "url": "https://www.linkedin.com/jobs/view/3912065271",
        "summary": "Agentitive is searching for a founding engineer to build and own the front-end of their auditing platform. This role involves working directly with customers to understand their needs, influencing product strategy, and contributing to building a strong engineering culture. The ideal candidate will have proficiency in React, Next.js, and TypeScript, experience in a startup environment, and an entrepreneurial mindset.",
        "industries": [
            "Technology",
            "Finance",
            "Auditing",
            "Software Development"
        ],
        "soft_skills": [
            "Entrepreneurial",
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Initiative",
            "Collaboration",
            "Customer Focus",
            "Adaptability"
        ],
        "hard_skills": [
            "React",
            "Next.js",
            "TypeScript",
            "AI",
            "ML",
            "Financial Products"
        ],
        "tech_stack": [
            "React",
            "Next.js",
            "TypeScript"
        ],
        "programming_languages": [
            "JavaScript",
            "TypeScript"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Equity Options",
            "Flexible Work Environment",
            "Remote Work",
            "Work-Life Balance",
            "Health Insurance",
            "Professional Development Stipend",
            "Collaborative Culture",
            "Diversity",
            "Creativity"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Laurel, MD",
        "job_id": 3732418031,
        "company": "The Johns Hopkins University Applied Physics Laboratory",
        "title": "Machine Learning Researcher",
        "created_on": 1720587247.07285,
        "description": "Description Are you a talented scientist looking to achieve technical breakthroughs at the cutting edge of artificial intelligence (AI) and machine learning (ML)? Do you thrive in a collaborative research environment, working alongside an energetic, multidisciplinary team of scientists and engineers? Are you ready to help the US secure and maintain leadership in the development and fielding of AI/ML algorithms for non-kinetic defense systems? If so, we 're looking for someone like you to join our team at APL. We are seeking an experienced Research Scientist to make substantial technical contributions in the pursuit of advanced research and innovative applications of AI/ML. You will be joining a team of engineers and scientists who are at the forefront of APL's mission to provide innovative solutions to critical challenges. As An AI/ML Research Scientist, You Will Pursue research that advances the science and applications of AI/ML to develop novel technical capabilities poised to revolutionize 21st century national security. Design, implement, and evaluate new algorithms, models, and agents for super human decision making, reinforcement learning, and machine learning generally. Collaborate closely with the talented team of scientists and engineers in our group and with others across APL. Document and publish your scientific results in academic conferences and journals to advance our collective knowledge in this fast paced, dynamic field of study. Qualifications You meet the minimum requirements for the job if you... Hold a PhD in Computer Science, Engineering, Math, Statistics, or a related field. Have a deep understanding of, and demonstrated expertise in, technical efforts related to AI/ML: deep learning, reinforcement learning, AI Explainability, or a closely related area. Have strong, effective communication skills - both verbal and written. Have experience developing AI/ML research prototypes in code, using one or more of scikitlearn, Tensorflow, PyTorch, or similar machine learning frameworks in Python. Are able to obtain an Interim Secret level security clearance by your start date and can ultimately obtain a Secret level clearance. If selected, you will be subject to a government security clearance investigation and must meet the requirements for access to classified information. Eligibility requirements include U.S. citizenship. You 'll go above and beyond our minimum requirements if you... Have at least five years of relevant experience. Possess demonstrated research experience represented by publications in academic conferences and journals. Have a track record of proposing, developing, and successfully executing novel research initiatives in the application of AI/ML. Have a strong understanding of state-of-the-art techniques in neural networks and reinforcement learning. Have experience working with models and simulations using C, C++, Java or other suitable programming languages (in addition to Python). Why work at APL? The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation's most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates. At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL's campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at http://www.jhuapl.edu/careers. About Us APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law. APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.",
        "url": "https://www.linkedin.com/jobs/view/3732418031",
        "summary": "The Johns Hopkins University Applied Physics Laboratory (APL) is seeking an experienced Research Scientist to advance the science and applications of AI/ML for non-kinetic defense systems. The role involves developing novel technical capabilities, designing and evaluating new algorithms and models, collaborating with a team of scientists and engineers, and publishing research results in academic conferences and journals.",
        "industries": [
            "Defense",
            "Security",
            "Aerospace",
            "Research",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Research"
        ],
        "hard_skills": [
            "Deep Learning",
            "Reinforcement Learning",
            "AI Explainability",
            "Scikit-learn",
            "Tensorflow",
            "PyTorch",
            "Python",
            "C",
            "C++",
            "Java"
        ],
        "tech_stack": [
            "Scikit-learn",
            "Tensorflow",
            "PyTorch",
            "Python",
            "C",
            "C++",
            "Java"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++",
            "Java"
        ],
        "experience": 5,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Computer Science",
                "Engineering",
                "Math",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Education Assistance Program",
            "Retirement Contributions",
            "Work/Life Balance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Laurel, MD",
        "job_id": 3882223287,
        "company": "The Johns Hopkins University Applied Physics Laboratory",
        "title": "Autonomous Systems Machine Learning Engineer",
        "created_on": 1720587248.6356678,
        "description": "Description Do you have a passion for creating machine-learning-based tools that enable the safe development and deployment of autonomous systems? Do you want to make an impact on the future of our nation's defense capabilities? Do you thrive in dynamic and collaborative environments? If so, we are looking for someone like you to join our team at APL! We are seeking a talented and motivated Machine Learning Engineer to join the Ocean Systems and Engineering Group. In this role, you will play a crucial part in the development of innovative testing solutions that incorporate sophisticated ML capabilities. You will work closely with multidisciplinary teams in an agile software and rapid prototyping environment to build the next generation of software and machine-learning-based test tools for autonomous platforms. These test tools will help assure the safety and performance of the novel capabilities deployed in operational environments by our service members. As a Machine Learning Engineer you will..... Leverage and advance machine-learning approaches to evaluate the performance of autonomous systems. Apply the fields of data science and statistics to verify autonomous decision processes. Develop and implement full-lifecycle testing software for assuring autonomous behavior. This includes interface and standards definition, agile software development, simulation-based tool development, field-testing, full-scope documentation, and technical reviews. Design, develop and configure simulation environments used to test and evaluate autonomy algorithms in autonomous systems. Plan, complete, and analyze field tests and experiments. Qualifications You meet our minimum requirements for the job if you... Possess a Bachelor’s degree in Software Engineering, Computer Science, or a related technical field, such as Robotics, Physics, or Mathematics. Have 5+ years of relevant software development expertise. Have 3+ years of experience applying and developing machine-learning algorithms, particularly in the areas of imitation and reinforcement learning. Have demonstrated full-lifecycle software development experience in either C++, Python, or Java. Are passionate about software design, software engineering, and developing groundbreaking tools for autonomous platforms. Possess strong organization and planning skills, with record of accomplishment in a team environment. Have excellent interpersonal skills and outstanding written and oral communications skills. Are able to work within the government infrastructure and address leadership roles in a diverse environment of contractors, government, and user staff. Are able to obtain an interim Secret level security clearance by you start date and can ultimately obtain a final Secret level clearance. If selected, you will be subject to a government security clearance investigation and must meet the requirements for access to Secret classified information. Eligibility requirements include U.S citizenship. You'll go above and beyond our minimum requirements if you... Have a Master of Science in Machine Learning, Artificial Intelligence, Computer Science, or a related technical field. Have significant experience in developing machine-learning-based test and evaluation software. Have significant experience developing and integrating autonomous maritime systems. Hold an active Secret security clearance. Why work at APL? The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation's most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates. At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL's campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers. About Us APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law. APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.",
        "url": "https://www.linkedin.com/jobs/view/3882223287",
        "summary": "The Johns Hopkins University Applied Physics Laboratory (APL) is seeking a Machine Learning Engineer to join their Ocean Systems and Engineering Group. This role will involve developing innovative testing solutions for autonomous systems, including building machine-learning-based test tools to ensure the safety and performance of autonomous platforms. The engineer will leverage and advance machine-learning approaches, apply data science and statistics to verify autonomous decisions, and develop full-lifecycle testing software. They will also design, develop, and configure simulation environments for testing autonomy algorithms, plan and analyze field tests, and work closely with multidisciplinary teams in an agile software environment.",
        "industries": [
            "Defense",
            "Aerospace",
            "Engineering",
            "Software Development",
            "Machine Learning",
            "Autonomous Systems",
            "Robotics",
            "Data Science"
        ],
        "soft_skills": [
            "Passionate",
            "Motivated",
            "Collaborative",
            "Agile",
            "Strong organization and planning skills",
            "Excellent interpersonal skills",
            "Outstanding written and oral communications skills",
            "Ability to work within government infrastructure",
            "Leadership skills",
            "Ability to work in diverse environments"
        ],
        "hard_skills": [
            "Machine Learning",
            "Imitation Learning",
            "Reinforcement Learning",
            "Data Science",
            "Statistics",
            "Software Development",
            "C++",
            "Python",
            "Java",
            "Agile Software Development",
            "Simulation",
            "Field Testing",
            "Documentation",
            "Technical Reviews",
            "Design",
            "Development",
            "Configuration",
            "Testing",
            "Evaluation",
            "Autonomy Algorithms",
            "Planning",
            "Analysis",
            "Field Tests",
            "Experiments"
        ],
        "tech_stack": [
            "Machine Learning",
            "C++",
            "Python",
            "Java",
            "Agile Software Development",
            "Simulation"
        ],
        "programming_languages": [
            "C++",
            "Python",
            "Java"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Software Engineering",
                "Computer Science",
                "Robotics",
                "Physics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Generous benefits",
            "Robust education assistance program",
            "Unparalleled retirement contributions",
            "Healthy work/life balance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3958009285,
        "company": "Dynamis, Inc.",
        "title": "Junior Applications Software Programmer",
        "created_on": 1720587250.2494528,
        "description": "Dynamis is looking for an experienced Junior Applications Software Programmer/Junior Engineer to support a data analytics contract in support of a US government client's mission. In this role the ideal candidate will develop information systems by studying operations; designing, developing, and installing software solutions that promote the client's data management mission. Requirements: Bachelor of Arts or Bachelor of Science (BA/BS) degree required in Computer Science, Statistics, Data Analytics, Data Science, Information Management, Engineering, or a closely related field. Ability to pass a National Agency Check with Inquiries (NACI) background investigation to obtain public trust clearance or higher. At least three years of data analytics and programming-related experience or relevant/similar experience which includes experience/knowledge/skills/abilities with all the following: Practical experience in at least two programming applications software packages (e.g., Java, C/C++, .NET, WebLogic, HTML, ServiceNow, SharePoint, Power Apps, etc.), preferably including knowledge of relational database design, the ability to read and understand data dictionaries, data coding, and the ability to infer the relationship of the tables to the application and the process. Has an initial level of understanding about maintaining and complying with requirements for the following task areas: collecting, compiling, processing, normalizing, analyzing and interpreting data using systems support tools such as SQL, Python, Oracle, Tableau, Power BI on Microsoft Azure, Quicksight on Amazon Web Services, Access, and Excel. Has experience with documenting and reviewing data sharing agreements, outstanding customer service and communication skills relaying technical concepts. Has experience with managing data quality, cleansing, tagging and metadata management. Has experience with testing and implementing application software with regards to collecting, processing, and storing data. Has experience with project management tools such as MS Project.",
        "url": "https://www.linkedin.com/jobs/view/3958009285",
        "summary": "Dynamis is seeking a Junior Applications Software Programmer/Junior Engineer to support a government client's data analytics mission. The role involves developing information systems, designing software solutions, and promoting data management. Responsibilities include data collection, processing, analysis, interpretation, and system support using tools like SQL, Python, Oracle, Tableau, Power BI, Quicksight, Access, and Excel. The candidate must have experience with data sharing agreements, data quality management, and project management tools like MS Project.",
        "industries": [
            "Government",
            "Data Analytics",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Customer Service",
            "Documentation",
            "Problem Solving"
        ],
        "hard_skills": [
            "Java",
            "C/C++",
            ".NET",
            "WebLogic",
            "HTML",
            "ServiceNow",
            "SharePoint",
            "Power Apps",
            "Relational Database Design",
            "SQL",
            "Python",
            "Oracle",
            "Tableau",
            "Power BI",
            "Quicksight",
            "Access",
            "Excel",
            "MS Project"
        ],
        "tech_stack": [
            "Java",
            "C/C++",
            ".NET",
            "WebLogic",
            "HTML",
            "ServiceNow",
            "SharePoint",
            "Power Apps",
            "SQL",
            "Python",
            "Oracle",
            "Tableau",
            "Power BI",
            "Quicksight",
            "Access",
            "Excel",
            "MS Project"
        ],
        "programming_languages": [
            "Java",
            "C/C++",
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Statistics",
                "Data Analytics",
                "Data Science",
                "Information Management",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Columbia, MD",
        "job_id": 3941197888,
        "company": "Visionist, Inc.",
        "title": "Junior Software Engineer",
        "created_on": 1720587251.9207242,
        "description": "Active Top Secret (TS/SCI) Clearance With Polygraph Is Required. Visionist has an exciting new, fully FUNDED opportunity for a Data Ingestion and Transformation Engineer on our largest PRIME contract. Our team of Analysts and Engineers is motivated by the direct impact on the mission, crafting specialized tools for enhanced efficiency and quick iterations for our operations user base. Seeing your tools in real-time action brings immediate gratification. This premier program encompasses traditional software services including Systems Design and Engineering, Database Administration, Data Science and Knowledge Management, Enterprise Risk Management, Integration and Test, as well as Operations and Systems Support. The program is characterized by innovation and excitement, fostering meaningful engagements, and offering distinctive collaboration opportunities with users, policy makers, and mission leadership, all while maintaining a service mindset. If you thrive in a collaborative work environment and enjoy utilizing a diverse tech stack, then this opportunity is tailor-made for you! For over 13 years, Visionist has been solving the Intelligence Community's toughest software and analysis challenges. We embed small engineering teams with analysts to rapidly identify and solve mission capability gaps playing a critical role in defending our nation’s cyber infrastructure & providing expertise in malware analysis, attribution, mapping adversarial infrastructure, pen testing, and operational planning. If you'd like to join a collaborative group supporting mission critical tasking in a cleared environment, then Visionist is the place for you. Learn more about us at www.visionistinc.com. Benefits of becoming a Visionist: We are a 100% employee-owned company, so our employees see the benefit of their contributions and have a stake in our overall success! 10% ESOP contribution + 5% 401K match + 8% employee 401K contribution = 23% combined annual contributions 4 weeks paid time off that is never “use or lose”, 12 paid holidays, comp time, AND flexible work hours And MORE… Your new career - Visionist, Inc. (visionistinc.com) Your contributions are… Develop and maintain scripts, tools, and applications to access and retrieve raw data from various sources Design and implement robust data structures and algorithms to organize and store extracted data effectively Apply advanced techniques such as data parsing, cleansing, and normalization to ensure data quality and consistency Identify and fix inefficiencies in the codebase, optimizing performance and resource utilization Troubleshoot and debug data-related issues, proposing and implementing scalable solutions Document data processing workflows, best practices, and technical specifications for knowledge sharing and maintainability Requirements For Your New Career… Bachelor's degree in a technical discipline. (Additional 4 years of experience may substitute degree) 3 years of experience in data engineering Experience in data manipulation, transformation, and extraction techniques Understanding of data structures, algorithms, and software design principles Familiarity with database systems (e.g., SQL, NoSQL) and data storage technologies Experience with version control systems (e.g., Git) and collaborative development workflows Experience with Python Not a good fit? Check out our other opportunities: https://jobs.jobvite.com/visionist Next steps: Apply online and one of our recruiters will reach out to you. We have a streamlined process of phone screen with a recruiter, interview with a Visionist team at our HQ in Columbia, MD, and that is all! Interested in learning more about Visionist and the work we do? Check out our website! https://www.visionistinc.com/what-we-do U.S citizenship required (green card holders and permanent residents are not eligible). Applicants selected will be required to obtain / maintain a government security clearance. Visionist, Inc. is an Equal Opportunity / Affirmative Action / Protected Veterans / Individuals with Disabilities employer.",
        "url": "https://www.linkedin.com/jobs/view/3941197888",
        "summary": "Visionist seeks a Data Ingestion and Transformation Engineer to work on a large, fully funded government contract. This role focuses on developing and maintaining scripts, tools, and applications to access, retrieve, and process raw data from various sources, ensuring data quality and consistency. The candidate will work on a team with analysts, designing and implementing data structures and algorithms for efficient data storage.  This position requires strong experience in data engineering, data manipulation, transformation, and extraction techniques. Familiarity with SQL, NoSQL databases, data storage technologies, and version control systems (e.g., Git) is essential. Experience with Python is also required.  ",
        "industries": [
            "Cybersecurity",
            "Intelligence",
            "Government",
            "Defense",
            "Software Engineering",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Skills",
            "Technical Skills",
            "Troubleshooting",
            "Time Management"
        ],
        "hard_skills": [
            "Data Ingestion",
            "Data Transformation",
            "Data Extraction",
            "Data Manipulation",
            "Data Structures",
            "Algorithms",
            "Software Design",
            "SQL",
            "NoSQL",
            "Data Storage Technologies",
            "Version Control Systems",
            "Git",
            "Python"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "NoSQL",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Technical Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "ESOP",
            "401K match",
            "4 weeks paid time off",
            "12 paid holidays",
            "Comp time",
            "Flexible work hours"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3910598403,
        "company": "ClearanceJobs",
        "title": "Data Scientist - 200k + 15% 401k with Security Clearance",
        "created_on": 1720587258.3010497,
        "description": "Title: Data Scientist (TS/SCI with Poly) Location: Chantilly, VA Base Salary: $100,000.00 - $200,000.00 per year 15% Employer 401k contribution (Regardless of Employee Contribution) PTO: 30 days annual total Stock Option $3000 annual training budget Medical/Dental/Vision: company funded, cash incentives if you waive Flexible work schedule Referral bonuses Paid Paternal and Maternal Leave Job Description Clearance Level Must Currently Possess: Top Secret SCI + Polygraph Millennial Software is looking for a self-starting, team-oriented Data Scientist to join our dynamic team in supporting a Government customer. The team requires data analysis support to address complex business and intelligence questions at an enterprise level and translate complex, technical findings into an easily understood narrative. REQUIRED SKILLS AND DEMONSTRATED EXPERIENCE The candidate shall have the following required skills, certifications and demonstrated experience: Experience in two or more of the following disciplines: business analytics, statistics, data verification and validation, and data visualization. Demonstrated experience applying qualitative and quantitative data analysis methods to business analytics problems. Demonstrated experience creating data visualization mockups, prototypes of visualizations, documenting work processes and effectively demonstrating products to technical and non-technical audiences. Demonstrated experience interpreting data models and working with a variety of data sources and structures. Demonstrated experience translating customer requirements into project or system specifications. Demonstrated Experience With Strong Interpersonal And Communications Skills. Demonstrated experience as a self-starter with the ability to decomposing ambiguous problems into actionable plans. Demonstrated experience using Tableau, Power BI, or similar interactive data visualization software. Demonstrated experience transforming, manipulating, and combining data using a programming language such as Python. Demonstrated experience using a data preparation tool such as Tableau Prep Builder. Demonstrated experience using Excel and SQL. Highly Desired Skills And Demonstrated Experience Skills and demonstrated experiences that are highly desired but not required to perform the work include: Demonstrated experience with data derived from technical missions, taskings, collection, processing, analysis, or dissemination. Demonstrated experience working with Sponsor business or mission data, Sponsor applications, or Sponsor database structures. Demonstrated experience with the Sponsor's data handling procedures. Demonstrated experience with visualization tools such as Jupyter, Visio, Sharepoint, or Confluence. Demonstrated experience with APIs. Demonstrated experience using GitHub or similar version control systems. Demonstrated experience using Python or R. Bachelor's Degree in a Business analytics, Statistics, Data Analytics, Computer Science, or Information Systems or 4 years of relevant data analysis experience with the IC or military may substitute in lieu of degree).",
        "url": "https://www.linkedin.com/jobs/view/3910598403",
        "summary": "Millennial Software is searching for a self-motivated Data Scientist to join their team in Chantilly, VA. This role requires data analysis expertise to address business and intelligence challenges for a government customer. The ideal candidate will have experience in areas like business analytics, statistics, data verification, and data visualization, along with demonstrated skills in creating visualizations, interpreting data models, and translating customer needs into project specifications. Strong communication and problem-solving abilities are essential.",
        "industries": [
            "Government",
            "Intelligence",
            "Data Analysis",
            "Software"
        ],
        "soft_skills": [
            "Self-starter",
            "Team-oriented",
            "Strong communication",
            "Problem-solving",
            "Analytical",
            "Detail-oriented",
            "Collaboration"
        ],
        "hard_skills": [
            "Business analytics",
            "Statistics",
            "Data verification",
            "Data visualization",
            "Qualitative and quantitative data analysis",
            "Data visualization mockups",
            "Prototyping",
            "Documentation",
            "Data modeling",
            "Data sources",
            "Data structures",
            "Customer requirements translation",
            "Tableau",
            "Power BI",
            "Python",
            "Tableau Prep Builder",
            "Excel",
            "SQL",
            "Jupyter",
            "Visio",
            "Sharepoint",
            "Confluence",
            "APIs",
            "GitHub",
            "R"
        ],
        "tech_stack": [
            "Tableau",
            "Power BI",
            "Python",
            "Tableau Prep Builder",
            "Excel",
            "SQL",
            "Jupyter",
            "Visio",
            "Sharepoint",
            "Confluence",
            "GitHub"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Business Analytics",
                "Statistics",
                "Data Analytics",
                "Computer Science",
                "Information Systems"
            ]
        },
        "salary": {
            "max": 200000,
            "min": 100000
        },
        "benefits": [
            "401k",
            "PTO",
            "Stock Options",
            "Training Budget",
            "Medical/Dental/Vision",
            "Flexible Work Schedule",
            "Referral Bonuses",
            "Paid Paternal and Maternal Leave"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3621828975,
        "company": "LMI",
        "title": "Senior Data Scientist - Clearance Required",
        "created_on": 1720587261.296062,
        "description": "Overview LMI is seeking a skilled Data Scientist at our headquarters office in Tysons, VA. Successful Data Scientists demonstrate competency in data analysis, data visualization, statistics, programming, project execution, and critical thinking. LMI is a consultancy dedicated to powering a future-ready, high-performing government, drawing from expertise in digital and analytic solutions, logistics, and management advisory services. We deliver integrated capabilities that incorporate emerging technologies and are tailored to customers’ unique mission needs, backed by objective research and data analysis. Founded in 1961 to help the Department of Defense resolve complex logistics management challenges, LMI continues to enable growth and transformation, enhance operational readiness and resiliency, and ensure mission success for federal civilian and defense agencies. Responsibilities This data scientist will work as part of a team of experienced data scientists, data engineers, and data analysts to support advanced analytics projects for the Chief Digital and Artificial Intelligence Office (CDAO) of the Department of Defense. Responsibilities include: Demonstrate the ability to frame and scale data problems to effectively analyze, visualize and find data solutions. Support data analysts and data engineers with the development of robust, scalable data pipelines using big data technologies such as Spark. Develop scalable heuristic-based and machine learning-based approaches to entity resolution across complex datasets. Support the deployment of the entity resolution algorithms into a production pipeline. Support the evaluation, maintenance, and retraining of the entity resolution algorithms in production over time. Identify, propose, and assist in the development of future analytics products based on the data pipeline to assist customers in gaining value from the data products. Assist the development of junior data scientists through technical mentoring, code review, and other assistance. The data scientist will need the ability to work in teams and independently. Required Qualifications Bachelor’s degree in data science, mathematics, statistics, economics, computer science, engineering, or other related business or quantitative discipline is required. Experience working with Python. Experience with data science methods related to data architecture, data munging, data and feature engineering, and predictive analytics. Superior communication skills, both oral and written Active DoD security clearance at the Top Secret level. Desired Skills Master’s degree or higher. Working knowledge of Spark or PySpark Experience with Databricks, Qlik, and the Advana analytics platform Experience with entity resolution algorithms Experience with deploying and maintaining models in production Experience scaling models and algorithms to large datasets Previous DOD experience. Previous experience working with supply chain or maintenance data or processes.",
        "url": "https://www.linkedin.com/jobs/view/3621828975",
        "summary": "LMI is seeking a skilled Data Scientist to work on advanced analytics projects for the Chief Digital and Artificial Intelligence Office (CDAO) of the Department of Defense. This role involves data analysis, visualization, machine learning, entity resolution, and supporting the development of data pipelines using big data technologies like Spark.",
        "industries": [
            "Government",
            "Defense",
            "Consultancy",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Critical Thinking",
            "Teamwork",
            "Independent Work",
            "Mentoring"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Visualization",
            "Statistics",
            "Programming",
            "Python",
            "Spark",
            "PySpark",
            "Data Architecture",
            "Data Munging",
            "Data Engineering",
            "Feature Engineering",
            "Predictive Analytics",
            "Entity Resolution",
            "Model Deployment",
            "Model Maintenance",
            "Model Scaling",
            "Supply Chain",
            "Maintenance"
        ],
        "tech_stack": [
            "Spark",
            "PySpark",
            "Databricks",
            "Qlik",
            "Advana",
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Mathematics",
                "Statistics",
                "Economics",
                "Computer Science",
                "Engineering",
                "Business",
                "Quantitative Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3955421661,
        "company": "Themis Insight, LLC",
        "title": "Sr. Data Scientist",
        "created_on": 1720587262.7410207,
        "description": "Themis Insight solves difficult business, IT, and analytic problems by addressing the whole problem – not just the symptoms – using interdisciplinary approaches that are both practical and innovative. We provide fresh alternatives to ordinary, mainstream consulting firms through small, highly skilled, and hand-picked teams that can meet clients' needs in any industry. Our broad interdisciplinary understanding allows us to provide the right solution, even if it is from outside the industry or traditionally defined problem space. We bring Public and Private, Civilian and Military expertise to every case. We are hiring a Sr. Data Scientist to work in Fort Meade, MD. Position location is subject to change based on central MD client's needs. Required: TS/SCI with a Polygraph Employ some combination (2 or more) of the following skill areas: Foundations: Mathematical, Computational, Statistical Data Processing: Data management and curation, data description and visualization, workflow and reproducibility Modeling, Inference, and Prediction: Data modeling and assessment, domain-specific considerations Devise strategies for extracting meaning and value from large datasets. Make and communicate principled conclusions from data using elements of mathematics, statistics, computer science, and application specific knowledge. Through analytic modeling, statistical analysis, programming, and/or another appropriate scientific method, develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets in various states of organization, cleanliness, and structure that account for the unique features and limitations inherent in NSA/CSS data holdings. Translate practical mission needs and analytic questions related to large datasets into technical requirements and, conversely, assist others with drawing appropriate conclusions from the analysis of such data. Effectively communicate complex technical information to non-technical audiences. Make informed recommendations regarding competing technical solutions by maintaining awareness of the constantly-shifting NSA/CSS collection, processing, storage and analytic capabilities and limitations. Individual Capabilities/Experience Required A Bachelor’s degree and 10 years of relevant experience. An Associate’s degree plus 12 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, social, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 300 level or higher; such as linear algebra, probability and statistics, machine learning) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university. Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g. Python) and skill in at least one mid-level language (e.g. C)), data mining, advanced statistical analysis (e.g. statistical foundations of machine learning, statistical approaches to missing data, time series), advanced mathematical foundations (e.g. numerical methods, graph theory), artificial intelligence, workflow and reproducibility, data management and curation, data modeling and assessment (e.g. model selection, evaluation, and sensitivity analysis), experience as a data scientist working to support a single or multiple domain areas, and/or software engineering. Experience in more than three areas is strongly preferred. Themis Insight has all the PERKS! You are our most valuable resource — your ambition, your knowledge, your creativity. We offer an industry-leading set of benefits to supplement your normal salary compensation. Themis Insight has you covered with flexible ways to balance work and home life, full health benefit premium coverage, and generous contributions toward your retirement. Competitive health, dental, and vision plans with 100% paid premiums. 401k: We contribute 6% even if you don't! Time Off: 11 standard holidays, and 25 days of PTO Career Development: Get career counseling and individualized career development plans, including education and training. Employee referral bonuses for successful hires Themis Insight is an Equal Opportunity/Affirmative Action employer. Themis Insight provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",
        "url": "https://www.linkedin.com/jobs/view/3955421661",
        "summary": "Themis Insight, a consulting firm specializing in solving complex business, IT, and analytic challenges, is seeking a Senior Data Scientist with a TS/SCI clearance and polygraph.  The role requires a strong background in mathematics, statistics, computer science, and data processing, with experience in machine learning, data mining, and advanced statistical analysis. The position offers competitive benefits including full health insurance coverage, 401k with employer contributions, generous PTO, and career development opportunities.  The ideal candidate will possess expertise in high-level programming languages like Python and mid-level languages like C. The position is located in Fort Meade, MD, with potential for relocation based on client needs.",
        "industries": [
            "Consulting",
            "Data Science",
            "Analytics",
            "IT",
            "Intelligence",
            "Defense",
            "Security"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Analytical Thinking",
            "Teamwork",
            "Collaboration",
            "Leadership",
            "Adaptability",
            "Creativity",
            "Strategic Thinking",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Data Mining",
            "Statistical Analysis",
            "Python",
            "C",
            "Data Management",
            "Data Curation",
            "Data Visualization",
            "Workflow and Reproducibility",
            "Model Selection",
            "Model Evaluation",
            "Sensitivity Analysis",
            "Artificial Intelligence",
            "Numerical Methods",
            "Graph Theory",
            "Data Modeling",
            "Data Assessment",
            "Software Engineering"
        ],
        "tech_stack": [
            "Python",
            "C",
            "Machine Learning",
            "Data Mining",
            "Statistical Analysis",
            "Artificial Intelligence",
            "Data Modeling",
            "Data Management",
            "Data Curation",
            "Data Visualization"
        ],
        "programming_languages": [
            "Python",
            "C"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Mathematics",
                "Applied Mathematics",
                "Statistics",
                "Applied Statistics",
                "Machine Learning",
                "Data Science",
                "Operations Research",
                "Computer Science",
                "Computer Information Systems",
                "Engineering",
                "Physics",
                "Chemistry",
                "Biology",
                "Social Sciences",
                "Life Sciences"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive health, dental, and vision plans with 100% paid premiums",
            "401k with 6% employer contribution",
            "25 days PTO",
            "11 standard holidays",
            "Career counseling and individualized career development plans",
            "Education and training",
            "Employee referral bonuses"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3905109093,
        "company": "GCI Incorporated",
        "title": "Data Scientist - AI/ML Senior Engineer (TS/SCI with Poly Required)",
        "created_on": 1720587264.2157404,
        "description": "GCI embodies excellence, integrity, and professionalism. The employees supporting our customers deliver unique, high-value mission solutions while effectively leveraging the technological expertise of our valued workforce to meet critical mission requirements in the areas of Data Analytics and Software Development, Engineering, Targeting and Analysis, Operations, Training, and Cyber Operations. We maximize opportunities for success by building and maintaining trusted and reliable partnerships with our customers and industry. At GCI, we solve the hard problems. As a Data Scientist, a typical day will include the following duties: Job Description The Data Scientist will be a member of a small team tasked with initiating an AI/ML initiative for the customer. The ideal Data Scientist will have a background in AI/ML Engineer that can develop algorithms, write scripts, build predictive analytics, use automation, apply machine learning, and use the right combination of tools and frameworks to turn a set of data points into objective answers to help senior leadership make informed decisions. The Data Scientist will apply data mining techniques perform statistical analysis, and build high-quality prediction models. The Data Scientist’s ability to obtain data through advanced computerized models and extrapolation of data patterns through advanced algorithms to explain how the information will influence the specific project will be an essential function to providing customers a better comprehension of the data. This candidate will work closely with customer management, other project managers, system architects, data scientists, data engineers, and machine learning engineers to formulate recommendations for enhancements and improvements geared towards utilizing innovative engineering solutions. Required Knowledge/Skills BS/BA in Software Engineering, Science, Mathematics, or similar OR equivalent combination of education and experience Familiarization with Large Language Model (LLM) architectures and training procedures Experience with search architecture tools (ex - Solr, ElasticSearch) Big Data Frameworks such as Spark or Hadoop Data Science frameworks such as Keras, Tensorflow, or Theano Experience with building querying ontologies such as Zeno, OWL, RDF, SparQL Experience with GPU processing Experience with word2vec or doc2vec algorithms Proficient in Java and Python Must know to use an IDE to code (ex – Visual Studio Code, IntelliJ, Eclipse, NetBeans) Experience with interacting in a Linux environment (ex - Bash scripting, VI) Intrapersonal communication skills Ability to work well in a constantly evolving work environment Desired Knowledge/Skills Familiarity with Source code management and integration (ex - GitHub/GitLab, Jenkins) Hands on experience with cloud technology (AWS / C2S) Experience in an Agile environment Experience with testing frameworks (ex - Junit, Mockito, Swagger, Postman) Experience with relational databases (ex - Oracle / MySql) Experience with JavaScript / Typescript Experience with front end development (ex - Angular 2+, React, HTML, CSS, JQuery) KEY RESPONSIBILITES Develop and train Large Language Models (LLMs) in support of the customer mission Investigate business area processes for creative implementation of LLMs Apply data mining techniques to perform statistical analysis Assists with technical planning activities, including roadmap development and systems integration. Collaborates with a variety of customers and contractors on a regular basis, which may include technical consultation, meeting coordination and support (e.g., TEMs), and preparation/support of technical briefings. Participates in the development of technical project plans, reports, and contract (e.g., PMR) briefings. The ideal candidate will work closely with data scientists, analysts, and customer stakeholders to create and deploy new product features. The AI/ML Engineer will establish scalable, efficient, automated processes for data analyses, model development, validation and implementation.",
        "url": "https://www.linkedin.com/jobs/view/3905109093",
        "summary": "GCI seeks a Data Scientist to join their AI/ML initiative. The ideal candidate will have experience in AI/ML Engineering, developing algorithms, building predictive analytics, and using machine learning frameworks. They will be responsible for applying data mining techniques, statistical analysis, and building prediction models. This role requires strong communication skills and the ability to work in a fast-paced environment.",
        "industries": [
            "Data Analytics",
            "Software Development",
            "Engineering",
            "Targeting and Analysis",
            "Operations",
            "Training",
            "Cyber Operations"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Teamwork",
            "Adaptability",
            "Self-motivation"
        ],
        "hard_skills": [
            "AI/ML",
            "Algorithm Development",
            "Predictive Analytics",
            "Machine Learning",
            "Data Mining",
            "Statistical Analysis",
            "Prediction Modeling",
            "Data Visualization",
            "Data Extraction",
            "Data Interpretation",
            "Data Analysis",
            "Data Engineering",
            "Machine Learning Engineering",
            "Software Engineering",
            "Large Language Models (LLMs)",
            "Search Architecture",
            "Big Data Frameworks",
            "Data Science Frameworks",
            "Ontology Building",
            "GPU Processing",
            "Word2vec/Doc2vec",
            "Java",
            "Python",
            "Bash Scripting",
            "Linux",
            "IDE (Visual Studio Code, IntelliJ, Eclipse, NetBeans)",
            "Source Code Management",
            "Cloud Technology (AWS/C2S)",
            "Agile Development",
            "Testing Frameworks",
            "Relational Databases",
            "JavaScript/TypeScript",
            "Front End Development"
        ],
        "tech_stack": [
            "AI/ML",
            "LLMs",
            "Solr",
            "ElasticSearch",
            "Spark",
            "Hadoop",
            "Keras",
            "Tensorflow",
            "Theano",
            "Zeno",
            "OWL",
            "RDF",
            "SparQL",
            "Java",
            "Python",
            "Visual Studio Code",
            "IntelliJ",
            "Eclipse",
            "NetBeans",
            "Bash",
            "VI",
            "GitHub",
            "GitLab",
            "Jenkins",
            "AWS",
            "C2S",
            "Junit",
            "Mockito",
            "Swagger",
            "Postman",
            "Oracle",
            "MySql",
            "Angular",
            "React",
            "HTML",
            "CSS",
            "JQuery"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "JavaScript",
            "TypeScript",
            "Bash"
        ],
        "experience": 0,
        "education": {
            "min_degree": "BS/BA",
            "fields": [
                "Software Engineering",
                "Science",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3969088704,
        "company": "Avint",
        "title": "Splunk Engineer",
        "created_on": 1720587266.1363227,
        "description": "Avint LLC is seeking a motivated, career, and customer oriented Splunk Engineer to join our growing team. This individual will manage and operate the organization's Splunk environment. This individual must be able to interact with Senior leadership and present findings and possible solutions where needed. This individual must also be a self-starter, gathering requirements while also providing solutions where needed. This individual must also be able to relay information to technical and non-technical contributors. Position Responsibilities: Operation of the Splunk Environment Troubleshooting new and current data collection issues Troubleshooting system issues that make the system unstable or unusable Deploying and managing commercial and custom Splunk add-ons required to fetch data from specific sources Designing, developing, and implementing data models while aggregating several data sources Implementing Splunk upgrades Extracting specific data attributes via regular expressions and transformations Creating custom dashboards, writing queries, and generating on-demand and saved search reports, and setting up alerts and notifications Integrating Splunk with other systems via API or other similar methods Developing and implementing solutions to integrate data provided into Splunk Indexes Analyzing data in Splunk indexes to determine relevant queries to populate specialized reporting dashboards, and modify Splunk Enterprise Security default searches to remove irrelevant alerts Designing, building, testing, and maintaining scalable and stable technology solutions to meet mission systems monitoring goals Performing automation tasks through scripting and testing Excellent Leadership and team building skills Provide monitoring data for networks, servers, workstations and other devices reporting to Splunk Provide support for the full-engineering lifecycle, including analysis, requirements, design, development, implementation, testing, integration, and documentation Requirements US Citizenship Required Secret Clearance required BA/BS in Information Security or related IT field with 8+ years of relevant experience 8+ years of experience with deploying, configuring, and performing functional testing and data validation in a Splunk environment 3+ years of experience with Splunk performing systems administration, including performing installation, configuration, monitoring system performance and availability, upgrades, and troubleshooting 2+ years of experience with designing, implementing, configuring, operating, or testing IT systems or security infrastructure 2+ years of Python programming experience specific to a Splunk environment Extensive experience with configuring, monitoring, and troubleshooting Splunk Significant experience ingesting data from multiple sources into Splunk Required: Relevant Cybersecurity Certification (CISSP, CISA, CISM, Sec+) Splunk Certified Architect Certification Preferred Experience in automating Splunk Deployments within a Cloud Environment (AWS, GCP, or Azure) Demonstrate strong communication skills (oral and written) and the ability to work with both teammates and senior leadership; leads working sessions to solicit ideas and develop solutions Proactively lead teams in the execution of complex tasks with minimal direction and produces high quality results Serve as a Career Manager responsible for performance management and professional development Proficiency in Microsoft Office Suite of tools (Excel, Word, Teams, Outlook) Proficiency in Linux/Unix environments as well as Windows Proactively drives business growth within a specific market segment (DOD, FedCiv, Commercial) Palo Alto firewall logs Linux audit logs PostgreSQL logs AWS Cloudtrail Red Hat IdM logs Trend Micro logs Setting up Enterprise Security Firewall configuration changes Shell access to certain priority VMs Use of root credentials Benefits Joining Avint is a win-win proposition! You will feel the personal touch of a small business and receive BIG business benefits. From competitive salaries, full health, and generous PTO and Federal Holidays. Additionally, we encourage every Avint employee to further their professional development. To assist you in achieving your goals, we offer reimbursement for courses, exams, and tuition. Interested in a class, conference, program, or degree? Avint will invest in YOU and your professional development! Avint is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity and Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.",
        "url": "https://www.linkedin.com/jobs/view/3969088704",
        "summary": "Avint LLC is seeking a Splunk Engineer with 8+ years of experience managing and operating Splunk environments. The role involves troubleshooting data collection issues, deploying Splunk add-ons, designing data models, implementing upgrades, creating custom dashboards, integrating Splunk with other systems, analyzing data, automating tasks, and providing monitoring data for networks, servers, and workstations. The ideal candidate will have experience with Python programming in a Splunk environment, configuring Splunk Enterprise Security, and working with various logs like Palo Alto firewall logs, Linux audit logs, PostgreSQL logs, AWS Cloudtrail, Red Hat IdM logs, and Trend Micro logs. This position requires US citizenship and a Secret Clearance.",
        "industries": [
            "Information Technology",
            "Cybersecurity",
            "Software Development",
            "Consulting"
        ],
        "soft_skills": [
            "Motivated",
            "Career-Oriented",
            "Customer-Oriented",
            "Self-Starter",
            "Problem-Solving",
            "Communication",
            "Teamwork",
            "Leadership",
            "Proactive",
            "Analytical",
            "Detail-Oriented",
            "Organized",
            "Time Management",
            "Problem Solving",
            "Decision Making"
        ],
        "hard_skills": [
            "Splunk",
            "Splunk Enterprise Security",
            "Python",
            "Linux",
            "Unix",
            "Windows",
            "Data Modeling",
            "Data Collection",
            "Data Analysis",
            "Data Visualization",
            "Dashboarding",
            "Reporting",
            "Alerting",
            "Integration",
            "API",
            "Scripting",
            "Automation",
            "Troubleshooting",
            "Performance Tuning",
            "Security",
            "Networking",
            "Firewall",
            "Cloud",
            "AWS",
            "GCP",
            "Azure",
            "Palo Alto",
            "PostgreSQL",
            "Red Hat IdM",
            "Trend Micro",
            "Microsoft Office Suite",
            "Excel",
            "Word",
            "Teams",
            "Outlook"
        ],
        "tech_stack": [
            "Splunk",
            "Splunk Enterprise Security",
            "Python",
            "Linux",
            "Unix",
            "Windows",
            "AWS",
            "GCP",
            "Azure",
            "Palo Alto",
            "PostgreSQL",
            "Red Hat IdM",
            "Trend Micro",
            "Microsoft Office Suite"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": "BA/BS",
            "fields": [
                "Information Security",
                "IT"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Full Health Benefits",
            "Generous PTO",
            "Federal Holidays",
            "Professional Development Reimbursement",
            "Tuition Reimbursement",
            "Equal Opportunity Employer"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3943914586,
        "company": "Braintrust",
        "title": "Sr Machine Learning Engineer (Python/Go/Java)",
        "created_on": 1720587274.8158574,
        "description": "About Us Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality. About The Hiring Process The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match. Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies. JOB TYPE: Freelance, Contract Position (no agencies/C2C - see notes below) LOCATION: Work from anywhere - CST/CDT | full day overlap HOURLY RANGE Our client is looking to pay $100.00 – $125.00/hr ESTIMATED DURATION: 40/week - long term EXPERIENCE: 5-9 years BRAINTRUST JOB ID: 11857 The Opportunity This is a W2 engagement. The pay rate reflects the fact that this is a W2 engagement. What You'll Be Working On Our team manages the platform for AI ML teams in Expedia. The Feature lifecycle team specifically works on managing feature stores for the models. We provide low latency services for model inferencing use cases. Support regular feature refresh pipelines and data for batch inference and training use cases. We're looking for a Sr ML Engineer to join our team. Key Activities **Software Development:** Proficient in designing, coding, testing, and debugging software applications. **System Architecture:** Capable of contributing to the design and architecture of complex software systems. **Code Review and Optimization:** Skilled in reviewing code, providing constructive feedback, and optimizing for performance. **Collaborative Problem Solving:** Ability to work with cross-functional teams to address technical challenges. Key Requirements Ability to write robust code in one or more of Python, Go, and Java Proficient in core technologies like Spark, Hadoop and Hive. Experience in building real-time applications, preferably in Spark and streaming platforms like Kafka and Kinesis. Good understanding of machine learning pipelines and machine learning frameworks such as TensorFlow and PyTorch. (good to have) Familiar with cloud services like AWS, Azure, and workflow orchestration tools (e.g., Airflow). Degree with a strong technical focus (Computer Science, Engineering). Design, develop, debug, and modify components of machine learning and deep learning systems and applications, including data/ETL and feature engineering pipelines. Work collaboratively with data scientists, machine learning engineers, program and product managers in the development of assigned components. Actively participate in group technology reviews to critique work of self and others. Apply Now! Notes Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application. Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.",
        "url": "https://www.linkedin.com/jobs/view/3943914586",
        "summary": "Braintrust is seeking a Sr ML Engineer to work on the platform for AI ML teams at Expedia. This role involves managing feature stores for models, providing low latency services for model inferencing, and supporting regular feature refresh pipelines for batch inference and training. The ideal candidate will have 5-9 years of experience and be proficient in Python, Go, Java, Spark, Hadoop, Hive, Kafka, Kinesis, TensorFlow, PyTorch, AWS, Azure, and Airflow.",
        "industries": [
            "Technology",
            "Software Development",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Code Review",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "Go",
            "Java",
            "Spark",
            "Hadoop",
            "Hive",
            "Kafka",
            "Kinesis",
            "TensorFlow",
            "PyTorch",
            "AWS",
            "Azure",
            "Airflow"
        ],
        "tech_stack": [
            "Spark",
            "Hadoop",
            "Hive",
            "Kafka",
            "Kinesis",
            "TensorFlow",
            "PyTorch",
            "AWS",
            "Azure",
            "Airflow"
        ],
        "programming_languages": [
            "Python",
            "Go",
            "Java"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 125,
            "min": 100
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3910576452,
        "company": "ClearanceJobs",
        "title": "Junior Data Scientist (Secret Clearance Required) with Security Clearance",
        "created_on": 1720587276.2310474,
        "description": "Overview LMI is a consultancy dedicated to powering a future-ready, high-performing government, drawing from expertise in digital and analytic solutions, logistics, and management advisory services. We deliver integrated capabilities that incorporate emerging technologies and are tailored to customers' unique mission needs, backed by objective research and data analysis. Founded in 1961 to help the Department of Defense resolve complex logistics management challenges, LMI continues to enable growth and transformation, enhance operational readiness and resiliency, and ensure mission success for federal civilian and defense agencies. LMI was recently awarded the #1 spot on the Washington Post Top Workplaces list for 2021! This position is embedded within our Advanced Analytics & AI practice. Leverage your curiosity and problem-solving skills to explore, discover, and predict patterns contained within data sets for a wide range of government clients. This includes the derivation of clear narratives that help our clients understand their data and how those insights address their research questions. Responsibilities Frame and scale data problems to analyze, visualize, and find data solutions. Manipulate common data formats, including comma-delimited, text files, and JSON. Transform data and analysis into informative data visualizations and interactive dashboards using open-source and commercially available visualization and dashboard tools. Derive insights and analytic narratives from data and visualizations for effective storytelling and clear communication in response to research questions. Work in a fast-paced, solutions-oriented environment focused on client deliverables, analysis, and reporting. Qualifications Active DoD Secret clearance Bachelor's degree in data science, mathematics, statistics, economics, computer science, engineering, or a related business or quantitative discipline Experience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn) Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js to communicate findings and relate them back to how your insights create business impact Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections At least 1-4 years of experience in the field Superior communication skills, both oral and written Preferred experience in the following areas: DoD experience preferred Data science methods related to data architecture, data munging, data and feature engineering, and predictive analytics Unstructured text and natural language processing R, Python, SAS, or MATLAB Anaconda, IBM Blue, and Oracle Big Data to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations Developing machine learning, data mining, statistical network, natural language processing, text analytics, and graph-based algorithms to analyze massive data sets Supervising algorithm implementation in on-premise and cloud-based computing environments Developing software to generate reports and visualizations that summarize data sets and provide data-driven insights Developing and implementing statistical, machine learning, and heuristic techniques to create descriptive, predictive, and prescriptive analytics as well as to develop statistical tests to make data-driven recommendations and decisions EEO Statement LMI is an Equal Opportunity Employer-all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.",
        "url": "https://www.linkedin.com/jobs/view/3910576452",
        "summary": "LMI, a consultancy focused on government solutions, seeks a Data Scientist with DoD Secret clearance. The role involves data analysis, visualization, and storytelling for various government clients. Responsibilities include framing data problems, manipulating data formats, creating dashboards, and deriving insights from data. Experience with programming languages (Python, Java, R, MATLAB), visualization tools (Tableau, Qlik, Power BI, RShiny, plotly, d3.js), and databases/SQL is essential. Preferred qualifications include DoD experience, data science methods, unstructured text processing, and experience with large data sets using tools like Anaconda, IBM Blue, and Oracle Big Data. The position involves developing algorithms, implementing them in cloud environments, and generating reports/visualizations for data-driven insights.",
        "industries": [
            "Government",
            "Defense",
            "Consulting",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Storytelling"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Visualization",
            "Data Manipulation",
            "Dashboard Creation",
            "Data Storytelling",
            "Object-Oriented Programming",
            "Python",
            "Java",
            "R",
            "MATLAB",
            "Tableau",
            "Qlik",
            "Power BI",
            "RShiny",
            "plotly",
            "d3.js",
            "SQL",
            "Data Architecture",
            "Data Munging",
            "Data and Feature Engineering",
            "Predictive Analytics",
            "Unstructured Text Processing",
            "Natural Language Processing",
            "Machine Learning",
            "Data Mining",
            "Statistical Network Analysis",
            "Text Analytics",
            "Graph-Based Algorithms",
            "Cloud Computing",
            "Report Generation",
            "Visualization",
            "Statistical Techniques",
            "Heuristic Techniques",
            "Descriptive Analytics",
            "Predictive Analytics",
            "Prescriptive Analytics",
            "Statistical Testing"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "R",
            "MATLAB",
            "Tableau",
            "Qlik",
            "Power BI",
            "RShiny",
            "plotly",
            "d3.js",
            "SQL",
            "Anaconda",
            "IBM Blue",
            "Oracle Big Data"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "R",
            "MATLAB",
            "SQL"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Mathematics",
                "Statistics",
                "Economics",
                "Computer Science",
                "Engineering",
                "Business",
                "Quantitative Disciplines"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3643230487,
        "company": "Georgetown University",
        "title": "Research Scientist (part-time), Neuroscience Lab – Georgetown University Medical Canter",
        "created_on": 1720587280.4811027,
        "description": "Located in a historic neighborhood in the nation's capital, Georgetown offers rigorous academic programs, a global perspective, exciting ways to take advantage of Washington, D.C., and a commitment to social justice. Our community is a tight knit group of remarkable individuals interested in intellectual inquiry and making a difference in the world. Requirements Research Scientist (part-time), Neuroscience Lab – Georgetown University Medical Canter Neuroscience is a priority mission of the Georgetown University Medical Center, and Neuroscience Lab also provides help for electrophysiology studies for many research groups in the GUMC, as evidenced by numerous co-PI-led grant applications. The Neuroscience Lab hosts 2-3 thesis students and 1-2 master students annually. The Research Scientist keeps the Neuroscience Lab in good order and condition, directly affecting the quality of collaboration and student thesis. Reporting to the Principal Investigator, the Research Specialist’s duty performance allows the PI to devote time to research, grant applications and academia publications and. Reporting to Lab’s Principal Investigator, the Research Scientist must apply consistent and absolute attention to detail. Any small errors (e.g., a bit of detergent left on a bottle or an inaccurate weight of a reagent) may lead to a wrong conclusion of the experiment or waste days of time for the research project. Therefore, an appreciation for - and dedication to - performance excellence in all within the biology wet lab is paramount. Responsibilities Include But Are Not Limited To Experiments Assists the Principal Investigator in experiments Prepares ice and solutions Keeps track of breeding animal colonies Checks mice 1 to 2 times per week Laboratory Maintenance Washes glassware Orders chemicals and supplies Administration Copies data to the lab database Maintains the lab record Qualifications High school diploma Preferred Qualifications 5+ years of experience in biological/ molecular biology/neuroscience laboratories Experience of maintaining transgenic mouse colonies Work Mode: Hybrid. Please note that work mode designations are regularly reviewed in order to meet the evolving needs of the University. Such review may necessitate a change to a position’s mode of work designation. Complete details about Georgetown University’s mode of work designations for staff and AAP positions can be found on the Department of Human Resources Mode of Work Designation . We encourage applications from experienced or recently retired biology scientists. Pay Range The projected salary or hourly pay range for this position which represents the full range of anticipated compensation is: $17.41 - $26.03 Compensation is determined by a number of factors including, but not limited to, the candidate’s individual qualifications, experience, education, skills, and certifications, as well as the University’s business needs and external factors. Current Georgetown Employees If you currently work at Georgetown University, please exit this website and login to GMS (gms.georgetown.edu) using your Net ID and password. Then select the Career worklet on your GMS Home dashboard to view Jobs at Georgetown. Submission Guidelines Please note that in order to be considered an applicant for any position at Georgetown University you must submit a resume for each position of interest for which you believe you are qualified. Documents are not kept on file for future positions. Need Assistance If you are a qualified individual with a disability and need a reasonable accommodation for any part of the application and hiring process, please click here for more information, or contact the Office of Institutional Diversity, Equity, and Affirmative Action (IDEAA) at 202-687-4798 or ideaa@georgetown.edu. Need some assistance with the application process? Please call 202-687-2500. For more information about the suite of benefits, professional development and community involvement opportunities that make up Georgetown's commitment to its employees, please visit the Georgetown Works website. EEO Statement Georgetown University is an Equal Opportunity/Affirmative Action Employer fully dedicated to achieving a diverse faculty and staff. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, national origin, age, sex (including pregnancy, gender identity and expression, and sexual orientation), disability status, protected veteran status, or any other characteristic protected by law . Benefits Georgetown University offers a comprehensive and competitive benefit package that includes medical, dental, vision, disability and life insurance, retirement savings, tuition assistance, work-life balance benefits, employee discounts and an array of voluntary insurance options. You can learn more about benefits and eligibility on the Department of Human Resources website. Current Georgetown Employees If you currently work at Georgetown University, please exit this website and login to GMS https://gms.georgetown.edu/ using your Net ID and password. Then select the Career worklet on your GMS Home dashboard to view Jobs at Georgetown. Submission Guidelines Please note that in order to be considered an applicant for any position at Georgetown University you must submit a cover letter and resume for each position of interest for which you believe you are qualified. These documents are not kept on file for future positions. Need Assistance If you are a qualified individual with a disability and need a reasonable accommodation for any part of the application and hiring process, please click https://ideaa.georgetown.edu/ada for more information, or contact the Office of Institutional Diversity, Equity, and Affirmative Action (IDEAA) at 202-687-4798 or ideaa@georgetown.edu. Need some assistance with the application process? Please call 202-687-2500. For more information about the suite of benefits, professional development and community involvement opportunities that make up Georgetown's commitment to its employees, please visit the Georgetown Works website https://georgetownworks.georgetown.edu/ EEO Statement Georgetown University is an Equal Opportunity/Affirmative Action Employer fully dedicated to achieving a diverse faculty and staff. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, national origin, age, sex (including pregnancy, gender identity and expression, and sexual orientation), disability status, protected veteran status, or any other characteristic protected by law https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf",
        "url": "https://www.linkedin.com/jobs/view/3643230487",
        "summary": "Georgetown University Medical Center is seeking a part-time Research Scientist to work in their Neuroscience Lab. The ideal candidate will have 5+ years of experience in biological/molecular biology/neuroscience laboratories and experience maintaining transgenic mouse colonies. Responsibilities include assisting with experiments, preparing ice and solutions, keeping track of breeding animal colonies, checking mice, washing glassware, ordering chemicals and supplies, and maintaining lab records.",
        "industries": [
            "Higher Education",
            "Research",
            "Neuroscience",
            "Healthcare",
            "Biotechnology",
            "Medical"
        ],
        "soft_skills": [
            "Attention to Detail",
            "Organization",
            "Time Management",
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Critical Thinking",
            "Adaptability",
            "Teamwork",
            "Self-Motivation"
        ],
        "hard_skills": [
            "Biological Sciences",
            "Molecular Biology",
            "Neuroscience",
            "Lab Maintenance",
            "Animal Handling",
            "Data Entry",
            "Record Keeping",
            "Transgenic Mouse Colonies"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 5,
        "education": {
            "min_degree": "High School Diploma",
            "fields": [
                "Biology",
                "Neuroscience",
                "Molecular Biology"
            ]
        },
        "salary": {
            "max": 2603,
            "min": 1741
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Disability Insurance",
            "Life Insurance",
            "Retirement Savings",
            "Tuition Assistance",
            "Work-Life Balance Benefits",
            "Employee Discounts",
            "Voluntary Insurance Options"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Springfield, VA",
        "job_id": 3924291663,
        "company": "TENICA Global Solutions",
        "title": "Junior Software Developer TS/SCI CI poly",
        "created_on": 1720587281.9151764,
        "description": "TENICA is looking to hire a junior software developer. Job Location: Springfield, VA Work on a small team as a front-end developer, building a prototype user interface for analysts. The interface allows analysts to examine patterns in track data, and visualize the results. Required Skills: JavaScript Additional Skills: CSS, HTML, basic python, some DevOps Required Experience: 3-12 years plus BA, or several years of experience without BA.",
        "url": "https://www.linkedin.com/jobs/view/3924291663",
        "summary": "TENICA seeks a Junior Software Developer for a small team building a prototype user interface for analysts to examine patterns in track data and visualize results in Springfield, VA. The role involves front-end development with JavaScript, CSS, HTML, and some Python, and basic DevOps experience. 3-12 years experience plus BA or several years without BA is required.",
        "industries": [
            "Software Development",
            "Analytics",
            "Technology"
        ],
        "soft_skills": [],
        "hard_skills": [
            "JavaScript",
            "CSS",
            "HTML",
            "Python",
            "DevOps"
        ],
        "tech_stack": [
            "JavaScript",
            "CSS",
            "HTML",
            "Python"
        ],
        "programming_languages": [
            "JavaScript",
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "BA",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Vienna, VA",
        "job_id": 3934964819,
        "company": "Task Force Talent",
        "title": "Senior Data Scientist (U.S. Citizen/Security Clearance Required)",
        "created_on": 1720587283.4562466,
        "description": "Task Force Talent is seeking a senior Data Scientist with an active TS/SCI FSP security clearance to support a unique government contract. Our client for this role is a small company with both commercial and government sector customers. They work on very interesting, usually highly technical roles in cybersecurity, software development, data science, and related areas for well-known companies and government organizations. They have a high bar; however, they also have top compensation, benefits, and a strong company culture not found at larger firms. This is rewarding work that cannot be done elsewhere. The primary responsibility of this role is developing technical capabilities that can produce insights from large, complex data sets. Further details will be provided to qualified candidates after an initial interview. Target salary range is $180k - $205k , depending on experience level. All positions are full-time, in-office, usually in a SCIF. If you apply but this company is not a fit, we will consider you for other available positions as well. We have several clients seeking very similar skill sets. Not your dream job, but perfect for a friend? You can submit a referral and get a check for $2000 or more: https://www.taskforcetalent.com/referral/ (Terms and conditions apply.) _______________________________________________________________________________________________________________________________________________ Qualifications U.S. citizen with active TS/SCI FSP security clearance. (Sorry, we are unable to sponsor or upgrade clearances for this role.) 10+ years of relevant experience, including data modeling and visualization developing, managing, and exploiting various types of databases ETL assessing data quality and integrity building/maintaining CI/CD pipelines Experience with: Python, SQL, and NiFI AWS or Azure cloud Git/GitHub ____________________________________________________________________________________________________________________________________ Interview Process The process typically involves an initial phone screen followed by technical interviews. Contigent offers are usually made quickly, within a week or two. Depending on the level of experience and terms of the contract, additional interviews may be required with a prime contractor/partners or the end customer. _____________________________________________________________________________________________________________________________________ About Us Task Force Talent is a specialized recruiting firm for science, engineering, and security careers. Our clients include seed to Series B startups working on AI, cybersecurity, quantum computing, and other novel technologies. We also work with small to medium size government contractors, and we help leading venture capital firms find talent for their portfolio companies. We have hundreds of jobs available and consider all applicants for all roles, now and in the future. Our goal is to find the best fit for you! If you don't see the perfect fit, simply use our general application at: https://taskforcetalent.breezy.hr/p/5bbc3c44433e-single-application-for-all-jobs-general",
        "url": "https://www.linkedin.com/jobs/view/3934964819",
        "summary": "Task Force Talent is seeking a Senior Data Scientist with a TS/SCI FSP security clearance to work on a government contract for a small company with both commercial and government sector clients. The role involves developing technical capabilities to produce insights from large, complex data sets. The company offers top compensation, benefits, and a strong company culture.  The ideal candidate will have 10+ years of experience in data modeling and visualization, developing and managing databases, ETL, data quality assessment, CI/CD pipeline building, Python, SQL, NiFI, AWS or Azure cloud, and Git/GitHub.",
        "industries": [
            "Cybersecurity",
            "Software Development",
            "Data Science",
            "Government",
            "AI",
            "Quantum Computing"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical Thinking",
            "Communication",
            "Collaboration",
            "Teamwork"
        ],
        "hard_skills": [
            "Data Modeling",
            "Data Visualization",
            "Database Development",
            "Database Management",
            "ETL",
            "Data Quality Assessment",
            "CI/CD Pipeline Building",
            "Python",
            "SQL",
            "NiFI",
            "AWS",
            "Azure",
            "Git",
            "GitHub"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "NiFI",
            "AWS",
            "Azure",
            "Git",
            "GitHub"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 10,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 205000,
            "min": 180000
        },
        "benefits": [
            "Top compensation",
            "Benefits",
            "Strong company culture"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3931507382,
        "company": "SAIC",
        "title": "Data Scientist and Policy Lead",
        "created_on": 1720587284.9996562,
        "description": "Job ID 2406918 Location FORT MEADE, MD, US Date Posted 2024-05-20 Category Information Technology Subcategory Data Scientist Schedule Full-time Shift Day Job Travel Yes, 10 % of the Time Minimum Clearance Required Top Secret Clearance Level Must Be Able to Obtain TS/SCI Potential for Remote Work No Description SAIC has a new opportunity for a Data Scientist at Fort Meade, MD providing support to the Nuclear Command, Control, and Communications (NC3) Enterprise Center (NEC) Systems Engineering & Integration (SE&I) Division to support systems architecture, data analytics, data strategy, data architecture, requirements, implementation plans, and strategic planning for a digital engineering cloud environment. Duties Include Develop and document strategy and architecture to store, manipulate, and manage data in a digital engineering environment. Lead digital transformation in cloud environments. Work with customers and senior managers to establish strategic plans and objectives. Provide management oversight of cloud developers, cloud engineers, and database developers for the deployment and operations of a cloud environment across multiple enclaves. Qualifications Experience with data strategy, architecture, and data analytics. Experience drafting strategy and implementation plans. Experience with cloud environments and enterprise data implementation. Experience deploying cloud services and network enclaves. Bachelor’s and fourteen (14) years or more of related experience; master’s and twelve (12) years or more of related experience; PhD or JD and nine (9) years or more of related experience. Relevant years of experience in lieu of degree. Experience with Amazon Web Services (AWS) desired. US Citizen and Active TS clearance with the ability to obtain a TS/SCI clearance. SAIC accepts applications on an ongoing basis and there is no deadline. Covid Policy SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.",
        "url": "https://www.linkedin.com/jobs/view/3931507382",
        "summary": "SAIC is seeking a Data Scientist to work at Fort Meade, MD supporting the Nuclear Command, Control, and Communications (NC3) Enterprise Center (NEC) Systems Engineering & Integration (SE&I) Division.  This role involves developing data strategy and architecture for a digital engineering cloud environment, leading digital transformation, and overseeing cloud developers and engineers.  Experience with data strategy, architecture, cloud environments, and AWS is desired.",
        "industries": [
            "Information Technology",
            "Government",
            "Defense",
            "Aerospace & Defense",
            "Cloud Computing",
            "Cybersecurity",
            "Data Analytics",
            "Digital Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Leadership",
            "Strategic Planning",
            "Problem Solving",
            "Analytical Skills",
            "Teamwork"
        ],
        "hard_skills": [
            "Data Strategy",
            "Data Architecture",
            "Data Analytics",
            "Cloud Computing",
            "Cloud Environments",
            "Digital Transformation",
            "Enterprise Data Implementation",
            "Cloud Services",
            "Network Enclaves",
            "AWS (Amazon Web Services)"
        ],
        "tech_stack": [
            "AWS (Amazon Web Services)",
            "Cloud Computing",
            "Digital Engineering",
            "Cloud Services",
            "Network Enclaves"
        ],
        "programming_languages": [],
        "experience": 14,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Computer Science",
                "Information Technology",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3966422587,
        "company": "ClearanceJobs",
        "title": "2026473 Data Scientist $260,000.00 with Security Clearance",
        "created_on": 1720587286.5009093,
        "description": "Labor Category: Data Scientist Position Title: Data Scientist Position Level: Level 1 Subject Matter Expert Salary: Up to $260,000.00 per year Core Hours: 9am to 4pm Location: McLean VA Description: Position Requires a Top Secret (TS/SCI) Clearance with a Polygraph. Seeking a Targeting Analyst to apply and enhance their skills with developing, running, and analyzing results of complex queries against massive scale data stores. The candidate will also increase their skills with the following: Manipulating high-volume structured and unstructured data to perform analysis and generate reporting/products. Using analytic techniques and tools and All-Source data analysis to provide technical targeting analytic support to the Customer Agency. Performing large scale parallel processing of data, and developing, validating, and using methodologies to support analytic requirements in Clustered Computing environments. Details: Labor Category: Data Scientist Position Title: Data Scientist Position Level: Level 1 Subject Matter Expert Salary: Up to $260,000.00 per year Core Hours: 9am to 4pm Location: McLean VA Mandatory Requirements: Demonstrated experience with ECL and HPCC. Demonstrated experience using analytic techniques and tools performing technical targeting analytic support for the Customer. Demonstrated experience manipulating high-volume structured and unstructured data to perform analysis and generate reporting/products. Demonstrated experience using computer languages (e.g., Python, R, Pig, Java, C, SQL) to perform large scale parallel processing of data. Demonstrated experience performing large scale parallel processing of data, and developing, validating, and using methodologies to support analytic requirements in Clustered Computing environments. Optional Requirements: Educational or practical experience in a STEM (Science, Technology, Engineering or Mathematics) field. B4CORP Company Information B4Corp is a small defense contracting company that focuses on providing an optimum environment for mission-focused, highly skilled consultants to support the United States of America's intelligence community and other defense organizations. B4Corp provides a low overhead, highly efficient, high salary environment that allows employees to excel at meeting the client's needs. B4Corp is looking for information technology professionals that have a high sense of personal responsibility, self-motivation, and mission drive. B4Corp's dedication and care for its employees is reflected in our outstanding compensation and benefits package. B4Corp's benefits reflect the company's policy of putting the employees first. B4Corp's maximum flexibility comp / makeup time policy, along with the company's cafeteria-style benefit plan that allows employees to maximize their Benefit Dollars, reflects B4Corp's commitment to its employees. Compensation: Outstanding Salaries Retirement: Full Vanguard 401k Plan Featuring a full scope of investment options 100% employer matched contribution up to 6% of employee's salary Ability to max out 401k savings $57k ($63.5k if over 50) Employees receive B4Corp phantom stock each year (2-year vesting period) Insurance: Medical United Health Care (UHC) (multiple plan options) Dental United Concordia (UC) Flex Plan Vision Vision Service Plan Insurance Co (VSP) Signature Plans Mutual of Omaha short-term disability (60% of salary up to $2,000.00/week) Mutual of Omaha long-term disability (60% of salary up to $10,000.00/month) Mutual of Omaha life insurance ($200,000.00) Employee Referral Bonus: Refer a friend or a coworker and receive $3,000 per year for every year the person works for B4CORP Paid Time Off (PTO): Seven weeks of leave per year (including ten federal holidays) Flexible work schedule with comp time (with customer approval) Tuition and Training: Free CBTNuggets Online Training Account More than 200 online IT courses on a large variety of topics, including networking, security, virtualization, and the cloud Cisco, Microsoft, and Google Virtual Labs Free L inux Academy Online Training Account Internal Tracking -SV-413-DS If you would like to complete a detailed B4Corp Employment Application, please do so using this form (You only need to fill out this application once for B4Corp or if you have updates to the information.): https://b4corp.com/b4corp-employment-application/ . This form will help us find you the best position quicker. B4Corp is an EEO and e-Verify employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender/gender identity, sexual orientation or national origin. Please take the time to review and complete these three voluntary identification forms if you choose to do so and email them to",
        "url": "https://www.linkedin.com/jobs/view/3966422587",
        "summary": "Data Scientist role at B4Corp, a defense contracting company, supporting the US intelligence community. Requires a TS/SCI security clearance with polygraph. Responsibilities include developing, running, and analyzing complex queries against large datasets, manipulating structured and unstructured data for analysis and reporting, performing parallel processing, and developing methodologies for clustered computing environments.",
        "industries": [
            "Defense",
            "Intelligence",
            "Government Contracting",
            "Information Technology"
        ],
        "soft_skills": [
            "Analytical",
            "Problem-Solving",
            "Communication",
            "Teamwork",
            "Self-Motivation",
            "Mission-Driven"
        ],
        "hard_skills": [
            "ECL",
            "HPCC",
            "Python",
            "R",
            "Pig",
            "Java",
            "C",
            "SQL",
            "Data Analysis",
            "Technical Targeting",
            "Parallel Processing",
            "Clustered Computing",
            "All-Source Data Analysis",
            "Reporting",
            "Query Development"
        ],
        "tech_stack": [
            "HPCC",
            "ECL",
            "Python",
            "R",
            "Pig",
            "Java",
            "C",
            "SQL",
            "Clustered Computing"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Pig",
            "Java",
            "C",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "None",
            "fields": [
                "STEM"
            ]
        },
        "salary": {
            "max": 260000,
            "min": 0
        },
        "benefits": [
            "401k with Matching",
            "Phantom Stock",
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Short-Term Disability",
            "Long-Term Disability",
            "Life Insurance",
            "Employee Referral Bonus",
            "Paid Time Off",
            "Flexible Work Schedule",
            "Comp Time",
            "Free Online Training",
            "Tuition Reimbursement"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3955847777,
        "company": "VRK IT Vision Inc.",
        "title": "SDET",
        "created_on": 1720587287.991102,
        "description": "Job Description Creates an overall automation strategy for the application under test Supports the application team in their continuous delivery efforts Participates in code review meetings Support other testers and automation engineers in the approach design, script development, execution, and reporting. Analyzes and communicates test results and defect resolution tasks Stays up to date with industry trends and best practices in order to apply them to an existing project Influences stakeholders to adopt automation practices to help make the software development processes more efficient Mandatory 6+ years of proven experience and well versed in Java, Selenium, BDD & TDD, Cucumber, Gherkin and CI/CD tools Strong knowledge and proven experience in API automation, experience with REST assured or Karate; front-end and backend automation as well Strong knowledge in Databases like (DB2, Mongo DB or Snowflake) and experience in writing SQL queries Must have strong communication skills with ability to work with all management levels Good To Have Preferred experience in File handling in Java Good knowledge or experience in Cypress Preferably certified in AWS",
        "url": "https://www.linkedin.com/jobs/view/3955847777",
        "summary": "This role involves developing an automation strategy for software applications, supporting continuous delivery, participating in code reviews, and mentoring other testers and automation engineers. It requires expertise in Java, Selenium, BDD & TDD, Cucumber, Gherkin, and CI/CD tools, as well as experience in API automation (REST assured or Karate), front-end and back-end automation, and database technologies (DB2, Mongo DB, Snowflake). Strong communication and the ability to influence stakeholders are essential. ",
        "industries": [
            "Software Development",
            "Technology",
            "IT",
            "Quality Assurance",
            "Automation"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Skills",
            "Influencing",
            "Leadership",
            "Teamwork",
            "Mentorship",
            "Presentation",
            "Time Management",
            "Organization",
            "Adaptability",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Java",
            "Selenium",
            "BDD",
            "TDD",
            "Cucumber",
            "Gherkin",
            "CI/CD",
            "API Automation",
            "REST Assured",
            "Karate",
            "Front-end Automation",
            "Back-end Automation",
            "Database",
            "DB2",
            "MongoDB",
            "Snowflake",
            "SQL",
            "File Handling",
            "Cypress",
            "AWS"
        ],
        "tech_stack": [
            "Java",
            "Selenium",
            "BDD",
            "TDD",
            "Cucumber",
            "Gherkin",
            "CI/CD",
            "REST Assured",
            "Karate",
            "Cypress",
            "AWS",
            "DB2",
            "MongoDB",
            "Snowflake"
        ],
        "programming_languages": [
            "Java",
            "SQL"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Software Engineering",
                "Information Technology",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Potential for Remote Work",
            "Training and Development Opportunities",
            "Career Growth Opportunities",
            "Exposure to Latest Technologies"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3955777663,
        "company": "Blackspoke",
        "title": "Data Scientist, Imagery and EO Sensors |  TS/SCI CI Poly",
        "created_on": 1720587289.4260967,
        "description": "Own your opportunity to serve as a critical component of our nation's safety and security. Make an impact by using your expertise to protect our country from threats. Be part of an exciting opportunity to contribute to one of the nation's most critical intelligence organizations. Your work directly impacts national security and global issues, you will have the chance to contribute to missions that are of paramount importance to the United States and its allies, know that that the environments and programs you support are making a difference on a global scale. Our customers operate at the forefront of technology, dealing with some of the most advanced defense, geospatial, and intelligence systems in the world. What you will be working on: We apply advanced technologies such as Digital Signal Processing, Analytics, Machine Learning, Artificial Intelligence, and Cloud computing to solve our customer and mission challenges. As a Senior Scientist, you'll work with a team of extraordinary scientists, engineers, and analysts. You will develop algorithms and software, and unique approaches to image data processing and exploitation for use in the latest ground processing architectures. You will also work with existing, advanced algorithms and software for automated target recognition, change detection, multi-source data fusion, and tracking. Areas of expertise includes: Design, develop, and test advanced, automated feature extraction algorithms. Extraction of information from large geospatial/spectral datasets. Development of processing architectures and software for use with customer systems and sensors. Explore new machine learning and artificial intelligence approaches for automated object detection, feature extraction/target state estimation, multi-source data fusion, and much more. Document developed algorithms and transition them to the software team for incorporation into the production code base. Understanding of problem and technical approach based on underlying mathematical/heuristic models. Prototyping/proof-of-concept demonstrations: Ability to demonstrate that your ideas work on real data in real processing environments and meet critical mission requirements. Develop evaluation techniques and processes. Develop performance metrics. Test algorithms and measure performance under different operating conditions. Document results. Support operations with the ability to diagnose/fix problems after algorithms/software are integrated into and run within a larger system in operational environments. Expansion of current capabilities: Add to existing algorithms/code bases to create new/expanded capabilities providing new functionality to enhance products and services. Experience with profiling and optimizing source codes. Strong fundamentals in data structures and algorithms. Support technical proposal/report writing with the ability to communicate ideas clearly making use of graphs, graphics, images, and equations when needed. Provide customers and General Dynamics leadership briefings: Ability to communicate complex ideas to audiences with a wide range of education and interest in technical details. Some customers simply want to understand the basic idea. Ability to go deep when needed. From inventing new products or enhancing existing applications, your talent and leadership abilities will be front and center. The ideal candidate for this position is comfortable working independently, and in small groups, to develop ideas that meet customer needs. They are highly motivated to write proposals and develop new ideas and carry through phases of scientific research and software development from initial physical equations of phenomenology to demonstration pseudo-code, to fully documented and tested large scale scientific software running in the newest cloud-based, ground processing architectures. Requirements Masters or PhD in degree in Electrical Engineering, Physics, Image Science, Remote Sensing, Optics, or other Physical Science or Engineering degree is required. A Masters and 12 years or PhD with 10 years of relevant experience with a TS/SCI clearance is also required. Post-degree work experience and post-doctoral work experience counts towards experience. Required Skills Technologies that are top-notch. A team of bold thinkers committed to exploring what's next. Opportunities to gain new knowledge through advanced research and development cycles driven by mission critical requirements. Small team environment where your voice is heard and direct involvement with a customer solving their immediate problems. State of the art facility company facility with on premise perks, gym, walking trails, and close by amenities. Excellent verbal, written, and interpersonal communication skills. Very strong knowledge of technology trends and the ability to champion new ideas, products, and process improvements. Passion to make a difference for our country in support of critical national security missions. What you will get A high-growth environment with plenty of opportunities to grow your career as the company grows. We are looking for leaders. Owner and Leadership team that come from technical backgrounds so they understand the day-to-day challenges of the technical consulting world and can offer real life solutions and guidance. Highly competitive benefits package that shows we want to hire the very best. Equal Opportunity Employer/Veterans/Disabled. Individuals with disabilities, including disabled veterans or veterans with service-connected disabilities, are encouraged to apply. If you need assistance applying outside of the online application, please contact recruiting@blackspoke.com for more information. This Organization Participates in E-Verify This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the Form I-9. E-Verify Works for Everyone For more information on E-Verify, or if you believe that your employer has violated its E-Verify responsibilities, please contact DHS. Department of Homeland Security: 888-897-7781and E-Verify.gov",
        "url": "https://www.linkedin.com/jobs/view/3955777663",
        "summary": "Serve as a Senior Scientist contributing to national security by developing advanced algorithms and software for image data processing and exploitation. You'll be working with a team of scientists, engineers, and analysts to develop technologies such as Digital Signal Processing, Analytics, Machine Learning, Artificial Intelligence, and Cloud computing.",
        "industries": [
            "Defense",
            "Intelligence",
            "Aerospace",
            "Security",
            "Government",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Leadership",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Decision Making",
            "Time Management",
            "Organization",
            "Self-Motivation",
            "Adaptability",
            "Creativity",
            "Innovation",
            "Customer Focus"
        ],
        "hard_skills": [
            "Digital Signal Processing",
            "Analytics",
            "Machine Learning",
            "Artificial Intelligence",
            "Cloud Computing",
            "Image Data Processing",
            "Image Exploitation",
            "Algorithm Development",
            "Software Development",
            "Automated Target Recognition",
            "Change Detection",
            "Multi-Source Data Fusion",
            "Tracking",
            "Feature Extraction",
            "Geospatial Data",
            "Spectral Data",
            "Data Structures",
            "Algorithms",
            "Technical Writing",
            "Proposal Writing",
            "Data Analysis",
            "Performance Metrics",
            "Software Optimization",
            "Problem Diagnosis",
            "Technical Briefing"
        ],
        "tech_stack": [
            "Digital Signal Processing",
            "Analytics",
            "Machine Learning",
            "Artificial Intelligence",
            "Cloud Computing",
            "Image Data Processing",
            "Image Exploitation",
            "Automated Target Recognition",
            "Change Detection",
            "Multi-Source Data Fusion",
            "Tracking",
            "Feature Extraction",
            "Geospatial Data",
            "Spectral Data",
            "Data Structures",
            "Algorithms",
            "Software Optimization"
        ],
        "programming_languages": [],
        "experience": 10,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Electrical Engineering",
                "Physics",
                "Image Science",
                "Remote Sensing",
                "Optics",
                "Physical Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Benefits Package",
            "State of the art facility company facility with on premise perks, gym, walking trails, and close by amenities.",
            "Opportunities to gain new knowledge through advanced research and development cycles driven by mission critical requirements.",
            "Small team environment where your voice is heard and direct involvement with a customer solving their immediate problems."
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3843524857,
        "company": "CGI",
        "title": "Data Scientist (Sr.) - U.S. Citizenship Required",
        "created_on": 1720587293.1460092,
        "description": "Position Description CGI is one of the top 5 largest global IT companies spread across 40 countries with endless opportunities to expand and grow. As a CGI Federal Member, you have the opportunity to be a shareholder at CGI and join a family of 90,000 members strong. CGI Federal is hiring a Sr. Data Scientist to work with a skilled and motivated team of professionals on a high-visibility Department of Homeland Security (DHS) Cybersecurity and Infrastructure Security Agency (CISA) cyber security program. You will support a dynamic, fast-paced project focused on improving the cyber security posture of civilian government agencies through the implementation and enhancement of a cybersecurity platform, providing integration services, and developing, securing and maintaining cybersecurity dashboards. You will work closely with a variety of agency stakeholders, supporting their mission, priorities, organization and unique challenges. You will also support the development of additional cyber security offerings focused on next generation security solutions and technologies. The successful candidate for this position is a motivated individual, a self-starter who works effectively in a dynamic environment. This is a great opportunity with room to grow both on the program and within CGI Federal! This position is located in our Fairfax, VA office; however a hybrid working model is acceptable. You will be required to be in our Fairfax, VA office two days per week. Your future duties and responsibilities Develop, implement and test components using Java/Python/R of financial models, algorithms, cash flow simulations and pricing/risk metrics calculations in end-user or production computing systems for use in business decisions, financial and regulatory reporting and risk management. Use advanced analytics and data science techniques to efficiently translate complex mathematical, business and financial modeling logic into software code. Design and execute test cases for modeling and analytical software applications to ensure they meet business needs and model requirements. Design and execute modeling application systems via distributed computing both on premise and on external cloud. Monitor emerging technologies and industry best practices of model and analytical system implementation, evaluate and propose adoption of such technologies or best practices. Execute model application runs, process/validate model outputs and produce/review quantitative reports for business use. Support Requirement Engineers to determine qualitative baselines and objective criteria for large data sets. Support test and technical teams involved in developing requirements and software design artifacts to ensure familiarity with the requirements and expected functionality of the system. Support the delivery of client expectations and involvement in the various reporting activities. Assist with managing the development of reports on project progress, risks and issues. Automate data analysis to improve and enhance data. Adept at picking up new tools and technologies. Manage large complex projects involving diverse datasets. Required Qualifications To Be Successful In This Role Due to the nature of the government contract requirements and/or clearance requirements, US citizenship is required as well as successful passing of CGI background check prior to beginning work. In addition, candidates must have the ability to obtain and maintain a DHS CISA EOD/Public Trust clearance. Bachelor’s degree and 5-8 years of experience. Experience with econometric modeling and statistical analysis. Experience with the implementation and creation of various models and algorithms including regression and statistical models. Knowledge of AI or machine learning techniques is desirable. Strong programming experience in Java and Python/R. Familiarity with SAS and with tools available in the AWS/Cloud environment. Proficiency in Unix/Linux environment. Effective communication and writing skills to communicate to customers and internal team members. Exceptional organizational skills to work with a vast array of information. Ability to maintain own workload and meet deadlines. Desired Qualifications Cybersecurity experience. Experience with CISA’s Continuous Diagnostics and Mitigation (CDM) program. CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to skill set, level, experience, relevant training, and licensure and certifications. To support the ability to reward for merit-based performance, CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range for this role in the U.S. is $108,600 - $209,100. #CGIFederalJob #DHSCareers Together, as owners, let’s turn meaningful insights into action. Life at CGI is rooted in ownership, teamwork, respect and belonging. Here, you’ll reach your full potential because… You are invited to be an owner from day 1 as we work together to bring our Dream to life. That’s why we call ourselves CGI Partners rather than employees. We benefit from our collective success and actively shape our company’s strategy and direction. Your work creates value. You’ll develop innovative solutions and build relationships with teammates and clients while accessing global capabilities to scale your ideas, embrace new opportunities, and benefit from expansive industry and technology expertise. You’ll shape your career by joining a company built to grow and last. You’ll be supported by leaders who care about your health and well-being and provide you with opportunities to deepen your skills and broaden your horizons. Come join our team—one of the largest IT and business consulting services firms in the world. Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, height, weight, or any other legally protected status or characteristics. CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com. You will need to reference the Position ID of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a Position ID will not be returned. We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members. All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. Dependent upon role and/or federal government security clearance requirements, and in accordance with applicable laws, some background investigations may include a credit check. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances. CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information.",
        "url": "https://www.linkedin.com/jobs/view/3843524857",
        "summary": "CGI Federal is seeking a Sr. Data Scientist to join a team working on a high-visibility Department of Homeland Security (DHS) Cybersecurity and Infrastructure Security Agency (CISA) cyber security program. The role involves developing, implementing, and testing financial models, algorithms, and risk metrics calculations using Java/Python/R, performing advanced analytics, and designing and executing test cases for modeling and analytical software applications. This position requires strong programming skills in Java, Python/R, and experience with econometric modeling and statistical analysis, including AI and machine learning techniques. Experience with CISA's Continuous Diagnostics and Mitigation (CDM) program is a plus.",
        "industries": [
            "Information Technology",
            "Cybersecurity",
            "Government",
            "Data Science",
            "Financial Modeling",
            "Risk Management"
        ],
        "soft_skills": [
            "Communication",
            "Writing",
            "Organizational",
            "Teamwork",
            "Problem Solving",
            "Self-Starter",
            "Motivation"
        ],
        "hard_skills": [
            "Java",
            "Python",
            "R",
            "Econometric Modeling",
            "Statistical Analysis",
            "Regression",
            "AI",
            "Machine Learning",
            "SAS",
            "AWS",
            "Cloud Computing",
            "Unix",
            "Linux"
        ],
        "tech_stack": [
            "Java",
            "Python",
            "R",
            "SAS",
            "AWS",
            "Cloud Computing",
            "Unix",
            "Linux"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "R",
            "SAS"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Mathematics",
                "Statistics",
                "Finance"
            ]
        },
        "salary": {
            "max": 209100,
            "min": 108600
        },
        "benefits": [
            "Shareholder Benefits",
            "Healthcare",
            "Retirement",
            "Paid Time Off",
            "Professional Development"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3932070720,
        "company": "CACI International Inc",
        "title": "AI/ML Senior Software Engineer",
        "created_on": 1720587297.287238,
        "description": "Job Category: Engineering Time Type: Full time Minimum Clearance Required to Start: TS/SCI with Polygraph Employee Type: Regular Percentage of Travel Required: Up to 10% Type of Travel: Local * * * What You’ll Get To Do CACI is seeking talented, results-oriented, mission-focused engineers with experience in developing Artificial Intelligence (AI) and Machine Learning (ML) algorithms. This is an opportunity to work with mission critical AI/ML applications to our greatest national security challenges with a team of motivated, innovative developers who are collectively responsible for creating innovative solutions in support of national security and defense. Our teams will be building the next generation of adaptive and AI-inspired algorithms for detecting and geo-locating threats to autonomously react and deploy countermeasures. More About the Rol e Ideal Candidates Will Have Experience In The Following Areas Conducting research into algorithmic concepts to understand and apply techniques for development of advanced RF payloads and intelligent algorithms that coordinate distributed assets to sense, locate and deny layered/networked threats in dynamic and contested environments Developing algorithms that enable advanced signal processing techniques creating new ways to detect and defeat the networked threat Supporting technical reviews of vendor software products and deliverables, interface development and development of software algorithms and models for simulation Debugging, testing, and validating our capabilities using both unit tests as well as scenarios reported by our end users Analyzing search ranking and relevance requirements, issues and opportunities Understanding product requirements, translate them into engineering tasks Deploying machine learning models in low-latency production system Building end-to-end production systems including query understanding and ranking to power search Utilizing Spark, Hadoop MapReduce, Hive, Impala to perform distributed data processing Programming in Python or C/C++, including an understanding of git, automated software builds, and containerization Understanding of Statistical Machine Learning methods such as Bayesian Inference, Clustering, Regression, Deep Convolutional Neural Networks, etc. Utilizing Linux operating systems and Linux command line You’ll Bring These Qualifications A bachelor’s degree (or higher) in Computer Science or Electrical Engineering or equivalent technical degree 7+ years of experience as a software engineer Understanding of principles in Artificial Intelligence, Machine Learning concepts and techniques Knowledge of AI/ML algorithms and their implementations, or an ability to learn and understand existing implementations A strong understanding of modern C, C++, or Python programming Ability to read and understand technical specifications, and create software-based implementations of the procedures and methods described therein A “TS/SCI Full Scope Poly” clearance is required to begin employment. For this position, CACI has the ability to provide clearance sponsorship for qualified individuals. What We Can Offer You We’ve been named a Best Place to Work by the Washington Post. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive benefits and learning and development opportunities. We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities. For over 60 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success. This position is contingent on funding and may not be filled immediately. However, this position is representative of positions within CACI that are consistently available. Individuals who apply may also be considered for other positions at CACI. ______________________________________________________________________________ What You Can Expect A culture of integrity. At CACI, we place character and innovation at the center of everything we do. As a valued team member, you’ll be part of a high-performing group dedicated to our customer’s missions and driven by a higher purpose – to ensure the safety of our nation. An environment of trust. CACI takes pride in fostering a diverse and accessible culture where every individual feels supported to chart their own path. You’ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality. A focus on continuous growth. Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground — in your career and in our legacy. Your potential is limitless. So is ours. Learn more about CACI here. ______________________________________________________________________________ Pay Range : There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here. The Proposed Salary Range For This Position Is $102,900 - $216,200 CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic.",
        "url": "https://www.linkedin.com/jobs/view/3932070720",
        "summary": "CACI is seeking talented engineers with experience in developing Artificial Intelligence (AI) and Machine Learning (ML) algorithms for mission-critical applications related to national security and defense. Responsibilities include researching algorithmic concepts, developing advanced signal processing techniques, supporting technical reviews, debugging and testing, analyzing search ranking, understanding product requirements, deploying machine learning models, building end-to-end production systems, utilizing big data technologies, and programming in Python or C/C++. ",
        "industries": [
            "Defense",
            "National Security",
            "Aerospace & Defense",
            "Government",
            "Technology"
        ],
        "soft_skills": [
            "Results-oriented",
            "Mission-focused",
            "Motivated",
            "Innovative",
            "Teamwork",
            "Communication",
            "Problem-solving",
            "Analytical",
            "Critical Thinking",
            "Research"
        ],
        "hard_skills": [
            "Artificial Intelligence",
            "Machine Learning",
            "RF Payloads",
            "Signal Processing",
            "Software Engineering",
            "Algorithm Development",
            "Python",
            "C/C++",
            "Git",
            "Software Builds",
            "Containerization",
            "Statistical Machine Learning",
            "Bayesian Inference",
            "Clustering",
            "Regression",
            "Deep Convolutional Neural Networks",
            "Linux",
            "Linux Command Line",
            "Spark",
            "Hadoop MapReduce",
            "Hive",
            "Impala"
        ],
        "tech_stack": [
            "Artificial Intelligence",
            "Machine Learning",
            "RF Payloads",
            "Signal Processing",
            "Python",
            "C/C++",
            "Git",
            "Spark",
            "Hadoop MapReduce",
            "Hive",
            "Impala",
            "Linux",
            "Linux Command Line"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Electrical Engineering"
            ]
        },
        "salary": {
            "max": 216200,
            "min": 102900
        },
        "benefits": [
            "Flexible Time Off",
            "Competitive Compensation",
            "Healthcare",
            "Wellness",
            "Financial",
            "Retirement",
            "Family Support",
            "Continuing Education",
            "Time Off"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3954927831,
        "company": "Censys",
        "title": "Detection Development Engineer",
        "created_on": 1720587298.7065108,
        "description": "Censys knows the internet and cloud better than anyone else. Attack Surface Management provides customers with an attacker-centric view of all externally facing internet and cloud to extend visibility, prioritize, and remediate the most critical risk exposures that will actually lead to a breach. Our daily IPv4 scans and the world’s largest SSL/TLS Certificate database enable customers with the most accurate and continuously updated attack surfaces. Enterprise security teams leverage Censys to keep pace with the speed of the business and gain an advantage over the rapidly evolving cyber-attack threats. Role Summary Censys is looking for a Detection Engineer, Security Research Engineer, or Software Engineer to join our engineering team. You’ll be focused on increasing our risk and threat detection coverage and vulnerability database by seeking out and fingerprinting software, vulnerabilities, and emerging threats. You will also help conduct reconnaissance to help expand our capabilities to capture, monitor, and properly identify Internet resources. You will work directly with our scanning team to provide guidance on building and scaling the tools, active scanning infrastructure, and frameworks used to provide software coverage, risks, and threats in our Internet Intelligence Platform. What You'll Do Research and develop custom fingerprints against Censys scan data to further enrich and contextualize services and infrastructure running on the Internet. Consult with the Scanning Team for implementing possible changes to scanning targets, payloads, and collection of data to further increase the fidelity and accuracy of identification of software and hardware versions and models. Coordinate with our Rapid Response team to facilitate researching and fingerprinting of emerging vulnerabilities and threats. Qualifications Bachelor's degree in Computer Science, Data Science, Engineering, or other technical discipline (or equivalent professional experience). 1+ years of experience in security research/systems security/network security or a similar field. Experience with protocol analysis and in-depth knowledge of common protocols such as TLS, HTTP, SSH, SMB, SMTP.High-level understanding of common network security vulnerabilities, CVSS scoring and exploit techniques. Experience exploring active scan data using tools such as Censys Search, Shodan, or similar; and/or experience with data analysis tools such as Google BigQuery. Proficient with regular expressions and other pattern-matching expressions. Ability to concisely communicate complex subject matter to technical and non-technical audiences. Ability to work independently as a researcher while being part of a larger cross-functional team. Our target salary range for this role is between $147,000 USD and $180,000 USD + bonus eligibility and equity. Our roots are in Ann Arbor, Michigan with location hubs in Seattle, the Bay Area, Washington D.C., and Dublin, Ireland. Our innovation is fueled by the team’s global perspectives and diverse backgrounds. Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they feel they meet every qualification. At Censys we are dedicated to building a diverse, inclusive, and authentic workplace - so if you're excited about this role but your past experience doesn't align perfectly with every listed requirement in the job description, we encourage you to apply anyways. You may be exactly who we need to fill this role or others! We value diversity and are committed to creating an inclusive environment for all employees. Censys is an equal opportunity employer.",
        "url": "https://www.linkedin.com/jobs/view/3954927831",
        "summary": "Censys, a leader in internet and cloud security, seeks a Detection Engineer, Security Research Engineer, or Software Engineer to enhance their vulnerability database and threat detection coverage. This role involves researching and developing custom fingerprints against Censys scan data, consulting with the Scanning Team on improving scan targets and data collection, and collaborating with the Rapid Response team on emerging vulnerabilities and threats.",
        "industries": [
            "Cybersecurity",
            "Information Technology",
            "Software Development",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Research",
            "Collaboration",
            "Independent Work"
        ],
        "hard_skills": [
            "Protocol Analysis",
            "TLS",
            "HTTP",
            "SSH",
            "SMB",
            "SMTP",
            "Network Security Vulnerabilities",
            "CVSS",
            "Exploit Techniques",
            "Regular Expressions",
            "Pattern Matching"
        ],
        "tech_stack": [
            "Censys Search",
            "Shodan",
            "Google BigQuery"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 180000,
            "min": 147000
        },
        "benefits": [
            "Bonus",
            "Equity"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3970164311,
        "company": "ClearanceJobs",
        "title": "Biomedical Data Science / Bioinformatics | Python, R, SQL | C... with Security Clearance",
        "created_on": 1720587302.3568316,
        "description": "In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace. Work you'll do The Bioinformatics Data Specialist will work closely with our team of senior bioinformaticians and epidemiologists on projects within our Federal Health sector. In this role, you will be responsible for: * Managing and analyzing large databases. * Data manipulation, algorithmic implementation, statistical programming, and integrated analyses. * Installing, troubleshooting and running analytical pipelines using open-source and commercial scientific software on Unix/Linux and Cloud-hosted platforms, and using publicly available databases and tools. The team Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise. The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights. Qualifications Required: * 2+ years of experience with Biomedical Data Science and/or Bioinformatics 2+ years of experience with analysis packages and programming languages such as R, Python, SPSS, SQL, and SAS * 2+ years of experience with scientific research methods as applied to quantitative data analysis * 2+ years of government or management consulting experience in the federal health sector * Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future * Masters degree in Biomedical Sciences, Computer Science, Engineering, Mathematics or other health-related field * Active Public Trust Security clearance or higher Preferred: * PhD in Biomedical Sciences, Computer Science, Engineering, Mathematics or other health-related field * Active government security clearance * Prior government consulting experience * Strong problem solving and troubleshooting skills with experience exercising mature judgment The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $88,800 to $148,000. Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html #engcamp2024",
        "url": "https://www.linkedin.com/jobs/view/3970164311",
        "summary": "Deloitte is seeking a Bioinformatics Data Specialist to join their Government and Public Services (GPS) practice. The ideal candidate will have 2+ years of experience with Biomedical Data Science and/or Bioinformatics, analysis packages and programming languages such as R, Python, SPSS, SQL, and SAS, scientific research methods as applied to quantitative data analysis, and government or management consulting experience in the federal health sector. They will be responsible for managing and analyzing large databases, data manipulation, algorithmic implementation, statistical programming, integrated analyses, installing, troubleshooting, and running analytical pipelines using open-source and commercial scientific software on Unix/Linux and Cloud-hosted platforms, and using publicly available databases and tools.",
        "industries": [
            "Government",
            "Public Services",
            "Healthcare",
            "Biotechnology",
            "Bioinformatics",
            "Federal Health",
            "Management Consulting"
        ],
        "soft_skills": [
            "Problem solving",
            "Troubleshooting",
            "Communication",
            "Collaboration",
            "Analytical Thinking",
            "Strategic Thinking",
            "Critical Thinking",
            "Decision Making",
            "Data Interpretation"
        ],
        "hard_skills": [
            "Biomedical Data Science",
            "Bioinformatics",
            "R",
            "Python",
            "SPSS",
            "SQL",
            "SAS",
            "Data Analysis",
            "Scientific Research Methods",
            "Quantitative Data Analysis",
            "Unix/Linux",
            "Cloud Computing",
            "Data Management",
            "Data Manipulation",
            "Algorithmic Implementation",
            "Statistical Programming",
            "Integrated Analyses",
            "Analytical Pipelines",
            "Open Source Software",
            "Commercial Scientific Software",
            "Publicly Available Databases",
            "Public Trust Security Clearance"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SPSS",
            "SQL",
            "SAS",
            "Unix/Linux",
            "Cloud Computing",
            "Open Source Software",
            "Commercial Scientific Software"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SPSS",
            "SQL",
            "SAS"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Biomedical Sciences",
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Health-related fields"
            ]
        },
        "salary": {
            "max": 148000,
            "min": 88800
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3956482776,
        "company": "Leidos",
        "title": "Python Software Engineer",
        "created_on": 1720587304.348795,
        "description": "Description Unleash Your Potential! At Leidos, we deliver innovative solutions by leveraging our diverse and talented workforce who are dedicated to our customer’s success. We empower our teams, contribute to our communities, and operate sustainably. Everything we do is built on a commitment to do the right thing for our customers, our people, and our community. Our Mission, Vision, and Values guide the way we do business. If this sounds like an environment where you can thrive, keep reading! Do you thrive working in small teams that collaborate closely with customers? Are you intrigued by big data? Our prototype development program is seeking someone with a strong mission focus who is passionate about new development and rapid prototyping. We want someone who can help us discover smarter, innovative approaches to support mission operations, discover new analytics, enhance tradecraft, and much more! Our LOE program provides our customer's Operations organization with the best possible solutions for their mission needs. We achieve this through rapid prototyping, new development, and advanced technology research. From leading-edge visualizations to analytic development, we're always pushing the boundaries to find new and better data sources and tradecraft to answer intelligence questions. With a focus on collaboration and a fast-paced environment, our prototype development program is the ideal place to grow your skills and make a real impact. Clickhereto learn more about how this program “Delivers Mission Success!” Your greatest work is ahead! If you’re a talented Senior Software Engineer with a TS/SCI polygraph clearance, we want to hear from you. The Leidos National Security Sector is looking for someone like you to join our team in the Fort Meade, MD area. As part of this highly visible and fast-paced prime contract, you'll enjoy a competitive benefits package including four or more weeks of Paid Time Off, Flexible Schedules, Discounted Stock Purchase Plans, Education and Training Support, Parental Paid Leave, and more! Don't miss out on this incredible opportunity to take your career to the next level. Apply today and join one of the most dynamic teams in the industry. Are you ready to join a team dedicated to a mission? Begin your journey of a flourishing and meaningful career, share your resume with us today! Your Main Objective Work with data scientist team to capture Cyber knowledge at scale transitioning to more traditional software development. Leverage data science tradecraft using Python to access APIs and transform the clean and normalized data into JSON for other applications. Analyze, design, verify, validate, implement, apply, and maintain software systems. Write software standards and practices documentation. Present briefings and demonstrations to stakeholders. Support a wide-range of cyber knowledge development priorities to include workflows, requirements specification management, custom dashboard and tool support, knowledge capture and documentation. What Sets You Apart (required) Bachelor's degree in Computer Science or related field plus 12 or more years of relevant experience or Master’s degree in Computer Science or related field plus 10 or more years of relevant experience. An Associate’s degree in Computer Science or related field plus 14 years of relevant experience or high school diploma/GED plus 16 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position Computer Science (CS) degree or related field required Active TS/SCI with polygraph clearance Strong Python skills. Familiarity with JSON format. Experience with Jupyter Notebooks and GitLab. You Might Also Have (desired) Experience with Javascript and Typescript. Understanding of Cyber mission. Understanding of MITRE ATT&CK framework. Ability to work with a team. At Leidos, the opportunities are boundless. We challenge our staff with interesting assignments that allow them to thrive professionally and personally. For us, helping you grow your career is good business. We look forward to learning more about you – apply today! conmd Original Posting Date 2024-06-21 While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above. Pay Range Pay Range $122,200.00 - $220,900.00 The Leidos pay range for this job level is a general guideline onlyand not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.",
        "url": "https://www.linkedin.com/jobs/view/3956482776",
        "summary": "Leidos is seeking a Senior Software Engineer with TS/SCI polygraph clearance to join their team in Fort Meade, MD. The role involves working with a data scientist team to capture cyber knowledge at scale, leveraging Python to access APIs, transform data into JSON format, and develop software systems. The ideal candidate will have strong Python skills, familiarity with JSON format, experience with Jupyter Notebooks and GitLab, and understanding of Cyber missions and MITRE ATT&CK framework.",
        "industries": [
            "Cybersecurity",
            "Information Technology",
            "Government",
            "Defense",
            "Intelligence"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Teamwork",
            "Analytical Thinking",
            "Presentation Skills"
        ],
        "hard_skills": [
            "Python",
            "JSON",
            "Jupyter Notebooks",
            "GitLab",
            "Javascript",
            "Typescript",
            "MITRE ATT&CK Framework",
            "API Access",
            "Data Transformation",
            "Software Development",
            "Requirements Management",
            "Data Visualization",
            "Dashboard Development",
            "Knowledge Management",
            "Documentation"
        ],
        "tech_stack": [
            "Python",
            "JSON",
            "Jupyter Notebooks",
            "GitLab",
            "Javascript",
            "Typescript",
            "MITRE ATT&CK Framework",
            "APIs"
        ],
        "programming_languages": [
            "Python",
            "Javascript",
            "Typescript"
        ],
        "experience": 12,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 220900,
            "min": 122200
        },
        "benefits": [
            "Paid Time Off",
            "Flexible Schedules",
            "Discounted Stock Purchase Plans",
            "Education and Training Support",
            "Parental Paid Leave"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Rockville, MD",
        "job_id": 3953183373,
        "company": "Digital Infuzion",
        "title": "AI Operations Engineer",
        "created_on": 1720587305.933967,
        "description": "Job Type Full-time Description Welcome! At Digital Infuzion, we believe people can lead better, healthier lives. To do so, researchers need insights faster, and providers need on-demand data and tailored software solutions. This is why we are passionate about developing innovative solutions for the healthcare industry so researchers and providers can better serve their patients. We go beyond ordinary health IT services and solutions because we see the advancement of technology and bioinformatics as opportunities to make meaningful impacts on patients’ lives. If you feel drawn to doing what you love in a creative, open, and growth-oriented environment all while helping people live healthier lives, then keep scrolling - we may have just the opportunity for you. We’re seeking an AI Operations Engineer to manage and optimize our AI infrastructure, ensuring the seamless deployment, performance, and security of AI systems. This role involves developing automation scripts, monitoring systems, and collaborating with cross-functional teams to support and enhance our AI operations. Responsibilities Manage AI infrastructure, including hardware, software, and cloud services. Develop and implement automation scripts and tools for deployment. Monitor AI systems for performance and security. Analyze system performance data to identify bottlenecks and areas for improvement. Ensure the security of AI systems by implementing best practices and conducting regular security audits. Collaborate with data scientists, AI developers, and other stakeholders to provide infrastructure support. Maintain comprehensive documentation of AI infrastructure configurations and processes Requirements Bachelor’s degree in Computer Science, Information Systems, or a related field. Minimum of 3 years of experience in AI operations. Proficiency with AI infrastructure components, automation tools, and scripting languages such as Python, Bash, or PowerShell. Strong analytical and problem-solving skills. Excellent communication and documentation skills. Familiarity with AI frameworks and tools such as TensorFlow, PyTorch, and Kubernetes. High level of accuracy and attention to detail. Preferred Qualifications Experience with cloud platforms such as AWS, Azure, or Google Cloud. Understanding of AI system security principles and experience in implementing security measures. Ability to manage multiple projects and priorities in a fast-paced environment. Digital Infuzion, Inc. is an Equal Opportunity Employer. EOE/AA/M/F/D/V It is the policy of Digital Infuzion, Inc. to provide equal employment opportunities without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, age, disability, marital status, veteran status, genetic information or any other protected characteristic under applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3953183373",
        "summary": "Digital Infuzion is seeking an AI Operations Engineer to manage and optimize their AI infrastructure, ensuring the seamless deployment, performance, and security of AI systems. This role involves developing automation scripts, monitoring systems, and collaborating with cross-functional teams to support and enhance AI operations.",
        "industries": [
            "Healthcare",
            "Information Technology",
            "Biotechnology"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Analytical",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Python",
            "Bash",
            "PowerShell",
            "TensorFlow",
            "PyTorch",
            "Kubernetes",
            "AWS",
            "Azure",
            "Google Cloud"
        ],
        "tech_stack": [
            "AI infrastructure",
            "Automation tools",
            "Scripting languages",
            "AI frameworks",
            "Cloud platforms",
            "AI system security"
        ],
        "programming_languages": [
            "Python",
            "Bash",
            "PowerShell"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Information Systems"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Equal Opportunity Employer"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3920761702,
        "company": "Amazon Web Services (AWS)",
        "title": "Applied Scientist, AWS HR WFP",
        "created_on": 1720587307.5072184,
        "description": "Description Success in any organization begins with its people and having a comprehensive understanding of our workforce and how we best utilize their unique skills and experience is paramount to our future success. AWS is looking for an exceptional Applied Scientist with ML expertise to join the Workforce Planning team. This Applied Scientist has proficiency in employing workforce and human behavior insights, operations research and machine learning techniques to build models and algorithms that enable the acceleration of revenue growth, improved operational efficiencies & delivery. Ultimately, results will be delivered through a workforce plan of optimized size and level in service of predictably accelerating product innovation, and enhancing the customer experience. Moreover, this Applied Scientist will work in partnership with the core WFP team that requires thought leadership to advance WFP content across AWS. This individual has proficiency in employing workforce and human behavior insights, strong business operations fundamentals and good judgement. Key job responsibilities In this role, you will be responsible for using operational and human capital data and leveraging machine learning methods to map enterprise strategies into actionable delivery plans, guiding data driven business decisions that results in predicting outcomes, understanding complex data relationships, and developing a quantitative return on investment. You will work closely with the business and technology teams. The ideal Senior Applied Scientist has a strong sense of ownership, is self-driven, loves breaking new ground. You will bring a mix of experience including complex program management, cross-functional collaboration, strategic thinking, technical expertise, and process improvement. If you enjoy working in a fast-paced dynamic environment and being challenged by new problems, we’d like to speak with you! A day in the life As an Applied Scientist within AWS, you will partner across the WFP group guided by a senior member of the team. You will play a key role on the Workforce Planning Science, Tooling and Inspection sub-teams that influence the long-range plans of the business and the technical agenda that supports it. You will influence tools and programs serving senior leaders globally and impacting AWS’ future. The ideal Applied Scientist has a strong sense of ownership, is self-driven, loves breaking new ground. About The Team Our team communicates who we are as an employer – what it’s like to be an Amazonian, why we love innovating on behalf of customers and why people should join us. We build trust with our partners, dive deep into our data, and love to learn and be curious as we deliver results. Our job is to bring that to life. Amazon values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship and Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. We value innovation and recognize this sometimes requires uninterrupted time to focus on a build. We also value in-person collaboration and time spent face-to-face. Our team affords employees options to work in the office every day or in a flexible, hybrid work model near one of our offices in Seattle and Arlington. Diverse Experiences AWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship & Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud. Basic Qualifications PhD 3+ years of building models for business application experience Experience programming in Java, C++, Python or related language Experience in any of the following areas: algorithms and data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing Preferred Qualifications Experience in professional software development Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc. Experience with large scale distributed systems such as Hadoop, Spark etc. experience in productionizing models Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $136,000/year in our lowest geographic market up to $222,200/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon.com Services LLC - A57 Job ID: A2637983",
        "url": "https://www.linkedin.com/jobs/view/3920761702",
        "summary": "AWS seeks an Applied Scientist with ML expertise to join the Workforce Planning team. This role involves using operational and human capital data, leveraging machine learning methods, to map enterprise strategies into actionable delivery plans, influencing data-driven business decisions, and predicting outcomes. The ideal candidate has strong ownership, self-motivation, and a desire to break new ground. They will work closely with business and technology teams, bringing experience in complex program management, cross-functional collaboration, strategic thinking, technical expertise, and process improvement.",
        "industries": [
            "Technology",
            "Cloud Computing",
            "Human Resources",
            "Data Science",
            "Machine Learning",
            "Operations Research"
        ],
        "soft_skills": [
            "Ownership",
            "Self-Driven",
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Strategic Thinking",
            "Process Improvement",
            "Analytical Thinking",
            "Decision Making",
            "Leadership",
            "Business Acumen",
            "Communication"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Mining",
            "Algorithm Development",
            "Data Structures",
            "Optimization",
            "Parallel and Distributed Computing",
            "High-Performance Computing",
            "Python",
            "Java",
            "C++",
            "R",
            "Scikit-Learn",
            "Spark MLLib",
            "MxNet",
            "Tensorflow",
            "Numpy",
            "Scipy",
            "Hadoop",
            "Spark"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "C++",
            "R",
            "Scikit-Learn",
            "Spark MLLib",
            "MxNet",
            "Tensorflow",
            "Numpy",
            "Scipy",
            "Hadoop",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C++"
        ],
        "experience": 3,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 222200,
            "min": 136000
        },
        "benefits": [
            "Medical",
            "Financial",
            "Equity",
            "Sign-On Payment",
            "Flexible Work Model",
            "Mentorship",
            "Career Growth",
            "Work/Life Balance",
            "Inclusive Team Culture",
            "Affinity Groups"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3968203274,
        "company": "VT Group (VTG)",
        "title": "AI/ML Systems Engineer",
        "created_on": 1720587311.086865,
        "description": "Overview We are seeking a AI/ML Systems Engineer located in Chantilly, VA. What will you do? AI/ML Systems Engineers execute engineering tasks, taking a multi-discipline approach to full lifecycle engineering. Engineer and assess current and future technology, and ensure the project captures innovative tradecraft, lessons learned, and best practices. Collaborate with engineers or software developers to select appropriate design solutions or ensure the compatibility of system components. Do you have what it takes? TS/SCI with Poly BS Degree (Technical) 15+ years experience Knowledge of Artifical Intelligence Machine Learning This is a Military Friendly job opportunity",
        "url": "https://www.linkedin.com/jobs/view/3968203274",
        "summary": "AI/ML Systems Engineer role in Chantilly, VA focusing on full lifecycle engineering, technology assessment, innovation, and collaboration with other engineers. Requires TS/SCI with Poly, BS degree in a technical field, and 15+ years of experience.",
        "industries": [
            "Technology",
            "Defense",
            "Aerospace"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Innovation"
        ],
        "hard_skills": [
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 15,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Technical"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Military Friendly"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3947634444,
        "company": "Leidos",
        "title": "Junior Software Engineer",
        "created_on": 1720587312.5448477,
        "description": "Description Unleash Your Potential! At Leidos, we deliver innovative solutions by leveraging our diverse and talented workforce who are dedicated to our customer’s success. We empower our teams, contribute to our communities, and operate sustainably. Everything we do is built on a commitment to do the right thing for our customers, our people, and our community. Our Mission, Vision, and Values guide the way we do business. If this sounds like an environment where you can thrive, keep reading! Do you thrive working in small teams that collaborate closely with customers? Are you intrigued by big data? Our prototype development program is seeking someone with a strong mission focus who is passionate about new development and rapid prototyping. We want someone who can help us discover smarter, innovative approaches to support mission operations, discover new analytics, enhance tradecraft, and much more! Our LOE program provides our customer's Operations organization with the best possible solutions for their mission needs. We achieve this through rapid prototyping, new development, and advanced technology research. From leading-edge visualizations to analytic development, we're always pushing the boundaries to find new and better data sources and tradecraft to answer intelligence questions. With a focus on collaboration and a fast-paced environment, our prototype development program is the ideal place to grow your skills and make a real impact. Clickhereto learn more about how this program “Delivers Mission Success!” Your greatest work is ahead! If you’re a talented Junior Software Engineer with a TS/SCI polygraph clearance, we want to hear from you. The Leidos National Security Sector is looking for someone like you to join our team in the Fort Meade, MD area. As part of this highly visible and fast-paced prime contract, you'll enjoy a competitive benefits package including four or more weeks of Paid Time Off, Flexible Schedules, Discounted Stock Purchase Plans, Education and Training Support, Parental Paid Leave, and more! Don't miss out on this incredible opportunity to take your career to the next level. Apply today and join one of the most dynamic teams in the industry. Are you ready to join a team dedicated to a mission? Begin your journey of a flourishing and meaningful career, share your resume with us today! Your Main Objective Work in a variety of environments to develop analytics based on data from multiple cyber sources, as well as classic SIGINT via data tagging. Developing analytics to produce metrics based on data tagging efforts. Develop prototypes, answering new questions, as well as providing better answers to existing questions. Work directly with the customer in a highly collaborative, integrated fast-paced environment using leading technologies, developing innovative solutions. Developing analytics using Java in a Linux environment Research and work with AWS and other platforms for development. Work in a cohesive, small team environment. What Sets You Apart Bachelor's degree plus 2-years of relevant experience or Master’s degree and no experience. An Associate’s degree plus 4-years of relevant experience or high school diploma/GED plus 6-years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position Computer Science (CS) degree or related field TS/SCI clearance with polygraph Software development/engineering experience including requirements analysis, installation, integration, evaluation, enhancement, maintenance, testing, and problem diagnosis/resolution. Experience with Java Pig/MapReduce & Python Experience with AWS Experience with distributed scalable Big Data Store (NoSQL) such as H Base, CloudBase/Accumulo, Big Table, etc. Experience with the Hadoop Distributed File System (HDFS); and technologies such as Hadoop, Hive, Pig, etc. Experience with Serialization such as JSON and or BSON; developing restful services; and using source code management tools. Experience with GHOSTMACHINE analytic development. Experience with analytic development in a Linux environment You Might Also Have Familiarity with GM analytic development Experience with Maven and Git Familiarity with Apachi NiFi Ability to work in a team environment Strong problem solving skills Initiative and must be self motivated At Leidos, the opportunities are boundless. We challenge our staff with interesting assignments that allow them to thrive professionally and personally. For us, helping you grow your career is good business. We look forward to learning more about you – apply today! conmd Original Posting Date 2024-06-10 While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above. Pay Range Pay Range $65,000.00 - $117,500.00 The Leidos pay range for this job level is a general guideline onlyand not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.",
        "url": "https://www.linkedin.com/jobs/view/3947634444",
        "summary": "Leidos is seeking a Junior Software Engineer with a TS/SCI polygraph clearance to join their team in Fort Meade, MD. The candidate will develop analytics based on data from multiple cyber sources and classic SIGINT via data tagging, work directly with the customer in a highly collaborative, integrated fast-paced environment, and develop analytics using Java in a Linux environment. Experience with Java Pig/MapReduce & Python, AWS, distributed scalable Big Data Store (NoSQL), Hadoop Distributed File System (HDFS), Serialization such as JSON and or BSON, developing restful services, and using source code management tools is desired.",
        "industries": [
            "Information Technology",
            "Cybersecurity",
            "National Security",
            "Intelligence",
            "Software Development",
            "Data Analytics",
            "Big Data"
        ],
        "soft_skills": [
            "Collaboration",
            "Problem Solving",
            "Initiative",
            "Self-Motivation",
            "Teamwork"
        ],
        "hard_skills": [
            "Java",
            "Python",
            "Pig",
            "MapReduce",
            "AWS",
            "NoSQL",
            "HBase",
            "CloudBase/Accumulo",
            "Big Table",
            "Hadoop",
            "Hive",
            "HDFS",
            "JSON",
            "BSON",
            "RESTful Services",
            "Source Code Management",
            "Linux",
            "Maven",
            "Git",
            "Apache NiFi"
        ],
        "tech_stack": [
            "Java",
            "Python",
            "AWS",
            "HBase",
            "CloudBase/Accumulo",
            "Big Table",
            "Hadoop",
            "Hive",
            "HDFS",
            "JSON",
            "BSON",
            "RESTful Services",
            "Linux",
            "Maven",
            "Git",
            "Apache NiFi"
        ],
        "programming_languages": [
            "Java",
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 117500,
            "min": 65000
        },
        "benefits": [
            "Paid Time Off",
            "Flexible Schedules",
            "Discounted Stock Purchase Plans",
            "Education and Training Support",
            "Parental Paid Leave"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3970253408,
        "company": "Precision Solutions",
        "title": "Junior Software Engineer",
        "created_on": 1720587317.210781,
        "description": "Onsite | Ft. Meade | 5 Days a Week Active TS/SCI w/FS Poly (NSA) Clearance Required Summary Since 2012, our client has helped mission-critical government organizations and businesses face their most daunting technology challenges. Their team have been trusted partners to many government agencies and are extremely familiar with a wide variety of systems, policies, and procedures. Our client is also a distinguished custom software development firm dedicated to delivering premium solutions tailored for businesses and governmental needs. They are home to top-tier technology professionals recognized as industry pioneers, comprehensive full-stack engineers, and reliable consultants. These experts are adept at clear communication, excel in resolving complex challenges where others may falter, and are skilled in actualizing an organization's vision. Responsibilities Our client is looking for multiple Junior Software Engineers to join their team! As a Junior Software Engineer, you will embark on a journey of growth and learning in the field of software development. Your foundation in computer science, coupled with expertise in programming languages such as Java, Python, C++, Ruby, Perl, or JavaScript, will be crucial as you navigate through various development environments including Linux, Unix, and Windows. Your responsibilities will span across an array of exciting domains such as web application development, user interface development, and big data analytics, to name a few. With a passion for technology and an eagerness to dive into new programming languages and frameworks, you will contribute to our client's dynamic team and projects while building your skills in a collaborative and innovative environment. Please be aware that due to our client's involvement in a wide array of projects, this job description serves as a foundational outline meant to align with their broad requirements. The specifics of each project vary, offering a rich landscape of opportunities! Detailed information about individual projects will be disclosed during the subsequent stages of the interview process. Requirements 0-7 years of software development experience in programming languages such as Java, Python, C++, Ruby, Perl, JavaScript is required An additional 4+ years of relevant experience may be substituted in lieu of a degree Familiarity with development environments in Linux, Unix, or Windows Experienced in and/or excited to work in any of the following areas Web application development Distributed systems User interface development Big data analytics Machine learning Data science Cloud-based computing Reverse engineering High-Performance Computing (HPC), or DevOps You have a passion for technology and the drive to learn new programming languages and frameworks Preferred Requirements We realize this is a long list of preferred various skills and experiences! - Don’t worry if you aren’t familiar with all of these. Only having some exposure and knowledge of the following various technologies is acceptable! Angular/AngularJS, Vue, CSS, HTML, React or equivalents for UI developers Spring, Hibernate, JPA, Servlets or equivalents for Java developers NoSQL technologies such as MongoDB, REDIS, Neo4J, Hbase, ElasticSearch, etc. Relational Databases such as MySQL, Oracle, PostgreSQL Developing RESTful Services using a framework such as Jersey, Spring MVC, CXF Enterprise Integration Frameworks such as Apache Camel, Spring Integration, or Apache NiFi JMS to include messaging Frameworks such as Apache ActiveMQ, Apache Artemis, or Kafka Spring to include Spring Boot, Spring Data, or Spring Security Java Persistence API through a persistence framework such as Spring, Hibernate, OpenJPA Developing and deploying applications to Servlet containers such as Tomcat or Jetty, or Application Servers such as Glassfish, JBoss, Weblogic Applications with NodeJS UI Component libraries such as Bootstrap, Material, Ant Distributed computing frameworks such as Apache Spark, Hadoop, and MapReduce Developing applications within utility clouds such as AWS, Rackspace, Heroku, or Azure Continuous integration tools such as Gitlab CI or Jenkins Containerization technologies such as Docker and Kubernetes IDEs such as Eclipse, IntelliJ, or Microsoft Visual Studio Education/Certification Requirements A Bachelor's degree in Computer Science or a related technical field is required. An additional 4+ years of relevant experience may be substituted in lieu of a degree Clearance Requirements Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; an active TS/SCI w/FS Poly clearance is required. Please note that the FS Poly currently needs to be held by the NSA or within the past two years. Other Duties Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. About Us Northern Virginia-based Precision Solutions is an expert in staffing solutions for companies of any size that open the door to new opportunities and seek outstanding talent. We pride ourselves on being versatile enough to tailor our relationships to the needs of each individual client, being agile in the fast-paced marketplace, and being precise in meeting the needs of any company. Equal Opportunity Employer Statement Precision Solutions is an equal opportunity employer. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.",
        "url": "https://www.linkedin.com/jobs/view/3970253408",
        "summary": "This role requires a Junior Software Engineer with 0-7 years of experience in various programming languages like Java, Python, C++, Ruby, Perl, or JavaScript. The engineer will work on projects related to web application development, user interface development, big data analytics, machine learning, data science, cloud-based computing, reverse engineering, High-Performance Computing (HPC), or DevOps. They will be exposed to technologies like Angular/AngularJS, Vue, CSS, HTML, React, Spring, Hibernate, JPA, Servlets, NoSQL technologies, Relational Databases, RESTful Services, Enterprise Integration Frameworks, Spring Boot, Spring Data, Spring Security, Java Persistence API, Servlet containers, Application Servers, NodeJS, UI Component libraries, Distributed computing frameworks, utility clouds, Continuous integration tools, Containerization technologies, and IDEs.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Government",
            "Defense"
        ],
        "soft_skills": [
            "communication",
            "problem-solving",
            "collaboration",
            "innovation",
            "learning",
            "passion for technology",
            "drive"
        ],
        "hard_skills": [
            "Java",
            "Python",
            "C++",
            "Ruby",
            "Perl",
            "JavaScript",
            "Linux",
            "Unix",
            "Windows",
            "Web application development",
            "Distributed systems",
            "User interface development",
            "Big data analytics",
            "Machine learning",
            "Data science",
            "Cloud-based computing",
            "Reverse engineering",
            "High-Performance Computing (HPC)",
            "DevOps",
            "Angular",
            "AngularJS",
            "Vue",
            "CSS",
            "HTML",
            "React",
            "Spring",
            "Hibernate",
            "JPA",
            "Servlets",
            "MongoDB",
            "REDIS",
            "Neo4J",
            "Hbase",
            "ElasticSearch",
            "MySQL",
            "Oracle",
            "PostgreSQL",
            "RESTful Services",
            "Jersey",
            "Spring MVC",
            "CXF",
            "Apache Camel",
            "Spring Integration",
            "Apache NiFi",
            "JMS",
            "Apache ActiveMQ",
            "Apache Artemis",
            "Kafka",
            "Spring Boot",
            "Spring Data",
            "Spring Security",
            "Java Persistence API",
            "Tomcat",
            "Jetty",
            "Glassfish",
            "JBoss",
            "Weblogic",
            "NodeJS",
            "Bootstrap",
            "Material",
            "Ant",
            "Apache Spark",
            "Hadoop",
            "MapReduce",
            "AWS",
            "Rackspace",
            "Heroku",
            "Azure",
            "Gitlab CI",
            "Jenkins",
            "Docker",
            "Kubernetes",
            "Eclipse",
            "IntelliJ",
            "Microsoft Visual Studio"
        ],
        "tech_stack": [
            "Java",
            "Python",
            "C++",
            "Ruby",
            "Perl",
            "JavaScript",
            "Linux",
            "Unix",
            "Windows",
            "Angular",
            "AngularJS",
            "Vue",
            "CSS",
            "HTML",
            "React",
            "Spring",
            "Hibernate",
            "JPA",
            "Servlets",
            "MongoDB",
            "REDIS",
            "Neo4J",
            "Hbase",
            "ElasticSearch",
            "MySQL",
            "Oracle",
            "PostgreSQL",
            "RESTful Services",
            "Jersey",
            "Spring MVC",
            "CXF",
            "Apache Camel",
            "Spring Integration",
            "Apache NiFi",
            "JMS",
            "Apache ActiveMQ",
            "Apache Artemis",
            "Kafka",
            "Spring Boot",
            "Spring Data",
            "Spring Security",
            "Java Persistence API",
            "Tomcat",
            "Jetty",
            "Glassfish",
            "JBoss",
            "Weblogic",
            "NodeJS",
            "Bootstrap",
            "Material",
            "Ant",
            "Apache Spark",
            "Hadoop",
            "MapReduce",
            "AWS",
            "Rackspace",
            "Heroku",
            "Azure",
            "Gitlab CI",
            "Jenkins",
            "Docker",
            "Kubernetes",
            "Eclipse",
            "IntelliJ",
            "Microsoft Visual Studio"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "C++",
            "Ruby",
            "Perl",
            "JavaScript",
            "NodeJS"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "related technical field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Columbia, MD",
        "job_id": 3952879984,
        "company": "Tenable",
        "title": "Research Engineer",
        "created_on": 1720587318.5923328,
        "description": "Who is Tenable? Tenable® is the Exposure Management company. 44,000 organizations around the globe rely on Tenable to understand and reduce cyber risk. Our global employees support 65 percent of the Fortune 500, 45 percent of the Global 2000, and large government agencies. Come be part of our journey! What makes Tenable such a great place to work? Ask a member of our team and they’ll answer, “Our people!” We work together to build and innovate best-in-class cybersecurity solutions for our customers; all while creating a culture of belonging, respect, and excellence where we can be our best selves. When you’re part of our #OneTenable team, you can expect to partner with some of the most talented and passionate people in the industry, and have the support and resources you need to do work that truly matters. We deliver results that exceed expectations and we win together! Your Role Tenable is looking for a Research Engineer to join our Solutions Engineering Team. This role will investigate potential solutions to Tenable challenges by organizing and presenting information about projects, collaborating with other Tenable organizations, determining the path forward, and developing solutions to the challenges we decide to pursue. Your Responsibility Contribute solutions to complex technical problems involving a wide range of technological knowledge. Contribute to process improvement to produce faster and/or better outcomes. Review current projects and understand the challenges that may need to be overcome for those projects to succeed. Develop in many different platform languages depending on the current task. Assess how secure a design may be when implemented. Collaborate with your team and other teams to produce clearly planned work. Provide documentation and training to other Tenable members so they can use the solutions provided. What You'll Need A curious mind that is eager to learn and interact with new ideas. A strong ability to communicate plans, ideas, and project details to involved members and key stakeholders. An ability to challenge ideas constructively. A solid understanding of the needs to architect and develop security products. A good grasp of many programming languages and concepts, such as object-oriented programming. Experience developing enterprise-level security products. Experience with developing protocols (examples: SSH, SSL, HTTP). Experience with multiple platforms (Windows, Linux, MacOS). And Ideally Experience developing in the NASL programming language. Skilled in presentation on complex topics. Training of peers on new concepts and processes. Skills to keep complex information organized and understandable. Knowledge about developing successful processes. This is the base pay range for this position. Compensation for the role will depend on a number of factors, including the candidate's qualifications, skills, competencies, location and experience, and may fall outside of the range shown. Employees are also eligible for variable compensation in addition to base pay (commission for sales roles, bonus for non-sales roles), depending on company and individual performance. Tenable also offers a variety of comprehensive and competitive benefits which include: medical, dental, vision, disability and life insurance; 401(k) retirement savings with company match; an employee stock purchase plan; an employee referral program; flexible spending accounts; an Employee Assistance Program (EAP); education assistance; parental leave; paid time off (PTO); company-paid holidays; health and wellness events; and community programs. US Pay Ranges $91,000—$121,000 USD If you’ve reached this point, and you’re still not sure if you should apply…..Just do it! We’re human and we don’t fit a perfect mold. Having diverse backgrounds, experiences and perspectives, that’s a good thing! If you’re coming from outside of the cyber industry - great! If you’re looking to try something new - awesome! All we ask is you bring passion to all that you do, crave creativity and innovation, and embrace the hard work of gaining new skills and accepting big challenges. We’re committed to promoting Equal Employment Opportunity (EEO) at Tenable - through all equal employment opportunity laws and regulations at the international, federal, state and local levels. If you need a reasonable accommodation due to a disability during the application or recruiting process, please contact Recruiting@Tenable.com for further assistance. Tenable Data Consent Statement Tenable is committed to protecting the privacy and security of your personal data. This Notice describes how we collect and use your personal data during and after your working relationship with us, in accordance with the General Data Protection Regulation (“GDPR”). Please click here to review. For California Residents: The California Consumer Privacy Act (CCPA) requires that Tenable advise you of certain rights related to the collection of your private information. Please click here to review.",
        "url": "https://www.linkedin.com/jobs/view/3952879984",
        "summary": "Tenable, the Exposure Management company, is seeking a Research Engineer to join their Solutions Engineering Team. This role will involve investigating solutions for Tenable challenges, collaborating with other teams, developing solutions, and contributing to process improvement. The ideal candidate will have a curious mind, strong communication skills, a solid understanding of security product architecture and development, experience with various programming languages and concepts, and experience developing enterprise-level security products, protocols (SSH, SSL, HTTP), and across multiple platforms (Windows, Linux, MacOS).",
        "industries": [
            "Cybersecurity",
            "Information Technology",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Creativity",
            "Innovation",
            "Teamwork",
            "Organization",
            "Presentation",
            "Training"
        ],
        "hard_skills": [
            "Object-Oriented Programming",
            "Security Product Development",
            "Protocol Development",
            "SSH",
            "SSL",
            "HTTP",
            "Windows",
            "Linux",
            "MacOS",
            "NASL"
        ],
        "tech_stack": [
            "Security Products",
            "Protocols",
            "Enterprise-Level Software Development",
            "NASL"
        ],
        "programming_languages": [
            "NASL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 121000,
            "min": 91000
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Disability Insurance",
            "Life Insurance",
            "401k",
            "Company Match",
            "Employee Stock Purchase Plan",
            "Employee Referral Program",
            "Flexible Spending Accounts",
            "Employee Assistance Program (EAP)",
            "Education Assistance",
            "Parental Leave",
            "Paid Time Off (PTO)",
            "Company-Paid Holidays",
            "Health and Wellness Events",
            "Community Programs"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Laurel, MD",
        "job_id": 3711916748,
        "company": "The Johns Hopkins University Applied Physics Laboratory",
        "title": "2024 PhD Graduate - AI/ML Data Scientist/Engineer - Analytic Capabilities",
        "created_on": 1720587323.4594662,
        "description": "Description Are you searching for a place to build upon the foundation of your academic work? Are you searching for engaging work with an employer that prioritizes impact, innovation, and personal development? Are you motivated to apply your skills within a vibrant intellectual community? If so, we're looking for someone like you to join our team at APL! We are seeking recent college graduates to help us tackle the complex research, engineering, and analytical problems that present critical challenges to our nation. Our group is currently making critical contributions in the fight against online misinformation and development of the first truly autonomous UAV. Our work on the public health response to the COVID-19 pandemic was recognized by Time Magazine as one of the \"Best Inventions of 2020\". To address these emerging national challenges, we design and develop software systems that leverage the potential of data science, generative AI, large language models, and artificial intelligence across various domains, including social media analysis, healthcare, climate monitoring, cybersecurity, and signal & image processing. As a member of our team you will... Collaborate with dedicated colleagues in developing solutions that align with national priorities. Harness your expertise in areas such as Artificial Intelligence, Machine Learning, Data Science, Cybersecurity, Software Engineering & DevOps, Signal and Image Processing, and Mathematics. Qualifications You meet our minimum qualifications for the job if you... Have a PhD in Computer Science, Mathematics, Engineering, or related technical field. Have maintained a minimum 3.0/4.0 GPA Are able to obtain a Top Secret level security clearance. If selected, a government security clearance investigation will need to be conducted and the requirements met for access to classified information. Eligibility requirements include U.S. citizenship. Why work at APL? The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation’s most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates. At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL’s campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers. About Us APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law. APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.",
        "url": "https://www.linkedin.com/jobs/view/3711916748",
        "summary": "The Johns Hopkins University Applied Physics Laboratory (APL) is seeking recent college graduates with PhDs in Computer Science, Mathematics, Engineering, or related fields to work on projects related to national security, space, and science. The work involves developing software systems that leverage data science, generative AI, large language models, and artificial intelligence. The role involves collaborating with colleagues to develop solutions that align with national priorities and harness expertise in areas such as Artificial Intelligence, Machine Learning, Data Science, Cybersecurity, Software Engineering & DevOps, Signal and Image Processing, and Mathematics.",
        "industries": [
            "Defense",
            "Security",
            "Space",
            "Science",
            "Research",
            "Engineering",
            "Data Science",
            "Artificial Intelligence",
            "Software Development",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Critical Thinking",
            "Innovation",
            "Teamwork",
            "Adaptability"
        ],
        "hard_skills": [
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science",
            "Cybersecurity",
            "Software Engineering",
            "DevOps",
            "Signal Processing",
            "Image Processing",
            "Mathematics"
        ],
        "tech_stack": [
            "Data Science",
            "Generative AI",
            "Large Language Models",
            "Artificial Intelligence",
            "Social Media Analysis",
            "Healthcare",
            "Climate Monitoring",
            "Cybersecurity",
            "Signal & Image Processing"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Engineering",
                "Related Technical Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Education Assistance Program",
            "Retirement Contributions",
            "Work/Life Balance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3959388528,
        "company": "Noblis",
        "title": "Applications Developer (All Levels)",
        "created_on": 1720587324.976179,
        "description": "Responsibilities Noblis is seeking a technical thinker and doer to work as a Applications Developer within a highly dynamic and impactful operating environment located in McLean, VA. The Applications Developer Will Design, develop and maintain software applications and/or databases Develop formal user requirements for Sponsor consideration Translate user requirements into end-to-end design for applications/databases that may involve multiple interfaces to other applications/supporting database systems Write interfaces to other applications or databases Conduct unit/functional testing Design and develop application layout and user interface Design, code and debug web applications; design and maintain interactive web databases and web services; design graphics and user interfaces Analyze, design, implement and maintain the database applications and structures Develop, test, implement and maintain complex applications and/or databa.ses Organize content, develop color schemes, design and produce graphics Transition data from legacy systems to new database structures Transition application/database to production; enhance application/database Write code Track and resolve programming bugs Required Qualifications Active TS/SCI with Polygraph. Demonstrated experience with application design and development, and associated practices to implement/transition applications into enterprise architectures. Demonstrated experience working with IC Agencies. Knowledge of IC systems, processes, data, and policies. Knowledge and application of agile techniques and methodologies. Experience mentoring or training (through formal or informal means) members of the team on applications architecting. Maintain one or more certifications in specific languages, systems, or technologies. Skill Levels Senior Expert (SME): Bachelor’s Degree in associated field and 14+ years of relevant experience; Master’s Degree in associated field and 11+ years of relevant experience; PhD and 10+years of relevant experience. Compensatoin $151,700 - $237,050 Expert: Bachelor’s Degree in associated field and has 10+ years of relevant experience; Master’s Degree and 9+ years of relevant experience; PhD and 8+ years of relevant experience. Compensation $125,500 - $196,075 Senior: Bachelor’s Degree in associated field and has 6+ years of relevant experience; Master’s Degree and 5+ years of relevant experience; PhD and 4+ years of relevant experience. Compensation $114,100 - $178,300 Junior: Bachelor’s Degree in associated field and 1+ years of relevant experience. Compensation $70,800 - $133,750 Desired Qualifications Strong communication skills, written and verbal. Overview Noblis and our wholly owned subsidiaries, Noblis ESI , and Noblis MSD tackle the nation's toughest problems and apply advanced solutions to our clients' most critical missions. We bring the best of scientific thought, management, and engineering expertise together in an environment of independence and objectivity to deliver enduring impact on federal missions. Noblis works with a wide range of government clients in the defense, intelligence and federal civil sectors. Learn more at Noblis -About Us Why work at a Noblis company? Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public. Noblis has won numerous workplace awards . Noblis maintains a drug-free workplace. Salary Range Explanation At Noblis we recognize and reward your contributions, provide you with growth opportunities, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, and work-life programs. Our award programs acknowledge employees for exceptional performance and superior demonstration of our service standards. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in our benefit programs. Other offerings may be provided for employees not within this category. We encourage you to learn more about our total benefits by visiting the Benefits page on our Careers site. Salary at Noblis is determined by various factors, including but not limited to, the combination of education, certifications, knowledge, skills, competencies, and experience, internal and external equity, location, and clearance level, as well as contract-specific affordability and organizational requirements and applicable employment laws. The projected compensation range for this position is provided within the posting and are based on full time status. Part time staff receive a prorated salary based on regularly scheduled hours. The estimated minimum and maximum displayed represents the broadest range for this position (inclusive of high geographic and high clearance requirements), and is just one component of Noblis’ total compensation package for employees. Posted Salary Range USD $70,800.00 - USD $237,050.00 /Yr. Equal Employment Opportunity Noblis is an Equal Opportunity Employer. Employment decisions are made without regard to race (as well as because of or on the basis of traits historically associated with race, including hair texture, hair type, and protective hairstyles such as braids, locks, and twists), color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, pregnancy, childbirth, lactation and related medical conditions, genetic factors, military/veteran status, or other characteristics protected by law. Noblis is committed to the full inclusion of all qualified individuals. As part of this commitment, Noblis will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact employee-relations@noblis.org .",
        "url": "https://www.linkedin.com/jobs/view/3959388528",
        "summary": "Noblis is seeking a technical thinker and doer to work as a Applications Developer in McLean, VA. The position involves designing, developing, and maintaining software applications and databases, translating user requirements into design, writing interfaces, conducting testing, and transitioning applications/databases to production. The ideal candidate will have experience in application design and development, working with IC Agencies, and knowledge of IC systems, processes, data, and policies. Strong communication skills are required. The salary range is $70,800 - $237,050 per year.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Intelligence"
        ],
        "soft_skills": [
            "Technical Thinking",
            "Communication",
            "Teamwork",
            "Mentoring",
            "Training",
            "Problem Solving",
            "Analytical"
        ],
        "hard_skills": [
            "Application Design",
            "Application Development",
            "Database Design",
            "Database Development",
            "Software Development",
            "Unit Testing",
            "Functional Testing",
            "User Interface Design",
            "Web Application Development",
            "Web Database Development",
            "Web Services",
            "Graphics Design",
            "Data Transition",
            "Legacy Systems",
            "Agile Methodologies",
            "IC Systems",
            "IC Processes",
            "IC Data",
            "IC Policies",
            "Bug Tracking",
            "Bug Resolution"
        ],
        "tech_stack": [
            "Agile"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Computer Science",
                "Information Technology",
                "Engineering"
            ]
        },
        "salary": {
            "max": 237050,
            "min": 70800
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Award Programs",
            "Drug-Free Workplace"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3944802117,
        "company": "Bcore",
        "title": "Software Developer",
        "created_on": 1720587328.192263,
        "description": "McLean,VA TS/SCI with Poly Bridge Core provides high energy, unified teams; technology integration experience; and innovative approaches, to enable our clients’ mission. We enable our clients’ mission by integrating innovative technologies and implementing adoption processes that modernize the digital workplace. Our trusted, skilled, and diverse team members are making a lasting impact by building tailored, client focused solutions. Do you want to join a team that is building tailored technical solutions to modernize our government’s mission and our client’s business? Do you have a desire to change how people work? Are you interested in helping to protect our nation’s cyber interests? Join our growing team supporting the government agencies in its mission as a Software Developer in McLean , Virginia . Required Qualifications Demonstrated professional experience in the development, customization, and use of developing applications for intelligence analysis. Demonstrated professional experience using Python, JavaScript, and PostgreSQL stack. Demonstrated experience with CSS, HTML, or web based development. Demonstrated professional experience using containerization such as Docker or developing and deploying containerized applications and databases. Demonstrated experience with user-centered design principles and practices, web standards, typography and color, and web usability standards. Demonstrated experience using Git for versioning. Desired Qualifications Demonstrated experience with Full Stack Development in Sponsor’s cloud environment. Demonstrated familiarity with the Sponsor’s data environment. Demonstrated experience working in a Sponsor analytic mission area, specifically involving research on analyst user needs. Demonstrated experience organizing and structuring solutions to complex problems. Demonstrated strong coordination and collaboration skills. Bridge Core is proud to be an equal opportunity workplace and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all team members and applicants. At Bridge Core, we ensure fair treatment for our team members and applicants based on their abilities, achievements and experience without regard to race, national origin, sex, age, disability, veteran status, sexual orientation, gender identity or any other classification protected by law. Bridge Core does not have a vaccination mandate applicable to team members. Vaccination requirements will depend on the status of the federal contractor mandate and customer site requirements. Regardless of vaccination status , personnel are required to wear masks while indoors when the CDC COVID-19 Community Level is High.",
        "url": "https://www.linkedin.com/jobs/view/3944802117",
        "summary": "Bridge Core seeks a Software Developer to develop, customize, and deploy applications for intelligence analysis.  The ideal candidate will have experience with Python, JavaScript, PostgreSQL, Docker, CSS, HTML, Git, and user-centered design principles.  Experience with Full Stack Development, the Sponsor's data environment, analytic mission area, research on analyst user needs, and strong collaboration skills are highly desired.  This role is located in McLean, Virginia and requires TS/SCI with Polygraph clearance.",
        "industries": [
            "Information Technology",
            "Government",
            "Intelligence",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Collaboration",
            "Problem Solving",
            "Organization",
            "Communication",
            "User-Centric Design"
        ],
        "hard_skills": [
            "Python",
            "JavaScript",
            "PostgreSQL",
            "Docker",
            "CSS",
            "HTML",
            "Git"
        ],
        "tech_stack": [
            "Python",
            "JavaScript",
            "PostgreSQL",
            "Docker",
            "CSS",
            "HTML",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "JavaScript"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3910561851,
        "company": "ClearanceJobs",
        "title": "Data Scientist AI/ML with Security Clearance",
        "created_on": 1720587331.2750518,
        "description": "Title: Data Scientist AI/ML Location: Tysons, VA Clearance: Active TS/SCI w/ Polygraph needed to apply Company Overview: Cornerstone Defense is the Employer of Choice within the Intelligence, Defense, and Space communities of the U.S. Government. Realizing early on that our most prized assets are our employees, we continually focus our attention on improving the overall work/life experience they have supporting the mission. Our Team is pushed every day to use their industry leading knowledge to provide end-to-end solutions to combat our nation's toughest and most secure problems. If you are looking for a place to not only be professionally challenged, but encouraged and supported by a company that cares, don't look any further than Cornerstone Defense. Highly visible position - Provide data science solutions to a variety of high-profile requirements as the continued success will require the creation of increasingly more sophisticated application of AI/ML capabilities to quickly identify actionable information. Mandatory Skills Demonstrated experience as a Data Scientist. Demonstrated experience with machine learning methods, techniques and algorithms for natural language processing (NLP), computer vision (CV), and deep learning/deep neural networks. Demonstrated experience in handling imperfection in data. Demonstrated experience with statistical programming languages such as R, SQL, and Python. Demonstrated experience with data visualization tools such as Tableau. Demonstrated experience in documenting data science work, participating in peer reviews and adhering to data science tradecraft best practices. Demonstrated experience with data science tools. Demonstrated experience with a problem-solving aptitude. Optional Skills Demonstrated experience with the Sponsor's workflow and research application. Demonstrated experience using JIRA, Confluence and SharePoint. Demonstrated experience working in a team environment. Demonstrated experience briefing technical topics to a non-technical audience. Demonstrated experience in strong oral and written communication skills. Demonstrated experience in strong leadership ability and experience juggling competing priorities.",
        "url": "https://www.linkedin.com/jobs/view/3910561851",
        "summary": "Data Scientist with AI/ML expertise needed for a highly visible role at Cornerstone Defense, providing data science solutions to high-profile requirements. The position involves applying AI/ML capabilities to extract actionable information from data, requiring expertise in NLP, CV, deep learning, data handling, statistical programming, data visualization, and documentation. Experience with the Sponsor's workflow and research application, as well as strong communication and leadership skills are desirable.",
        "industries": [
            "Defense",
            "Intelligence",
            "Space"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Leadership",
            "Teamwork"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Natural Language Processing",
            "Computer Vision",
            "Deep Learning",
            "Deep Neural Networks",
            "Data Handling",
            "Statistical Programming",
            "R",
            "SQL",
            "Python",
            "Data Visualization",
            "Tableau",
            "Documentation",
            "Data Science Tools",
            "JIRA",
            "Confluence",
            "SharePoint",
            "Briefing"
        ],
        "tech_stack": [
            "AI/ML",
            "NLP",
            "CV",
            "Deep Learning",
            "Deep Neural Networks",
            "R",
            "SQL",
            "Python",
            "Tableau",
            "JIRA",
            "Confluence",
            "SharePoint"
        ],
        "programming_languages": [
            "R",
            "SQL",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3960556280,
        "company": "The George Washington University",
        "title": "Research Scientist",
        "created_on": 1720587334.034494,
        "description": "Posting Details I. DEPARTMENT INFORMATION Job Description Summary The Watkins’ lab at George Washington University is seeking an energetic, motivated individual to join our team and lead our Protein Biochemistry and Biophysics work. The Research Scientist will be expected to design/engineer proteins and carry out purification and biophysical/functional characterization of tagged and untagged proteins. These engineered antigens and antibodies will need to be expressed in either mammalian or bacterial systems. This position is responsible for planning, conducting and supervising research at a high level, by designing and conducting experiments in a controlled laboratory setting. Using extensive experience and judgment, this role will plan independent research, analyze and interpret data, publish results, represent the university at conferences and meetings, develop new theories and methodologies, and will lead and direct the work of lower level research staff, while transferring technical expertise. Responsibilities include: Performs high-through put screens for protein function, interaction, and expression. Engineers proteins via directed evolution for a next generation protein sequencing platform and develops novel biochemical and molecular assays. Conducts protein-ligand mechanistic studies and characterization is desired (e.g. ELISA , SPR , Octet, SEC - MALS , MST , NanoDSF). Performs protein engineering, production, and purification from E. coli, insect cell, and mammalian expression systems. Performs other related duties as assigned. The omission of specific duties does not preclude the supervisor from assigning duties that are logically related to the position. Minimum Qualifications Qualified candidates will hold a Master’s degree plus 5 years of experience or a PhD plus 2 years of experience in a related discipline to include at least 2 years of research and/or college level teaching in a field basic to the work to be performed. Degree must be conferred by the start date of the position. Preferred Qualifications Additional Required Licenses/Certifications/Posting Specific Minimum Qualifications: Proficiency in a structural imaging program (eg. PyMOL). Experience in microbiology, biochemistry or biophysics. Proficiency in a structural imaging program (eg. PyMOL). Clarity in communication as well as flexibility to adjust to a dynamic, high-paced research environment with shifting priories and deadlines. . Familiarity with a variety of expression systems, protein structures and common characteristics. Knowledge of AKTA instrumentation and a broad range of purification techniques (affinity chromatography, ion exchange, size exclusion, mixed mode) Experience with different protein purification approaches such as affinity (His-tag, Fc-fusion), cation- and anion-exchange, size-exclusion chromatography ( SEC ). Experience with protein characterization techniques, such as SDS - PAGE and Western Blot. Hiring Range $89,266.88 - $130,317.91 GW Staff Approach to Pay How is pay for new employees determined at GW? Healthcare Benefits GW offers a comprehensive benefit package that includes medical, dental, vision, life & disability insurance, time off & leave, retirement savings, tuition, well-being and various voluntary benefits. For program details and eligibility, please visit https://hr.gwu.edu/benefits-programs. II. POSITION INFORMATION Campus Location: Foggy Bottom, Washington, D.C. College/School/Department: School of Medicine and Health Sciences (SMHS) Family Research and Labs Sub-Family Field Research Stream Individual Contributor Level Level 4 Full-Time/Part-Time Hours Per Week: 40 Work Schedule: Monday through Friday, 8:30am - 5:00pm Will this job require the employee to work on site? Yes Employee Onsite Status On-campus (in person) Telework: No Required Background Check Criminal History Screening, Education/Degree/Certifications Verification, Social Security Number Trace, and Sex Offender Registry Search Special Instructions To Applicants Employer will not sponsor for employment Visa status Internal Applicants Only? No Posting Number: R001698 Job Open Date: 06/27/2024 Job Close Date If temporary, grant funded or limited term appointment, position funded until: Background Screening Successful Completion of a Background Screening will be required as a condition of hire. EEO Statement The university is an Equal Employment Opportunity/Affirmative Action employer that does not unlawfully discriminate in any of its programs or activities on the basis of race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, gender identity or expression, or on any other basis prohibited by applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3960556280",
        "summary": "The Watkins' lab at George Washington University seeks a Research Scientist to lead protein biochemistry and biophysics work. Responsibilities include designing/engineering proteins, purification, and biophysical/functional characterization. The ideal candidate will have experience with mammalian and bacterial expression systems, protein-ligand mechanistic studies, and a range of protein characterization techniques.",
        "industries": [
            "Biotechnology",
            "Pharmaceutical",
            "Research",
            "Academic"
        ],
        "soft_skills": [
            "Energetic",
            "Motivated",
            "Communication",
            "Flexibility",
            "Leadership"
        ],
        "hard_skills": [
            "Protein Engineering",
            "Protein Purification",
            "Biophysical Characterization",
            "Directed Evolution",
            "Protein Sequencing",
            "Biochemical Assays",
            "ELISA",
            "SPR",
            "Octet",
            "SEC-MALS",
            "MST",
            "NanoDSF",
            "Microbiology",
            "Biochemistry",
            "Biophysics",
            "PyMOL",
            "AKTA Instrumentation",
            "Affinity Chromatography",
            "Ion Exchange",
            "Size Exclusion",
            "Mixed Mode Chromatography",
            "SDS-PAGE",
            "Western Blot"
        ],
        "tech_stack": [
            "PyMOL",
            "AKTA Instrumentation",
            "ELISA",
            "SPR",
            "Octet",
            "SEC-MALS",
            "MST",
            "NanoDSF"
        ],
        "programming_languages": [],
        "experience": 5,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Biochemistry",
                "Biophysics",
                "Related discipline"
            ]
        },
        "salary": {
            "max": 130317,
            "min": 89266
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Life & Disability Insurance",
            "Time Off & Leave",
            "Retirement Savings",
            "Tuition",
            "Well-being",
            "Voluntary Benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3941882741,
        "company": "Deloitte",
        "title": "Biomedical Data Science / Bioinformatics | Python, R, SQL | Clearance Req. | Washington DC",
        "created_on": 1720587338.0018826,
        "description": "In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace. Work you'll do The Bioinformatics Data Specialist will work closely with our team of senior bioinformaticians and epidemiologists on projects within our Federal Health sector. In this role, you will be responsible for: Managing and analyzing large databases. Data manipulation, algorithmic implementation, statistical programming, and integrated analyses. Installing, troubleshooting and running analytical pipelines using open-source and commercial scientific software on Unix/Linux and Cloud-hosted platforms, and using publicly available databases and tools. The team Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise. The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights. Qualifications Required: 2+ years of experience with Biomedical Data Science and/or Bioinformatics 2+ years of experience with analysis packages and programming languages such as R, Python, SPSS, SQL, and SAS 2+ years of experience with scientific research methods as applied to quantitative data analysis 2+ years of government or management consulting experience in the federal health sector Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future Masters degree in Biomedical Sciences, Computer Science, Engineering, Mathematics or other health-related field Active Public Trust Security clearance or higher Preferred: PhD in Biomedical Sciences, Computer Science, Engineering, Mathematics or other health-related field Active government security clearance Prior government consulting experience Strong problem solving and troubleshooting skills with experience exercising mature judgment The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $88,800 to $148,000. Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html #engcamp2024",
        "url": "https://www.linkedin.com/jobs/view/3941882741",
        "summary": "Deloitte is seeking a Bioinformatics Data Specialist to join their Government and Public Services (GPS) practice. The role involves managing and analyzing large databases, implementing algorithms, performing statistical programming, and running analytical pipelines using open-source and commercial scientific software.  The ideal candidate will have experience in Biomedical Data Science, Bioinformatics, and working with various analysis packages and programming languages.  A Master's degree in a relevant field and active Public Trust Security clearance are required.",
        "industries": [
            "Government",
            "Public Services",
            "Federal Health",
            "Biomedical",
            "Bioinformatics",
            "Data Science"
        ],
        "soft_skills": [
            "Problem Solving",
            "Troubleshooting",
            "Mature Judgement"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Manipulation",
            "Algorithmic Implementation",
            "Statistical Programming",
            "Unix/Linux",
            "Cloud Platforms",
            "Open Source Software",
            "Commercial Scientific Software",
            "R",
            "Python",
            "SPSS",
            "SQL",
            "SAS"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SPSS",
            "SQL",
            "SAS",
            "Unix/Linux",
            "Cloud Platforms"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL",
            "SAS"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Biomedical Sciences",
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Health-Related Fields"
            ]
        },
        "salary": {
            "max": 148000,
            "min": 88800
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3912157516,
        "company": "ICR, Inc.",
        "title": "Junior Software Developer Engineer - Fairfax",
        "created_on": 1720587339.7872138,
        "description": "Junior Software Development Engineer Fairfax, VA Applications will be accepted on an ongoing basis. Key Responsibilities: ICR is seeking software developers to grow our teams dedicated to building our government customers mission critical systems. We are seeking talented engineers skilled in building, testing, designing, and enhancing software applications across our diverse portfolio of projects and partners. Candidates should possess strong technical expertise in one or more programming languages and be familiar with agile development methodologies. Ideal candidates will also demonstrate a commitment to collaborative problem solving, sophisticated design, and quality is essential. You will work closely with other engineers to create software that is both innovative and reliable, supporting complex operations and meeting stringent customer standards. Required Skills and Experience: Bachelor’s degree in a STEM (Science, Technology, Engineering, and Math) field. Active Top Secret security clearance with SCI eligibility. 1+ years of non-internship professional software development experience. 1+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience. Experience programming with at least one software programming language. Desirable Skills and Experience: 1+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience. Salary Range: $110,000 - $140,000 This position offers a comprehensive benefits package that includes company equity, retirement plan, company-paid health care benefits, a flexible paid time off policy, and opportunity for a raise and bonus during the year. ICR, Inc. considers several factors when extending job offers, including but not limited to candidates’ key skills, relevant work and/or military experience, education, training, certifications, and work location.",
        "url": "https://www.linkedin.com/jobs/view/3912157516",
        "summary": "ICR is seeking software developers to build mission critical systems for government clients. The ideal candidate has 1+ years of professional software development experience, strong technical expertise in one or more programming languages, and is familiar with agile development methodologies. They will work closely with other engineers to create software that is both innovative and reliable.",
        "industries": [
            "Information Technology",
            "Government",
            "Software Development",
            "Defense",
            "Security"
        ],
        "soft_skills": [
            "Problem Solving",
            "Collaboration",
            "Design",
            "Quality Focus",
            "Innovation",
            "Reliability"
        ],
        "hard_skills": [
            "Agile Development",
            "Software Development",
            "Programming Languages",
            "Design Patterns",
            "Reliability",
            "Scaling",
            "Code Standards",
            "Code Reviews",
            "Source Control Management",
            "Build Processes",
            "Testing",
            "Operations"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Science",
                "Technology",
                "Engineering",
                "Math"
            ]
        },
        "salary": {
            "max": 140000,
            "min": 110000
        },
        "benefits": [
            "Equity",
            "Retirement Plan",
            "Health Insurance",
            "Paid Time Off",
            "Raise",
            "Bonus"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3926569532,
        "company": "Intelliforce-IT Solutions Group, LLC.",
        "title": "Software Engineer",
        "created_on": 1720587341.2446418,
        "description": "To be considered for this opportunity you will need to possess an active TS/SCI with polygraph. We regret that we do not have the ability to assist you with gaining clearance at this time. Are you a cleared software engineer looking for a company that understands employees are its most valuable resources? Join our Best Workplace winning company that offers excellent perks, all designed to support the needs of you and your family! Overview: Intelliforce is seeking a full stack Java Developer needed to help develop, maintain, and enhance diverse software systems. Some hybrid options may be available. Desired Skills: Experience with C, C++, Python, Ruby, Perl, Javascript Nice to have experience developing with Java in a Linux environment Familiar with Apache NIFI Ability to work in a team environment Qualifications: TS/SCI with polygraph is required B.S. Degree in Computer Science or related discipline from an accredited university/college in needed. Five (5 )additional years as a software developer experience may be substituted for the B.S degree Who Is Intelliforce-ITSG We are an Intelligent Force of Engineers providing solutions to complicated problems. We are people driven and motivated to provide you with an excellent work life balance. Offering all employees clear expectations, professional development, and social connections. Benefits We host a variety of fun employee and family events throughout the year to say thanks for all that you do to make Intelliforce a phenomenal place to work Competitive salary Health, Dental, and Vision Insurance plans Quality of life differential We offer a 401(k) Profit Sharing Plan that offers a powerful way to enhance your long- term financial well-being by investing in yourself Ample Paid Time Off Paid Training and Education! Don't see a fit but know someone who might be? Intelliforce offers an external referral bonus to all qualified hires. Powered by JazzHR 8z1OZq5IKP",
        "url": "https://www.linkedin.com/jobs/view/3926569532",
        "summary": "Intelliforce is seeking a full-stack Java Developer with TS/SCI with polygraph clearance to develop, maintain, and enhance software systems. The ideal candidate will have experience with C, C++, Python, Ruby, Perl, Javascript and familiarity with Apache NIFI.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Engineering",
            "Defense",
            "Government",
            "Intelligence"
        ],
        "soft_skills": [
            "Teamwork",
            "Communication",
            "Problem Solving",
            "Self-Motivation"
        ],
        "hard_skills": [
            "Java",
            "C",
            "C++",
            "Python",
            "Ruby",
            "Perl",
            "Javascript",
            "Apache NIFI",
            "Linux"
        ],
        "tech_stack": [
            "Java",
            "Apache NIFI",
            "Linux"
        ],
        "programming_languages": [
            "Java",
            "C",
            "C++",
            "Python",
            "Ruby",
            "Perl",
            "Javascript"
        ],
        "experience": 5,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Computer Science",
                "Related Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "Health, Dental, and Vision Insurance plans",
            "Quality of life differential",
            "401(k) Profit Sharing Plan",
            "Ample Paid Time Off",
            "Paid Training and Education",
            "Employee and Family Events",
            "Referral bonus"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3962617367,
        "company": "GeoYeti, a division of Bcore",
        "title": "Senior Geospatial Data Scientist",
        "created_on": 1720587342.764151,
        "description": "GeoYeti focuses on advanced analytics, data science, development of the applications that support such work. We seek a Senior Geospatial Data Scientist to support a client in Reston, VA . We support a broad range of IC and DoD clients, though a common theme across our portfolio is that our team members, regardless of their role, interact with the end users around the globe. GeoYeti offers competitive pay, a sign-on or relo bonus, and amazing benefits, to include up to 10 percent company contribution into your 401k; 100 percent company paid premiums for medical (to include 100 percent of your medical deductible), dental, vision, life, and short- and long-term disabilities; tuition reimbursement; gym stipend; commuter stipend ($10/day after tax); automatic enrollment in the GeoYeti 360 Bonus Program; and many others. Identify corollary datasets to compare against model outputs, especially those with which were unlikely used as part of the training set. Assist in the evaluation of the effectiveness of ML models. Minimum Top Secret clearance required to start; active TS/SCI preferred. Expert level understanding of Python, including geospatial libraries like Fiona and Shapely. Expert level understanding of spatial data storage formats such as ESRI GeoDatabases, shapefiles, GeoPackage, and text-based storage in spatial databases such as PostGIS. Ideally an understanding of storage formats and methodologies for ML models. GeoYeti is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. GeoYeti does not have a vaccination mandate applicable to team members. Vaccination requirements will depend on the status of the federal contractor mandate and customer site requirements. Regardless of vaccination status , personnel are required to wear masks while indoors when the CDC COVID-19 Community Level is High.",
        "url": "https://www.linkedin.com/jobs/view/3962617367",
        "summary": "GeoYeti seeks a Senior Geospatial Data Scientist with expert knowledge of Python, geospatial libraries (Fiona, Shapely), and spatial data formats (ESRI GeoDatabases, shapefiles, GeoPackage, PostGIS). Responsibilities include identifying corollary datasets, evaluating ML models, and contributing to advanced analytics and data science projects.  Top Secret clearance is required, with TS/SCI preferred.",
        "industries": [
            "Data Science",
            "Analytics",
            "Geospatial Intelligence",
            "Defense",
            "Intelligence Community"
        ],
        "soft_skills": [
            "Problem Solving",
            "Analytical Skills",
            "Communication",
            "Collaboration",
            "Critical Thinking",
            "Research",
            "Evaluation"
        ],
        "hard_skills": [
            "Python",
            "Fiona",
            "Shapely",
            "ESRI GeoDatabases",
            "Shapefiles",
            "GeoPackage",
            "PostGIS",
            "Machine Learning",
            "Model Evaluation"
        ],
        "tech_stack": [
            "Python",
            "Fiona",
            "Shapely",
            "ESRI GeoDatabases",
            "Shapefiles",
            "GeoPackage",
            "PostGIS"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Pay",
            "Sign-on Bonus",
            "Relocation Bonus",
            "401k with Company Contribution",
            "Company Paid Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Life Insurance",
            "Short-Term Disability",
            "Long-Term Disability",
            "Tuition Reimbursement",
            "Gym Stipend",
            "Commuter Stipend",
            "Bonus Program"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3894362680,
        "company": "Motion Recruitment",
        "title": "Senior Data Scientist (Active Full-Scope Poly Required)",
        "created_on": 1720587346.5414827,
        "description": "A large federal consulting company in Washington, DC that just won a multi-year engagement is looking to add a Senior Data Scientist who can help with researching LLM and help implement them within their environment. Ideal candidates must have an active FSP and come from a Data Science background. Required Skills & Experience Active TS/SCI Full-Scope Poly Living In/Around the Greater Washington, DC Area The Offer Competitive Salary Full-Health Benefits You Will Receive The Following Benefits Medical Insurance Dental Benefits Vision Benefits Paid Time Off (PTO) 401(k) Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Posted By: Derek Progin",
        "url": "https://www.linkedin.com/jobs/view/3894362680",
        "summary": "A large federal consulting firm in Washington, DC is seeking a Senior Data Scientist with an active TS/SCI Full-Scope Poly clearance to research and implement Large Language Models (LLMs) within their environment. This multi-year engagement offers a competitive salary and full health benefits.",
        "industries": [
            "Consulting",
            "Federal Government"
        ],
        "soft_skills": [],
        "hard_skills": [
            "LLM",
            "Data Science"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental Benefits",
            "Vision Benefits",
            "Paid Time Off (PTO)",
            "401(k)"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3969335161,
        "company": "Banjo Health",
        "title": "Senior Engineer",
        "created_on": 1720587348.1477787,
        "description": "Job Highlights: Position Overview: We are currently seeking a remote Senior Engineer to support our continued growth and product development. We are looking for a candidate that can bring their expertise, experience, and perspective to the Banjo Health team, helping us build solutions that empower holistic and tangible transformation at every level. Who is Banjo Health? Banjo Health Inc. is a health industry solutions provider that helps customers navigate the ever-changing medical climate through Artificial Intelligence (AI). With deep technical expertise, Banjo Health is empowering enterprises to harness the full power of the cloud and emerging technologies such generative artificial intelligence, machine learning, and natural language processing through robust solutions and first-party cloud-based products. Banjo Health is uniquely comprised of technologists and clinicians who share a deep understanding of managed care market needs and the appropriate application of cloud technology + AI to solve the biggest burdens in healthcare. Banjo Health prides itself on providing a community and culture that allows for the sharing of ideas and thoughts no matter what position or rank. For more information on Banjo Health, please visit http://www.banjohealth.com. Qualifications: Analyze the business requirements of all departments to determine their technology needs. Inspect the use of technological equipment and software to ensure functionality and efficiency. Identify the need for upgrades, configurations or new systems and report to upper management. Collaborate with team members and other professionals to provide guidance. Help to organize IT-related projects. Analyze the costs, value, and risks of information technology to advise management and suggest actions. Building and maintaining complex front-end web applications utilizing JQuery and vanilla. JavaScript as needed. Extensive knowledge and expertise in designing, implementing, and testing highly scalable, performant, and fault-tolerant serverless and container-based apps executing in the cloud (AWS and Azure). Collaborates with the IT development team to build and catalog efficient, reusable, and secure microservices, standardized REST-based services, and web applications. Champion development of production-ready workflows that align with project initiatives. Translating designs and wireframes into high-quality code. Assist with creating/maintaining code repositories, CI/CD pipelines. Assist with testing automation. Research, analyze, and recommend technical approaches for solving challenging and complex logic and integration problems. Participate in code and design reviews to meet and exceed quality goals and standards. Accountable for completing assignments on time and within budget. Ask smart questions, take risks, and champion new ideas. Education Requirements: Bachelor in engineering or system architecture and/or commiserate experience. Required Licensure, Certification or Conditions of Employment: N/A. Competencies, Skills, And Attributes: Work experience as a senior engineer. Extensive experience with cloud technologies and modern human-computer interfaces. Leadership abilities with a strategic mind. Excellent project management skills. Advanced hands-on experience in the following: TypeScript, JavaScript, Node.js, Express.js, React, JQuery, HTML5, SASS/LESS. Advanced experience working with and integrating RESTful services, including microservices and service bus and API management gateways. Advanced experience working within a service-oriented, microservice architecture to establish event-driven service orchestrations. 5+ years of experience working within the AWS and Azure ecosystem including Lambda and Azure functions, Web Apps, Azure DevOps and Bitbucket, and MySQL, Azure SQL. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases including No-SQL. Advance knowledge working with security frameworks and standards such as NIST to develop robust security solutions. 7+ years building robust front end applications including SPA. 5+ years building and integrating with internal and external REST APIs. 5+ years of experience working within a development team utilizing agile methodologies. 4+ years of experience creating and maintaining optimal CI/CD pipelines for DevOps. Experience performing root cause analysis on internal and external processes and data to answer specific business questions and identify opportunities for improvement. Strong written and verbal skills, readily able to articulate ideas, processes, and applications to several different audiences. Has strong attention to detail with a quality control mindset. Strong critical thinking skills, outside-of-the-box thought leader. Experience using standard Agile tools and methodologies to control, track, and report to senior management on project/product health. Ability to diagnose and solve problems quickly. Ability to process design specifications and infer details that are not explicitly stated. JOB DISCLOSURES: Job Type: Full-time Work Authorization within the United States (Required). Location: Remote Work From Home (WFH) Position. The role may also include some minimal out of state travel. Role will primarily work during normal business hours based on their time zone location (ex., AZ Role during AZ MST time), but on occasion be expected to accommodate meetings with stakeholders in other time zones across the country. Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws. Delegation of I, II, or III is dependent on overall qualifications and used as a guide for promotions without elevation requirements to be a people leader, unless the candidate/employee aspires to be a leader as part of their career growth ladder. About Banjo Health: Our experienced team of engineers and clinicians have built our platform to reduce prior authorization inefficiencies for health plans, PBMs, employer groups, and providers by offering advanced solutions that benefit patient care from top to bottom. Our solutions use AI and cloud-based technologies to meet compliance regulations across all lines of business. About Banjo Health: Our experienced team of engineers and clinicians have built our platform to reduce prior authorization inefficiencies for health plans, PBMs, employer groups, and providers by offering advanced solutions that benefit patient care from top to bottom.Our solutions use AI and cloud-based technologies to meet compliance regulations across all lines of business.",
        "url": "https://www.linkedin.com/jobs/view/3969335161",
        "summary": "Banjo Health is seeking a remote Senior Engineer to support product development. The ideal candidate will have extensive experience in cloud technologies, modern human-computer interfaces, and building scalable, performant, and fault-tolerant applications. Responsibilities include analyzing business requirements, identifying technology needs, collaborating with team members, building complex front-end web applications, and working with cloud platforms like AWS and Azure.",
        "industries": [
            "Healthcare",
            "Health Technology",
            "Artificial Intelligence",
            "Software Development",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Leadership",
            "Strategic Thinking",
            "Project Management",
            "Communication",
            "Problem Solving",
            "Critical Thinking",
            "Attention to Detail",
            "Teamwork",
            "Collaboration",
            "Adaptability"
        ],
        "hard_skills": [
            "TypeScript",
            "JavaScript",
            "Node.js",
            "Express.js",
            "React",
            "JQuery",
            "HTML5",
            "SASS/LESS",
            "RESTful Services",
            "Microservices",
            "Service Bus",
            "API Management Gateways",
            "Service-Oriented Architecture",
            "Microservice Architecture",
            "Event-Driven Service Orchestrations",
            "AWS",
            "Azure",
            "Lambda",
            "Azure Functions",
            "Web Apps",
            "Azure DevOps",
            "Bitbucket",
            "MySQL",
            "Azure SQL",
            "SQL",
            "Relational Databases",
            "NoSQL",
            "Security Frameworks",
            "NIST",
            "SPA",
            "Agile Methodologies",
            "CI/CD",
            "Root Cause Analysis",
            "Agile Tools"
        ],
        "tech_stack": [
            "TypeScript",
            "JavaScript",
            "Node.js",
            "Express.js",
            "React",
            "JQuery",
            "HTML5",
            "SASS/LESS",
            "RESTful Services",
            "Microservices",
            "Service Bus",
            "API Management Gateways",
            "Service-Oriented Architecture",
            "Microservice Architecture",
            "Event-Driven Service Orchestrations",
            "AWS",
            "Azure",
            "Lambda",
            "Azure Functions",
            "Web Apps",
            "Azure DevOps",
            "Bitbucket",
            "MySQL",
            "Azure SQL",
            "SQL",
            "Relational Databases",
            "NoSQL",
            "Security Frameworks",
            "NIST"
        ],
        "programming_languages": [
            "TypeScript",
            "JavaScript",
            "SQL"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor",
            "fields": [
                "Engineering",
                "System Architecture"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Lorton, VA",
        "job_id": 3959232417,
        "company": "Systems Planning & Analysis",
        "title": "Data Scientist - Nuclear Tech Integration",
        "created_on": 1720587349.6657789,
        "description": "Overview Systems Planning and Analysis, Inc. (SPA) delivers high-impact, technical solutions to complex national security issues. With over 50 years of business expertise and consistent growth, we are known for continuous innovation for our government customers, in both the US and abroad. Our exceptionally talented team is highly collaborative in spirit and practice, producing Results that Matter. Come work with the best! We offer opportunity, unique challenges, and clear-sighted commitment to the mission. SPA: Objective. Responsive. Trusted. The Joint, Office of the Secretary of Defense, Interagency Division (JOID) provides expert support services to a range of customers spanning across the Department of Defense, Federal Civilian, and international markets. JOID provides a diverse portfolio of analytical and programmatic capabilities to help our customers make informed decisions on their most challenging issues. JOID assists the Defense Threat Reduction Agency (DTRA) in developing leading edge technologies to counter WMD in support of Combatant Commands (CCMDs) and transitioning these technologies to military services and Combatant Commanders (COCOMs). SPA provides expertise across the full range of chemical, biological, radiological, nuclear and high-yield explosives (CBRNE) WMD, Counter Improvised Threat and Countering Threat Network technologies to support understanding, detection, identification, characterization, denial, control, disabling, defeating, disposing, safeguarding the force, managing consequences, and test and evaluation in support of military and civilian operations. We have a near-term need for a Data Scientist to provide on-site support in Lorton, VA. Responsibilities The successful candidate will assist our customer in providing a data architecture capable of supporting scalable, highly available application solutions that leverage cloud native services; supporting the transformation of monolithic, legacy applications to a more modular, micro-services architecture; providing data architecture design, development and test knowledge and expertise with respect to cloud architecture, design patterns, and data analysis requirements; and defining data architectures that support both the enterprise and application level capabilities with systems and network security, scalability, fault tolerance and optimal performance. Responsibilities include supporting analysis and development of customer-driven technical data architectures and solutions; providing technical guidance to software development teams designing, developing and integrating a data-intensive application framework using modern data-centric enabling technologies, cloud computing and virtualization architecture; providing recommendations for technology implementations, application & data migration techniques and tools for the most efficient solution to meet mission needs, including present and future capacity requirements; supporting the transformation of monolithic, legacy applications to a more modular, micro-services architecture; analyzing and recommending approaches for making heterogeneous data sources broadly available for discover-ability and access to support a wide consumer-base, analytic needs, and use by diverse applications, services, and systems; and optimizing the management of data across nodes and the performance of distribution, search and retrieval. This will include evaluating new technology, reviewing existing technology and architecture patterns and practices, helping guide and estimate new feature development, architectural and development guardrails, and identifying ways to measure architecture maturity objectively, to include identifying performance bottle-necks and evaluating scaling benchmarks. 10-25% travel required. Qualifications Required: Bachelor's degree in engineering, data science, computer science, or related technical discipline and 4+ years of experience (or a MS degree + 2 years) Direct experience supporting data architecture and solution efforts and a demonstrated understanding of Systems Engineering and Acquisition processes Knowledge of and experience with DoD Architecture Framework (DoDAF) Experience with data compliance, data security, and modern data management approaches Experience transitioning legacy systems to cloud environment optimized applications Certification in agile software development methods (Scrum, SAFe) Familiarity developing applications that use containers, micro-services programming, and cloud services Working knowledge of programming language such as Python, SQL, R, etc. Must be able to work independently and complete tasking with minimum guidance and supervision Must have excellent interpersonal communication skills Strong working knowledge of Microsoft Office products and use of Teams Active DoD Secret clearance with ability to obtain a TS/SCI clearance Desired Active DoD TS/SCI Experience in Dev/Sec/Ops delivery of software capabilities Experience with DoD Command & Control (C2) networks (JADC2, IEW, etc.)",
        "url": "https://www.linkedin.com/jobs/view/3959232417",
        "summary": "Data Scientist to support customer in Lorton, VA, with a focus on data architecture and solutions, cloud native services, and transitioning legacy applications to microservices. The role involves technical guidance, technology recommendations, analysis of data sources, optimization of data management, and evaluation of new technologies.",
        "industries": [
            "Defense",
            "National Security",
            "Government",
            "Military",
            "Technology",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical",
            "Teamwork",
            "Leadership",
            "Collaboration",
            "Interpersonal",
            "Independent",
            "Self-motivated"
        ],
        "hard_skills": [
            "Data Architecture",
            "Cloud Native Services",
            "Microservices Architecture",
            "Data Analysis",
            "Cloud Computing",
            "Virtualization",
            "Data Management",
            "Data Compliance",
            "Data Security",
            "Systems Engineering",
            "Acquisition Processes",
            "DoDAF",
            "Agile Software Development",
            "Scrum",
            "SAFe",
            "Containers",
            "Microservices Programming",
            "Cloud Services",
            "Python",
            "SQL",
            "R",
            "Microsoft Office",
            "Teams"
        ],
        "tech_stack": [
            "DoDAF",
            "Cloud Native Services",
            "Microservices Architecture",
            "Cloud Computing",
            "Virtualization",
            "Containers",
            "Microservices Programming",
            "Cloud Services",
            "Python",
            "SQL",
            "R"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "R"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Engineering",
                "Data Science",
                "Computer Science",
                "Technical"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Columbia, MD",
        "job_id": 3909847610,
        "company": "Axient",
        "title": "Threat and Weapons System Engineer with ML/AI",
        "created_on": 1720587351.3530455,
        "description": "SEG is seeking a Threat and Weapons System Engineer with ML/AI t o be part of a systems analysis team providing technical contributions and analysis for U.S. Surface Navy (e.g. Aegis Baseline) programs and Missile Defense Agency (MDA) Ballistic Missile Defense System (BMDS) projects Responsibilities What you will do... Characterize sensor and missile performance against threat ballistic and cruise missiles through modeling, simulation and analysis using digital simulations and machine learning tools. Characterize sensitivities to threat variability Develop, integrate, and use analytical models and tools to test new threat data and software products, assess system capability, and drive system requirements and design Define technical approach and plan studies based on understanding of engineering community and appreciation of customer need Employ commercial machine learning tools to characterize large amounts data supporting analysis studies and model generation Travel anticipated at 5 percent of time or less Systems Group Overview Candidate will be part of a team responsible for weapon system simulation and performance analysis. The team develops and integrates individual system models for analysis (threats, weapons, sensors) to include multiple interacting systems. This team contributes to defining, leading and performing analyses for requirements feasibility, sensitivity studies for threat variability and fidelity, asset planning and what-if scenarios, flight-test mission (requirements, planning, and analysis) support and certification efforts. The group provides independent verification and validation support for internal system-level products. This offers opportunities to work with SEG sensors, vehicles, phenomenology products and engineers integrated within our simulation software development environment to view the battle environment scenes through the eyes of combat systems. The group includes subject matter experts and technical leads providing direct technical support to various defense programs as a contributing member of broad cross-functional and technical subject-specific integrated product teams. We bring threat and weapons knowledge together to support concept definition, threat driver assessments, system requirements, design reviews, test planning, and defining roadmaps for future development Required Qualifications Skills you will need... Ability to obtain and maintain a US DoD SECRET clearance Bachelor of Science Degree: Systems Engineering, Aerospace, Mechanical, Electrical, Physics or Applied Math. 5-10 years work experience Strong analytical skills Must demonstrate solid background and experience with MATLAB or Python Programming and scripting experience in a Linux environment Excellent written and oral communication Experience developing and presenting briefing material Desired Qualifications Active US DoD SECRET or TOP SECRET Security Clearance Master of Science or PhD degree preferred with relevant research project experience Experience with radar modeling Experience with machine learning tools including how to set-up, train, and generate results to inform analysis and support model design and development Experience working with C++ API and creating test drivers Self-starter – Demonstrate independent ownership of tasking. Position affords opportunity to define path and lead tasks based on technical understanding of engineering community and appreciation of customer needs Modeling and analysis experience and capability in one or more of the following areas: RF Sensors / EO-IR Imaging / Remote Sensing Systems – Signal Processing, Detection and Track Filtering Multi-Sensor Data Fusion, Target Classification and Discrimination (Machine Learning / AI applications) Missile Systems (Aerodynamic, Ballistic, Space) Defense Weapon System Performance (e.g. Navy Surface systems, Ballistic Missile Defense systems) Ground Test and Field Test Events (missile flight and sensor track pre-event prediction and post-mission assessment) Familiarity with version-control (Git), issue tracking (JIRA), collaboration software (Confluence), and cross-language software integration tools (SWIG) Familiarity with high-performance computing environments Knowledge of aerospace /defense systems technology domains Demonstrated experience working with Navy, Air Force, and DoD contractors in a software development environment Mathematical background in areas such as statistics, linear algebra, complex analysis, differential equations, Monte Carlo methods, numerical methods, and machine learning (ML) or artificial Intelligence (AI)",
        "url": "https://www.linkedin.com/jobs/view/3909847610",
        "summary": "SEG is seeking a Threat and Weapons System Engineer with ML/AI experience to join their systems analysis team. The role involves using modeling, simulation, and analysis techniques, including machine learning, to characterize sensor and missile performance against various threats. The candidate will develop and utilize analytical models and tools to assess system capabilities, drive requirements, and define technical approaches for studies. The position requires strong analytical skills, experience with MATLAB or Python, programming in a Linux environment, and excellent communication skills.",
        "industries": [
            "Defense",
            "Aerospace",
            "Military",
            "Engineering",
            "Software Development"
        ],
        "soft_skills": [
            "Analytical",
            "Communication",
            "Presentation",
            "Problem-solving",
            "Leadership",
            "Teamwork",
            "Self-starter",
            "Independent",
            "Time management",
            "Organizational"
        ],
        "hard_skills": [
            "MATLAB",
            "Python",
            "Linux",
            "Machine Learning",
            "Modeling",
            "Simulation",
            "Analysis",
            "Radar Modeling",
            "C++",
            "Git",
            "JIRA",
            "Confluence",
            "SWIG",
            "High-Performance Computing",
            "Statistics",
            "Linear Algebra",
            "Complex Analysis",
            "Differential Equations",
            "Monte Carlo Methods",
            "Numerical Methods"
        ],
        "tech_stack": [
            "MATLAB",
            "Python",
            "Linux",
            "Machine Learning",
            "C++",
            "Git",
            "JIRA",
            "Confluence",
            "SWIG",
            "High-Performance Computing"
        ],
        "programming_languages": [
            "MATLAB",
            "Python",
            "C++"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor of Science",
            "fields": [
                "Systems Engineering",
                "Aerospace",
                "Mechanical",
                "Electrical",
                "Physics",
                "Applied Math"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Travel"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Alexandria, VA",
        "job_id": 3966607500,
        "company": "American Academy of Otolaryngology",
        "title": "Application Developer",
        "created_on": 1720587352.8375747,
        "description": "Reporting Structure The Application Developer reports to the Senior Director, Information Technology. Qualifications Bachelor’s degree in computer science or a related field combined with Association experience. Must have 2-5 years of experience implementing, supporting, and developing solutions using the iMIS RiSE web engagement platform. Experience integrating commercial-off-the-shelf (COTS) packages into cohesive solutions a plus. Expertise in C#, SQL Server, SSRS, JavaScript, jQuery and the iMIS Forms Builder module beneficial. Must have strong project management skills, including requirements gathering and meetings facilitation skills. Must be able to work on concurrent tasks. Some travel may be required. Key Responsibilities Act as the primary technical resource for assigned development and integration projects. Participate in regular software maintenance and periodic system reviews. Ensure that all project and subsequent system documentation is completed and maintained for developed solutions per recognized Software Development Life Cycle (SDLC) or other best practices. Work collaboratively with other IT personnel to deliver solutions are well architected, developed, and documented. Capture all project requests and requirements, including functional and nonfunctional requirements. Assist in maintaining and troubleshooting of all existing websites, applications, and integrations. Keep skill levels up-to-date with latest coding trends, project management skills, and software development practices. Research, recommend, and implement new technologies where appropriate to enhance user experiences. Specific Duties Develop solutions primarily in the iMIS RiSE web engagement platform. Assist in testing custom applications and enhancements to web-based solutions. Develop web-based forms using the iMIS Form Builder module. Conduct needs analysis and fact finding for user requirements. Develop technical documentation and assist in end-user training, rollout, and support of new solutions. Assist in the development of back-office reports using SSRS, IQAs, or Report Writer. Utilize SDLC methodologies and best practices when developing software and web applications. Integrate open source and third-party applications into comprehensive user solutions. Consistently demonstrate courteous, cooperative and helpful behavior to all contacts and stakeholders; internal and external. Duties and responsibilities may be added, deleted, or changed at any time at the discretion of management, formally or informally, either orally or in writing.",
        "url": "https://www.linkedin.com/jobs/view/3966607500",
        "summary": "Application Developer will be responsible for developing and implementing solutions using the iMIS RiSE web engagement platform. This role requires 2-5 years of experience with iMIS RiSE, C#, SQL Server, SSRS, JavaScript, jQuery, and iMIS Forms Builder. The candidate will work on assigned development and integration projects, participate in system reviews, and ensure proper documentation. This role also requires strong project management skills and the ability to work on multiple tasks.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Web Development",
            "Association Management"
        ],
        "soft_skills": [
            "Project Management",
            "Requirements Gathering",
            "Meeting Facilitation",
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Documentation",
            "Technical Writing",
            "Training",
            "Troubleshooting",
            "Research",
            "Time Management",
            "Multitasking"
        ],
        "hard_skills": [
            "iMIS RiSE",
            "C#",
            "SQL Server",
            "SSRS",
            "JavaScript",
            "jQuery",
            "iMIS Forms Builder",
            "SDLC",
            "Open Source Integration",
            "Third-Party Application Integration",
            "Needs Analysis",
            "Fact Finding",
            "Technical Documentation",
            "End-User Training"
        ],
        "tech_stack": [
            "iMIS RiSE",
            "C#",
            "SQL Server",
            "SSRS",
            "JavaScript",
            "jQuery",
            "iMIS Forms Builder"
        ],
        "programming_languages": [
            "C#",
            "JavaScript",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3946213068,
        "company": "CyberCoders",
        "title": "Software Test Engineer (TS/SCI Full Scope Poly)",
        "created_on": 1720587354.2434433,
        "description": "Job Title: Software Test Engineer (TS/SCI Full Scope Poly) Location: Annapolis Junction, MD Salary: $140,000 - $170,000 Requirements: Testing Web Applications, Test plans, Software Development, Version Control Systems, Git, Linux, Unix We are a custom software and systems development company focused on solving problems within the U.S. government and intelligence community, working across a diverse set of missions, products, and applications. Our engineers partner with mission domain experts to deliver capabilities in the most effective, rapid, and impactful way. Key Responsibilities Create and execute test plans and test cases to ensure software applications meet customer requirements and expectations Identify, document, and report software defects to appropriate teams for resolution Develop and execute automated tests for web applications Utilize version control systems like GIT to track software changes Monitor software performance following deployment and conduct follow-up testing Develop and maintain documentation on all test processes and results Collaborate with other teams to develop and improve software applications Qualifications Experience testing web application user interfaces. Experience analyzing functional requirements to understand possible test paths and parameters. Experience developing, coordinating, and executing test plans for periodic software releases. Solid understanding of software development principles, methodologies, and best practices. Experience working with version control systems, particularly Git. Knowledge of Linux and Unix systems. Excellent problem-solving skills and the ability to adapt to changing project requirements. Strong communication and collaboration skills. Benefits Competitive salary (140k-170k) Vacation/PTO Medical Dental Vision 401k w/ 8% match Life Insurance FSA for child care Holiday party with unique gifts Great work environment Email Your Resume In Word To Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also: parker.graham@cybercoders.com Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : PG2-1804373 -- in the email subject line for your application to be considered.*** Parker Graham - Lead Recruiter Applicants must be authorized to work in the U.S. CyberCoders is proud to be an Equal Opportunity Employer All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity or expression, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, status as a crime victim, disability, protected veteran status, or any other characteristic protected by law. CyberCoders will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. CyberCoders is committed to working with and providing reasonable accommodation to individuals with physical and mental disabilities. If you need special assistance or an accommodation while seeking employment, please contact a member of our Human Resources team to make arrangements. CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.",
        "url": "https://www.linkedin.com/jobs/view/3946213068",
        "summary": "Software Test Engineer needed for a U.S. government and intelligence community focused company. Responsibilities include creating and executing test plans, identifying and reporting software defects, developing automated tests, using version control systems, monitoring software performance, and collaborating with other teams.",
        "industries": [
            "Software Development",
            "Government",
            "Intelligence",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Problem-solving",
            "Adaptability",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Testing Web Applications",
            "Test Plans",
            "Software Development",
            "Version Control Systems",
            "Git",
            "Linux",
            "Unix",
            "Functional Requirements Analysis"
        ],
        "tech_stack": [
            "Git",
            "Linux",
            "Unix"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 170000,
            "min": 140000
        },
        "benefits": [
            "Competitive salary",
            "Vacation/PTO",
            "Medical",
            "Dental",
            "Vision",
            "401k w/ 8% match",
            "Life Insurance",
            "FSA for child care",
            "Holiday party with unique gifts",
            "Great work environment"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3930466263,
        "company": "Amazon Web Services (AWS)",
        "title": "Sr. Data Scientist, Generative AI Innovation Center",
        "created_on": 1720587358.3514307,
        "description": "Description Are you looking to work at the forefront of Machine Learning and AI? Would you be excited to apply cutting edge Generative AI algorithms to solve real world problems with significant impact? The Generative AI Innovation Center at AWS is a new strategic team that helps AWS customers implement Generative AI solutions and realize transformational business opportunities. This is a team of strategists, data scientists, engineers, and solution architects working step-by-step with customers to build bespoke solutions that harness the power of generative AI. The team helps customers imagine and scope the use cases that will create the greatest value for their businesses, select and train and fine tune the right models, define paths to navigate technical or business challenges, develop proof-of-concepts, and make plans for launching solutions at scale. The GenAI Innovation Center team provides guidance on best practices for applying generative AI responsibly and cost efficiently. You will work directly with customers and innovate in a fast-paced organization that contributes to game-changing projects and technologies. You will design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience. We’re looking for Data Scientists capable of using GenAI and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems. A key focus of this role is GenAI model customization using techniques such as fine-tuning and continued pre-training to help customers build differentiating solutions with their unique data. Key job responsibilities As an Data Scientist, you will Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate cutting-edge generative AI algorithms to address real-world challenges Interact with customers directly to understand the business problem, help and aid them in implementation of generative AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholder Provide customer and market feedback to Product and Engineering teams to help define product direction About The Team About the team Sales, Marketing and Global Services (SMGS) AWS Sales, Marketing, and Global Services (SMGS) is responsible for driving revenue, adoption, and growth from the largest and fastest growing small- and mid-market accounts to enterprise-level customers including public sector. The AWS Global Support team interacts with leading companies and believes that world-class support is critical to customer success. AWS Support also partners with a global list of customers that are building mission-critical applications on top of AWS services. About AWS Diverse Experiences AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship & Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud. We are open to hiring candidates to work out of one of the following locations: Arlington, VA, USA | Atlanta, GA, USA | Austin, TX, USA | Houston, TX, USA | San Francisco, CA, USA | San Jose, CA, USA | Santa Clara, CA, USA | Seattle, WA, USA Basic Qualifications Bachelor's degree and 8 years of experience or Master's degree and 4 years of experience 5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience Experience in any of the following areas: algorithms and data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high- performance computing, neural deep learning methods and/or machine learning Experience in using Python and hands on experience building models with deep learning frameworks like Tensorflow, Keras, PyTorch, MXNet Preferred Qualifications PhD or Masters degree in computer science, engineering, mathematics, operations research, or in a highly quantitative field Practical experience in solving complex problems in an applied environment Hands on experience with deep learning (e.g., CNN, RNN, LSTM, Transformer) Prior experience in training and fine-tuning of Large Language Models (LLMs) Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon Web Services, Inc. Job ID: A2648619",
        "url": "https://www.linkedin.com/jobs/view/3930466263",
        "summary": "AWS is seeking a Data Scientist to join their Generative AI Innovation Center. This role involves collaborating with AI/ML scientists and architects to research, design, develop, and evaluate cutting-edge generative AI algorithms. You will work directly with customers to understand their business problems, implement generative AI solutions, and provide guidance on adoption patterns.  This position requires strong experience with data querying languages, scripting languages, and statistical/mathematical software, as well as hands-on experience building models with deep learning frameworks like TensorFlow, Keras, PyTorch, and MXNet.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Customer Interaction",
            "Presentation Skills",
            "Technical Guidance",
            "Innovation",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "Generative AI",
            "AI/ML",
            "Algorithms",
            "Data Structures",
            "Parsing",
            "Numerical Optimization",
            "Data Mining",
            "Parallel and Distributed Computing",
            "High-Performance Computing",
            "Neural Deep Learning",
            "Machine Learning",
            "Python",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "MXNet",
            "SQL",
            "Scripting Languages",
            "R",
            "SAS",
            "Matlab",
            "Large Language Models (LLMs)",
            "Deep Learning",
            "CNN",
            "RNN",
            "LSTM",
            "Transformer"
        ],
        "tech_stack": [
            "Generative AI",
            "AI/ML",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "MXNet",
            "SQL",
            "Python",
            "R",
            "SAS",
            "Matlab"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "R",
            "SAS",
            "Matlab"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Operations Research"
            ]
        },
        "salary": {
            "max": 247600,
            "min": 143300
        },
        "benefits": [
            "Medical",
            "Financial",
            "Equity",
            "Sign-on payments"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3969179154,
        "company": "Pivot Path Solutions",
        "title": "Test Engineer (Entellitrak)",
        "created_on": 1720587360.074322,
        "description": "Based in the Washington, D.C. Metro area, Pivot Path Solutions, LLC is a government contracting and management consulting firm that offers enterprise IT solutions, strategic planning, organizational development, and business transformation services to help customers adapt and thrive in changing market conditions. We bring passion, sincerity and integrity to every product and service we provide to our customers. Pivot Path Solutions is currently seeking a dedicated and experienced Test Engineer to support the implementation and sustainment of the Entellitrak Commercial Off-The-Shelf (COTS) solution. The ideal candidate will have a strong background in software testing and quality assurance, with specific experience in COTS solutions. This role involves developing and executing testing processes to ensure the ongoing support of the Entellitrak platform within our DoD customer's health IT environment. This is a remote position, but candidates residing in the Washington, D.C. metro area are preferred. Key Responsibilities: Test Planning and Strategy: Develop and document comprehensive test plans and strategies tailored to the Entellitrak solution, ensuring thorough coverage of all functional and non-functional requirements Test Execution: Execute test cases, including functional, integration, system, and regression tests. Identify and document defects, track their resolution, and verify fixes to ensure the Entellitrak solution meets specified requirements Automation: Develop and maintain automated test scripts to enhance test efficiency and coverage for the Entellitrak platform. Integrate automated tests into the continuous integration/continuous deployment (CI/CD) pipeline Collaboration: Work closely with developers, business analysts, project managers, and other stakeholders to understand requirements, design test cases, and ensure the overall quality of the Entellitrak solution Documentation: Create and maintain detailed test documentation, including test plans, test cases, test scripts, and test reports for the Entellitrak solution. Ensure documentation is up-to-date and accurately reflects the current state of the system Risk Management: Identify and assess risks related to testing activities and develop mitigation strategies specific to the Entellitrak implementation. Communicate risks and issues to the project team and management Compliance: Ensure testing processes comply with DoD agency standards, policies, and regulatory requirements. Stay current with industry best practices and emerging trends in testing User Support: Provide support for user acceptance testing (UAT) by assisting end-users in defining test scenarios, conducting tests, and resolving issues related to the Entellitrak solution Continuous Improvement: Identify opportunities to improve the testing process, tools, and methodologies specific to the Entellitrak platform. Implement best practices to enhance the overall efficiency and effectiveness of the testing function Qualifications: Education: Bachelor’s degree in Computer Science, Information Technology, Engineering, or a related field Experience: Minimum of 3-5 years of experience in software testing, with a focus on COTS solutions. Specific experience with the Entellitrak platform and in the healthcare IT sector or with DoD projects is highly preferred Technical Skills: Proficiency in testing tools and frameworks (e.g., Selenium, JIRA, HP ALM, TestRail). Strong understanding of software development life cycle (SDLC) and testing methodologies Analytical Skills: Excellent problem-solving and analytical skills with a keen attention to detail. Ability to analyze complex systems and understand their interactions Communication: Strong written and verbal communication skills. Ability to effectively communicate technical issues to both technical and non-technical stakeholders Team Player: Ability to work collaboratively in a team environment. Strong interpersonal skills and the ability to build positive working relationships with team members and stakeholders Certifications: Relevant certifications such as ISTQB, CSTE, or equivalent are preferred Additional Requirements: Must be a U.S. citizen Ability to obtain and maintain the necessary security clearance as required by the position What We Offer: Pivot Path Solutions strives to attract, motivate, and retain the best people in the industry. Our benefits package reflects our continued commitment to our employees by prioritizing the health and well-being of each member. These benefits include: 100% Employer Paid Health Insurance for Employee Generous Contribution on Dental and Vision Insurances 100% Employer Paid Group Life Insurance, Short Term and Long-Term Disability Safe Harbor 401(K) Plan Health Saving Account (HSA) Healthcare Flexible Saving Account (FSA) and Dependent Care FSA Education Reimbursement Employee Referral Program U.S Citizenship or U.S. Permanent Residence is required for this specific opportunity and all selected applicants will be subject to a government security investigation. This includes but not limited to; meeting the eligibility requirements for access to classified information and the ability to obtain a government-granted security clearance. Individuals may also be subject to a background investigation including, but not limited to criminal history, employment verification, education verification, drug testing, and creditworthiness. Pivot Path Solutions, LLC is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, marital status, disability, veteran status, sexual orientation, or genetic information. Powered by JazzHR WgEhDa870b",
        "url": "https://www.linkedin.com/jobs/view/3969179154",
        "summary": "Pivot Path Solutions, LLC seeks a Test Engineer with 3-5 years of experience in software testing, specifically with COTS solutions and ideally Entellitrak. This remote position involves developing and executing test plans, automating tests, collaborating with developers, and ensuring compliance with DoD standards. The role also involves user support for UAT and continuous improvement of testing processes.",
        "industries": [
            "Government Contracting",
            "Management Consulting",
            "IT Solutions",
            "Strategic Planning",
            "Organizational Development",
            "Business Transformation",
            "Healthcare IT",
            "Defense (DoD)"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Analytical",
            "Teamwork",
            "Interpersonal",
            "Detail-oriented"
        ],
        "hard_skills": [
            "Software Testing",
            "Quality Assurance",
            "COTS Solutions",
            "Entellitrak",
            "Test Planning",
            "Test Execution",
            "Test Automation",
            "Selenium",
            "JIRA",
            "HP ALM",
            "TestRail",
            "SDLC",
            "Testing Methodologies",
            "Risk Management",
            "Compliance",
            "User Acceptance Testing (UAT)",
            "Continuous Improvement"
        ],
        "tech_stack": [
            "Entellitrak",
            "Selenium",
            "JIRA",
            "HP ALM",
            "TestRail"
        ],
        "programming_languages": [],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Computer Science",
                "Information Technology",
                "Engineering",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "100% Employer Paid Health Insurance for Employee",
            "Generous Contribution on Dental and Vision Insurances",
            "100% Employer Paid Group Life Insurance",
            "Short Term and Long-Term Disability",
            "Safe Harbor 401(K) Plan",
            "Health Saving Account (HSA)",
            "Healthcare Flexible Saving Account (FSA)",
            "Dependent Care FSA",
            "Education Reimbursement",
            "Employee Referral Program"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3962824498,
        "company": "Pinnacle Government Solutions",
        "title": "Momentum Software Engineer",
        "created_on": 1720587364.1544337,
        "description": "Position Description: Pinnacle Government Solutions is actively seeking a Software Engineer to provide O&M support for various 3rd party software that is part of the Momentum suite. As a Momentum Engineer, you will be responsible for developing and maintaining Momentum applications, creating custom modules, and integrating Momentum with other systems. You will work closely with our development team to design, develop, test, and deploy Momentum solutions that meet the needs of our clients. Your future duties and responsibilities: The Momentum Software Engineer is responsible for developing and maintaining both new and existing applications or functions. Whether you're troubleshooting a software defect, enhancing an existing application or developing a new solution you should be able to dig into frameworks and libraries to deliver coherent solutions in line with the overall architecture of the application landscape. The successful candidate will be a member of a high-performing multi-site agile team and must be self-motivated with a strong work ethic, time-management, and interpersonal skills. The successful candidate must have demonstrated effective communication skills. Required qualifications to be successful in this role: • 2 + years of relevant experience with Java, C++, webMethods, Visual Studio 2010 to 2015, Oracle SQL • Active TS/SCI CI Poly • Hands on experience and knowledge of Momentum Financials/Acquisitions • Ability to bring projects to completion in a timely manner • Strong analytical and troubleshooting skills • Ability to learn and understand the nature of business • Able to communicate effectively with non-technical staff and with members of interdisciplinary teams. • Ability to effectively prioritize and execute tasks in a high-pressure environment • Ability to work both independently and in a team-oriented, collaborative environment. Desired qualifications/non-essential skills required: • Experience working under Agile methodology. • Angular 1.X , 2.0 • HTML, Javascript, JQuery, Bootstrap • GIT source control • ERP software experience • Spring • API • Familiarity with SOAP/REST",
        "url": "https://www.linkedin.com/jobs/view/3962824498",
        "summary": "Pinnacle Government Solutions is looking for a Software Engineer to provide support for the Momentum suite of 3rd party software. The engineer will develop and maintain Momentum applications, create custom modules, and integrate Momentum with other systems. The role requires strong analytical and troubleshooting skills, as well as excellent communication skills. The candidate will be part of a high-performing agile team and must be self-motivated and organized.",
        "industries": [
            "Government",
            "Software Development",
            "Information Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Skills",
            "Time Management",
            "Teamwork",
            "Self-Motivation",
            "Organization",
            "Interpersonal Skills"
        ],
        "hard_skills": [
            "Java",
            "C++",
            "webMethods",
            "Visual Studio",
            "Oracle SQL",
            "Momentum Financials",
            "Momentum Acquisitions",
            "Agile Methodology",
            "Angular",
            "HTML",
            "Javascript",
            "JQuery",
            "Bootstrap",
            "GIT",
            "ERP",
            "Spring",
            "API",
            "SOAP",
            "REST"
        ],
        "tech_stack": [
            "Java",
            "C++",
            "webMethods",
            "Visual Studio",
            "Oracle SQL",
            "Momentum Financials",
            "Momentum Acquisitions",
            "Angular",
            "HTML",
            "Javascript",
            "JQuery",
            "Bootstrap",
            "GIT",
            "ERP",
            "Spring",
            "API",
            "SOAP",
            "REST"
        ],
        "programming_languages": [
            "Java",
            "C++",
            "Javascript"
        ],
        "experience": 2,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Alexandria, VA",
        "job_id": 3961261275,
        "company": "US Army Corps of Engineers",
        "title": "Research Interdisciplinary",
        "created_on": 1720587365.692151,
        "description": "Summary About the Position: This position is with the U.S. Army Engineer Research and Development Center (ERDC), Geospatial Research Laboratory (GRL). This is a Direct Hire Authority (DHA) solicitation to recruit and appoint qualified candidates to positions in the competitive service. This position is being filled as a Research Interdisciplinary DB-04 (GS-12/14 equivalent). Learn more about this agency Help Duties Uses optical design software for modeling such as Zemax (OpticStudio). Evaluates stress, kinematic, vibration, and thermal considerations in opto-mechanical components. Designs and build mechanical, optomechanical, and electro-optical systems for defense applications. Uses CAD in the design of opto-mechanical instruments. Is familiar with optical systems, components, and applicable codes, standards, and regulations. Prepares or delivers reports or presentations of geospatial project information. Help Requirements Conditions of Employment Appointment may be subject to a suitability or fitness determination, as determined by a completed background investigation. This position requires pre-employment financial disclosure and annually thereafter in accordance with DoD Directive 5500-7-R. Detection of the presence of drugs is warranted. This position is subject to a pre-employment screening, and random testing thereafter, to include testing based on reasonable suspicion and testing due to direct involvement with an on-duty accident. This position requires the incumbent be able to obtain and maintain a determination of eligibility for a Top Secret security clearance or access for the duration of employment. Appointment to this position is subject to a two year probationary period unless the appointee has previously met the requirements as described in 5 CFR Part 315. Qualifications Who May Apply: US Citizens In order to qualify, you must meet the requirements described below. Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community; student; social). You will receive credit for all qualifying experience, including volunteer experience. Your resume must clearly describe your relevant experience; if qualifying based on education, your transcripts will be required as part of your application. Additional information about transcripts is in this document. For 0801Series: General Engineering Series 0801 (opm.gov) For 0830 Series: Mechanical Engineering Series 0830 (opm.gov) For 0850 Series: Electrical Engineering Series 0850 (opm.gov) For 0855 Series: Electronics Engineering Series 0855 (opm.gov) For the 1301 Series: General Physical Science Series, 1301 (opm.gov) For the 1520 Series: Mathematics Series 1520 (opm.gov) For the 1550 Series: Computer Science Series 1550 (opm.gov) For the 1310 Series: Physics Series 1310 (opm.gov) In Addition To Meeting The Basic Requirement Above, To Qualify For This Position You Must Also Meet The Qualification Requirements Listed Below: To qualify at the DB-04 (GS-12-14) grade level in addition to the Basic Education requirement you must also have one year of Specialized Experience: One year of specialized experience which includes experience in 1) Research and Development of advanced technology and scientific investigation; 2) Writing proposals and obtaining funding to conduct research and development aimed at developing technology-enabled solutions for customers; 3) Managing customer-focused Research and Development (R&D) programs in order to develop solutions aligned with mission requirements; and 4) Provide expertise in remote sensing and lidar research. This definition of specialized experience is typical of work performed at the next lower grade/level position in the federal service DB-02 (GS-11). OR Education: Ph.D. or equivalent doctoral degree in a field which demonstrates the knowledge, skills, and abilities necessary to do the work of the position, such as: Data Scientist, Geographer, General Engineer, Physical Scientist, Mathematician, and/or Computer Scientist. OR Combination of Education and Experience: A combination of education and experience may be used to qualify for this position as long as the computed percentage of the requirements is at least 100%. To compute the percentage of the requirements, divide your total months of experience by 12. Then divide the total number of completed graduate semester hours (or equivalent) beyond the second year (total graduate semester hours minus 36) by 18. Add the two percentages. This announcement MAY be used to fill like vacancies six months from the closing date. All qualification requirements, including time after competitive appointment, must be met by the closing date of this announcement. Education FOREIGN EDUCATION: If you are using education completed in foreign colleges or universities to meet the qualification requirements, you must show the education credentials have been evaluated by a private organization that specializes in interpretation of foreign education programs and such education has been deemed equivalent to that gained in an accredited U.S. education program; or full credit has been given for the courses at a U.S. accredited college or university. For further information, visit: https://sites.ed.gov/international/recognition-of-foreign-qualifications/ Additional information Male applicants born after December 31, 1959, must complete a Pre-Employment Certification Statement for Selective Service Registration. You will be required to provide proof of U.S. Citizenship. One year trial/probationary period may be required. Direct Deposit of Pay is required. This position requires you to submit a Public Financial Disclosure Report (OGE 278) or a Confidential Financial Disclosure Report (OGE450) upon entry, and annually thereafter. Selection is subject to restrictions resulting from Department of Defense referral system for displaced employees. If you have retired from federal service and you are interested in employment as a reemployed annuitant, see the information in the Reemployed Annuitant information sheet. This is a(n) 16 - Engineers and Scientists Career Field position. Multiple positions may be filled from this announcement. Salary includes applicable locality pay or Local Market Supplement. Payment of Permanent Change of Station (PCS) costs is not authorized, based on a determination that a PCS move is not in the Government interest. This position is Exempt from the Fair Labor Standards Act Eligible for situational telework only, including emergency and OPM prescribed \"Unscheduled Telework\". Nepotism: Under the provisions of 5 USC 3110, an individual may not be appointed into a position if the position is under the supervisory chain of command of a relative. Read more Help  A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. Review our benefits Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. RG-W2R2AA US ARMY ENGR RESEARCH AND DEVELOPMT CTR DO NOT MAIL Vicksburg, MS 39183 US",
        "url": "https://www.linkedin.com/jobs/view/3961261275",
        "summary": "The U.S. Army Engineer Research and Development Center (ERDC), Geospatial Research Laboratory (GRL) is seeking a Research Interdisciplinary DB-04 (GS-12/14 equivalent) to design and build mechanical, optomechanical, and electro-optical systems for defense applications. The role involves using optical design software like Zemax (OpticStudio), evaluating stress, kinematic, vibration, and thermal considerations in opto-mechanical components, and preparing reports and presentations on geospatial projects.",
        "industries": [
            "Defense",
            "Engineering",
            "Research and Development",
            "Geospatial"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Problem Solving",
            "Collaboration"
        ],
        "hard_skills": [
            "Optical Design",
            "Zemax (OpticStudio)",
            "Opto-Mechanical Design",
            "Stress Analysis",
            "Kinematic Analysis",
            "Vibration Analysis",
            "Thermal Analysis",
            "CAD",
            "Remote Sensing",
            "Lidar",
            "Proposal Writing",
            "Project Management"
        ],
        "tech_stack": [
            "Zemax (OpticStudio)",
            "CAD"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Ph.D.",
            "fields": [
                "Data Science",
                "Geography",
                "General Engineering",
                "Physical Science",
                "Mathematics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive benefits package",
            "Health Insurance",
            "Retirement",
            "Life Insurance",
            "Disability Insurance",
            "Paid Time Off",
            "Training and Development",
            "Telework"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Rockville, MD",
        "job_id": 3964870760,
        "company": "KOB Solutions, Inc.",
        "title": "Scientist, Antibody Discovery and Optimization",
        "created_on": 1720587367.3081877,
        "description": "-- Join a growing team! ~ can be Scientist or Senior Scientist level ~ onsite in Rockville, MD Elevate your career, work with a group of distinguished scientists, serve as the Phage Display SME, and enjoy the camaraderie of a high level team! ✓ Grow with the company - we've worked with the hiring manager for 15+ years, a leader in the antibody engineering field. ✓ YOU will have the opportunity to make an impact. ✓ Hire and grow a team to support the research efforts. Key Responsibilities Perform hands-on lab work and apply molecular biology, phage display, and rational protein engineering techniques to generate novel multi-specific therapeutics. Collaborate with team members to construct libraries and guide project development. Provide technical expertise to design experiments and ensure deliverables. Analyze and present data and recommend project advancements. Essential Qualifications PhD and expertise in antibody/protein engineering. Stellar publication record. Preferred Experience Phage display to discover and optimize antibodies from naïve, immune, and synthetic libraries. Strong problem-solving and analytical skills. Excellent communication, organizational, and time management skills. Additional Points This is a full time position and the title can be Scientist or Senior Scientist. Title and salary (base plus annual bonus) are commensurate with experience, and relocation is provided. If you’re looking to work with the leaders in the antibody engineering field, apply now! We are looking forward to speaking with you and learning more about your career goals and how we can help you get there!",
        "url": "https://www.linkedin.com/jobs/view/3964870760",
        "summary": "Join a growing team as a Scientist or Senior Scientist at a leading antibody engineering company in Rockville, MD.  You will have the opportunity to make an impact by generating novel multi-specific therapeutics using phage display and molecular biology techniques.  Lead project development, collaborate with team members, design experiments, analyze data, and present findings.  You will also have the opportunity to hire and grow a team to support research efforts.",
        "industries": [
            "Biotechnology",
            "Pharmaceuticals",
            "Healthcare",
            "Life Sciences",
            "Research",
            "Antibody Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical",
            "Organizational",
            "Time Management"
        ],
        "hard_skills": [
            "Molecular Biology",
            "Phage Display",
            "Antibody Engineering",
            "Rational Protein Engineering",
            "Library Construction",
            "Experiment Design",
            "Data Analysis",
            "Project Management",
            "Team Leadership"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Antibody/Protein Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Relocation"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3930271479,
        "company": "Probity Inc.",
        "title": "Senior Data Scientist - Cloud 04-DM0422-3",
        "created_on": 1720587369.025021,
        "description": "PLEASE NOTE: This position requires an ACTIVE Top Secret/SCI Clearance with Polygraph. To be considered for this position, you MUST have an ACTIVE Clearance Level of Top Secret/SCI with Polygraph Summary The successful candidate will possess a diverse range of data-focused skills and experience, both technical and analytical. They will have a strong desire and capability for problem solving, data analysis and troubleshooting, analytical thinking, and experimentation, with a particular interest or aptitude in the Cloud arena. Duties, Tasks & Responsibilities Working with large, complex, and disparate data sets Designing and implementing innovative ways to analyze and exploit the Sponsor’s data holdings, particularly Cloud-related data holdings Researching and reporting on a wide variety of Sponsor inquiries Raising proactive inquiries to the Sponsor based on observations and proposed data analysis/exploitation Solving difficult, non-routine problems by applying advanced analytical methodologies, and improving analytic methodologies Developing custom searches Communicating and coordinating with internal and external partners as needed Required Experience, Skills, & Technologies Thorough knowledge of appropriate analytic tools and methodologies in one or more of the following: Applied mathematics (e.g. probability and statistics, formal modeling, computational social sciences) Computer programming (e.g. programming languages, math/statistics packages, computer science, machine learning, scientific computing) Ability to code or script in one or more general programming language Experience with, and understanding of, algorithms for classification, regression, clustering, and anomaly detection Knowledge of relational databases, including SQL and large-scale distributed systems (e.g. Hadoop) Expertise with statistical data analysis (e.g. linear models, multivariate analysis, stochastic models, sampling methods) Demonstrated effectiveness in collecting information and accurately representing/visualizing it to non-technical third parties Desired Experience, Skills & Technologies Understanding of, and/or hands-on experience with, Cloud technologies, such as AWS, Microsoft Azure, etc. Experience working in a mission environment and/or with many different types of data",
        "url": "https://www.linkedin.com/jobs/view/3930271479",
        "summary": "The position requires a data analyst with strong technical and analytical skills, particularly in the Cloud arena. The candidate will work with large datasets, design innovative analysis methods, conduct research, solve problems, develop custom searches, and communicate findings to stakeholders.",
        "industries": [
            "Government",
            "Intelligence",
            "Cybersecurity",
            "Data Analysis",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Problem Solving",
            "Data Analysis",
            "Troubleshooting",
            "Analytical Thinking",
            "Experimentation",
            "Communication",
            "Coordination"
        ],
        "hard_skills": [
            "Applied Mathematics",
            "Probability and Statistics",
            "Formal Modeling",
            "Computational Social Sciences",
            "Computer Programming",
            "Programming Languages",
            "Math/Statistics Packages",
            "Computer Science",
            "Machine Learning",
            "Scientific Computing",
            "Classification",
            "Regression",
            "Clustering",
            "Anomaly Detection",
            "Relational Databases",
            "SQL",
            "Hadoop",
            "Statistical Data Analysis",
            "Linear Models",
            "Multivariate Analysis",
            "Stochastic Models",
            "Sampling Methods",
            "Data Visualization"
        ],
        "tech_stack": [
            "AWS",
            "Microsoft Azure",
            "Hadoop",
            "SQL"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3960358981,
        "company": "MyStudio",
        "title": "Software Engineer",
        "created_on": 1720587370.4416635,
        "description": "As a Software Engineer, you will primarily focus on backend development while having the opportunity to leverage your full stack experience. You will be instrumental in rewriting and developing new backend APIs and maintaining our existing systems. Responsibilities Develop high-quality software solutions according to specifications Collaborate with product managers and designers to understand requirements and propose innovative solutions Participate in code reviews to ensure quality and maintainability of codebase Test and debug code to ensure optimal performance and reliability Collaborate with cross-functional teams to integrate software components Continuously enhance and improve existing software applications Stay up-to-date with industry trends and new technologies to bring innovation to the development process Support and maintain software systems post-deployment Skills and Qualifications Bachelor's degree in computer science or a related field Strong understanding of backend technologies such as PHP or Java Proficiency in frontend technologies such as HTML, CSS, and JavaScript Ability to design, develop, and maintain both frontend and backend components of web applications Strong knowledge of software development principles and best practices Experience with software development frameworks and tools, such as Agile, Git, or Jira Familiarity with database management systems and SQL Excellent problem-solving and analytical skills Strong communication and interpersonal skills Ability to work independently and as part of a team Attention to detail and a commitment to delivering high-quality software Ability to learn quickly and adapt to changing technologies and requirements Experience with frontend frameworks/libraries such as React.js or Angular is a plus Experience with cloud-based technologies and microservices architecture is a plus - Familiarity with software testing and test automation frameworks is a plus Nice to Have Full Stack Experience: Knowledge and experience in full stack development to understand the entire application workflow. Future Tech Moves: Understanding of AWS services and the ability to assist in the migration process. Automation: Experience with CI/CD pipelines and automation tools.",
        "url": "https://www.linkedin.com/jobs/view/3960358981",
        "summary": "This role focuses on backend development for rewriting and developing new APIs. It involves collaborating with product teams, code reviews, testing, debugging, and maintaining systems. Full-stack experience is a plus, and the role includes responsibilities like understanding requirements, proposing solutions, integrating components, and staying up-to-date with tech trends.",
        "industries": [
            "Software Development",
            "Technology",
            "Web Development"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Skills",
            "Collaboration",
            "Teamwork",
            "Independent Work",
            "Attention to Detail"
        ],
        "hard_skills": [
            "PHP",
            "Java",
            "HTML",
            "CSS",
            "JavaScript",
            "Software Development Principles",
            "Agile",
            "Git",
            "Jira",
            "SQL",
            "Database Management",
            "React.js",
            "Angular",
            "AWS",
            "CI/CD",
            "Automation"
        ],
        "tech_stack": [
            "PHP",
            "Java",
            "HTML",
            "CSS",
            "JavaScript",
            "React.js",
            "Angular",
            "AWS",
            "Git",
            "Jira",
            "SQL"
        ],
        "programming_languages": [
            "PHP",
            "Java",
            "JavaScript"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3933815230,
        "company": "Accroid Inc",
        "title": "full stack engineer",
        "created_on": 1720587371.89934,
        "description": "Title : full stack engineer Location : McLean, VA - hybrid Job Description We are looking for full stack engineer to join the Card Onboarding team. PX is a growing organization and at the forefront of building customer facing features that delight and engage our card customers. Our mission is Transform our business by driving early engagement with our customers and helping them spend smarter. EASE Web features and outbound communications lay the foundation for an enduring relationship, while owning the front door to spend, delivering seamless spend management experience, and growth. We are full-stack team expanding our footprint in backend development - server less, lamda, dynamo dB, redis, java, python, nodejs.",
        "url": "https://www.linkedin.com/jobs/view/3933815230",
        "summary": "Full Stack Engineer needed for Card Onboarding team at PX. The role focuses on building customer-facing features and driving early engagement, with a focus on backend development using serverless, Lambda, DynamoDB, Redis, Java, Python, and Node.js.",
        "industries": [
            "Financial Services",
            "Technology"
        ],
        "soft_skills": [
            "Customer Focus",
            "Problem Solving",
            "Teamwork",
            "Communication",
            "Growth Mindset"
        ],
        "hard_skills": [
            "Full Stack Development",
            "Backend Development",
            "Serverless Architecture",
            "Lambda",
            "DynamoDB",
            "Redis",
            "Java",
            "Python",
            "Node.js"
        ],
        "tech_stack": [
            "Serverless",
            "Lambda",
            "DynamoDB",
            "Redis",
            "Java",
            "Python",
            "Node.js"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "Node.js"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Silver Spring, MD",
        "job_id": 3963726057,
        "company": "Tentek, Inc.",
        "title": "Front-End Developer",
        "created_on": 1720587373.7990615,
        "description": "Daily Responsibilities Collaborate with engineers, designers, and product managers to build delightful, performant, and accessible user experiences Develop and maintain high-quality web applications using React Develop and maintain applications using multiple frameworks working in Jira and Git Ability to build from user stories and be active in technical design Build efficient, scalable, secure, and observable applications Able to take and give feedback in team meetings and code review Building functional and efficient pages for our operational teams Be proactive and responsive in addressing technical issues Technology Requirements Solid experience with JavaScript/Typescript and Node.js Skilled in React.js, Vue.js, or similar frameworks. Strong understanding of front-end technologies, including HTML5, CSS3, JS, responsive UIs. Knowledge of best practices and standards for web development. Good understanding of asynchronous request handling, and partial page updates. Familiarity with RESTful APIs.",
        "url": "https://www.linkedin.com/jobs/view/3963726057",
        "summary": "This role involves collaborating with teams to build user-friendly web applications using React and other frameworks. Responsibilities include developing and maintaining applications, building efficient pages for operational teams, and participating in technical design, code reviews, and issue resolution. The ideal candidate possesses strong JavaScript/TypeScript and Node.js skills, experience with React or similar frameworks, and a solid understanding of front-end technologies and best practices.",
        "industries": [
            "Software Development",
            "Web Development",
            "Technology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Technical Design",
            "Feedback",
            "Proactivity",
            "Responsiveness"
        ],
        "hard_skills": [
            "JavaScript",
            "TypeScript",
            "Node.js",
            "React.js",
            "Vue.js",
            "HTML5",
            "CSS3",
            "JS",
            "Responsive UI",
            "RESTful APIs",
            "Asynchronous Request Handling",
            "Partial Page Updates",
            "Jira",
            "Git"
        ],
        "tech_stack": [
            "React.js",
            "Vue.js",
            "JavaScript",
            "TypeScript",
            "Node.js",
            "HTML5",
            "CSS3",
            "RESTful APIs",
            "Jira",
            "Git"
        ],
        "programming_languages": [
            "JavaScript",
            "TypeScript"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3903616971,
        "company": "Constellation Technologies, Inc",
        "title": "Software Engineers - multiple levels - CLEARANCE REQUIRED",
        "created_on": 1720587375.3202546,
        "description": "Java, Python, C/C++, BASH, Docker, Kubernetes, Cloud Must have TS/SCI clearance w/ active polygraph Must be a US Citizen This position is open to multiple levels of years of experience; two (02) years within the last five (05) years must be directly related to Software Engineering: Level 04 requires a minimum fifteen (15) years of experience Level 03 requires a minimum twelve (12) years of experience Level 02 requires a minimum nine (09) years of experience Level 01 requires a minimum six (06) years of experience Minimum of High School Diploma Experience programming in C/C++ or similar and Python The benefits package: Affordable healthcare options with 80% employer paid premium PLUS a company-funded HSA Dental insurance with 100% employer paid premium Vision with 80% employer paid premium Employer paid Life insurance 100% Employer paid Short-term and Long-term disability 100% Annual training, continued education, and professional memberships reimbursement Unlimited access to Red Hat Enterprise Linux, AWS, and NetApp training and accreditation Annual reimbursement for technology i.e. phones, computers, printers, etc.. 401(k) with company match up to 5% with 100% immediate vesting (after 90 days of employment) The environment and perks: Professional development investment and paid time off for training Contract and work locations in Maryland, Virginia, Colorado, Texas, Utah, California, Florida and Hawaii Team building events throughout the year such as Destination Family Events, Holiday Party, Monthly Get-Togethers Leadership Team engagement and mentorship Performance Recognition Program Complimentary branded apparel Don't see a job opening that's the perfect fit? Apply to our General Position to join our talent pool for consideration for future opportunities. Know someone else who may be a good fit? Refer them through the CTI External Referral Program and you could receive a one-time referral bonus of up to $10,000! Email cti-staffing@cti-md.com for more information. Constellation Technologies is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, religion, creed, color, national origin, ancestry, sex (including pregnancy, childbirth, breastfeeding, or medical conditions related to pregnancy, childbirth, or breastfeeding), age, medical condition, marital or domestic partner status, sexual orientation, gender, gender identity, gender expression and transgender status, mental disability or physical disability, genetic information, military or veteran status, citizenship, low-income status or any other status or characteristic protected by applicable law. Job applicants can submit questions about CTI’s equal employment opportunity policy to cti-hr@cti-md.com.",
        "url": "https://www.linkedin.com/jobs/view/3903616971",
        "summary": "Constellation Technologies is seeking Software Engineers with TS/SCI clearance and active polygraph. They offer competitive salaries and benefits, including healthcare, dental, vision, life insurance, short-term and long-term disability, training reimbursement, access to Red Hat Enterprise Linux, AWS, and NetApp training, technology reimbursement, and a 401(k) with company match. The company offers a variety of work locations in Maryland, Virginia, Colorado, Texas, Utah, California, Florida, and Hawaii. They also provide professional development opportunities and team building events.",
        "industries": [
            "Software Engineering",
            "Technology",
            "Defense",
            "Government",
            "Aerospace",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Teamwork",
            "Communication",
            "Problem-solving",
            "Leadership",
            "Mentorship",
            "Organization"
        ],
        "hard_skills": [
            "Java",
            "Python",
            "C/C++",
            "BASH",
            "Docker",
            "Kubernetes",
            "Cloud"
        ],
        "tech_stack": [
            "Java",
            "Python",
            "C/C++",
            "BASH",
            "Docker",
            "Kubernetes",
            "Cloud",
            "Red Hat Enterprise Linux",
            "AWS",
            "NetApp"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "C/C++",
            "BASH"
        ],
        "experience": 6,
        "education": {
            "min_degree": "High School Diploma",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Affordable healthcare options with 80% employer paid premium PLUS a company-funded HSA",
            "Dental insurance with 100% employer paid premium",
            "Vision with 80% employer paid premium",
            "Employer paid Life insurance 100%",
            "Employer paid Short-term and Long-term disability 100%",
            "Annual training, continued education, and professional memberships reimbursement",
            "Unlimited access to Red Hat Enterprise Linux, AWS, and NetApp training and accreditation",
            "Annual reimbursement for technology i.e. phones, computers, printers, etc..",
            "401(k) with company match up to 5% with 100% immediate vesting (after 90 days of employment)"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3912434625,
        "company": "Unreal Staffing, Inc",
        "title": "Software Engineer",
        "created_on": 1720587378.4619763,
        "description": "About Us Are you ready to join one of the fastest-growing companies in the W23 batch? Look no further because we're hiring for our first founding engineers, starting right now. We're a small team backed by supportive investors, having closed our seed round recently. Our expertise was honed in the early days of some of today's top companies like Stripe, Airbnb, and Notion. Our growth is soaring, and the next three hires will play a pivotal role in shaping the future of our business. Are you up for the challenge? Requirements Mission: Online store owners, regardless of their size, juggle countless tasks every day, often unrelated to improving their business and product. Our goal is to build the automation layer for e-commerce, starting with accounting and sales tax compliance. Currently, we're assisting hundreds of businesses in streamlining their operations, saving them from the hassle of managing complex tax compliance issues. Tomorrow, we aim to enable business owners to focus entirely on what they love doing. Tech Stack: Client/Server: TypeScript, React, Node.js Data: Python, PostgreSQL, dbt, Snowflake Infrastructure: AWS, Render Benefits Competitive salary range: $110,000 - $170,000 annually, depending on experience Equity options to align your success with the company's growth Flexible work environment with the option for remote work Generous vacation policy and paid time off Healthcare benefits including medical, dental, and vision coverage Opportunity to work with a highly experienced and supportive team in a fast-paced startup environment",
        "url": "https://www.linkedin.com/jobs/view/3912434625",
        "summary": "We are a fast-growing startup backed by investors, aiming to automate tasks for online store owners, specifically focusing on accounting and sales tax compliance. We are seeking founding engineers to build the automation layer for e-commerce, using a tech stack including TypeScript, React, Node.js, Python, PostgreSQL, dbt, Snowflake, and AWS.",
        "industries": [
            "E-commerce",
            "Software",
            "Technology",
            "FinTech",
            "Accounting",
            "Tax Compliance"
        ],
        "soft_skills": [
            "Problem-solving",
            "Teamwork",
            "Communication",
            "Adaptability",
            "Learning",
            "Growth Mindset"
        ],
        "hard_skills": [
            "TypeScript",
            "React",
            "Node.js",
            "Python",
            "PostgreSQL",
            "dbt",
            "Snowflake",
            "AWS",
            "Render"
        ],
        "tech_stack": [
            "TypeScript",
            "React",
            "Node.js",
            "Python",
            "PostgreSQL",
            "dbt",
            "Snowflake",
            "AWS",
            "Render"
        ],
        "programming_languages": [
            "TypeScript",
            "React",
            "Node.js",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 170000,
            "min": 110000
        },
        "benefits": [
            "Competitive salary",
            "Equity options",
            "Flexible work environment",
            "Remote work option",
            "Generous vacation policy",
            "Paid time off",
            "Healthcare benefits",
            "Medical, dental, and vision coverage",
            "Supportive team",
            "Fast-paced startup environment"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3943573466,
        "company": "Amazon Web Services (AWS)",
        "title": "Sr. Applied Scientist, AWS Data Center Infrastructure Operations",
        "created_on": 1720587383.9888375,
        "description": "Description Are you interested in using data and science to solve the largest scale problems in AWS Data Center Global Operations? Do you want to play a critical role in developing the future of repair in Data Center Operations through Machine Learning? Come join us! The Central Infrastructure Analytics Team (CIAT) Sr. Applied Scientist transforms data into actionable insights for global teams by 1) interpreting enterprise scale data sets from a variety of internal sources to uncover the functional activity and implications, 2) analyzing this data to discover patterns, trends and correlations, 3) developing hypotheses and assisting in the design of experiments to explore these hypotheses, and 4) developing and deploying actionable ML models and business intelligence solutions for global customers. CIAT collects data from diverse sources of internal systems which often require cleaning, interpretation, and combination in order to tell a functional story. The Applied Scientist role is critical in transitioning the analysis output from Descriptive/Diagnostic to Predictive/Prescriptive, and providing the operations teams with actionable insights to enable ongoing improvements. The Applied Scientist will use a variety of tools (e.g. Python, SQL, SageMaker, R, SAS, etc.) to deep dive data sources to discover useful patterns that will drive process improvement or remediate systemic issues. Key job responsibilities Design, develop, and evaluate innovative ML models to solve diverse challenges and opportunities across data center global operations Drive end-to-end Machine Learning projects that have a high degree of ambiguity, scale, complexity. Build machine learning models, perform proof-of-concept, experiment, optimize, and deploy your models into production. Work with a scientists and software engineers to deliver machine-learning and data science solutions to production. Perform hands-on data analysis, employ statistical testing methods and strategies, run regular A/B tests, and clearly communicate the impact to technical and non-technical audiences in senior leadership. Establish scalable, efficient, automated processes for large-scale data analysis, machine-learning model development, model validation and serving. In this role you will apply advanced analysis techniques and statistical concepts to draw insights from enterprise scale datasets, build scalable machine learning models, and create intuitive data visualizations. You will contribute to each layer of the data solutions, working closely with Data Scientists, Engineers, Business Intelligence Engineers, and Global Process Owners to understand the business objectives, obtain relevant datasets and build prototype predictive and prescriptive analytic models. You will review key results with business leaders and stakeholders, and you will work with your team to develop and deploy a productionized version of the model to your global customers. About The Team The Central Infrastructure Analytics Team (CIAT) provides critical business intelligence services across a broad range of functions within the AWS global Data Center Community (DCC). Situated within Central Operations, CIAT is the analytics hub for Data Center based organizations, including but not limited to: operations, logistics, engineering and equipment management, safety, and security. CIAT is comprised of several specialty Builder functions including data engineering, business intelligence (visualization), systems engineering, and data science. We build business intelligence solutions that drive the right actions at scale across our global data centers and supporting services. We are open to hiring candidates to work out of one of the following locations: Herndon, VA, USA | Seattle, WA, USA Basic Qualifications 3+ years of building machine learning models for business application experience PhD, or Master's degree and 6+ years of applied research experience Experience programming in Java, C++, Python or related language Experience with neural deep learning methods and machine learning Preferred Qualifications Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc. Experience with large scale distributed systems such as Hadoop, Spark etc. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $150,400/year in our lowest geographic market up to $260,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon Data Services, Inc. Job ID: A2568176",
        "url": "https://www.linkedin.com/jobs/view/3943573466",
        "summary": "This role involves developing machine learning models to solve various challenges and opportunities in AWS Data Center Global Operations. The Sr. Applied Scientist will interpret large datasets, identify patterns, build predictive models, and deploy them to production. The individual will work with a team of scientists, engineers, and business stakeholders to ensure the models' effectiveness and deliver actionable insights.",
        "industries": [
            "Information Technology",
            "Computer Hardware",
            "Data Center"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Critical Thinking",
            "Analytical Skills",
            "Presentation Skills",
            "Decision Making"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Python",
            "SQL",
            "SageMaker",
            "R",
            "SAS",
            "Java",
            "C++",
            "Hadoop",
            "Spark",
            "Scikit-learn",
            "Spark MLLib",
            "MxNet",
            "TensorFlow",
            "Numpy",
            "Scipy",
            "A/B Testing",
            "Data Visualization"
        ],
        "tech_stack": [
            "SageMaker",
            "Hadoop",
            "Spark",
            "Scikit-learn",
            "Spark MLLib",
            "MxNet",
            "TensorFlow",
            "Numpy",
            "Scipy"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "R",
            "SAS",
            "Java",
            "C++"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 260000,
            "min": 150400
        },
        "benefits": [
            "Medical",
            "Financial",
            "Equity",
            "Sign-on Payments"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3938855526,
        "company": "Addison Group",
        "title": "Software Developer (Top Secret)",
        "created_on": 1720587390.8923373,
        "description": "We are seeking a skilled Software Developer with an active TS/SCI clearance and experience in Java or Python to join our team. This position requires a strong understanding of software methodologies, secure software development practices, and cybersecurity principles. The role involves consulting with engineering staff, tailoring code analysis for specific applications, and identifying security concerns in critical infrastructure systems. Responsibilities: Utilize Java or Python experience in a non-coding heavy position, focusing on the evaluation and improvement of existing software systems. Apply software methodologies to enhance development processes and outcomes. Tailor code analysis to address application-specific concerns, ensuring optimal performance and security. Utilize complex mathematical concepts, such as discrete math, in software development and analysis. Develop secure software in line with secure deployment methodologies, tools, and practices. Apply cybersecurity and privacy principles to meet organizational requirements related to confidentiality, integrity, availability, authentication, and non-repudiation. Identify critical infrastructure systems with information communication technology that lack system security considerations. Qualifications: Bachelor’s degree in a related field preferred; an Associate's degree with relevant certifications ( CISSP-ISSAP ) will be considered. Active Top Secret clearance . Strong experience in using Java or Python. In-depth understanding of software methodologies. Proficiency in applying complex mathematical concepts to software development. Experience in developing secure software and applying cybersecurity principles. Ability to identify and address security concerns in critical infrastructure systems. Excellent communication skills and the ability to work collaboratively with engineering and management teams.",
        "url": "https://www.linkedin.com/jobs/view/3938855526",
        "summary": "Software Developer with active TS/SCI clearance and experience in Java or Python, responsible for evaluating and improving existing software systems, tailoring code analysis, ensuring optimal performance and security, applying cybersecurity principles, and identifying security concerns in critical infrastructure systems.",
        "industries": [
            "Information Technology",
            "Cybersecurity",
            "Software Development",
            "Engineering",
            "Defense"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Java",
            "Python",
            "Code Analysis",
            "Software Methodologies",
            "Secure Software Development",
            "Cybersecurity Principles",
            "Discrete Math",
            "Secure Deployment Methodologies",
            "System Security",
            "Critical Infrastructure"
        ],
        "tech_stack": [
            "Java",
            "Python"
        ],
        "programming_languages": [
            "Java",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Associate's",
            "fields": [
                "Computer Science",
                "Information Technology",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3960175284,
        "company": "Booz Allen Hamilton",
        "title": "Generative AI Engineer",
        "created_on": 1720587395.0978036,
        "description": "Job Number: R0200361 Generative AI Engineer The Opportunity: As an experienced engineer, you know that machine learning (ML) is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on business processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support a variety of high-impact missions across sectors and domains. As an ML engineer, you’ll train, test, deploy, and maintain models that learn from data. In this role, you’ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You’ll be part of a large community of ML engineers across the firm and collaborate with data engineers, data scientists, software engineers, solutions architects, and product owners to deliver world-class solutions to real-world problems, processing data and information at a massive scale, developing pipelines that optimize the use of infrastructure, and integrating critical technologies into efficient user experiences. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. Work with us to solve real-world challenges and define ML strategy for our firm and our clients. Join us. The world can’t wait. You Have: 3+ years of experience with artificial intelligence (AI), data science, ML engineering, data research, software engineering, or data analytics Experience with software and AI projects Experience with Python programming language Experience with Generative AI, including transformers or large language models (LLM) work Knowledge of modern software design patterns, including microservice design or edge computing Ability to obtain a security clearance Bachelor's degree Nice If You Have: Experience with project work in deep learning, computer vision, NLP, or chatbot development Experience with modern Cloud computing technologies, including Docker and Kubernetes Experience with embedded systems programming in C, C++, or Rust Experience with frameworks such as Huggingface, LangChain, AutoGPT, or AgentGPT Experience with GPU programming, including CUDA or RAPIDs Ability to gather requirements from customers and lead Agile teams Master's degree Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $75,600.00 to $172,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "url": "https://www.linkedin.com/jobs/view/3960175284",
        "summary": "Booz Allen Hamilton is seeking an experienced Generative AI Engineer to develop and deploy machine learning solutions for various high-impact missions. The ideal candidate will have 3+ years of experience with AI, data science, ML engineering, and a strong understanding of Generative AI, including transformers and large language models (LLM). This role involves training, testing, deploying, and maintaining models, collaborating with data engineers, data scientists, and other stakeholders to deliver world-class solutions.",
        "industries": [
            "Information Technology and Services",
            "Consulting",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Problem-solving",
            "Collaboration",
            "Communication",
            "Technical Expertise",
            "Leadership",
            "Consulting",
            "Agile"
        ],
        "hard_skills": [
            "Python",
            "Generative AI",
            "Transformers",
            "Large Language Models (LLMs)",
            "Machine Learning",
            "Deep Learning",
            "Computer Vision",
            "Natural Language Processing (NLP)",
            "Chatbot Development",
            "Cloud Computing",
            "Docker",
            "Kubernetes",
            "C",
            "C++",
            "Rust",
            "Huggingface",
            "LangChain",
            "AutoGPT",
            "AgentGPT",
            "GPU Programming",
            "CUDA",
            "RAPIDS"
        ],
        "tech_stack": [
            "Python",
            "Generative AI",
            "Transformers",
            "Large Language Models (LLMs)",
            "Machine Learning",
            "Deep Learning",
            "Cloud Computing",
            "Docker",
            "Kubernetes",
            "Huggingface",
            "LangChain",
            "AutoGPT",
            "AgentGPT",
            "GPU Programming",
            "CUDA",
            "RAPIDS"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++",
            "Rust"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 172000,
            "min": 75600
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Dependent Care",
            "Recognition Awards",
            "Flexible Schedules",
            "Remote Work",
            "Hybrid Work"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Columbia, MD",
        "job_id": 3948895368,
        "company": "BigBear.ai",
        "title": "Python Software Engineer",
        "created_on": 1720587400.2446072,
        "description": "Overview BigBear.ai is seeking a Python Software Engineer at BigBear.ai, you will collaborate with the data science team to encapsulate cyber knowledge on a large scale, transitioning into conventional software development. Utilizing Python, you will access APIs to transform and standardize data into JSON for diverse applications. Your role involves the full lifecycle of software systems, including analysis, design, verification, implementation, and maintenance. Additionally, you will be responsible for authoring software standards and documentation, delivering presentations to stakeholders, and supporting an array of cyber knowledge development initiatives, encompassing workflow optimization, requirements management, and the creation of custom dashboards and tools. What You Will Do Work with data scientist team to capture Cyber knowledge at scale transitioning to more traditional software development Leverage data science tradecraft using Python to access APIs and transform the clean and normalized data into JSON for other applications Analyze, design, verify, validate, implement, apply, and maintain software systems Write software standards and practices documentation Present briefings and demonstrations to stakeholder Support a wide-range of cyber knowledge development priorities to include workflows, requirements specification management, custom dashboard and tool support, knowledge capture and documentation What You Need To Have Bachelor's degree plus 8-years of relevant experience, Master's degree in plus 6-years of relevant experience, or Doctoral degree plus 4-years of relevant experience. An Associate's degree plus 10-years of relevant experience or high school diploma/GED plus 12-years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position Computer Science (CS) degree or related field TS/SCI clearance with polygraph What We'd Like You To Have Strong Python skills. Experience with JavaScript. Familiarity with JSON format. Experience with Jupyter Notebooks and GitLab. Experience developing in Linux environment. Experience with Docker. Experience with Typescript. Understanding of Cyber mission. Understanding of MITRE ATT&CK framework. Ability to work with a team. About BigBear.ai BigBear.ai is a leading provider of AI-powered decision intelligence solutions for national security, supply chain management, and digital identity. Customers and partners rely on BigBear.ai’s predictive analytics capabilities in highly complex, distributed, mission-based operating environments. Headquartered in Columbia, Maryland, BigBear.ai is a public company traded on the NYSE under the symbol BBAI. For more information, visit https://bigbear.ai/ and follow BigBear.ai on LinkedIn: @BigBear.ai and X: @BigBearai.",
        "url": "https://www.linkedin.com/jobs/view/3948895368",
        "summary": "BigBear.ai is looking for a Python Software Engineer to work on their data science team to encapsulate cyber knowledge. The role involves developing software systems using Python, accessing APIs to transform data into JSON, and supporting a range of cyber knowledge development initiatives.",
        "industries": [
            "Cybersecurity",
            "National Security",
            "Data Science",
            "Software Development",
            "Artificial Intelligence",
            "Supply Chain Management",
            "Digital Identity"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Presentation Skills",
            "Problem-solving",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "JavaScript",
            "JSON",
            "Jupyter Notebooks",
            "GitLab",
            "Linux",
            "Docker",
            "Typescript"
        ],
        "tech_stack": [
            "Python",
            "JavaScript",
            "JSON",
            "Jupyter Notebooks",
            "GitLab",
            "Linux",
            "Docker",
            "Typescript"
        ],
        "programming_languages": [
            "Python",
            "JavaScript",
            "Typescript"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3946663338,
        "company": "Teal Media",
        "title": "Front-end Developer",
        "created_on": 1720587401.6850057,
        "description": "Teal Media is seeking an experienced remote front-end developer for a full-time position. Working closely with our visual design team and our technical team, you will create complex, custom front-end code for our high-profile social impact clients, under the direction of our CTO and Technical Director. Depending on the project, responsibilities may include handing off front-end code for integration into a CMS, custom microsites, or ‘design in the browser’ for key client deliverables. Ideal Location: Remote (US residents only) Who We Are Teal Media is a full-service creative and design agency with a conscience. We believe purposeful design can transform organizations, inspire action, and enable progress. Our clients and nonprofit partners commit their lives to creating positive social change. We pour every ounce of our passion and skill into their success, because we, too, want the world to be a better place. We offer a variety of strategic, creative, and technical services, including brand strategy, web design and development, and creative support. We are a woman-owned and woman-led firm with a diverse staff. At Teal Media, we value our people above all else and choose to work with partners and clients who share those beliefs. Your Team This role is under the Development team. You will report to the Technical Director and work closely with the Development, Content, and Creative teams. What You’ll Do Create beautiful, performant and accessible front-end website designs using HTML5, CSS, JavaScript, and related libraries Communicate and collaborate with internal and external project team members Collaborate closely with the design team to enhance the overall design experience Think deeply about tools and frameworks to create flexible design systems Serve as the front-end developer for web-based projects as well as support retainer development tasks for existing clients Build high-quality prototypes for client demonstration Ensure the technical feasibility of UI/UX designs Regularly consult with team members on code deliverables to ensure work meets project requirements before sharing with the client Conduct quality assurance, testing, and proofing on project deliverables Assist with technical solutions discovery on projects Train/educate clients as needed Ideal Candidates Will Have 3-7+ years of front-end coding experience Agency experience is strongly preferred Demonstrable experience developing complex front-end HTML code with examples and a willingness to walk us through code that you have written Very comfortable with coding ‘from scratch’ as well as light use of existing frameworks Strong understanding of the website design and development process, including working knowledge of git, mobile responsive design, and accessibility standards Self-starter, independent thinker, highly responsible Excellent communication and problem-solving skills Thrives working in a fast-paced environment Strict attention to detail and adherence to project deadlines Salary & Level Teal Media is committed to equity and transparency when it comes to salary and the growth of our people. This role is open to both level 2T and 3T in our progression framework and is determined by the candidate’s unique background and experience. Level: 3T Official Title: Senior Developer Department: Development Salary Range: $100,000-$125,000 Level: 2T Official Title: Developer Department: Development Salary Range: $90,000-$120,000 Benefits Make a positive impact on mission-driven organizations and nonprofits while working in a fun, collaborative, and flexible environment. We’re a nimble, close-knit group that values teamwork and individual contribution. All our positions are remote (in the US), but we work to maintain a fun and engaging company culture. Work from home (or at the beach!) Professional Development Coaching Yearly Continuing Education Stipend Eligibility for bi-annual bonuses Flexible Time Off and Unlimited Sick Leave Compassionate Leave Health, dental, and vision insurance Company 401(k) with match Flexible working hours Flex Fridays - a day dedicated to self-directed work. Spend time working on the things you want - whether it be honing in on your craft or taking off a few hours early for your mental wellness! Equal Opportunity Employer If your experience doesn’t exactly match the qualifications listed but you believe you would shine in this role, we want to hear from you! Please apply and tell us why you’re the right person for the job. Black & Indigenous people of color, immigrants, women, and femmes, LGBTQI+ individuals, people with disabilities, neurodiverse people, and formerly incarcerated or systems-impacted people are highly encouraged to apply. Teal Media is an equal-opportunity employer that values a diverse workforce and an inclusive culture. Teal Media encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, age, national origin, marital status, citizenship, disability, and veteran status. Teal Media does not discriminate on the basis of race, color, religion, creed, age, sexual orientation, gender identity or expression, marital status, country of origin, citizenship, ancestry, genetic information, physical or mental disability, military or veteran status, political affiliation, exercising one’s right to family care and medical leave, medical condition, including pregnancy, childbirth, breastfeeding, and related medical conditions, or any other category protected by local, state, or federal laws. We are not offering US visa sponsorship at this time.",
        "url": "https://www.linkedin.com/jobs/view/3946663338",
        "summary": "Teal Media, a full-service creative and design agency, is seeking a remote front-end developer to create custom front-end code for their high-profile social impact clients. The ideal candidate will have 3-7+ years of experience, agency experience, strong understanding of website design and development processes, and excellent communication and problem-solving skills.",
        "industries": [
            "Marketing & Advertising",
            "Design",
            "Nonprofit",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Collaboration",
            "Teamwork",
            "Self-starter",
            "Independent thinking",
            "Highly responsible",
            "Attention to detail",
            "Deadline-oriented"
        ],
        "hard_skills": [
            "HTML5",
            "CSS",
            "JavaScript",
            "Git",
            "Mobile responsive design",
            "Accessibility standards"
        ],
        "tech_stack": [
            "HTML5",
            "CSS",
            "JavaScript",
            "Git",
            "Mobile responsive design",
            "Accessibility standards"
        ],
        "programming_languages": [
            "HTML5",
            "CSS",
            "JavaScript"
        ],
        "experience": 3,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 125000,
            "min": 90000
        },
        "benefits": [
            "Work from home",
            "Professional Development Coaching",
            "Yearly Continuing Education Stipend",
            "Bi-annual bonuses",
            "Flexible Time Off",
            "Unlimited Sick Leave",
            "Compassionate Leave",
            "Health, dental, and vision insurance",
            "Company 401(k) with match",
            "Flexible working hours",
            "Flex Fridays"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort Meade, MD",
        "job_id": 3947179615,
        "company": "Cyber Armor Solutions",
        "title": "Software Engineer",
        "created_on": 1720587408.6401484,
        "description": "Active TS/SCI security clearance with a current polygraph is mandatory. (DoD or IC experience is not required, but clearance must be verifiable). Responsibilities:﻿ Design, develop, and maintain software applications using C/C++ with a focus on digital signal processing (DSP) implementations. Analyze and modify existing DSP code for optimal performance. Collaborate with engineers and other team members to ensure successful project execution. Write clear and concise technical documentation. Participate in code reviews and maintain high coding standards. Stay up-to-date on the latest advancements in DSP technologies. Qualifications Bachelor's degree in Computer Science or a related field from an accredited institution (or). Four (4) years of demonstrably relevant software engineering experience in projects with similar software development processes (to substitute for a bachelor's degree). Proficiency in C/C++ programming language. Strong understanding of digital signal processing (DSP) concepts. Active TS/SCI security clearance with a current polygraph is mandatory. (DoD or IC experience is not required, but clearance must be verifiable). Preferred Skills Experience with precision synchronous digital sampling and timestamping techniques. Familiarity with high-order angle and amplitude modulation, multiplexed signals, and spread spectrum technology. Background in high-speed digital signal processing systems development for military, aerospace, or intelligence applications. Skills: software,signal,signal processing,digital signal processing,processing",
        "url": "https://www.linkedin.com/jobs/view/3947179615",
        "summary": "This position involves designing, developing, and maintaining software applications using C/C++ with a focus on digital signal processing (DSP). The role requires strong DSP knowledge, proficiency in C/C++, and the ability to collaborate with engineers. Active TS/SCI security clearance with a current polygraph is mandatory.",
        "industries": [
            "Aerospace",
            "Defense",
            "Intelligence",
            "Military",
            "Software Development"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Documentation",
            "Problem Solving",
            "Teamwork"
        ],
        "hard_skills": [
            "C++",
            "Digital Signal Processing",
            "Software Development",
            "Precision Synchronous Digital Sampling",
            "Timestamping Techniques",
            "High-Order Angle and Amplitude Modulation",
            "Multiplexed Signals",
            "Spread Spectrum Technology",
            "High-Speed Digital Signal Processing Systems Development"
        ],
        "tech_stack": [
            "C/C++",
            "DSP"
        ],
        "programming_languages": [
            "C++"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3967702356,
        "company": "Ascendion",
        "title": "Frontend Developer",
        "created_on": 1720587410.0808973,
        "description": "About Ascendion Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: Build the coolest tech for world’s leading brands Solve complex problems – and learn new skills Experience the power of transforming digital engineering for Fortune 500 clients Master your craft with leading training programs and hands-on experience Experience a community of change makers! Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. About the Role: Job Title: Front End Engineer Job Description: We are seeking a talented and experienced Front-End Engineer to join our team. The ideal candidate will have a strong background in modern front-end technologies, including VueJS, AngularJS, ReactJS, TypeScript, NodeJS, and AWS. Responsibilities: Develop and maintain high-quality, responsive web applications using VueJS, AngularJS, or ReactJS. Write clean, maintainable, and efficient code in TypeScript. Collaborate with back-end developers to integrate APIs and ensure seamless functionality. Optimize applications for maximum speed and scalability. Implement best practices in front-end development, including responsive design, cross-browser compatibility, and accessibility standards. Utilize NodeJS for server-side rendering and other back-end tasks as needed. Work with AWS services to deploy, manage, and scale web applications. Participate in code reviews, testing, and debugging to ensure high-quality deliverables. Stay updated with the latest industry trends and technologies to continually improve our products and processes. Location: Richmond, VA / McLean, VA (Hybrid) Salary Range: The salary for this position is between $110,000 – $132,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate. Benefits : The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day(s) accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day(s) of paid vacation time] [6 paid holiday(s) and 1 floating holiday per calendar year] [Ascendion Learning Management System] Want to change the world? Let us know. Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!",
        "url": "https://www.linkedin.com/jobs/view/3967702356",
        "summary": "Ascendion, a digital engineering solutions company, is seeking a Front End Engineer with experience in VueJS, AngularJS, ReactJS, TypeScript, NodeJS, and AWS. This role involves developing and maintaining web applications, collaborating with back-end developers, optimizing applications for speed and scalability, implementing best practices in front-end development, utilizing NodeJS for server-side rendering, working with AWS services, and staying updated with industry trends.",
        "industries": [
            "Software Engineering",
            "Digital Engineering",
            "Technology",
            "Cloud Computing",
            "Web Development",
            "Data"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Teamwork",
            "Creativity",
            "Adaptability",
            "Time Management",
            "Organization",
            "Attention to Detail",
            "Critical Thinking",
            "Leadership"
        ],
        "hard_skills": [
            "VueJS",
            "AngularJS",
            "ReactJS",
            "TypeScript",
            "NodeJS",
            "AWS",
            "Responsive Design",
            "Cross-Browser Compatibility",
            "Accessibility Standards",
            "Server-Side Rendering",
            "API Integration",
            "Code Review",
            "Testing",
            "Debugging"
        ],
        "tech_stack": [
            "VueJS",
            "AngularJS",
            "ReactJS",
            "TypeScript",
            "NodeJS",
            "AWS"
        ],
        "programming_languages": [
            "VueJS",
            "AngularJS",
            "ReactJS",
            "TypeScript",
            "NodeJS"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 132000,
            "min": 110000
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "401(k) Retirement Plan",
            "Long-Term Disability Insurance",
            "Short-Term Disability Insurance",
            "Paid Time Off",
            "Paid Vacation Time",
            "Paid Holidays",
            "Floating Holiday",
            "Ascendion Learning Management System"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3931517046,
        "company": "Jobs Malaysia - Two95 HR HUB",
        "title": "Sr. Python AWS Engineer",
        "created_on": 1720587411.5224097,
        "description": "Title: Sr. Python AWS Engineer Location: Tysons, VA Job Type: 24 Months Contract Rate: $Open/hr. Requirements Job Description: Senior Python developer (boto3) Extensive AWS cloud platform experience (Lambda, APIs, CFT, S3, SNS, SQS) Working on automating compliance tasks and working on AWS service catalogue extension and customization. Service enables creation of compliance of AWS resources based on COF regulations. Working on producing S3 buckets, working with 2 other engineers on developing/customization Need to have knowledge of automating AWS Services including SNS and SQS via Lambda using Python code Develop and deploy in ALL Capital One accounts using a CI/CD pipeline called Capital One pipeline Working with other internal compliance apps, which will need to be integrated (A/D, Service Now), consuming and synchronizing API's AWS certificate Benefits Note: If interested please send your updated resume to joseph.prabakar@two95intl.com and include your salary requirement along with your contact details with a suitable time when we can reach you. If you know of anyone in your sphere of contacts, who would be a perfect match for this job then, we would appreciate if you can forward this posting to them with a copy to us. We look forward to hearing from you at the earliest!",
        "url": "https://www.linkedin.com/jobs/view/3931517046",
        "summary": "Senior Python AWS Engineer with extensive experience in AWS cloud platform (Lambda, APIs, CFT, S3, SNS, SQS), specifically automating compliance tasks and extending/customizing AWS service catalogue. The role involves developing and deploying in ALL Capital One accounts using a CI/CD pipeline, integrating with other internal compliance apps, consuming and synchronizing APIs. Proficiency in Python (boto3) and AWS certification required.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Cloud Computing",
            "Compliance",
            "Financial Services"
        ],
        "soft_skills": [
            "Automation",
            "Problem Solving",
            "Teamwork",
            "Communication",
            "Integration",
            "API Development"
        ],
        "hard_skills": [
            "Python",
            "boto3",
            "AWS",
            "Lambda",
            "APIs",
            "CFT",
            "S3",
            "SNS",
            "SQS",
            "CI/CD",
            "Service Now",
            "Git",
            "API Development",
            "AWS Certification"
        ],
        "tech_stack": [
            "AWS",
            "Lambda",
            "APIs",
            "CFT",
            "S3",
            "SNS",
            "SQS",
            "CI/CD",
            "Service Now",
            "Git",
            "Python",
            "boto3"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3866669812,
        "company": "Mission Technologies, a division of HII",
        "title": "Senior Data Scientist (Data Scientist 4) - 18361",
        "created_on": 1720587412.9451783,
        "description": "Requisition Number: 18361 Required Travel: 0 - 10% Employment Type: Full Time/Salaried/Exempt Security Clearance: TS/SCI Level of Experience: Senior This opportunity resides with Cyber & Electronic Warfare , a business group within HII’s Mission Technologies division. HII works within our nation’s intelligence and cyber operations communities to defend our interests in cyberspace. Our deep expertise in network architecture, software and hardware development, cybersecurity and the electromagnetic environment uniquely enables us to support sensitive missions for federal agency partners. Meet HII’s Mission Technologies Division Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense – the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that’s right for you. Apply today. We look forward to meeting you. Job Description HII Mission Technologies is seeking an experienced Senior Data Scientist to help support our customer in Fairfax, VA. This position will act as the leader in identifying ETL tools to be incorporated in a data science enclave and participate in implementing a cloud-based environment into that data enclave. This role typically works on high-visibility or mission-critical aspects of a given program and performs all functional duties independently. This role may oversee the efforts of less senior staff and/or be responsible for the efforts of all staff assigned to a specific job. Essential Job Responsibilities Develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. Visualize, interpret, and report data findings. May create dynamic data reports. Conduct data cleaning and normalization Serve as data engineering POC for study areas ( JTIM, IMM, etc.) Work with data science tools in the cloud environment Leverage API's for data extraction Create data pipelines for data ingestion and leverage NLP for data conditioning/ transformation Design databases based on documented data model Manage data ( data categorization/labeling, retention, etc.) according to government strategy. Minimum Qualifications 9 years relevant experience with Bachelors in related field; 7 years relevant experience with Masters in related field; 4 years relevant experience with PhD or Juris Doctorate in realted field; or High School Diploma or equivalent and 13 years relevant experience. Holds an active TS/SCI IAT level II Certification Why HII We build the world’s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our diverse workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals. Recognized as one of America’s top large company employers, we are a values and ethics driven organization that puts people’s safety and well-being first. Regardless of your role or where you serve, at HII, you’ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career. Together we are working to ensure a future where everyone can be free and thrive. Today’s challenges are bigger than ever, and the nation needs the best of us. It’s why we’re focused on hiring, developing and nurturing our diversity. We believe that diversity among our workforce strengthens the organization, stimulates creativity, promotes the exchange of ideas and enriches the work lives of all our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law. Do You Need Assistance? If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Technical Solutions.",
        "url": "https://www.linkedin.com/jobs/view/3866669812",
        "summary": "HII Mission Technologies is looking for a Senior Data Scientist to support their customer in Fairfax, VA. The role involves leading the identification and implementation of ETL tools in a data science enclave, building a cloud-based environment, and applying data mining, modeling, NLP, and machine learning to analyze large datasets. Responsibilities include data cleaning, normalization, serving as data engineering POC, working with cloud tools, leveraging APIs, creating data pipelines, designing databases, and managing data according to government strategy.",
        "industries": [
            "Defense",
            "Cybersecurity",
            "Intelligence",
            "Data Science",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Leadership",
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Collaboration",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "ETL",
            "Data Mining",
            "Data Modeling",
            "Natural Language Processing",
            "Machine Learning",
            "Data Visualization",
            "Data Cleaning",
            "Data Normalization",
            "Data Engineering",
            "Cloud Computing",
            "API",
            "Data Pipelines",
            "NLP",
            "Database Design",
            "Data Management",
            "Data Categorization",
            "Data Labeling"
        ],
        "tech_stack": [
            "ETL Tools",
            "Data Science Enclave",
            "Cloud Environment",
            "Data Mining",
            "Data Modeling",
            "Natural Language Processing",
            "Machine Learning",
            "Visualization Software",
            "Data-Oriented Programming Languages",
            "API's",
            "Data Pipelines",
            "NLP",
            "Databases"
        ],
        "programming_languages": [],
        "experience": 9,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Benefits",
            "Educational and Training Programs"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3926566832,
        "company": "Intelliforce-IT Solutions Group, LLC.",
        "title": "Software Engineer",
        "created_on": 1720587414.4660747,
        "description": "To be considered for this opportunity you will need to possess an active TS/SCI with polygraph. We regret that we do not have the ability to assist you with gaining clearance at this time. Are you a cleared software engineer looking for a company that understands employees are its most valuable resources? Join our Best Workplace winning company that offers excellent perks, all designed to support the needs of you and your family! Overview Intelliforce is seeking a Software Engineer needed to support the innovation team within CNO's Foundational Services product group. Working with experienced operators, analysts and developers, you will have the ability to design and implement ideas that will benefit all professionals within the CNO product groups. Candidate must have excellent communication skills, the desire to learn and a passion for impacting mission critical work. Desired Skills: Expert with object oriented programming languages (Java, C ) Strong experience in Gradle or Maven Familiar with Git Containerization (Docker/Kubernetes) JavaScript Elasticsearch Nice to Know: Python Experience in GitLab CI/CD Knowledge of SIGINT Experience with CNO capabilities and operations Qualifications: Active TS/SCI with polygraph clearance is required 14 years experience, B.S. Degree in Computer Science or related discipline from an accredited university/college in needed. Four (4)additional years as a software developer experience may be substituted for the B.S degree Who Is Intelliforce-ITSG We are an Intelligent Force of Engineers providing solutions to complicated problems. We are people driven and motivated to provide you with an excellent work life balance. Offering all employees clear expectations, professional development, and social connections. Benefits We host a variety of fun employee and family events throughout the year to say thanks for all that you do to make Intelliforce a phenomenal place to work Competitive salary Health, Dental, and Vision Insurance plans Quality of life differential We offer a 401(k) Profit Sharing Plan that offers a powerful way to enhance your long- term financial well-being by investing in yourself Ample Paid Time Off Paid Training and Education! If this isn't quite right for you but you know someone who would love it? Intelliforce offers a $10,000 referral bonus for all qualified hires. Powered by JazzHR EHCiQ25qI5",
        "url": "https://www.linkedin.com/jobs/view/3926566832",
        "summary": "Intelliforce seeks a Software Engineer to join its innovation team within CNO's Foundational Services product group. The role involves designing and implementing solutions for mission-critical work, collaborating with experienced operators, analysts, and developers. Strong communication skills, a passion for learning, and a desire to contribute to impactful work are essential. The ideal candidate will be an expert in object-oriented programming languages, particularly Java and C++, with experience in Gradle/Maven, Git, containerization (Docker/Kubernetes), JavaScript, and Elasticsearch. Knowledge of Python, GitLab CI/CD, SIGINT, CNO capabilities and operations is also beneficial.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Learning Agility",
            "Teamwork"
        ],
        "hard_skills": [
            "Java",
            "C++",
            "Gradle",
            "Maven",
            "Git",
            "Docker",
            "Kubernetes",
            "JavaScript",
            "Elasticsearch",
            "Python",
            "GitLab CI/CD",
            "SIGINT"
        ],
        "tech_stack": [
            "Java",
            "C++",
            "Gradle",
            "Maven",
            "Git",
            "Docker",
            "Kubernetes",
            "JavaScript",
            "Elasticsearch",
            "Python",
            "GitLab CI/CD"
        ],
        "programming_languages": [
            "Java",
            "C++",
            "JavaScript",
            "Python"
        ],
        "experience": 14,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Computer Science",
                "Related Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "Health, Dental, and Vision Insurance plans",
            "Quality of life differential",
            "401(k) Profit Sharing Plan",
            "Ample Paid Time Off",
            "Paid Training and Education",
            "Employee and family events"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3945556992,
        "company": "Citizant",
        "title": "Applications Software Developer - SME - 100% Remote (REF1606N)",
        "created_on": 1720587416.0471232,
        "description": "Company Description Citizant is a leading provider of professional IT services to the U.S. government. We seek to address some of our country’s most pressing challenges in the areas of Agile application development, Enterprise Data Management, Enterprise Architecture, and Program Management support services – focusing on the U.S. Departments of Homeland Security and Treasury. We strive to hire only ethical, talented, passionate, and committed “A Players” who already align with the company’s core values: Drive, Excellence, Reputation, Responsibility, and a Better Future. No matter how large we grow, Citizant will retain its collaborative, supportive, small-company culture, where successful team effort to address external and internal customer challenges is valued above all individual contributions. Job Description Position Overview: We are seeking a highly skilled and experienced Subject Matter Expert Applications Software Developer to join our dynamic team. As a key member of our software development team, you will play a critical role in designing, developing, and maintaining high-quality applications that meet the needs of our clients and end-users. Responsibilities: Collaborate with cross-functional teams to gather and analyze requirements, design solutions, and develop software applications that align with business objectives. Lead the design and architecture of complex software systems, ensuring scalability, reliability, and performance. Develop clean, efficient, and maintainable code in accordance with best practices and coding standards. Conduct thorough testing and debugging of applications to ensure quality and reliability. Stay current with emerging technologies and industry trends and incorporate them into the development process as appropriate. Provide technical guidance and mentorship to junior developers, fostering a culture of continuous learning and growth. Participate in code reviews, team meetings, and project planning sessions to ensure effective collaboration and communication. Qualifications Minimum of 7-10 years of experience in software development, with a focus on application development. Proficiency in multiple programming languages, such as Java, C#, Python, or JavaScript. Integrated Development Environment (IDE) experience for example (Eclipse). Extensive experience with software development methodologies and practices, including Agile/Scrum. Strong understanding of software architecture, design patterns, and principles. Proven track record of delivering high-quality, scalable software solutions on time and within budget. Excellent problem-solving skills and attention to detail. Strong communication and interpersonal skills, with the ability to collaborate effectively with team members and stakeholders. Experience with cloud computing platforms (e.g., AWS, Azure, Google Cloud) is a plus. Familiarity with DevOps practices and tools (e.g., CI/CD, Docker, Kubernetes) is desirable. Education Requirements: Bachelor’s degree in computer science, Software Engineering, or a related field. Clearance Requirements: Must be a US Citizen Active Public Trust/MBI or have the ability to obtain one. Additional Information Citizant strives to be an employer of choice in the Washington metropolitan area. Citizant associates accept challenging and rewarding work and in return receive excellent compensation and benefits, as well as the opportunity for personal and professional development. Citizant is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3945556992",
        "summary": "Citizant is seeking a skilled Subject Matter Expert Applications Software Developer with 7-10 years of experience in application development. Responsibilities include collaborating with teams, designing and developing software applications, ensuring scalability, and providing technical guidance. The ideal candidate will have proficiency in Java, C#, Python, or JavaScript, experience with Agile/Scrum, and familiarity with cloud platforms and DevOps tools. A Bachelor's degree in computer science or a related field is required.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Government",
            "Defense",
            "Cybersecurity",
            "Data Management",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Attention to Detail",
            "Leadership",
            "Mentorship",
            "Teamwork",
            "Interpersonal Skills"
        ],
        "hard_skills": [
            "Java",
            "C#",
            "Python",
            "JavaScript",
            "Agile/Scrum",
            "Software Architecture",
            "Design Patterns",
            "Cloud Computing",
            "AWS",
            "Azure",
            "Google Cloud",
            "DevOps",
            "CI/CD",
            "Docker",
            "Kubernetes",
            "Eclipse"
        ],
        "tech_stack": [
            "Java",
            "C#",
            "Python",
            "JavaScript",
            "Agile/Scrum",
            "AWS",
            "Azure",
            "Google Cloud",
            "CI/CD",
            "Docker",
            "Kubernetes",
            "Eclipse"
        ],
        "programming_languages": [
            "Java",
            "C#",
            "Python",
            "JavaScript"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Software Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Compensation",
            "Benefits Package",
            "Personal and Professional Development Opportunities"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3916110943,
        "company": "Capital One",
        "title": "Senior Data Scientist, AI Foundations",
        "created_on": 1720587417.4922564,
        "description": "Center 2 (19050), United States of America, McLean, VirginiaSenior Data Scientist, AI Foundations At Capital One, we think big and do big things. We are not just a nationally recognized credit card issuer, a top 10 bank by deposit, but a high-tech company with products that reach tens of millions of consumers and have been recognized by numerous prestigious awards for their customer-friendliness. Capital One was the first major bank to move to cloud computing and to publish APIs for the Open Banking future. AI is transforming every industry. At Capital One, you will help shape how it transforms financial services. Team Description AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies. In this role, you will: Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money. Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data. Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features. Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers. Flex your interpersonal skills to translate the complexity of your work into tangible business goals. The Ideal Candidate is: Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers. Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them. Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea. A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond. Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms. Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences. You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF. You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products. Basic Qualifications: Currently has, or is in the process of obtaining a Bachelor’s Degree plus 2 years of experience in data analytics, or currently has, or is in the process of obtaining Master’s Degree, or currently has, or is in the process of obtaining PhD, with an expectation that required degree will be obtained on or before the scheduled start dat At least 1 year of experience in open source programming languages for large scale data analysis At least 1 year of experience with machine learning At least 1 year of experience with relational databases Preferred Qualifications: Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) At least 1 year of experience working with AWS At least 2 years’ experience in Python, PyTorch, Scala, or R At least 2 years’ experience with machine learning At least 2 years’ experience with SQL At least 2 years' experience working with natural language processing Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. New York City (Hybrid On-Site): $138,500 - $158,100 for Data Science Masters San Francisco, California (Hybrid On-site): $146,700 - $167,500 for Data Science Masters Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter. This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
        "url": "https://www.linkedin.com/jobs/view/3916110943",
        "summary": "Capital One seeks a Senior Data Scientist to join their AI Foundations Specialist Models Data Science team. This role involves building and deploying scalable AI/ML solutions for the Capital One mobile app, working with product, tech, and design teams to create personalized experiences for customers. Key responsibilities include leveraging a variety of technologies (Pytorch, AWS, Hugging Face, LangChain, etc.) for data analysis, specializing in NLP and LLMs for customer-facing applications, and building machine learning models in a production environment.  Ideal candidates are customer-first, innovative, creative, leaders with strong technical skills and experience with LLMs, open-source tools, and cloud platforms.  Prior experience in training language or vision models, training optimization, self-supervised learning, explainability, RLHF, and delivering models at scale is preferred.",
        "industries": [
            "Financial Services",
            "Technology",
            "Banking"
        ],
        "soft_skills": [
            "Customer-Oriented",
            "Innovative",
            "Creative",
            "Leadership",
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical"
        ],
        "hard_skills": [
            "Python",
            "PyTorch",
            "AWS",
            "Hugging Face",
            "LangChain",
            "Lightning",
            "VectorDBs",
            "Natural Language Processing (NLP)",
            "Large Language Models (LLMs)",
            "Machine Learning",
            "Deep Learning",
            "Relational Databases",
            "SQL",
            "Scala",
            "R",
            "Training Optimization",
            "Self-Supervised Learning",
            "Explainability",
            "Reinforcement Learning from Human Feedback (RLHF)"
        ],
        "tech_stack": [
            "Pytorch",
            "AWS Ultraclusters",
            "Hugging Face",
            "LangChain",
            "Lightning",
            "VectorDBs"
        ],
        "programming_languages": [
            "Python",
            "Scala",
            "R"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Analytics",
                "Science",
                "Technology",
                "Engineering",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 167500,
            "min": 138500
        },
        "benefits": [
            "Health Insurance",
            "Financial Benefits",
            "Performance Based Incentive Compensation",
            "Cash Bonus",
            "Long Term Incentives"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3921566899,
        "company": "Booz Allen Hamilton",
        "title": "Supply Chain Data Scientist, Senior",
        "created_on": 1720587419.0080118,
        "description": "Job Number: R0197432 Supply Chain Data Scientist, Senior The Opportunity: As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, we need you to help find the answers in the data. On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used. Work with us as we use data science for good. Join us. The world can’t wait. You Have: 10+ years of experience with Data Science challenges for Supply Chain challenges 5+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining 5+ years of experience with statistical and general-purpose programming languages for data analysis, and analyzing structured and unstructured data sources Experience providing technical and management leadership to specify and implement data management solutions for logistics information systems Experience with Agile practices, AI, and ML technologies to drive the collection, storage, analysis, and utilization of data to enable informed business decisions for Supply Chain needs Experience developing predictive data models, quantitative analyses, and visualization of targeted data sources Experience leading the development of solutions to complex programs Experience with natural language processing, text mining, or ML techniques Top Secret clearance Bachelor’s degree Nice If You Have: Experience in the development of algorithms leveraging R, Python, or SQL/NoSQL Experience with distributed data or computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL Experience with visualization packages, including Plotly, Seaborn, or ggplot2 Master's degree preferred; Doctorate degree a plus Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Top Secret clearance is required. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $110,100.00 to $250,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "url": "https://www.linkedin.com/jobs/view/3921566899",
        "summary": "Booz Allen Hamilton is seeking a Senior Supply Chain Data Scientist to work with clients on understanding their data and using it to solve global challenges. This role will require strong leadership and technical skills in data exploration, analysis, and visualization, as well as experience with AI and ML technologies. The ideal candidate will have experience in supply chain challenges and working with structured and unstructured data sources. The role offers a competitive salary and comprehensive benefits package.",
        "industries": [
            "Data Science",
            "Supply Chain",
            "Logistics",
            "Information Systems",
            "Analytics",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Leadership",
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Analytical Thinking",
            "Decision Making",
            "Time Management",
            "Presentation Skills",
            "Client Relationship Management"
        ],
        "hard_skills": [
            "Data Exploration",
            "Data Cleaning",
            "Data Analysis",
            "Data Visualization",
            "Data Mining",
            "Statistical Programming",
            "General-Purpose Programming",
            "Agile Practices",
            "AI",
            "ML",
            "Predictive Modeling",
            "Quantitative Analysis",
            "Natural Language Processing",
            "Text Mining",
            "R",
            "Python",
            "SQL",
            "NoSQL",
            "MapReduce",
            "Hadoop",
            "Hive",
            "EMR",
            "Kafka",
            "Spark",
            "Gurobi",
            "MySQL",
            "Plotly",
            "Seaborn",
            "ggplot2"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SQL",
            "NoSQL",
            "MapReduce",
            "Hadoop",
            "Hive",
            "EMR",
            "Kafka",
            "Spark",
            "Gurobi",
            "MySQL",
            "Plotly",
            "Seaborn",
            "ggplot2"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL",
            "NoSQL"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Statistics",
                "Computer Science",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 250000,
            "min": 110100
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs",
            "Dependent Care",
            "Recognition Awards"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Bethesda, MD",
        "job_id": 3967166273,
        "company": "Infomatics Corp",
        "title": "Software Engineer",
        "created_on": 1720587420.4188378,
        "description": "Looking for Golang developer. Those who have strong experience with Cloud (AWS, OR Azure OR GCP) and Microservices.",
        "url": "https://www.linkedin.com/jobs/view/3967166273",
        "summary": "Looking for a Golang developer with strong experience in cloud platforms (AWS, Azure, or GCP) and microservices.",
        "industries": [
            "Software Development",
            "Technology",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork"
        ],
        "hard_skills": [
            "Golang",
            "Cloud Computing",
            "Microservices",
            "AWS",
            "Azure",
            "GCP"
        ],
        "tech_stack": [
            "Golang",
            "AWS",
            "Azure",
            "GCP",
            "Microservices"
        ],
        "programming_languages": [
            "Golang"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3969823311,
        "company": "Ntrepid LLC",
        "title": "Service Now Developer",
        "created_on": 1720587422.2070744,
        "description": "Ntrepid’s Customer Operations and Support (COPS) org is seeking an energetic and talented ServiceNow Developer. In this role, you will be responsible for the on-going implementation and maintenance of Ntrepid’s ServiceNow Platform in close collaboration with other team members within the Business Services and Support department. The ideal candidate will have fluency in ServiceNow design and development principles with focus on the ITSM product, a strong background collecting requirements and implementing business workflows, and extensive experience with the integration of other tools into the ServiceNow Platform via the ServiceNow Store, ServiceNow Integration Hub, and/or custom development. Implement, configure, and maintain the ServiceNow deployment and new and existing ServiceNow Modules including Incident Management, Change Management, Self Service Portal and Service Catalog, Asset Management, CMDB, and IT Operations Management; Integrate complementary tools into the ServiceNow deployment (Splunk, Crowdstrike, Atlassian, etc.) as available through ServiceNow Integration Hub, ServiceNow Store, or custom development if required; Customize and develop workflows, business rules, UI policies, and client scripts to automate processes, support business needs, and enhance user experience; Participate in project planning, requirements gathering, solution design, and implementation phases with business stakeholders and implementation team members to achieve desired outcomes and ensure the stability and scalability of the platform; Perform testing and validation of configured solutions to ensure they meet the specified requirements and are free of defects; Generate and maintain ServiceNow Platform technical documentation for end users, administrators, and business stakeholders; and Stay up to date with ServiceNow best practices, new features, and industry trends to continually improve implementation processes. U.S. Citizenship Required Ability to obtain and maintain a security clearance 7+ years technology/software industry, customer service, or related experience 3+ years direct development experience with the ServiceNow platform Experience implementing and supporting ServiceNow IT Service Management and related modules Experience with troubleshooting and resolving issues and problems with varying levels of complexity within the ServiceNow Platform and integrations Demonstrated experience and knowledge of JavaScript, XML, web services and APIs Flexibility to support issues or planned activities after hours, weekends and holidays as needed Strong communication skills and effective time management skills ServiceNow System Administrator Certification ServiceNow Developer Certification ITILv4 Foundations Certification (or demonstrated competency in ITIL best practices) Preferred Qualifications Active or Current Secret Clearance Demonstrated experience implementing/working with IT Operations Management and Service Graph Connectors Experience with ServiceNow Employee Center Experience with ServiceNow Mobile App design and configuration; ServiceNow Implementation Specialist Certification Additional ServiceNow or ITILv4 Certifications Candidate must not reside in the following states CA, CO, CT, MA, NJ, NY, NV, RI, or WA",
        "url": "https://www.linkedin.com/jobs/view/3969823311",
        "summary": "Ntrepid seeks a ServiceNow Developer to implement, maintain, and integrate their ServiceNow platform. Responsibilities include developing workflows, customizing modules, integrating tools like Splunk and Crowdstrike, and ensuring platform stability.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Time Management",
            "Collaboration",
            "Project Planning",
            "Requirements Gathering",
            "Solution Design",
            "Documentation"
        ],
        "hard_skills": [
            "ServiceNow",
            "ITSM",
            "Incident Management",
            "Change Management",
            "Self Service Portal",
            "Service Catalog",
            "Asset Management",
            "CMDB",
            "IT Operations Management",
            "Splunk",
            "Crowdstrike",
            "Atlassian",
            "JavaScript",
            "XML",
            "Web Services",
            "APIs"
        ],
        "tech_stack": [
            "ServiceNow",
            "Splunk",
            "Crowdstrike",
            "Atlassian"
        ],
        "programming_languages": [
            "JavaScript",
            "XML"
        ],
        "experience": 7,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3967340124,
        "company": "Dice",
        "title": "Data Scientist (TS/SCI)",
        "created_on": 1720587423.778845,
        "description": "Dice is the leading career destination for tech experts at every stage of their careers. Our client, Motion Recruitment Partners, LLC, is seeking the following. Apply via Dice today! A leading analytics company for federal clients is seeking a Data Scientist to join their team. The client is seeking an experienced professional with strong analytical and problem-solving skills, and is eager to lead projects supporting the Department of Defense (DoD). This role requires candidates to hold at least a TS/SCI clearance. Responsibilities Data curation and modeling Deployment and implementation Collaborate with external team for user requirements Qualifications Degree completion in Science, Math, or Engineering Python SQL Applicants must be currently authorized to work in the US on a full-time basis now and in the future. LI#-DP1 Data Scientist (TS/SCI)",
        "url": "https://www.linkedin.com/jobs/view/3967340124",
        "summary": "A leading analytics company serving federal clients seeks a Data Scientist with strong analytical and problem-solving skills. The candidate will lead projects for the Department of Defense (DoD) and must hold a TS/SCI clearance.",
        "industries": [
            "Analytics",
            "Government",
            "Defense"
        ],
        "soft_skills": [
            "Analytical",
            "Problem Solving",
            "Leadership"
        ],
        "hard_skills": [
            "Data Curation",
            "Modeling",
            "Deployment",
            "Implementation",
            "User Requirements",
            "SQL",
            "Python"
        ],
        "tech_stack": [
            "Python",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Science",
                "Math",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3970006943,
        "company": "ClearanceJobs",
        "title": "Artificial Intelligence / Machine Learning (AI/ML) Engineer with Security Clearance",
        "created_on": 1720587425.3971152,
        "description": "COMPANY OVERVIEW: ANSER enhances national and homeland security by strengthening public institutions. We provide thought leadership for complex issues through independent analysis, and we deliver practical, useful solutions. ANSER values collaboration, integrity, and initiative and we are client focused in all that we do. Because we were established for the purpose of public service and not for profit, we measure our success in the impact of our service. SPECIFIC JOB DESCRIPTION: ANSER is seeking Artificial Intelligence (AI)/ Machine Learning (ML) Engineers and Architects who have experience in designing and implementing AI solutions across various domains. In this key role you will support national geospatial programs and projects. You will play a crucial part in designing and implementing scalable, efficient AI/ML solutions for various projects. You will use AI, big data analytic tools and ML as mechanisms to predict and determine relationships and trends. You will develop new and improve existing AI/ML models operating on various forms of RF data to identify anomalies and events of interest. You will correlate complex, technical findings into graphical, written, visual, and verbal narrative products on existing data trends to leverage other military or commercial data sources. As part of the key team you will also develop white papers, reports and other documents including technical and programmatic assessments presenting analysis, results, conclusions, and recommendations. Required Qualifications and Experience: Bachelors degree with 8 or more years of relevant experience. Will consider a Masters degree and 5+ years of relevant experience. A minimum of 5 years of hands-on experience in architecting and implementing AI solutions, with focus in machine learning, deep learning, and natural language processing. Expertise in one or more modern programming languages such as C. C++ or Python Hands-on development experience in AI/ML model building and tuning. A minimum of 1-year demonstrable experience in working with non-proprietary large language models. Modern software development practices (Git, CI/CD toolchains) TS/SCI with Polygraph level clearance. Demonstrated knowledge of advanced AI techniques, such as reinforcement learning, generative adversarial networks (GANs), or federated learning. THIS POSITION REQUIRES WORK ON-SITE 5 DAYS A WEEK IN CHANTILLY, VA. REMOTE OR HYBRID WORK IS NOT AN OPTION. Preferred Qualifications and Experience: DISCLAIMER: In compliance with the Americans with Disabilities Act Amendment Act (ADA), if you have a disability and would like to request an accommodation in order to apply for a position with ANSER, please call 703-416-2000 or e-mail . ANSER is proud to be an Equal Opportunity Employer. We seek individuals from a broad variety of backgrounds with varying levels of experience who have a desire to do meaningful work. We recruit, employ, train, compensate, and promote regardless of race, color, gender, religion, national origin, ancestry, disability, age, sexual orientation, or any other characteristic protected by law.",
        "url": "https://www.linkedin.com/jobs/view/3970006943",
        "summary": "ANSER is looking for AI/ML Engineers and Architects with experience in designing and implementing AI solutions for national geospatial programs. You will use AI, big data analytics, and ML to predict trends and develop/improve AI/ML models for RF data analysis. The role involves creating reports, presentations, and technical assessments. This position requires on-site work 5 days a week in Chantilly, VA.",
        "industries": [
            "National Security",
            "Geospatial Intelligence",
            "Defense",
            "Government",
            "Aerospace"
        ],
        "soft_skills": [
            "Collaboration",
            "Integrity",
            "Initiative",
            "Client Focus",
            "Communication",
            "Presentation Skills",
            "Technical Writing"
        ],
        "hard_skills": [
            "AI",
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing",
            "RF Data Analysis",
            "Big Data Analytics",
            "Model Building",
            "Model Tuning",
            "Large Language Models",
            "Reinforcement Learning",
            "Generative Adversarial Networks",
            "Federated Learning"
        ],
        "tech_stack": [
            "C",
            "C++",
            "Python",
            "Git",
            "CI/CD Toolchains"
        ],
        "programming_languages": [
            "C",
            "C++",
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Springfield, VA",
        "job_id": 3910599147,
        "company": "ClearanceJobs",
        "title": "Junior Data Scientist with Security Clearance",
        "created_on": 1720587427.003341,
        "description": "Job Description Why Choose Royce Geo We're not your typical government contracting company, nor do we want to be. At Royce Geo, we live for building durable and long-lasting relationships with our clients, providing exceptional service with a CAN'T QUIT / WON'T QUIT attitude. We are creating a culture of winning, optimism, FUN, and caring for the person next to you. If you want to work in a real team environment and share the wealth and satisfaction of providing real value to your customer, then this company may be just for you. Royce Geo prides ourselves in our values-first approach. Our values of Accountability, Attitude, Communication, Innovation, and Leadership are integrated into how we approach problems, guide our interactions with others, and create the framework for our culture. We recognize and reward our team members that champion these attributes. We offer a competitive benefit package that is designed to attract and retain exceptional talent. We take care of our team members from multiple facets including health, financial, and well-being programs: * Robust health plan including medical, dental, and vision * Health Savings Account with company contribution * Annual Paid Time Off and Paid Holidays * Paid Parental Leave * 401k with generous company match * Training and Development Opportunities * Award Programs * Variety of Company Sponsored Events Be a part of a new corporate program for Royce Geo! We are looking for a results-driven Data Scientist to support NSG strategies through the creation of automated collection, models, dynamic analytic models, workflow automations, and any other automation processes and products as assigned. Responsibilities: * Support NSG strategies through the creation of automated collection models, dynamic analytic models, workflow automations, and any other automation processes and products as assigned. Refine, enhance, and improve the operational performance of any automated solution through the evaluation of performance data, regular customer interaction, and a standardized maintenance cycle. Apply data science and visual programming tradecraft to support and streamline analysis tasks as identified by stakeholders and the government. Enhance technical solutions to problems related to IC intelligence integration, automated collections, tipping and cueing, information sharing, and visualization. Conduct extensive collections and analytic modeling, data processing, data mining, and visualization. Conduct gap analysis on existing technologies and processes. Provide communication to customers on the progress for projects, processes, and emerging technologies as they become available. Clearly communicate data-driven findings and automation to technical and non-technical audiences. Design, integrate, and maintain Bayesian Belief Network (BBN) processes that utilize automation tools or scripts to drive predictive, activity-based automated collection. Conduct customer elicitation to identify processing problems due to procedures, tools, and services; work arounds that may need a permanent solution; and gaps in tools and technology. Train and integrate new tools, processes, and capabilities to be used in collection orchestration. Provide support for emerging requirements as assigned by the government. Required Qualifications: * Active TS/SCI Clearance. Proficiency in common geospatial software applications and tools, such as visual programming (JEMA, FADE/MIST, ECO/ETAS), Python, SQL, Git, GIMS, A WS Sagemaker, A WS Cloud, ESRI ArcGIS, statistics (descriptive, Bayesian), Markov-Chain modelling, TensorFlow, Linear Algebra, R, SAS, NLP. 1 year of relevant experiencewith a bachelor's degree. (A combination of years of experience & professional certifications/trainings can be used in lieu of a degree) EEO Statement Royce Geo. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability. Anyone requiring reasonable accommodations should email or call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days. Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov) Please review our current job openings and apply for the positions you believe may be a fit. If you are not an immediate fit, we will also keep your resume in our database for future opportunities. About Royce Geo Established in 2015, Royce Geo has quickly evolved into a well-rounded, diverse, small business tackling some of the most complex issues for our Defense and Intelligence Community clients. We are an award-winning small business firm, providing vital support to our mission partners across four core areas: Geospatial Information Technology, Data Analytics, Intelligence, and Training. Our team members are highly skilled subject matter experts, who listen and partner with our clients to accomplish the mission. We own the problem and find the solution while upholding the highest standards-to exceed expectations. We take risks and challenge the status quo to deliver innovative and cutting-edge solutions. Our employee-centric company culture is everything. Even while we grow, our small company mentality continues to exist. We demand inspiration from our leadership, and accountability from all so that we can influence others through our actions. This is Royce Geo.",
        "url": "https://www.linkedin.com/jobs/view/3910599147",
        "summary": "Royce Geo, a government contracting company, is looking for a Data Scientist to support NSG strategies through the creation of automated collection models, dynamic analytic models, workflow automations, and other automation processes. The candidate will work on refining, enhancing, and improving the operational performance of automated solutions, applying data science and visual programming tradecraft to support and streamline analysis tasks, and enhancing technical solutions to problems related to IC intelligence integration, automated collections, tipping and cueing, information sharing, and visualization.  They will conduct gap analysis on existing technologies and processes, communicate data-driven findings and automation to technical and non-technical audiences, and design, integrate, and maintain Bayesian Belief Network (BBN) processes that utilize automation tools or scripts to drive predictive, activity-based automated collection. They will also conduct customer elicitation to identify processing problems due to procedures, tools, and services, workarounds that may need a permanent solution, and gaps in tools and technology. The ideal candidate has proficiency in common geospatial software applications and tools, such as visual programming (JEMA, FADE/MIST, ECO/ETAS), Python, SQL, Git, GIMS, A WS Sagemaker, A WS Cloud, ESRI ArcGIS, statistics (descriptive, Bayesian), Markov-Chain modelling, TensorFlow, Linear Algebra, R, SAS, NLP.  They will also have 1 year of relevant experience with a bachelor's degree.",
        "industries": [
            "Government Contracting",
            "Defense",
            "Intelligence",
            "Geospatial Information Technology",
            "Data Analytics"
        ],
        "soft_skills": [
            "Results-driven",
            "Communication",
            "Customer Interaction",
            "Problem-solving",
            "Technical Communication",
            "Teamwork",
            "Leadership"
        ],
        "hard_skills": [
            "Automated Collection",
            "Dynamic Analytic Models",
            "Workflow Automations",
            "Data Science",
            "Visual Programming",
            "IC Intelligence Integration",
            "Tipping and Cueing",
            "Information Sharing",
            "Visualization",
            "Gap Analysis",
            "Bayesian Belief Network",
            "Customer Elicitation",
            "Training",
            "JEMA",
            "FADE/MIST",
            "ECO/ETAS",
            "Python",
            "SQL",
            "Git",
            "GIMS",
            "AWS Sagemaker",
            "AWS Cloud",
            "ESRI ArcGIS",
            "Descriptive Statistics",
            "Bayesian Statistics",
            "Markov-Chain Modelling",
            "TensorFlow",
            "Linear Algebra",
            "R",
            "SAS",
            "NLP"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Git",
            "GIMS",
            "AWS Sagemaker",
            "AWS Cloud",
            "ESRI ArcGIS",
            "JEMA",
            "FADE/MIST",
            "ECO/ETAS"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "R",
            "SAS"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Robust health plan (medical, dental, vision)",
            "Health Savings Account with company contribution",
            "Annual Paid Time Off",
            "Paid Holidays",
            "Paid Parental Leave",
            "401k with company match",
            "Training and Development Opportunities",
            "Award Programs",
            "Variety of Company Sponsored Events"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3956006144,
        "company": "ApTask",
        "title": "AWS Gen AI Engineer",
        "created_on": 1720587428.5000124,
        "description": "About Client: The Client is a leading global IT services and consulting company, providing a wide range of services to clients in various industries, including banking, financial services, retail, manufacturing, healthcare, and more. It is one of the largest employers in the IT industry and has a vast and diverse workforce. The company places a strong emphasis on employee training and development. Client is known for its commitment to innovation and invests in research and development to stay at the forefront of technological advancements. It offers a comprehensive set of services, including: IT Services: Application development, maintenance, and testing. Consulting: Business consulting, IT strategy, and digital transformation. Business Process Outsourcing (BPO): Outsourcing of business processes to improve efficiency. Enterprise Solutions: Implementation and support of enterprise-level software solutions. Digital Services: Services related to digital technologies, such as analytics, cloud, and IoT. Salary Range: $110K-$120K/Annum Job Description: Strong understanding of machine learning and deep learning principles and algorithms. Strong Experience in Copilot or Amazon Code Whisperer(Amazon Q). Proficiency in programming languages such as Python and PyTorch. Experience in applying Gen AI techniques using JIRA, Confluence, Jenkins, BitBucket DevOps Tools. Ability to work with large datasets and knowledge of data preprocessing techniques. Understand of different languages like Java, Groovy and SQL. Experience in developing and implementing generative AI models and algorithms. Familiarity with natural language processing (NLP) and computer vision for generative AI applications. Experience in building and deploying generative AI systems in real-world applications. Strong problem-solving and critical thinking skills for complex AI problems. Excellent communication and teamwork abilities to collaborate with cross-functional teams. Proven track record of delivering innovative solutions using generative AI technologies. Ability to stay updated with the latest advancements in generative AI and adapt to new techniques and methodologies. Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders About ApTask: ApTask is a leading global provider of workforce solutions and talent acquisition services, dedicated to shaping the future of work. As an African American-owned and Veteran-certified company, ApTask offers a comprehensive suite of services, including staffing and recruitment solutions, managed services, IT consulting, and project management. With a focus on excellence, collaboration, and innovation, ApTask provides unparalleled opportunities for professional growth and development. As a member of the ApTask team, you will have the chance to connect businesses with top-tier professionals, optimize workforce performance, and drive success across diverse industries. Join us at ApTask and be part of our mission to empower organizations to thrive while fostering a diverse and inclusive work environment. Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. Candidate Data Collection Disclaimer: At ApTask, we prioritize safeguarding your privacy. As part of our recruitment process, certain Personally Identifiable Information (PII) may be requested by our clients for verification and application purposes. Rest assured, we strictly adhere to confidentiality standards and comply with all relevant data protection laws. Please note that we only collect the necessary information as specified by each client and do not request sensitive details during the initial stages of recruitment. If you have any concerns or queries about your personal information, please feel free to contact our compliance team at businessexcellence@aptask.com",
        "url": "https://www.linkedin.com/jobs/view/3956006144",
        "summary": "This job posting seeks a Generative AI specialist with strong experience in machine learning, deep learning, and Gen AI technologies. The role involves developing and deploying AI models and algorithms for real-world applications. Expertise in Python, PyTorch, NLP, computer vision, and DevOps tools is crucial, along with excellent communication and problem-solving skills.",
        "industries": [
            "IT Services",
            "Consulting",
            "Business Process Outsourcing (BPO)",
            "Enterprise Solutions",
            "Digital Services",
            "Financial Services",
            "Retail",
            "Manufacturing",
            "Healthcare",
            "Banking"
        ],
        "soft_skills": [
            "Problem-solving",
            "Critical Thinking",
            "Communication",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Copilot",
            "Amazon Code Whisperer",
            "Python",
            "PyTorch",
            "JIRA",
            "Confluence",
            "Jenkins",
            "BitBucket",
            "Data Preprocessing",
            "Java",
            "Groovy",
            "SQL",
            "Natural Language Processing (NLP)",
            "Computer Vision"
        ],
        "tech_stack": [
            "Python",
            "PyTorch",
            "JIRA",
            "Confluence",
            "Jenkins",
            "BitBucket",
            "Java",
            "Groovy",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Groovy",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 120000,
            "min": 110000
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3952844149,
        "company": "Catapult Federal Services",
        "title": "Application Developer",
        "created_on": 1720587431.477796,
        "description": "Application Developer Technical Skills with 7-10 Years of Experience: Agile Team Practices Oral Communications Written Communication Java Full Stack Development Java Role Description : Design, build and configure applications to meet business process and application requirements. Design, develop and test custom software solutions across multiple system components or applications. Create implementation or integration approach for applications and components. Translate system requirements into design specifications. Provide primary support for installation of application releases into production. Design and code applications in line with programming standards and interface specifications. JAVA Full Stack Development, Structured Query Language (SQL), Oracle Applications, GitHub, Agile Team Practices. Education Level: Bachelor's Preferred Work Location: Washington, D.C. 20% Clearance Required : Public Trust - Full Clearance",
        "url": "https://www.linkedin.com/jobs/view/3952844149",
        "summary": "This job requires a skilled Application Developer with 7-10 years of experience. The role involves designing, building, and configuring applications to fulfill business needs, developing custom software solutions, creating implementation plans, translating requirements into specifications, and providing support for production releases.  The ideal candidate will have strong Java Full Stack development skills, SQL experience, proficiency in Oracle Applications, familiarity with GitHub, and experience with Agile methodologies.",
        "industries": [
            "Information Technology",
            "Software Development"
        ],
        "soft_skills": [
            "Oral Communications",
            "Written Communication",
            "Agile Team Practices"
        ],
        "hard_skills": [
            "Java Full Stack Development",
            "Java",
            "Structured Query Language (SQL)",
            "Oracle Applications",
            "GitHub",
            "Agile Team Practices"
        ],
        "tech_stack": [
            "Java",
            "SQL",
            "Oracle Applications",
            "GitHub"
        ],
        "programming_languages": [
            "Java"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor's",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3961646248,
        "company": "ClearanceJobs",
        "title": "Data Scientist with Security Clearance",
        "created_on": 1720587434.388718,
        "description": "We are a federal IT company on a mission to make customer experience (CX) the center of every government solution. Technology is our Passion. People are our Purpose. We know tech, but we love people. NuAxis is home to thinkers and feelers; engineers and artists. We work hard and support each other along the way. Teamwork is more than just a buzzword for us, it's a state of mind. We believe happy employees do amazing work, so join our team NOW! We are seeking a talented and motivated Data Scientist for a Full-Time remote position. Job Summary: You will be responsible for developing automated tools, conducting data mining, enhancing data collection procedures, and supporting various analytical and IT initiatives. This role will directly support the customer's mission through the creation of intelligence products and automated systems that streamline processes and enhance operational efficiency. Key Responsibilities: Select features, build, and optimize classifiers using machine learning techniques. Create usable tools and systems to streamline processes and reduce manual resource hours. Utilize advanced methods to mine large data sets from various sources. Produce intelligence products that support USPIS strategies and missions. Enhance product results by integrating third-party data where applicable. Automate repetitive processes and include relevant data for analytical systems. Process, cleanse, and verify the integrity of collected data. Perform ad-hoc analysis and present results clearly through presentations, written documents, graphs, and charts. Develop and implement an automated anomaly detection system with performance tracking. Assist with general IT support tasks as needed within the CI2 and CI2 NTC environment. Support and enhance Cloud resource hosting solutions for APOLLO, HYDRA, and ORION. Qualifications: Bachelor's degree in Computer Science, Data Science, Statistics, or a related field (Master's degree preferred). Proven experience in developing machine learning models and automated tools. Strong expertise in data mining and the use of state-of-the-art methods. Experience with third-party data integration and enhancement. Proficiency in data collection, processing, and verification. Ability to conduct and present ad-hoc analysis clearly and effectively. Experience with anomaly detection systems and performance tracking. General IT support skills and familiarity with USPS and USPIS policies. Experience with Cloud resource hosting solutions is a plus. Strong analytical, problem-solving, and communication skills. Does this opportunity sound like a fit for you? If so, join our talent community and click to apply now!! Our Profile: We are an IT company with a unique mission-to make people the center of every federal IT solution. Our technologists have always gone the extra mile to help our federal clients succeed. And over the years, we saw a growing disconnect in how federal IT initiatives were built and managed.Time after time, programs failed because the focus was on the tools and products and not the people using them. Learn More NuAxis is an Equal Opportunity/Affirmative Action Employer, including Vets and Disabled. Employment is contingent upon successful completion of a background investigation. Learn More about our Benefits and Culture! #NAI #DICE",
        "url": "https://www.linkedin.com/jobs/view/3961646248",
        "summary": "NuAxis is seeking a Data Scientist to develop automated tools, conduct data mining, and enhance data collection procedures for a federal IT client. This role will support the customer's mission by creating intelligence products and automated systems to streamline processes and enhance operational efficiency.",
        "industries": [
            "Information Technology",
            "Government",
            "Federal",
            "Data Science",
            "Machine Learning",
            "Analytics",
            "Intelligence"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Analytical",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Mining",
            "Data Collection",
            "Data Processing",
            "Data Verification",
            "Data Integration",
            "Anomaly Detection",
            "Performance Tracking",
            "Cloud Resource Hosting",
            "IT Support",
            "Presentation",
            "Reporting"
        ],
        "tech_stack": [
            "APOLLO",
            "HYDRA",
            "ORION"
        ],
        "programming_languages": [],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Equal Opportunity Employer",
            "Affirmative Action Employer",
            "Vets and Disabled",
            "Background Investigation"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3815993872,
        "company": "Software Engineering Institute | Carnegie Mellon University",
        "title": "Machine Learning Research Scientist",
        "created_on": 1720587435.8406355,
        "description": "What We Do: At the SEI AI Division, we conduct research in applied artificial intelligence and the engineering questions related to the practical design and implementation of AI technologies and systems. We currently lead a community-wide movement to mature the discipline of AI Engineering for Defense and National Security. As our government customers adopt AI and machine learning to provide leap-ahead mission capabilities, we build real-world, mission-scale AI capabilities through solving practical engineering problems discover and define the processes, practices, and tools to support operationalizing AI for robust, secure, scalable, and human-centered mission capabilities prepare our customers to be ready for the unique challenges of adopting, deploying, using, and maintaining AI capabilities identify and investigate emerging AI and AI-adjacent technologies that are rapidly transforming the technology landscape Are you creative, curious, energetic, collaborative, technology-focused, and hard-working? Are you interested in making a difference by bringing innovation to government organizations and beyond? Apply to join our team. Position Summary: As a research scientist specializing in machine learning, you will identify, shape, apply, conduct, and lead research that matches critical U.S. government needs. Requirements: BS in Computer Science or related discipline with eight (8) years of experience; OR MS in the same fields with five (5) years of experience; OR PhD with three (3) years of experience. Flexible to travel to other SEI offices in Pittsburgh and Washington, DC, sponsor sites, conferences, and offsite meetings on occasion. Moderate (25%) travel outside of your home location. You will be subject to a background investigation and must be eligible to obtain and maintain a Department of Defense security clearance. Applicants for this position must be currently legally authorized to work for CMU in the United States. CMU will not sponsor or take over sponsorship of an employment visa for this opportunity. Duties: Hands-on research: You’ll conduct and lead novel research in applied machine learning and artificial intelligence. Solution development: You’ll work with and lead interdisciplinary teams to turn research results into prototype operational capabilities for government customers and stakeholders. Strategy: You’ll work with Center leaders and colleagues to plan, develop, and carry out an overall research strategy, and to influence the national research agenda regarding future technology. Collaboration: You'll actively participate on teams of software developers, researchers, designers, and technical leads. You'll build relationships and collaborate with researchers, government customers, and other stakeholders to understand challenges, needs, possible solutions, and research directions. Mentoring: You'll contribute to improving the overall technical capabilities of the team by mentoring and teaching others, participating in design (software and otherwise) sessions, and sharing insights and wisdom across the SEI Artificial Intelligence Division. Knowledge, Skills, and Abilities: Deep technical knowledge: You have performed extensive research in applied machine learning and artificial intelligence. You have worked with tools, techniques, algorithms, software, and programming languages for deep learning, reinforcement learning, statistics, sensors and sensor fusion, planning, computer vision, or related areas. Communication and Collaboration: You have strong written and verbal communication skills and can interact collaboratively and diplomatically with customers and colleagues. You grasp the big picture, direction, and goals of an effort while focusing great attention to detail. You can present complex ideas to people who may not have a deep understanding of the subject area. Dedication: You can meet deadlines while multi-tasking–sometimes under pressure and with shifting priorities. Creativity and Innovation: You are creative and curious, and you are inspired by the prospect of collaborating with premier researchers and visionaries at Carnegie Mellon and other universities and organizations. You quickly learn new procedures, techniques, and approaches. You are forward-looking and can connect research with practical challenges. Knowledge and Learning: You possess broad technical interests along with a deep knowledge of a particular field such as human-computer interaction, data analytics and machine learning, advanced computing, and autonomy and adaptive systems. Desired Experience: Research practices and publications: You have a track record of conducting research in machine learning and artificial intelligence. You have a reputation for the highest level of research and technical integrity. You have demonstrated contributions and have published research. Familiarity with emerging trends and opportunities: You are familiar with technical challenges and emerging trends in computing and information science, and you are aware of opportunities in industry and government. Technical leadership: You have led research projects and have experience collaborating across research teams and mentoring other researchers. Proposals: You have formulated and delivered successful research proposals to funding agencies and led the resulting projects. Government projects: You have worked or are familiar with DARPA, IARPA, Service Labs, or other government research sponsors. Location Arlington, VA, Pittsburgh, PA Job Function Software/Applications Development/Engineering Position Type Staff – Regular Full time/Part time Full time Pay Basis Salary More Information: Please visit “Why Carnegie Mellon” to learn more about becoming part of an institution inspiring innovations that change the world. Click here to view a listing of employee benefits Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran. Statement of Assurance",
        "url": "https://www.linkedin.com/jobs/view/3815993872",
        "summary": "Research Scientist specializing in machine learning to conduct research, develop solutions, shape research strategy, collaborate with teams, and mentor others. Focuses on applied machine learning and AI, working with tools and techniques for deep learning, reinforcement learning, statistics, sensors, computer vision, etc. Requires strong communication, collaboration, and problem-solving skills. Experience with research practices, publications, emerging trends, technical leadership, proposal writing, and government projects preferred.",
        "industries": [
            "Defense",
            "National Security",
            "Government",
            "Research"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Creativity",
            "Innovation",
            "Learning",
            "Mentoring",
            "Leadership"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Reinforcement Learning",
            "Statistics",
            "Sensors",
            "Sensor Fusion",
            "Planning",
            "Computer Vision",
            "Data Analytics",
            "Human-Computer Interaction",
            "Advanced Computing",
            "Autonomy",
            "Adaptive Systems"
        ],
        "tech_stack": [
            "Machine Learning",
            "Deep Learning",
            "Reinforcement Learning",
            "Statistics",
            "Sensors",
            "Sensor Fusion",
            "Planning",
            "Computer Vision",
            "Data Analytics"
        ],
        "programming_languages": [],
        "experience": 8,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Computer Science",
                "Related discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Travel",
            "Background Investigation",
            "Department of Defense Security Clearance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Bethesda, MD",
        "job_id": 3968526270,
        "company": "LCG, Inc.",
        "title": "Test Automation Engineer",
        "created_on": 1720587437.5572815,
        "description": "Position Summary : We are seeking a highly skilled and experienced Test Automation Engineer to join our team. This hybrid role involves evaluating, testing, and validating IT systems, services, and software while also designing, building, and maintaining a stable and efficient infrastructure. The ideal candidate will ensure that our products meet the highest quality standards and improve our development and deployment processes through automation and continuous integration. Qualifications Evaluate, test, and validate IT systems, services, and software to ensure they meet established quality standards. Assess service levels and product performance, documenting issues and tracking status in designated systems. Develop and execute comprehensive test plans, defining test cases, scenarios, scripts, hardware, and software to cover all product backlog items. Utilize automated test solutions, specifically Subject 7, integrated with Azure DevOps to streamline testing processes. Implement continuous integration and continuous deployment (CI/CD) pipelines to facilitate automated testing at each stage of the sprint cycle. Conduct various types of testing including unit tests, integration tests, performance tests, and Section 508 compliance testing. Generate detailed test reports to provide insights into test coverage, identified defects, and overall application quality. Develop solutions to resolve problems and recommend improvements to processes, configurations, and products. Collaborate with project teams to ensure thorough coverage of all application user stories and acceptance criteria. Design, build, and maintain a stable and efficient infrastructure to optimize service delivery across production, QA, and development environments. Monitor, troubleshoot, maintain, and continuously improve building, packaging, and deployment processes. Implement automated infrastructure capabilities such as backups, security tools, and monitoring. Utilize deployment/configuration management tools like Jenkins, Maven, Puppet, or Ansible. Use version control tools like GIT, Bitbucket, SVN, or CVS. Ensure end-to-end quality across functions using a consistent DevOps approach. Manage network infrastructure, databases, cloud and data center operations, and security protocols. Develop scripts and programs using languages such as Python, Perl, Bash, PHP, Java, SQL, or C++. Understand AWS and other cloud services. Qualifications: Bachelor’s degree in IT, Computer Science, or a related field. 4-7 years of related experience in IT quality assurance and DevOps engineering. Strong knowledge of automated testing tools and frameworks, preferably Subject 7 and Azure DevOps. Experience with CI/CD pipelines and automated testing at each stage of the development cycle. Proficiency with deployment/configuration management tools like Jenkins, Maven, Puppet, or Ansible. Familiarity with version control tools such as GIT, Bitbucket, SVN, or CVS. Strong understanding of network infrastructure, databases, cloud and data center operations, and security protocols. Expertise in scripting and programming languages such as Python, Perl, Bash, PHP, Java, SQL, or C++. Excellent problem-solving skills and ability to develop innovative solutions. Strong communication and collaboration skills, with the ability to work independently and as part of a team. Compensation And Benefits The projected compensation range for this position is $103,000 to $143,000 per year benchmarked in the Washington, D.C. metropolitan area. The salary range provided is a good faith estimate representative of all experience levels. Salary at LCG is determined by various factors, including but not limited to role, location, the combination of education/training, knowledge, skills, competencies, certifications, and work experience. LCG offers a competitive, comprehensive benefits package which includes health insurance options (medical, dental, vision), life and disability insurance, retirement plan contributions, as well as paid leave, federal holidays, professional development, and lifestyle benefits. Devoted to Fair and Inclusive Practices All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. If you are interested in applying for employment with LCG and need special assistance or an accommodation to apply for a posted position, contact our Human Resources department by email at hr@lcginc.com. Securing Your Data Beware of fraudulent job offers using LCG's name. LCG will never request payment-related details or advancement of money during the application process. Legitimate communication will only come from lcginc.com or system@hirebridgemail.com emails, not free commercial services like Gmail or WhatsApp. If you receive suspicious emails asking for payment or personal information, contact us immediately at hr@lcginc.com. If you believe you are the victim of a scam, contact your local law enforcement and report the incident to the U.S. Federal Trade Commission.",
        "url": "https://www.linkedin.com/jobs/view/3968526270",
        "summary": "This hybrid role involves evaluating, testing, and validating IT systems, services, and software, while also designing, building, and maintaining a stable and efficient infrastructure. The ideal candidate will ensure that our products meet the highest quality standards and improve our development and deployment processes through automation and continuous integration.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Quality Assurance",
            "DevOps"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Teamwork"
        ],
        "hard_skills": [
            "Automated Testing",
            "Subject 7",
            "Azure DevOps",
            "CI/CD",
            "Jenkins",
            "Maven",
            "Puppet",
            "Ansible",
            "GIT",
            "Bitbucket",
            "SVN",
            "CVS",
            "Network Infrastructure",
            "Databases",
            "Cloud",
            "Data Center Operations",
            "Security Protocols",
            "Python",
            "Perl",
            "Bash",
            "PHP",
            "Java",
            "SQL",
            "C++",
            "AWS"
        ],
        "tech_stack": [
            "Subject 7",
            "Azure DevOps",
            "Jenkins",
            "Maven",
            "Puppet",
            "Ansible",
            "GIT",
            "Bitbucket",
            "SVN",
            "CVS",
            "AWS"
        ],
        "programming_languages": [
            "Python",
            "Perl",
            "Bash",
            "PHP",
            "Java",
            "SQL",
            "C++"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "IT",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 143000,
            "min": 103000
        },
        "benefits": [
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Retirement Plan",
            "Paid Leave",
            "Federal Holidays",
            "Professional Development"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3958543184,
        "company": "Get It Recruit - Educational Services",
        "title": "Data Science Instructor -- Remote | WFH",
        "created_on": 1720587438.9291556,
        "description": "About Us We are a leading educational institution dedicated to providing exceptional bootcamps and training programs across various fields, including Data Science. Our mission is to empower individuals with the skills and knowledge needed to thrive in the dynamic tech industry. Position Overview We are seeking a highly skilled and experienced Data Science Instructor to join our team and lead our Data Science bootcamp. The ideal candidate will possess a deep understanding of Data Science, encompassing both front-end and back-end components, and have the ability to guide students through our comprehensive curriculum. Key Responsibilities Design and develop a comprehensive Data Science bootcamp curriculum covering essential topics such as data analysis, machine learning, and data visualization. Deliver engaging lectures, workshops, and hands-on sessions to students of varying skill levels. Provide personalized mentorship to help students grasp complex concepts and complete projects successfully. Assess student progress through assignments, projects, and constructive feedback. Stay abreast of the latest trends and advancements in Data Science to ensure curriculum relevance. Collaborate with fellow instructors and staff to enhance the overall bootcamp experience. Contribute to the development of additional learning materials and resources. Qualifications Proven experience in Data Science with a robust portfolio of relevant projects. Comprehensive understanding of front-end and back-end Data Science, including statistical modeling. Strong teaching and communication skills, capable of simplifying complex concepts effectively. Experience in educational content development, preferably in intensive learning environments. Proficiency in programming languages and tools like Python, R, and SQL. Strong problem-solving skills and adaptability to diverse learning styles. Passion for teaching and supporting students in achieving their career aspirations. Preferred Qualifications Advanced degree (Master's or Ph.D.) in Data Science, Computer Science, Statistics, or a related field. Previous experience as a Data Science Instructor or in a similar educational role. About Our Institution Industry experience demonstrating practical application of Data Science skills. Our technical bootcamps bridge the gap between academic education and the practical demands of the tech industry. We recognize the challenge graduates face in applying theoretical knowledge to real-world scenarios. Our hands-on approach ensures students gain the skills and experience employers seek, making them highly competitive in the job market. Employment Type: Full-Time",
        "url": "https://www.linkedin.com/jobs/view/3958543184",
        "summary": "We are seeking a highly skilled and experienced Data Science Instructor to join our team and lead our Data Science bootcamp. The ideal candidate will have a deep understanding of Data Science, encompassing both front-end and back-end components, and be able to guide students through our comprehensive curriculum.",
        "industries": [
            "Education",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Teaching",
            "Mentorship",
            "Problem-solving",
            "Adaptability",
            "Passion for Teaching",
            "Collaboration"
        ],
        "hard_skills": [
            "Data Science",
            "Data Analysis",
            "Machine Learning",
            "Data Visualization",
            "Statistical Modeling",
            "Python",
            "R",
            "SQL"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Sterling, VA",
        "job_id": 3960530029,
        "company": "ManTech",
        "title": "Sr. Data Scientist",
        "created_on": 1720587442.7605395,
        "description": "Secure our Nation, Ignite your Future Overview Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of solutions to promote efficient trade and travel. Further, effective solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure. In response to this challenge, ManTech, as a trusted mission partner of CBP, seeks capable, qualified, and versatile Data Scientists to help lead the development and delivery of high-quality predictive modelling solutions. Successful applicants will serve as recognized subject matter experts in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. They will help our team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy. This position potentially offers a flexible work schedule at the discretion of the customer. At this time, we are only accepting candidates who reside within a commutable distance to the DMV area . The strongest applicants will offer multiple years of experience in highly dynamic, threat/risk driven operating environments. They will also have a proven track record of delivering production ready decision support tools and applications employed in the field and by mission-support entities. Further, highly competitive applicants will have a demonstrated capacity to: work closely and collaboratively with mission stakeholders; respond to emergent, mission-driven changes in priorities and expected outcomes; and, apply new and emerging tools and techniques. Within three - six months of joining the project, Data Scientists will be expected to: Perform hands-on analysis and modeling involving the creation of intervention hypotheses and experiments, assessment of data needs and available sources, determination of optimal analytical approaches, performance of exploratory data analysis, and feature generation (e.g., identification, derivation, aggregation). Collaborate with mission stakeholders to define, frame, and scope mission challenges where big data interventions may offer important mitigations and develop robust project plans with key milestones, detailed deliverables, robust work tracking protocols, and risk mitigation strategies. Demonstrate proficiency in extracting, cleaning, and transforming CBP transactional and mission data associated within an identified problem space to build predictive models as well as develop appropriate supporting documentation. Leverage knowledge of a variety of statistical and machine learning techniques and methods to define and develop programming algorithms; train, evaluate, and deploy predictive analytics models that directly inform mission decisions. Execute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching. Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior government stakeholders throughout the model development/ project lifecycle through written as well as in-person reporting. Required Qualifications Experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems Experience with programming languages including: R, Python, Scala, Java. Proficiency with SQL programming Experience constructing and executing queries to extract data in support of EDA and model development Proficiency with statistical software packages including: SAS, SPSS Modeler, R, WEKA, or equivalent Experience with pattern recognition and extraction, automated classification, and categorization Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) Experience with unsupervised and supervised machine learning techniques and methods Experience performing data mining, analysis, and training set construction Desired Qualifications Proficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc. Proficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc. Experience with pattern recognition and extraction, automated classification, and categorization Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) Experience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI) Experience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop) Master’s Degree in mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience Education: HS Diploma/GED and 15+ years AS/AA and 13-18 years BS/BA and 7-12 years MS/MA/MBA and 5-9 years PhD/Doctorate and 3-7 years Certification: None Clearance: Selected applicants must be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) suitability. Physical Requirements: Office work, typically sedentary with some movement around the office For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.",
        "url": "https://www.linkedin.com/jobs/view/3960530029",
        "summary": "ManTech is seeking Data Scientists to develop and deliver predictive modeling solutions for U.S. Customs and Border Protection (CBP). Responsibilities include data analysis, model development, and collaboration with mission stakeholders. The position requires experience in machine learning, programming languages (R, Python, Scala, Java), SQL, and statistical software packages. Desired qualifications include proficiency in unsupervised and supervised machine learning methods, experience with big data technologies, and visualization tools.",
        "industries": [
            "Government",
            "National Security",
            "Homeland Security",
            "Data Science",
            "Analytics",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Analytical Skills",
            "Project Management",
            "Teamwork",
            "Decision Making",
            "Time Management"
        ],
        "hard_skills": [
            "Machine Learning",
            "Predictive Modeling",
            "Data Analysis",
            "Data Mining",
            "Data Transformation",
            "Data Cleaning",
            "SQL",
            "R",
            "Python",
            "Scala",
            "Java",
            "SAS",
            "SPSS Modeler",
            "WEKA",
            "Cluster Analysis",
            "K-means",
            "K-nearest Neighbor",
            "Hierarchical Clustering",
            "Deep Belief Networks",
            "Principal Component Analysis",
            "Segmentation",
            "Decision Trees",
            "Support Vector Machines",
            "Logistic Regression",
            "Random Forests",
            "Rotation Forests",
            "Categorization",
            "Classification",
            "Neural Networks",
            "Bayesian Networks",
            "Pattern Recognition",
            "Automated Classification",
            "Categorization",
            "Entity Resolution",
            "Record Linking",
            "Named-Entity Matching",
            "Deduplication",
            "Disambiguation",
            "Visualization Tools",
            "Periscope",
            "Business Objects",
            "D3",
            "ggplot",
            "Tableau",
            "SAS Visual Analytics",
            "PowerBI",
            "Hadoop",
            "HIVE",
            "HDFS",
            "HBase",
            "MapReduce",
            "Spark",
            "Kafka",
            "Sqoop"
        ],
        "tech_stack": [
            "R",
            "Python",
            "Scala",
            "Java",
            "SQL",
            "SAS",
            "SPSS Modeler",
            "WEKA",
            "Hadoop",
            "HIVE",
            "HDFS",
            "HBase",
            "MapReduce",
            "Spark",
            "Kafka",
            "Sqoop",
            "Periscope",
            "Business Objects",
            "D3",
            "ggplot",
            "Tableau",
            "SAS Visual Analytics",
            "PowerBI"
        ],
        "programming_languages": [
            "R",
            "Python",
            "Scala",
            "Java",
            "SQL"
        ],
        "experience": 7,
        "education": {
            "min_degree": "HS Diploma/GED",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fairfax, VA",
        "job_id": 3965915569,
        "company": "Dewberry",
        "title": "Scientific Programmer",
        "created_on": 1720587444.5467634,
        "description": "Job Description Dewberry is currently seeking a Scientific Programmer to join our Resilience Solutions Group in our Fairfax, VA offic e (note: a lternate offices and remote locations may be considered on a case-by-case basis ) . The role will support federal, state, and local government clients to help them better understand, prepare, and respond to natural disasters, climate change, and sea level rise . Dewberry is a leading, market-facing professional services firm with more than 50 locations and 2,000 professionals nationwide. What sets us apart from our competitors are our people. At Dewberry, we seek out exceptional talent and strive to deliver the highest quality of services to our clients. Whether you’re an experienced professional or a new graduate, you’ll have the chance to collaborate with the best and brightest and work on innovative and complex projects at the forefront of the industry. Our commitment to excellence stems from our personal integrity and from other defining attributes, which we call “Dewberry at Work,” that have inspired our employees to be successful for more than a half-century . Responsibilities Responsibilities You will design, write, and maintain semi-automated routines and related documentation and reports for data analysis , data engineering, data management, and mass processing , primarily in the context of hydrologic & hydraulic (H&H) flood modeling and related risk analysis of natural hazards . You will gather requirements, design , and write components of our backend cloud computing stack, leveraging Python, Postgres (SQL), Go, and Docker on AWS infrastructure ( S3, EC2, Batch, Lambda, RDS ) . The role fit s into an existing team of passionate developers and earth science modelers with backgrounds in hydrology, fluid dynamics, meteorology, computer science, geographic information systems (GIS), environmental science , civil engineering, oceanography, and statistics . Projects are version-controlled in Git (GitHub). Some projects involve publicly accessible websites and/or open-source codebases. Most projects involve geospatial data (vector and raster). Recent Federal And State Clients Include Federal Emergency Management Agency (FEMA) – HQ and Regions U.S. Army Corps of Engineers (USACE) Virginia Department of Conservation and Recreation (VADCR) Virginia Department of Transportation (VDOT) Port Authority of New York and New Jersey (PANYNJ) New York State Department of Environmental Conservation (NY S DEC) New Jersey Turnpike Authority (NJTA) Colorado Water Conservation Board (CWCB) Texas General Land Office (GLO) National Academies of Sciences (NAS) Required Skills & Required Experience Required Skills & Experience 3 - 8 years of experience in developing tools , processes, and workflows related to scien tific analysis , with preference for expertise in GIS, hydrology, hydraulics, fluid dynamics, climate change, meteorology, hydrometeorology , statistics, or other earth sciences Bachelor's d egree in computer science, civil engineering, environmental engineering, water resources engineering , statistics, meteorology, climate science, mathematics, or related technical discipline Proficiency in Python : O pen GIS libraries: geopandas , rasterio , shapely, fiona , OGR2OGR, GDAL, etc O pen mathematics & statistics libraries : numpy , xarray , scipy , etc Experience handling large amounts of data efficiently (compression, spatial indexing, tiling, etc ) Proficiency in Git Proficiency in d esktop GIS (QGIS, ArcGIS) Strong problem solving and persistence Professional communication Willingness to showcase skills through a portfolio , example apps , or shared code Desired Skills & Experience Postgres (SQL + PostGIS ) Go Docker: development of images and container orchestration AWS: S3, EC2, Batch, ECR, Lambda, RDS GitHub Actions Statistical machine learning (regression, decision tree, random forest) QGIS Plugin Development Must have a valid driver’s license, good driving record and ability to pass a driving record background check. At this time, Dewberry will not sponsor a new applicant for work authorization. Dewberry is an Equal Opportunity/ Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, gender identity or sexual orientation. Prior to a final offer of employment, the selected candidate will be required to submit to a background screening which may include, but is not limited to, employment verification, educational and other credential verification, driving record check, criminal background check, and an investigative consumer report. These screenings will be conducted by Dewberry’s background vendor of choice and will be conducted in compliance with all applicable federal, state, and local law.",
        "url": "https://www.linkedin.com/jobs/view/3965915569",
        "summary": "Dewberry is seeking a Scientific Programmer to join their Resilience Solutions Group in Fairfax, VA. The role will involve designing, writing, and maintaining automated routines for data analysis, engineering, management, and processing related to flood modeling and risk analysis of natural hazards. The candidate will also contribute to the development of a backend cloud computing stack using Python, Postgres (SQL), Go, and Docker on AWS infrastructure. The ideal candidate will have 3-8 years of experience in scientific analysis with expertise in GIS, hydrology, hydraulics, climate change, or other earth sciences. A Bachelor's degree in a relevant field is required, along with proficiency in Python, open GIS and mathematics libraries, experience with large data handling, Git, and desktop GIS. Additional desired skills include Postgres, Go, Docker, AWS, GitHub Actions, statistical machine learning, and QGIS Plugin Development.",
        "industries": [
            "Engineering",
            "Environmental Consulting",
            "GIS",
            "Data Science",
            "Climate Change",
            "Disaster Response"
        ],
        "soft_skills": [
            "Problem Solving",
            "Persistence",
            "Communication",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "Postgres",
            "SQL",
            "Go",
            "Docker",
            "AWS",
            "S3",
            "EC2",
            "Batch",
            "Lambda",
            "RDS",
            "Git",
            "GitHub",
            "QGIS",
            "ArcGIS",
            "Geopandas",
            "Rasterio",
            "Shapely",
            "Fiona",
            "OGR2OGR",
            "GDAL",
            "NumPy",
            "Xarray",
            "SciPy",
            "Regression",
            "Decision Tree",
            "Random Forest",
            "Machine Learning",
            "QGIS Plugin Development"
        ],
        "tech_stack": [
            "Python",
            "Postgres",
            "SQL",
            "Go",
            "Docker",
            "AWS",
            "S3",
            "EC2",
            "Batch",
            "Lambda",
            "RDS",
            "Git",
            "GitHub",
            "QGIS",
            "ArcGIS"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "Go"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Civil Engineering",
                "Environmental Engineering",
                "Water Resources Engineering",
                "Statistics",
                "Meteorology",
                "Climate Science",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3959769564,
        "company": "Soft Source, Inc",
        "title": "Developer",
        "created_on": 1720587446.0578856,
        "description": "Position Title: Developer 100% REMOTE EST HOURS Must Have Low Code/No Code Experience THIS IS ONLY FUNDED FOR 2 MONTHS Developer Senior Develops application changes, new functionality, address security updates, and develops JUnit automation Develops in Java/Tool Specific language/Low Code-No Code platforms Interfaces with Technical representatives from vendors and technology providers Addresses 508 compliance items Addresses application and data security items Performs unit and integration testing Updates Jira Participates in Agile SCRUM process",
        "url": "https://www.linkedin.com/jobs/view/3959769564",
        "summary": "Remote, 2-month contract position for a senior developer. Responsibilities include developing application changes, new functionality, and security updates, working with vendors, addressing accessibility and security issues, performing testing, and participating in Agile SCRUM.",
        "industries": [
            "Software Development",
            "Information Technology",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Time Management",
            "Teamwork",
            "Organization",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Java",
            "JUnit",
            "Agile Scrum",
            "Low Code",
            "No Code",
            "Security Updates",
            "508 Compliance",
            "Data Security",
            "Unit Testing",
            "Integration Testing",
            "Jira"
        ],
        "tech_stack": [
            "Java",
            "JUnit",
            "Jira",
            "Agile Scrum"
        ],
        "programming_languages": [
            "Java"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Laurel, MD",
        "job_id": 3718498748,
        "company": "The Johns Hopkins University Applied Physics Laboratory",
        "title": "2024 PhD Graduate - Data Scientist/Engineer - Decision Systems",
        "created_on": 1720587447.6648297,
        "description": "Description Are you passionate about translating your academic career into building solutions to some of our nation's most pressing challenges? Are you searching for engaging, impactful work and personal growth? Do you value working in a creative and collaborative environment? If so we're looking for someone like you to join our team! In the Decision Systems Group (QAX) we strive to make \"Critical Contributions to Critical Challenges\", positively impacting national security. During the COVID-19 pandemic this has meant leaning into the public and federal pandemic response: owning the data engineering efforts behind the Johns Hopkins University COVID-19 Dashboard and Coronavirus Resource Center, and driving analysis and engineering efforts that influence decisions at the highest levels of government. Our work has been recognized by Time Magazine as one of the \"Best Inventions of 2020\", and our team was named Fast Company's 2021 Innovative Team of the Year. Beyond this, we bring our talents to a wide range of challenges, making impactful contributions to problems in health and bio-security, homeland protection, cyber security, and military special operations. We are problem solvers committed to making a difference who are looking for teammates who will bring their passion and dedication to our work. In QAX, you will help design, develop, and deploy systems to address complex problems and enable decision making. Ideally, you are a systems thinker who takes initiative in solving problems based on your solid mathematical and engineering foundations. If you are willing to collaborate and grow as part of a diverse team of data scientists and engineers, our group may be a place for you to thrive. On Our Team You Will Design and prototype innovative approaches that advance our capacity for defensible decision making at speed and scale. Manage a research agenda related to some of our key focus areas: decision science, digital engineering, AI/ML, predictive and prescriptive modeling, information visualization, data and software engineering. Qualifications You meet our minimum qualifications for the job if you... Possess a terminal degree (PhD or DEng) in Computer Science, Mathematics, Physics, Systems Engineering, or a related field. Are self-motivated and self-directed, with a strong intellectual curiosity and a desire to learn from those around you. Are proficient in one or more programming languages, including: Python, Java, C, C++, Javascript. Possess outstanding written and oral communication skills, organizational skills, and a proficiency at relationship building. Are able to obtain an Interim Secret Clearance by your start date and can ultimately obtain a Secret security clearance. If selected, you will be subject to a government security clearance investigation and must meet the requirements for access to classified information. Eligibility requirements include U.S. citizenship. You'll go above and beyond our minimum requirements if you... Have prior experience with a subset of: Deep Learning, Reinforcement Learning, Probabilistic Modeling, Dynamic Systems Modeling, NLP, Knowledge Graphs, Model Based Systems Engineering. Have a record of communicating analyses of real-world data sets to audiences with broadly varying technical backgrounds. Why work at APL? The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation’s most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates. At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL’s campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers. About Us APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law. APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.",
        "url": "https://www.linkedin.com/jobs/view/3718498748",
        "summary": "The Johns Hopkins University Applied Physics Laboratory (APL) is seeking a data scientist or engineer to join their Decision Systems Group (QAX). The successful candidate will design, develop, and deploy systems to address complex problems and enable decision making. They will also manage a research agenda related to key focus areas, including decision science, digital engineering, AI/ML, predictive and prescriptive modeling, information visualization, data and software engineering. The ideal candidate will have a terminal degree in a related field, experience with a subset of: Deep Learning, Reinforcement Learning, Probabilistic Modeling, Dynamic Systems Modeling, NLP, Knowledge Graphs, Model Based Systems Engineering, and strong communication and organizational skills. APL offers a vibrant, welcoming atmosphere where employees can bring their authentic self to work, continue to grow, and build strong connections with inspiring teammates. APL is an Equal Opportunity/Affirmative Action employer.",
        "industries": [
            "National Security",
            "Defense",
            "Space",
            "Science",
            "Data Science",
            "Engineering"
        ],
        "soft_skills": [
            "Self-motivated",
            "Self-directed",
            "Strong intellectual curiosity",
            "Desire to learn",
            "Outstanding written and oral communication skills",
            "Organizational skills",
            "Relationship building"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "C",
            "C++",
            "Javascript",
            "Deep Learning",
            "Reinforcement Learning",
            "Probabilistic Modeling",
            "Dynamic Systems Modeling",
            "NLP",
            "Knowledge Graphs",
            "Model Based Systems Engineering"
        ],
        "tech_stack": [
            "Decision science",
            "Digital engineering",
            "AI/ML",
            "Predictive and prescriptive modeling",
            "Information visualization",
            "Data and software engineering"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C",
            "C++",
            "Javascript"
        ],
        "experience": 0,
        "education": {
            "min_degree": "PhD or DEng",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Physics",
                "Systems Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Robust education assistance program",
            "Unparalleled retirement contributions",
            "Healthy work/life balance"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington DC-Baltimore Area",
        "job_id": 3952856641,
        "company": "Genesys Impact",
        "title": "Software Engineer",
        "created_on": 1720587452.3635943,
        "description": "Genesys Impact is looking for a highly motivated and talented individual that possesses the necessary skill set to successfully deliver on projects. We currently provide solutions for USAID, Department of Defense (DoD) Defense Health Agency (DHA), private companies ranging from startup to enterprise, and local universities. We have provided Software and IT solutions to organizations and businesses in the DC metro area since 2010 and are a leading business process and information technology firm based in Washington DC. Genesys Impact is a forward-thinking company and we believe in a positive work culture where team members can grow and prosper. Genesys Impact is currently working on an array of projects using various technologies. We’re looking for a team member who is comfortable designing and developing User Interfaces (UI) for enterprise web applications. The Software Engineer is a collaborative contributor role that will implement projects under the lead engineer’s direction. The prospective candidate will collaborate with the client Account Manager and existing engineering resources to bring product requirements from conception to reality. The candidate will ensure architectural design, software implementation, and quality assurance needs are met and continually updated throughout the product's life. Collaborate with developers/engineers and other team members to establish objectives and design more functional, cohesive codes to enhance the user experience of Med365. Support the project lead in building robust and scalable software and code. Compile and analyze data, processes, and codes to troubleshoot problems and identify areas for improvement. Responsibilities will include: Individually contribute to multiple source code repositories for ongoing projects Collaborate with the engineering team and assist in translating requirements into engineering tasks Collaborate with clients and members of technical and non-technical teams to gather business requirements and translate them into technical specifications Experience Required MUST BE A U.S. CITIZEN AND ELIGIBLE TO OBTAIN A DoD SECURITY CLEARANCE Experience with modern JavaScript front-end frameworks Experience with M365 / SharePoint Experience consuming REST APIs Knowledge and passion for modern web UI/UX design Ability to understand business requirements and translate them into technical requirements Strong analytical, organizational, writing, and communication skills Strong critical thinking and problem-solving skills Comfortable working with new software tools Bonus Skills Experience with reusable components and design Experience with React, NextJS, and/or Vercel .NET, Visual Studio, and/or VS Code",
        "url": "https://www.linkedin.com/jobs/view/3952856641",
        "summary": "Genesys Impact, a software and IT solutions company, is seeking a Software Engineer to design and develop user interfaces (UI) for enterprise web applications. This role involves collaborating with engineers, account managers, and clients to translate requirements into technical specifications and ensure quality throughout the product lifecycle. The position requires experience with modern JavaScript frameworks, M365/SharePoint, REST APIs, and modern web UI/UX design, along with strong analytical and communication skills.",
        "industries": [
            "Software Development",
            "Information Technology",
            "Consulting",
            "Government (USAID, DoD, DHA)"
        ],
        "soft_skills": [
            "Motivated",
            "Talented",
            "Collaborative",
            "Problem-solving",
            "Analytical",
            "Organizational",
            "Communication",
            "Critical Thinking"
        ],
        "hard_skills": [
            "JavaScript",
            "M365",
            "SharePoint",
            "REST APIs",
            "UI/UX Design",
            "Requirements Gathering",
            "Technical Specifications",
            "Source Code Management",
            "Troubleshooting"
        ],
        "tech_stack": [
            "JavaScript",
            "M365",
            "SharePoint",
            "REST APIs",
            "React",
            "NextJS",
            "Vercel",
            ".NET",
            "Visual Studio",
            "VS Code"
        ],
        "programming_languages": [
            "JavaScript",
            ".NET"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Bethesda, MD",
        "job_id": 3968524306,
        "company": "LCG, Inc.",
        "title": "Application Developer",
        "created_on": 1720587455.5875561,
        "description": "Position Summary: We are seeking a skilled Application Developer to join our team. The ideal candidate will have experience developing modernized .NET, Python, and R/Studio applications. This position requires a strong understanding of Azure Cloud services, agile methodologies, and DevSecOps practices to ensure scalable, secure, and performant applications. Key Responsibilities Develop modernized .NET, Python, and R/Studio applications based on approved design documents. Utilize Azure Cloud services such as Azure App Services, Azure Functions, and Azure Kubernetes Service (AKS) to build scalable and secure applications. Engage in the development of new systems and the modernization of existing ones, ensuring seamless integration with the current application portfolio and Azure ecosystem. Participate in Scrum Agile framework activities, including sprint planning, daily stand-ups, sprint reviews, and retrospectives. Ensure iterative progress and continuous feedback throughout the development lifecycle. Implement necessary integrations with other systems and services. Conduct thorough unit and integration testing to maintain high code quality and reliability. Support the development and optimization of Power Apps, Power Automate flows, and Power BI reports within the Microsoft PowerPlatform. Develop applications in compliance with NIH/HHS/NIST security requirements. Ensure all applications undergo a Security Assessment. Integrate DevSecOps practices to embed security at every stage of the development lifecycle. Implement robust Quality Assurance Testing, including automated test solutions and continuous monitoring. Ensure high-quality, secure, and reliable application deployments. Provide comprehensive user training and documentation for custom systems. Ensure users and IRMB developers can effectively utilize and maintain the developed solutions. Qualifications Bachelor's degree in Computer Science, Information Technology, or a related field. Minimum 5 years proven experience in .NET, Python, and R/Studio application development. Experience with Azure Cloud services and Microsoft PowerPlatform. Familiarity with Scrum Agile framework and DevSecOps practices. Strong understanding of application security and compliance standards. Excellent problem-solving skills and attention to detail. Effective communication and collaboration skills. Preferred Qualifications Experience with Azure DevOps for CI/CD pipelines. Knowledge of automated testing frameworks and tools. Familiarity with NIH Risk Management Framework and related security practices. Compensation And Benefits The projected compensation range for this position is $113,075 to $145,400 per year benchmarked in the Washington, D.C. metropolitan area. The salary range provided is a good faith estimate representative of all experience levels. Salary at LCG is determined by various factors, including but not limited to role, location, the combination of education/training, knowledge, skills, competencies, certifications, and work experience. LCG offers a competitive, comprehensive benefits package which includes health insurance options (medical, dental, vision), life and disability insurance, retirement plan contributions, as well as paid leave, federal holidays, professional development, and lifestyle benefits. Devoted to Fair and Inclusive Practices All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. If you are interested in applying for employment with LCG and need special assistance or an accommodation to apply for a posted position, contact our Human Resources department by email at hr@lcginc.com. Securing Your Data Beware of fraudulent job offers using LCG's name. LCG will never request payment-related details or advancement of money during the application process. Legitimate communication will only come from lcginc.com or system@hirebridgemail.com emails, not free commercial services like Gmail or WhatsApp. If you receive suspicious emails asking for payment or personal information, contact us immediately at hr@lcginc.com. If you believe you are the victim of a scam, contact your local law enforcement and report the incident to the U.S. Federal Trade Commission.",
        "url": "https://www.linkedin.com/jobs/view/3968524306",
        "summary": "LCG seeks an Application Developer with 5+ years of experience developing modernized .NET, Python, and R/Studio applications. The role requires expertise in Azure Cloud services, Agile methodologies, and DevSecOps practices. Responsibilities include developing secure and scalable applications, utilizing Azure services, participating in Scrum Agile activities, implementing integrations, conducting thorough testing, and supporting the development and optimization of Microsoft Power Platform tools. The position ensures compliance with NIH/HHS/NIST security requirements and integrates DevSecOps practices throughout the development lifecycle.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Problem-solving",
            "Attention to detail",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            ".NET",
            "Python",
            "R/Studio",
            "Azure App Services",
            "Azure Functions",
            "Azure Kubernetes Service (AKS)",
            "Scrum Agile",
            "DevSecOps",
            "Power Apps",
            "Power Automate",
            "Power BI",
            "Unit Testing",
            "Integration Testing",
            "Automated Testing",
            "Quality Assurance Testing",
            "Continuous Monitoring",
            "User Training",
            "Documentation"
        ],
        "tech_stack": [
            ".NET",
            "Python",
            "R/Studio",
            "Azure App Services",
            "Azure Functions",
            "Azure Kubernetes Service (AKS)",
            "Microsoft Power Platform",
            "Azure DevOps",
            "Automated testing frameworks"
        ],
        "programming_languages": [
            ".NET",
            "Python",
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Information Technology"
            ]
        },
        "salary": {
            "max": 145400,
            "min": 113075
        },
        "benefits": [
            "Health insurance (medical, dental, vision)",
            "Life and disability insurance",
            "Retirement plan contributions",
            "Paid leave",
            "Federal holidays",
            "Professional development",
            "Lifestyle benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3812080350,
        "company": "SonyAI",
        "title": "Research Scientist – Vision Foundation Model",
        "created_on": 1720587456.8443403,
        "description": "Sony AI America, a branch of Sony AI, is a remotely distributed organization spread across the U.S. and Canada. Sony AI is Sony’s new research organization pursuing the mission to use AI to unleash human creativity. Sony AI works closely with Sony’s other business units, including Sony Interactive Entertainment LLC., Sony Pictures Entertainment Inc., and Sony Music Entertainment. With some 900 million Sony devices in hands and homes worldwide today, a vast array of Sony movies, television shows and music, and the PlayStation Network, Sony creates and delivers more entertainment experiences to more people than anyone else on earth. To learn more: https://ai.sony/ Position Summary Sony AI is seeking research scientists to join our Privacy-Preserving Machine Learning (PPML) team. Our team mainly focuses on fundamental and applied research in privacy and security, with a focus on building vision foundation models in a trustworthy manner. The role of a research scientist is to conduct innovative research, develop methodologies, design and prototype solutions, and collaborate with various team members to empower real-world AI applications (e.g., Imaging&Sensing) in Sony. Job Responsibilities Conduct fundamental and innovative research in large vision foundation models, including but not limited to architecture design and methodology design. Contribute to deployment foundation models and use them in production to solve problems of business partners. Work closely with research, engineering, and product teams, seeking high-impact opportunities to launch solutions and advance long-term business growths, specifically Imaging&Sensing business. Deep understanding of large vision foundation model development and various CV applications, such as Image classification, object detection, pose detection, semantic image segmentation, etc. Publish influential research outcomes, and give presentations in top-tier conferences and journals. Qualifications For Position Your qualifications and experience should include: Work experience with a role with a primary emphasis on vision foundation model and computer vision research. PhD (or equivalent experience) in Computer Science, Electrical Engineering, Math, Statistics, data science, or other related disciplines. Publications or hands-on experience in large vision foundation model development, computer vision, data synthesis, knowledge distillation, and distributed/decentralized system design. Strong programming skills in Python, experience in Pytorch or Tensorflow. Excellent communication and presentation skills. Ability to work in a team (Preferred) Experience in leading or participating in significant research projects. (Preferred) Experience in computer vision applications and/or AI (Preferred) Paper awards in top conferences, or winner of international competition award Life at Sony: We ensure Competitive Salaries by using established benchmarking with excellent compensation policies, and encourage healthy Work-Life Balance with hybrid working policies where available. We are a positive Community who dream big together, respect each other, and enjoy a collaborative culture across Europe. We like to celebrate and reward our colleagues who make a real difference using our Recognition platform, Bravo! . We also provide access to numerous services & platforms for all aspects of Wellbeing . We Listen to our people through conversations and surveys, Respect their suggestions, then act on them. You can build your career around you with our fantastic range of Learning & Personal Development programs. We also encourage our staff to try an exciting new roles in an exciting new countries, with a fantastic Mobility team to support you if you take that leap! Bring your uniqueness to Sony: We recognize that each and every one of us is original and unique. Diversity and inclusion are in our DNA, they drive innovation. We empower our people to achieve one goal: to fill the world with emotion, through the power of creativity and technology. In addition to competitive pay and benefits, we offer an environment and culture that promotes Diversity, Equity, and Inclusion. We are committed to creating an inclusive employee experience for you to thrive as part of Sony’s purpose to “fill the world with emotion through the power of creativity and technology”. Benefits: SCA offers benefits-eligible employees (generally regular employees scheduled to work 20 or more hours a week) a comprehensive benefits program that offers coverage and support for employees and their family’s physical, emotional, and financial well-being. What we offer you: Comprehensive medical, prescription drug, dental, and vision coverage with coverage for spouses/domestic partners and child dependents, including access to a Health Savings Account (HSA) and Flexible Spending Account (FSA) Employee assistance plan and comprehensive behavioral health benefits Fertility benefits, including surrogacy, and adoption assistance programs Basic and supplemental life insurance for employees as well as supplemental life insurance coverage for their spouses/domestic partners and children Voluntary benefits such as group legal, identity theft protection, accident, and hospital indemnity insurance Short-term & long-term disability plans Paid parental and caregiver leave 401(k) Plan with pre-tax, Roth, and after-tax options and company match which vests immediately Education assistance and student loan programs Other Programs: Time off to include vacation, paid holidays, sick leave, Summer Fridays (early release), and a winter break between Christmas and New Year’s Day (based on business needs) Referral bonuses (subject to eligibility) Matching gift program A wide variety of employee business resource groups (EBRGs) Special discounts on Sony products, offered exclusively to Sony employees Employee stock purchase plan (Sony covers commissions and fees for your Sony stock purchases made through after-tax payroll deductions) Annual incentive bonus The anticipated annual base salary for this position is $130,000 to $170,000. This range does not include any other compensation components or other benefits that an individual may be eligible for. The actual base salary offered depends on a variety of factors, which may include as applicable, the qualifications of the individual applicant for the position, years of relevant experience, specific and unique skills, level of education attained, certifications or other professional licenses held, and the location in which the applicant lives and/or from which they will be performing the job. Sony is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy), gender, national origin, citizenship, ancestry, age, physical or mental disability, military status, status as a veteran or disabled veteran, sexual orientation, gender identity or expression, marital or family status, genetic information, medical condition, or any other basis protected by applicable federal, state, or local law, ordinance, or regulation. Disability Accommodation for Applicants to Sony Corporation of America Sony Corporation of America provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. For reasonable accommodation requests, please contact us by email at careers@sonyusa.com or by mail to: Sony Corporation of America, Human Resources Department, 25 Madison Avenue, New York, NY 10010. Please indicate the position you are applying for. EEO is the Law EEO is the Law Supplement Right to Work (English/Spanish) E-Verify Participation (English/Spanish) While SCA does not require employees to be vaccinated against COVID-19, there are certain Sony offices that require employees to be vaccinated in order to enter. If you will be located at or travel to those offices, you will be required to be fully vaccinated to enter. The Company will consider requests for reasonable accommodations for documented medical reasons and for sincerely held religious beliefs in accordance with applicable law. Please do not include proof of vaccination status or any indication of a possible request for a vaccination accommodation when submitting your application materials. If applicable, the Company will follow up with you directly to request proof of vaccination and to discuss any potential accommodations.",
        "url": "https://www.linkedin.com/jobs/view/3812080350",
        "summary": "Sony AI seeks research scientists to join their Privacy-Preserving Machine Learning (PPML) team, focusing on fundamental and applied research in privacy and security, building trustworthy vision foundation models. Responsibilities include conducting innovative research, developing methodologies, designing and prototyping solutions, and collaborating with various teams to empower real-world AI applications, particularly in Imaging&Sensing.",
        "industries": [
            "Computer Science",
            "Artificial Intelligence",
            "Research",
            "Technology",
            "Entertainment",
            "Media",
            "Imaging",
            "Sensing"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Teamwork",
            "Leadership",
            "Collaboration"
        ],
        "hard_skills": [
            "Vision Foundation Model",
            "Computer Vision",
            "Data Synthesis",
            "Knowledge Distillation",
            "Distributed/Decentralized System Design",
            "Python",
            "Pytorch",
            "Tensorflow"
        ],
        "tech_stack": [
            "Pytorch",
            "Tensorflow"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Computer Science",
                "Electrical Engineering",
                "Math",
                "Statistics",
                "Data Science"
            ]
        },
        "salary": {
            "max": 170000,
            "min": 130000
        },
        "benefits": [
            "Competitive Salaries",
            "Work-Life Balance",
            "Hybrid Working",
            "Community",
            "Recognition",
            "Wellbeing",
            "Listening",
            "Respect",
            "Learning & Personal Development",
            "Mobility",
            "Medical",
            "Prescription Drug",
            "Dental",
            "Vision",
            "Health Savings Account",
            "Flexible Spending Account",
            "Employee Assistance Plan",
            "Behavioral Health",
            "Fertility",
            "Surrogacy",
            "Adoption Assistance",
            "Basic Life Insurance",
            "Supplemental Life Insurance",
            "Group Legal",
            "Identity Theft Protection",
            "Accident",
            "Hospital Indemnity",
            "Short-Term Disability",
            "Long-Term Disability",
            "Paid Parental Leave",
            "Caregiver Leave",
            "401(k)",
            "Company Match",
            "Education Assistance",
            "Student Loan Programs",
            "Vacation",
            "Paid Holidays",
            "Sick Leave",
            "Summer Fridays",
            "Winter Break",
            "Referral Bonuses",
            "Matching Gift Program",
            "Employee Business Resource Groups",
            "Sony Product Discounts",
            "Employee Stock Purchase Plan",
            "Annual Incentive Bonus"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3967688998,
        "company": "TCG",
        "title": "Full Stack Developer (Fully Remote)",
        "created_on": 1720587458.6897042,
        "description": "You've stumbled upon the rare B Corp government contractor! At TCG, we aim to prove that businesses can be good to their employees and responsible to their community while being profitable. We're an award-winning IT solutions provider to the Federal government seeking a Full Stack Developer to join our team. The Full Stack Developer designs, develops, documents, tests, and debugs new and existing Java software systems and applications. Serves as senior level technical expert on development projects. Participates in full development life cycle including requirements analysis and design. Writes technical specifications based on conceptual design and stated business requirements. Either US Citizenship or Permanent Residency is required for this role. In addition, the selected applicant must submit to a government background investigation and be favorably adjudicated before their first day. TCG is pleased to offer remote employment in the following states: AL, AZ, CO, CT, DE, GA, HI, IL, IN, KS, LA, MD, MA, MI, MN, MO, NJ, NC, OH, OR, PA (excluding the City of Philadelphia), SC, TN, UT, VA, WV, and WI. Responsibilities Design, develop and/or re-engineer highly complex application components, and integrate software packages, programs, and reusable objects residing on multiple platforms Supports, maintains, and documents software functionality Analyzes code to find causes of errors and revises programs as needed Leads software design meetings and analyzes user needs to determine technical requirements Consults with the end-user as needed to prototype, refine, test, and debug programs to meet needs Keep up-to-date with best practices and skills Other duties as assigned Required Experience & Skills 5 years of relevant application development experience, focused on Java/J2EE and Javascript languages and technologies, including Spring framework Strong knowledge of SQL and relational databases including MySQL 3 years of experience with automated testing tools, such as JUnit, Pa11y, SonarQube, and Selenium 2 years experience with DevSecOps automation tools, including Git, Openshift, Docker, Jenkins, Maven, and Kubernetes Ability to pass a Federal government clearance is required for this position Ability to contribute quickly to the project and learning new APIs, libraries, and programming frameworks quickly Ability to prioritize and organize efforts in a fast-paced environment Independent problem-solving skills, strong analytical abilities, creativity, and a customer service-oriented personality Experience with Agile development methodologies applied to bug fixing, software issue management, implementing minor enhancements, and patching and upgrades Preferred Experience & Skills Knowledge of government IT requirements and standard operating procedures Experience in an Agile environment and familiarity with Agile ceremonies and practices Experience using Jira for issue/ticket management Education Bachelor's degree in Computer Engineering or Computer Science, strongly preferred. Equivalent years of experience in related field is acceptable in lieu of degree Proof of COVID-19 vaccination is a job requirement. Reasonable accommodations may be available for those not vaccinated due to health reasons or sincerely held religious beliefs. TCG does not discriminate based on race, sex, color, religion, national origin, age, disability, caste, or veteran status. Our B Corp mission is reflected in our benefits, including offerings like health care, 401K, parental leave, adoption assistance, financial planning services, student loan repayment assistance, and training budget, among others. There's more, see for yourself. TCG is recognized for treating employees well, in fact, in 2024 The Washington Post named TCG as a \"Top Workplace\" for the tenth straight year based on how our employees feel about the company, the benefits TCG offers, and the work/life balance that our staff achieves. And, our CEO was ranked best, by TCG employees' votes, among all midsize companies in the Washington Post Top Workplace survey. Try us ... we'll make you happy Internal title/grade: Software Engineer, Grade 5 Salary Range: $73,500 - $110,000 All individuals being hired to work for TCG must submit to, and successfully pass, a pre-employment background investigation prior to reporting for their first day of work. The pre-employment background investigation will include verification of employment and education, as well as, a criminal and DMV check. Additional documentation and background checks will also be required for positions that require clearance from the Federal government. Salary: $73500.00 - $112000.00 per year Job Posted by ApplicantPro",
        "url": "https://www.linkedin.com/jobs/view/3967688998",
        "summary": "TCG, a B Corp government IT solutions provider, is seeking a Full Stack Developer with 5+ years of experience in Java/J2EE and Javascript, strong SQL and relational database knowledge, and experience with automated testing and DevSecOps tools. The role involves designing, developing, and maintaining software applications, leading design meetings, and collaborating with users. The ideal candidate will have experience in Agile development methodologies, government IT requirements, and Jira. A Bachelor's degree in Computer Engineering or Computer Science is preferred but not required.",
        "industries": [
            "Information Technology",
            "Government",
            "Software Development"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Creative",
            "Customer Service",
            "Communication",
            "Teamwork",
            "Leadership",
            "Organization",
            "Prioritization"
        ],
        "hard_skills": [
            "Java",
            "J2EE",
            "Javascript",
            "Spring Framework",
            "SQL",
            "MySQL",
            "JUnit",
            "Pa11y",
            "SonarQube",
            "Selenium",
            "Git",
            "Openshift",
            "Docker",
            "Jenkins",
            "Maven",
            "Kubernetes",
            "Agile Development",
            "Jira",
            "DevSecOps"
        ],
        "tech_stack": [
            "Java",
            "J2EE",
            "Javascript",
            "Spring Framework",
            "SQL",
            "MySQL",
            "JUnit",
            "Pa11y",
            "SonarQube",
            "Selenium",
            "Git",
            "Openshift",
            "Docker",
            "Jenkins",
            "Maven",
            "Kubernetes",
            "Jira"
        ],
        "programming_languages": [
            "Java",
            "Javascript"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Engineering",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 112000,
            "min": 73500
        },
        "benefits": [
            "Health care",
            "401K",
            "Parental leave",
            "Adoption assistance",
            "Financial planning services",
            "Student loan repayment assistance",
            "Training budget"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3946946592,
        "company": "Capital One",
        "title": "Manager Data Scientist - The Card Loss Forecasting and Allowance team",
        "created_on": 1720587460.2244806,
        "description": "Center 2 (19050), United States of America, McLean, VirginiaManager Data Scientist - The Card Loss Forecasting and Allowance team Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. Team Description- The Card Loss Forecasting and Allowance team uses machine learning models to forecast and optimize future losses associated with Capital One’s credit card portfolio. We work with the enterprise tech teams to use the latest technologies and algorithms to build predictive models and automate insight generation. As a Data Scientist, you will focus on loss forecasting modernization as we continuously enhance the platform that executes the card loss forecasting process that feeds earnings, financial planning, and stress testing. Role Description In this role, you will: Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data Gain exposure to a variety of Build machine learning models/methods through all phases of development, from design through training, evaluation, validation, and implementation Flex your interpersonal skills to translate the complexity of your work into tangible business goals. The Ideal Candidate is: Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers. Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them. Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea. A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You’re passionate about talent development for your own team and beyond. Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms. Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning. A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science. Basic Qualifications: Currently has, or is in the process of obtaining a Bachelor’s Degree plus 6 years of experience in data analytics, or currently has, or is in the process of obtaining a Master’s Degree plus 4 years of experience in data analytics, or currently has, or is in the process of obtaining PhD plus 1 year of experience in data analytics, with an expectation that required degree will be obtained on or before the scheduled start date At least 2 years’ experience in open source programming languages for large scale data analysis At least 2 years’ experience with machine learning At least 2 years’ experience with relational databases Preferred Qualifications PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics At least 1 year of experience working with AWS At least 4 years’ experience in Python, Scala, or R for large scale data analysis At least 4 years’ experience with machine learning At least 4 years’ experience with SQL Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
        "url": "https://www.linkedin.com/jobs/view/3946946592",
        "summary": "Capital One is seeking a Data Scientist to join their Card Loss Forecasting and Allowance team. The ideal candidate will have a strong background in data analytics, machine learning, and open-source programming languages. They will be responsible for developing and implementing predictive models to forecast and optimize future losses associated with Capital One's credit card portfolio. The role will involve partnering with a cross-functional team of data scientists, software engineers, and product managers.",
        "industries": [
            "Financial Services",
            "Banking",
            "Credit Cards"
        ],
        "soft_skills": [
            "Customer-Oriented",
            "Innovative",
            "Creative",
            "Leadership",
            "Communication",
            "Problem Solving",
            "Collaboration"
        ],
        "hard_skills": [
            "Python",
            "Conda",
            "AWS",
            "H2O",
            "Spark",
            "Machine Learning",
            "SQL",
            "Relational Databases",
            "Clustering",
            "Classification",
            "Sentiment Analysis",
            "Time Series",
            "Deep Learning",
            "Data Retrieval",
            "Data Analysis"
        ],
        "tech_stack": [
            "Python",
            "Conda",
            "AWS",
            "H2O",
            "Spark",
            "SQL",
            "Relational Databases"
        ],
        "programming_languages": [
            "Python",
            "Scala",
            "R"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Analytics",
                "STEM"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive benefits",
            "Health insurance",
            "Financial benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3910592360,
        "company": "ClearanceJobs",
        "title": "Data Scientist -Hybrid - 0205-R with Security Clearance",
        "created_on": 1720587464.216596,
        "description": "Data Scientist -Hybrid - 0205-R Location: Washington, DC, Metro Area Job Description: Come join the future of data-driven decision making! At Data Machines we leverage data analytics, DevSecOps, machine intelligence, and data science to engineer solutions for our Federal government, defense, and commercial sponsors to solve real-world, critical mission problems. This position will be based out of our Reston, VA office with a 3 day a week onsite requirement. Responsibilities: Data Machines seeks an energetic data scientist with the desire to work with a tightly-knit team supporting the development and production of cutting-edge defense and intelligence capabilities. The ideal candidate will apply expert knowledge in statistical analysis, complex data mining, and artificial intelligence to make value out of data. They will provide consulting relating to the data mining and analysis of data from a range of sources to transform raw data into concise and actionable insights. The candidate will design and implement data-driven solutions, with specific focus on advanced analytical methods, data models, and visualizations. The ideal candidate will develop quantitative simulations and models to provide descriptive and predictive analytics solution recommendations. Finally, they will identify trends and problems through complex big data analysis and will maintain current in emerging tools and techniques in machine learning, statistical modeling, and analytics. Minimum Qualifications: * Four (4) years of relevant experience in applied research, big data analytics, statistics, applied mathematics, data science, computer science, operations research or other closely related field BS in software Engineering or at least 4 years of experience managing data science projects At least three (2) years of direct experience in machine learning Demonstrates knowledge of data mining methods, databases, data visualization and machine learning Ability to communicate analysis techniques, concepts, and products Ability to develop data-driven solutions, data models, and visualizations Data Bricks Certification Must be able to pass a background check and a drug screen Education: * Advanced Degree (MS or PhD) in Statistics, Applied Mathematics, Data Science, Computer Science, Operations Research or other closely related quantitative or mathematical discipline Experience with open-source cloud tools (e.g. Docker, Kubernetes, OpenStack) Experience with public cloud (e.g. AWS, Azure) security Software Development Experience (any language) Ability to obtain a Secret clearance.",
        "url": "https://www.linkedin.com/jobs/view/3910592360",
        "summary": "Data Machines is seeking a data scientist to work on defense and intelligence projects. Responsibilities include data mining, analysis, and visualization, developing data-driven solutions, and creating quantitative simulations and models. Requires 4 years of relevant experience, a BS in Software Engineering or 4 years of experience managing data science projects, 3 years of experience in machine learning, and Data Bricks Certification. An advanced degree in a related field is preferred. Experience with open-source cloud tools, public cloud security, and software development is also preferred.",
        "industries": [
            "Defense",
            "Intelligence",
            "Government",
            "Data Analytics",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Analytical",
            "Teamwork",
            "Consulting"
        ],
        "hard_skills": [
            "Data Mining",
            "Statistical Analysis",
            "Machine Learning",
            "Artificial Intelligence",
            "Data Visualization",
            "Data Modeling",
            "Data Analysis",
            "Quantitative Simulations",
            "Big Data Analytics",
            "Databases",
            "Docker",
            "Kubernetes",
            "OpenStack",
            "AWS",
            "Azure",
            "Software Development"
        ],
        "tech_stack": [
            "Data Bricks",
            "Docker",
            "Kubernetes",
            "OpenStack",
            "AWS",
            "Azure"
        ],
        "programming_languages": [
            "Software Development (any language)"
        ],
        "experience": 4,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Software Engineering",
                "Statistics",
                "Applied Mathematics",
                "Data Science",
                "Computer Science",
                "Operations Research"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3917252142,
        "company": "ManTech",
        "title": "Senior Data Scientist",
        "created_on": 1720587465.6097825,
        "description": "Secure our Nation, Ignite your Future Become an integral part of a diverse team while working at an Industry Leading Organization, where our employees come first. At ManTech, you’ll help protect our national security while working on innovative projects that offer opportunities for advancement. Currently, ManTech is seeking a motivated, career and customer-oriented Data Scientist III to join our team in the DMV area. Responsibilities include but are not limited to: Manages data science strategy and implementation efforts Remain engaged with the broader data science community and stay up to date with the latest breakthroughs in research and industry, incorporating new data science tradecraft into their areas of responsibility as they see fit Serves as the data science authority within their assigned projects and programs. Their hands-on expertise enables them to oversee the development of new models and/or optimize existing models across datasets that include, but are not limited to, text, speech, images, and video Supervises and mentors subordinate project staff. They collaborate with other Data Scientist IIIs Basic Qualifications: Bachelors degree in a STEM field Five or more (5+) years of related experience If a candidate does not have a degree at all, four (4) additional years of experience are required If a candidate holds an Associates degree rather than a Bachelors degree, two (2) additional years of experience are required Hold one of the following certifications within 6 months of commencing work on the Task Order: CCNA-Security CySA+ GICSP GSEC Security+ CE CND SSCP Preferred Qualifications: Masters degree in computer science or related field Vendor tool certifications appropriate to TDL requirements; e.g., Oracle and Mongo Clearance Requirements: This position requires an active Secret clearance. Physical Requirements Must be able to be in a stationary position more than 50% of the time Must be able to communicate, converse, and exchange information with peers and senior personnel Constantly operates a computer and other office productivity machinery, such as a computer The person in this position frequently communicates with co-workers, management, and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, etc. The projected compensation range for this position is $134,700-$224,700. There are differentiating factors that can impact a final salary/hourly rate, including, but not limited to, Contract Wage Determination, relevant work experience, skills and competencies that align to the specified role, geographic location (For Remote Opportunities), education and certifications as well as Federal Government Contract Labor categories. In addition, ManTech invests in it’s employees beyond just compensation. ManTech’s benefits offerings include, dependent upon position, Health Insurance, Life Insurance, Paid Time Off, Holiday Pay, Short Term and Long Term Disability, Retirement and Savings, Learning and Development opportunities, wellness programs as well as other optional benefit elections. For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.",
        "url": "https://www.linkedin.com/jobs/view/3917252142",
        "summary": "ManTech seeks a Data Scientist III to manage data science strategy and implementation, stay current with advancements in the field, and serve as the data science authority within projects. The ideal candidate has a Bachelor's degree in a STEM field and 5+ years of experience, or equivalent experience based on degree level. Certifications like CCNA-Security, CySA+, and Security+ CE are desired. The position requires an active Secret clearance and offers a competitive salary range of $134,700-$224,700, along with various benefits including health insurance, life insurance, paid time off, and learning & development opportunities.",
        "industries": [
            "National Security",
            "Defense",
            "Government",
            "Data Science",
            "Cybersecurity",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Mentoring",
            "Leadership",
            "Problem-Solving",
            "Decision-Making",
            "Strategic Thinking",
            "Analytical Thinking",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Deep Learning",
            "Statistical Modeling",
            "Data Analysis",
            "Data Visualization",
            "Data Engineering",
            "Model Development",
            "Model Optimization",
            "Text Analysis",
            "Speech Recognition",
            "Image Processing",
            "Video Analysis"
        ],
        "tech_stack": [
            "Oracle",
            "Mongo"
        ],
        "programming_languages": [],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "STEM",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 224700,
            "min": 134700
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Paid Time Off",
            "Holiday Pay",
            "Short Term Disability",
            "Long Term Disability",
            "Retirement Savings",
            "Learning & Development Opportunities",
            "Wellness Programs"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3968763368,
        "company": "USAJOBS",
        "title": "Applications Developer",
        "created_on": 1720587467.0650842,
        "description": "Duties As an Applications Developer for CIA, you will analyze, develop and deploy innovative information/software systems and capabilities to enhance the CIA's capabilities to collect, produce, and disseminate intelligence. Utilizing your education and experience as a Computer Scientist, Software Engineer, or Web Designer and Publisher, you will directly support analysis, intelligence collection, and other business. Applications Developers participate in team environments via structured development lifecycles: analyze and define local and/or enterprise information system requirements, perform system/application design, develop capability prototypes, develop and implement operational information systems, and conduct unit and integration testing of application modules. You also have the opportunity for hands-on research and exploration of leading-edge commercial technologies through application/integration of technology in delivering IT solutions. Requirements Conditions of Employment You must be physically in the United States or one of its territories when you submit your resume via MyLINK. You must be registered for the Selective Service, if applicable. You must be a U.S. citizen and at least 18 years of age (dual-national US citizens are eligible). You must be willing to move to the Washington, DC area. You must successfully complete a thorough medical and psychological exam, a polygraph interview, and a comprehensive background investigation. For further information, please visit: https://www.cia.gov/careers/how-we-hire Qualifications Minimum Qualifications Experience in one or more of the following areas: Big data concepts and technologies, such as: Apache Hadoop, Apache Hive, Solr, Cloudera, MapReduce, R, Spark, Kafka, NiFi, and the ELK (ElasticSearch, Logstash, Kibana) stack DevOps concepts and tools, such as: GitHub, JIRA, Maven, Jenkins, Chef, Ansible, Docker, ELK stack, Nexus, Nagios Database platforms, such as: Oracle, MySQL, NoSQL, Mongo DB, HDFS Programming languages, and related web technologies, such as: Java, Javascript, Python, C#, C++, Perl, Ruby on Rails, SQL, CSS, HTML, XML, JSON Application architecture and systems engineering principles, including: n-tier/services-oriented architecture, application design patterns, Agile development with Scrum, Kanban, application security, developing system requirements, system design artifacts and models, design documentation and development using Amazon Web Services Familiarity with multiple hosting platforms, such as: Windows, Linux, VMware, Citrix, Amazon cloud computing platforms Ability to meet the minimum requirements for joining CIA , including U.S. citizenship and a background investigation Desired Qualifications Proficiency in programming languages and related web technologies, such as: Java, Javascript, Python, C#, C++, Perl, Ruby on Rails, CSS, HTML, XML, JSON, Angular, React, or Vue Familiarity with multiple hosting platforms, such as: Windows, Linux, VMware, Citrix, Amazon cloud computing platforms Education Bachelor's degree in one of the following fields or related studies: Computer Science Computer Engineering Information Systems At least a 3.0 GPA on a 4-point scale",
        "url": "https://www.linkedin.com/jobs/view/3968763368",
        "summary": "The CIA is seeking an Applications Developer to analyze, develop, and deploy innovative software systems to enhance intelligence collection, production, and dissemination. Responsibilities include analyzing and defining system requirements, designing and developing applications, conducting testing, and researching leading-edge technologies. The ideal candidate will have experience in big data, DevOps, database platforms, programming languages, and application architecture. Proficiency in web technologies and familiarity with multiple hosting platforms are also desired. A bachelor's degree in Computer Science, Computer Engineering, or Information Systems with a GPA of at least 3.0 is required.",
        "industries": [
            "Intelligence",
            "Government",
            "Software Development",
            "Information Technology",
            "Cybersecurity"
        ],
        "soft_skills": [
            "Analytical",
            "Problem-solving",
            "Communication",
            "Teamwork",
            "Research",
            "Innovation",
            "Adaptability"
        ],
        "hard_skills": [
            "Apache Hadoop",
            "Apache Hive",
            "Solr",
            "Cloudera",
            "MapReduce",
            "R",
            "Spark",
            "Kafka",
            "NiFi",
            "ELK Stack",
            "GitHub",
            "JIRA",
            "Maven",
            "Jenkins",
            "Chef",
            "Ansible",
            "Docker",
            "Nexus",
            "Nagios",
            "Oracle",
            "MySQL",
            "NoSQL",
            "Mongo DB",
            "HDFS",
            "Java",
            "Javascript",
            "Python",
            "C#",
            "C++",
            "Perl",
            "Ruby on Rails",
            "SQL",
            "CSS",
            "HTML",
            "XML",
            "JSON",
            "Angular",
            "React",
            "Vue",
            "N-Tier Architecture",
            "Services-Oriented Architecture",
            "Application Design Patterns",
            "Agile Development",
            "Scrum",
            "Kanban",
            "Application Security",
            "System Requirements Development",
            "System Design",
            "Amazon Web Services",
            "Windows",
            "Linux",
            "VMware",
            "Citrix"
        ],
        "tech_stack": [
            "Apache Hadoop",
            "Apache Hive",
            "Solr",
            "Cloudera",
            "MapReduce",
            "R",
            "Spark",
            "Kafka",
            "NiFi",
            "ELK Stack",
            "GitHub",
            "JIRA",
            "Maven",
            "Jenkins",
            "Chef",
            "Ansible",
            "Docker",
            "Nexus",
            "Nagios",
            "Oracle",
            "MySQL",
            "NoSQL",
            "Mongo DB",
            "HDFS",
            "Java",
            "Javascript",
            "Python",
            "C#",
            "C++",
            "Perl",
            "Ruby on Rails",
            "SQL",
            "CSS",
            "HTML",
            "XML",
            "JSON",
            "Angular",
            "React",
            "Vue",
            "Amazon Web Services"
        ],
        "programming_languages": [
            "Java",
            "Javascript",
            "Python",
            "C#",
            "C++",
            "Perl",
            "Ruby on Rails",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Computer Engineering",
                "Information Systems"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive background investigation",
            "Medical and psychological exam",
            "Polygraph interview"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3814638225,
        "company": "Carnegie Mellon University",
        "title": "Machine Learning Research Scientist",
        "created_on": 1720587470.9972067,
        "description": "What We Do: At the SEI AI Division, we conduct research in applied artificial intelligence and the engineering questions related to the practical design and implementation of AI technologies and systems. We currently lead a community-wide movement to mature the discipline of AI Engineering for Defense and National Security. As our government customers adopt AI and machine learning to provide leap-ahead mission capabilities, we build real-world, mission-scale AI capabilities through solving practical engineering problems discover and define the processes, practices, and tools to support operationalizing AI for robust, secure, scalable, and human-centered mission capabilities prepare our customers to be ready for the unique challenges of adopting, deploying, using, and maintaining AI capabilities identify and investigate emerging AI and AI-adjacent technologies that are rapidly transforming the technology landscape Are you creative, curious, energetic, collaborative, technology-focused, and hard-working? Are you interested in making a difference by bringing innovation to government organizations and beyond? Apply to join our team. Position Summary: As a research scientist specializing in machine learning, you will identify, shape, apply, conduct, and lead research that matches critical U.S. government needs. Requirements: BS in Computer Science or related discipline with eight (8) years of experience; OR MS in the same fields with five (5) years of experience; OR PhD with three (3) years of experience. Flexible to travel to other SEI offices in Pittsburgh and Washington, DC, sponsor sites, conferences, and offsite meetings on occasion. Moderate (25%) travel outside of your home location. You will be subject to a background investigation and must be eligible to obtain and maintain a Department of Defense security clearance. Applicants for this position must be currently legally authorized to work for CMU in the United States. CMU will not sponsor or take over sponsorship of an employment visa for this opportunity. Duties: Hands-on research: You’ll conduct and lead novel research in applied machine learning and artificial intelligence. Solution development: You’ll work with and lead interdisciplinary teams to turn research results into prototype operational capabilities for government customers and stakeholders. Strategy: You’ll work with Center leaders and colleagues to plan, develop, and carry out an overall research strategy, and to influence the national research agenda regarding future technology. Collaboration: You'll actively participate on teams of software developers, researchers, designers, and technical leads. You'll build relationships and collaborate with researchers, government customers, and other stakeholders to understand challenges, needs, possible solutions, and research directions. Mentoring: You'll contribute to improving the overall technical capabilities of the team by mentoring and teaching others, participating in design (software and otherwise) sessions, and sharing insights and wisdom across the SEI Artificial Intelligence Division. Knowledge, Skills, and Abilities: Deep technical knowledge: You have performed extensive research in applied machine learning and artificial intelligence. You have worked with tools, techniques, algorithms, software, and programming languages for deep learning, reinforcement learning, statistics, sensors and sensor fusion, planning, computer vision, or related areas. Communication and Collaboration: You have strong written and verbal communication skills and can interact collaboratively and diplomatically with customers and colleagues. You grasp the big picture, direction, and goals of an effort while focusing great attention to detail. You can present complex ideas to people who may not have a deep understanding of the subject area. Dedication: You can meet deadlines while multi-tasking–sometimes under pressure and with shifting priorities. Creativity and Innovation: You are creative and curious, and you are inspired by the prospect of collaborating with premier researchers and visionaries at Carnegie Mellon and other universities and organizations. You quickly learn new procedures, techniques, and approaches. You are forward-looking and can connect research with practical challenges. Knowledge and Learning: You possess broad technical interests along with a deep knowledge of a particular field such as human-computer interaction, data analytics and machine learning, advanced computing, and autonomy and adaptive systems. Desired Experience: Research practices and publications: You have a track record of conducting research in machine learning and artificial intelligence. You have a reputation for the highest level of research and technical integrity. You have demonstrated contributions and have published research. Familiarity with emerging trends and opportunities: You are familiar with technical challenges and emerging trends in computing and information science, and you are aware of opportunities in industry and government. Technical leadership: You have led research projects and have experience collaborating across research teams and mentoring other researchers. Proposals: You have formulated and delivered successful research proposals to funding agencies and led the resulting projects. Government projects: You have worked or are familiar with DARPA, IARPA, Service Labs, or other government research sponsors. Location Arlington, VA, Pittsburgh, PA Job Function Software/Applications Development/Engineering Position Type Staff – Regular Full Time/Part time Full time Pay Basis Salary More Information: Please visit “Why Carnegie Mellon” to learn more about becoming part of an institution inspiring innovations that change the world. Click here to view a listing of employee benefits Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran. Statement of Assurance",
        "url": "https://www.linkedin.com/jobs/view/3814638225",
        "summary": "The SEI AI Division is seeking a research scientist specializing in machine learning to conduct research and develop operational AI capabilities for government customers. The ideal candidate will have a strong background in applied machine learning, deep learning, reinforcement learning, statistics, and related areas, as well as excellent communication and collaboration skills.",
        "industries": [
            "Defense",
            "National Security",
            "Government",
            "Research",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Creativity",
            "Innovation",
            "Dedication",
            "Problem Solving",
            "Leadership",
            "Mentoring",
            "Teaching",
            "Teamwork",
            "Interpersonal Skills",
            "Diplomatic"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Reinforcement Learning",
            "Statistics",
            "Sensors and Sensor Fusion",
            "Planning",
            "Computer Vision",
            "Data Analytics",
            "Human-Computer Interaction",
            "Advanced Computing",
            "Autonomy and Adaptive Systems",
            "Research"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 8,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Computer Science",
                "Related Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Travel",
            "Security Clearance",
            "Employee Benefits"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3961645719,
        "company": "ClearanceJobs",
        "title": "DATA SCIENTIST with Security Clearance",
        "created_on": 1720587475.1528347,
        "description": "Duties Provides the development and implementation of Data Science solutions Leverages the latest data science innovations in alternative data sourcing, such as the use of administrative records and other data sources Evaluation and Assessment of New Technologies Research Leadership Exercises Designated Contracting Officer Representative processes Requirements Conditions of Employment U.S. Citizenship Required Males must be registered for Selective Service, see www.sss.gov If authorized, PCS will be paid IAW JTR and AF Regulations. If receiving an authorized PCS, you may be subject to completing/signing a CONUS agreement. More information on PCS requirements, may be found at: https://afciviliancareers.com/regulatory/ This position is subject to provisions of the DoD Priority Placement Program Disclosure of Political Appointments Recruitment Incentive may be authorized for this position Relocation Incentive may be authorized for this position At a minimum, qualification requirements stipulated by the US Office of personnel Management for the 1560 occupational series must be met. A degree in mathematics, statistics, computer science, data science or field directly related to the position Degree must be in a major field of study (at least baccalaureate level) appropriate for the position or a combination of education and experience: courses equivalent to a major field of study (30 hours), plus education or appropriate experience A nationally recognized professional certification in Data Science, Data Analytics, or a directly related sub-field; and professional experience in operations research or computer science is highly desirable Work may occasionally require travel away from the normal duty station on military or commercial aircraft Must exhibit a high degree of judgment, resourcefulness, originality, and the ability to foresee the impact of changing technology Must be able to obtain and maintain the appropriate security clearance This position has been designated by the Air Force as a Testing Designated Position (TDP) under the Air Force Civilian Drug Demand Reduction Program. Employee must pass initial and periodic short notice drug testing Illegal drug use by employees in sensitive positions presents a clear threat to the mission of the Air Force, national security, and public safety The incumbent must be able to obtain Contracting Officer Representative (COR) designation within 30 days of hiring and maintain COR designation as coordinated with the Chief COR and/or Contracting Officer Professional knowledge of a full range of federal contracting laws, executive orders, regulations, principles, polices, procedures methods, techniques, and contract types applicable to [cont.] * pre-award and post-award actions for a variety of complex and /or diversified services; contracting negotiation, administration, and termination principles, polices, procedures and technical requirements Skill in qualitative and quantitative analysis techniques to measure return of investment and efficiency of contracted services Qualifications In order to qualify, you must meet the specialized experience requirements described in the Office of Personnel Management (OPM) Qualification Standards for General Schedule Positions, Professional and Scientific Positions. BASIC REQUIREMENT OR INDIVIDUAL OCCUPATIONAL REQUIREMENT: In addition to meeting the basic requirement above, to qualify for this position you must also meet the qualification requirements listed below: I have a degree in mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. Or, I have courses equivalent to a major field of study (30 semester hours), plus additional education or appropriate experience. NOTE: You must submit a copy of your transcripts with your application SPECIALIZED EXPERIENCE: Applicants must have at least one (1) year of specialized experience at the next lower grade GS-13, or equivalent in other pay systems. Examples of specialized experience includes professional knowledge and mastery of a broad range of data analyses, mathematics, statistical analysis, modeling/simulation, and/or other scientific concepts, principles, standards, methods, techniques, practices, and procedures; professional knowledge and expertise in data modeling, query authoring and performance tuning with an in-depth understanding of data modeling best practices, relational and graph databases; knowledge of advanced, analytical, mathematical, or statistical theories, principles, concepts, methods, and techniques to provide expert judgments concerning the validity of assumptions made and the criteria to evaluate alternatives; expert knowledge and experience working with large and complex data sets and performing extensive analysis of volumes of data and designing and delivering frameworks to facilitate the data development lifecycle and design, implementation integration and maintenance of the pipeline and data warehouse and transitions to cloud-based data solutions; extensive knowledge and mastery of research techniques and concurrent ability to obtain information concerning subject studies to perform sound analyses; knowledge of information systems security principles and concepts in order to ensure all data analytics efforts are conducted in accordance with information security best practices; knowledge and skill in coordinating extensive projects in assigned areas of responsibility. Projects are characterized by high visibility, unusual urgency, or program criticality. FEDERAL TIME-IN-GRADE (TIG) REQUIREMENT FOR GENERAL SCHEDULE (GS) POSITIONS: Merit promotion applicants must meet applicable time-in-grade requirements to be considered eligible. One year at the GS-13 level is required to meet the time-in-grade requirements for the GS-14 level. TIG applies if you are in a current GS position or held a GS position within the previous 52 weeks. NOTE: Applicants applying as VEOA candidates who are current GS civil service employees or are prior GS civil service employees within the past 52 weeks must also meet time-in-grade requirements. KNOWLEDGE, SKILLS AND ABILITIES (KSAs): Your qualifications will be evaluated on the basis of your level of knowledge, skills, abilities and/or competencies in the following areas: Expert professional knowledge of quantitative techniques and methods used to conceptualize, develop, adapt, modify, and apply new models to resolve the most difficult problems and to achieve support for alternative solutions within the scientific community. Advanced knowledge and skill of a broad range of defense department or private sector C4 systems, data, scientist Big Data analytics, machine learning, AI, cognitive science, programs, operations, strategies, tactics, resource and information processes, force structure, and weapons systems. Includes operations research analysis techniques and mastery of scientific and analytical capabilities. Advanced skill in articulating and negotiating very complex and sensitive issues with officials of diverse perspectives and often with different or opposing views. Expert Ability to negotiate and defend findings and gain executive support for new program concepts. Skill in leading advanced study teams composed of industry, government, and academic experts; originate new ideas, projects, and methodologies; and execute projects and/or studies within established financial and/or time constraints. Skill to develop and utilize appropriate data collection techniques and design, build and use models and simulation techniques. Ability to plan, organize, direct, and lead the functions and staff and/or study team tasked to originate new ideas, projects, and methodologies. Communicates in a way to negotiate complex and/or sensitive issues and maintain good working relations. PART-TIME OR UNPAID EXPERIENCE: Credit will be given for appropriate unpaid and or part-time work. You must clearly identify the duties and responsibilities in each position held and the total number of hours per week. VOLUNTEER WORK EXPERIENCE: Refers to paid and unpaid experience, including volunteer work done through National Service Programs (i.e., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community; student and social). Volunteer work helps build critical competencies, knowledge and skills that can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience. Education IF USING EDUCATION TO QUALIFY: If position has a positive degree requirement or education forms the basis for qualifications, you MUST submit transcriptswith the application. Official transcripts are not required at the time of application; however, if position has a positive degree requirement, qualifying based on education alone or in combination with experience, transcripts must be verified prior to appointment. An accrediting institution recognized by the U.S. Department of Education must accredit education. Click here to check accreditation. FOREIGN EDUCATION: Education completed in foreign colleges or universities may be used to meet the requirements. You must show proof the education credentials have been deemed to be at least equivalent to that gained in conventional U.S. education program. It is your responsibility to provide such evidence when applying. Additional information Continued from Summary Section: The incumbent provides authoritative data science leadership in the development, analysis, and implementation of a data program(s). Interagency Career Transition Assistance Program (ICTAP): For information on how to apply as an ICTAP eligible click here . To be well-qualified and exercise sel",
        "url": "https://www.linkedin.com/jobs/view/3961645719",
        "summary": "This is a Data Science position at the Air Force, requiring at least one year of specialized experience at the GS-13 level or equivalent. The position involves development and implementation of Data Science solutions, leveraging new data sources and technologies. The role demands expertise in data analytics, modeling, simulation, query authoring, and data warehouse management. The individual must possess advanced knowledge of data science concepts, quantitative techniques, and research methodologies.  Strong communication and leadership skills are crucial for collaborating with diverse teams and negotiating complex issues.  A degree in mathematics, statistics, computer science, data science or a related field is mandatory, and a nationally recognized professional certification in Data Science is desirable.",
        "industries": [
            "Aerospace & Defense",
            "Government",
            "Military"
        ],
        "soft_skills": [
            "Communication",
            "Leadership",
            "Negotiation",
            "Problem Solving",
            "Collaboration",
            "Teamwork",
            "Resourcefulness",
            "Originality",
            "Judgment",
            "Analytical Thinking"
        ],
        "hard_skills": [
            "Data Analysis",
            "Mathematics",
            "Statistical Analysis",
            "Modeling",
            "Simulation",
            "Data Modeling",
            "Query Authoring",
            "Performance Tuning",
            "Data Warehouse Management",
            "Cloud-based Data Solutions",
            "Research Techniques",
            "Information Security",
            "Project Management",
            "Quantitative Techniques",
            "Big Data Analytics",
            "Machine Learning",
            "AI",
            "Cognitive Science",
            "Operations Research",
            "Data Collection"
        ],
        "tech_stack": [
            "Data Science",
            "Big Data Analytics",
            "Machine Learning",
            "AI",
            "Cognitive Science",
            "Data Modeling",
            "Query Authoring",
            "Performance Tuning",
            "Cloud-based Data Solutions",
            "Data Warehouse",
            "Data Pipeline",
            "C4 Systems",
            "Defense Department Systems",
            "Private Sector Systems"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Data Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Relocation Incentive",
            "Recruitment Incentive",
            "PCS (Permanent Change of Station)"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Reston, VA",
        "job_id": 3940941397,
        "company": "Zenius Corporation",
        "title": "Databricks Developer - Pipeline",
        "created_on": 1720587482.8546164,
        "description": "Databricks Developer Candidates must be a US Citizen or a Legal Permanent Resident (Green Card status) for 3 years and be Federal Tax compliant Active IRS MBI Clearance is highly desirable. Remote Position Overview: Business Master File Modernization (BMF Mod) is one of multiple programs created to modernize the Internal Revenue Services (IRS) the legacy Tax processing systems and is critical to the IRS IT Application Development (AD) and IRS IT Enterprise Service (ES) organizations’ goal to support the objectives of the IRS IT Modernization Business Plan. BMF Mod’s initiative will modernize IRS systems and processes, improve taxpayer experience, increase voluntary compliance, and reduce the Service’s reliance on costly and unsustainable legacy technology. Key Responsibilities Design, develop, and deploy data pipelines and ETL processes using Databricks. Collaborate with data engineers, data scientists, and other stakeholders to understand requirements and translate them into technical solutions. Optimize and tune Databricks jobs for performance and scalability. Implement best practices for data governance, security, and compliance on the Databricks platform. Troubleshoot and debug issues with Databricks jobs and pipelines. Stay current with emerging trends and technologies in big data and cloud computing, particularly related to Databricks and Apache Spark. Requirements Proven experience working with Databricks for big data processing and analytics. Strong programming skills in languages such as Python, Scala, or SQL. Experience with Apache Spark and related technologies. Familiarity with cloud platforms such as AWS, Azure, or Google Cloud Platform. Excellent problem-solving and analytical skills. Strong communication and collaboration skills. Preferred Qualifications: Experience with machine learning and data science workflows on Databricks. Certification in Databricks or related technologies. Experience with containerization and orchestration tools such as Docker and Kubernetes. Education Bachelor’s degree in computer science, information technology, or related field. About The Company Headquartered in Leesburg, Virginia, Zenius Corporation is a HUBZone-certified small business. Zenius specializes in providing Grants Management, IT Modernization, Acquisition Management, and Financial Management services to Federal agencies. Zenius is selected by Inc 5000 as one of the fastest-growing companies in the DC Metro Area award for two years in a row – 2021 and 2020. Zenius is also listed by Financial Times as one of the fastest-growing companies in the Americas in 2021. Zenius is an awardee of 2019 Best of Leesburg winner (Business Management Consultant category). Learn more at. Benefits Zenius Corporation is a very employee-oriented company. Join us now and help us grow! We offer a competitive benefits package that includes paid holidays and paid time off, medical insurance including health, vision, dental insurance, 401K matching, Flexible Spending Account and flexible schedules, as per business needs. We also work with our employees on training and professional certification plans that benefit the employee. Equal Opportunity Employer Zenius Corporation provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws. Zenius complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. Zenius Corporation expressly prohibits any form of unlawful employee harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status.",
        "url": "https://www.linkedin.com/jobs/view/3940941397",
        "summary": "Zenius Corporation is seeking a Databricks Developer to design, develop, and deploy data pipelines and ETL processes using Databricks. This role involves collaborating with data engineers, data scientists, and other stakeholders to understand requirements and translate them into technical solutions. The ideal candidate will have proven experience working with Databricks for big data processing and analytics, strong programming skills in languages such as Python, Scala, or SQL, and experience with Apache Spark and related technologies. Experience with machine learning and data science workflows on Databricks is preferred.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Big Data",
            "Cloud Computing",
            "Data Analytics",
            "Data Science",
            "Government",
            "Consulting"
        ],
        "soft_skills": [
            "Problem Solving",
            "Analytical",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Databricks",
            "Python",
            "Scala",
            "SQL",
            "Apache Spark",
            "AWS",
            "Azure",
            "Google Cloud Platform",
            "Docker",
            "Kubernetes"
        ],
        "tech_stack": [
            "Databricks",
            "Apache Spark",
            "AWS",
            "Azure",
            "Google Cloud Platform",
            "Docker",
            "Kubernetes"
        ],
        "programming_languages": [
            "Python",
            "Scala",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Information Technology"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Paid Holidays",
            "Paid Time Off",
            "Medical Insurance",
            "Vision Insurance",
            "Dental Insurance",
            "401K Matching",
            "Flexible Spending Account",
            "Flexible Schedules",
            "Training",
            "Professional Certification"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Chantilly, VA",
        "job_id": 3963299871,
        "company": "ClearanceJobs",
        "title": "Junior Data Scientist with Security Clearance",
        "created_on": 1720587484.3959565,
        "description": "20240628-454-04-01 Active Top Secret Clearance with Poly Required Salary Range: Up to $130K **salary is commensurate with education and experience** **Please note: This job requires an existing Top Secret Clearance and Polygraph** Responsibilities and Duties: Recommend changes to current applications and databases based on Sponsor requirements. Recommend modernization options for data hosting, data cleansing, data transport, data exposure and data ingestion at an enterprise scale Make recommendations to the Sponsor for modernization with a focus on performance, security, and cost, with the flexibility to store and manage large volumes of disparate, enterprise datasets while identifying the authoritative dataset and reducing dataset duplication. Manage enhancements and improvements to current data systems technology and processes, including data access authorizations against enterprise-approved user attributes and solutions with Sponsor oversight. Provide operations and maintenance of databases in the cloud infrastructure. Support Sponsor's representatives in cloud environment purchase, engineering, and architecture related activities as applicable to applications and databases. Execute development, design and creation of database systems that enable storage and smooth retrieval of data. Ensure the smooth and secure running of the Sponsor's enterprise database systems. Collaborate with team members, external stakeholders, and data stewards to define the current state of Sponsor data. Build data models that are optimized for reporting from a data warehouse. Experience Needed: Citizenship: Must Be a US Citizen Existing Clearance Required: Active Top Secret SCI with Poly Demonstrated experience utilizing Oracle, PostgreSQL and modern database technologies. Demonstrated experience with Tableau, COGNOS and modern technologies for reporting presentation. Demonstrated experience performing testing and quality assurance of developed solutions within the existing Oracle data tier. Demonstrated experience developing, creating, and modifying data structure and data load routines for analytic use cases. Demonstrated experience working with relational data tiers including cleansing, transforming and processing of structured data. Demonstrated experience working with views, triggers and Oracle PL and SQL. Demonstrated knowledge of Amazon Web Services environments, including RDS, S3, etc. Optional Skills: Demonstrated experience with IMMUTA data policy. Demonstrated experience with a variety of data repository types (i.e., relational, NoSQL, distributed processing framework, etc.). Demonstrated experience creating and interfacing with REST APIs. Health Benefits Work/Life Balance Financial Opportunities Medical, Dental, Vision, Health Savings Account and more. Paid Time Off, Holidays, Social Events, Employee Assistance Program and Team Building 401K, Tuition Assistance, Annual and Referral Bonuses Main Number: 1-888-663-2690 | [email protected] | www.dezign-concepts.com Dezign Concepts provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",
        "url": "https://www.linkedin.com/jobs/view/3963299871",
        "summary": "This is a job posting for a Database Engineer with a focus on data modernization and cloud infrastructure. The position requires an active Top Secret Clearance with Polygraph and involves responsibilities such as recommending data hosting, cleansing, and ingestion strategies, managing database systems, and collaborating with stakeholders to define data needs. It also involves working with Oracle, PostgreSQL, Tableau, COGNOS, and AWS environments.",
        "industries": [
            "Information Technology",
            "Government",
            "Defense"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Decision Making"
        ],
        "hard_skills": [
            "Oracle",
            "PostgreSQL",
            "Tableau",
            "COGNOS",
            "REST APIs",
            "AWS",
            "RDS",
            "S3",
            "Data Modeling",
            "Data Warehousing",
            "Data Cleansing",
            "Data Transformation",
            "Data Processing",
            "Data Ingestion",
            "Data Security",
            "Data Governance",
            "Database Administration",
            "Database Design",
            "Database Development",
            "Cloud Infrastructure",
            "Cloud Computing",
            "IMMUTA"
        ],
        "tech_stack": [
            "Oracle",
            "PostgreSQL",
            "Tableau",
            "COGNOS",
            "AWS",
            "RDS",
            "S3",
            "REST APIs",
            "IMMUTA"
        ],
        "programming_languages": [
            "PL/SQL",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": [
                "Computer Science",
                "Information Technology",
                "Data Science"
            ]
        },
        "salary": {
            "max": 130000,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Health Savings Account",
            "Paid Time Off",
            "Holidays",
            "Social Events",
            "Employee Assistance Program",
            "Team Building",
            "401K",
            "Tuition Assistance",
            "Annual and Referral Bonuses"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Annapolis Junction, MD",
        "job_id": 3941738507,
        "company": "Belay Technologies",
        "title": "Junior Software Engineer",
        "created_on": 1720587485.9498613,
        "description": "Belay Technologies has been voted Baltimore Business Journal's (BBJ) Best Places to Work 2019, runner up in 2020 and a finalist in 2021! Belay Technologies is seeking a Software Engineer (Full Stack) to join our intel team. , so you will see products through their full lifecycle and take full ownJoin CNO's Custom Media Operations team, recent winners of the President's Intelligence Advisory Board Killian Award for outstanding mission support. CMO is leading the charge on AI/ML capabilities in the IC. You will support the team in full-stack web development efforts that connect CMO's capabilities with their customers. This is a small team, so you will see products through their full lifecycle and take full ownership of their success. Responsibilities: Build a full stack application in collaboration with machine learning and artificial intelligence engineers doing novel computer vision model development. Interact with ML/AI engineers, senior stakeholders, and CMO customers to provide the best possible user experience for all involved. Continue development of the CMO homepage and website, which is not only customers' first impression of the organization but also used by CMO to track individual deliverables through their workflow and includes self-service features for the CMO team. Prototype future capabilities with the CMO data science team as they generate new ideas to meet their customers' needs Candidates should have the following qualifications: TS/SCI Clearance with polygraph 3 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S. (Degree must be in Computer Science or equivalent field.) Candidates are desired to have the following skills: Successful applicants must be self-starters, capable of scoping and tracking work through completion, working closely with a team and stakeholders, reaching out to users to iterate on new capabilities, and testing and deploying their software. Full stack development experience is a must, including experience with the following technologies: Docker General DevOps experience, including GitLab CI/CD Java and Spring Boot MongoDB UI development including JavaScript, React, and/or Material UI Linux command line (especially Bash) Nice to Haves: Machine learning experience, or experience working with data scientists and deploying ML models Experience with AWS (especially C2S) Python experience Node.js Perks and Benefits: 8 weeks paid leave - 4 weeks of personal leave, 3 Yay! days, take off on your birthday,11 paid holidays and optional leave up to 6 days through Belay's volunteer program 10% matching in 401(k) contributions vested on day one $5,000 annual training/tuition Student Loan Repayment Program 100% company-funded HSA Rich medical coverage (100% coinsurance) Dental coverage including orthodontia Up to $420,000 in life insurance, premiums 100% company funded Amazon Prime, gym reimbursement, monthly lunches, games and prizes Pet adoption program, generous referral bonus program, fun events, and more! Belay Technologies is a certified Service-Disabled Veteran-Owned Small Business located in Columbia, Maryland (Baltimore/Washington area). Belay Technologies specializes in systems automation and full stack development. Belay Technologies provides leading technology and engineering solutions to the DoD, as well as state-of-the-art commercial products. We hire software engineers, web designers, test engineers, systems engineers, systems administrators, database engineers and other tech services. We are an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law. Powered by JazzHR s3Yqfy8yQa",
        "url": "https://www.linkedin.com/jobs/view/3941738507",
        "summary": "Belay Technologies seeks a full-stack Software Engineer to join their Custom Media Operations (CMO) team, developing web applications that connect CMO's AI/ML capabilities with their customers. The role involves building full-stack applications in collaboration with ML/AI engineers, interacting with stakeholders and customers, developing the CMO homepage and website, and prototyping future capabilities. Ideal candidate will have full-stack development experience with Docker, DevOps, Java, Spring Boot, MongoDB, UI development (JavaScript, React, Material UI), and Linux command line. Experience with machine learning, AWS, Python, and Node.js is a plus.",
        "industries": [
            "Technology",
            "Software Development",
            "Artificial Intelligence",
            "Machine Learning",
            "Computer Vision",
            "Defense",
            "Government",
            "Intelligence"
        ],
        "soft_skills": [
            "Self-starter",
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Stakeholder Management",
            "User Experience (UX)",
            "Iterative Development",
            "Testing",
            "Deployment"
        ],
        "hard_skills": [
            "Docker",
            "DevOps",
            "GitLab CI/CD",
            "Java",
            "Spring Boot",
            "MongoDB",
            "JavaScript",
            "React",
            "Material UI",
            "Linux",
            "Bash",
            "Machine Learning",
            "AWS",
            "Python",
            "Node.js"
        ],
        "tech_stack": [
            "Docker",
            "GitLab CI/CD",
            "Java",
            "Spring Boot",
            "MongoDB",
            "JavaScript",
            "React",
            "Material UI",
            "Linux",
            "Bash",
            "AWS",
            "Python",
            "Node.js"
        ],
        "programming_languages": [
            "Java",
            "JavaScript",
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Computer Science",
                "Technical discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Paid Leave",
            "Personal Leave",
            "Holiday Pay",
            "Volunteer Leave",
            "401k Matching",
            "Training/Tuition",
            "Student Loan Repayment",
            "HSA",
            "Medical Coverage",
            "Dental Coverage",
            "Life Insurance",
            "Amazon Prime",
            "Gym Reimbursement",
            "Lunches",
            "Games",
            "Pet Adoption Program",
            "Referral Bonus",
            "Events"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Sterling, VA",
        "job_id": 3940847830,
        "company": "ManTech",
        "title": "Senior Data Scientist",
        "created_on": 1720587487.4012985,
        "description": "Secure our Nation, Ignite your Future Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of solutions to promote efficient trade and travel. Further, effective solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure. In response to this challenge, ManTech, as a trusted mission partner of CBP, seeks capable, qualified, and versatile Data Scientists to help lead the development and delivery of high-quality predictive modelling solutions. Successful applicants will serve as recognized subject matter experts in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. They will help our team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy. This position potentially offers a flexible work schedule at the discretion of the customer. At this time, we are only accepting candidates who reside within a commutable distance to the DMV area. The strongest applicants will offer multiple years of experience in highly dynamic, threat/risk driven operating environments. They will also have a proven track record of delivering production ready decision support tools and applications employed in the field and by mission-support entities. Further, highly competitive applicants will have a demonstrated capacity to: work closely and collaboratively with mission stakeholders; respond to emergent, mission-driven changes in priorities and expected outcomes; and, apply new and emerging tools and techniques. Within three - six months of joining the project, Data Scientists will be expected to: Perform hands-on analysis and modeling involving the creation of intervention hypotheses and experiments, assessment of data needs and available sources, determination of optimal analytical approaches, performance of exploratory data analysis, and feature generation (e.g., identification, derivation, aggregation). Collaborate with mission stakeholders to define, frame, and scope mission challenges where big data interventions may offer important mitigations and develop robust project plans with key milestones, detailed deliverables, robust work tracking protocols, and risk mitigation strategies. Demonstrate proficiency in extracting, cleaning, and transforming CBP transactional and mission data associated within an identified problem space to build predictive models as well as develop appropriate supporting documentation. Leverage knowledge of a variety of statistical and machine learning techniques and methods to define and develop programming algorithms; train, evaluate, and deploy predictive analytics models that directly inform mission decisions. Execute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching. Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior government stakeholders throughout the model development/ project lifecycle through written as well as in-person reporting. Required Qualifications Experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems Experience with programming languages including: R, Python, Scala, Java. Proficiency with SQL programming Experience constructing and executing queries to extract data in support of EDA and model development Proficiency with statistical software packages including: SAS, SPSS Modeler, R, WEKA, or equivalent Experience with pattern recognition and extraction, automated classification, and categorization Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) Experience with unsupervised and supervised machine learning techniques and methods Experience performing data mining, analysis, and training set construction Desired Qualifications Proficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc. Proficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc. Experience with pattern recognition and extraction, automated classification, and categorization Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) Experience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI) Experience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop) Master’s Degree in mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience Minimum Qualifications: HS Diploma/GED and 15+ years AS/AA and 13-18 years BS/BA and 7-12 years MS/MA/MBA and 5-9 years PhD/Doctorate and 3-7 years Certification: None Clearance: Selected applicants must be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) suitability. For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.",
        "url": "https://www.linkedin.com/jobs/view/3940847830",
        "summary": "ManTech is seeking Data Scientists to develop and deliver predictive modeling solutions for U.S. Customs and Border Protection (CBP). The role involves applying quantitative methods, machine learning, and predictive models to address national and homeland security challenges. Responsibilities include data collection, mining, analysis, and model development to enhance automated risk assessment and drive optimized decision-making. This position offers potential for a flexible work schedule and requires applicants to reside within a commutable distance to the DMV area.",
        "industries": [
            "Government",
            "National Security",
            "Homeland Security",
            "Data Science",
            "Machine Learning",
            "Predictive Modeling"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Decision Making",
            "Time Management",
            "Project Management",
            "Adaptability",
            "Teamwork",
            "Stakeholder Management"
        ],
        "hard_skills": [
            "Data Collection",
            "Data Mining",
            "Data Analysis",
            "Text Analytics",
            "Clustering Analysis",
            "Pattern Recognition",
            "Automated Classification",
            "Categorization",
            "Entity Resolution",
            "Machine Learning",
            "Predictive Modeling",
            "Data Visualization",
            "SQL",
            "R",
            "Python",
            "Scala",
            "Java",
            "SAS",
            "SPSS Modeler",
            "WEKA",
            "Hadoop",
            "HIVE",
            "HDFS",
            "HBase",
            "MapReduce",
            "Spark",
            "Kafka",
            "Sqoop",
            "K-means",
            "K-nearest Neighbor",
            "Hierarchical Clustering",
            "Deep Belief Networks",
            "Principal Component Analysis",
            "Decision Trees",
            "Support Vector Machines",
            "Logistic Regression",
            "Random Forests",
            "Rotation Forests",
            "Neural Networks",
            "Bayesian Networks",
            "Periscope",
            "Business Objects",
            "D3",
            "ggplot",
            "Tableau",
            "SAS Visual Analytics",
            "PowerBI"
        ],
        "tech_stack": [
            "R",
            "Python",
            "Scala",
            "Java",
            "SQL",
            "SAS",
            "SPSS Modeler",
            "WEKA",
            "Hadoop",
            "HIVE",
            "HDFS",
            "HBase",
            "MapReduce",
            "Spark",
            "Kafka",
            "Sqoop",
            "Periscope",
            "Business Objects",
            "D3",
            "ggplot",
            "Tableau",
            "SAS Visual Analytics",
            "PowerBI"
        ],
        "programming_languages": [
            "R",
            "Python",
            "Scala",
            "Java",
            "SQL"
        ],
        "experience": 7,
        "education": {
            "min_degree": "HS Diploma/GED",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Flexible Work Schedule"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Fort George G. Meade, MD",
        "job_id": 3921374733,
        "company": "Elder Research",
        "title": "Front End Software Engineer",
        "created_on": 1720587491.3469844,
        "description": "Onsite Location: Ft Meade, MD Clearance: TS/SCI + Polygraph At Elder Research Inc., a recognized leader in data science and machine learning solutions, we pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We are looking for innovative and inquisitive self-starters who enjoy understanding a problem space and building fast, efficient, and tractable data infrastructure to deliver real value for our clients. As a member of the Elder Research team, you will join a functional team of accomplished Data Scientists and Software Engineers that deliver custom analytic solutions. Description The Front End Software Engineer shall support the customer’s mission through the integration of prototype processing solutions to improve ETL processes, performance and stability of the customer’s products. In addition, contractor shall support the creation of metrics and monitoring capabilities and dashboards for the customer’s products. You will Support development of GUIs to enable non-technical analysts to review and interact with data. Job Description The Software Engineer designs, develops, tests, deploys, documents, maintains, and enhances complex and diverse software systems based upon documented requirements. These systems might include, but are not limited to, processing­ intensive analytics, novel algorithm development, manipulation of extremely large data sets, real-time systems, business management information systems, and systems which incorporate data repositories, data transport services, and application and systems development and monitoring. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Open Source Software (OSS) and/or Commercial Off­The-Shelf (COTS) or Government Off-The-Shelf (GOTS) software in place of new development, and requirements analysis and synthesis from system level to individual software components. Experience developing in Unix. Ability to perform shell scripting. Working knowledge of Configuration Management (CM) tools and Web Services implementation. Qualifications Required Must have an active TS/SCI with Poly. Bachelor’s degree in Computer Science or related discipline from an accredited college or university, plus five (5) years of experience as a SWE, in programs and contracts of similar scope, type, and complexity. Required Skills Experience using the Unix command line Angular 12/13, Typescript, Python 3 Pandas, PIL/Pillow, Wand/Imagemagick, Docker Experience writing scripts using Bash Experience developing in Java in a Unix environment Experience developing, configuring, troubleshooting, and sustaining large Accumulo cloud deployments in a Unix environment Experience developing with multiple programming languages such as C, Java, and Python Experience with containerization technologies such as Docker Experience with container orchestration technologies such as Kubernetes Experience with distributed file systems such as Ceph Excellent verbal and written communication skills Willing and ability to work with clients either on-site or from an ERI Corporate Office Desired Skills General HPC knowledge regarding compute, networking, memory, and storage components Experience with CI/CD principals and concepts using tools such as Jenkins, GitLab CI, and Bamboo Experience with IaC principles and automation tools such as Ansible, Puppet, and SaltStack Experience with the Atlassian suite of tools (Jira, Confluence, Bitbucket) Experience with scala/spark About Elder Research, Inc. Headquartered in Charlottesville, VA with offices in Arlington, VA, Baltimore, MD, and Raleigh, NC, Elder Research is a fast growing solutions and consulting firm specializing in predictive analytics. At Elder Research, you’ll be part of a fun, friendly community. In keeping with our entrepreneurial spirit, we want candidates that are self-motivated with an innate curiosity and strong team work ethic. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately. Elder Research provides analytic solutions to hundreds of companies across numerous industries. Our team enjoys great variety in the type of work they do and exposure to a wide range of techniques and tools. If you are passionate about integrating data, technology, and analytics in a team-based environment to solve problems, then Elder Research may be a good fit for you. Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Elder Research is unable to sponsor H1B visas for this role",
        "url": "https://www.linkedin.com/jobs/view/3921374733",
        "summary": "Elder Research Inc. is seeking a Front End Software Engineer to support the integration of prototype processing solutions and develop GUIs for non-technical analysts. The ideal candidate will have experience with Unix, Angular, Typescript, Python, Pandas, Docker, Bash scripting, Java, Accumulo, C, containerization, Kubernetes, Ceph, and CI/CD tools. Strong communication skills and a willingness to work with clients are essential. ",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Analytics",
            "Software Development",
            "Consulting"
        ],
        "soft_skills": [
            "Problem Solving",
            "Innovation",
            "Communication",
            "Teamwork",
            "Client Interaction"
        ],
        "hard_skills": [
            "Unix",
            "Angular",
            "Typescript",
            "Python",
            "Pandas",
            "Docker",
            "Bash",
            "Java",
            "Accumulo",
            "C",
            "Kubernetes",
            "Ceph",
            "CI/CD",
            "Jenkins",
            "GitLab CI",
            "Bamboo",
            "Ansible",
            "Puppet",
            "SaltStack",
            "Jira",
            "Confluence",
            "Bitbucket",
            "Scala",
            "Spark"
        ],
        "tech_stack": [
            "Angular",
            "Typescript",
            "Python",
            "Pandas",
            "Docker",
            "Bash",
            "Java",
            "Accumulo",
            "C",
            "Kubernetes",
            "Ceph",
            "Jenkins",
            "GitLab CI",
            "Bamboo",
            "Ansible",
            "Puppet",
            "SaltStack",
            "Jira",
            "Confluence",
            "Bitbucket",
            "Scala",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C",
            "Bash",
            "Typescript",
            "Scala"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Lanham, MD",
        "job_id": 3917178855,
        "company": "Science Systems and Applications, Inc (SSAI)",
        "title": "Earth Science Data Initiatives Data Workflows Software Engineer",
        "created_on": 1720587492.965547,
        "description": "Science Systems and Applications, Inc. (SSAI) is seeking a Software Engineer to support multiple interrelated Earth Science projects at NASA Goddard Space Flight Center. This person will be tasked with implementing, testing, documenting, and maintaining a variety of computational workflows, including (but not limited) to: Migration and transformation of NASA data products into analysis-ready, cloud-optimized formats Interactive visualization and analysis of NASA data products Generating new data products from a combination of NASA observations and models Numerical modeling and model-data fusion of physical, chemical, and ecological processes Application Programming Interfaces (APIs) for remote access and analysis of data products Required Qualifications B.S./B.A. degree or equivalent and two or more years of experience in software development or equivalent combination of education and experience Advanced knowledge of Python, R, Julia, or similar scripting languages Familiarity with the Unix/Linux command line Strong written and oral communication skills. Ability to communicate with software engineers and scientists. Strong organizational and time-management skills Flexibility, patience, and perseverance to overcome unexpected technical or organizational issues and sudden changes in expectations Desire and ability to learn quickly about both science topics and new and unfamiliar technologies Permanent Residency or US Citizenship required. Desired Qualifications Disciplinary knowledge in Earth science, environmental science, physics, chemistry, biology, or a related field. Reading, interpreting, and modifying code in Fortran and C/C++ Compiling and installing software from source using the GNU Build System and/or Cmake Configuring and managing Amazon Web Services (AWS), especially S3, EC2, and Lambda. Experience with using high-performance computing systems, including batch queuing systems (e.g., SLURM) and environment module systems Geographic Information Systems (GIS) concepts (e.g., projections, raster vs. vector data) and technologies, especially for scripted analysis and visualization (e.g., GDAL/OGR, OGC APIs) Creating and working with containerization (e.g., Docker, Singularity) and orchestration (e.g., Kubernetes, Docker Compose) software Version control using Git, especially in the context of open-source development and contribution workflows Remote sensing concepts and technology, especially as applied to Earth Sciences Statistics concepts and their practical applications Data science concepts and technologies, including data cleaning, advantages and disadvantages of different data formats and data models EOE, including disability/vets Physical Requirements: While performing the duties of this job, the employee is regularly required to stand, walk, and use hands to touch, handle or feel objects, tools or controls. The employee frequently is required to talk and hear and occasionally required to reach with hands and arms and stoop, kneel, crouch, or crawl. Must regularly lift and/or move up to 10 pounds, and occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision, peripheral vision, depth perception and the ability to adjust focus.",
        "url": "https://www.linkedin.com/jobs/view/3917178855",
        "summary": "SSAI is seeking a Software Engineer to work on Earth Science projects at NASA Goddard Space Flight Center. Responsibilities include data migration, visualization, analysis, data product generation, numerical modeling, API development, and maintaining computational workflows. Requires strong Python, R, Julia scripting skills and familiarity with Unix/Linux.",
        "industries": [
            "Aerospace",
            "Earth Science",
            "Software Development",
            "Research & Development"
        ],
        "soft_skills": [
            "Communication",
            "Organizational Skills",
            "Time Management",
            "Flexibility",
            "Patience",
            "Perseverance",
            "Learning",
            "Problem Solving"
        ],
        "hard_skills": [
            "Python",
            "R",
            "Julia",
            "Unix/Linux",
            "Fortran",
            "C/C++",
            "GNU Build System",
            "Cmake",
            "AWS",
            "S3",
            "EC2",
            "Lambda",
            "SLURM",
            "GIS",
            "GDAL/OGR",
            "OGC APIs",
            "Docker",
            "Singularity",
            "Kubernetes",
            "Docker Compose",
            "Git",
            "Remote Sensing",
            "Statistics",
            "Data Science",
            "Data Cleaning"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Julia",
            "Unix/Linux",
            "Fortran",
            "C/C++",
            "GNU Build System",
            "Cmake",
            "AWS",
            "S3",
            "EC2",
            "Lambda",
            "SLURM",
            "GIS",
            "GDAL/OGR",
            "OGC APIs",
            "Docker",
            "Singularity",
            "Kubernetes",
            "Docker Compose",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Julia",
            "Fortran",
            "C/C++"
        ],
        "experience": 2,
        "education": {
            "min_degree": "B.S./B.A.",
            "fields": [
                "Computer Science",
                "Software Engineering",
                "Earth Science",
                "Environmental Science",
                "Physics",
                "Chemistry",
                "Biology"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "EOE",
            "Disability/Vets"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Tysons Corner, VA",
        "job_id": 3959385671,
        "company": "Shepherd Search Group® Inc. - #845.290.1900 - info@shepherdsg.com",
        "title": "Software Engineer (On-site)",
        "created_on": 1720587493.905762,
        "description": "Our client is working on a platform that functions as a continuous reliability system that autonomously identifies issues within your software using a simulated environment. Each identified issue can be accurately reproduced, facilitating efficient debugging of even the most intricate problems. About the Engineering Position: Their team operates across diverse domains, developing proprietary tools with a small but versatile group of generalists. They seek individuals who excel in specific areas yet thrive on learning new technologies, adeptly tackling varied challenges. Key attributes they value include intelligence, effective execution, collaborative spirit, and comfort in navigating ambiguous problems. Technologies and languages integral to our work include: Extensive use of Nix for builds and infrastructure. C/C++ and Rust for kernel and systems programming. Typescript and JavaScript for frontend development, backed by Node.js. A comprehensive suite of SDKs supporting various other languages. The Team: Their team comprises individuals from diverse backgrounds, spanning conventional engineering disciplines to non-traditional paths such as philosophy or self-taught expertise. Despite varied backgrounds, all team members, including managers, are united by a commitment to high standards of engineering proficiency. They emphasize the value of in-person collaboration for fostering trust, sharing knowledge, and mentorship among colleagues.",
        "url": "https://www.linkedin.com/jobs/view/3959385671",
        "summary": "The client is building a continuous reliability system that autonomously identifies software issues using a simulated environment. The system reproduces identified issues for debugging. They are seeking a generalist engineer who is intelligent, collaborative, and comfortable with ambiguity. The work involves using Nix for builds and infrastructure, C/C++ and Rust for kernel/systems programming, Typescript and Javascript for frontend, Node.js, and SDKs for other languages.",
        "industries": [
            "Software Development",
            "DevOps",
            "Reliability Engineering",
            "Systems Programming"
        ],
        "soft_skills": [
            "Intelligence",
            "Effective Execution",
            "Collaboration",
            "Ambiguity Tolerance",
            "Learning"
        ],
        "hard_skills": [
            "Nix",
            "C",
            "C++",
            "Rust",
            "Typescript",
            "Javascript",
            "Node.js",
            "SDK Development"
        ],
        "tech_stack": [
            "Nix",
            "C",
            "C++",
            "Rust",
            "Typescript",
            "Javascript",
            "Node.js",
            "SDKs"
        ],
        "programming_languages": [
            "C",
            "C++",
            "Rust",
            "Typescript",
            "Javascript"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Arlington, VA",
        "job_id": 3956055256,
        "company": "Amazon Web Services (AWS)",
        "title": "Senior Generative AI Data Scientist, Amazon SageMaker",
        "created_on": 1720587495.6759708,
        "description": "Description Are you passionate about Generative AI (GenAI)? Do you want to help define the future of Go to Market (GTM) at AWS using generative AI? In this role, you will help some of our largest customers build and deploy GenAI enabled applications using Amazon SageMaker, fine tune and build Generative AI models, and help enterprise customers leverage these models to power end applications. You will engage with AWS product owners to influence product direction and help our customers tap into new markets by utilizing GenAI along with AWS Services. At Amazon, we’ve been investing deeply in artificial intelligence for over 20 years, and many of the capabilities customers experience in our products are driven by machine learning. Amazon.com’s recommendations engine is driven by machine learning (ML), as are the paths that optimize robotic picking routes in our fulfillment centers. Our supply chain, forecasting, and capacity planning are also informed by ML algorithms. Alexa is fueled by Natural Language Understanding and Automated Speech Recognition deep learning; as is Prime Air, and the computer vision technology in our new retail experience, Amazon Go. We have thousands of engineers at Amazon committed to machine learning and deep learning, and it’s a big part of our heritage. AWS is looking for a Generative AI Data Scientist, who will be the Subject Matter Expert (SME) for helping customers in designing solutions that leverage our Generative AI services. You will interact with customers directly to understand the business problem, help and aid them in implementation of generative AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths for generative AI. As part of the Generative AI Worldwide Specialist organization, you will work closely with other Data Scientists and Machine Learning Architects from various geographies to enable large-scale customer use cases and drive the adoption of Amazon Web Services for GenAI services. You will interact with other Data Scientists and Solution Architects in the field, providing guidance on their customer engagements. You will develop white papers, blogs, reference implementations, and presentations to enable customers and partners to fully leverage Generative AI services on Amazon Web Services. You will also create field enablement materials for the broader technical field population, to help them understand how to integrate AWS Generative AI solutions into customer architectures. You drive effective feedback gathering from customers, and you distill and translate that feedback into clear business and technical requirements for product and engineering teams to review. You must have deep technical experience working with technologies related to large language models including LLM architectures, model evaluation, adapters, pre-training and fine-tuning techniques. You should be proficient with design, deployment, and evaluation of LLM-powered agents and tools and orchestration approaches. You must have experience with embedding model fine tuning and retrieval method evaluation approaches. Candidates must have great communication skills and be very technical, with the ability to impress Amazon Web Services customers at any level, from executive to developer. Previous experience with Amazon Web Services is desired but not required, provided you have experience building large scale solutions. You will get the opportunity to work directly with senior ML engineers and Data Scientists at customers, partners and Amazon Web Services service teams, influencing their roadmaps and driving innovation. Key job responsibilities Customer Advisor- Implement, and deploy state of the art machine learning algorithms under Gen AI. You will build prototypes, PoCs, and explore new solutions. You will interact closely with our customers and with the academic community. Thought Leadership – Evangelize AWS GenAI services and share best practices through forums such as AWS blogs, white-papers, reference architectures and public-speaking events such as AWS Summit, AWS re:Invent, etc. Partner with Data Scientists, SAs, Sales, Business Development and the Generative AI Service teams to accelerate customer adoption and providing guidance on their customer engagements. Act as a technical liaison between customers and the AWS Generative AI services teams to provide customer driven product improvement feedback. Develop and support an AWS internal community of ML related subject matter experts worldwide. Create field enablement materials for the broader technical population, to help them understand how to integrate AWS GenAI solutions into customer architectures. We are open to hiring candidates to work out of one of the following locations: Arlington, VA, USA | Irvine, CA, USA | New York City, NY, USA | San Francisco, CA, USA | Santa Monica, CA, USA | Seattle, WA, USA Basic Qualifications Experience working as a Data Scientist Preferred Qualifications 10+ years of data scientist or similar role involving data extraction, analysis, statistical modeling and communication experience Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site. Company - Amazon Web Services, Inc. Job ID: A2678385",
        "url": "https://www.linkedin.com/jobs/view/3956055256",
        "summary": "AWS is seeking a Generative AI Data Scientist to help customers build and deploy GenAI applications using Amazon SageMaker, fine tune and build Generative AI models, and help enterprise customers leverage these models to power end applications. The ideal candidate will have deep technical experience working with technologies related to large language models (LLMs), including LLM architectures, model evaluation, adapters, pre-training and fine-tuning techniques. Excellent communication skills and the ability to work with customers at all levels are required.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Cloud Computing",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Customer Service",
            "Technical Leadership"
        ],
        "hard_skills": [
            "Generative AI",
            "Amazon SageMaker",
            "LLMs",
            "Fine-tuning",
            "Model Evaluation",
            "Model Deployment",
            "Pre-training",
            "Data Extraction",
            "Analysis",
            "Statistical Modeling",
            "Machine Learning",
            "Deep Learning"
        ],
        "tech_stack": [
            "Amazon SageMaker",
            "LLMs",
            "Pre-training",
            "Fine-tuning",
            "Model Evaluation"
        ],
        "programming_languages": [],
        "experience": 10,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 247600,
            "min": 143300
        },
        "benefits": [
            "Medical",
            "Financial",
            "Equity",
            "Sign-on Payments"
        ]
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Springfield, VA",
        "job_id": 3931499457,
        "company": "Red Gate Group",
        "title": "Application Developer",
        "created_on": 1720587497.264143,
        "description": "Company Description At RED GATE we do everything we can to serve our clients: Using the right technical skills, unique methodologies, best practices, and integrated technology, we help clients implement bold solutions. New approaches to emerging and evolving threats. Non-traditional ways to overcome entrenched obstacles. Advantage through opportunity. If you have a serious challenge or problem, we can help you solve it. The below job description provides details on how this role will help to serve our clients. Job Description The Red Gate Group is seeking an experienced Application Developer to support the NGA's FM Business Solutions Office (FMZ) in Springfield, VA. This role focuses on enhancing financial data processing, analysis, and management across the enterprise. You will lead teams, conduct analyses, and develop solutions using technologies such as Python, VBA, SQL, SQL Server, Microsoft Access, and Microsoft Excel. Responsibilities: Lead research teams to document requirements, business processes, and data challenges. Perform quantitative and qualitative analyses to link business processes with data solutions. Develop and implement advanced solutions for financial data management. Convert older programming languages to SQL Server and Python. Participate in system engineering and technical exchange meetings. Coordinate milestone events and validate system operational needs. Document and update processes, creating user manuals, desk guides, and standard operating procedures. Qualifications Required Skills & Experience Active TS/SCI Bachelors degree 15 years of experience 3 years demonstrated experience developing and implementing automated solutions to financial challenges using Python, VBA, SQL, SQL Server, Microsoft Access, and/or Microsoft Excel At least 3 years of demonstrated experience extracting technical requirements from business processes or other methods for configuration changes and system enhancements at least 3 years of demonstrated experience communicating both orally and in writing to a variety of audiences, ranging from inexperienced employees to senior executives Desired Skills & Experience 5 years of demonstrated experience with financial data and reports 3 years of demonstrated experience with Momentum-based system 3 years of demonstrated experience in developing reports in COGNOS reporting tool in the Intelligence Community 3 years of demonstrated experience with the United States Standard General Ledger (USSGL) Possess a Master's degree in a business or IT related field such as Business, Management, Economics, Accounting, Computer Science, MIS, etc. or demonstrate at least 10 years of hands - on experience 20 years of total experience Additional Information The Red Gate Group, Ltd. is an Equal Opportunity/Affirmative Action Employer. The Red Gate Group, Ltd. considers applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state, or local law. EEO is the Law",
        "url": "https://www.linkedin.com/jobs/view/3931499457",
        "summary": "Red Gate Group is seeking an experienced Application Developer to support the NGA's FM Business Solutions Office in Springfield, VA. This role focuses on enhancing financial data processing, analysis, and management across the enterprise. You will lead teams, conduct analyses, and develop solutions using technologies such as Python, VBA, SQL, SQL Server, Microsoft Access, and Microsoft Excel.",
        "industries": [
            "Information Technology",
            "Government",
            "Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Leadership",
            "Teamwork",
            "Problem Solving",
            "Analytical Skills"
        ],
        "hard_skills": [
            "Python",
            "VBA",
            "SQL",
            "SQL Server",
            "Microsoft Access",
            "Microsoft Excel",
            "Financial Data Analysis",
            "Report Development",
            "System Engineering",
            "Technical Requirements Gathering",
            "Data Management",
            "Business Process Analysis",
            "System Enhancement",
            "User Manual Creation",
            "Standard Operating Procedure Creation"
        ],
        "tech_stack": [
            "Python",
            "VBA",
            "SQL",
            "SQL Server",
            "Microsoft Access",
            "Microsoft Excel",
            "COGNOS",
            "Momentum"
        ],
        "programming_languages": [
            "Python",
            "VBA",
            "SQL"
        ],
        "experience": 15,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Business",
                "Management",
                "Economics",
                "Accounting",
                "Computer Science",
                "MIS"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "8eae39a77a8d43659709cf1fe8b1deb1",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3945827046,
        "company": "Motion Recruitment",
        "title": "Staff Applied Machine Learning Scientist (Python, TensorFlow, LLM)",
        "created_on": 1720587498.9976215,
        "description": "A renowned news and media outlet is looking for a Senior Data Scientist/General-AI Scientist. Located in Washington, DC, you will be implementing LLMs and Generative-AI to improve reader experiences. A technical understanding of Python, TensorFlow, PyTorch, Keras and AWS is needed. The goal is to answer reader’s questions by using past data from previous coverages. Looking for candidates that are at a principal-level in their career, tech-savvy working with various LLMS, and enjoys mentoring more junior staff. The position is full-time and hybrid. Required Skills & Experience Master’s in Computer Science, Statistics, or Mathematics 5+ years of Python, PyTorch, TensorFlow, and AWS 5+ years of Machine Learning and Data Mining algorithms Experience studying and working with various LLMs The Offer Competitive Salary Bonuses Full Health Benefits 401K w/ match You Will Receive The Following Benefits Medical Insurance Dental Benefits Vision Benefits Paid Time Off (PTO) 401(k) Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Posted By: Akibu Koroma",
        "url": "https://www.linkedin.com/jobs/view/3945827046",
        "summary": "A renowned news and media outlet is seeking a Senior Data Scientist/General-AI Scientist to implement LLMs and Generative-AI in Washington, DC. You will leverage past data to answer reader questions and enhance reader experiences. The ideal candidate will have a strong technical background in Python, TensorFlow, PyTorch, Keras, and AWS, and a proven track record of working with various LLMs. Experience mentoring junior staff is also valued. This full-time, hybrid position offers a competitive salary, bonuses, full health benefits, 401K with match, and additional benefits like medical, dental, vision, PTO, and 401(k).",
        "industries": [
            "Media",
            "News",
            "Journalism",
            "Data Science",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Mentoring",
            "Teamwork",
            "Problem Solving"
        ],
        "hard_skills": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "AWS",
            "Machine Learning",
            "Data Mining",
            "LLMs",
            "Generative AI"
        ],
        "tech_stack": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "AWS"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Bonuses",
            "Full Health Benefits",
            "401K w/ match",
            "Medical Insurance",
            "Dental Benefits",
            "Vision Benefits",
            "Paid Time Off (PTO)",
            "401(k)"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Providence, RI",
        "job_id": 3970715170,
        "company": "Team Remotely Inc",
        "title": "Junior Machine Learning Engineer",
        "created_on": 1720587500.5681322,
        "description": "This is a remote position. Junior Machine Learning Engineer (1 year experience, remote) Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum. Summary: As a Junior Machine Learning Engineer, you will have the opportunity to work on exciting projects, develop your skills, and contribute to the development and implementation of machine learning solutions. This is an excellent opportunity for individuals looking to kick-start their careers in the field of machine learning and gain valuable experience in a collaborative and supportive environment. Responsibilities: Collaborate with senior engineers and data scientists to understand project requirements and develop machine learning models and algorithms. Assist in collecting, preprocessing, and analyzing data to uncover patterns and insights. Implement and optimize machine learning models, algorithms, and pipelines. Participate in model evaluation, validation, and performance tuning. Contribute to the development and improvement of existing machine learning infrastructure and frameworks. Stay up-to-date with the latest advancements in machine learning and actively participate in knowledge-sharing activities within the team. Collaborate with cross-functional teams to integrate machine learning solutions into production systems. Document technical processes, methodologies, and outcomes effectively. Qualifications: Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, or a related field. Solid understanding of machine learning fundamentals, algorithms, and statistical concepts. Proficiency in programming languages such as Python, Java, or C++. Familiarity with machine learning frameworks and libraries, such as TensorFlow, PyTorch, or scikit-learn. Experience with data preprocessing, feature engineering, and model evaluation techniques. Knowledge of deep learning architectures and techniques is a plus. Familiarity with big data processing tools (e.g., Hadoop, Spark) is advantageous. Strong problem-solving skills and the ability to work on multiple projects simultaneously. Excellent communication and collaboration skills. Self-motivated with a strong desire to learn and grow in the field of machine learning.",
        "url": "https://www.linkedin.com/jobs/view/3970715170",
        "summary": "Junior Machine Learning Engineer role focusing on developing and implementing machine learning solutions. This entry-level position offers opportunities to learn, collaborate, and contribute in a supportive environment.",
        "industries": [
            "Computer Software",
            "Information Technology",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Self-motivation",
            "Learning"
        ],
        "hard_skills": [
            "Machine Learning",
            "Algorithms",
            "Statistical Concepts",
            "Python",
            "Java",
            "C++",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Data Preprocessing",
            "Feature Engineering",
            "Model Evaluation",
            "Deep Learning",
            "Hadoop",
            "Spark"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "Hadoop",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C++"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 67000,
            "min": 57000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3964835909,
        "company": "Carrot Fertility",
        "title": "Data Scientist",
        "created_on": 1720587504.5223594,
        "description": "About Carrot Carrot Fertility is the leading global fertility and family-building platform providing care for everyone, everywhere. Trusted by more than a thousand multinational employers, health plans, and health systems, Carrot's comprehensive clinical program delivers industry-leading cost savings for employers and award-winning experiences for millions of people worldwide. From maternity through menopause and pre-pregnancy through parenting, Carrot is dedicated to expanding access and improving outcomes. Carrot empowers members with compassionate, personalized, and inclusive support. The Role Carrot is seeking a Senior Data Scientist to join our rapidly growing Data team. This role involves designing and implementing advanced diagnostic, predictive, and prescriptive models, leading data analysis projects, and mentoring junior team members. Success in this role means developing robust data-driven solutions, ensuring data quality, and proactively collaborating with cross-functional teams while taking initiative to drive projects and tasks forward independently. This position is exciting as it offers the opportunity to work with extensive healthcare, financial, and product/platform data, applying advanced statistical methodologies and machine learning techniques to drive positive member outcomes. The primary goal is to strategically engage members to foster meaningful interactions, thereby driving impactful and measurable outcomes that align with and enhance Carrot’s value proposition. The Team The Data team sits within the Product Organization and is a highly cross-functional team that is central to Carrot’s long-term success. Led by the Senior Director, Analytics & Business Intelligence, this role is part of the Data Science function, which sits alongside our Data Engineering and Business Intelligence functions. The Data Science function primarily supports our Customer Success, Commercial Sales, and Strategy (Research/Outcomes) teams, producing data to support the sales team and leveraging work alongside the strategy team to provide data-driven insights for ongoing customers, effectively serving both prospective and existing customers with our value story end-to-end. Minimum Qualifications Master's degree in Data Science, Statistics, Computer Science, Health Informatics, Actuarial Science, Economics, or a related field. A Bachelor's degree with extensive relevant experience will also be considered. 5+ years of experience in data science or related roles, with a strong background in healthcare analytics. Advanced proficiency in SQL, Python, leveraging cloud-based data platforms (Snowflake, AWS, Azure) and machine learning frameworks, as well as statistical modeling techniques and tools like R or SAS. Familiarity with data science libraries and tools such as NumPy, pandas, and scikit-learn. Strong experience with data visualization tools (DOMO, Tableau, PowerBI, etc.). Excellent problem-solving and analytical skills, with the ability to independently conceive, implement, and drive projects and proactively address challenges. Demonstrated ability to thrive in a fast-paced, high-growth environment, balancing large-scale projects with ad-hoc requests and support tasks. Proven ability to interface with and communicate complex technical concepts to technical and non-technical audiences, including customers, consultants, senior leadership, and executives. Experience working with healthcare data, including medical and pharmacy claims, EHR/EMR, and clinical records. Clear understanding of coding standards and classifications (ICD, CPT, HCPCS, DRG, etc.) Understanding of healthcare regulations and standards, such as HIPAA, including de-identification methodologies and minimum sample size requirements for both de-identification and statistical significance testing. Preferred Qualifications Strong project management skills, including the ability to handle multiple large-scale projects simultaneously, develop project and data science initiatives roadmaps, and deliver high-quality documentation and training materials. Ability to manage commitments and deliverables, and align projects and tasks with strategic objectives. Demonstrated experience with dbt (data build tool) for data transformation and version control systems like Git, including developing and maintaining CI/CD pipelines to ensure robust and efficient data workflows. Experience with healthcare-specific data standards and interoperability frameworks (e.g., HL7, FHIR). Understanding of value-based care models and healthcare economics. Experience in identifying, extracting, and integrating data from diverse sources using advanced data extraction, OCR, NLP, and web scraping technologies, ensuring comprehensive and robust datasets for analysis. Experience in developing and implementing advanced predictive and prescriptive models using advanced machine learning techniques to solve healthcare problems. Experience leading AI-enabled initiatives, such as automating routine tasks, extracting insights from large datasets, and deploying AI models for business process improvements and solutions. Familiarity with Snowflake, leveraging its advanced AI/ML capabilities such as Snowflake's Data Science Workbench Cortex, and Snowpark to drive innovative data analytics and machine learning projects in healthcare. Familiarity with additional programming languages such as Java, Scala, or C++. Compensation Carrot offers a holistic Total Rewards package designed to support our employees in all aspects of their life inside and outside of work, including health and wellness benefits, retirement savings plans, short- and long-term incentives, parental leave, family-forming assistance, and a competitive compensation package. The expected base salary for this position will range from $140,000- $160,000. Actual compensation may vary from posted base salary depending on your confirmed job-related skills and experience. Why Carrot? Carrot has received national and international recognition for its pioneering work, including Best Diversity, Equity, & Inclusion Product from the Anthem Awards, Fast Company's Most Innovative Companies, CNBC's 100 Barrier Breaking Startups, and more. Carrot is regularly featured in media reporting on issues related to the future of work, women in leadership, healthcare innovation and diversity, equity, and inclusion, including MSNBC, The Economist, Bloomberg, The Wall Street Journal, CNBC, National Public Radio, Harvard Business Review, and more. Carrot teams span more than 40 states across the United States and dozens of countries around the world. Carrot has received numerous workplace awards, including Fortune's Best Workplaces in Healthcare, Quartz’s Best Companies for Remote Workers, and Great Place to Work and Age-Friendly Employer certifications. Learn more at carrotfertility.com.",
        "url": "https://www.linkedin.com/jobs/view/3964835909",
        "summary": "Carrot Fertility seeks a Senior Data Scientist to design and implement advanced data models, lead data analysis projects, and mentor junior team members. The role involves working with healthcare, financial, and product/platform data to drive positive member outcomes. The ideal candidate will have 5+ years of data science experience, strong healthcare analytics background, and advanced proficiency in SQL, Python, and cloud-based data platforms.",
        "industries": [
            "Healthcare",
            "Technology",
            "FinTech",
            "Data Science",
            "Analytics",
            "Fertility"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Communication",
            "Collaboration",
            "Project management",
            "Initiative",
            "Leadership",
            "Mentorship"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "Snowflake",
            "AWS",
            "Azure",
            "Machine Learning",
            "Statistical Modeling",
            "R",
            "SAS",
            "NumPy",
            "Pandas",
            "Scikit-learn",
            "Data Visualization",
            "DOMO",
            "Tableau",
            "PowerBI",
            "Git",
            "dbt",
            "HL7",
            "FHIR",
            "OCR",
            "NLP",
            "Web Scraping",
            "Java",
            "Scala",
            "C++"
        ],
        "tech_stack": [
            "Snowflake",
            "AWS",
            "Azure",
            "DOMO",
            "Tableau",
            "PowerBI",
            "dbt",
            "Git",
            "HL7",
            "FHIR"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R",
            "SAS",
            "Java",
            "Scala",
            "C++"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Statistics",
                "Computer Science",
                "Health Informatics",
                "Actuarial Science",
                "Economics"
            ]
        },
        "salary": {
            "max": 160000,
            "min": 140000
        },
        "benefits": [
            "Health and wellness benefits",
            "Retirement savings plans",
            "Short- and long-term incentives",
            "Parental leave",
            "Family-forming assistance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3962981337,
        "company": "Firstsource",
        "title": "Data Scientists",
        "created_on": 1720587506.0360339,
        "description": "Summarize the latest news articles by searching for recent news articles, summarizing key points, and instructing the model to generate a detailed response. You must be able to ensure the model accurately generates responses based on summaries. Qualifications Bachelor's degree or equivalent experience Expertise with content writing and research Java Script, Sequel and Python",
        "url": "https://www.linkedin.com/jobs/view/3962981337",
        "summary": "This job description seeks a content writer and researcher with expertise in JavaScript, SQL, and Python. A bachelor's degree or equivalent experience is required. ",
        "industries": [
            "Content Writing",
            "Research",
            "Technology"
        ],
        "soft_skills": [
            "Content Writing",
            "Research",
            "Expertise"
        ],
        "hard_skills": [
            "JavaScript",
            "SQL",
            "Python"
        ],
        "tech_stack": [
            "JavaScript",
            "SQL",
            "Python"
        ],
        "programming_languages": [
            "JavaScript",
            "SQL",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Baltimore, MD",
        "job_id": 3971512197,
        "company": "Donato Technologies, Inc.",
        "title": "Data Scientist",
        "created_on": 1720587507.553058,
        "description": "Data Scientist Baltimore, MD, On -site (HYBRID) Description Of Work Strong knowledge of R, Python, SAS, Gen AI and Machine Learning. Determine the nature of analytic problems, evaluate options, and offer recommendations for resolution; Advise on the methods and data needed and/or available to evaluate the (intelligence or data) problem; Collaborate with data collectors and analysts to identify and close gaps on complex monitoring problems; Provide accurate, timely, complex and sophisticated data analysis; Determine and employ the most appropriate research design for data collection and analysis; Analyze, evaluate, and assess quantitative data (using statistical software, computer models, geospatial models, software languages, and mathematical models) to contribute to or develop software tools, analytic models, or reports. All other duties as assigned or directed. Basic Qualifications: Minimum knowledge, skills, abilities needed. Bachelor degree in Statistics, Applied Mathematics, Computer Science, or Information Science Minimum 8 Year (s) of Data Scientist experience Expert-level experience working with real world data sets in predictive modelling using a scripting language such as Python, SAS and R. Knowledge of TensorFlow, PyTorch, scikit-learn, NLTK, Azure ML (optional), Amazon Web Services EC2. Expert knowledge in conducting data analysis and applying advanced statistical concepts and machine learning methods to build, train, test, and evaluate a variety of supervised and unsupervised analytic models. Ability to clean and process large amounts of real-world data. Experience retrieving and manipulating data from a variety of data sources included Db2, Oracle, SQL Server, Hadoop and flat files. Experience with database management systems, e.g., MySQL, SQLite, SQL, etc. Either experience with, or the ability and willingness to learn distributed processing via the Hadoop ecosystem, i.e., Spark, Impala and Hive. Excellent analytical skills to identify potential risks and propose effective solutions. Clear communication skills to convey complex technical concepts to various partners. Ability to collaborate with cross-functional teams. Providing problem solving skills, proven communication in written and verbal formats to various audiences to include executive leadership. Must be able to obtain and maintain a US Public Trust clearance. Preferred Qualifications: Candidates with these skills will be given preferential consideration. Prior experience with federal or state governments IT projects. Prior experience working on applications that help identify fraudulent activities (Anti-Fraud) in government or larger private organizations. Experience working in an analytical research environment. Experience with statistical and machine learning software such as pandas and scikit-learn. Experience in parallel processing such as GPU programming with CUDA Mathematica Experience using markup languages such as LaTeX, HTML, etc. Natural Language Processing for anomaly detection Selected candidate must Selected candidate must reside within two (2) hours of SSA Headquarters in Woodlawn, MD Selected candidate must be willing to work on-site at least 2 days a week..",
        "url": "https://www.linkedin.com/jobs/view/3971512197",
        "summary": "Data Scientist with 8+ years of experience is needed to analyze data, build and evaluate machine learning models, and provide insights to support the organization's data-driven decision making. The role requires expertise in Python, R, SAS, machine learning algorithms, and data manipulation techniques, with a focus on real-world data sets. Strong communication and collaboration skills are essential for working with cross-functional teams.  Preference is given to candidates with experience in federal government IT projects, fraud detection, and parallel processing.",
        "industries": [
            "Government",
            "Data Science",
            "Analytics",
            "Research",
            "Information Technology",
            "Machine Learning",
            "Anti-Fraud"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Decision Making"
        ],
        "hard_skills": [
            "R",
            "Python",
            "SAS",
            "Gen AI",
            "Machine Learning",
            "Predictive Modeling",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "NLTK",
            "Azure ML",
            "Amazon Web Services EC2",
            "Data Analysis",
            "Statistical Concepts",
            "Machine Learning Methods",
            "Data Cleaning",
            "Data Processing",
            "Db2",
            "Oracle",
            "SQL Server",
            "Hadoop",
            "Flat Files",
            "MySQL",
            "SQLite",
            "SQL",
            "Spark",
            "Impala",
            "Hive",
            "Pandas",
            "CUDA",
            "Mathematica",
            "LaTeX",
            "HTML",
            "Natural Language Processing",
            "Anomaly Detection"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SAS",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "NLTK",
            "Azure ML",
            "Amazon Web Services EC2",
            "Db2",
            "Oracle",
            "SQL Server",
            "Hadoop",
            "MySQL",
            "SQLite",
            "SQL",
            "Spark",
            "Impala",
            "Hive",
            "Pandas",
            "CUDA",
            "Mathematica",
            "LaTeX",
            "HTML"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SAS"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Statistics",
                "Applied Mathematics",
                "Computer Science",
                "Information Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Virginia Beach, VA",
        "job_id": 3969295411,
        "company": "CBC",
        "title": "AI/ML engineer, expert in python",
        "created_on": 1720587508.9533155,
        "description": "AI/ML engineer, expert in python. Client Sogeti Remote $60/hr OPTs are Fine, NO H1T Need candidate on AI/ML engineer, expert in python. Build robust machine learning pipelines to support production processes Implement online learning methods to optimize ML models in prospective pilot scenarios using approaches.such as Multi-Armed Bandits and Reinforcement Learning. Experience monitoring and evaluating performance of deployed AI/ML solutions. Experience with large language models (LLMs) & prompt engineering techniques, vector DB's Cloud BC Labs Inc is a digital transformation organization aimed at creating seamless solutions for clients to effectively manage their business operations. The company specializes in Business and Management Consulting, AI/ML, Data Analytics & Visualization, Cloud Data Warehouse Migration, Snowflake Implementation, Informatica Implementation & Upgrade, Staffing Services and Data Management Solutions",
        "url": "https://www.linkedin.com/jobs/view/3969295411",
        "summary": "Cloud BC Labs Inc. is seeking an AI/ML engineer with expertise in Python to develop robust machine learning pipelines for production processes. The role involves implementing online learning methods for model optimization, monitoring deployed AI/ML solutions, and experience with large language models (LLMs), prompt engineering, and vector databases.",
        "industries": [
            "Information Technology",
            "Consulting",
            "Data Analytics",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical skills",
            "Communication",
            "Collaboration",
            "Time management"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "AI",
            "ML Pipelines",
            "Online Learning",
            "Multi-Armed Bandits",
            "Reinforcement Learning",
            "Model Performance Monitoring",
            "Evaluation",
            "Large Language Models",
            "LLMs",
            "Prompt Engineering",
            "Vector Databases"
        ],
        "tech_stack": [
            "Python",
            "Machine Learning",
            "AI",
            "ML Pipelines",
            "Online Learning",
            "Multi-Armed Bandits",
            "Reinforcement Learning",
            "Model Performance Monitoring",
            "Evaluation",
            "Large Language Models",
            "LLMs",
            "Prompt Engineering",
            "Vector Databases"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Artificial Intelligence",
                "Engineering"
            ]
        },
        "salary": {
            "max": 60,
            "min": 60
        },
        "benefits": [
            "Remote work"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Chandler, AZ",
        "job_id": 3970927368,
        "company": "HireMeFast LLC",
        "title": "Junior Data Scientist",
        "created_on": 1720587510.6086762,
        "description": "This is a remote position. DISCLAIMER: This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $65,000 - $75,000 per annum Experience Required: Minimum 1 year of project experience Minimum Background And Qualifications Requirement Bachelor's degree or Master's degree in Computer Engineering, Computer Science, Mathematics, Electrical Engineering, Information Systems, or IT Must have Mathematics or Statistics background Required Technical and Soft Skills Required Experience in Python programming and understanding of the software development life cycle. Knowledge of Linear Algebra, Statistics, and Mathematics concepts. Excellent written and verbal communication skills. Highly motivated, self-learner, team player, and technically inquisitive. Strong work ethics and creative problem-solving abilities. Preferred Skills Deep Learning Data visualization NLP Scala Django Roles and Responsibilities Collaborate with dynamic teams of engineers, developers, and scientists who research and integrate algorithms to develop an application, software, and computer system solutions to address complex data problems. Assess project requirements and develop data analysis algorithms. Engage developers to share their opinions, knowledge, and recommendations to meet the deliverables. Contribute to technical solutions and implement software analyses to unlock the secrets held by big data sets. Integrate components like web-based UI, commercial indexing products, and access control mechanisms to create operational information and knowledge discovery systems. Benefits Competitive salary Flexible work schedule & part-time off E-verified No relocation H1B filing On job technical support Skill Enhancement Opportunity to work with Fortune 500 Companies",
        "url": "https://www.linkedin.com/jobs/view/3970927368",
        "summary": "This is a remote position for a data scientist with 1+ years of experience and a background in mathematics and statistics. The role involves developing data analysis algorithms, collaborating with engineering teams, and contributing to technical solutions for big data problems. The ideal candidate has experience with Python programming, linear algebra, and data visualization, and is skilled in communication and problem-solving. ",
        "industries": [
            "Data Science",
            "Software Development",
            "Information Technology",
            "Computer Science"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Self-Learning",
            "Motivation"
        ],
        "hard_skills": [
            "Python",
            "Linear Algebra",
            "Statistics",
            "Software Development Life Cycle",
            "Data Visualization",
            "Deep Learning",
            "NLP",
            "Scala",
            "Django"
        ],
        "tech_stack": [
            "Python",
            "Django",
            "Scala",
            "Deep Learning",
            "NLP"
        ],
        "programming_languages": [
            "Python",
            "Scala"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Engineering",
                "Computer Science",
                "Mathematics",
                "Electrical Engineering",
                "Information Systems",
                "IT"
            ]
        },
        "salary": {
            "max": 75000,
            "min": 65000
        },
        "benefits": [
            "Competitive salary",
            "Flexible work schedule",
            "Part-time off",
            "E-verified",
            "No relocation",
            "H1B filing",
            "On job technical support",
            "Skill Enhancement",
            "Opportunity to work with Fortune 500 Companies"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959938973,
        "company": "eddii",
        "title": "Data Scientist",
        "created_on": 1720587512.251738,
        "description": "Position Title: Data Scientist About eddii eddii is a cutting-edge digital health care delivery platform designed to deliver fun, support, and education to users living with diabetes and other cardiometabolic conditions. Our AI-enabled platform gamifies real-time glucose data, transforming diabetes management into an engaging experience. eddii acts as a smart virtual health buddy, providing witty conversations, health reports, and collectible in-app items. By humanizing the management of diabetes, eddii helps users take control of their health in an enjoyable and supportive way. Contact us: careers@eddiihealth.com Time Type: Part Time Travel Requirements: 0% Key Responsibilities: Data Analysis and Insight Generation: Analyze and derive insights from continuous glucose monitoring (CGM) data, and other relevant patient information (e.g., meal intake, insulin dosing). Develop predictive and prescriptive analytics to personalize diabetes management strategies for non-clinical users and clinical patients. Algorithm Development: Create and refine algorithms that personalize overall diabetes management strategies. Design machine learning models to predict and prescribe actions based on non-clinical and clinical data. Develop models that motivate and support non-clinical users and clinical patients in developing sustainable healthy habits. Behavioral Analytics: Analyze patient behavior data to identify patterns and trends that can inform the development of personalized motivational strategies. Use behavioral science principles to design interventions that encourage habit formation and adherence to diabetes management plans. Model Monitoring and Optimization: Monitor and optimize the performance of data models to enhance non-clinical user and clinical patient experience and healthcare outcomes. Use analytics such as average glucose levels, glucose standard deviation, and time in range to refine models. Data Integration and Utilization: Integrate various data sources, including standard claims processing system files and user generated data, to enhance predictive and prescriptive capabilities. Collaborate with engineering and product teams to ensure seamless data flow and utilization within the platform. Collaboration and Communication: Work closely with cross-functional teams, including product, engineering, and clinical teams, to align data science initiatives with business goals. Communicate complex data insights and model outcomes to non-technical stakeholders. Research and Innovation: Stay updated with the latest advancements in data science, machine learning, and healthcare analytics. Continuously explore new methodologies and technologies to improve the platform's capabilities. Regulatory and Compliance Adherence: Ensure that all data science activities comply with relevant healthcare regulations and standards. Maintain data privacy and security in accordance with industry best practices. Required Qualifications: Education: Bachelor's or higher degree in Statistics, Computer Science, Biomedical Engineering, or a related field. Experience: Minimum of 3 years of experience working in data science, preferably within the healthcare or telehealth industry. Proven experience working with real-time medical data, including CGM data. Skills: Strong understanding of machine learning algorithms and programming languages such as Python, Java, or R. Familiarity with big data platforms and tools (e.g., Hadoop, Spark). Excellent analytical and problem-solving skills with a passion for utilizing data to improve patient care. Ability to navigate a complex healthcare environment and understand the intricacies of diabetes management. Experience with behavioral analytics and designing interventions to promote habit formation. Preferred Qualifications: Advanced Education: Master's or Ph.D. degree in a related field. Certifications: Relevant data science or machine learning certifications (e.g., TensorFlow, AWS Machine Learning). Industry Knowledge: In-depth understanding of the digital health landscape and patient engagement strategies. Additional Skills: Experience with AI-driven healthcare solutions. Knowledge of regulatory requirements and standards in healthcare data management. Benefits: Be part of a fast-paced, innovative startup environment Work directly with the founding team and a broader community of advisors, investors, and partners Compensation will include competitive salary, equity, healthcare benefits, and PTO",
        "url": "https://www.linkedin.com/jobs/view/3959938973",
        "summary": "eddii, a digital healthcare platform focused on diabetes management, seeks a Data Scientist to analyze CGM data, develop predictive & prescriptive analytics, design ML models for personalized strategies, and optimize data models for improved user experience and healthcare outcomes. They'll also collaborate with cross-functional teams, stay updated on industry advancements, and ensure compliance with healthcare regulations.",
        "industries": [
            "Healthcare",
            "Digital Health",
            "Telehealth",
            "Diabetes Management",
            "Cardiometabolic Conditions"
        ],
        "soft_skills": [
            "Analytical",
            "Problem-Solving",
            "Communication",
            "Collaboration",
            "Passion for Patient Care",
            "Time Management",
            "Organization",
            "Adaptability"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "R",
            "Machine Learning",
            "Predictive Analytics",
            "Prescriptive Analytics",
            "Algorithm Development",
            "Big Data",
            "Hadoop",
            "Spark",
            "Continuous Glucose Monitoring (CGM) Data",
            "Behavioral Analytics",
            "Data Integration",
            "Data Visualization",
            "Model Monitoring",
            "Optimization",
            "Healthcare Regulations"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "R",
            "Hadoop",
            "Spark",
            "Machine Learning",
            "AI",
            "TensorFlow",
            "AWS Machine Learning"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "R"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Computer Science",
                "Biomedical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Equity",
            "Healthcare Benefits",
            "PTO",
            "Fast-Paced Environment",
            "Work with Founding Team",
            "Community of Advisors, Investors, and Partners"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Phoenix, AZ",
        "job_id": 3969083757,
        "company": "Conch Technologies, Inc",
        "title": "AI/ML Engineer Data Science",
        "created_on": 1720587513.678725,
        "description": "Hi, Greetings from Conch Technologies Inc ML / AI Engineer Duration: 12+ months contract Location: Phoenix, AZ ( From day 1 onsite ) Top Skill Sets Python App Dev Must have Machine Learning & Artificial Intelligence A minimum of 6+ years of experience has been a hard requirement; we need someone very senior to lead in a complex environment. _ Thanks and Regards, Chanakya [IT Recruiter] Direct : 214-247-7117 chanakya@conchtech.com linkedin.com/in/nameischanikya",
        "url": "https://www.linkedin.com/jobs/view/3969083757",
        "summary": "Conch Technologies Inc is seeking a senior ML/AI Engineer with at least 6 years of experience for a 12+ month contract in Phoenix, AZ.  This role requires strong Python App Dev skills and expertise in Machine Learning and Artificial Intelligence.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Leadership",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "tech_stack": [
            "Python App Dev",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Honolulu, HI",
        "job_id": 3970225457,
        "company": "Eminence Talent Group",
        "title": "Data Scientists",
        "created_on": 1720587515.1425571,
        "description": "Data Scientists (TS/SCI) Company Overview: Join a prestigious government organization dedicated to safeguarding national security and advancing technological innovation. The mission is to protect and enhance our nations capabilities through cutting-edge research, development, and implementation of advanced data science solutions. Role Overview: We are seeking highly skilled Data Scientists to join our clients' team in Hawaii. This position requires top-tier professionals with expertise in data analysis, machine learning, algorithm development, and data visualization. Candidates must hold a TS/SCI clearance and be passionate about leveraging data science to support intelligence operations. Responsibilities: Data Analysis: Perform advanced data analysis to extract meaningful insights from large datasets. Utilize statistical methods to identify trends, patterns, and anomalies. Machine Learning: Develop and implement machine learning models to support intelligence operations. Continuously improve models by incorporating new data and feedback. Algorithm Development: Create algorithms to automate data analysis and enhance efficiency. Develop scalable solutions to process and analyze large volumes of data. Data Visualization Use tools like Excel, Tableau, and Power BI to visualize data and present findings. Create interactive dashboards and reports to communicate results effectively Collaboration: Work with cross-functional teams to integrate data science solutions into broader intelligence efforts. Collaborate with other analysts to ensure comprehensive analysis and reporting. Reporting: Produce comprehensive reports on data findings and model performance. Document methodologies and provide actionable insights to stakeholders. Training And Mentorship: Provide training and mentorship to junior data scientists, sharing knowledge and best practices. Foster a collaborative and innovative team environment. Skills And Qualifications: Minimum of 10 years of experience in data science, with specific experience in Department of Defense (DoD) and US Navy data analysis and operations. Strong background in applied data science, including machine learning and artificial intelligence. Familiarity with creating models/algorithms for automating the analysis and evaluation of very large datasets. Proficiency in using advanced data analysis and visualization tools such as Excel, Tableau, and Power BI. Preferred Skills: Programming Languages: Proficiency in programming languages such as Python, R, or SQL. Data Visualization: Extensive experience with data visualization tools like Tableau or Power BI to present findings clearly. DoD And US Navy Experience: In-depth understanding of DoD and US Navy data requirements, protocols, and security measures. Machine Learning Frameworks: Experience with machine learning frameworks such as TensorFlow, Keras, or PyTorch. Big Data Technologies: Familiarity with big data technologies like Hadoop, Spark, or similar platforms. Communication Skills: Excellent written and verbal communication skills for producing detailed reports and presenting findings to stakeholders. Collaboration: Ability to work effectively in a team environment, collaborating with other analysts and intelligence professionals. Location: This position is based in Hawaii. On-site presence is required, and remote work is not an option. Salary Range: Master Level: $170,000 - $210,000 Senior Level: $140,000 - $170,000 Benefits: Opportunities for professional growth and development. Work with cutting-edge data science technologies. Comprehensive benefits package including health insurance, retirement plans, and paid time off. Join the team in making a significant impact on national security through advanced data science initiatives. Apply today to be part of a dynamic and innovative team.",
        "url": "https://www.linkedin.com/jobs/view/3970225457",
        "summary": "This role involves utilizing data science skills to support intelligence operations for a prestigious government organization in Hawaii. Responsibilities include advanced data analysis, machine learning model development, algorithm creation, and data visualization.  The ideal candidate will have at least 10 years of experience in data science, particularly within the Department of Defense (DoD) and US Navy. Strong technical skills in programming languages like Python, R, and SQL, along with data visualization tools like Tableau and Power BI are essential. Experience with big data technologies, machine learning frameworks, and DoD/US Navy data requirements are preferred. This on-site position offers a competitive salary, comprehensive benefits, and opportunities for professional growth.",
        "industries": [
            "Government",
            "Defense",
            "Intelligence",
            "National Security",
            "Technology",
            "Research & Development",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Teamwork",
            "Leadership",
            "Mentorship",
            "Presentation Skills",
            "Time Management",
            "Project Management"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "Algorithm Development",
            "Data Visualization",
            "Excel",
            "Tableau",
            "Power BI",
            "Python",
            "R",
            "SQL",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Hadoop",
            "Spark"
        ],
        "tech_stack": [
            "Excel",
            "Tableau",
            "Power BI",
            "Python",
            "R",
            "SQL",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Hadoop",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Master's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 210000,
            "min": 140000
        },
        "benefits": [
            "Health Insurance",
            "Retirement Plans",
            "Paid Time Off",
            "Professional Development",
            "Opportunity to Work with Cutting-Edge Technologies"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3971283021,
        "company": "Reddit, Inc.",
        "title": "Data Scientist",
        "created_on": 1720587519.1811793,
        "description": "Reddit is a community of communities. It’s built on shared interests, passion, and trust and is home to the most open and authentic conversations on the internet. Every day, Reddit users submit, vote, and comment on the topics they care most about. With 100,000+ active communities and approximately 82M+ daily active unique visitors, Reddit is one of the internet’s largest sources of information. For more information, visit redditinc.com . Location: US remote-friendly At Reddit we continue to grow our teams with the best talent and we're completely remote friendly. The Data Science Team at Reddit is growing and we are looking for experienced Data Scientists to partner with our cross-functional partners (Product, Engineering, Designer, Marketing, Business Development etc.) to help us build and improve the systems that continuously drive our user and revenue growth. As a Data Scientist on the team, you will have the opportunity to drive the success of Reddit’s core products by helping define the product strategy through identifying business opportunities and user pain points. You will also drive measurement and metrics design for a product area, along with experimentation and causal analyses to support product/engineering decisions and investments. A successful candidate will have a solid technical background, strong business acumen, and excellent cross-functional stakeholder management skills. You will go through a general Data Scientists hiring process and get matched to the product area that best fits your background and interest. Responsibilities Be actively involved in all phases of product development, including but not limited to, ideation, exploratory analysis, opportunity sizing, metrics design, offline modeling, experimentation and decision-making, post-launch monitoring/measurements etc. Leverage data to understand Reddit, its users, and potential product investments through experiment design and analysis, data deep dives, causal inference, and improving data accessibility for stakeholders (e.g. by creating ETLs, reporting dashboards and data aggregations needed for business tracking). Serve as a thought-partner for product managers, engineering managers and leadership from your respective product domain, communicating and shaping the roadmap and strategy for Reddit by identifying actionable and impactful insights through deep-dive analyses and analytics insights. Required Qualifications Relevant experiences in quantitative or data science roles, preferably for a consumer-facing service/app, ads monetization, safety etc. Ph.D., M.S. or Bachelors degree in Statistics, Machine Learning, Economics, Computer Science, or other quantitative fields (If M.S. or Bachelors degree, a minimum of 3+ years of industry data science experience required; If PhD degree, a minimum of 1+ years of industry data science experience required) Familiar with statistical analysis, programming languages (e.g., R / Python) and querying relational databases (e.g., SQL) Deep understanding of online experimentation and causal inference Comfortable in innovative and fast-paced environments, and an innate ability to bias toward action Strong technical communication and demonstrated ability to discuss complex topics with technical and non-technical audiences alike Able to tackle ambiguous and undefined problems Benefits Comprehensive Healthcare Benefits 401k Matching Workspace benefits for your home office Personal & Professional development funds Family Planning Support Flexible Vacation (please use them!) & Reddit Global Wellness Days 4+ months paid Parental Leave Paid Volunteer time off Pay Transparency This job posting may span more than one career level. In addition to base salary, this job is eligible to receive equity in the form of restricted stock units, and depending on the position offered, it may also be eligible to receive a commission. Additionally, Reddit offers a wide range of benefits to U.S.-based employees, including medical, dental, and vision insurance, 401(k) program with employer match, generous time off for vacation, and parental leave. To learn more, please visit https://www.redditinc.com/careers/ . To provide greater transparency to candidates, we share base pay ranges for all US-based job postings regardless of state. We set standard base pay ranges for all roles based on function, level, and country location, benchmarked against similar stage growth companies. Final offer amounts are determined by multiple factors including, skills, depth of work experience and relevant licenses/credentials, and may vary from the amounts listed below. The Base Pay Range For This Position Is $164,200—$229,900 USD Reddit is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please contact us at ApplicationAssistance@Reddit.com.",
        "url": "https://www.linkedin.com/jobs/view/3971283021",
        "summary": "Reddit is seeking experienced Data Scientists to join their growing team. The role involves partnering with cross-functional teams to improve user and revenue growth. Responsibilities include product development, data analysis, experimentation, and communication of insights. Ideal candidates have strong technical and business acumen, experience with online experimentation and causal inference, and the ability to handle ambiguous problems. ",
        "industries": [
            "Technology",
            "Social Media",
            "Internet",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Decision Making",
            "Stakeholder Management",
            "Time Management",
            "Action-Oriented",
            "Analytical",
            "Ambiguity Tolerance"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "R",
            "Machine Learning",
            "Statistical Analysis",
            "Causal Inference",
            "Experiment Design",
            "Data Deep Dives",
            "ETL",
            "Dashboards",
            "Data Aggregation"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "R",
            "Machine Learning"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Machine Learning",
                "Economics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 229900,
            "min": 164200
        },
        "benefits": [
            "Comprehensive Healthcare",
            "401k Matching",
            "Workspace Benefits",
            "Personal & Professional Development Funds",
            "Family Planning Support",
            "Flexible Vacation",
            "Reddit Global Wellness Days",
            "Parental Leave",
            "Paid Volunteer Time Off",
            "Pay Transparency",
            "Equity",
            "Commission",
            "Medical",
            "Dental",
            "Vision",
            "401k Program with Employer Match",
            "Vacation"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Redmond, WA",
        "job_id": 3959643267,
        "company": "Microsoft",
        "title": "Data Scientist",
        "created_on": 1720587520.9543936,
        "description": "Would you like to bring your data science skills to work on some of the most impactful problems at Microsoft? The Office of the Chief Economist drives value for Microsoft and its customers by providing insights into some of the most important questions at Microsoft, from the ways that AI will change the way that people work to understanding how efficient pricing can help grow Microsoft’s cloud revenue. The Office of the Chief Economist seeks a Data Scientist with deep knowledge of machine learning and research methodologies, including power analysis, experimental design, hypothesis testing, and inference. As a Data Scientist, you will use your expertise in data science, machine learning, and artificial intelligence to drive insights that help Microsoft grow its business through more efficient pricing and decision making. You will work with business partners to identify areas of the business that can help them drive value, identify data sources and appropriate technique that can deliver critical insights for decision makers, and then develop and execute each step in the analysis work, from data wrangling, quality control and data sleuthing, to producing summary statistics and using statistical and machine learning to deliver statistically sound causal insights to business leaders. Our team values collaboration, craftsmanship, and continuous learning. As a member of the team, you will be able to shape and grow a positive and productive data engineering culture. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Develop a deep understanding of modern and legacy data systems and build data pipelines that enable experimentation and data analysis at scale. Understand business needs and develop appropriate data analyses plans to meet those needs ranging from exploratory data analysis, inference and experimentation. Sleuth data quality issues that threaten to undermine econometrically sound analysis by identifying clear data requirements and ensuring that analytic datasets meet those rigorous requirements. Execute analysis plans ranging from classical statistics to modern machine learning and econometric inference. Embody our Culture and Values Qualifications Required/Minimum Qualifications Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) or consulting experience OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 2+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) OR equivalent experience. Deep knowledge of at least one modern statistical programming language, such as R or Python Experience with data query languages such as SQL and management platforms such as SQL Server or Cosmos Additional Or Preferred Qualifications Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) OR equivalent experience. Experience with Exploratory Data Analyses, Inference analysis, Predictive analysis (Regression, Classification etc.,) and forecasting. Experience with Experiment Design and analysis. Demonstrated leadership in complex areas, through critical thinking, thought leadership, technical skills and relentless drive for progress. Data Science IC3 - The typical base pay range for this role across the U.S. is USD $98,300 - $193,200 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $127,200 - $208,800 per year. Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay Microsoft will accept applications and processes offers for these roles on an ongoing basis. Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
        "url": "https://www.linkedin.com/jobs/view/3959643267",
        "summary": "Microsoft's Office of the Chief Economist is seeking a Data Scientist to drive insights for business growth through pricing and decision-making. Responsibilities include developing data pipelines, conducting analyses ranging from exploratory to inferential and predictive, and ensuring data quality for econometrically sound results. The role involves collaborating with business partners, identifying data sources and techniques, and delivering actionable insights to leaders.",
        "industries": [
            "Technology",
            "Data Science",
            "Economics",
            "Business Intelligence",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Critical Thinking",
            "Problem Solving",
            "Data Analysis",
            "Decision Making",
            "Leadership",
            "Analytical Skills",
            "Data Interpretation",
            "Statistical Reasoning",
            "Business Acumen",
            "Project Management"
        ],
        "hard_skills": [
            "Machine Learning",
            "Artificial Intelligence",
            "Data Wrangling",
            "Data Quality Control",
            "Statistical Analysis",
            "Econometrics",
            "Causal Inference",
            "Data Pipelines",
            "Exploratory Data Analysis",
            "Inferential Analysis",
            "Predictive Analysis",
            "Regression",
            "Classification",
            "Forecasting",
            "Experiment Design",
            "SQL",
            "Python",
            "R"
        ],
        "tech_stack": [
            "SQL Server",
            "Cosmos",
            "R",
            "Python",
            "Azure"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Mathematics",
                "Statistics",
                "Econometrics",
                "Economics",
                "Operations Research",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 208800,
            "min": 127200
        },
        "benefits": [
            "Compensation",
            "Benefits"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Redmond, WA",
        "job_id": 3933004023,
        "company": "Microsoft",
        "title": "Data Scientist",
        "created_on": 1720587522.443633,
        "description": "The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services. The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other. As a Data Scientist in the team, you will work closely with our software engineers, program managers, and data engineers across different teams within Azure. You will leverage statistical techniques to analyze data, find patterns and apply visualization techniques to drive business insights that lead to action and successful business outcomes. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities You will help with initial data collection and understand which analysis techniques are appropriate and which tools are necessary for data exploration. You’ll also develop a foundational understanding of methodology and standard statistical options so that you can analyze and organize data as required. You will understand modeling techniques used within the team, then run model tools on prepared data sets. You’ll also analyze model performance and incorporate customer feedback into its evaluation. You will understand the current state of the industry, including current trends, so that you can contribute to thought leadership best practices. You’ll also write code for a specific feature or model and develop an understanding of proper debugging techniques. You will understand each customer’s business goals and learn best practices for identifying growth opportunities. You’ll also examine projects through a customer-oriented focus and manage customer expectations regarding project progress. You will develop Data insights, analysis, recommendations generation gaining deeper domain knowledge. You will integrate analytics intelligence, ML capabilities into the Azure platform. You will collaborate with Microsoft Researchers on strategic projects as applicable. Other: Embody our Culture and Values. Qualifications Required Qualifications: Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field. OR equivalent experience. 1+ year experience with python or R. Other Requirements Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. Additional / Preferred Qualifcations Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, OR related field. OR related field AND 1+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results). OR equivalent experience. OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science. Data Science IC2 - The typical base pay range for this role across the U.S. is USD $81,900 - $160,200 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $105,600 - $174,600 per year. Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay Microsoft will accept applications for the role until Aug 31, 2024. #Azurecorejobs Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
        "url": "https://www.linkedin.com/jobs/view/3933004023",
        "summary": "Data Scientist at Microsoft's Azure Compute Capacity and Efficiency (AC2E) team. Analyze data to improve capacity management, optimize cost efficiency, and enhance customer satisfaction. Leverage statistical techniques, data visualization, and modeling to drive business insights and contribute to platform improvements.",
        "industries": [
            "Cloud Computing",
            "Software",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Data Analysis",
            "Data Visualization",
            "Statistical Modeling",
            "Customer Focus",
            "Growth Mindset",
            "Teamwork",
            "Thought Leadership",
            "Problem-solving",
            "Customer-oriented"
        ],
        "hard_skills": [
            "Python",
            "R",
            "Statistical Techniques",
            "Data Analysis",
            "Modeling Techniques",
            "Data Exploration",
            "Data Organization",
            "Data Preparation",
            "Model Performance Analysis",
            "Customer Feedback Incorporation",
            "Code Development",
            "Debugging",
            "Data Insights",
            "Analytics Intelligence",
            "ML Capabilities",
            "Azure Platform",
            "Microsoft Research Collaboration",
            "SQL",
            "Data Warehousing",
            "Data Mining",
            "Machine Learning"
        ],
        "tech_stack": [
            "Azure",
            "Azure Platform",
            "Azure Services",
            "Data Science",
            "Machine Learning",
            "Analytics Intelligence",
            "Statistical Modeling",
            "Data Visualization",
            "Python",
            "R",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Mathematics",
                "Statistics",
                "Econometrics",
                "Economics",
                "Operations Research",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 160200,
            "min": 81900
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Columbus, Ohio Metropolitan Area",
        "job_id": 3960350170,
        "company": "Agility Partners",
        "title": "Data Scientist",
        "created_on": 1720587525.623015,
        "description": "*unable to do C2C *must be local to Columbus, OH and willing to work onsite 3 days per week Agility Partners is seeking qualified applicants to fill an open Data Scientist position with one of our Banking clients. In this dynamic role you will dive into their Fraud, Physical Security and Disputes data. You will also enable stakeholders with actionable, intuitive insights that provides the business with decision making capabilities. Responsibilities Synthesize data from our analytics tools into actionable insights. Clearly communicate these recommendations to internal stakeholders and senior leadership. Ability to quickly grasp complex technical concepts and make them easily understandable through various communication mediums like visualizations and presentations. Extract and analyze data using analytics tools such as Python, R, and/or SAS. Create compelling, intuitive dashboards to enable the business with critical metrics, with a focus on data automation, anomaly detection, and actionable data visualizations. Apply visualization techniques to internal and external data sources to make accurate and actionable analyses in a timely fashion. Create self-service dashboards for internal business partners to learn, understand, have access to, and derive insights from data, metrics, and KPIs. Apply automation techniques to manual processes to create efficiency, improve accuracy, and build upon successes that create a suite of self-service assets. Qualifications Master's degree in Computer Science or Information Systems, Decision Sciences, Statistics, Operations Research, Applied Mathematics, Engineering, or a STEM degree; Extensive experience with programming languages R or Python Direct experience with SQL programming and large database applications such as Oracle, DB2, SQL Server, SPSS, Teradata, and Hadoop Developing and applying statistical or machine learning methods in a corporate environment through applications such as R, Python, or SAS Business intelligence and data mining experience with Tableau Server Creative thinker and problem solver, with a strong ability to manage ambiguity/complexity Work effectively in teams as well as independently across multiple tasks while meeting aggressive timelines Experience in banking or financial services is a plus",
        "url": "https://www.linkedin.com/jobs/view/3960350170",
        "summary": "Agility Partners seeks a Data Scientist to analyze Fraud, Physical Security, and Disputes data for a banking client in Columbus, OH. The role involves data synthesis, communication of insights, dashboard creation, and automation.",
        "industries": [
            "Banking",
            "Finance"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Ambiguity Management",
            "Teamwork",
            "Independent Work"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SAS",
            "SQL",
            "Oracle",
            "DB2",
            "SQL Server",
            "SPSS",
            "Teradata",
            "Hadoop",
            "Tableau",
            "Data Visualization",
            "Data Automation",
            "Anomaly Detection",
            "Statistical Modeling",
            "Machine Learning",
            "Business Intelligence",
            "Data Mining"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SAS",
            "SQL",
            "Oracle",
            "DB2",
            "SQL Server",
            "SPSS",
            "Teradata",
            "Hadoop",
            "Tableau"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SAS",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Information Systems",
                "Decision Sciences",
                "Statistics",
                "Operations Research",
                "Applied Mathematics",
                "Engineering",
                "STEM"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3971351291,
        "company": "Novapulse AI",
        "title": "AI/ML Developer",
        "created_on": 1720587527.346154,
        "description": "We are seeking a talented AI/ML Developer to join our innovative team. The ideal candidate will have strong expertise in machine learning algorithms, data preprocessing, model development, fine-tuning large language models (LLMs), and working with big data. You will work on creating, deploying, and optimizing AI models to solve real-world problems and enhance our products. Responsibilities: Design and develop machine learning models Preprocess and analyze large datasets Implement and optimize algorithms for performance and scalability Fine-tune large language models (LLMs) for specific applications Manage and analyze big data to derive insights and improve models Collaborate with cross-functional teams to integrate AI solutions Stay up-to-date with the latest advancements in AI and ML technologies Requirements Requirements: 5+ years of experience in working with AI/LLMs, or any similar relevant field Bachelor's or Master's degree in Computer Science, Data Science, or a related field Proficiency in Python and ML frameworks such as TensorFlow, PyTorch, or scikit-learn Experience with data preprocessing and feature engineering Strong understanding of machine learning algorithms and techniques Proven experience in fine-tuning large language models Experience with big data tools and technologies (e.g., Hadoop, Spark) Excellent problem-solving and analytical skills Benefits What we offer: Competitive salary that reflects your skills, experience, and contributions to the company Flexible working hours and remote work options to support your personal and professional life Full reimbursement for business-related travel expenses for group meet-ups Individual benefits and bonuses. Join us to work on cutting-edge AI projects and make a significant impact in a dynamic and collaborative environment!",
        "url": "https://www.linkedin.com/jobs/view/3971351291",
        "summary": "We are looking for an AI/ML Developer with 5+ years of experience in machine learning, data preprocessing, model development, fine-tuning large language models (LLMs), and big data. You'll be responsible for designing and developing AI models, analyzing large datasets, optimizing algorithms, and collaborating with teams to integrate AI solutions.  This role offers competitive salary, flexible working hours, remote work options, travel reimbursement, and individual benefits.",
        "industries": [
            "Artificial Intelligence",
            "Machine Learning",
            "Software Development",
            "Data Science",
            "Technology"
        ],
        "soft_skills": [
            "Problem Solving",
            "Analytical Skills",
            "Collaboration",
            "Communication"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Preprocessing",
            "Model Development",
            "Fine-tuning LLMs",
            "Big Data",
            "Python",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "Data Preprocessing",
            "Feature Engineering",
            "Hadoop",
            "Spark"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "Hadoop",
            "Spark"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Flexible Working Hours",
            "Remote Work Options",
            "Travel Reimbursement",
            "Individual Benefits and Bonuses"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Columbus, Ohio Metropolitan Area",
        "job_id": 3964776084,
        "company": "Agility Partners",
        "title": "Data Scientist",
        "created_on": 1720587528.8559713,
        "description": "About this Role Agility Partners is seeking a qualified Senior Data Scientist to fill an open position with one of our banking clients. As a Senior Data Scientist you will join a dynamic team and you will leverage machine learning, segmentation, and statistical inference on huge data sets to improve how we understand our customers and the communities we serve. Responsibilities: Performs advanced analytics methods to extract value from business data Performs large-scale experimentation and build data-driven models to answer business questions Conducts research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence Determines requirements that will be used to train and evolve deep learning models and algorithms Articulates a vision and roadmap for the exploitation of data as a valued corporate asset Influences product teams through presentation of data-based recommendations Evangelizes best practices to analytics and products teams Owns the entire model development process, from identifying the business requirements, data sourcing, model fitting, presenting results, and production scoring Benefits and Perks Reasons to Love It: This is a great opportunity to work for a mid-sized financial institution that is striving to be the bank of choice; one that focuses on its customers, not its competition. An organization that provides a dynamic, fulfilling work environment that is productive, collaborative and innovative. Highly visible team with a regional financial services company where your work matters and your accomplishments are recognized! Amazing opportunity for growth, healthy work/life balance and a community focused environment Working for an organization that focuses on company culture, inclusion and diversity On a team whose Core values that include: Can-Do Attitude, Service at Heart and Forward Thinking 50% medical coverage for you and your entire family, short/long term disability and life insurance options 401(k) Life Insurance Disability coverage The Ideal Candidate Qualifications: Up-to-date knowledge of machine learning and data analytics tools and techniques Strong knowledge in predictive modeling methodology Experienced at leveraging both structured and unstructured data sources Willingness and ability to learn new technologies on the job Demonstrated ability to communicate complex results to technical and non-technical audiences Demonstrated ability to work effectively in teams as well as independently across multiple tasks while meeting aggressive timelines Strategic, intellectually curious thinker with focus on outcomes Professional image with the ability to form relationships across functions Strong experience with R/RStudio, Python, SAS, SQL, NoSQL Strong experience with Cloud Machine Learning technologies (e.g., AWS Sagemaker) Strong experience with machine learning environments (e.g., TensorFlow, scikit-learn, caret) Strong understanding of statistical methods and skills such as Bayesian Networks Inference, linear and non-linear regression, hierarchical, mixed models/multi-level modeling Financial Services background preferred",
        "url": "https://www.linkedin.com/jobs/view/3964776084",
        "summary": "Agility Partners is seeking a Senior Data Scientist to join a banking client. The role involves leveraging machine learning, segmentation, and statistical inference on large datasets to understand customers and improve services. Responsibilities include conducting advanced analytics, building data-driven models, researching cutting-edge techniques, and influencing product teams with data-based recommendations. Ideal candidates possess strong knowledge of machine learning and data analytics tools, experience with structured and unstructured data, and proficiency in R/RStudio, Python, SAS, SQL, NoSQL, Cloud Machine Learning technologies (AWS Sagemaker), machine learning environments (TensorFlow, scikit-learn, caret), and statistical methods like Bayesian Networks Inference, linear and non-linear regression, and hierarchical modeling. Financial Services background is preferred.",
        "industries": [
            "Banking",
            "Finance",
            "Financial Services"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Teamwork",
            "Time Management",
            "Strategic Thinking",
            "Intellectual Curiosity",
            "Relationship Building"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Analytics",
            "Predictive Modeling",
            "Structured Data",
            "Unstructured Data",
            "R",
            "RStudio",
            "Python",
            "SAS",
            "SQL",
            "NoSQL",
            "AWS Sagemaker",
            "TensorFlow",
            "Scikit-learn",
            "Caret",
            "Bayesian Networks Inference",
            "Linear Regression",
            "Non-Linear Regression",
            "Hierarchical Modeling",
            "Multi-level Modeling"
        ],
        "tech_stack": [
            "AWS Sagemaker",
            "TensorFlow",
            "Scikit-learn",
            "Caret",
            "R",
            "RStudio",
            "Python",
            "SAS",
            "SQL",
            "NoSQL"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SAS",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "50% Medical Coverage",
            "Short/Long Term Disability",
            "Life Insurance",
            "401(k)",
            "Disability Coverage"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Miami, FL",
        "job_id": 3960509334,
        "company": "Royal Caribbean Group",
        "title": "Data Scientist",
        "created_on": 1720587534.6945925,
        "description": "Journey with us! Combine your career goals and sense of adventure by joining our exciting team of employees. Royal Caribbean Group is pleased to offer a competitive compensation and benefits package, and excellent career development opportunities, each offering unique ways to explore the world. The Royal Caribbean Group’s Data Analytics and AI team has an exciting career opportunity for a full time Data Scientist reporting to the Data Science Manager. This position will work on-site in Miami, Florida. Position Summary: Royal Caribbean is seeking a seasoned, experienced, and inquisitive Data Scientist that will lead our Research & Development initiatives and assimilate new, cutting-edge technologies into our broader Artificial Intelligence and Machine Learning capabilities. The position demands an inquisitive individual who can direct a team of other data scientists and machine learning professionals to deliver. This Data Scientist will focus on architecting, deploying and evaluating the feasibility of emerging technologies within the fields of Data Science, Artificial Intelligence and Machine Learning. They are expected to work independently and in collaboration with other Data Scientists to explore new capabilities that will continue to keep Royal Caribbean Cruise Lines ahead of its competitors in this space. While research oriented, the success of role will be dependent on the tangible value their efforts and the efforts of the Data Science team will add. Essential Duties and Responsibilities: A successful candidate will possess a strong background, either professionally or academically, in statistics, mathematics, artificial intelligence, research methods, experiment design, developing novel solutions beyond the use of well-established methods, and taking new technologies to a prototype state that can be expanded into a robust product. The candidate should demonstrate a progressive maturation of prior research projects, publications, patents or similar capabilities in the field of applied research. This individual will be responsible for scripting / programming, mentorship, stakeholder presentation, collaboration with other team members to execute a research experiment within the framework of implementing, utilizing and expanding R&D capabilities within the broader Data Science team. Major responsibilities include: Research and apply emerging forms of statistical, machine learning (neural networks / deep networks, ensemble methods, natural language processing, computer vision) and engineering methods to Royal Caribbean Cruise Lines, data science and AI ecosystem. Must be comfortable doing so with little or not documentation or reliance on research articles and papers. Evaluate the progress of Data Scientists, the AI & Robotics team, and company at large on the acclimation of research methods towards the rapid delivery of experimental technologies to a prototype state. Execute these objectives with respect to both purely exploratory endeavors as well as established products requiring novel ingenuity to meet known stakeholder objectives. Manipulates high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships, and trends. Empower and enhance the capabilities of Data Scientists and the AI & Robotics team as whole to properly design R&D explorations, rapidly experiment with, prototype, and demonstrate the viability of in-house research. Collaborate with Digital, IT, Business stakeholders to design and implement R&D prototypes into broader automated systems and establish a Minimum Viable Product. Assist with research related to customer based analytical practice and develop communications for management and strategies for building institutional knowledge. Work with product and enterprise teams via both Agile And Waterfall Methodologies. Foster a `data-driven culture based on pragmatism and strategic decision through rigorous factual analysis at all levels. Should be willing to engage outside the immediate team to expand data science footprint throughout organization. Qualifications: Master’s degree required in Statistics, Operations Research, Mathematics, Economics, Computer Science, Engineering, Physics, Chemical Engineering or field of comparable foundations in mathematical and statistical analysis through the use of models, algorithms or programmed solutions. 5+ years of experience with any of the following programming languages: R, Python, Java, C++, C#, Scala, SAS, MATLAB or similar scripting languages. Similar experience and proficiency with SQL required. 5+ years of experience across a breadth of data science, AI and machine learning disciplines including, but not limited to: forecasting, natural language processing (topic modeling, semantic search, text classification), deep learning and GPU-based algorithms (CNN, LSTM), computer vision 5+ years designing experiments and researching novel solutions beyond established literature or documentation. Experience with data mining processes (SEMMA, CRISP-DM), data preparation, consolidation, imputation, transformation, interaction, variable reduction, modeling, maintenance, and post-mortem analysis. Experience with statistical methods such t-test of means, Tukey-HSD tests of means on groups, ANOVA, Proportion tests, data normalization and scaling, univariate and multivariate outlier detection. Experience with modeling techniques such as linear models, decision trees, neural networks, k-nearest-neighbor, support vector machines, cluster analyses, and ensembling methods. Strong Oral and Written skills. Additional Preferred Qualifications: Ph.D. degree in a quantitative field preferred but will also consider candidates that are currently enrolled in a Ph.D. program. Experience with Agile Software Development Experience in a large corporation or consulting firm with focus in marketing strategies, modeling, CRM and management sciences/statistics highly desired. Experience with Deep Learning tools and packages such as TensorFlow, Keras, H2O, and Theano Experience with frameworks and languages designed for big-data analysis, including Hadoop, Spark, Hive, and Pig Experience with cloud computing frameworks or API¿s such as Microsoft Azure, Amazon Web Services and IBM / Watson Must have published articles in a peer-reviewed scientific or academic journal, or filed patents in the fields of data science, artificial intelligence or machine learning. Knowledge and Skills: Must have a strong background in one or more of the following: Mathematical, Statistics, Probability, Deep Learning, Machine Learning, Natural Language Processing, Computer Vision, Recommendation Systems, Pattern Recognition, Large Scale Data Mining or Artificial Intelligence. Demonstrates a strong capacity for learning and assimilating new techniques, tools and methods. Comfortable with preparing or collaborating on presentation decks as well as delivering final stakeholder presentations as primary or supporting presenter. Has knowledge and can quickly ramp-up and leverage cloud-based cognitive service APIs such as Microsoft Azure, AWS and/or IBM Watson. Is passionate about your work, but willing to support several projects at one time and can accept reprioritization as necessary. Comfortable delivering within an agile program. We know there's a lot to consider. As you go through the application process, our recruiters will be glad to provide guidance, and more relevant details to answer any additional questions. Thank you again for your interest in Royal Caribbean Group. We'll hope to see you onboard soon! It is the policy of the Company to ensure equal employment and promotion opportunity to qualified candidates without discrimination or harassment on the basis of race, color, religion, sex, age, national origin, disability, sexual orientation, sexuality, gender identity or expression, marital status, or any other characteristic protected by law. Royal Caribbean Group and each of its subsidiaries prohibit and will not tolerate discrimination or harassment. #LI-MP1 Nearest Major Market: Miami",
        "url": "https://www.linkedin.com/jobs/view/3960509334",
        "summary": "Royal Caribbean Group is seeking a seasoned Data Scientist to lead Research & Development initiatives, integrate cutting-edge technologies into AI and Machine Learning capabilities, and guide a team of data scientists and machine learning professionals. The ideal candidate will possess expertise in statistics, mathematics, AI, research methods, experiment design, and translating novel solutions into prototypes for robust product development. Responsibilities include research and application of emerging statistical, machine learning, and engineering methods, evaluation of research progress, collaboration with stakeholders, data manipulation, and fostering a data-driven culture. The role requires a Master's degree in a quantitative field, 5+ years of experience in programming languages (R, Python, Java, C++, C#, Scala, SAS, MATLAB), and extensive knowledge in data science, AI, and machine learning disciplines.",
        "industries": [
            "Travel & Tourism",
            "Hospitality",
            "Data Science",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Inquisitive",
            "Team leadership",
            "Collaboration",
            "Communication",
            "Presentation skills",
            "Problem-solving",
            "Analytical",
            "Strategic thinking",
            "Passionate",
            "Agile",
            "Adaptable",
            "Pragmatic",
            "Data-driven",
            "Mentorship",
            "Innovation",
            "Research",
            "Communication",
            "Leadership"
        ],
        "hard_skills": [
            "Statistics",
            "Mathematics",
            "Artificial Intelligence",
            "Research Methods",
            "Experiment Design",
            "Programming",
            "R",
            "Python",
            "Java",
            "C++",
            "C#",
            "Scala",
            "SAS",
            "MATLAB",
            "SQL",
            "Forecasting",
            "Natural Language Processing",
            "Topic Modeling",
            "Semantic Search",
            "Text Classification",
            "Deep Learning",
            "GPU-based Algorithms",
            "CNN",
            "LSTM",
            "Computer Vision",
            "Data Mining",
            "SEMMA",
            "CRISP-DM",
            "Data Preparation",
            "Data Consolidation",
            "Data Imputation",
            "Data Transformation",
            "Data Interaction",
            "Variable Reduction",
            "Modeling",
            "Maintenance",
            "Post-Mortem Analysis",
            "T-Test of Means",
            "Tukey-HSD Tests",
            "ANOVA",
            "Proportion Tests",
            "Data Normalization",
            "Data Scaling",
            "Univariate Outlier Detection",
            "Multivariate Outlier Detection",
            "Linear Models",
            "Decision Trees",
            "Neural Networks",
            "K-Nearest-Neighbor",
            "Support Vector Machines",
            "Cluster Analyses",
            "Ensemble Methods",
            "Agile Software Development",
            "Marketing Strategies",
            "CRM",
            "Management Sciences",
            "TensorFlow",
            "Keras",
            "H2O",
            "Theano",
            "Hadoop",
            "Spark",
            "Hive",
            "Pig",
            "Microsoft Azure",
            "Amazon Web Services",
            "IBM Watson"
        ],
        "tech_stack": [
            "R",
            "Python",
            "Java",
            "C++",
            "C#",
            "Scala",
            "SAS",
            "MATLAB",
            "SQL",
            "TensorFlow",
            "Keras",
            "H2O",
            "Theano",
            "Hadoop",
            "Spark",
            "Hive",
            "Pig",
            "Microsoft Azure",
            "Amazon Web Services",
            "IBM Watson"
        ],
        "programming_languages": [
            "R",
            "Python",
            "Java",
            "C++",
            "C#",
            "Scala",
            "SAS",
            "MATLAB",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Statistics",
                "Operations Research",
                "Mathematics",
                "Economics",
                "Computer Science",
                "Engineering",
                "Physics",
                "Chemical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive compensation",
            "Benefits package",
            "Career development opportunities"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3960135135,
        "company": "Augment Jobs",
        "title": "Data Scientist",
        "created_on": 1720587536.2226732,
        "description": "Position Overview: We are seeking a talented and experienced Data Scientist to join our team. As a Data Scientist, you will leverage your expertise in data analysis, machine learning, and statistical modeling to extract insights from complex data sets and drive actionable recommendations. You will play a key role in solving business problems, optimizing processes, and enhancing decision-making across the organization. Roles And Responsibilities Data Exploration and Analysis: Collect, clean, and preprocess large volumes of structured and unstructured data from multiple sources. Perform exploratory data analysis to understand patterns, trends, and relationships within the data. Apply statistical techniques and hypothesis testing to derive meaningful insights and validate assumptions. Machine Learning and Modeling: Develop and deploy machine learning models to solve predictive and prescriptive analytics problems. Select appropriate algorithms and techniques based on the nature of the data and business objectives. Evaluate model performance, fine-tune parameters, and iterate to improve accuracy and reliability. Data Visualization and Communication: Create visualizations and dashboards to effectively communicate findings and insights to stakeholders. Present complex technical concepts and analytical results to non-technical audiences in a clear and concise manner. Collaborate with cross-functional teams to integrate data-driven solutions into business processes and decision-making. Experimentation and Optimization: Design and execute experiments to test hypotheses and optimize business processes or product features. Analyze A/B test results and provide recommendations for continuous improvement and optimization. Work closely with product management and engineering teams to implement data-driven solutions in production. Continuous Learning and Development: Stay updated with the latest trends, tools, and techniques in data science and machine learning. Share knowledge and best practices within the team and contribute to the broader data science community. Mentor junior team members and collaborate on projects to foster a culture of learning and innovation. Skills And Qualifications Proven experience (X+ years) as a Data Scientist or similar role, with a strong background in data analysis, machine learning, and statistical modeling. Proficiency in programming languages and tools commonly used in data science (e.g., Python, R, SQL, TensorFlow, PyTorch). Solid understanding of data manipulation, feature engineering, and data preprocessing techniques. Experience with data visualization tools (e.g., Tableau, Power BI) and storytelling with data. Strong analytical and problem-solving skills, with the ability to translate complex data into actionable insights. Excellent communication and collaboration skills, with the ability to work effectively in cross-functional teams. Education Bachelor’s degree in Computer Science, Statistics, Mathematics, Engineering, or a related field; advanced degree (e.g., Master’s, PhD) in a quantitative discipline is preferred. Additional Attributes Curiosity and passion for exploring data to uncover hidden patterns and solve challenging problems. Ability to thrive in a fast-paced, dynamic environment and manage multiple projects concurrently. Detail-oriented and results-driven, with a focus on delivering impactful solutions that drive business outcomes. This job description outlines the critical responsibilities and qualifications expected of a Data Scientist role, emphasizing expertise in data analysis, machine learning, modeling, visualization, communication, and continuous learning. Adjustments can be made based on specific company needs, industry focus, and organizational structure.",
        "url": "https://www.linkedin.com/jobs/view/3960135135",
        "summary": "We are seeking a talented and experienced Data Scientist to join our team. As a Data Scientist, you will leverage your expertise in data analysis, machine learning, and statistical modeling to extract insights from complex data sets and drive actionable recommendations. You will play a key role in solving business problems, optimizing processes, and enhancing decision-making across the organization.",
        "industries": [
            "Data Science",
            "Analytics",
            "Machine Learning",
            "Technology",
            "Business"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Curiosity",
            "Passion",
            "Detail-Oriented",
            "Results-Driven"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "Statistical Modeling",
            "Data Exploration",
            "Data Cleaning",
            "Data Preprocessing",
            "Hypothesis Testing",
            "Predictive Analytics",
            "Prescriptive Analytics",
            "Model Development",
            "Model Deployment",
            "Algorithm Selection",
            "Model Evaluation",
            "Model Optimization",
            "Data Visualization",
            "Data Storytelling",
            "A/B Testing",
            "Experiment Design",
            "Experimentation",
            "Optimization",
            "Continuous Learning",
            "Mentoring"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "TensorFlow",
            "PyTorch",
            "Tableau",
            "Power BI"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Irving, TX",
        "job_id": 3861232363,
        "company": "Syntricate Technologies",
        "title": "Data Scientist (AI/ML)",
        "created_on": 1720587537.8292794,
        "description": "Hi, Hope you are doing well Number of position : 6 Only Full Time no C2C and No Contract Full-time I, Shakib (i3 infotek) would like to share a job opportunity as Data Scientist based in Irving, TX (Onsite) location for a Full-time position. In case, if you are not comfortable with this location, please share your preference with contact details for further requirements *** Kindly find the JD below and let me know if you are available for the same. D ata Scientist Job Location: Irving, TX (Onsite) Duration: Full-time Job Description Skill: Data Scientist with Generative AI Expertise Role & Responsibilities Design, develop, and implement advanced AI solutions to solve complex business problems across various domains. Collaborate with engineers, researchers, and product managers to understand business needs and translate them into technical specifications for AI models. Gather, clean, and prepare data for training and evaluating sophisticated AI models, ensuring data quality and ethical considerations. Explore and implement state-of-the-art AI techniques, including deep learning, natural language processing, and computer vision, tailored to specific needs. Evaluate and compare different AI model architectures and hyperparameters to optimize performance, address potential biases, and ensure responsible development. Develop monitoring and evaluation frameworks to track AI model performance and ensure alignment with business goals. Communicate complex AI concepts and findings to technical and non-technical audiences through data visualization, storytelling, and presentations. Skills Technical: Programming languages: Python (proficient) with major Client libraries. Experience with opensource Gen AI LLMs e.g., Llama and Dolly. Machine learning, NLP & deep learning: Strong understanding of supervised and unsupervised learning, neural networks, transformers. Generative AI techniques: Experience with GANs, text-to-image generation, text generation models. Data wrangling & manipulation: SQL, data cleaning, feature engineering. Hyperscalers: AWS, Azure, or GCP experience a plus Non-technical Problem-solving & critical thinking: Ability to identify and solve complex problems with data-driven solutions. Communication & collaboration: Effectively communicate technical concepts to diverse audiences, work with geographically distributed teams. Innovation & creativity. Attention to detail & accuracy. Self-motivation & continuous learning. Please reply me with your updated resume and required details: Full Name Best number to reach you: Work Authorization/Visa Status Current Location: Expected Compensation Best time to call you: Waiting for your earliest response Sincerely, Mohd Shakib Sr. Technical Recruiter Direct: 781-896-2153 Address: 1500 District Avenue, Ste. 4135, Burlington, MA 01803",
        "url": "https://www.linkedin.com/jobs/view/3861232363",
        "summary": "Data Scientist with Generative AI Expertise. Design, develop, and implement advanced AI solutions. Collaborate with engineers, researchers, and product managers. Gather, clean, and prepare data for training and evaluating sophisticated AI models. Explore and implement state-of-the-art AI techniques, including deep learning, natural language processing, and computer vision. Evaluate and compare different AI model architectures and hyperparameters to optimize performance. Develop monitoring and evaluation frameworks to track AI model performance. Communicate complex AI concepts and findings.",
        "industries": [
            "Artificial Intelligence",
            "Technology",
            "Software Development"
        ],
        "soft_skills": [
            "Problem-solving",
            "Critical Thinking",
            "Communication",
            "Collaboration",
            "Innovation",
            "Creativity",
            "Attention to Detail",
            "Accuracy",
            "Self-motivation",
            "Continuous Learning"
        ],
        "hard_skills": [
            "Python",
            "Generative AI",
            "LLMs",
            "Llama",
            "Dolly",
            "Machine Learning",
            "NLP",
            "Deep Learning",
            "Supervised Learning",
            "Unsupervised Learning",
            "Neural Networks",
            "Transformers",
            "GANs",
            "Text-to-Image Generation",
            "Text Generation Models",
            "SQL",
            "Data Cleaning",
            "Feature Engineering",
            "AWS",
            "Azure",
            "GCP"
        ],
        "tech_stack": [
            "Python",
            "LLMs",
            "Llama",
            "Dolly",
            "GANs",
            "AWS",
            "Azure",
            "GCP"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3971276801,
        "company": "RJC Group",
        "title": "Data Scientist",
        "created_on": 1720587539.3443096,
        "description": "Company We are working with a one of the worlds largest energy trading organisation who are committed to building a best-in-class Data Science platform, as being at the forefront of data management and analytics is the foundation to their investment strategy. Role This is a front office position where you will work close to the traders and be part of a team that uses modelling and time series forecasting to inform trades. Your Responsibilities Collaborate with desk heads, traders, and analysts to understand data requirements and perform time series forecasting for European Power, Natural Gas, and Petroleum markets. Develop machine learning models and deliver end-to-end data science solutions using advanced analytics and custom coding. Apply mathematical and statistical fundamentals to enhance existing applications, create new data ingestion pipelines, and source new data sets. Communicate insights to stakeholders through reports and presentations and support global Risk and Commercial investing teams with their data needs. Key Skills Minimum 2+ years of experience in a Data Science role within an energy commodity trading or investment firm. Proven experience with time series forecasting and machine learning techniques in the energy markets, strong programming skills in Python and SQL, and familiarity with frameworks such as TensorFlow, PyTorch, and Scikit-learn. Excellent problem-solving skills, ability to work independently and as part of a team, and strong communication skills for conveying complex technical concepts to non-technical stakeholders. Benefits Excellent base salary Industry Leading Bonus - up to 80% Private Medical Insurance Private Dental Insurance Hybrid/Flexible Working Sponsorship cannot be offered for this role. ​​​​​​​Apply below with an up to date CV below to set up an initial call.",
        "url": "https://www.linkedin.com/jobs/view/3971276801",
        "summary": "This is a front office Data Science role at a major energy trading organization, focused on time series forecasting for European energy markets. Responsibilities include collaborating with traders, developing ML models, enhancing existing applications, and communicating insights. Requires 2+ years of experience in energy trading, proficiency in Python, SQL, and ML frameworks (TensorFlow, PyTorch, Scikit-learn).",
        "industries": [
            "Energy",
            "Trading",
            "Finance",
            "Data Science",
            "Machine Learning",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Collaboration",
            "Teamwork",
            "Presentation",
            "Stakeholder Management"
        ],
        "hard_skills": [
            "Time Series Forecasting",
            "Machine Learning",
            "Python",
            "SQL",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Data Ingestion",
            "Data Analysis"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Base Salary",
            "Bonus",
            "Private Medical Insurance",
            "Private Dental Insurance",
            "Hybrid/Flexible Working"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3969226261,
        "company": "Augment Jobs",
        "title": "Data Scientist",
        "created_on": 1720587545.9738579,
        "description": "Overview: We are seeking a talented and experienced Data Scientist to join our team. As a Data Scientist, you will utilize your analytical, statistical, and programming skills to collect, analyze, and interpret large datasets. You will work closely with cross-functional teams to uncover insights, inform business decisions, and develop data-driven solutions. This role requires a strong foundation in data analysis, machine learning, and statistical modeling, as well as the ability to communicate complex findings to stakeholders effectively. Roles And Responsibilities Data Analysis and Modeling: Collect, clean, and preprocess data from various sources to prepare for analysis. Apply statistical analysis, machine learning techniques, and data mining algorithms to extract insights and build predictive models. Conduct exploratory data analysis (EDA) to understand patterns, trends, and anomalies in the data. Machine Learning Development: Develop and deploy machine learning models for tasks such as classification, regression, clustering, and recommendation systems. Optimize models for performance, scalability, and interpretability, considering factors like feature selection, feature engineering, and model evaluation. Data Visualization and Communication: Visualize data and present findings to technical and non-technical stakeholders using visualization tools and storytelling techniques. Collaborate with business leaders and domain experts to understand requirements and translate them into analytical solutions. Experimentation and Testing: Design and conduct A/B tests and experiments to evaluate the effectiveness of new algorithms and models. Monitor model performance in production and implement improvements or updates as needed. Collaboration and Teamwork: Work collaboratively with data engineers, software developers, and other team members to integrate models into production systems. Mentor junior team members and contribute to knowledge sharing and best practices within the data science team. Skills And Qualifications Proven experience as a Data Scientist or in a similar role, applying statistical analysis, machine learning, and data mining techniques to real-world problems. Strong programming skills in languages such as Python, R, or SQL, with experience in data manipulation and analysis libraries (e.g., pandas, NumPy, scikit-learn). Experience with data visualization tools (e.g., Matplotlib, Seaborn, Tableau) and proficiency in presenting data insights effectively. Solid understanding of machine learning algorithms (e.g., regression, classification, clustering, neural networks) and their practical applications. Knowledge of big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, Azure) is a plus. Excellent analytical and problem-solving skills, with the ability to work independently and as part of a team. Education And Experience Bachelor’s or Master’s degree in Computer Science, Statistics, Mathematics, Data Science, or a related field. Relevant work experience in data analysis, statistical modeling, and machine learning. Industry certifications (e.g., Certified Analytics Professional, AWS Certified Data Analytics) are advantageous. Compensation The compensation package includes a competitive base salary commensurate with experience and qualifications. Additional benefits such as performance bonuses, stock options, and healthcare coverage will be provided. The exact compensation will be determined based on the candidate's expertise and alignment with the company's strategic goals. Company Culture Our company values innovation, collaboration, and continuous learning. We provide a supportive and inclusive work environment where employees are encouraged to grow both personally and professionally. The Data Scientist will have the opportunity to make a significant impact by leveraging data to drive insights and business decisions. Application Process Interested candidates are encouraged to submit a resume and cover letter outlining their qualifications and interest in the position. We welcome applicants who are passionate about data science, analytics, and leveraging data to solve complex problems and drive business outcomes. This job description outlines the key responsibilities, required skills, and compensation details for the Data Scientist position, aiming to attract qualified candidates who can apply their expertise in data analysis, machine learning, and statistical modeling to extract insights and develop data-driven solutions for the organization.",
        "url": "https://www.linkedin.com/jobs/view/3969226261",
        "summary": "We are looking for a Data Scientist to join our team.  You will collect, analyze, and interpret large datasets, build predictive models, and communicate complex findings to stakeholders.  The role requires strong skills in data analysis, machine learning, and statistical modeling.",
        "industries": [
            "Data Science",
            "Analytics",
            "Machine Learning"
        ],
        "soft_skills": [
            "Analytical",
            "Communication",
            "Problem-Solving",
            "Collaboration",
            "Teamwork",
            "Independent",
            "Presentation"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "Statistical Modeling",
            "Python",
            "R",
            "SQL",
            "Pandas",
            "NumPy",
            "Scikit-learn",
            "Matplotlib",
            "Seaborn",
            "Tableau",
            "Regression",
            "Classification",
            "Clustering",
            "Neural Networks",
            "Hadoop",
            "Spark",
            "AWS",
            "Azure"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Pandas",
            "NumPy",
            "Scikit-learn",
            "Matplotlib",
            "Seaborn",
            "Tableau",
            "Hadoop",
            "Spark",
            "AWS",
            "Azure"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Performance Bonuses",
            "Stock Options",
            "Healthcare Coverage"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Elk Grove, CA",
        "job_id": 3969301224,
        "company": "iMettle Consulting LLC",
        "title": "Data Scientist",
        "created_on": 1720587550.4249384,
        "description": "Elk grove, CA (Onsite from Day 1) Full Time Job Description Tableau, SQL, and Python on a weekly basis for the past 5+ years Use Tableau to create visualizations Use SQL to manipulate and model data Use python to manipulate and model data; create visualizations; Require a working knowledge of formal statistical analysis Require excellent communication skills.",
        "url": "https://www.linkedin.com/jobs/view/3969301224",
        "summary": "Data Analyst position in Elk Grove, CA requiring 5+ years experience with Tableau, SQL, and Python. Responsibilities include data manipulation, modeling, and visualization. Strong statistical analysis and communication skills are essential.",
        "industries": [
            "Data Analysis",
            "Business Intelligence",
            "Analytics"
        ],
        "soft_skills": [
            "Communication"
        ],
        "hard_skills": [
            "Tableau",
            "SQL",
            "Python",
            "Statistical Analysis"
        ],
        "tech_stack": [
            "Tableau",
            "SQL",
            "Python"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greater Orlando",
        "job_id": 3963957749,
        "company": "VaxCare",
        "title": "Data Scientist",
        "created_on": 1720587551.8392673,
        "description": "JOB DESCRIPTION Do you want to be part of a company making real impact on the world of healthcare? ABOUT VAXCARE VaxCare is a vaccine dispensing platform that leverages proprietary technology to improve immunization rates and overall vaccine program profitability. We are problem solvers at heart. We love to tackle challenges with an analytical spin, and we are constantly looking for ways to employ new technologies to develop tools and solutions that help accomplish our vision of getting the right medications to the right patients at every encounter. THE POSITION VaxCare is currently seeking an experienced Data Scientist to work within our Data Analytics team. The ideal candidate should have experience solving critical business problems in a data driven way with the ability to communicate results clearly to key stakeholders. The Data Scientist will be responsible for working with key members within VaxCare to prepare proprietary data for real-world evidence research and publications both in conjunction with various internal and external stakeholders. This includes building analytics pipelines and complex logic for complicated data projects that solve tangible research use cases. The ideal candidate will have a strong background in mathematics, statistics, and communication with a genuine curiosity to learn new technologies and techniques. They must be comfortable working with domain experts to improve business outcomes and have a passion for solving difficult problems. RESPONSIBILITIES · Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions and prepare data for research and publication initiatives. · Ability and interest to do research, design of experiments and publish papers. · Effectively partner with customer-facing teams to reconcile client requirements with the capabilities of datasets available at VaxCare. · Illustrate the ideas underlying model development to a range of audiences: technical and non-technical, internal and external, academic research and marketing. · Develop end-to-end algorithms for productized models: model specs, training data generation, testing and parameter tuning. · Coordinate with different functional teams to implement models and monitor outcomes. · Develop processes and tools to monitor and analyze model performance and data accuracy. · Harness a good understanding of the healthcare datasets at VaxCare and client use-cases to effectively partner with data engineering teams for architectural decisions · Create a plan with the team to scale our solutions, automate code and centralize complex logic. Advocated for good engineering practices within the team like documentation and code reusability · Present findings, insights and analytical results to internal partners for client deliveries, as well as the larger DS function for continued growth and learning DESIRED EXPERIENCE · Minimum 2 years of experience in a data scientist role. · Have a few published paper and familiarity to write manuscripts and papers. · Have a Master or PhD. · Ability to do exploratory analysis on large volumes of data and find key descriptive and inferential properties. · Strong problem-solving skills with an emphasis on product development. · Experienced with development tools and data cataloging, search, analysis, visualization, and reporting tools such as Power BI and Tableau. · Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. · Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. · Strong SQL skills. · Experience using statistical programming languages (R, Python) to manipulate data and gain insights. · Experience working with Databricks, Microsoft Azure (or similar cloud platform) and Salesforce is a plus. Note: Team Members in this position will be responsible for implementing and acting in accordance with VaxCare’s information security policies; protecting assets from unauthorized access, disclosure, modification, destruction or interference; executing specific security processes or activities as assigned by the Information Security and/ or Privacy officers; and reporting security events or potential security risks to the organization",
        "url": "https://www.linkedin.com/jobs/view/3963957749",
        "summary": "VaxCare is searching for a Data Scientist to join their Data Analytics team. This role will focus on leveraging data to drive business solutions, prepare data for research and publications, and build analytics pipelines for complex data projects. The ideal candidate will have experience in a data scientist role, strong problem-solving skills, and a background in mathematics, statistics, and communication.  Experience working with Databricks, Microsoft Azure (or similar cloud platform) and Salesforce is a plus.",
        "industries": [
            "Healthcare",
            "Technology",
            "Pharmaceuticals",
            "Biotechnology"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Analytical",
            "Collaboration",
            "Presentation",
            "Curiosity",
            "Passion",
            "Research",
            "Teamwork"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Science",
            "Machine Learning",
            "Statistical Modeling",
            "Regression",
            "SQL",
            "R",
            "Python",
            "Power BI",
            "Tableau",
            "Databricks",
            "Microsoft Azure",
            "Salesforce"
        ],
        "tech_stack": [
            "Power BI",
            "Tableau",
            "Databricks",
            "Microsoft Azure",
            "Salesforce"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Master",
            "fields": [
                "Data Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3963159275,
        "company": "InfiCare Staffing",
        "title": "Data Scientist",
        "created_on": 1720587555.9543815,
        "description": "Hi There, Hope you are doing great. InfiCare has been providing Contingent Staffing and Direct Hire staffing services to its clients across the US and in four continents Since 2001. Starting from a modest beginning in 2001, today we service clients ranging from Fortune 500 companies to medium sized businesses as well as small niche firms. In US we are based at Dulles, VA. We are hiring “Data Scientist-(Remote) ” for one of our clients. If you are interested in this position, you can revert to my email or call me at 703-652-5162. Request ID: 44527-1 Duration: 6+ Months Location work will be performed: Remote Job Title: Data Scientist The Data Scientists will be responsible for helping identify intelligence hidden in vast amounts of data and illuminating networks of concern and direct investigative decisions in order to deliver high quality investigative products. The primary focus will be in applying data mining techniques, doing statistical analysis, building high quality prediction systems, and integrating these specialties and results with our products. The Data Scientists will use classified (if Security Clearance is high enough) and unclassified systems in support of creating targetable opportunities by identifying individuals and drugs and/or weapons trafficking organizations that pose a threat to the mail stream , employees, and infrastructure. Clientseeks to have the data scientists use analytical targeting information from CBP’s Team Avenger program. The associated Data Scientists will embed themselves with the Program Manager assigned to CBP – NTC and analyze the processes already in place to find a way to incorporate those processes within the target model. Description: Identifies business trends and problems through complex big data analysis. Interprets results from multiple sources using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining independently. Designs, develops and implements the most valuable business solutions for the organization. Prepares big data, implements data models and develops database to support the business solutions. Description: Fifteen (15) year ‘s relevant Data Analyst/Data mining experience to include but not limited to, Cloud resource hosting solution for APOLLO, HYDRA and ORION. Works on high-visibility, or mission critical aspects of a given program, and performs all functional duties independently. Oversees the efforts of direct reporting resources and/or be responsible for the efforts of all staff assigned to a specific job. Complete/delivery of the following Tasks: Task #1: Developing and Building Automated Tools Description: Client requires the Suppliers to select features and build and optimize classifiers using machine learning techniques associated to automation when working with large data sets. Deliverables: Creating usable tools and systems to streamline processes and reduce manual resource hours. Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: Must follow guidelines acceptable to Client's Office of Counsel, and technical departments. Task #2: Data Mining using state-of-the-art methods Description: requires the Suppliers utilize state-of-the-art methods to mine large data sets in various formats and from various sources at their access to produce intelligence products to support strategies and mission. Deliverables: Useable and understandable product results will be derived from data mining. Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: Must be formatted in a way that is acceptable to Inspectors for use in the field with data that is helpful and drives intel-based targeting and investigations. Task #3: Provide third party data, where applicable, to enhance product results Description: requires the Suppliers to utilize any available third-party data sources to enhance and extend the client's data to provide a more comprehensive analytical picture. Deliverables: Complete and comprehensive product results utilizing internal data and external data where, authorized and acceptable. Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: The use of any third-party data used should be authorized by the providing entity and acceptable . Task #4: Enhance data collection procedures Description: requires the Suppliers to Enhance data collection procedures to automate repetitive processes, include relevant data for building analytical systems, process, cleanse and verify the integrity of the data. Deliverables: Provide a technologically advanced data collection system. Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: Criteria would include the automation process for collecting data for building analytical systems. The data must be processed, cleansed and the integrity of the data must be verified. Task #5: Conduct ad-hoc analysis and present results Description: requires the Suppliers to Conduct ad-hoc analysis and present results in a clear manner which could include presentations, written documents and/or graphs and charts for visual aids. Deliverables: Product outputs from ad-hoc analysis requests from CI2 Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: The product must contain an output presented in a variety of formats for clear understanding by intended audiences. Task #6: Create automated anomaly detection systems Description: requires the Suppliers to create an automated detection system with internal tracking of its performance. Deliverables: Automated anomaly detection system. Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: Anomaly detection system with a built-in process to track performance of the system. Task #7: Assist in general IT support as needed Description: requires the Suppliers to assist with general IT support as needed for the skill level of the data scientists. Deliverables: Successful assistance in general IT support within the CI2 and CI2 NTC environment Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: Support will be provided in a way that adheres to policy and is acceptable to . Task #8: Continue to enhance a Cloud resource hosting solution Description: requires the Suppliers to Enhance and support a Cloud resource hosting solution for APOLLO, HYDRA and ORION. Deliverables: Fully Cloud resource-hosted and accessible tools including APOLLO, HYDRA and ORION. Acceptance Criteria: The deliverable must meet the following acceptance criteria in addition to compliance with the technical approach outlined below: Tools must be hosted and made accessible to Inspectors in the field. Education Requirements: A minimum of thirteen (13) to twenty (20) years’ relevant experience A degree from an accredited College/University in the applicable field of services is preferred. four additional years of relevant experience in lieu of a college degree is required. If the individual's degree is not in the applicable field, then four additional years of related experience is required.",
        "url": "https://www.linkedin.com/jobs/view/3963159275",
        "summary": "Data Scientist with 15 years of experience required for a 6+ month contract. The role involves leveraging data mining, statistical analysis, and machine learning techniques to identify threats in the mail stream and build intelligence products. The ideal candidate will have experience in cloud resource hosting solutions (APOLLO, HYDRA, ORION) and be comfortable with automated anomaly detection systems. This role will be performed remotely.",
        "industries": [
            "Government",
            "Intelligence",
            "Cybersecurity",
            "Data Analytics"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Analytical Skills",
            "Presentation Skills",
            "Adaptability"
        ],
        "hard_skills": [
            "Data Mining",
            "Statistical Analysis",
            "Machine Learning",
            "Cloud Computing",
            "Data Visualization",
            "Data Modeling",
            "Anomaly Detection",
            "Python",
            "R",
            "SQL",
            "NoSQL",
            "Tableau",
            "Power BI",
            "Qlik Sense",
            "Git",
            "Azure",
            "AWS",
            "GCP"
        ],
        "tech_stack": [
            "APOLLO",
            "HYDRA",
            "ORION",
            "Machine Learning",
            "Data Mining",
            "Cloud Computing",
            "Data Visualization",
            "Anomaly Detection"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 15,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Beaverton, OR",
        "job_id": 3967138290,
        "company": "Kforce Inc",
        "title": "Data Scientist",
        "created_on": 1720587561.514763,
        "description": "Responsibilities Kforce has a client that is seeking a Data Scientist in Beaverton, OR. Responsibilities: Designs, develops, and programs methods, processes, and systems to consolidate and analyze structured/unstructured, diverse -big data- sources to generate actionable insights and solutions for client services and product enhancement Builds \"products\" for Analysis Interacts with product and service teams to identify questions and issues for data analysis and experiments Develops and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources Identifies meaningful insights from large data and metadata sources; Interprets and communicates insights and findings from analysis and experiments to product, service, and business managers Lead to the accomplishment of key goals across consumer and commercial analytics functions Work with key stakeholders to understand requirements, develop sustainable data solutions, and provide insights and recommendations Document and communicate systems and analytics changes to the business, translating complex functionality into business relevant language Validate key performance indicators and build queries to quantitatively measure business performance Communicate with cross-functional teams to understand the business cause of data anomalies and outliers Develop data governance standards from data ingestion to product dictionaries and documentation Develop SQL queries and data visualizations to fulfill ad-hoc analysis requests and ongoing reporting needs leveraging standard query syntax Organize and transform information into comprehensible structures Use data to predict trends and perform statistical analysis Use data mining to extract information from data sets and identify correlations and patterns Monitor data quality and remove corrupt data Evaluate and utilize new technologies, tools Requirements Typically requires a Bachelor's degree and minimum of 2-4 years of directly relevant work experience Note: One of the following alternatives may be accepted: PhD or Law + 1 year; Masters + 0-3 years; Associate's degree + 1-3 years; High School diploma/GED + 3-5 years The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future. We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave. Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law. This job is not eligible for bonuses, incentives or commissions. Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3967138290",
        "summary": "Kforce is seeking a Data Scientist in Beaverton, OR to analyze big data, build analytical products, develop algorithms, and communicate insights to product and business teams. The role requires strong data analysis, programming, and communication skills.",
        "industries": [
            "Data Science",
            "Analytics",
            "Software Development",
            "Product Development",
            "Business Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Decision Making",
            "Presentation Skills",
            "Teamwork",
            "Leadership"
        ],
        "hard_skills": [
            "Data Analysis",
            "Big Data",
            "Machine Learning",
            "Statistical Modeling",
            "Data Mining",
            "Data Visualization",
            "SQL",
            "Python",
            "R",
            "Java",
            "Data Governance",
            "Data Quality",
            "Data Cleansing",
            "Data Integration",
            "Algorithm Development",
            "Software Development"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Java",
            "SQL",
            "Data Mining",
            "Machine Learning"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Java",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical/Dental/Vision Insurance",
            "HSA",
            "FSA",
            "401(k)",
            "Life Insurance",
            "Disability Insurance",
            "ADD Insurance",
            "Paid Time Off"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3970073117,
        "company": "Marlee (Fingerprint For Success)",
        "title": "Expression of Interest - Data Scientist",
        "created_on": 1720587565.4447384,
        "description": "We are inviting professionals in high-growth industries who are thinking about their next move or looking for a new opportunity to join our expanding talent pool. The Marlee Talent Pool is a pilot project designed to: Help job seekers get discovered by our partners based on their anticipated hiring needs Provide optional support and resources for job seekers in their career endeavours Help individuals understand, and bring out the best in themselves and each other The Marlee Talent Pool process: Once you express your interest, you will be asked to complete the Marlee work style assessment which measures 48 key attitudes and motivations in the context of work. On completion, you will be automatically added to our growing talent pool and contacted as new opportunities arise. About Marlee (Fingerprint For Success) Backed by 20+ years of research, Marlee’s revolutionary predictive analytics have achieved over 90% reliability in forecasting personal and team motivations, behaviours, and performance. Ultimately, we help people find purpose and fulfillment at work, and help build and scale high-performing teams. Keep in mind that joining our talent pool does not guarantee a job offer. We aim to balance your technical skills with the results of your Marlee work style assessment to match the hiring needs of our partners. Your feedback is a gift! Write to us via: to help co-create the future of recruitment, together. Powered by JazzHR RcMRfus2fn",
        "url": "https://www.linkedin.com/jobs/view/3970073117",
        "summary": "Marlee Talent Pool is a pilot project designed to connect job seekers with hiring partners based on their skills and work style assessment results. The assessment measures 48 key attitudes and motivations in the context of work. By joining the talent pool, individuals can be discovered by Marlee's partners and receive support for their career endeavors.",
        "industries": [
            "Recruitment",
            "Human Resources",
            "Talent Acquisition",
            "Technology",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Teamwork",
            "Problem Solving",
            "Critical Thinking",
            "Self-Awareness",
            "Motivation",
            "Adaptability",
            "Goal Orientation"
        ],
        "hard_skills": [],
        "tech_stack": [
            "Predictive Analytics"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Career Support",
            "Resources"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Atlanta, GA",
        "job_id": 3969407681,
        "company": "Visa",
        "title": "Data Scientist",
        "created_on": 1720587566.849885,
        "description": "Company Description Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid. Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa. Job Description Visa U.S.A. Inc, a Visa Inc. company, needs a Data Scientist (Multiple Openings) in Atlanta, GA to work within a team to: Work within a team to generate business insights based on big data, identify actionable recommendations and communicate the findings to clients. Brainstorm innovative ways to use our unique data to answer business problems. Communicate with clients to understand the challenges they face and convince them with data. Extract and understand data to form an opinion on how to best help our clients and derive relevant insights. Develop visualizations to make your complex analyses accessible to a broad audience. Find opportunities to craft products out of analyses that are suitable for multiple clients. Work with stakeholders throughout the organization to identify opportunities for leveraging Visa data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of product, marketing techniques and business strategies for Visa and its clients. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, data insights, and other business outcomes. Position reports to the Atlanta, GA office and may allow for partial telecommuting. Qualifications Employer will accept a Master’s degree, or foreign equivalent, in Statistics, Operations Research, Applied Mathematics, Economics, Data Science, Business Analytics, Computer Science, or a related technical field. Extracting and aggregating data from large data sets using SQL/Hive or Spark; Analyzing large data sets using programming languages such as Python, R, SQL and/or Spark; Generating and visualizing data-based insights in software such as Tableau; Communicating data-driven insights and conveying actionable recommendations; Managing and organizing work in Office software such as Word, Excel, PowerPoint and/or Teams; Building predictive and descriptive statistical models using machine learning tool kit, Jupyter notebooks, Python, and/or SAS; and Data mining and statistical modeling (e.g., regression modeling, clustering techniques, decision trees, etc.). Additional Information WORKSITE: Atlanta, GA This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Travel Requirements: This position does not require travel. Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers. Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is $ 122,900.00 USD to $196,700.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.",
        "url": "https://www.linkedin.com/jobs/view/3969407681",
        "summary": "Visa is seeking a Data Scientist to join their team in Atlanta, GA. The role involves analyzing large datasets, extracting insights, creating visualizations, and communicating actionable recommendations to clients. The ideal candidate will have experience with SQL/Hive, Spark, Python, R, Tableau, and machine learning techniques like regression modeling, clustering, and decision trees.",
        "industries": [
            "Financial Services",
            "Technology",
            "Payments",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Data Visualization",
            "Collaboration",
            "Stakeholder Management"
        ],
        "hard_skills": [
            "SQL",
            "Hive",
            "Spark",
            "Python",
            "R",
            "Tableau",
            "Machine Learning",
            "Regression Modeling",
            "Clustering Techniques",
            "Decision Trees",
            "Jupyter Notebooks",
            "SAS",
            "Data Mining"
        ],
        "tech_stack": [
            "SQL",
            "Hive",
            "Spark",
            "Python",
            "R",
            "Tableau",
            "Jupyter Notebooks",
            "SAS"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Statistics",
                "Operations Research",
                "Applied Mathematics",
                "Economics",
                "Data Science",
                "Business Analytics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 196700,
            "min": 122900
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401(k)",
            "FSA/HSA",
            "Life Insurance",
            "Paid Time Off",
            "Wellness Program"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Fayetteville, North Carolina Metropolitan Area",
        "job_id": 3970376811,
        "company": "Top Stack",
        "title": "Data Scientist",
        "created_on": 1720587568.4804478,
        "description": "Are you a transitioning military looking for an entry level opportunity in Data Science? Do you have an active security clearance and looking to grow your data skills? Our customer is looking for an entry level data science candidate to join a dynamic, military supporting team. This role does require an ACTIVE Interim- Secret or Top Secret security clearance upon hire. *Please do not apply if you do not have an Active Interim Secret or Top Secret Security Clearance* • Minimum of 1-year experience is required • Bachelor’s degree in a STEM field is required. Master’s degree is preferred in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields. • Proficient with one or more programming languages (Java, C++, Python, R, etc.). • Bachelor’s degree is acceptable in the above fields if the incumbent has training and verifiable work experience in a related field. • Proficient in Agile Development and Git Operations. • Demonstrated experience applying data science methods to real-world data problems. • At least “Interim Secret” w/in 30 days of hire is required, while Top Secret clearance eligible for SCI is preferred. Description and Duties: • Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific method. • Coordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data • Experiment against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges. • Coordinate with Data Engineers to build Data environments providing data identified by other data professionals • Apply and develop scientific methodology, statistics, and algorithms to discover and frame relevant problems, hypotheses, and opportunities. • Develop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniques. • Design and automate processes to facilitate the manipulation and analysis of data. Manage and integrate data across dissimilar data sets. Analyze large-scale structured and unstructured data. • Use frameworks such as Spark and Hadoop to conduct large-scale data processing. Perform statistical modeling and create data visualizations using products like Tableau, Microsoft Power BI and R Shiny. • Research, design, and implement algorithms to solve complex problems. Program using R, Python (NumPy, SciPy, Pandas) or similar analytical languages. • Perform data engineering, data processing and modeling techniques using cloud-based data management, data science, and ML platforms such as Databricks, IBM Cloud Pak, Cloudera, and Snowflake. • Communicate complex concepts and hypothesis to a non-technical audience through digital storytelling.",
        "url": "https://www.linkedin.com/jobs/view/3970376811",
        "summary": "Entry level Data Scientist position for a military supporting team requiring active security clearance (Interim Secret or Top Secret). Responsibilities include analyzing data, developing predictive models, using data science platforms, and communicating findings to non-technical audiences.",
        "industries": [
            "Defense",
            "Military",
            "Government",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Research",
            "Teamwork",
            "Coordination",
            "Communication",
            "Storytelling"
        ],
        "hard_skills": [
            "Data Analysis",
            "Statistical Techniques",
            "Scientific Method",
            "Programming",
            "Data Cleaning",
            "Data Organization",
            "Data Exploration",
            "Experimentation",
            "Predictive Modeling",
            "Prescriptive Modeling",
            "Natural Language Processing",
            "Robotic Process Automation",
            "Text Mining",
            "Clustering",
            "Forecasting",
            "Statistical Modeling",
            "Data Visualization",
            "Data Engineering",
            "Data Processing",
            "Cloud Computing",
            "Data Management",
            "Machine Learning"
        ],
        "tech_stack": [
            "Spark",
            "Hadoop",
            "Tableau",
            "Microsoft Power BI",
            "R Shiny",
            "Databricks",
            "IBM Cloud Pak",
            "Cloudera",
            "Snowflake",
            "Git",
            "Agile Development"
        ],
        "programming_languages": [
            "Java",
            "C++",
            "Python",
            "R",
            "NumPy",
            "SciPy",
            "Pandas"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "STEM",
                "Operations Research",
                "Industrial Engineering",
                "Applied Mathematics",
                "Statistics",
                "Physics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Titusville, NJ",
        "job_id": 3970263239,
        "company": "Johnson & Johnson",
        "title": "Data Scientist",
        "created_on": 1720587570.014872,
        "description": "Description: Johnson & Johnson Innovative Medicine, is recruiting for a Data Scientist in Business Technology located in Titusville, NJ, or Horsham, PA. At Johnson & Johnson, we believe health is everything. Our strength in healthcare innovation empowers us to build a world where complex diseases are prevented, treated, and cured, where treatments are smarter and less invasive, and solutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com/. The Commercial Data Sciences team is looking for an extraordinary scientist who is passionate about crafting, developing, and fielding data science solutions that drive impact for patients and for Johnson & Johnson. There are many ways to explore and analyze data, and this powers the excitement and passion of data scientists at J&J as many business units are eager to use the data to build business value. In this role you will be someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with primary focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development. The role requires both a broad knowledge of existing AI-type algorithms and the creativity to invent and customize when necessary. You will lead and deliver projects and develop solutions that in turn deliver insights. You will also work closely with matrixed teams across business and technology to understand how best to solve complex problems. You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions. Come join us in our mission to transform the future of health! Qualifications: Required Qualifications: Ph.D. with 2 years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma sales & marketing experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field. Strong working knowledge of machine learning platforms/environments. Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models. Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows. Proficiency with one or more programming language such as Python or R. Proficiency with SQL. Experience delivering on data science projects using predictive technologies, data mining and/or text mining. Familiarity with working in a cloud-based technology stack. Strong communication skills and ability to translate complex methods and results to diverse audiences. Strong ability to establish relationships with business partners and understand their needs. Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations Experience with vendor management – ensuring timelines and expectations Preferred Qualifications: Experience in the commercial pharmaceutical business. Experience with sales and marketing best practices, processes, and related technology. Experience in digital media and direct-to-consumer marketing Familiarity of commercially available healthcare data sets. Experience with PySpark. Familiarity with usage of Generative AI for productivity improvement. Familiarity with open-source and gated/paid model landscape Other: This position will require up to 15% domestic travel. The anticipated base pay range for this position is between $104K to $166,750K. The Company maintains highly competitive, performance-based compensation programs. Under current guidelines, this position is eligible for an annual performance bonus in accordance with the terms of the applicable plan. The annual performance bonus is a cash bonus intended to provide an incentive to achieve annual targeted results by rewarding for individual and the corporation’s performance over a calendar/performance year. Bonuses are awarded at the Company’s discretion on an individual basis. Employees and/or eligible dependents may be eligible to participate in the following Company sponsored employee benefit programs: medical, dental, vision, life insurance, short- and long-term disability, business accident insurance, and group legal insurance. Employees may be eligible to participate in the Company’s consolidated retirement plan (pension) and savings plan (401(k)). This position is eligible to participate in the Company’s long-term incentive program. Employees are eligible for the following time off benefits: Vacation – up to 120 hours per calendar year Sick time - up to 40 hours per calendar year; for employees who reside in the State of Washington – up to 56 hours per calendar year Holiday pay, including Floating Holidays – up to 13 days per calendar year of Work, Personal and Family Time - up to 40 hours per calendar year Additional information can be found through the link below. https://www.careers.jnj.com/employee-benefits The compensation and benefits information set forth in this posting applies to candidates hired in the United States. Candidates hired outside the United States will be eligible for compensation and benefits in accordance with their local market. Johnson and Johnson is an Equal Opportunity Employer committed to a diverse workforce. Johnson and Johnson will not discriminate against any worker or job applicant on the basis of race, color, religion, gender, gender identity, national origin, ancestry, age, sex, sexual orientation, gender identity, marital or civil partnership status, pregnancy, gender reassignment, non-job related mental or physical disability, genetic information, veteran status, military service, application for military service, or membership in any other category protected under law. Johnson and Johnson maintains a drug-free workplace.",
        "url": "https://www.linkedin.com/jobs/view/3970263239",
        "summary": "Johnson & Johnson is seeking a Data Scientist to join their Commercial Data Sciences team in Titusville, NJ or Horsham, PA. This role involves leveraging AI and advanced analytics to optimize omnichannel sales and marketing, analyze patient/payer data, and contribute to commercial strategy. The ideal candidate will have a strong foundation in machine learning, experience with healthcare data, and excellent communication skills. They will lead projects, develop solutions, and collaborate with cross-functional teams to drive business value.",
        "industries": [
            "Healthcare",
            "Pharmaceuticals",
            "Data Science",
            "Artificial Intelligence",
            "Marketing",
            "Sales"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Relationship Building",
            "Analytical Thinking",
            "Project Management",
            "Leadership"
        ],
        "hard_skills": [
            "Machine Learning",
            "Regression",
            "Decision Trees",
            "Probability Networks",
            "Association Rules",
            "Clustering",
            "Neural Networks",
            "Bayesian Models",
            "Data Analysis",
            "Python",
            "R",
            "SQL",
            "Predictive Modeling",
            "Data Mining",
            "Text Mining",
            "Cloud Computing",
            "PySpark",
            "Generative AI"
        ],
        "tech_stack": [
            "Machine Learning Platforms",
            "Cloud-based Technology Stack",
            "PySpark",
            "Generative AI"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "M.S.",
            "fields": [
                "Computer Sciences",
                "Statistics",
                "Machine Learning",
                "Artificial Intelligence",
                "Physics",
                "Molecular Biology",
                "Bioinformatics",
                "Computational Informatics",
                "Medical Informatics",
                "Computational Biology"
            ]
        },
        "salary": {
            "max": 166750,
            "min": 104000
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Life Insurance",
            "Short-Term Disability",
            "Long-Term Disability",
            "Business Accident Insurance",
            "Group Legal Insurance",
            "Retirement Plan (Pension)",
            "Savings Plan (401(k))",
            "Long-Term Incentive Program",
            "Vacation",
            "Sick Time",
            "Holiday Pay",
            "Floating Holidays",
            "Work, Personal and Family Time"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Seattle, WA",
        "job_id": 3962796572,
        "company": "Supernormal",
        "title": "Machine Learning Engineer",
        "created_on": 1720587571.903319,
        "description": "About Us We're on a mission to transform spoken communication for individuals, teams and organizations of any size. Meetings may be our most information-rich channel for work, but suffer from a lack of structure and documentation. At Supernormal, we're solving this problem with focus, design and craft. We've been working on this since 2019 and have customers like Snap, Salesforce, Replay, Gitcoin, Pinterest and thousands more on this journey with us. Today, we are growing rapidly and are excited for new teammates to join who are the best at what they do. We're passionately building a team that is as diverse and creative as the millions of people we serve worldwide. Supernormal is a remote-first company and does not require co-location. We have annual team retreats and gather quarterly. About The Role Machine learning engineers at Supernormal build the AI that superpowers the core product experience for people's meetings including transcription, note generation, and task automation. The AI team builds reliable and secure services that use the most advanced AI models in the market to generate millions of high-quality meeting notes to a rapidly growing customer base. Our work revolves heavily around software engineering, too - we are looking for people with a drive to roll up their sleeves and get new models and features out to users as quickly as possible. What You'll Work On As an ML engineer on Supernormal's AI team, you will be responsible for the end-to-end development of our AI solutions for meeting notes, question answering, and task completion. Your work will encompass LLM API calls, custom model training and deployment, speech recognition, quality evaluation and fixes, retrieval augmented generation, and much more. You'll play a key role in optimizing for cost, latency, and quality. Some of the projects you'll work on include: Prompt engineering using state-of-the-art techniques to improve the core meeting assistant scenarios Building and shipping custom machine learning models to augment the AI stack, including improving transcript quality, reducing tokens sent to APIs, removing defects in LLM output, and extracting semi-structured data Training and deploying custom large language models from open source using state-of-the-art techniques (LoRA, RLHF, instruction-tuning, etc) Developing new product experiences using NLP & LLMs that get better based on user feedback & iteration while collaborating with product engineers & design team Defining and improving business & product metrics to optimize the quality and cost of AI usage Improving LLM-powered search and question answering (using RAG) over sets of meetings Advocating for, and building, new and better ways of doing things. You'll leave everything you touch just a bit better than you found it Requirements What you will bring We are a fast-moving startup building zero-to-one products on top of large language models. The ideal candidate has a strong machine learning background and a hacker mindset, someone who can both spin up Jupyter Notebooks to train models and also excel at writing solid, fast production code for deployment. AI/ML Experience: Demonstrated proficiency in AI/ML with a track record of at least 3-5 years experience building machine learning systems, up to speed on the latest in NLP & LLMs, and proficient in data curation, modeling, and training models A Solid Educational Foundation: Bachelor's degree in Computer Science, Engineering, AI, Mathematics, or related field; Master's degree or PhD a plus Versatile Software Engineering Skills: A solid engineering background with a robust foundation in software engineering principles. You have written code for and supported production engineering systems. Proficient in Python and SQL: our AI stack uses Python & PyTorch and interfaces with Ruby on Rails (bonus if you know it, but not required) and we write a lot of SQL queries on top of Snowflake to pull data What we'll expect of you A collaborative and open outlook — we're all about lifting each other up and getting better every day A willingness to get deep into a problem even when it seems impossible. You'll always have support from the team Confidence operating with high agency. We'll work together to decide what's important, but we'd love for you to bring (and build!) your own ideas You'll come in willing to learn why things are the way they are, then suggest a better way You'll understand that there's no difference between \"my idea\" and \"their idea.\" It's our ideas and we're all responsible for it You'll approach speed bumps and reviews through a \"how can the team level up?\" lens — let's all get better and learn, together Benefits 💰 Competitive salary, 401K 📈 Stock options 🏥 Full healthcare coverage (Medical, Dental, and Vision) 🚀 Totally remote. Not hybrid. Remote. No return-to-office here 🏠 WFH budget to make sure you have everything you need to do your best work ✈️ Annual team-wide offsite to someplace cool 🎓 Education credit (up to $500 per year) 🧳 Unlimited PTO (minimum 4 weeks)",
        "url": "https://www.linkedin.com/jobs/view/3962796572",
        "summary": "Supernormal is seeking a Machine Learning Engineer to build AI models for meeting transcription, note generation, and task automation. This role involves developing custom models, prompt engineering, and optimizing for cost and latency. You'll be involved in projects like improving transcript quality, extracting data, training large language models, and developing new product experiences. The ideal candidate has a strong machine learning background, a hacker mindset, and at least 3-5 years of experience building machine learning systems. Experience with NLP and LLMs, data curation, modeling, and training models is essential. The role also requires proficiency in Python, SQL, and ideally, Ruby on Rails.",
        "industries": [
            "Software",
            "Technology",
            "AI",
            "Machine Learning",
            "Natural Language Processing",
            "Meeting Technology"
        ],
        "soft_skills": [
            "Collaborative",
            "Open",
            "Willing to learn",
            "Problem-solving",
            "Confidence",
            "Agency",
            "Teamwork",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "PyTorch",
            "Ruby on Rails",
            "Snowflake",
            "Jupyter Notebook",
            "NLP",
            "LLMs",
            "Data Curation",
            "Modeling",
            "Training Models",
            "Prompt Engineering",
            "Speech Recognition",
            "Quality Evaluation",
            "Retrieval Augmented Generation",
            "Cost Optimization",
            "Latency Optimization",
            "Machine Learning Systems",
            "AI"
        ],
        "tech_stack": [
            "Python",
            "PyTorch",
            "Ruby on Rails",
            "Snowflake",
            "Jupyter Notebook"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "Ruby on Rails"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Engineering",
                "AI",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "401K",
            "Stock options",
            "Full healthcare coverage",
            "Remote work",
            "WFH budget",
            "Annual team-wide offsite",
            "Education credit",
            "Unlimited PTO"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3964349491,
        "company": "Digital Janet",
        "title": "Data Scientist",
        "created_on": 1720587573.585964,
        "description": "Jd Knowledge, Skills, Abilities and other Requirements: Proficiency in programming languages such as Python, R, and SQL. Experience with data visualization tools such as Tableau, Power BI, or similar. Familiarity with Snowflake or other cloud-based data platforms. Knowledge of ETL processes and tools. Experience with AI and ML techniques to enhance data analysis and RAG implementation.but not limited to SQL, Excel and/or SAAS Proficient in various data catalog and visualizations tools, including but not limited to Tableau, PowerBI, Informatica, and/or Snowflake Knowledgeable in electronic medical records, preferably EPIC Years Of Experience Minimum of 5 years of experience in data science, with a focus on healthcare analytics. Proven experience working with Epic EMR data, including extraction, transformation, and analysis. Strong background in implementing rules-based logic and RAG in a healthcare setting.",
        "url": "https://www.linkedin.com/jobs/view/3964349491",
        "summary": "This role requires a data scientist with 5+ years of experience in healthcare analytics, specifically with Epic EMR data. The candidate should be proficient in Python, R, SQL, data visualization tools like Tableau and Power BI, cloud platforms like Snowflake, and ETL processes. Experience with AI/ML techniques and RAG implementation in a healthcare context is also crucial.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Problem Solving",
            "Analytical Thinking",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Power BI",
            "Snowflake",
            "ETL",
            "AI",
            "ML",
            "RAG",
            "Epic EMR",
            "Data Extraction",
            "Data Transformation",
            "Data Analysis",
            "Rules-based Logic"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Power BI",
            "Snowflake",
            "ETL",
            "AI",
            "ML",
            "RAG",
            "Epic EMR"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Healthcare Informatics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Redmond, WA",
        "job_id": 3964446083,
        "company": "Syren Cloud Inc",
        "title": "Data Scientist",
        "created_on": 1720587575.182537,
        "description": "Basic Qualifications: 5 year of industrial experience with one or more of the following: classification, regression, NLP, GBM, unsupervised learning, transit time estimation, Deep-Learning, GNN. Experience in big data processing, e.g. Hadoop, SQL, Spark/PySpark Experience with Python, Java or Scala, and PyTorch. Demonstrated experience developing and deploying large scale ML models. Job Responsibilities: Seek scientifically valid solutions that deliver real value to client's customers Build machine learning models and data pipelines to deliver insightful yet practical solutions across web-scale data. Work with multiple teams to help promote standard scientific methodologies and processes in your field Present key technical and novel research work in public forums and conferences",
        "url": "https://www.linkedin.com/jobs/view/3964446083",
        "summary": "This role involves developing and deploying large-scale machine learning models to deliver valuable solutions for clients. Responsibilities include building data pipelines, promoting scientific methodologies, and presenting research findings.",
        "industries": [
            "Machine Learning",
            "Data Science",
            "Artificial Intelligence",
            "Software Development",
            "Technology",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Research",
            "Scientific Methodologies"
        ],
        "hard_skills": [
            "Classification",
            "Regression",
            "NLP",
            "GBM",
            "Unsupervised Learning",
            "Transit Time Estimation",
            "Deep Learning",
            "GNN",
            "Hadoop",
            "SQL",
            "Spark",
            "PySpark",
            "Python",
            "Java",
            "Scala",
            "PyTorch",
            "Machine Learning Model Development",
            "Data Pipeline Development"
        ],
        "tech_stack": [
            "Hadoop",
            "SQL",
            "Spark",
            "PySpark",
            "Python",
            "Java",
            "Scala",
            "PyTorch"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Columbus, OH",
        "job_id": 3964656944,
        "company": "Designer Brands",
        "title": "Machine Learning Engineer (Remote)",
        "created_on": 1720587578.2820828,
        "description": "General Summary: The Machine Learning Engineer is responsible for supporting the business by developing Integrated AL/ML solutions for use cases across the company. This position will develop and deploy AI/Machine Learning models in GCP, Azure Open AI or other cloud platform that drives business value, automates processes and enables efficiency. Machine Learning Engineer is an expert at working with structured and non-structured data sources and other programming/scripting languages. His/her expertise will be at the intersection of programming, mathematics, and data science. The role requires strong programing background and analytical mindset to collect requirements and translate them into an analytical solution. This person needs to have the ability to ask the right questions and translate complex technical details into business language for leadership. Ideal candidates enjoy working in demanding and fast-paced environments and are proactive, goal-oriented and team players. Reports To: VP, Enterprise Data Analytics & AI Essential Duties and Responsibilities: Design, build, and fine-tune machine learning models. Work with large datasets to train algorithms. Preprocess data, select appropriate models, and optimize their performance. Develop and deploy machine learning and AI models in cloud platform to enable and support strategic priorities of DBI across departments. Collaborate with stakeholders across organization to understand requirements, assimilate data needed, build predictive/prescriptive models, communicate results, and deploy predictions on edge or central database system for real time or batch predictions. Developing and implementing appropriate RAG architecture for model deployment. Working closely with cloud data engineers to implement RAG effectively within cloud platform for efficient inference. Staying current with generative AI enhancements and foundational models being available in the market and doing R&D on applicability on DBI use cases. Build an AI infrastructure and set standards for leveraging available cloud platforms to enable and educate citizen data scientists to leverage the power of machine learning, Build self-serve AI framework. Develop a strategic working relationship with cross-functional teams to align the data solutions to business KPI’s, levers and goals. Drive cross-functional teams to meet business objectives and influence co-workers and stakeholders, fostering strong working relationships. Ability to stand by decisions and move forward with courage. Lead several concurrent initiatives/projects to develop custom, easy-to-use self-service solutions to serve multiple stakeholder groups and business objectives. Furnish analysis with analytical insight while maintaining completeness, accuracy, and documentation. Identify areas and define solutions to maximize value-add to the organization Required Skills: Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy using descriptive and predictive analytics that optimize statistical efficiency and quality of the model – feature engineering, feature selection, model evaluation, model selection, model drift evaluation etc. Strong Knowledge of supervised and unsupervised deep learning algorithms and experience in advanced deep learning libraries like TensorFlow, Keras, Pytorch, Caffe, Theano etc. Experience leveraging foundational models like Claude 3.5, GPTs, Gemini, Llama etc. Knowledge and experience in implementing ethical and responsible AI principles while implementing ML solutions is preferred. Strong statistical knowledge and understanding of application of algorithms based on data and business need. Extensive background in statistical analysis, computational sciences, mathematics, physics, or econometrics. Advanced analytical and problem-solving skills and an ability to work independently in a fast-paced and rapidly changing environment. Entrepreneurial spirit - self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively. Competencies: SETTING GOALS – Creates and follows effective plans. Anticipates risks, creates contingency plans. Aligns plans with goals. Allocates adequate resources. Accepts and supports change. Willing to take risks and suggests new ideas, approaches. Takes initiative. Seeks out learning activities. WORKING WITH OTHERS – Clearly articulates own, other’s goals. Promotes a team atmosphere by demonstrating humility and respect. Builds effective relationships, relates well to others. Delivers and responds to feedback in a constructive manner. Considers multiple perspectives. Handles conflict, pressure, uncertainty and adapts independently. Meets commitments. Dedicated to working with business partners on their expectations. GETTING RESULTS – Personally accountable for work performance targets and achieving results. Prioritizes well. Anticipates and handles obstacles effectively. Makes good, timely decisions. Can simplify and process complex problems. Understands underlying issues and addresses root causes. Meets deadlines, works until finished. Qualifications: Experience: Master’s degree in analytics or computer science with 4+ years of experience developing and deploying machine learning models is required Experience with Big Data environments (very large 1st party data integrating multiple internal and external disjointed data) Experience in model metrics monitoring, orchestrating ML workflows using pipelines, version control, model drift management. Experience working with underlying databases and tables. Understands table relationships to be able to do dimensional modeling; understands lookup tables and fact tables. Ability to write reusable code components Familiarity with programming languages such as R and/or Python/ Julia/ Scala Communication skills including the ability to identify and communicate data driven insights Preferred Qualifications: Experience in development and deployment of models in GCP including Vertex AI OR Azure Open AI Experience in SQL for data mining, feature engineering. Experience with cloud infrastructure platforms (Google Cloud Platform) is preferable PhD in statistical domain/topic Retail experience preferred. Education: Master’s degree in Analytics or other STEM field (Data Analytics, Data Science, Computer Science, Data Engineering, Applied Mathematics)",
        "url": "https://www.linkedin.com/jobs/view/3964656944",
        "summary": "This role involves developing and deploying AI/ML models to optimize business processes and efficiency. The ideal candidate is an expert in machine learning, data analysis, and programming languages, with strong analytical skills and the ability to communicate technical details effectively. This position is responsible for designing, building, and fine-tuning models, working with large datasets, and collaborating with stakeholders across the organization.",
        "industries": [
            "Data Analytics",
            "Artificial Intelligence",
            "Machine Learning",
            "Cloud Computing",
            "Retail"
        ],
        "soft_skills": [
            "Analytical skills",
            "Communication skills",
            "Problem-solving skills",
            "Teamwork",
            "Leadership",
            "Goal-oriented",
            "Proactive",
            "Entrepreneurial spirit",
            "Time management",
            "Accountability",
            "Self-motivated",
            "Adaptability",
            "Conflict resolution",
            "Relationship building"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Caffe",
            "Theano",
            "Claude 3.5",
            "GPTs",
            "Gemini",
            "Llama",
            "SQL",
            "Python",
            "R",
            "Julia",
            "Scala",
            "Data mining",
            "Feature engineering",
            "Model metrics monitoring",
            "ML workflows",
            "Pipelines",
            "Version control",
            "Model drift management",
            "Dimensional modeling",
            "Data analytics",
            "Data science",
            "Computer science",
            "Data engineering",
            "Applied mathematics",
            "Statistical analysis",
            "Computational sciences",
            "Mathematics",
            "Physics",
            "Econometrics"
        ],
        "tech_stack": [
            "GCP",
            "Vertex AI",
            "Azure Open AI",
            "Google Cloud Platform"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Julia",
            "Scala",
            "SQL"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Analytics",
                "Data Analytics",
                "Data Science",
                "Computer Science",
                "Data Engineering",
                "Applied Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959109752,
        "company": "MM International, LLC",
        "title": "Data Scientist",
        "created_on": 1720587581.524388,
        "description": "Position: “Technical Analyst/Editor” Location: 100% Remote Role Duration: Contract, Long Term Visa GC or USC Job Description: LCAT: Data Scientist I (CS) Required Education Level: Bachelors in Healthcare, Science, Computer Engineering or related scientific, technical, or clinical discipline Required Experience (Years): 4 Substitution Criteria : 4 years of additional relevant experience may be substituted for education Location: Remote Pillars : FEHRM Sub-Pillars : FEHRM - Technical Job Description: Support the Federal Electronic Health Records Modernization (FEHRM) office. Responsible for improving the quality of artifacts developed by the FEHRM technical team. Establish methods to review artifacts in terms of accuracy, completeness, grammar, formatting and the like. Review artifacts according to standards. Ask critical questions to evaluate the logic of artifacts, particularly those in MS Word and MS PowerPoint formats. Artifacts may include, but are not limited to, briefings of record, memorandums, meeting minutes, and input to leadership presentations. Offer suggested edits to authors, by performing your own analyses, and drawing your own conclusions. Collaborate with a wide range of stakeholders, from across the FEHRM technical team, across the FEHRM itself and with DoD and VA. Function as a member of a consulting team. Minimum Qualifications: 4+ years of professional work experience Possesses knowledge of appropriate data sources to address the specific requirements of projects for monitoring, characterization, analysis and modeling Performs scientific research, scientific writing and editing, including the writing and editing of project products to established government standards for the targeted science and lay audiences, proofreading of draft and final documents. Works under supervision. Bachelor's degree in Healthcare, Science, Computer Engineering or related scientific, technical, or clinical discipline is required, or an additional 4 years of experience may be substituted for degree requirements Preferred Qualifications: VA experience preferred Experience implementing Electronic Health Records",
        "url": "https://www.linkedin.com/jobs/view/3959109752",
        "summary": "This is a long-term contract position for a Technical Analyst/Editor to support the Federal Electronic Health Records Modernization (FEHRM) office.  The role involves reviewing technical artifacts for accuracy, completeness, grammar, and formatting, and offering suggested edits. Collaboration with various stakeholders is essential.",
        "industries": [
            "Healthcare",
            "Government",
            "Technology",
            "Data Science",
            "Consulting"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Critical Thinking",
            "Problem Solving",
            "Attention to Detail",
            "Editing",
            "Writing"
        ],
        "hard_skills": [
            "Data Analysis",
            "Scientific Writing",
            "Editing",
            "Proofreading",
            "MS Word",
            "MS PowerPoint",
            "Meeting Minutes",
            "Briefing Preparation"
        ],
        "tech_stack": [
            "Electronic Health Records (EHR)",
            "MS Word",
            "MS PowerPoint"
        ],
        "programming_languages": [],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Healthcare",
                "Science",
                "Computer Engineering",
                "Scientific",
                "Technical",
                "Clinical"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Plano, TX",
        "job_id": 3967782892,
        "company": "Ascentt",
        "title": "Data Scientist",
        "created_on": 1720587588.5599535,
        "description": "The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers. Responsibilities Analyze raw data: assessing quality, cleansing, structuring for downstream processing Design accurate and scalable prediction algorithms Collaborate with engineering team to bring analytical prototypes to production Generate actionable insights for business improvements Qualifications Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.) At least 2 years of experience in quantitative analytics or data modeling Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms Fluency in a programming language - Python 3 years of experience as a Data Scientist in ML such as NLP, Machine vision, Time series etc. Strong expertise in Model Tuning, Model Validation, Supervised and Unsupervised Learning Hands on experience with model development, data preparation, training and inference ready deployment of models Well versed on descriptive and inferential statistics, hypothesis testing, etc Excellent at data analysis and exploration skills Develops the code useful for reproducible analysis of data Good hands on knowledge of AWS Sagemaker, Lambda, Glue, Step functions and EC2 Knowledge of Databricks, Anaconda distribution and similar data science code development and deployment IDEs Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)",
        "url": "https://www.linkedin.com/jobs/view/3967782892",
        "summary": "Data Scientist with strong analytical skills to analyze raw data, design scalable prediction algorithms, and collaborate with engineers to bring prototypes to production.  Experience with ML techniques like NLP, Machine Vision, Time Series, and AWS Sagemaker is required.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Analytics",
            "Technology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Critical Thinking",
            "Analytical Skills"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Cleansing",
            "Data Structuring",
            "Predictive Modeling",
            "Machine Learning",
            "Clustering",
            "Classification",
            "Model Tuning",
            "Model Validation",
            "Supervised Learning",
            "Unsupervised Learning",
            "Model Development",
            "Data Preparation",
            "Data Exploration",
            "Statistical Analysis",
            "Hypothesis Testing",
            "AWS Sagemaker",
            "Lambda",
            "Glue",
            "Step Functions",
            "EC2",
            "Databricks",
            "Anaconda",
            "Cassandra",
            "Hadoop",
            "Spark",
            "Tableau"
        ],
        "tech_stack": [
            "AWS Sagemaker",
            "Lambda",
            "Glue",
            "Step Functions",
            "EC2",
            "Databricks",
            "Anaconda",
            "Cassandra",
            "Hadoop",
            "Spark",
            "Tableau"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Mathematics",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Florida, United States",
        "job_id": 3969225107,
        "company": "Oscar",
        "title": "Senior Data Scientist",
        "created_on": 1720587589.9514008,
        "description": "Senior Data Scientist 📍 US / Remote | $150,000 - $175,000 + Bonus. About The Business: My client are on a mission to revolutionize banking and make money work for everyone. They simplify the complexities of traditional banking by combining the best product options for credit, debit and savings. This is also combined with financial education on social media and award-winning customer assistance. It isn't simply a service, it's a way of improving financial literacy for all ❤️ What You'll Be Working On: Collaborating with data scientists, analysts, analytics engineers, CRM managers, and product teams to enhance the CRM function. Using your expertise in analytics and data storytelling to understand user interactions and inform our communication strategy. Guiding CRM teams in measuring critical metrics and running A/B experiments to improve our communications. Working with the finance team to develop a unified understanding of user lifetime value and the impact of communication strategies. Ensuring we collect relevant data for valuable business insights. Your Day-to-Day: Apply your analytics, data science, and storytelling skills to gain insights into user behavior. Support CRM teams in measuring important metrics and conducting A/B experiments. Collaborate with the finance team to understand user lifetime value and the impact of communications. Work with engineers to ensure we collect the right data. You Should Apply If: You're excited about playing an active role in a wider mission! You're impact-driven and eager to positively influence the company, product, users, and colleagues. You're commercially minded and can translate numbers into business insights. You're comfortable with both hands-on work and strategic thinking. You have a proactive mindset and identify opportunities without being prompted. Exposure deploying models to the Cloud (AWS and it's attached services). You have strong skills in SQL, DBT, Looker, and Python. You have experience with large-scale A/B experiments, especially in CRM or engagement-focused teams. You have excellent presentation and communication skills and enjoy turning data into accessible stories for stakeholders. The Interview Process: Our process includes: A chat with myself or one of the Oscar team. Initial call with the hiring manager A take-home task Final interviews including a case study and collaboration interview We aim to complete the process within 2-3 weeks but are flexible to accommodate your availability. However, with the hiring manager having an apetite to move swiftly....what are you waiting for ✨ Desired Skills and Experience AWS, Python, Scikit-Learn, Sagemaker, Vertex AI Oscar Associates Limited (US) is acting as an Employment Agency in relation to this vacancy.",
        "url": "https://www.linkedin.com/jobs/view/3969225107",
        "summary": "Senior Data Scientist to enhance CRM function, analyze user interactions, inform communication strategy, measure key metrics, run A/B experiments, develop understanding of user lifetime value, and ensure data collection for valuable business insights.",
        "industries": [
            "FinTech",
            "Banking",
            "Financial Services"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Data Storytelling",
            "Analytical Thinking",
            "Strategic Thinking",
            "Impact-Driven",
            "Commercial Mindset",
            "Proactive",
            "Problem-Solving"
        ],
        "hard_skills": [
            "SQL",
            "DBT",
            "Looker",
            "Python",
            "A/B Testing",
            "CRM",
            "User Lifetime Value",
            "Data Collection",
            "Data Science",
            "Analytics"
        ],
        "tech_stack": [
            "AWS",
            "Scikit-Learn",
            "Sagemaker",
            "Vertex AI"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 175000,
            "min": 150000
        },
        "benefits": [
            "Bonus"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Nashua, NH",
        "job_id": 3840135034,
        "company": "Syntricate Technologies",
        "title": "Data Scientist",
        "created_on": 1720587593.9444354,
        "description": "Hi Hello, Greetings from Syntricate Technologies ......! Hope you are doing great... I This is Gaurav from Syntricate Technologies. I have some urgent requirements with one of my clients. Please go through the Job Description and let me know your interest. Below is the job Details. Title: Data Scientist Location: Tampa FL/ Dallas TX/ Remote Fulltime Job Description Must Have Preferred Knowledge/Skills Demonstrates some abilities and/or a proven record of success with identifying and addressing client needs using the following techniques, tools and programs: Machine Learning; Deep Learning; Natural Language Processing (NLP); Generative AI; Programming skills (e.g., Python, R, Java, SQL, Jupyter Notebooks, IDEs); Data wrangling/modeling; Structured data storage technologies (e.g., SQL Server, PostgreSQL); Unstructured data storage technologies (e.g., MongoDB, Neo4j); Big data tools (e.g., Hadoop, Spark/PySpark, Kafka); Testing tool experiences (e.g., Selenium, Cucumber, Postman); Visualization tools (e.g., Tableau, Zoomdata, PowerBI); DevOps technologies & tools (e.g., Git, Jenkins, Docker/Kubernetes); Cloud Platforms (e.g., Azure, AWS, GCP); and, Scrum/Agile Methodologies. Roles & Responsibilities Collecting, processing, and analyzing large and complex data sets. Developing predictive models and algorithms to derive insights from data. Collaborating with cross-functional teams to understand business requirements and deliver actionable insights. Presenting the results in a clear and interesting way. Good To Have Must have exposure in Agile projects with knowledge of Azure DevOps and Agile tools. Best Regards, Gaurav Sharma Sr. Talent Acquisition Specialist Syntricate Technologies Inc. Burlington, MA =� Phone: (781) 896-2155 Ext- 126 =� Email : gaurav@syntricatetechnologies.com SYNTRICATE Technologies",
        "url": "https://www.linkedin.com/jobs/view/3840135034",
        "summary": "Data Scientist needed to collect, process, analyze, and model data to derive insights.  Must have experience with Machine Learning, Deep Learning, NLP, Generative AI, Python, R, Java, SQL, and various data storage, big data, testing, visualization, DevOps, and cloud platform technologies. Agile experience with Azure DevOps and Agile tools is a plus.",
        "industries": [
            "Data Science",
            "Analytics",
            "Technology"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing",
            "Generative AI",
            "Python",
            "R",
            "Java",
            "SQL",
            "Jupyter Notebooks",
            "IDEs",
            "Data Wrangling",
            "Data Modeling",
            "SQL Server",
            "PostgreSQL",
            "MongoDB",
            "Neo4j",
            "Hadoop",
            "Spark",
            "PySpark",
            "Kafka",
            "Selenium",
            "Cucumber",
            "Postman",
            "Tableau",
            "Zoomdata",
            "PowerBI",
            "Git",
            "Jenkins",
            "Docker",
            "Kubernetes",
            "Azure",
            "AWS",
            "GCP",
            "Scrum",
            "Agile"
        ],
        "tech_stack": [
            "Machine Learning",
            "Deep Learning",
            "NLP",
            "Generative AI",
            "Python",
            "R",
            "Java",
            "SQL",
            "Jupyter Notebooks",
            "IDEs",
            "SQL Server",
            "PostgreSQL",
            "MongoDB",
            "Neo4j",
            "Hadoop",
            "Spark",
            "PySpark",
            "Kafka",
            "Selenium",
            "Cucumber",
            "Postman",
            "Tableau",
            "Zoomdata",
            "PowerBI",
            "Git",
            "Jenkins",
            "Docker",
            "Kubernetes",
            "Azure",
            "AWS",
            "GCP"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Java",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Bentonville, AR",
        "job_id": 3913490975,
        "company": "Syntricate Technologies",
        "title": "Data Scientist",
        "created_on": 1720587599.2320073,
        "description": "Hi, Hope you are doing well Number of position : 3 Only Full Time no C2C and No Contract Full-time I, Shakib (i3 infotek) would like to share a job opportunity as Data Scientist based in Bentonville, AR (Onsite) location for a Full-time position. In case, if you are not comfortable with this location, please share your preference with contact details for further requirements *** Kindly find the JD below and let me know if you are available for the same. Job tittle - Data Scientist Job Location: Bentonville, AR (Onsite) Duration: Full-time Job Description AI/Client model deployment/implementation skills are must for Walmart Expertise with classical Client algorithm like K-NN, LSH, logistic regression, linear regression, SVM, Random forest and clustering. Good understanding of Client & DL algorithms and frameworks (Scikit-learn,Spacy, Tensorflow/Keras/ PyTorch) Experience in deep learning Algorithms like MLP, CNN, RNN, LSTMs and GANs, Transformers and LLMs. Excellent programming skills in Python Expertise in Google Cloud and operationalization of models using MLOPs. Proven experience in deploying real-time AI/Client models using Google Cloud Platform. Strong programming skills in Python and PySpark. Proficiency with SQL and relational databases, data warehouses, and BigQuery. Experience in scaling marketing-related AI/Client solutions such as cross/upsell, recommended systems, and category propensity. Experience in deploying and managing Large scale Machine Learning Models is a plus Expertise with classical Client algorithm like K-NN, LSH, logistic regression, linear regression, SVM, Random forest and clustering. Good understanding of Client & DL algorithms and frameworks (Scikit-learn,Spacy, Tensorflow/Keras/ PyTorch) Experience in deep learning Algorithms like MLP, CNN, RNN, LSTMs and GANs, Transformers and LLMs. Excellent programming skills in Python Expertise in Google Cloud and operationalization of models using MLOPs. Experience in scheduling jobs for automated training and inference of AI/Client models using airflow or any other workflow orchestration platform. Proficiency in collecting data from different data sources, data cleaning, preprocessing, and feature engineering. Understanding of regression, classification, and unsupervised Client algorithms. Experience in mentoring junior associates in scaling AI/Client models. Excellent problem-solving and analytical skills. Strong written and verbal communication skills, with the ability to present and explain complex concepts to both technical and non-technical audiences. Please reply me with your updated resume and required details: Full Name Best number to reach you: Work Authorization/Visa Status Current Location: Expected Compensation Best time to call you: Waiting for your earliest response Sincerely, Mohd Shakib Sr. Technical Recruiter Direct: 781-896-2153 Address: 1500 District Avenue, Ste. 4135, Burlington, MA 01803",
        "url": "https://www.linkedin.com/jobs/view/3913490975",
        "summary": "Data Scientist needed for Walmart in Bentonville, AR. Role requires expertise in machine learning algorithms and frameworks, deep learning, Python, Google Cloud Platform, and MLOps. Experience with large-scale model deployment and mentoring junior associates is a plus.",
        "industries": [
            "Retail",
            "E-commerce",
            "Technology"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Communication",
            "Presentation",
            "Mentoring"
        ],
        "hard_skills": [
            "K-NN",
            "LSH",
            "Logistic Regression",
            "Linear Regression",
            "SVM",
            "Random Forest",
            "Clustering",
            "Scikit-learn",
            "Spacy",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "MLP",
            "CNN",
            "RNN",
            "LSTMs",
            "GANs",
            "Transformers",
            "LLMs",
            "Python",
            "PySpark",
            "SQL",
            "BigQuery",
            "Airflow",
            "Data Cleaning",
            "Preprocessing",
            "Feature Engineering",
            "Regression",
            "Classification",
            "Unsupervised Machine Learning"
        ],
        "tech_stack": [
            "Google Cloud Platform",
            "MLOps",
            "Airflow",
            "BigQuery",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Scikit-learn",
            "Spacy"
        ],
        "programming_languages": [
            "Python",
            "PySpark",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Texas, United States",
        "job_id": 3958364905,
        "company": "AgnesCole Consulting",
        "title": "Data Scientist",
        "created_on": 1720587601.972463,
        "description": "Data Scientist - Optimization A globally recognised client of ours in Texas is looking for a Data Scientist to join their team on a full-time basis. The Data Scientist will be an experienced professional with exceptional optimization skills and a robust background in data science to drive the development of their Digital Transformation. This is an excellent opportunity to make your mark on a globally recognised organisation. Do you have? 8+ years of Implementing and Developing optimization algorithms Experience using Linear programming, Mixed Integer programming and heuristics Python, C++ and build automation Background using optimization libraries including CPLEX / Gurobi Strong interpersonal skills, attention to detail, and ability to prioritize tasks effectively. Do you want? The chance to make an impact on a globally recognized client? Work with the latest cut edge technology? Have a clear progression path? Is so please apply now! Please note – Client is unable to provide sponsorship for this role Candidates must be based in Texas Data Scientist | Optimizations | CPLEX | Gurobi | ML | Python | Supply Chain",
        "url": "https://www.linkedin.com/jobs/view/3958364905",
        "summary": "A globally recognized client in Texas seeks a Data Scientist with 8+ years of experience implementing and developing optimization algorithms, specifically using Linear programming, Mixed Integer programming and heuristics. The role requires proficiency in Python, C++, build automation, and optimization libraries like CPLEX and Gurobi.  Strong communication, attention to detail, and prioritization skills are essential.",
        "industries": [
            "Technology",
            "Supply Chain",
            "Digital Transformation"
        ],
        "soft_skills": [
            "Strong Interpersonal Skills",
            "Attention to Detail",
            "Prioritization"
        ],
        "hard_skills": [
            "Optimization Algorithms",
            "Linear Programming",
            "Mixed Integer Programming",
            "Heuristics",
            "Python",
            "C++",
            "Build Automation",
            "CPLEX",
            "Gurobi"
        ],
        "tech_stack": [
            "CPLEX",
            "Gurobi",
            "Python",
            "C++"
        ],
        "programming_languages": [
            "Python",
            "C++"
        ],
        "experience": 8,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Tempe, AZ",
        "job_id": 3963086341,
        "company": "Gen",
        "title": "Senior Data Scientist",
        "created_on": 1720587603.381705,
        "description": "About Gen: Gen is a global company powering Digital Freedom through consumer brands including Norton, Avast, LifeLock, Avira, AVG, ReputationDefender, and CCleaner. Our combined heritage is rooted in providing safety for the first digital generations. We bring leading technology solutions in cybersecurity, privacy and identity protection to more than 500 million users in 150 countries so they can live their digital lives safely, privately, and confidently today and for generations to come. We're always looking for smart, fearless, and dedicated people. Together, we have collective passion and a big vision to power Digital Freedom by protecting consumers and giving them control of their digital lives. When you’re a part of Gen, you are provided access to a range of resources and support to ensure you can do your best work and live your best life. This includes flexible working options with generous time off and competitive benefits & compensation packages. Diversity is foundational to how we do business because we know the greatest ideas and results come from our unique perspectives and differences. We strive to create a safe, inclusive environment where you can bring your whole self to work. Team members are valued, respected, and celebrated for who they are in a meaningful and exciting atmosphere. Gen is an equal employment opportunity employer. Employment decisions are based on merit, experience, and business needs. If this sounds like you—Gen has a dynamic, supportive culture with core values that celebrate diversity, promote teamwork, and encourage every team member to contribute and grow—join us! HYBRID ROLE: 3x/week in the Tempe, AZ office About the Role: For our Analytics and Data Science team in Tempe, Arizona we're seeking a highly motivated Senior Data Scientist to join our dynamic team and play a key role in unlocking the power of our data. In this senior role, the candidate will go beyond building models – he/she will partner with stakeholders across the business to identify strategic opportunities and leverage the expertise in machine learning, statistical analysis, and data visualization to design and implement innovative solutions that solve real-world problems and propel our business forward. We expect the successful candidate to have a degree in a quantitative field from a leading university and at least 5 years of experience in a relevant position. Fluent English is required. What You Will Do in This Role: Lead and execute data science projects from conception to deployment, ensuring they align with business goals. Design, develop, and implement machine learning models to solve complex business problems and predict future outcomes. Collaborate with business stakeholders to understand their needs and translate data into actionable strategies. Clean, transform, and analyze large datasets from various sources, ensuring data quality and consistency. Develop and maintain a scalable and robust data science infrastructure. Communicate complex technical concepts to a non-technical audience in a clear and concise manner. Requirements : Graduate degree in physics, computer science, engineering, mathematics, statistics, or related field; alternatively, a comparable industry career with a proven track record of successful AI/ML/DS projects in production. Responsible for data preparation and analysis of complex SQL queries to become a SME of data sources for brand(s). Experience in any of the following frameworks or libraries for model development: TensorFlow, PyTorch, Keras, Vertex AI, PySpark, MPI, Pandas/NumPy/SciPy/Scikit-learn, Stan, R, MATLAB (or others not listed). Experience in using cloud services and platforms, such as GCP, Azure, AWS, etc. Curiosity, strong analytical mind, willingness to learn and desire to make an impact. Excellent communication and presentation skills. Ability to work independently and in a team. Preferred Qualifications: Experience in continuous integration/deployment (CI/CD) best practices Experience with experimental design Gen is proud to be an equal-opportunity employer. We celebrate diversity and are committed to creating an inclusive and accessible environment for all employees. All employment decisions are based on merit, experience, and business needs, without regard to race, color, national origin, age, religion, sex, pregnancy (including childbirth or related medical conditions), genetic information, disability (physical or mental), medical condition, marital status, sexual orientation, gender identity or gender expression, military or veteran status, or any other consideration made unlawful by federal, state, or local law. Gen strictly prohibits unlawful discrimination based on such protected characteristics and seeks to recruit the most talented candidates from diverse cultures and backgrounds. We also consider employment-qualified individuals with arrest and conviction records. In addition, we will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Learn more about pay transparency. Gen complies with all anti-discrimination laws. To conform to U.S. export control regulations, applicant should be eligible for any required authorizations from the U.S. Government.",
        "url": "https://www.linkedin.com/jobs/view/3963086341",
        "summary": "Gen, a global leader in cybersecurity, privacy, and identity protection, is seeking a Senior Data Scientist to join their Analytics and Data Science team in Tempe, Arizona. This role will involve leading and executing data science projects, building machine learning models, collaborating with stakeholders, and analyzing large datasets. The ideal candidate will have a graduate degree in a quantitative field and 5+ years of relevant experience.",
        "industries": [
            "Cybersecurity",
            "Privacy",
            "Identity Protection",
            "Software",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Collaboration",
            "Teamwork",
            "Analytical",
            "Problem-Solving",
            "Curiosity",
            "Initiative",
            "Leadership",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "Statistical Analysis",
            "Data Visualization",
            "SQL",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "Vertex AI",
            "PySpark",
            "MPI",
            "Pandas",
            "NumPy",
            "SciPy",
            "Scikit-learn",
            "Stan",
            "R",
            "MATLAB",
            "Cloud Services",
            "GCP",
            "Azure",
            "AWS",
            "CI/CD",
            "Experimental Design"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "Keras",
            "Vertex AI",
            "PySpark",
            "MPI",
            "Pandas",
            "NumPy",
            "SciPy",
            "Scikit-learn",
            "Stan",
            "R",
            "MATLAB",
            "GCP",
            "Azure",
            "AWS"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R",
            "MATLAB"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Physics",
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Flexible Working Options",
            "Generous Time Off",
            "Competitive Benefits",
            "Compensation Packages"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Orlando, FL",
        "job_id": 3963897673,
        "company": "ONE Agency",
        "title": "Data Scientist",
        "created_on": 1720587604.8622818,
        "description": "Data Scientist - Digital Customer Acquisition Agency (Orlando, FL) About ONE Agency ONE Agency (visit us at oneagency.com) is a performance based digital marketing agency specializing in helping companies hyperscale their digital customer acquisition results. Leveraging data is our secret sauce. We maintain our own proprietary pixel allowing for behavioral analysis and our own data cloud (MyONEdatacloud), an aggregation of 1st party behavioral and targeting data as well as licensed 3rd party data enabling robust lead profile data enrichment. ONE Agency is the largest digital agency in the Resort Vacation Ownership sector representing many of the world’s largest hospitality brands and is now rapidly expanding into other B2C verticals. We are a full service digital agency with an exceptional in-house team of senior creatives, media buyers, analysts, coders, developers, product engineers, strategists and business builders. We're a passionate team of performance marketing experts who leverage bleeding-edge data science and marketing strategies to help our clients achieve explosive growth. In this fast-paced role designed for growth and upward opportunity, you'll play a pivotal role in unlocking the power of data to fuel our clients' success. As a Data Scientist, you'll be responsible for analyzing massive datasets, building sophisticated models, and providing actionable insights to optimize our client acquisition campaigns. Responsibilities: Design, develop, and implement machine learning models to segment and target audiences based on first and third-party data sources Analyze audience patterns and identify key commonalities to inform marketing strategies Develop and maintain data pipelines to ensure clean and accessible data for analysis Leverage Google BigQuery, MySQL and other Databases to perform complex data analysis and reporting Collaborate with marketing and business development teams to translate insights into actionable strategies Stay current on the latest data science trends and technologies Communicate complex data findings in a clear and concise manner Expanded Responsibilities: Data Acquisition & Wrangling: Collaborate with marketing and engineering teams to acquire relevant data sets from various sources. Clean, transform, and prepare large datasets for analysis using tools like Python (pandas) and SQL. Ensure data quality and integrity to guarantee reliable results. Artificial Intelligence (AI) Modeling & Analytics: Predictive Analytics: Develop and implement statistical models and machine learning algorithms to predict customer behavior and optimize marketing campaign performance. Analysis: Analyze customer acquisition data to identify trends, patterns, and opportunities for improvement. Visualization: Leverage AI to visualize trends in collected data to help the agency campaign and customer trends to clients. Anomaly detection: Apply AI and machine learning models to historical data to raise real-time alerts for unexpected scenarios, helping the agency improve productivity and reduce the time it takes to resolve issues. Testing: Collaborate with the Campaign Team to conduct A/B testing and other marketing experiments to measure the effectiveness of different strategies. Insights & Communication: Translate complex data analysis into clear and actionable insights that inform client acquisition strategies. Create compelling data visualizations using tools like Tableau or Power BI to communicate findings to both technical and non-technical audiences. Collaborate with marketing teams and executives to ensure data-driven decision making for new customer acquisition efforts. Stay Ahead of the Curve: Continuously learn new data science techniques and technologies to stay at the forefront of the ever-evolving field. Actively participate in the data science community through conferences, workshops, or online resources. Qualifications: Master's degree in Statistics, Data Science, Computer Science, or related field (or Bachelor's degree with equivalent experience). 3+ years of experience as a Data Scientist or similar role, preferably within the digital marketing or advertising industry. Strong proficiency in statistical modeling and machine learning techniques (regression analysis, classification models, clustering). Experience with data wrangling and manipulation tools like Python (pandas, NumPy) and SQL. Excellent communication skills (written and verbal) to effectively present data insights to both technical and non-technical audiences. Business acumen and understanding of how data science can be applied to optimize B2C marketing campaigns. A passion for data-driven decision making and a collaborative spirit. Strong work ethic with the ability to manage time effectively and prioritize tasks in a fast-paced environment. Bonus points for: Experience with big data technologies (Hadoop, Spark) or cloud platforms (AWS, Azure, GCP). Experience with marketing automation platforms (Marketo, Hubspot, Pardot). If you're a data-driven problem-solver with a passion for helping businesses grow, we want to hear from you! Join our team and be a part of our mission to revolutionize B2C customer acquisition with the power of data science.",
        "url": "https://www.linkedin.com/jobs/view/3963897673",
        "summary": "ONE Agency, a digital marketing agency specializing in customer acquisition, seeks a Data Scientist to analyze massive datasets, build sophisticated models, and provide insights to optimize marketing campaigns. The role involves developing machine learning models, analyzing audience patterns, building data pipelines, collaborating with marketing teams, and staying current on data science trends.  The ideal candidate has 3+ years of experience, a strong background in statistical modeling and machine learning, experience with data wrangling tools, excellent communication skills, and a passion for data-driven decision making.",
        "industries": [
            "Marketing",
            "Digital Marketing",
            "Advertising",
            "Data Science",
            "Hospitality"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Data-Driven Decision Making",
            "Passion for Data",
            "Time Management",
            "Prioritization"
        ],
        "hard_skills": [
            "Machine Learning",
            "Regression Analysis",
            "Classification Models",
            "Clustering",
            "Data Wrangling",
            "Python",
            "Pandas",
            "NumPy",
            "SQL",
            "Google BigQuery",
            "MySQL",
            "Tableau",
            "Power BI",
            "A/B Testing"
        ],
        "tech_stack": [
            "Python",
            "Pandas",
            "NumPy",
            "SQL",
            "Google BigQuery",
            "MySQL",
            "Tableau",
            "Power BI",
            "Hadoop",
            "Spark",
            "AWS",
            "Azure",
            "GCP",
            "Marketo",
            "Hubspot",
            "Pardot"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Statistics",
                "Data Science",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967490675,
        "company": "Tror - AI for everyone",
        "title": "Data Scientist",
        "created_on": 1720587606.4057667,
        "description": "Job Title: Data scientist Contract: W2 Visa H1B, OPT Passport number mandatory Tror is actively looking for a highly skilled Senior Data Scientist with a minimum of 8 years of experience to join our dynamic team Responsibilities: ML, Gen AI, NLP, LLM Strategy: Develop and implement ML modeling and LLM development and fine-tuning strategies, best practices, and standards to enhance AI ML model deployment and monitoring efficiency. Develop roadmap and strategy for NLP, LLM, Gen AI model development and lifecycle implementation ML, Gen AI, NLP, LLM Model Design and Development: Responsible for the design and development of custom ML, Gen AI, NLP, LLM Models for batch and stream processing-based AI ML pipelines including data ingestion, preprocessing modules, search and retrieval, Retrieval Augmented Generation (RAG), NLP/LLM model development and ensure the end-to-end solution meets all technical and business requirements, and SLA specifications. Work closely with members of technology and business leads and their teams in the design, development, and implementation of the ML model solutions ML, NLP, LLM Model Evaluation: Work closely with the MLOps team to create and maintain robust evaluation solutions and tools to evaluate model performance, accuracy, consistency, reliability, during development, UAT. Identify and implement model optimizations to improve system efficiency. NLP, LLM, Gen AI Model Deployment: Work closely with the MLOps team for the deployment of machine learning models into production environments, ensuring reliability and scalability. Internal Collaboration: Collaborate closely with product teams, business stakeholders, MLOps, machine learning engineers, and software engineers to ensure smooth integration of machine learning models into production systems. Stakeholder Engagement and Collaboration: Collaborate closely with business and PM stakeholders in roadmap planning and implementation efforts and ensure technical milestones align with business requirements. Mentorship: Recruit, develop and mentor technical AI/ML, NLP, LLM, Gen AI talent on the team Provide guidance and mentorship to junior ML scientists, fostering their professional growth and development. Documentation: Maintain comprehensive documentation of ML modeling processes and procedures for reference and knowledge sharing. Standards and Best Practices: Ensure the use of standards, governance and best practices in ML model development, and adherence to model and data governance standards. Problem Solving: Troubleshoot complex issues related to machine learning model development and data pipelines and develop innovative solutions. Requirements: 8+ years of professional hands-on experience leveraging large sets of structured and unstructured data to develop data-driven tactical and strategic analytics and insights using ML, NLP, computer vision solutions. Demonstrated 4+ years hands-on experience with Python, Hugging Face, TensorFlow, Keras, PyTorch, Spark or similar statistical tools. Expert in python programming. 4 or more years project leadership experience including Agile project management, Scaled Agile Frameworks (SAFE) 5+ years hands-on experience developing natural language processing (NLP) models, ideally with transformer architectures. 5+ year's experience with implementing information search and retrieval at scale, using a range of solutions ranging from keyword search to semantic search using embeddings. Strong knowledge of and measurable hands-on experience with developing or tuning Large Language Models (LLM) and Generative AI (GAI) Experience in creating reports, projections, models, and presentations to support business goals and outcomes. Ability to exercise independent judgment and decision making on complex issues regarding initiatives, technical and business goals and related tasks. Experience with mentoring junior ML scientists, Ability to works under minimal supervision, using independent judgment. Excellent written & verbal communication and stakeholder management skill Strategic thinker and influencer with demonstrated technical and business acumen and problem-solving skills. Experienced with NLP, LLMs (extractive and generative), fine-tuning and LLM model development. Strong familiarity with higher level trends in LLMs and open-source platforms Must have: LLM NLP Computer vision",
        "url": "https://www.linkedin.com/jobs/view/3967490675",
        "summary": "Tror is looking for a Senior Data Scientist with 8+ years of experience in developing and implementing machine learning, natural language processing (NLP), and large language models (LLM). The role involves designing and developing custom models for AI/ML pipelines, evaluating model performance, deploying models into production environments, and collaborating with stakeholders.  Experience with Python, Hugging Face, TensorFlow, Keras, PyTorch, Spark, and Agile project management is required.  This position requires strong knowledge of NLP, LLMs, and generative AI, as well as experience in fine-tuning and developing LLM models.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Problem Solving",
            "Strategic Thinking",
            "Communication",
            "Collaboration",
            "Leadership",
            "Mentorship",
            "Independent Judgement",
            "Decision Making",
            "Stakeholder Management"
        ],
        "hard_skills": [
            "Python",
            "Hugging Face",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Spark",
            "NLP",
            "LLM",
            "Generative AI",
            "Machine Learning",
            "Computer Vision",
            "Model Development",
            "Model Deployment",
            "Model Evaluation",
            "Agile Project Management",
            "Scaled Agile Framework (SAFE)",
            "Information Search and Retrieval",
            "Data Ingestion",
            "Data Preprocessing",
            "Search and Retrieval",
            "Retrieval Augmented Generation (RAG)",
            "Model Optimization",
            "Data Pipelines",
            "Reporting",
            "Projections",
            "Modeling",
            "Presentations"
        ],
        "tech_stack": [
            "Python",
            "Hugging Face",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Spark",
            "NLP",
            "LLM",
            "Generative AI",
            "Machine Learning",
            "Computer Vision",
            "Agile Project Management",
            "Scaled Agile Framework (SAFE)"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3966454598,
        "company": "Cotiviti",
        "title": "Data Scientist I",
        "created_on": 1720587607.9529672,
        "description": "Overview The Data Scientist I is focused on machine learning solutions in Healthcare Technology and builds value-oriented, production level machine learning solutions. This is not a research oriented data scientist; instead you will apply your knowledge and experience to real world problems, and seek to utilize Artificial Intelligence and Machine Learning to reduce the cost of healthcare and improve health quality and outcomes. With access to dedicated on premise and cloud based big data solutions, the team can work with a vast amount of structured and unstructured data including claims, membership, physician demographics, medical records and others to begin to solve some of the most pressing healthcare issues of our time. A Data Scientist at Cotiviti will be given the opportunity to work directly with a team of healthcare professionals including analysts, clinicians, coding specialists, auditors and innovators to set aggressive goals and execute on them with the team. This is for an ambitious technologist, with the flexibility and personal drive to succeed in a dynamic environment where they are judged based on their direct impact to business outcomes. Responsibilities As a Data Scientist within Cotiviti you will be responsible for delivering solutions that help our clients identify payment integrity issues, reduce the cost of healthcare processes, or improve the quality of healthcare outcomes. You will work as part of a team and will be individually responsible for the delivery of value associated with your projects. You will be expected to follow processes and practices that allow your models to be incorporated into our machine learning platform for production execution and monitoring, however, initial exploratory data analysis allows for more flexible experimentation to discover solutions to the business problems presented. Create actionable and pragmatic data science models with minimal supervision. Understands business needs and identifies potential use cases in more than one business unit. Works with external partners to develop a minimal viable product to meet those needs while resolving any issues that may arise. Consistently collaborates with fellow data scientists and frequently interacts with business partners, project managers, cross-functional teams, key stakeholders, and other domains to build analytics capabilities and drive business value. Continuously work to be updated on the latest developments in machine learning and the healthcare industry. Work with key stakeholders both within R&D and Operations, along with product management to assess the potential value and risks associated with business problems that have the potential to be solved using machine learning and AI techniques. Develop an exploratory data analysis approach to verify the initial hypothesis associated with potential AI/ML use cases. Document your approach, thinking and results in standard approaches to allow other data scientists to collaborate with you on this work. Prepare your final trained model and develop a validation test set for QA. Work with production operations to deploy your model into production and support them in monitoring model performance. Participate in other data science teams collaborating with your peers to support their projects Participate in knowledge sharing sessions to bring new insights and technologies to the team. Participate in design sessions to continuously develop and improve the Cotiviti machine learning platform Provide End to End value-based solutions, including data pipeline, model creation and application for end user Qualifications Applied Machine Learning: Application of a variety of machine learning techniques to increase identification of payment integrity issues for our clients, reduce the cost of auditing processes or increase the quality of care and outcomes. Must have implemented machine learning solutions within production environments at scale Big Data Analysis: Strong ability to manage and analyze data in a Big Data environment using a variety of scripts, potentially including but not limited to Scala/Spark and Python as well as Cloud based ML/AI capabilities. Reasoning and Problem Solving: Ability to actively and skillfully conceptualize, apply, analyze, synthesize, and/or evaluate information gathered from, or generated by, observation, experience, reflection, reasoning, or communication, as a guide to belief and action Consulting: Demonstrated ability to make and gain acceptance of data-driven recommendations made to business owners. Strong ability to appropriately summarize and effectively communicate complex concepts & varied data sets to inform stakeholders, gain approval, or prompt actions; Applies to multiple audiences ranging from the analyst to executive level; Includes oral & written communication and multimedia presentation Statistical Analysis: Apply statistical methodology to solve business problems; appropriately interprets meaning from results Business Knowledge: Good understanding of the tenets of health insurance, the managed care model, industry coding/policy standards, the claim adjudication process, and issues related to fraud waste and abuse. Ability to apply this knowledge to the development & evaluation of new initiatives and support leading the team strategy toward best practices. Financial Analysis: Ability to understand, generate and evaluate healthcare utilization, unit cost and medical cost trends. This includes understanding levers that effect healthcare cost, such as contracting, networks, policies, benefit structures, and product design. Ability to draw conclusions and make recommendations based on financial data Functional Programming: Ability to work with, understand and create object oriented/functional programming solutions using modern application frameworks. Minimum Qualifications MS or PhD. Degree in relevant discipline (Math, Statistics, Computer Science, Engineering or Health Sciences) or commensurate professional work experience. 1-3 years experience building and deploying Machine learning models 1-3 years experience in working in Big Data environments Experience developing machine learning models in an exploratory data analytics environment and working with others to develop production ready versions of the models that are deployed within operational environments Experience in using machine learning tools to develop production strength models including, but not limited to, Python, TensorFlow, Keraes, pandas, numpy, scikit-learn, spark, scala, hive, impala Ability to write SQL queries to efficiently extract data from relational databases Ability to work independently as well as collaborate as a team Flexibility to work with global teams as well geographically dispersed US based teams Professional with ability to properly handle confidential information Be value-driven, understand that success is based on the impact of your work rather than its complexity or the level of effort. Ability to handle multiple tasks, prioritize and meet deadlines Ability to work within a matrixed organization Proficiency in all required skills and competencies above Mental Requirements Reasoning and Problem Solving: Ability to actively and skillfully conceptualize, apply, analyze, synthesize, and/or evaluate information gathered from, or generated by, observation, experience, reflection, reasoning, or communication, as a guide to belief and action. Consulting: Demonstrated ability to make and gain acceptance of data-driven recommendations made to business owners. Strong ability to appropriately summarize and effectively communicate complex concepts & varied data sets to inform stakeholders, gain approval, or prompt actions; Applies to multiple audiences ranging from the analyst to executive level; Includes oral & written communication and multimedia presentation. Statistical Analysis: Apply statistical methodology to solve business problems; appropriately interpret meaning from results. Business Knowledge: Good understanding of the tenets of health insurance, the managed care model, industry coding/policy standards, the claim adjudication process, and issues related to fraud, waste, and abuse. Ability to apply this knowledge to the development & evaluation of new initiatives and support leading the team strategy toward best practices. Financial Analysis: Ability to understand, generate, and evaluate healthcare utilization, unit cost, and medical cost trends. This includes understanding levers affecting healthcare costs, such as contracting, networks, policies, benefit structures, and product design. Ability to draw conclusions and make recommendations based on financial data. Functional Programming: Ability to work with, understand, and create object oriented/functional programming solutions using modern application frameworks. Ability to work independently as well as collaborate as a team. Flexibility to work with global teams as well geographically dispersed US based teams. Professional with ability to properly handle confidential information. Be value-driven, understand that success is based on the impact of your work rather than its complexity or the level of effort. Ability to handle multiple tasks, prioritize and meet deadlines. Ability to work within a matrixed organization. Proficiency in all required skills and competencies above. Physical Requirements And Working Conditions Remaining in a stationary position, often standing or sitting for prolonged periods. Repeating motions that may include the wrists, hands, and/or fingers. Must be able to provide a dedicated, secure work area. Must be able to provide high-speed internet access/connectivity and office setup and maintenance. Base compensation ranges from $93,000.00 to $115,000.00. Specific offers are determined by various factors, such as experience, education, skills, certifications, and other business needs. Cotiviti offers team members a competitive benefits package to address a wide range of personal and family needs, including medical, dental, vision, disability, and life insurance coverage, 401(k) savings plans, paid family leave, 9 paid holidays per year, and 17-27 days of Paid Time Off (PTO) per year, depending on specific level and length of service with Cotiviti. For information about our benefits package, please refer to our Careers page. Since this job will be based remotely, all interviews will be conducted virtually. Date of posting: 2/6/2024 Applications are assessed on a rolling basis. We anticipate that the application window will close on 4/6/2024, but the application window may change depending on the volume of applications received or close immediately if a qualified candidate is selected. #senior",
        "url": "https://www.linkedin.com/jobs/view/3966454598",
        "summary": "Cotiviti is seeking a Data Scientist I to build production-level machine learning solutions for the healthcare industry. The role focuses on applying AI and ML to reduce healthcare costs and improve health outcomes using large datasets. The Data Scientist will collaborate with healthcare professionals, develop models, deploy them in production, and continuously monitor their performance.",
        "industries": [
            "Healthcare",
            "Healthcare Technology",
            "Health Insurance",
            "Managed Care",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Big Data",
            "Analytics"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Consulting",
            "Presentation Skills",
            "Time Management",
            "Prioritization",
            "Organization",
            "Detail-Oriented",
            "Flexibility",
            "Adaptability",
            "Self-Motivation",
            "Independent Thinking",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "Big Data Analysis",
            "Python",
            "TensorFlow",
            "Keras",
            "Pandas",
            "NumPy",
            "Scikit-Learn",
            "Spark",
            "Scala",
            "Hive",
            "Impala",
            "SQL",
            "Statistical Analysis",
            "Health Insurance",
            "Managed Care",
            "Claim Adjudication",
            "Fraud Detection",
            "Financial Analysis",
            "Object-Oriented Programming",
            "Functional Programming"
        ],
        "tech_stack": [
            "Python",
            "TensorFlow",
            "Keras",
            "Pandas",
            "NumPy",
            "Scikit-Learn",
            "Spark",
            "Scala",
            "Hive",
            "Impala",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "Scala",
            "SQL"
        ],
        "experience": 1,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Math",
                "Statistics",
                "Computer Science",
                "Engineering",
                "Health Sciences"
            ]
        },
        "salary": {
            "max": 115000,
            "min": 93000
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Disability",
            "Life Insurance",
            "401(k)",
            "Paid Family Leave",
            "Paid Holidays",
            "Paid Time Off"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Boston, MA",
        "job_id": 3961346301,
        "company": "CodaMetrix",
        "title": "Data Scientist II",
        "created_on": 1720587609.3320866,
        "description": "CodaMetrix is revolutionizing Revenue Cycle Management with its AI-powered autonomous coding solution, a multi-specialty AI-platform that translates clinical information into accurate sets of medical codes. CodaMetrix’s autonomous coding supports improved patient care and drives efficiency under fee-for-service and value-based care models. We are passionate about getting doctors away from the keyboard and back to clinical care. Job Description At CodaMetrix, the machine learning and AI team is responsible for the invention, analysis, and deployment of new machine learning and AI-driven solutions using healthcare data to improve administrative and clinical medicine. We are looking for a highly talented individual to join our machine learning team and focus on innovating and developing novel statistical / machine learning solutions for healthcare problems. As a Machine Learning Data Scientist, you can take advantage of our unique Amazon Web Services-based machine learning infrastructure, as well as large labeled clinical datasets to develop your ideas in the form of proof of concepts, and furthermore, translate them to product features with the help of our highly experienced team of engineers. The Machine Learning Data Scientist will report to the Chief Data Scientist. This is a fast-paced, collaborative, and iterative environment requiring quick learning, agility, and flexibility. Responsibilities Innovate, implement, and test machine learning and deep learning techniques at scale. Analyze the quality and calibration of predictive models. Collaborate with machine learning and engineering team members for deployment of new machine learning techniques, and follow deployments tracking issues and successes Interface with medical coders, administrators, radiologists, and physicians to understand the strengths and weaknesses of existing products and to help develop new machine learning-empowered products. Requirements Ph.D. in Computer Science, Mathematics, Statistics, or related field or M.S. with a minimum of two years of related work experience in ML and AI Hands on experience with the state-of-the-art machine learning techniques, and understanding of the analysis and testing processes of machine learning techniques Familiarity with deep learning approaches such as CNN, RNN, and LSTM Proficiency in Python and Jupyter notebooks Demonstrated end-to-end project leadership Strong verbal, visual, and written communication skills Beneficial Experience Demonstrable experience with state-of-the-art Natural Language Processing techniques such as transformers and Large Language Models Publications in major ML/NLP conferences, and/or participation in Kaggle or similar competitions Knowledge of U.S. healthcare systems Experience with common Amazon Web Services (AWS) products such as EC2, SageMaker, and Lambda Experience with DataBricks Full-Time Employee Benefits Learn more about how we take care of our team. Insurance: We cover 80% of the cost of medical and dental insurance and offer vision insurance Retirement: CMX offers a 401(k) plan that eligible employees can contribute to one month after their first day Life: We offer employer-paid life insurance and short-term and long-term disability insurance Flexibility: We have an unlimited PTO policy so you can take the time you need to relax and rejuvenate Learning: All new hires complete our 7-week Fellowship program to learn about each of our departments Development: We provide annual performance evaluations and outline a clear path for promotions Engagement: We host recurring events like Meditation Mondays, CMX Connections and Socials Recognition: We recognize quarterly You've Been Awesome winners and celebrate our team's service milestones Background Check All candidates will be required to complete a background check upon acceptance of a job offer. Equal Employment Opportunity Our company, as well as our products, are made better because we embrace diverse skills, perspectives, and ideas. CodaMetrix is an Equal Employment Opportunity Employer and all qualified applicants will receive consideration for employment. Powered by JazzHR mqen047BbH",
        "url": "https://www.linkedin.com/jobs/view/3961346301",
        "summary": "CodaMetrix is seeking a Machine Learning Data Scientist to develop and deploy novel statistical and machine learning solutions for healthcare problems. The role involves innovating and implementing machine learning techniques, analyzing model quality, collaborating with engineers, and interfacing with medical professionals to improve existing products and develop new ones. The ideal candidate will have a PhD or MS in a related field with experience in machine learning, deep learning, and NLP, along with proficiency in Python and Jupyter notebooks.",
        "industries": [
            "Healthcare",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Revenue Cycle Management",
            "Medical Coding"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Leadership",
            "Problem Solving",
            "Analytical Skills",
            "Quick Learning",
            "Agility",
            "Flexibility",
            "Critical Thinking",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing",
            "Python",
            "Jupyter Notebooks",
            "CNN",
            "RNN",
            "LSTM",
            "Transformers",
            "Large Language Models",
            "AWS",
            "EC2",
            "SageMaker",
            "Lambda",
            "DataBricks"
        ],
        "tech_stack": [
            "Amazon Web Services (AWS)",
            "EC2",
            "SageMaker",
            "Lambda",
            "DataBricks",
            "Python",
            "Jupyter Notebooks"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "401(k)",
            "Life Insurance",
            "Disability Insurance",
            "Unlimited PTO",
            "Fellowship Program",
            "Performance Evaluations",
            "Promotion Opportunities",
            "Meditation Mondays",
            "CMX Connections",
            "Socials",
            "Quarterly Recognition",
            "Service Milestone Celebrations"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York City Metropolitan Area",
        "job_id": 3963166431,
        "company": "InVitro Cell Research, LLC",
        "title": "Associate Data Scientist",
        "created_on": 1720587611.0290082,
        "description": "ICR is hiring Associate Data Scientists to work with our Translational Bioinformatics Team . We're applying data analytics and cutting-edge machine learning to multi-omic human disease datasets to find diagnostic signatures and actionable targets for drug development. Because you will be working with biomedical datasets, a background in biomedical sciences is required . These are three-year, fixed-term positions. Please notice that this is not a financial-sector job , thanks. With ICR, you'll get to: Apply cutting-edge data analysis and machine learning techniques to help diagnose and treat rare and hard-to-diagnose diseases Be part of a team working to improve the lives of millions of people Use your creativity to solve challenging problems Please apply if you have: A recent BS or MS degree Outstanding programming skills (R and Python fluency preferred) Deep knowledge of predictive modeling and probability statistics An understanding of the difference between predicting observables versus estimating parameters A practical and theoretical understanding of \"scoring rules\" The ability to work in the United States without sponsorship A can-do attitude and a friendly, easygoing personality Position title and compensation are commensurate with experience. The compensation ranges listed below are starting ranges. Starting base pay range: $60,000/yr - $95,000/yr Starting bonus range: $3,000/yr - $12,000/yr",
        "url": "https://www.linkedin.com/jobs/view/3963166431",
        "summary": "ICR is seeking Associate Data Scientists to join their Translational Bioinformatics Team. This role involves applying data analytics and machine learning to multi-omic human disease datasets for drug development. Candidates must have a biomedical sciences background, strong programming skills (R and Python), expertise in predictive modeling, and a solid understanding of statistical concepts. The position offers a competitive salary and bonus structure, and the opportunity to work on impactful research.",
        "industries": [
            "Biotechnology",
            "Healthcare",
            "Pharmaceuticals",
            "Research",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Creativity",
            "Teamwork",
            "Can-do attitude",
            "Friendly",
            "Easygoing"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "Predictive Modeling",
            "Probability and Statistics",
            "R",
            "Python",
            "Biomedical Sciences",
            "Scoring Rules"
        ],
        "tech_stack": [
            "R",
            "Python",
            "Machine Learning"
        ],
        "programming_languages": [
            "R",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Biomedical Sciences",
                "Data Science",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 95000,
            "min": 60000
        },
        "benefits": [
            "Bonus"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Redmond, WA",
        "job_id": 3962921105,
        "company": "Microsoft",
        "title": "Data Scientist",
        "created_on": 1720587612.5763638,
        "description": "Microsoft is built on trust, and Azure is dedicated to becoming the most trusted cloud service for its customers. As Azure expands its services, certifications, and regions for its global customers, there is a growing need for increased support to uphold customer promises. The Azure Core Trusted Platform team is committed to enabling product teams to deliver capabilities that align with customer commitments and provide transparency. We are looking for a Data Scientist with a proven track record of solving large, complex data analysis and machine learning problems in a real-world software product development setting. If you're a skilled engineer who is passionate about building end-to-end ML solutions and eager to learn new technologies, with the determination to solve complex technical problems, then this position is perfect for you. Join our diverse and welcoming team that is dedicated to building privacy, security, and compliance engineering solutions for the Azure cloud. We use cutting-edge Azure service, data, and ML technologies to create products that are widely used across Microsoft teams. Our team values inclusiveness and diverse ideas, and we prioritize empathy, trust, and ownership to drive our team culture and deliver products quickly and iteratively. You'll work in a fast-paced environment, tackling problems that require creativity and collaboration to achieve meaningful business outcomes. We continuously strive for world-class engineering and operational excellence and encourage you to influence our designs and architectural roadmap and drive specific goals around scalability and availability. Join us and help make Azure the most trusted cloud platform! #AzureCoreTrustedPlatform Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Business understanding: Understands underlying business and product goals to inform design of data science solutions. Evaluates project plan for resources, risks, contingencies, requirements, assumptions, and constraints. Effectively communicates business goals, data insights, and data science solutions with variety of stakeholders. Data fluency: Explore, query, visualize, and process data sets to deeply understand available datasets. Evaluates and leverages existing methodologies and tools, such as statistical and ML packages. Able to identify and propose solutions to data integrity and quality issues. Modeling & analysis: Understands pros/cons of wide variety of ML techniques (classification, regression, clustering, time series analysis, natural language processing, etc.) and algorithms (linear/logistic regression, gradient boosting, agglomerative clustering, deep neural networks, Transformer networks, etc.) to select the most appropriate solution. Applies standard modeling techniques (cross-validation, regularization, ensembling, etc.) as appropriate to ensure high-quality, reproducible results. Conducts well-designed experiments, performs statistically sound analyses, communicates results clearly and accurately to stakeholders (engineering and PM teams and leadership). Measurement & iteration: Measures success of data science solutions in the context of business impact and goals. Analyzes model performance and quickly iterates to improve performance metrics. Engineering skills: Writes efficient, scalable, maintainable code. Performs comprehensive quality checks for data processing and ML modeling code. Understands proper debugging techniques when dealing with data pipelines and non-deterministic code. Familiar with big data tooling, ETL pipeline principles, REST API consumption and deployment. Customer focus: Considers user experience when designing data science solutions. Examine and evaluate projects through customer-focused lens. Responsive to user feedback. Qualifications Required Qualifications: Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical tec OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 2+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques) OR equivalent experience. 1+ year(s) customer-facing, project-delivery experience, professional services, and/or consulting experience. Other Requirements Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. Additional/Preferred Qualifications Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science,or related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) OR equivalent experience. Data Science IC3 - The typical base pay range for this role across the U.S. is USD $94,300 - $182,600 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $120,900 - $198,600 per year. Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay Microsoft will accept applications for the role until July 15, 2024. #Azurecorejobs Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
        "url": "https://www.linkedin.com/jobs/view/3962921105",
        "summary": "Microsoft Azure is seeking a Data Scientist to join their Core Trusted Platform team. This role will involve building end-to-end ML solutions, utilizing Azure services, data, and ML technologies to create products for privacy, security, and compliance engineering within the Azure cloud. Responsibilities include understanding business and product goals to inform data science solutions, exploring and analyzing data sets, selecting appropriate ML techniques and algorithms, measuring and iterating on model performance, writing efficient and scalable code, and considering user experience.",
        "industries": [
            "Software Development",
            "Cloud Computing",
            "Machine Learning",
            "Data Science",
            "Information Technology",
            "Security",
            "Privacy",
            "Compliance"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Creativity",
            "Customer Focus",
            "Empathy",
            "Ownership",
            "Growth Mindset",
            "Innovation"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "Statistical Modeling",
            "Data Visualization",
            "Data Processing",
            "Data Integrity",
            "Model Evaluation",
            "Code Optimization",
            "Scalability",
            "Availability",
            "Debugging",
            "Big Data Tools",
            "ETL Pipelines",
            "REST APIs",
            "Deployment",
            "Cross-validation",
            "Regularization",
            "Ensembling"
        ],
        "tech_stack": [
            "Azure",
            "Azure Services",
            "Azure Data",
            "Azure ML",
            "ML Techniques",
            "ML Algorithms",
            "Classification",
            "Regression",
            "Clustering",
            "Time Series Analysis",
            "Natural Language Processing",
            "Linear Regression",
            "Logistic Regression",
            "Gradient Boosting",
            "Agglomerative Clustering",
            "Deep Neural Networks",
            "Transformer Networks",
            "Big Data Tooling",
            "ETL Pipeline",
            "REST APIs"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Mathematics",
                "Statistics",
                "Econometrics",
                "Economics",
                "Operations Research",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 198600,
            "min": 94300
        },
        "benefits": [
            "Microsoft Cloud Background Check"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Bruno, CA",
        "job_id": 3912947208,
        "company": "Syntricate Technologies",
        "title": "Data Scientist (SQL/Python/R)",
        "created_on": 1720587620.3478615,
        "description": "Job Title: Data Scientist (SQL/Python/R) Location: San Bruno, CA Duration: Contract Job Description Minimum Qualifications Master's degree in statistics, economics, operations research, engineering, or related field 6+ years of industry experience in data science, measurement, marketing strategy & analytics Strong communication skills to 'tell a story' that provides insight into the business Proficient coding skills (SQL/Python/R) and database knowledge Extensive experience with predictive modeling algorithms Strong project management skills, including managing technical resources and multiple priorities & milestones. You have a passion for working in a fast-paced agile environment. A collaborative mindset and sense of curiosity",
        "url": "https://www.linkedin.com/jobs/view/3912947208",
        "summary": "Data Scientist with 6+ years of experience in data science, measurement, marketing strategy & analytics. Proficient in SQL, Python, and R with strong communication skills and experience in predictive modeling. Passionate about working in a fast-paced agile environment.",
        "industries": [
            "Marketing",
            "Technology",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Storytelling",
            "Project Management",
            "Collaboration",
            "Curiosity"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "R",
            "Predictive Modeling"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "R"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Statistics",
                "Economics",
                "Operations Research",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3965973620,
        "company": "Dropbox",
        "title": "Data Scientist",
        "created_on": 1720587622.894885,
        "description": "Company Description Dropbox is a special place where we are all seeking to fulfill our mission to design a more enlightened way of working. We’re looking for innovative talent to join us on our journey. The words shared by our founders at the start of Dropbox still ring true today. Wouldn’t it be great if our working environment—and the tools we use—were designed with people’s actual needs in mind? Imagine if every minute at work were well spent—if we could focus and spend our time on the things that matter. This is possible, and Dropbox is connecting the dots. The nearly 3,000 Dropboxers around the world have helped make Dropbox a living workspace - the place where people come together and their ideas come to life. Our 700+ million global users have been some of our best salespeople, and they have helped us acquire customers with incredible efficiency. As a result, we reached a billion dollar revenue run rate faster than any software-as-a-service company in history. Dropbox is making the dream of a fulfilling and seamless work life a reality. We hope you’ll join us on the journey. Team Description Our Product team advocates for our users and our business, setting the vision for our growing family of products. We use data, research, strategy, and empathy to guide multidisciplinary teams toward a common goal, balancing diverse perspectives and empowering our teams to do great work. As we scale globally, there’s plenty of space for you to grow alongside us and simplify life for millions of people around the world in team that always focuses on we, not I, and creates delightful products that are worthy of trust. Role Description We're looking for a Data Scientist to partner with revenue, marketing, and product teams to answer key questions about how to grow revenue, optimize product, scale and monetize the business, and launch high-impact initiatives. We solve challenging problems and boost business growth through a deep understanding of user behaviors with applied analytics techniques and business insights. An ideal candidate should have robust knowledge of consumer lifecycle and behavior analysis, customer segmentation, digital campaigns, monetization analytics and business operations for a SaaS company. Responsibilities Develop a deep understanding of customer journey phases and key business metrics Perform analytical deep-dives to analyze problems and opportunities, identify the hypothesis and design & execute experiments Inform future experimentation design and roadmaps by performing exploratory analysis to understand user engagement behavior and derive insights Create personalized segmentation strategies leveraging propensity models to enable targeting of offers and experiences based on user attributes Identify key trends and build automated reporting & executive-facing dashboards to track the progress of acquisition, monetization, and engagement trends. Extract actionable insights through analyzing large, complex, multi-dimensional customer behavior data sets Monitor and analyze a high volume of experiments designed to optimize the product for user experience and revenue & promote best practices for multivariate experiments Translate complex concepts into implications for the business via excellent communication skills, both verbal and written Understand what matters most and prioritize ruthlessly Work with cross-functional teams (including Data Science, Marketing, Product, Engineering, Design, User Research, and senior executives) to rapidly execute and iterate Requirements Bachelors’ or above in quantitative discipline: Statistics, Applied Mathematics, Economics, Computer Science, Engineering, or related field 3-5 years experience using analytics to drive key business decisions; examples include business/product/marketing analytics, business intelligence, strategy consulting Proven track record of being able to work independently and proactively engage with business stakeholders with minimal direction Significant experience with SQL and large unstructured datasets such as Hadoop Deep understanding of statistical analysis, experimentation design, and common analytical techniques like regression, decision trees Solid background in running multivariate experiments to optimize a product or revenue flow Strong verbal and written communication skills Proficiency in programming/scripting and knowledge of statistical packages like R or Python is a plus Preferred Qualifications Master’s or above in quantitative discipline: Statistics, Applied Mathematics, Economics, Computer Science, Engineering, or related field Previous experience working in tech as a product data scientist Proven track record of working successfully with engineering partners Total Rewards US Zone 1$154,700—$209,300 USDUS Zone 2$139,200—$188,400 USDUS Zone 3$123,800—$167,400 USD Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).",
        "url": "https://www.linkedin.com/jobs/view/3965973620",
        "summary": "Dropbox seeks a Data Scientist to partner with revenue, marketing, and product teams to drive business growth. The role involves analyzing user behavior, conducting experiments, building reporting dashboards, and translating insights into actionable recommendations.  The ideal candidate will have experience with consumer lifecycle analysis, customer segmentation, digital campaigns, monetization analytics, and a strong understanding of statistical analysis, experimentation design, and common analytical techniques.  Experience working with large datasets, SQL, and statistical packages like R or Python is required.  The role offers competitive compensation and benefits.",
        "industries": [
            "Software",
            "Technology",
            "SaaS",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Data Interpretation",
            "Decision Making",
            "Leadership",
            "Strategic Thinking",
            "Project Management",
            "Time Management",
            "Organization",
            "Prioritization",
            "Adaptability",
            "Detail-Oriented"
        ],
        "hard_skills": [
            "SQL",
            "Hadoop",
            "Statistical Analysis",
            "Experimentation Design",
            "Regression",
            "Decision Trees",
            "Multivariate Experiments",
            "Python",
            "R"
        ],
        "tech_stack": [
            "SQL",
            "Hadoop",
            "Python",
            "R"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Applied Mathematics",
                "Economics",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 209300,
            "min": 123800
        },
        "benefits": [
            "Competitive Compensation",
            "Comprehensive Benefits Package"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3962402766,
        "company": "Upstart",
        "title": "Staff Data Scientist",
        "created_on": 1720587626.0767524,
        "description": "About Upstart Upstart is a leading AI lending marketplace partnering with banks and credit unions to expand access to affordable credit. By leveraging Upstart's AI marketplace, Upstart-powered banks and credit unions can have higher approval rates and lower loss rates across races, ages, and genders, while simultaneously delivering the exceptional digital-first lending experience their customers demand. More than two-thirds of Upstart loans are approved instantly and are fully automated. Upstart is a digital-first company, which means that most Upstarters live and work anywhere in the United States. However, we also have offices in San Mateo, California; Columbus, Ohio; and Austin, Texas. Most Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we’d love to hear from you! The Team: Upstart’s Machine Learning team has a direct impact on our company's success. The team consists of Research Scientists, Data Scientists and other highly specialized roles who build and enable our core production models. Because our challenges are so new, members of our Machine Learning team need strong creative problem-solving skills and the technical background to implement solutions. Our research environment affords team members the opportunity to utilize a variety of statistical and machine learning methods with the freedom and encouragement to pursue alternative approaches to solving problems. Whether developing new products or identifying novel approaches to core models, we are continuously seeking the next big ideas to move our business forward. As a Data Scientist, you'll leverage technical and business acumen to become an expert in our models and how the models interact with the business. Identify potential problems or opportunities for improvement, communicate these issues to the team, stakeholders and suggest solutions. This involves self-directed investigation into our business and its data, designing and preparing regular reports, as well as conducting ad hoc analyses for the Machine Learning team, company leadership, and external business partners. How You’ll Make An Impact By presenting reports to key stakeholders and decision makers on model performance and how it impacts the business. Oftentimes this person will report directly to corporate executives. By finding issues with the models before they have a chance to impact our business. By analyzing experimental data to uncover heterogeneous effects and recommend opportunities for personalized interventions. By collaborating with research scientists to build and evaluate novel models and modeling applications. By writing clear, bug-free, and well documented code that runs well and is easy to understand. Minimum Qualifications MS degree or related experience in a production setting 5+years experience in data science projects Knowledge in applied statistical methods and causal inference (e.g., AB testing, hypothesis testing, linear and logistic regression) Experience with modern predictive modeling techniques (XGBoost, artificial neural networks) Experience with Python or R and SQL Strong Machine Learning experience Preferred Qualifications PHD in Applied Stats, Mathematics, Economics A subject matter expert on model performance evaluation in a business context Experience in building visualizations and maintaining Dashboards (Plotly or Matplotlib) to track model performance Serving as an expert in the areas of experimental testing, Causal Inference, A/B testing or Hypothesis testing Collaborating with and mentoring other data scientists in these areas. Position location This role is available in the following locations: Remote Time zone requirements The team operates on the East/West coast time zones. Travel requirements As a digital first company, the majority of your work can be accomplished remotely. The majority of our employees can live and work anywhere in the U.S but are encouraged to to still spend high quality time in-person collaborating via regular onsites. The in-person sessions’ cadence varies depending on the team and role; most teams meet once or twice per quarter for 2-4 consecutive days at a time. What you'll love: Competitive Compensation (base + bonus & equity) Comprehensive medical, dental, and vision coverage with Health Savings Account contributions from Upstart 401(k) with 100% company match up to $4,500 and immediate vesting and after-tax savings Employee Stock Purchase Plan (ESPP) Life and disability insurance Generous holiday, vacation, sick and safety leave Supportive parental, family care, and military leave programs Annual wellness, technology & ergonomic reimbursement programs Social activities including team events and onsites, all-company updates, employee resource groups (ERGs), and other interest groups such as book clubs, fitness, investing, and volunteering Catered lunches + snacks & drinks when working in offices At Upstart, your base pay is one part of your total compensation package. The anticipated base salary for this position is expected to be within the below range. Your actual base pay will depend on your geographic location–with our “digital first” philosophy, Upstart uses compensation regions that vary depending on location. Individual pay is also determined by job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. In addition, Upstart provides employees with target bonuses, equity compensation, and generous benefits packages (including medical, dental, vision, and 401k). United States | Remote - Anticipated Base Salary Range $174,900—$242,000 USD Upstart is a proud Equal Opportunity Employer. We are dedicated to ensuring that underrepresented classes receive better access to affordable credit, and are just as committed to embracing diversity and inclusion in our hiring practices. We celebrate all cultures, backgrounds, perspectives, and experiences, and know that we can only become better together. If you require reasonable accommodation in completing an application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please email candidate_accommodations@upstart.com https://www.upstart.com/candidate_privacy_policy",
        "url": "https://www.linkedin.com/jobs/view/3962402766",
        "summary": "Upstart, a leading AI lending marketplace, seeks a Data Scientist to join its Machine Learning team. This role involves analyzing model performance, identifying issues, collaborating with research scientists, and writing code. The ideal candidate has a Master's degree (or equivalent experience), 5+ years of experience in data science projects, and expertise in statistical methods, predictive modeling techniques, Python/R, and SQL. The position offers competitive compensation, comprehensive benefits, and a chance to impact the company's success.",
        "industries": [
            "Financial Technology (FinTech)",
            "Artificial Intelligence (AI)",
            "Lending",
            "Machine Learning"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Collaboration",
            "Analytical",
            "Presentation",
            "Self-directed",
            "Critical Thinking",
            "Mentoring"
        ],
        "hard_skills": [
            "Data Science",
            "Statistical Methods",
            "Causal Inference",
            "A/B Testing",
            "Hypothesis Testing",
            "Linear Regression",
            "Logistic Regression",
            "Predictive Modeling",
            "XGBoost",
            "Artificial Neural Networks",
            "Python",
            "R",
            "SQL",
            "Model Performance Evaluation",
            "Data Visualization",
            "Dashboards",
            "Plotly",
            "Matplotlib",
            "Experimental Testing"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "XGBoost",
            "Artificial Neural Networks",
            "Plotly",
            "Matplotlib"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Data Science",
                "Statistics",
                "Mathematics",
                "Economics"
            ]
        },
        "salary": {
            "max": 242000,
            "min": 174900
        },
        "benefits": [
            "Competitive Compensation",
            "Bonus",
            "Equity",
            "Medical Coverage",
            "Dental Coverage",
            "Vision Coverage",
            "Health Savings Account",
            "401k",
            "Company Match",
            "Employee Stock Purchase Plan",
            "Life Insurance",
            "Disability Insurance",
            "Holiday Leave",
            "Vacation Leave",
            "Sick Leave",
            "Safety Leave",
            "Parental Leave",
            "Family Care Leave",
            "Military Leave",
            "Wellness Reimbursement",
            "Technology Reimbursement",
            "Ergonomic Reimbursement",
            "Social Activities",
            "Team Events",
            "On-sites",
            "Employee Resource Groups",
            "Catered Lunches",
            "Snacks",
            "Drinks"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Atlanta, GA",
        "job_id": 3965753099,
        "company": "K2 Integrity",
        "title": "Data Scientist",
        "created_on": 1720587632.743725,
        "description": "K2 Integrity is looking for a highly motivated and focused Data Scientist to design, develop, and implement our Systemic Risk Analytics Framework for K2 Integrity’s market leading Anti-Financial Crime and Compliance solutions. This role will be involved in working with Product Management, R&D, Business, Data Science and Data Architecture teams to design, build, and deploy a leading-edge platform supporting a robust analytics framework for the identification and reporting of illicit activities and associated behavioral patterns of abuse. This will include development of risk models for individual entities, populations and jurisdictional detection and monitoring. Modern analytical techniques such as customer segmentation, identity resolution and identification, neural networks, and large language and machine learning models will be leveraged alongside defined operational summary statistics analysis and reporting. Responsibilities: Design, develop and implement a robust analytics framework and reporting capability in conjunction with your counterparts in the Systemic Risk Analytics function Partner with stakeholders to ideate and identify new “unknown unknown” risk typologies that can be codified into new risk models Work with data science counterparts and product management to define, develop, and implement new models and techniques to more effectively analyze data for known and unknown illicit behaviors with the chief goal of higher value alerts and reduction of false positives. Codify and implement developed compliance rules for analyzing payments and their associated beneficiaries, remitters and managing directors for identification of sanctions and other compliance risks. Partner to develop a robust KYC/CDD analytics solution in concert with internal systems and technology vendor partners to understand individual and systemic risk across entities, populations, and jurisdictions Implement appropriate data governance controls, policies and procedures to ensure data integrity and data lineage. Ensure automation for the operational execution of rules, models and reports. Implement an automated alerting function detecting data cleanliness and data availability issues Overall, increase the accuracy and effectiveness of investigations while reducing operational overhead and run rate cost Qualifications: Bachelor’s, master’s degree or Ph.D. in statistics or math, or equivalent quantitative field of study Demonstrated experience in developing, implementing, and managing operational analytical solutions or frameworks. (8+ years of experience) Demonstrated experience in optimization and automation of analytical models/rules including look back, audit, “What if?” and impact analysis testing and performance validations. Demonstrated programming skills with SAS, Spark, Python, R or equivalent languages Demonstrated use of Large Language Models such as ChatGPT or equivalent Demonstrated experience working with Anti-Financial Crime and Compliance technologies. For example: Transaction Monitoring Systems, KYC/CDD, Sanctions and Wire screening Applications, Network Analysis, Entity Resolution & Identification and Segmentation utilities or Case Management solutions Ability to work during Eastern Standard Time regular business hours Certified Analytics Professional (CAP), Data Science Council of America (DASCA), Principal Data Scientist (PDS), SAS Big Data Professional, Microsoft Certified Azure Data Scientist Associate, or equivalents Strong working knowledge and familiarity with Palantir Foundry applications, products, and solutions Powered by JazzHR Od9blayHGq",
        "url": "https://www.linkedin.com/jobs/view/3965753099",
        "summary": "K2 Integrity is seeking a Data Scientist to design, develop, and implement a Systemic Risk Analytics Framework for their anti-financial crime and compliance solutions. The role involves working with various teams to build a platform supporting a robust analytics framework for identifying and reporting illicit activities and associated behavioral patterns. Responsibilities include developing risk models, leveraging modern analytical techniques, implementing compliance rules, and ensuring data governance and automation.",
        "industries": [
            "Financial Services",
            "Compliance",
            "Risk Management",
            "Data Science",
            "Anti-Financial Crime"
        ],
        "soft_skills": [
            "Highly Motivated",
            "Focused",
            "Analytical",
            "Problem-Solving",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Project Management",
            "Data Governance"
        ],
        "hard_skills": [
            "Systemic Risk Analytics",
            "Risk Modeling",
            "Customer Segmentation",
            "Identity Resolution",
            "Neural Networks",
            "Large Language Models",
            "Machine Learning",
            "SAS",
            "Spark",
            "Python",
            "R",
            "ChatGPT",
            "Transaction Monitoring Systems",
            "KYC/CDD",
            "Sanctions",
            "Wire Screening Applications",
            "Network Analysis",
            "Entity Resolution",
            "Segmentation",
            "Case Management",
            "Palantir Foundry"
        ],
        "tech_stack": [
            "SAS",
            "Spark",
            "Python",
            "R",
            "ChatGPT",
            "Palantir Foundry"
        ],
        "programming_languages": [
            "SAS",
            "Spark",
            "Python",
            "R"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Math",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3970157464,
        "company": "Steneral Consulting",
        "title": "Sr Data Scientist W/AI Modeling",
        "created_on": 1720587634.142313,
        "description": "Work is HYBRID w/Video interviews. Due to W2 client restrictions only USC or GC candidates may be submitted.** (client is looking for local candidates) . Sr Data Scientist w/AI Modeling having 5+ years of experience in statistical data analysis. Experience using common statistical and visualization software tools such as SAS, SPSS, R and Tableau. Experience with AWS AI/GenAI models.",
        "url": "https://www.linkedin.com/jobs/view/3970157464",
        "summary": "Senior Data Scientist with 5+ years of experience in statistical data analysis, skilled in using statistical and visualization tools like SAS, SPSS, R, and Tableau. Experience with AWS AI/GenAI models is a must. This is a hybrid role and only US Citizens or Green Card holders are eligible.",
        "industries": [
            "Data Science",
            "Analytics",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Statistical Analysis",
            "Data Visualization"
        ],
        "hard_skills": [
            "SAS",
            "SPSS",
            "R",
            "Tableau",
            "AWS AI",
            "GenAI Models"
        ],
        "tech_stack": [
            "AWS AI",
            "GenAI Models",
            "SAS",
            "SPSS",
            "R",
            "Tableau"
        ],
        "programming_languages": [
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3966608492,
        "company": "Stefanini North America and APAC",
        "title": "Data Scientist",
        "created_on": 1720587635.5263772,
        "description": "Stefanini group is hiring! Stefanini is looking for a Data Scientist in Dallas, TX (Hybrid Role). For quick Apply, please reach out to Ravi Singh Call: 248 213 3610/ email: Ravi.singh@stefanini.com Open for W2 candidates only. Responsibilities: Independently consult with business partners and internal/external department functional experts to develop and maintain department dashboards/metrics. Perform research and apply knowledge of existing and emerging data science principles, theories, and techniques to inform business decisions. Lead the development of queries, validation and exporting of data in various formats for the organization, automating the delivery where possible. Develop and maintain infrastructure systems that connect internal data sets; create new data collection frameworks for structured and unstructured data. Perform quantitative and qualitative data analysis to produce reports, assessments and proposals that will help organizational leaders make informed and data driven business decisions. Maintain an up-to-date perspective of tools, practices, industry standards, national trends and System standards Required Skills: 5+ years of experience in statistical data analysis. Experience using common statistical and visualization software tools such as SAS, SPSS, R and Tableau. Excellent time management skills including multi-tasking, managing deadlines and providing project oversight. Excellent written, verbal and listening skills to effectively communicate with staff at all organizational levels. Strong facilitation skills with the ability to drive issues to closure. Strong problem solving and critical thinking skills. Ability to maintain trust and integrity when working with confidential situations and information. Ability to work collaboratively across a variety of business units within the organization. Listed salary ranges may vary based on experience, qualifications, and local market. Also, some positions may include bonuses or other incentives Stefanini takes pride in hiring top talent and developing relationships with our future employees. Our talent acquisition teams will never make an offer of employment without having a phone conversation with you. Those face-to-face conversations will involve a description of the job for which you have applied. We also speak with you about the process including interviews and job offers. About Stefanini Group: The Stefanini Group is a global provider of offshore, onshore and near shore outsourcing, IT digital consulting, systems integration, application, and strategic staffing services to Fortune 1000 enterprises around the world. Our presence is in countries like the Americas, Europe, Africa, and Asia, and more than four hundred clients across a broad spectrum of markets, including financial services, manufacturing, telecommunications, chemical services, technology, public sector, and utilities. Stefanini is a CMM level 5, IT consulting company with a global presence. We are CMM Level 5 company.",
        "url": "https://www.linkedin.com/jobs/view/3966608492",
        "summary": "Stefanini is looking for a Data Scientist with 5+ years of experience in statistical data analysis. The role involves developing and maintaining dashboards/metrics, performing data analysis, and building data infrastructure. The ideal candidate will have experience with SAS, SPSS, R, and Tableau, and strong communication and problem-solving skills.",
        "industries": [
            "IT",
            "Technology",
            "Consulting",
            "Outsourcing",
            "Financial Services",
            "Manufacturing",
            "Telecommunications",
            "Chemical Services",
            "Public Sector",
            "Utilities"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Critical Thinking",
            "Collaboration",
            "Time Management",
            "Multitasking",
            "Facilitation",
            "Leadership",
            "Integrity",
            "Trust"
        ],
        "hard_skills": [
            "SAS",
            "SPSS",
            "R",
            "Tableau",
            "Data Analysis",
            "Data Visualization",
            "Data Infrastructure",
            "Data Collection",
            "Data Mining",
            "Data Modeling",
            "Querying",
            "SQL",
            "Reporting"
        ],
        "tech_stack": [
            "SAS",
            "SPSS",
            "R",
            "Tableau"
        ],
        "programming_languages": [
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Overland, MO",
        "job_id": 3960246092,
        "company": "Clayco",
        "title": "Data Scientist",
        "created_on": 1720587636.9320118,
        "description": "About Us Clayco is a full-service, turnkey real estate development, master planning, architecture, engineering, and construction firm that safely delivers clients across North America the highest quality solutions on time, on budget, and above and beyond expectations. With $5.8 billion in revenue for 2023, Clayco specializes in the \"art and science of building,\" providing fast track, efficient solutions for industrial, commercial, institutional, and residential related building projects. The Role We Want You For We are currently seeking a skilled Data Scientist to join our Data Analytics team in our Overland, MO office. As a Data Scientist you will play a critical role in understanding our business operations, identifying challenges and opportunities, and leveraging data to drive informed decision-making. You will collaborate with various stakeholders to analyze data, develop predicitive models, and provide actionable insights. Additionally, you will actively contribute to the continuous improvement of our data science function and help track the business value delivered by our team. The Specifics of the Role Leverage an excellent understanding of the business operations to identify challenges and opportunities from business stakeholders and align them with available data. Identify the relevant stage/source of data within the business process and curate and QA the necessary data using engineering skills. Perform quantitative and qualitative analysis to solve business challenges and identify actionable insights. Develop and validate AI/ML models, deploy them to production, and monitor their technical and business performance. Apply causal inference techniques to estimate the effect of changes on relevant outcomes using experimental or non-experimental data. Assess the performance of data science solutions and define metrics to track and monitor performance and benefits to the company. Adhere to clean and reproducible programming practices, ensuring documentation for both technical and business audiences. Collaborate with project management teams to translate business requirements into detailed technical requirements. Create and utilize detailed test plans to evaluate data science efforts and gain alignment with business partners. Requirements Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or a related field. 3+ years of applied experience in a professional setting, with a focus on data science and analytics. Strong proficiency in SQL, Python, Spark, Scala, and R programming languages. Experience working with structured and non-structured data sources to build models. Knowledge of AI/ML modeling techniques and ability to engineer features based on a deep understanding of the business process. Familiarity with causal inference methodologies and non-parametric strategies. Proficiency in platforms such as Snowflake, Tableau, DOMO, and AutoML Platforms. Excellent verbal and written communication skills, with the ability to effectively communicate complex concepts to technical and non-technical stakeholders. Strong documentation skills for technical and business audiences. Resilience and adaptability to overcome challenges and deliver high-quality results. Ability to develop and maintain detailed business knowledge to drive data-driven decision-making. Some Things You Should Know This position will service our clients in add city or add states of region here. Our clients and projects are nationwide – Travel will be required. No other builder can offer the collaborative design-build approach that Clayco does. We work on creative, complex, award-winning, high-profile jobs. The pace is fast! Why Clayco? Best Places to Work – St. Louis Business Journal, Los Angeles Business Journal, Phoenix Business Journal. ENR – Top Midwest Contractors (#1), Top Design Build Contractors (#4), Top 400 Contractors (#23), ENR – Top Green Builders (#5). Compensation and Benefits Competitive Annual Salary based on qualifications, skills, training, and experience. Discretionary Annual Bonus: Subject to company performance and individual contribution. Comprehensive Benefits Package Including: medical, dental and vision plans, 401k, generous PTO and paid company holidays, employee assistance program, flexible spending accounts, life insurance, disability coverage, learning & development programs and more!",
        "url": "https://www.linkedin.com/jobs/view/3960246092",
        "summary": "Clayco, a full-service real estate development and construction firm, seeks a Data Scientist to join their Data Analytics team in Overland, MO. The role involves understanding business operations, identifying challenges and opportunities, and using data to drive informed decision-making. Responsibilities include data analysis, predictive model development, and providing actionable insights. The ideal candidate will have a strong understanding of data science and analytics, proficiency in SQL, Python, Spark, Scala, and R, and experience with structured and non-structured data sources. They should also have knowledge of AI/ML modeling techniques, causal inference methodologies, and experience with platforms like Snowflake, Tableau, DOMO, and AutoML. Excellent communication skills, documentation skills, and a strong understanding of business operations are essential.",
        "industries": [
            "Real Estate",
            "Construction",
            "Architecture",
            "Engineering",
            "Data Analytics",
            "Artificial Intelligence",
            "Machine Learning",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Decision-Making",
            "Collaboration",
            "Adaptability",
            "Resilience",
            "Documentation",
            "Critical Thinking",
            "Business Acumen",
            "Presentation"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "Spark",
            "Scala",
            "R",
            "AI/ML Modeling",
            "Causal Inference",
            "Feature Engineering",
            "Data Analysis",
            "Predictive Modeling",
            "Data Visualization",
            "Snowflake",
            "Tableau",
            "DOMO",
            "AutoML Platforms"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "Spark",
            "Scala",
            "R",
            "AI/ML",
            "Snowflake",
            "Tableau",
            "DOMO",
            "AutoML"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "Spark",
            "Scala",
            "R"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Statistics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Annual Salary",
            "Discretionary Annual Bonus",
            "Medical",
            "Dental",
            "Vision",
            "401k",
            "PTO",
            "Paid Holidays",
            "Employee Assistance Program",
            "Flexible Spending Accounts",
            "Life Insurance",
            "Disability Coverage",
            "Learning & Development Programs"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Stamford, CT",
        "job_id": 3969209112,
        "company": "Smith Arnold Partners",
        "title": "Data Scientist",
        "created_on": 1720587642.5463188,
        "description": "Exciting Data Scientist opportunity! You will play a pivotal role in extracting meaningful insights from complex datasets to drive strategic decision-making and improve business outcomes. You will collaborate closely with cross-functional teams to identify opportunities, develop analytical solutions, and deploy predictive models! Competitive compensation, tremendous benefit package and 401k. Cutting edge technology, incredible culture and working environment! Employee testimonials: Fantastic Place to Work. Hope to finish out the rest of my career with this great company! Good salary and package deal Friendly environment Great career advancement Everyone loves working here and you feel it! Great company, culture, and work-life balance! Title: Data Scientist Location: Stamford, CT Salary: $130,000 – $160,000 + Generous Bonus, Incredible benefits and retirement package! Responsibilities: Critical role in the design and development of enterprise-grade deep analytics. Explore and analyze large, complex datasets to identify patterns, trends, and correlations. Develop hypothesis-driven analyses to uncover actionable insights. Design, develop, and deploy predictive models and machine learning algorithms to address business challenges. Optimize model performance through feature engineering, parameter tuning, and validation techniques. Communicate findings and recommendations to stakeholders through clear and compelling data visualizations, reports, and presentations. Collaborate with teams across the organization to translate data-driven insights into actionable strategies. Stay abreast of the latest advancements in data science, machine learning, and analytics technologies. This Data Scientist position is involved in the entire lifecycle of the Advanced Analytics environment that underpins the vital business requirements of the corporation. This includes the design, development, implementation, operation, and ongoing support of these critical systems. Apply analytical and problem-solving skills to diagnose and resolve intricate technical issues. Creating data processing and integration solutions for both batch and real-time scenarios, proficiently handling structured and unstructured data. Requirements: Proven work experience, 3-6+ years in Data Science or deep analytics in the financial sector. Proficiency in programming languages such as Python, R, or SQL with experience in data manipulation, statistical analysis, and machine learning. Strong understanding of machine learning algorithms, including supervised and unsupervised learning techniques. Strong expertise in data visualization tools such as PowerBI or Tableau. Must have experience developing and deploying Data Science solutions leveraging components like Azure OpenAI and Azure Notebooks. Excellent communication and collaboration skills, with the ability to distill complex technical concepts into understandable insights for non-technical stakeholders Experience with big data technologies such as Hadoop and Spark. Strong knowledge or advanced analytics techniques such as deep learning, natural language processing, or reinforcement learning. Experience deploying machine learning models into production.",
        "url": "https://www.linkedin.com/jobs/view/3969209112",
        "summary": "Data Scientist position at a financial company in Stamford, CT. Responsibilities include designing and developing deep analytics, exploring complex datasets, building predictive models, and communicating insights to stakeholders. Requires 3-6+ years of experience in data science within the financial sector.",
        "industries": [
            "Finance",
            "Financial Services"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical",
            "Critical Thinking",
            "Presentation Skills",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Data Manipulation",
            "Statistical Analysis",
            "Machine Learning",
            "Supervised Learning",
            "Unsupervised Learning",
            "Data Visualization",
            "PowerBI",
            "Tableau",
            "Azure OpenAI",
            "Azure Notebooks",
            "Hadoop",
            "Spark",
            "Deep Learning",
            "Natural Language Processing",
            "Reinforcement Learning",
            "Model Deployment"
        ],
        "tech_stack": [
            "Azure OpenAI",
            "Azure Notebooks",
            "Hadoop",
            "Spark",
            "PowerBI",
            "Tableau"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 160000,
            "min": 130000
        },
        "benefits": [
            "Competitive Compensation",
            "Generous Bonus",
            "Incredible Benefits",
            "Retirement Package",
            "401k"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Tampa, FL",
        "job_id": 3965753098,
        "company": "K2 Integrity",
        "title": "Data Scientist",
        "created_on": 1720587644.3362038,
        "description": "K2 Integrity is looking for a highly motivated and focused Data Scientist to design, develop, and implement our Systemic Risk Analytics Framework for K2 Integrity’s market leading Anti-Financial Crime and Compliance solutions. This role will be involved in working with Product Management, R&D, Business, Data Science and Data Architecture teams to design, build, and deploy a leading-edge platform supporting a robust analytics framework for the identification and reporting of illicit activities and associated behavioral patterns of abuse. This will include development of risk models for individual entities, populations and jurisdictional detection and monitoring. Modern analytical techniques such as customer segmentation, identity resolution and identification, neural networks, and large language and machine learning models will be leveraged alongside defined operational summary statistics analysis and reporting. Responsibilities: Design, develop and implement a robust analytics framework and reporting capability in conjunction with your counterparts in the Systemic Risk Analytics function Partner with stakeholders to ideate and identify new “unknown unknown” risk typologies that can be codified into new risk models Work with data science counterparts and product management to define, develop, and implement new models and techniques to more effectively analyze data for known and unknown illicit behaviors with the chief goal of higher value alerts and reduction of false positives. Codify and implement developed compliance rules for analyzing payments and their associated beneficiaries, remitters and managing directors for identification of sanctions and other compliance risks. Partner to develop a robust KYC/CDD analytics solution in concert with internal systems and technology vendor partners to understand individual and systemic risk across entities, populations, and jurisdictions Implement appropriate data governance controls, policies and procedures to ensure data integrity and data lineage. Ensure automation for the operational execution of rules, models and reports. Implement an automated alerting function detecting data cleanliness and data availability issues Overall, increase the accuracy and effectiveness of investigations while reducing operational overhead and run rate cost Qualifications: Bachelor’s, master’s degree or Ph.D. in statistics or math, or equivalent quantitative field of study Demonstrated experience in developing, implementing, and managing operational analytical solutions or frameworks. (8+ years of experience) Demonstrated experience in optimization and automation of analytical models/rules including look back, audit, “What if?” and impact analysis testing and performance validations. Demonstrated programming skills with SAS, Spark, Python, R or equivalent languages Demonstrated use of Large Language Models such as ChatGPT or equivalent Demonstrated experience working with Anti-Financial Crime and Compliance technologies. For example: Transaction Monitoring Systems, KYC/CDD, Sanctions and Wire screening Applications, Network Analysis, Entity Resolution & Identification and Segmentation utilities or Case Management solutions Ability to work during Eastern Standard Time regular business hours Certified Analytics Professional (CAP), Data Science Council of America (DASCA), Principal Data Scientist (PDS), SAS Big Data Professional, Microsoft Certified Azure Data Scientist Associate, or equivalents Strong working knowledge and familiarity with Palantir Foundry applications, products, and solutions Powered by JazzHR mr5Ud2Ig1H",
        "url": "https://www.linkedin.com/jobs/view/3965753098",
        "summary": "K2 Integrity is searching for a Data Scientist to design, develop, and implement their Systemic Risk Analytics Framework for Anti-Financial Crime and Compliance solutions.  The role involves collaborating with teams to create a platform for analyzing illicit activities and associated behavioral patterns. Responsibilities include developing risk models, implementing compliance rules, and automating operational processes to enhance investigative accuracy and efficiency.",
        "industries": [
            "Financial Services",
            "Compliance",
            "Risk Management",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Highly motivated",
            "Focused",
            "Collaborative",
            "Analytical",
            "Problem-solving",
            "Communication",
            "Data governance",
            "Automation"
        ],
        "hard_skills": [
            "Systemic Risk Analytics",
            "Risk Modeling",
            "Customer Segmentation",
            "Identity Resolution",
            "Neural Networks",
            "Large Language Models",
            "Machine Learning",
            "Operational Summary Statistics",
            "Reporting",
            "Data Governance",
            "Data Lineage",
            "Automation",
            "Data Cleanliness",
            "Data Availability",
            "SAS",
            "Spark",
            "Python",
            "R",
            "ChatGPT",
            "Transaction Monitoring Systems",
            "KYC/CDD",
            "Sanctions",
            "Wire Screening",
            "Network Analysis",
            "Entity Resolution",
            "Segmentation",
            "Case Management",
            "Palantir Foundry"
        ],
        "tech_stack": [
            "Palantir Foundry",
            "SAS",
            "Spark",
            "Python",
            "R",
            "ChatGPT",
            "Transaction Monitoring Systems",
            "KYC/CDD",
            "Sanctions",
            "Wire Screening",
            "Network Analysis",
            "Entity Resolution",
            "Segmentation",
            "Case Management"
        ],
        "programming_languages": [
            "SAS",
            "Spark",
            "Python",
            "R"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Math",
                "Quantitative"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Redmond, WA",
        "job_id": 3959386656,
        "company": "Kforce Inc",
        "title": "Data Scientist",
        "created_on": 1720587645.7008388,
        "description": "Responsibilities Kforce has a client in Redmond, WA that is looking for a Data Scientist with a drive to achieve high impact, high quality results for a large game. Summary: In this role, you will be responsible for driving insights that inform the Studio's player support and experimentation strategies. You will partner with business and engineering teams to ensure robust reporting on business metrics and make recommendations to optimize product health and collaborate on experiments to improve player experiences. You will develop and lead analysis that identify key drivers of acquisition, engagement, and monetization. Responsibilities: Data Scientist will identify key learnings from analysis and synthesize them into recommendations for stakeholders Manage partnerships with Product, Marketing, and other teams to integrate insights into product decisions Be self-driven and show ability to deliver on ambiguous projects with incomplete or dirty data As a Data Scientist, you will work with the Engineering team to build and maintain reporting queries for monitoring business health Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques Requirements 8+ years of experience in business analytics, with a focus on subscriptions 8+ years of experience with SQL, bonus if familiar with SparkSQL, Databricks, or Azure Data Explorer Proficient in a statistical programming language such as Python or PySpark Able to work in a collaborative, diverse and fast-paced team Excellent analytical, and problem-solving skills and autonomy when faced with solving data problems Excellent verbal, visual and written communication skills Interest in games, bonus if experience in gaming industry Local to Seattle area The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future. We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave. Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law. This job is not eligible for bonuses, incentives or commissions. Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3959386656",
        "summary": "Kforce is seeking a Data Scientist in Redmond, WA to drive insights that inform the Studio's player support and experimentation strategies.  This role involves partnering with business and engineering teams, building reports on business metrics, optimizing product health, collaborating on experiments to improve player experiences, and identifying key drivers of acquisition, engagement, and monetization.",
        "industries": [
            "Gaming",
            "Technology",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Skills",
            "Self-Driven",
            "Autonomy",
            "Partnership Building"
        ],
        "hard_skills": [
            "SQL",
            "SparkSQL",
            "Databricks",
            "Azure Data Explorer",
            "Python",
            "PySpark",
            "Data Analysis"
        ],
        "tech_stack": [
            "SQL",
            "SparkSQL",
            "Databricks",
            "Azure Data Explorer",
            "Python",
            "PySpark"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "PySpark"
        ],
        "experience": 8,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "HSA",
            "FSA",
            "401(k)",
            "Life Insurance",
            "Disability Insurance",
            "ADD Insurance",
            "Paid Time Off"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3970942478,
        "company": "Mondo",
        "title": "Machine Learning Engineer",
        "created_on": 1720587649.0619411,
        "description": "Role Purpose: As a Machine Learning Engineer, your primary responsibility will be to comprehend complex business challenges, translate them into data-driven solutions, and lead the development and deployment of state-of-the-art machine learning models. You will collaborate cross-functionally with various teams, ensuring that our ML solutions align with organizational goals and deliver tangible business value. Key Responsibilities: Design, develop, and deploy complex ML models and systems, ensuring they align with business goals and user needs. Architect and implement robust, scalable ML solutions, leveraging state-of-the-art techniques and frameworks such as PyTorch, TensorFlow, etc. Fine-tune and optimize large language models (e.g., Mistral, LLaMA) for specific use cases. Implement and experiment with cutting-edge NLP, NLU, and NLG techniques to enhance the capabilities and performance of our conversational AI products. Monitor and optimize model performance, ensuring efficiency, accuracy, and fairness in production environments. Collaborate with software engineers to integrate machine learning models into production systems, ensuring scalability, reliability, and performance. Use tools and frameworks such as Docker, Kubernetes, ONNX, Kubeflow, MLflow, and other model serving platforms to optimize the deployment and management journey. Stay abreast of the latest advancements in ML research, actively exploring emerging technologies and identifying opportunities for application within the company. Communicate complex technical concepts effectively to both technical and non-technical audiences, fostering seamless collaboration across teams (ML Engineers, Product Managers, Software Engineers). Requirements: A minimum of 2 years of professional experience as a Machine Learning Engineer. Bachelor’s degree or higher in Computer Science, Machine Learning, AI, Mathematics, or a related field (Master’s preferred). Excellent problem-solving abilities and a pragmatic approach to building scalable and robust machine learning systems. Strong foundation in machine learning and deep learning, including embedding methods, supervised and unsupervised learning, and deep learning architectures. Strong programming skills in Python and proficiency with machine learning libraries such as TensorFlow, PyTorch, or JAX. Experience with cloud platforms (e.g., AWS, GCP) and containerization technologies (e.g., Docker, Kubernetes). Strong foundation in statistics and an understanding of machine learning concepts, especially in NLP, NLU, and NLG. Familiarity with the MLOps lifecycle, including deployment, monitoring, and orchestration of ML models in production settings. Experience with model deployment tools and platforms like TFServing, TensorRT, TorchServe, ONNX, Kubeflow, and MLflow. Nice to Haves: Experience with Sitecore. Experience managing global teams. Knowledge of the insurance domain.",
        "url": "https://www.linkedin.com/jobs/view/3970942478",
        "summary": "Machine Learning Engineer responsible for developing and deploying state-of-the-art ML models, fine-tuning large language models, and implementing cutting-edge NLP, NLU, and NLG techniques for conversational AI products. Collaborates with cross-functional teams to ensure ML solutions align with organizational goals.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Software Development",
            "Insurance"
        ],
        "soft_skills": [
            "Problem-solving",
            "Collaboration",
            "Communication",
            "Pragmatic",
            "Leadership"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "NLP",
            "NLU",
            "NLG",
            "PyTorch",
            "TensorFlow",
            "JAX",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "MLOps",
            "TFServing",
            "TensorRT",
            "TorchServe",
            "ONNX",
            "Kubeflow",
            "MLflow"
        ],
        "tech_stack": [
            "PyTorch",
            "TensorFlow",
            "Mistral",
            "LLaMA",
            "Docker",
            "Kubernetes",
            "ONNX",
            "Kubeflow",
            "MLflow",
            "TFServing",
            "TensorRT",
            "TorchServe",
            "Sitecore"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Computer Science",
                "Machine Learning",
                "AI",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Los Angeles, CA",
        "job_id": 3967142850,
        "company": "Tripalink",
        "title": "Machine Learning Engineer",
        "created_on": 1720587650.603914,
        "description": "Location: Hybrid/Remote. Preferred: LA, SF Bay Area, Austin. Job Type: Full-Time Tripalink is a well-funded growth-stage Proptech startup headquartered in Los Angeles backed by prominent technology investors in Silicon Valley and others deeply rooted in the real estate space. We’re dedicated to building the next-gen real estate solutions powered by AI, with a current focus on delivering a frictionless experience end to end for renters and compelling economics for property owners. We have strong and accelerating momentum, having grown 7x in the last 3 years despite the tough environment for startups and the aggressive interest rate hikes negatively impacting the real estate market. We are seeking ML engineers passionate about building products powered by AI that delight users and are scalable and secure. The ideal candidates will be self-driven and have a solid foundation in ML (including GenAI/LLM) and a proven track record of shipping products powered by AI. Main Responsibilities: Collaborate with cross-functional teams to understand business and user needs and design AI-powered solutions Develop, evaluate/test, fine tune, and deploy various AI applications Produce high-quality code and documentation for machine learning processes and architectures Stay abreast of emerging technologies, especially new developments in GenAI/LLM areas, and leverage latest technologies and methodologies to improve our solutions Requirements: 1-3 years of experience as a ML engineer. Experience in shipping SaaS products or Internet services powered by LLMs is highly desirable Bachelor’s or Master’s degree or PhD in Computer Science, ML, or a related field Proficiency in programming in Python and Java Experience in NLP, AWS and relational databases such as MySQL, PostgreSQL, etc. is highly desirable Strong problem-solving skills with the ability to work independently and manage multiple tasks under pressure Ability to communicate effectively and work well as part of a distributed team in a fast-paced environment that optimizes for quick iterations. The estimated annual base salary for this role is $100,000 - $180,000.",
        "url": "https://www.linkedin.com/jobs/view/3967142850",
        "summary": "Tripalink, a Proptech startup, is seeking an ML Engineer with 1-3 years of experience to develop AI-powered solutions for their SaaS products. The ideal candidate will have experience with LLMs, NLP, AWS, and relational databases.",
        "industries": [
            "PropTech",
            "Technology",
            "Real Estate",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Independent work",
            "Time management",
            "Self-driven"
        ],
        "hard_skills": [
            "Machine Learning",
            "GenAI",
            "LLM",
            "Python",
            "Java",
            "NLP",
            "AWS",
            "MySQL",
            "PostgreSQL"
        ],
        "tech_stack": [
            "AI",
            "LLMs",
            "GenAI",
            "NLP",
            "AWS",
            "MySQL",
            "PostgreSQL",
            "SaaS",
            "Cloud",
            "Databases"
        ],
        "programming_languages": [
            "Python",
            "Java"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 180000,
            "min": 100000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959930467,
        "company": "Tellagence",
        "title": "Data Scientist (contract)",
        "created_on": 1720587652.9196851,
        "description": "We're seeking a mid-senior level Data Scientist to join our dynamic team and play a pivotal role in building and implementing social media attribution solutions. In this role, you'll leverage your expertise in marketing attribution, data science and analytics to evaluate the ROI and impact of social media data and provide valuable insights for optimizing marketing campaigns. Responsibilities: Conduct technical discovery to understand existing social attribution methods and document your findings. Design, develop, and implement statistical models that power automation and analyses specifically focused on social media attribution. Translate existing tools and methodologies into production-ready code that leverages Google Cloud Platform (GCP) services for scalability and efficiency. Design and develop dashboards using Google Data Studio or other visualization tools to clearly communicate model accuracy and provide an analyst view of results. Conduct ad hoc data analysis throughout the ROI/Attribution work, leveraging industry leading social data platforms such as Sprinklr, Brandwatch, Newswhip and other relevant internal data sources. Collaborate with cross-functional teams (marketing, media, engineering, product) to ensure alignment between data-driven insights and business objectives. Education & Work Experience: Master's degree in Statistics, Computer Science, Data Science, or a related field (or Bachelor's degree with significant experience). 3-5 years of experience as a Data Scientist or similar role. Strong proficiency in Python (including libraries like pandas, scikit-learn) and SQL. Experience with machine learning algorithms and a solid understanding of statistical analysis. Familiarity with Google Cloud Platform (GCP) and Google Analytics is a plus. Excellent communication and collaboration skills. Ability to work independently and manage multiple projects simultaneously. Bonus Points: Prior experience with social media attribution modeling or econometrics/MMM Familiarity with Google Marketing Platform products (DoubleClick Campaign Manager, Google Ads, etc.) and social media analytics software (Sprinklr, Brandwatch or other Social Listening software) Please note this is a 6-month duration contract from July - December.",
        "url": "https://www.linkedin.com/jobs/view/3959930467",
        "summary": "Data Scientist needed to build and implement social media attribution solutions. Responsibilities include designing statistical models, developing dashboards, conducting ad-hoc data analysis, and collaborating with cross-functional teams.",
        "industries": [
            "Marketing",
            "Social Media",
            "Analytics",
            "Data Science",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Time Management"
        ],
        "hard_skills": [
            "Python",
            "Pandas",
            "Scikit-learn",
            "SQL",
            "Machine Learning",
            "Statistical Analysis",
            "Data Visualization",
            "Google Cloud Platform",
            "Google Analytics",
            "Google Data Studio",
            "Sprinklr",
            "Brandwatch",
            "Newswhip"
        ],
        "tech_stack": [
            "Google Cloud Platform (GCP)",
            "Google Analytics",
            "Google Data Studio",
            "Sprinklr",
            "Brandwatch",
            "Newswhip"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Statistics",
                "Computer Science",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3960133812,
        "company": "Augment Jobs",
        "title": "Machine Learning Engineer",
        "created_on": 1720587654.289779,
        "description": "Position Overview: We are looking for a skilled and motivated Machine Learning Engineer to join our team. As a Machine Learning Engineer, you will be responsible for designing, implementing, and deploying machine learning models and systems that solve complex business problems and drive innovation. You will collaborate closely with data scientists, software engineers, and cross-functional teams to deliver scalable and robust machine learning solutions. Roles And Responsibilities Machine Learning Model Development: Design and develop machine learning models and algorithms to address business challenges and opportunities. Implement state-of-the-art machine learning techniques and frameworks to analyze and interpret large datasets. Optimize models for performance, scalability, and reliability in production environments. Data Preparation and Feature Engineering: Collect, preprocess, and clean data from various sources to build high-quality datasets for model training. Perform feature engineering and selection to enhance model accuracy and generalization capabilities. Collaborate with data engineers to ensure efficient data pipelines and data quality. Model Training and Evaluation: Train, validate, and test machine learning models using appropriate methodologies and metrics. Conduct experiments and iterate on models to improve performance and achieve desired outcomes. Implement model monitoring and evaluation strategies to ensure ongoing model accuracy and effectiveness. Deployment and Integration: Deploy machine learning models into production environments and integrate them with existing systems and applications. Collaborate with software engineering teams to implement scalable and efficient APIs and services for model inference. Ensure robustness, scalability, and security of deployed machine learning solutions. Collaboration and Communication: Work closely with data scientists, product managers, and stakeholders to understand business requirements and translate them into technical solutions. Communicate technical concepts, methodologies, and results to non-technical stakeholders in a clear and concise manner. Collaborate with cross-functional teams to drive the adoption of machine learning solutions and support ongoing improvements. Skills And Qualifications Proven experience (X+ years) as a Machine Learning Engineer or similar role, with a strong background in machine learning, deep learning, and data science. Proficiency in programming languages commonly used in machine learning (e.g., Python, TensorFlow, PyTorch, scikit-learn). Solid understanding of machine learning algorithms, statistical models, and optimization techniques. Experience with data preprocessing, feature engineering, and model evaluation. Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and containerization technologies (e.g., Docker, Kubernetes). Strong analytical and problem-solving skills, with the ability to troubleshoot complex issues and drive solutions. Excellent communication and collaboration skills, with the ability to work effectively in a team environment. Education Bachelor’s degree in Computer Science, Engineering, Mathematics, or a related field; advanced degree (e.g., Master’s, PhD) in Machine Learning or Data Science is preferred. Additional Attributes Passion for machine learning and artificial intelligence, with a desire to innovate and apply new technologies to solve real-world problems. Ability to thrive in a fast-paced, dynamic environment and adapt to evolving business requirements. Detail-oriented and results-driven, with a focus on delivering high-quality machine learning solutions that meet business objectives. This job description outlines the critical responsibilities and qualifications expected of a Machine Learning Engineer role, emphasizing expertise in machine learning model development, data preparation, model deployment, collaboration, and communication. Adjustments can be made based on specific company needs, industry focus, and organizational structure.",
        "url": "https://www.linkedin.com/jobs/view/3960133812",
        "summary": "We are looking for a skilled and motivated Machine Learning Engineer to design, implement, and deploy machine learning models and systems that solve complex business problems and drive innovation. You will collaborate closely with data scientists, software engineers, and cross-functional teams to deliver scalable and robust machine learning solutions.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical Skills",
            "Detail-Oriented",
            "Results-Driven"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Data Science",
            "Python",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Data Preprocessing",
            "Feature Engineering",
            "Model Evaluation",
            "AWS",
            "Azure",
            "GCP",
            "Docker",
            "Kubernetes"
        ],
        "tech_stack": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "AWS",
            "Azure",
            "GCP",
            "Docker",
            "Kubernetes"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York, NY",
        "job_id": 3965101176,
        "company": "SoFi",
        "title": "Senior Data Scientist, Pricing",
        "created_on": 1720587655.6212623,
        "description": "Employee Applicant Privacy Notice Who we are: Shape a brighter financial future with us. Together with our members, we’re changing the way people think about and interact with personal finance. We’re a next-generation financial services company and national bank using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. Join us to invest in yourself, your career, and the financial world. The role We are seeking a Senior Data Scientist to join our Pricing team in the Lending Organization, with focus on our Personal Loans (PL) business. This is an exciting role for someone to make a direct impact on the revenue of SoFi. As a senior data scientist in our Pricing team, you will be working closely with a world-class team of business leaders and data scientists to help develop, launch, and monitor SoFi pricing strategies across our PL business. What you’ll do: Develop and test pricing strategies that optimize for profitability through the improvement of revenue, credit risk, and/or cost per customer acquisition Innovate and own new pricing strategies to drive company profits Run significance tests and continuously discover trends in customer behavior to inform decision making with a high level of confidence Leverage pricing models to simulate profitability from pricing strategies and forecast changes to SoFi’s customer credit portfolio Build reporting pipelines and dashboards to deliver results of pricing strategies to the business Build intuitive and analytical models to help decision makers understand the price elasticity of customer segments Routinely present analyses to SoFi business leaders. What you’ll need: B.S. or M.S. in Computer Science, Statistics, Operations Research, Engineering, Mathematics or a related quantitative field is required for this position. M.B.A preferred, not required. 5-7 years of industrial experience working in the area of pricing, financial services, consulting, and/or credit risk strategies Proven track record of end-to-end experience in utilizing and laying strategic framework for model development, testing, implementation and performance tracking in the financial services industry Exceptional programming skills in Python and SQL Strong knowledge of Tableau and experience building production-level dashboards Ability to work in a dynamic, cross-functional environment, with strong attention to detail Effective communication skills and ability to explain complex concepts in simple terms Strong relationship building and collaborative skills Excels in a fast moving environment with outstanding stakeholder management abilities Exceptional problem-solving skills Nice to have: Experience working with product and/or engineering teams Experience working in the consumer unsecured lending space Experience with Snowflake, Gitlab, & DBT Experience with machine learning and statistical modeling methods for supervised and unsupervised learning Compensation And Benefits The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location. To view all of our comprehensive and competitive benefits, visit our Benefits at SoFi page! SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law. The Company hires the best qualified candidate for the job, without regard to protected characteristics. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. New York applicants: Notice of Employee Rights SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com. Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time. Internal Employees If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.",
        "url": "https://www.linkedin.com/jobs/view/3965101176",
        "summary": "SoFi is seeking a Senior Data Scientist to join their Pricing team in the Lending Organization. The role will focus on Personal Loans (PL) and involve developing, testing, and launching pricing strategies to optimize profitability. The ideal candidate will have strong programming skills in Python and SQL, experience with Tableau, and a proven track record in model development and implementation in the financial services industry.",
        "industries": [
            "Financial Services",
            "Lending",
            "Banking",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Relationship Building",
            "Collaboration",
            "Stakeholder Management",
            "Attention to Detail",
            "Analytical",
            "Presentation",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Tableau",
            "Model Development",
            "Model Implementation",
            "Performance Tracking",
            "Pricing Strategy",
            "Credit Risk",
            "Customer Acquisition",
            "Data Analysis",
            "Significance Testing",
            "Trend Analysis",
            "Customer Behavior",
            "Profitability Analysis",
            "Reporting",
            "Dashboards",
            "Price Elasticity"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Tableau",
            "Snowflake",
            "Gitlab",
            "DBT"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Computer Science",
                "Statistics",
                "Operations Research",
                "Engineering",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive benefits"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New Jersey, United States",
        "job_id": 3965661211,
        "company": "Hexaware Technologies",
        "title": "Data Scientist",
        "created_on": 1720587657.0765598,
        "description": "What Working at Hexaware offers: Hexaware is a dynamic and innovative IT organization committed to delivering cutting-edge solutions to our clients worldwide. We pride ourselves on fostering a collaborative and inclusive work environment where every team member is valued and empowered to succeed. Hexaware provides access to a vast array of tools that enhance, revolutionize, and advance professional profile. We complete the circle with excellent growth opportunities, chances to collaborate with highly visible customers, chances to work alongside bright brains, and the perfect work-life balance. With an ever-expanding portfolio of capabilities, we delve deep into and identify the source of our motivation. Although technology is at the core of our solutions, it is still the people and their passion that fuel Hexaware’s commitment towards creating smiles. “At Hexaware we encourage to challenge oneself to achieve full potential and propel growth. We trust and empower to disrupt the status quo and innovate for a better future. We encourage an open and inspiring culture that fosters learning and brings talented, passionate, and caring people together.” We are always interested in, and want to support, the professional and personal you. We offer a wide array of programs to help expand skills and supercharge careers. We help discover passion—the driving force that makes one smile and innovate, create, and make a difference every day. The Hexaware Advantage: Your Workplace Benefits Health benefits with low-cost employee premium. range of voluntary benefits such as Legal, Identity theft and Critical Care Coverage training and upskilling opportunities through Udemy and Hexavarsity Role: Data Scientist Work Mode: Hybrid (NJ/CT) Salary Range: $120K - $130K Role: Data Scientist: Someone with experience in predictive modeling and LLM application building / architecture Skill-sets: Python Spark Efficient data manipulation Tree based and NN based model training with large data Experience with OCR, layout model File parsing with various file types LLM, RAG Experience with using REST API Great coding practice Communication Nice to have Databricks Sentiment analysis Insurance especially commercial claims experience / knowledge with medical or injuries French / Swedish language Experience Required: 10 years of experience, Or 8 years with Master in relevant fields Privacy Statement: The information you provide will be used in accordance with the terms of our Privacy Policy and will be used specifically for the business/processing purpose of the event. You should be aware that we may share your details with our approved vendors for this event to be handled successfully.",
        "url": "https://www.linkedin.com/jobs/view/3965661211",
        "summary": "Hexaware is seeking a Data Scientist with 10 years of experience (or 8 years with a Master's degree) to join their team in a hybrid work model (NJ/CT). The role involves predictive modeling, LLM application building, and data manipulation using Python and Spark. The salary range is $120K - $130K.",
        "industries": [
            "IT",
            "Technology",
            "Software Development",
            "Data Science",
            "Insurance"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Creativity",
            "Passion"
        ],
        "hard_skills": [
            "Python",
            "Spark",
            "Data Manipulation",
            "Tree based models",
            "NN based models",
            "Large Data",
            "OCR",
            "Layout Model",
            "File Parsing",
            "LLM",
            "RAG",
            "REST API",
            "Coding",
            "Databricks",
            "Sentiment Analysis"
        ],
        "tech_stack": [
            "Python",
            "Spark",
            "LLM",
            "RAG",
            "REST API",
            "Databricks"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 130000,
            "min": 120000
        },
        "benefits": [
            "Health Benefits",
            "Voluntary Benefits",
            "Training and Upskilling Opportunities",
            "Udemy",
            "Hexavarsity"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3969225473,
        "company": "Oreva Technologies, Inc.",
        "title": "Decision Scientist",
        "created_on": 1720587660.9245384,
        "description": "Role - Decision Scientist Work Auth – USC or GC Top 3 Skills Needed: 1: Skill: all the broad technical skills listed above – 6 years 2: Skill: Data aggregation experience – 6 years Application: taking messy data sets and being able to put them together in one section 3: Skill: collaboration/prioritization – 6 years We have the following remote contract (working PST business hours) with Starbucks. This came in on Fri morning while our office was closed. Since they usually shortlist candidates 48 business hours after posting, this means I will need any candidates sent to me by 3pm PST today in order to get them in on time. They will likely shortlist candidates tomorrow by 9am, so I need to have them submitted in the system before tomorrow. Once this happens the role will halt. This starts at 6 months, and it states that it possibly could extend up to 12 monthsI need to be able to talk to them by 4pm PST today at the latest. After that I will not be available. Thanks. Decision Scientist As a decision scientist on Portfolio Management for US Licensed Stores, you will… Daily Responsibilities: • Updating reporting dashboards weekly • Maintaining existing dashboards (including issue resolution) • Building new dashboards and tools • Gathering requirements • Querying data tables • Aggregating data from multiple sources and in varying formats • Cleaning up data • Building flexible dashboards/visualizations • Cross-functional collaboration • Project management Degree or certifications required?: • None Years experience?: • 6+ Required background? Skills?: • Strong prioritization skills • Business acumen (or experience working directly with business partners) • Strong cross-functional collaboration • Proactive communication • Keen critical thinking skills and strong analytical ability • Ability to simplify and structure complex and ambiguous problems • Strong communication and ability to present work to team leadership and other partners Nice-to-Haves: • Experience in product/brand management • Experience interfacing directly with business partners and/or sitting on a team solely comprised of business partners • Advanced degree in related field • Any degrees or certifications Top 3 Skills Needed: 1: Skill: all the broad technical skills listed above – 6 years 2: Skill: Data aggregation experience – 6 years Application: taking messy data sets and being able to put them together in one section 3: Skill: collaboration/prioritization – 6 years",
        "url": "https://www.linkedin.com/jobs/view/3969225473",
        "summary": "Decision Scientist for Portfolio Management at Starbucks, responsible for updating, maintaining, and building reporting dashboards, querying data, aggregating data from multiple sources, cleaning data, and collaborating with cross-functional teams.",
        "industries": [
            "Retail",
            "Data Science",
            "Business Intelligence"
        ],
        "soft_skills": [
            "Prioritization",
            "Business Acumen",
            "Cross-functional Collaboration",
            "Proactive Communication",
            "Critical Thinking",
            "Analytical Ability",
            "Problem Solving",
            "Communication",
            "Presentation"
        ],
        "hard_skills": [
            "Data Aggregation",
            "Data Cleaning",
            "Data Querying",
            "Dashboard Building",
            "Visualization",
            "Project Management"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 6,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3966372931,
        "company": "Arctos",
        "title": "Data Scientist",
        "created_on": 1720587662.3079114,
        "description": "Arctos is a private investment firm that provides bespoke growth and liquidity solutions, differentiated thought partnership, and value creation advice to sports franchises (Arctos Sports) and alternative asset managers, their funds, and portfolio companies (Arctos Keystone). Founded in 2019, Arctos serves as a catalyst for innovation and business transformation for its portfolio companies and its markets. The firm’s proprietary approach is anchored by its unique quantitative research and data science platform, Arctos Insights. At Arctos, we believe that our Core Values, Character – as individuals and as a collective, Insight, Excellence, Teamwork, Trust, and Servant Leadership are our hallmarks and guide. Arctos is a U.S.-based firm with offices in Dallas, New York and London. Responsibilities: ·         Standardize unstructured data using cleaning, parsing and clustering techniques. ·         Utilize NLP / embedding techniques to contextualize unstructured business data. ·         Convert business questions in sports and private markets into mathematical frameworks. ·         Collaborate internally and externally with investment professionals and business leaders to understand their approach to data and key questions that could be answered for them or their industry with analytics ·         Build visualizations to help illustrate results to a broad spectrum of stakeholders ·         Contribute to Arctos Insights from idea generation through execution and publication of white papers and other industry-leading research pieces. ·         Apply advanced statistical and machine learning techniques to build predictive models and algorithms that support decision-making processes inside Arctos, the markets it serves and its portfolio companies. ·         Ensure data quality and integrity throughout the data lifecycle. ·         Assist with and/or manage various firm projects and initiatives Desired qualifications include but are not limited to: ·         Collaborative team player who shares Arctos’ values ·         At least five to seven years experience in data science, data engineering, data architecture or a similar role. ·         Bachelor’s degree with a strong academic record (GPA of 3.5+), preferably in computer science, statistics, mathematics or a related field. ·         Strong command of Python, R, and SQL, experience with cloud technologies and knowledge of data visualization tools preferred. Experience with Palantir’s Foundry platform is preferred, but not required. · Ability to self-direct and manage projects, interact and build relationships with multiple  stakeholders ·         Strong written and oral communication skills, including an ability to lead discussions with non-technical stakeholders · Ability to analyze, evaluate, form independent judgments and think creatively · Highly detail-oriented and strong organizational skills Qualified applicants should submit a resume and cover letter to meaghan.murphy@arctospartners.com. To learn more about Arctos please visit our website. Arctos Partners is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to their race, color, sex, gender or gender identity, religion, age, national origin, alienage or citizenship, physical or mental disability, sexual orientation, veteran status, or any other classification protected by applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3966372931",
        "summary": "Arctos, a private investment firm focused on sports franchises and alternative asset management, seeks a Data Scientist to lead the development and implementation of data-driven solutions. This role will involve standardizing unstructured data, utilizing NLP techniques, translating business questions into mathematical frameworks, collaborating with internal and external stakeholders, building visualizations, and contributing to Arctos Insights research. The ideal candidate will have 5-7 years of experience in data science, a strong academic background (GPA 3.5+), proficiency in Python, R, SQL, cloud technologies, and data visualization tools. Experience with Palantir's Foundry platform is preferred but not required.",
        "industries": [
            "Finance",
            "Sports",
            "Investment Management",
            "Alternative Investments",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-Solving",
            "Leadership",
            "Teamwork",
            "Analytical Thinking",
            "Critical Thinking",
            "Detail-Oriented",
            "Organization",
            "Relationship Building",
            "Project Management",
            "Self-Direction"
        ],
        "hard_skills": [
            "Data Cleaning",
            "Data Parsing",
            "Clustering",
            "NLP",
            "Data Embedding",
            "Statistical Modeling",
            "Machine Learning",
            "Predictive Modeling",
            "Algorithm Development",
            "Data Visualization",
            "Python",
            "R",
            "SQL",
            "Cloud Technologies",
            "Palantir Foundry"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Cloud Technologies",
            "Palantir Foundry"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Atlanta, GA",
        "job_id": 3961454227,
        "company": "The Home Depot",
        "title": "Associate Data Scientist",
        "created_on": 1720587663.8160925,
        "description": "Req119587 Position Purpose The Associate Data Scientist is responsible for supporting data science initiatives that drive business profitability, increased efficiencies and improved customer experience. This role works closely with Data Scientists and/or Sr. Data Scientists in their team to develop solutions by applying advanced analytics methods and algorithms for identifying trends and providing business solutions. Based on the specific data science team, this role may need to develop skills in one or more data science specializations, such as optimization, computer vision, recommendation, search or NLP. As an Associate Data Scientist, you will develop skills that effectively leverage data science methodologies to creatively solve business problems and provide strategic insights. This requires effective communication skills as well as continuous learning and development at both the technical and business level. Key Responsibilities 70% Solution Development - Design and develop algorithms and models to use against large datasets to create business insights; Supports data science projects by conducting effective analysis to solve business problems; Executes tasks with high levels of efficiency and quality; Consults with Data Scientist or Sr. Data Scientist on appropriate selection, utilization and interpretation of advanced analytical methodologies; Learn about the assigned business areas to provide better solutions by incorporating business-specific knowledge 20% Communicating Results - Effectively communicate insights and recommendations to both technical and non-technical audience; Support preparation of reports, updates and/or presentations related to progress made on a project or solution; Highlights potential impacts of recommendations to drive alignment and appropriate implementation 10% Technical Learning - Keep up to date on industry trends, best practices and emerging methodologies; Continually develop skills and expertise in data analytics concepts and methodologies; Identify opportunities to apply learnings Direct Manager/Direct Reports This position reports to manager or above This position has 0 direct reports Travel Requirements No travel required. Physical Requirements Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles. Working Conditions Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable. Minimum Qualifications Must be eighteen years of age or older. Must be legally permitted to work in the United States. Preferred Qualifications Master's degree in a quantitative field (Computer Science, Math, Statistics, etc.) or equivalent work experience 3+ years of experience in business intelligence and analytics Working knowledge of Microsoft Excel and Power Point Experience in a modern scripting language (preferably Python) Experience running queries against data (preferably with Google BigQuery or SQL) Experience in predictive modeling, data mining and data analysis Experience with data visualization software (preferably Tableau) Experience utilizing statistical techniques to identify key insights that help solve business problems Basic knowledge or exposure to Prescriptive Modeling like optimization, computer vision, recommendation, search or NLP Basic knowledge or exposure to predictive modeling, data mining and data analysis Minimum Education The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job. Preferred Education No additional education Minimum Years Of Work Experience 0 Preferred Years Of Work Experience No additional years of experience Minimum Leadership Experience None Preferred Leadership Experience None Certifications None Competencies Action Oriented: Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasm Business Insight: Applying knowledge of the business and the marketplace to advance the organization's goals Collaborates: Building partnerships and working collaboratively with others to meet shared objectives Communicates Effectively: Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences Customer Focus: Building strong customer relationships and delivering customer-centric solutions Drives Results: Consistently achieving results, even under tough circumstances Nimble Learning: Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder Optimizes Work Processes: Knowing the most efficient and effective processes to get things done, with a focus on continuous improvement Plans and Aligns: Planning and prioritizing work to meet commitments aligned with organizational goals Self-Development: Actively seeking new ways to grow and be challenged using both formal and informal development channels",
        "url": "https://www.linkedin.com/jobs/view/3961454227",
        "summary": "The Associate Data Scientist role supports data science initiatives driving business profitability, efficiency, and customer experience. This individual collaborates with senior data scientists to develop solutions using advanced analytics and algorithms, focusing on areas like optimization, computer vision, recommendations, search, or NLP. Strong communication and continuous learning are crucial, as this role analyzes large datasets, develops models, and communicates insights to both technical and non-technical audiences.",
        "industries": [
            "Data Science",
            "Analytics",
            "Business Intelligence",
            "Technology",
            "Customer Experience"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Decision Making",
            "Time Management",
            "Organization",
            "Learning Agility",
            "Adaptability",
            "Teamwork",
            "Customer Focus",
            "Presentation Skills",
            "Leadership"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Mining",
            "Predictive Modeling",
            "Machine Learning",
            "Statistical Techniques",
            "Optimization",
            "Computer Vision",
            "Recommendation Systems",
            "Search Algorithms",
            "NLP",
            "Python",
            "SQL",
            "Google BigQuery",
            "Tableau",
            "Microsoft Excel",
            "PowerPoint"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Google BigQuery",
            "Tableau",
            "Microsoft Excel",
            "PowerPoint"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Math",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Boston, MA",
        "job_id": 3967787869,
        "company": "John Hancock",
        "title": "Associate Data Scientist",
        "created_on": 1720587665.2923386,
        "description": "We are a leading financial services provider committed to making decisions easier and lives better for our customers and colleagues around the world. From our environmental initiatives to our community investments, we lead with values throughout our business. To help us stand out, we help you step up, because when colleagues are healthy, respected and meaningfully challenged, we all thrive. Discover how you can grow your career, make impact and drive real change with our Winning Team today. Working Arrangement Hybrid Job Description The Opportunity John Hancock’s Advanced Analytics & AI team works across the US Insurance business to optimize our sales and marketing activities, make life insurance easy to buy, and streamline in-force and claims operations! We have close relationships with functional leadership across the business and a strong working relationship with technology partners. As part of a 160+ member community of data scientists, John Hancock, and our parent Manulife, you will have an opportunity to network with experts across the globe. John Hancock is a unit of Manulife Financial Corporation, a leading international financial services group offering insurance and wealth management solutions in the US, Canada, Europe, and Asia! We are on a transformational journey. We want to remove complexity from the financial services industry, to make people’s lives better and decisions easier. Being part of this transformation is hugely exciting and offers dedicated, ambitious people an amazing opportunity to build a career. You will work as part of multi-functional team including actuaries and business domain experts. With help from SMEs, you will transform policy language into code to create automated projections and simulations as part of systems testing. You will independently experiment with data and communicate findings to your team and other partners. Responsibilities Actively participate in the development of data analytics-enabled solutions to improve internal business processes. Generate useful insights based on iterative data analysis and make appropriate recommendations to business partners. Develop ML models and AI solutions to enable business values. Effectively Collaborate with cross-functional teams, establish an internal network. Strong communication to help business partners better understand the use of data, ML models and AI solutions. Keep up with new developments in AI, machine learning, and alternative data sources. What motivates you? You obsess about customers, listen, engage and act for their benefit. You think big, with curiosity to discover ways to use your agile approach and enable business outcomes. You thrive in teams and enjoy getting things done together. You take ownership and build solutions, focusing on what matters. You do what is right, work with integrity and speak up. You share your humanity, helping us build a diverse and inclusive work environment for everyone. What We Are Looking For Master’s degree in a quantitative field such as Statistics, Applied Mathematics, Data Science, Engineering, or Computer Science or Physics Proficient in programming using Python and SQL. Proven problem-solving abilities, including conducting root cause analysis to address specific business inquiries and find opportunities for enhancement. Demonstrated expertise in the data analytics life cycle, encompassing problem framing, data collection, data cleansing, insights generation, reporting, and communication. Good understanding of statistics and related technical fields. Skilled in the machine learning modeling life cycle, including exploratory data analysis, data cleansing, feature engineering, model building, deployment and monitoring. Solid knowledge and highly skilled in supervised and unsupervised machine learning algorithms and deep learning. Experience in developing and deploying models in cloud-based environments, specifically Microsoft Azure. What can we offer you? A competitive salary and benefits packages. A growth trajectory that extends upward and outward, encouraging you to follow your passions and learn new skills. A focus on growing your career path with us. Flexible work policies and strong work-life balance. Professional development and leadership opportunities. Our commitment to you Values-first culture: We lead with our Values every day and bring them to life together. Boundless opportunity: We create opportunities to learn and grow at every stage of your career. Continuous innovation: We invite you to help redefine the future of financial services. Delivering the promise of Diversity, Equity and Inclusion: We foster an inclusive workplace where everyone thrives. Championing Corporate Citizenship: We build a business that benefits all partners and has a positive social and environmental impact. About Manulife And John Hancock Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. With our global headquarters in Toronto, Canada, we operate as Manulife across our offices in Asia, Canada, and Europe, and primarily as John Hancock in the United States. We provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. At the end of 2022, we had more than 40,000 employees, over 116,000 agents, and thousands of distribution partners, serving over 34 million customers. At the end of 2022, we had $1.3 trillion (US$1.0 trillion) in assets under management and administration, including total invested assets of $0.4 trillion (US $0.3 trillion), and segregated funds net assets of $0.3 trillion (US$0.3 trillion). We trade as ‘MFC’ on the Toronto, New York, and the Philippine stock exchanges, and under ‘945’ in Hong Kong. Manulife is an Equal Opportunity Employer At Manulife /John Hancock , we embrace our diversity. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour , ethnic origin, citizenship, religion or religious beliefs, creed, sex (including pregnancy and pregnancy-related conditions), sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law. It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will work with applicants who request a reasonable accommodation during the application process . All information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and Manulife/John Hancock policies . To request a reasonable accommodation in the application process, contact recruitment@manulife.com. Salary & Benefits The annual base salary for this role is listed below. Primary Location Boston, Massachusetts Salary range is expected to be between $68,740.00 USD - $127,660.00 USD If you are applying for this role outside of the primary location, please contact recruitment@manulife.com for the salary range for your location. The actual salary will vary depending on local market conditions, geography and relevant job-related factors such as knowledge, skills, qualifications, experience, and education/training. Employees also have the opportunity to participate in incentive programs and earn incentive compensation tied to business and individual performance. Manulife/John Hancock offers eligible employees a wide array of customizable benefits, including health, dental, mental health, vision, short- and long-term disability, life and AD&D insurance coverage, adoption/surrogacy and wellness benefits, and employee/family assistance plans. We also offer eligible employees various retirement savings plans (including pension/401(k) savings plans and a global share ownership plan with employer matching contributions) and financial education and counseling resources. Our generous paid time off program in the U.S. includes up to 11 paid holidays, 3 personal days, 150 hours of vacation, and 40 hours of sick time (or more where required by law) each year, and we offer the full range of statutory leaves of absence. Know Your Rights I Family & Medical Leave I Employee Polygraph Protection I Right to Work I E-Verify I Pay Transparency Company: John Hancock Life Insurance Company (U.S.A.)",
        "url": "https://www.linkedin.com/jobs/view/3967787869",
        "summary": "John Hancock's Advanced Analytics & AI team is seeking a Data Scientist to join their team and contribute to optimizing sales and marketing activities, streamlining operations, and developing AI solutions. The ideal candidate will have a Master's degree in a quantitative field, proficiency in Python and SQL, experience with data analytics, machine learning, and cloud-based environments (especially Microsoft Azure).",
        "industries": [
            "Financial Services",
            "Insurance",
            "Data Science",
            "Analytics",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Ownership",
            "Curiosity",
            "Integrity"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Data Analytics",
            "Machine Learning",
            "Deep Learning",
            "Statistics",
            "Data Cleansing",
            "Feature Engineering",
            "Model Building",
            "Deployment",
            "Monitoring",
            "Microsoft Azure",
            "Root Cause Analysis"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Microsoft Azure"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Statistics",
                "Applied Mathematics",
                "Data Science",
                "Engineering",
                "Computer Science",
                "Physics"
            ]
        },
        "salary": {
            "max": 127660,
            "min": 68740
        },
        "benefits": [
            "Competitive Salary",
            "Benefits Packages",
            "Growth Opportunities",
            "Flexible Work Policies",
            "Work-Life Balance",
            "Professional Development",
            "Leadership Opportunities",
            "Health Insurance",
            "Dental Insurance",
            "Mental Health Benefits",
            "Vision Insurance",
            "Disability Insurance",
            "Life Insurance",
            "AD&D Insurance",
            "Adoption/Surrogacy Benefits",
            "Wellness Benefits",
            "Employee/Family Assistance Plans",
            "Retirement Savings Plans",
            "Pension/401(k) Savings Plans",
            "Global Share Ownership Plan",
            "Financial Education",
            "Financial Counseling",
            "Paid Time Off",
            "Holidays",
            "Personal Days",
            "Vacation",
            "Sick Time",
            "Statutory Leaves of Absence"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Francisco, CA",
        "job_id": 3970207835,
        "company": "Replicate",
        "title": "Machine Learning Engineer",
        "created_on": 1720587666.9472036,
        "description": "You’re a machine learning engineer who is an expert at productionizing and optimizing models. We have a huge library of community-contributed machine learning models. You’ll maintain some of the most popular ones so they’re fast and reliable. It’ll involve implementing open-source models, optimizing them, and doing general maintenance on them. It’s part ML engineer, part open-source gardener. We’re Looking For The Right Person, Not Just Someone Who Checks Boxes, So You Don’t Need To Satisfy All Of These Things. But, You Might Have Some Of These Qualities A balance of software engineering and machine learning skills. - You can squeeze every last drop of performance out of a GPU. - You’ve worked with model compression techniques like pruning and distillation. - You know your way out of CUDA error: device-side assert triggered. - Ideally you’re involved in the generative AI community and familiar with diffusion models and similar techniques. - You don’t need a PhD or know how to build new architectures from scratch. - Excellent communication skills. We think most of being a programmer is not programming. We want you to be able to communicate complex topics clearly, write down your thinking, write good docs, etc.",
        "url": "https://www.linkedin.com/jobs/view/3970207835",
        "summary": "Machine learning engineer responsible for maintaining and optimizing a library of community-contributed models, focusing on performance and reliability. This role involves implementing open-source models, optimizing them, and general maintenance, requiring a blend of software engineering and machine learning expertise.  Strong communication skills are essential for documenting and explaining complex technical concepts.",
        "industries": [
            "Machine Learning",
            "Artificial Intelligence",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Documentation",
            "Problem Solving",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "Software Engineering",
            "Model Optimization",
            "Performance Tuning",
            "CUDA",
            "Model Compression",
            "Pruning",
            "Distillation",
            "Generative AI",
            "Diffusion Models"
        ],
        "tech_stack": [
            "CUDA",
            "Open Source"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Tempe, AZ",
        "job_id": 3963350237,
        "company": "Prosum",
        "title": "Machine Learning Engineer",
        "created_on": 1720587669.7881382,
        "description": "Position Title: Jr. AI/ML Engineer Location: Hybrid Work Schedule (Tempe, AZ/Remote) Term: Full-time/Direct hire Compensation: Negotiable Salary, plus Benefits Our direct client is actively searching for a talented AI/ML Engineer to join their team. As an AI/ML Engineer, you will play a crucial role in the development and implementation of cutting-edge artificial intelligence products. Your responsibilities will involve designing and constructing machine learning models, as well as refining and updating existing systems. Responsibilities Study and transform data science prototypes Design machine learning systems Research and implement appropriate ML algorithms and tools Develop machine learning applications according to requirements Select appropriate datasets and data representation methods Run machine learning tests and experiments Perform statistical analysis and fine-tuning using test results Train and retrain systems when necessary Extend existing ML libraries and frameworks Keep abreast of developments in the field Requirements and skills Master’s degree in Data Science, Computer Science, Mathematics or similar field 1+ year of proven experience as a Machine Learning Engineer or similar role Understanding of data structures, data modeling and software architecture Strong knowledge of math, probability, statistics and algorithms Ability to write code in Python, Java and R Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn) Excellent communication skills Ability to work in a team Outstanding analytical and problem-solving skills",
        "url": "https://www.linkedin.com/jobs/view/3963350237",
        "summary": "This is a full-time, direct-hire position for a Jr. AI/ML Engineer. The role involves designing and implementing machine learning models, researching and implementing algorithms, developing applications, and maintaining existing systems. The candidate should have a Master's degree in a related field and 1+ years of experience in machine learning.",
        "industries": [
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science",
            "Software Development",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Analytical",
            "Problem Solving"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Data Structures",
            "Data Modeling",
            "Software Architecture",
            "Math",
            "Probability",
            "Statistics",
            "Algorithms",
            "Python",
            "Java",
            "R",
            "Keras",
            "PyTorch",
            "Scikit-learn"
        ],
        "tech_stack": [
            "Keras",
            "PyTorch",
            "Scikit-learn"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "R"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Negotiable Salary",
            "Benefits"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Oregon, United States",
        "job_id": 3962957408,
        "company": "Red Oak Technologies",
        "title": "Data Scientist",
        "created_on": 1720587671.3701465,
        "description": "Remote in these states: California, Oregon, Washington, Georgia, Colorado, Maryland Red Oak Technologies is a leading provider of comprehensive resourcing solutions across a variety of industries and sectors including IT, Marketing, Finance, Business Operations, Manufacturing and Engineering. We specialize in quickly acquiring and efficiently matching top-tier professional talent with clients in immediate need of highly skilled contract, permanent or project management based resources. Job Summary: This individual contributor is primarily responsible for designing and developing data pipelines and automation for data acquisition and ingestion of raw data from multiple data sources and data formats by transforming, cleansing, and storing data for consumption. This role is also responsible for developing detailed problem statements outlining hypotheses and their effect on target clients/customers, analyzing and investigating complex data sets and summarizing key characteristics, selecting, manipulating and transforming data into features used in machine learning algorithms, training statistical models, deploying and maintaining reliable and efficient models through production, verifying model performance, and collaborating with internal and external stakeholders across domains to develop and deliver statistical driven outcomes. Essential Responsibilities: Promotes learning in others by proactively providing and/or developing information, resources, advice, and expertise with coworkers and members; builds relationships with cross-functional/external stakeholders and customers. Listens to, seeks, and addresses performance feedback; proactively provides actionable feedback to others and to managers. Pursues self-development; creates and executes plans to capitalize on strengths and develop weaknesses; leads by influencing others through technical explanations and examples and provides options and recommendations. Adopts new responsibilities; adapts to and learns from change, challenges, and feedback; demonstrates flexibility in approaches to work; champions change and helps others adapt to new tasks and processes. Facilitates team collaboration to support a business outcome. Completes work assignments autonomously and supports business-specific projects by applying expertise in subject area and business knowledge to generate creative solutions; encourages team members to adapt to and follow all procedures and policies. Collaborates cross-functionally and/or externally to achieve effective business decisions; provides recommendations and solves complex problems; escalates high-priority issues or risks, as appropriate; monitors progress and results. Supports the development of work plans to meet business priorities and deadlines; identifies resources to accomplish priorities and deadlines. Identifies, speaks up, and capitalizes on improvement opportunities across teams; uses influence to guide others and engages stakeholders to achieve appropriate solutions. Develops detailed problem statements outlining hypotheses and their effect on target clients/customers by defining scope, objectives, outcome statements and metrics. Designs and develops data pipelines and automation for data acquisition and ingestion of raw data from multiple data sources and data formats by transforming, cleansing, and storing data for consumption by downstream processes; writing and optimizing diverse SQL queries; and demonstrating advanced knowledge of database fundamentals. Analyzes and investigates complex data sets and summarizes key characteristics by employing data visualization methods; and determining how best to manipulate data sources to discover patterns, spot anomalies, test hypotheses, and/or check assumptions. Selects, manipulates, and transforms data into features used in machine learning algorithms by leveraging techniques to conduct dimensionality reduction, feature importance, and feature selection. Trains statistical models by using algorithms and data mining techniques; testing models with various algorithms to assess the input dataset and related features; and applying techniques to prevent overfitting such as cross-validation. Deploys and maintains reliable and efficient models through production. Verifies model performance by demonstrating expertise in the practice of a variety of model validation techniques to assess and discriminate the goodness of model fit; and leveraging feedback and output to manage and strengthen model performance. Collaborates with internal and external stakeholders across domains to develop and deliver statistical driven outcomes by delivering insights and values from heterogeneous data to investigate complex problems for multiple use cases; driving informed decision-making; and presenting findings to both technical and non-technical audiences. Minimum Qualifications: Minimum three (3) years experience working with Exploratory Data Analysis (EDA) and visualization methods. Minimum three (3) years machine learning and/or algorithmic experience. Minimum three (3) years statistical analysis and modeling experience. Minimum three (3) years programming experience. Minimum one (1) year experience in a leadership role with or without direct reports. Bachelors degree in Mathematics, Statistics, Computer Science, Engineering, Economics, Public Health, or related field AND Minimum five (5) years experience in data science or a directly related field. Additional equivalent work experience in a directly related field may be substituted for the degree requirement. Advanced degrees may be substituted for the work experience requirements. Additional Requirements: Knowledge, Skills, and Abilities (KSAs): Advanced Quantitative Data Modeling; Algorithms; Applied Data Analysis; Data Extraction; Data Visualization Tools; Machine Learning; Relational Database Management; Microsoft Excel; Design Thinking; Business Intelligence Tools; Data Manipulation/Wrangling; Data Ensemble Techniques; Feature Analysis/Engineering; Data bricks, Azure, Open Source Languages & Tools; Model Optimization; Strategic Thinking; Deep Learning/Neural Networks; Project Management Red Oak Technologies is made up of people from a wide variety of backgrounds and lifestyles. We embrace diversity and invite applications from people of all walks of life. See what it’s like to be at the top; connect with one of our recruiters and apply today. Let us help you find your next career opportunity! JOIN RED OAK TECHNOLOGIES! Learn what it’s like to be a Red Oak Consultant! Red Oak Tech: Quality | Talent | Integrity",
        "url": "https://www.linkedin.com/jobs/view/3962957408",
        "summary": "Red Oak Technologies is seeking a Data Scientist to design and develop data pipelines, analyze complex data sets, train statistical models, and collaborate with stakeholders to deliver statistical-driven outcomes. Responsibilities include data acquisition, cleansing, and storage, as well as model deployment and performance verification. The ideal candidate will have strong expertise in data mining, machine learning algorithms, and data visualization, and experience in a leadership role.",
        "industries": [
            "IT",
            "Marketing",
            "Finance",
            "Business Operations",
            "Manufacturing",
            "Engineering"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Decision Making",
            "Leadership",
            "Adaptability",
            "Teamwork",
            "Influencing",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "Exploratory Data Analysis (EDA)",
            "Data Visualization",
            "Machine Learning",
            "Statistical Analysis",
            "Modeling",
            "Programming",
            "SQL",
            "Database Fundamentals",
            "Data Manipulation",
            "Data Wrangling",
            "Feature Engineering",
            "Dimensionality Reduction",
            "Feature Importance",
            "Feature Selection",
            "Data Mining",
            "Model Validation",
            "Model Optimization",
            "Deep Learning",
            "Neural Networks",
            "Project Management"
        ],
        "tech_stack": [
            "Azure",
            "Data Bricks",
            "Open Source Languages & Tools",
            "Microsoft Excel",
            "Business Intelligence Tools",
            "Data Visualization Tools"
        ],
        "programming_languages": [],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Engineering",
                "Economics",
                "Public Health"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Indianapolis, IN",
        "job_id": 3970924588,
        "company": "Patterned Learning Career",
        "title": "Junior Machine Learning Engineer",
        "created_on": 1720587672.9170544,
        "description": "This is a remote position. Junior Machine Learning Engineer - Remote Job, 1+ Year Experience Annual Income: $55K - $75K A valid work permit is necessary in the US About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities. Summary: As a Junior Machine Learning Engineer, you will have the opportunity to work on exciting projects, develop your skills, and contribute to the development and implementation of machine learning solutions. This is an excellent opportunity for individuals looking to kick-start their careers in the field of machine learning and gain valuable experience in a collaborative and supportive environment. Responsibilities: Collaborate with senior engineers and data scientists to understand project requirements and develop machine learning models and algorithms. Assist in collecting, preprocessing, and analyzing data to uncover patterns and insights. Implement and optimize machine learning models, algorithms, and pipelines. Participate in model evaluation, validation, and performance tuning. Contribute to the development and improvement of existing machine learning infrastructure and frameworks. Stay up-to-date with the latest advancements in machine learning and actively participate in knowledge-sharing activities within the team. Collaborate with cross-functional teams to integrate machine learning solutions into production systems. Document technical processes, methodologies, and outcomes effectively. Qualifications: Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, or a related field. Solid understanding of machine learning fundamentals, algorithms, and statistical concepts. Proficiency in programming languages such as Python, Java, or C++. Familiarity with machine learning frameworks and libraries, such as TensorFlow, PyTorch, or scikit-learn. Experience with data preprocessing, feature engineering, and model evaluation techniques. Knowledge of deep learning architectures and techniques is a plus. Familiarity with big data processing tools (e.g., Hadoop, Spark) is advantageous. Strong problem-solving skills and the ability to work on multiple projects simultaneously. Excellent communication and collaboration skills. Self-motivated with a strong desire to learn and grow in machine learning. Why Patterned Learning LLC? Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process. Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.",
        "url": "https://www.linkedin.com/jobs/view/3970924588",
        "summary": "As a Junior Machine Learning Engineer at Patterned Learning, you will contribute to the development and implementation of machine learning solutions, working on exciting projects in a collaborative environment. You will be involved in data analysis, model development, evaluation, and integration into production systems. This is a great opportunity to gain experience in machine learning and contribute to a platform that aims to enhance developer productivity.",
        "industries": [
            "Software Development",
            "Machine Learning",
            "Artificial Intelligence",
            "Technology",
            "Education"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Self-Motivation",
            "Learning",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "C++",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Data Preprocessing",
            "Feature Engineering",
            "Model Evaluation",
            "Deep Learning",
            "Hadoop",
            "Spark"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "Hadoop",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C++"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 75000,
            "min": 55000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3967936749,
        "company": "Augment Jobs",
        "title": "Data Scientist",
        "created_on": 1720587674.2729528,
        "description": "Job Description We are seeking a talented and motivated Data Scientist to join our team. The Data Scientist will utilize advanced analytical, statistical, and programming skills to collect, analyze, and interpret large datasets. This role requires expertise in data mining, machine learning, and statistical modeling to derive actionable insights that drive business decisions and innovation. Roles And Responsibilities Data Collection and Integration: Identify, collect, and preprocess large datasets from multiple sources for analysis. Develop data pipelines and workflows to streamline data processing and integration. Exploratory Data Analysis (EDA): Perform exploratory data analysis to understand patterns, trends, and anomalies in the data. Visualize data using appropriate tools and techniques to communicate findings effectively. Statistical Analysis and Modeling: Apply statistical methods and predictive modeling techniques to analyze data and solve complex problems. Develop and implement machine learning algorithms and models for classification, regression, clustering, and recommendation systems. Data Interpretation and Insights: Interpret model results and findings to extract actionable insights and recommendations. Collaborate with business stakeholders to understand requirements and provide data-driven solutions. Experimentation and Optimization: Design and conduct experiments to test hypotheses and optimize business processes. Evaluate and iterate on models and algorithms to improve performance and accuracy. Data Visualization and Reporting: Create compelling data visualizations and dashboards to present analysis results and key metrics. Prepare and present technical and non-technical audiences with clear and concise reports. Collaboration and Teamwork: Work collaboratively with cross-functional teams, including IT, business analysts, and product managers. Mentor junior team members and contribute to a culture of continuous learning and innovation. Ethics and Compliance: Ensure ethical considerations and data privacy regulations are adhered to in all data-related activities. Maintain confidentiality and integrity of sensitive information and datasets. Skills And Qualifications Master's or PhD in Computer Science, Statistics, Mathematics, Data Science, or related field. X+ years of experience as a Data Scientist or in a similar role, with a proven track record of delivering impactful data-driven solutions. Proficiency in programming languages such as Python, R, or Java, and proficiency in SQL for data querying. Strong knowledge of statistical techniques and machine learning algorithms (e.g., regression, classification, clustering, deep learning). Experience with data visualization tools (e.g., Tableau, Power BI) and big data technologies (e.g., Hadoop, Spark) is a plus. Excellent analytical and problem-solving skills, with the ability to work with complex datasets and derive meaningful insights. Strong communication skills, with the ability to explain technical concepts and analysis results to both technical and non-technical audiences. Ability to work independently and collaboratively in a fast-paced environment, with a focus on delivering high-quality work and meeting deadlines. Compensation The salary for this position is competitive and commensurate with experience. Benefits package includes health insurance, retirement plan options, paid time off, and professional development opportunities. Application Process Please submit your resume and cover letter detailing your qualifications and interest in this position. We will contact selected candidates for further interviews. This job description is designed to attract qualified candidates for a Data Scientist position by outlining specific responsibilities, required skills, and offering details about compensation and benefits. Adjustments can be made based on the company's industry, size, and specific data science needs, such as specialization in particular domains (e.g., healthcare, finance, e-commerce).",
        "url": "https://www.linkedin.com/jobs/view/3967936749",
        "summary": "We are looking for a Data Scientist with expertise in data mining, machine learning, and statistical modeling to collect, analyze, and interpret large datasets, derive actionable insights, and drive business decisions. Responsibilities include data collection, integration, exploratory data analysis, statistical modeling, interpretation of findings, experimentation, and reporting. ",
        "industries": [
            "Data Science",
            "Analytics",
            "Machine Learning",
            "Business Intelligence",
            "Technology"
        ],
        "soft_skills": [
            "Analytical",
            "Problem-Solving",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Independent Work",
            "Time Management",
            "Continuous Learning",
            "Innovation"
        ],
        "hard_skills": [
            "Python",
            "R",
            "Java",
            "SQL",
            "Data Mining",
            "Machine Learning",
            "Statistical Modeling",
            "Regression",
            "Classification",
            "Clustering",
            "Deep Learning",
            "Data Visualization",
            "Tableau",
            "Power BI",
            "Hadoop",
            "Spark",
            "Data Pipelines",
            "EDA",
            "Data Integration"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Java",
            "SQL",
            "Tableau",
            "Power BI",
            "Hadoop",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Java",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Retirement Plan",
            "Paid Time Off",
            "Professional Development Opportunities"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3963999088,
        "company": "Brooksource",
        "title": "Data Scientist",
        "created_on": 1720587675.8781617,
        "description": "Data Scientist Remote out of Indianapolis, IN This is an exciting time to join our Healthcare client! You will help the team continue to progress through the data maturity model using data science methods and principles to generate deeper insights from a great variety of internal and external data sources. To achieve this, you will identify needs, lead the design and implementation of analytical solutions, provide advice and consulting support to our key business stakeholders, and demonstrate value by executing proof-of-concept initiatives and prototyping analytical solutions to answer business questions. As a Data Scientist, you will position data science as a key competency within the enterprise and be responsible for creating value from data assets using advanced analytics capabilities including data science, machine learning, and artificial intelligence methodologies to identify critical business risk and opportunities for the client. You have an overall understanding of the key challenges in our industry. You have experience in the areas of analytics, data transformation, and data science. You are passionate about applying state-of-the-art analytical methods, as well as cutting edge machine learning algorithms to find solutions to complex business problems. Responsibilities: Identify high-impact data science use cases, develop, and implement innovative solutions to drive business impact and develop state-of-the-art analytical capabilities to address identified needs. Evaluate, drive, and implement solutions from concept to minimum viable product and final product Apply analytical and statistical methods to solve identified use cases in an agile manner using multiple data sources and analytical tools Collaborate within cross-functional teams to develop solutions, gain alignment and deliver impactful business insights; engage necessary stakeholders to enable better decision-making Interpret and communicate analytics results clearly and concisely to audiences with varying backgrounds and degrees of technical understanding. Take an enterprise mindset, linking individual responsibilities with the broader organization; focus on outcomes that provide most business value Required Skills: Master’s degree in Data Science, Computer Science, Statistics, Bioinformatics, Mathematics or equivalent field 2-3 years experience working in a hands-on capacity as a Data Scientist Strong SQL skills Experience working within large language models (LLM) Cloud Experience- AWS Boto preferred Python (or R) skills including understanding of common analytics-oriented packages/libraries Excellent communication and effective problem-solving skills; track record in serving a variety of diverse customers and projects Ability to prioritize within an interdisciplinary environment that includes data scientists, analysts, business stakeholders and other consultants Nice to have Skills: Understanding of data exploration, visualization, and BI tools such as Tableau Working knowledge of source control using git Foundational experience with Alteryx, or similar ETL application Experience with Agile development methods including Scrum and Kanban preferred Experience with Snowflake or similar cloud data warehouse platform Prior experience operationalizing data science models into production (user-facing) solutions Brooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws.",
        "url": "https://www.linkedin.com/jobs/view/3963999088",
        "summary": "A Data Scientist is needed to join a Healthcare client in Indianapolis, IN. This role will focus on using data science methods to generate insights from various internal and external data sources. The ideal candidate will have experience in analytics, data transformation, and data science, and be passionate about applying state-of-the-art analytical methods and machine learning algorithms to solve complex business problems. Responsibilities include identifying high-impact data science use cases, developing and implementing innovative solutions, evaluating and implementing solutions from concept to product, applying analytical and statistical methods to solve use cases, collaborating with cross-functional teams to develop solutions and gain alignment, and communicating analytics results clearly to various audiences. The role requires a Master's degree in a related field, 2-3 years of experience as a Data Scientist, strong SQL skills, experience with large language models (LLM), cloud experience (AWS Boto preferred), Python (or R) skills, excellent communication and problem-solving skills, and the ability to prioritize within an interdisciplinary environment.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Collaboration",
            "Prioritization",
            "Decision-making",
            "Communication",
            "Critical thinking"
        ],
        "hard_skills": [
            "SQL",
            "Large Language Models (LLM)",
            "AWS Boto",
            "Python",
            "R",
            "Tableau",
            "Git",
            "Alteryx",
            "Snowflake"
        ],
        "tech_stack": [
            "AWS",
            "Boto",
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Git",
            "Alteryx",
            "Snowflake",
            "LLM"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Bioinformatics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greenville, SC",
        "job_id": 3967786970,
        "company": "V-Soft Consulting Group, Inc.",
        "title": "Data Scientist",
        "created_on": 1720587677.3621752,
        "description": "Primary Location: Greenville, South Carolina V-Soft Consulting is currently hiring for a Data Scientist for our premier client in Greenville, South Carolina . What You’ll Need Technical Requirements and Certifications » Process/project management experience or training/certifications (preferred). Education And Experience » Bachelor degree in computer science, mathematics/statistics or related field. Advanced degree (master’s or PhD) in computer science, mathematics/statistics or a related field (preferred). 3+ years post-university experience in advanced analytics in the field of data science, applying scientific data analytics methods preferably to automotive industry datasets. 1+ years proven experience completing projects with a set of various data sources. Experience using statistical computer languages (python) to manipulate data and draw insights from large data sets. Experience using a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and knowledge of their real-world advantages/drawbacks. Experience using deep learning architectures (RNN, CNN, LSTM, etc.) and frameworks (Tensor flow, Keras, etc.) Experience in natural language processing. Experience using database technologies including SQL, Oracle, SQL Server, or NoSQL databases. Experience using cloud technology and services specifically in AWS including Athena, Glue, Sagemaker, and QuickSight. Experience with at least one common Opensource high-level LLM-framework (e.g. LangChain, Llama-Index), evaluation techniques and agentic principles. Familiarity with modern software development, devops strategies and tooling (GitOps). Experience using machine learning models in the automotive industry would be nice to have. Knowledge, Skills And Abilities » Basic = less than 1 year of experience/training needed; Intermediate = 1 – 3 years of experience/some training may be needed; Advanced = 3-5 years experience/no training needed; Expert = 5+ years experience/able to train others. 3+ years of knowledge in using statistical computer languages (Python, SLQL, etc.) to manipulate data and draw insights from large data sets. 1+ years of knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Intermediate knowledge of deep learning architectures (RNN, CNN, LSTM, etc.) and frameworks (Tensor flow, Keras, etc.). 3+ years of knowledge of in one or more of the following programming languages: Python, Java, C++. 3+ years of knowledge and experience in Computer Science and in database technologies including SQL, Oracle, SQL Server, SAP HANA and NoSQL databases. 3+ years of experience in statistical languages and tools in particular R. 3+ years of experience in problem solving skills with an emphasis on product development. What You’ll Do Job Responsibilities: Working with large data sets and prepping the data for consumption. Working with business users to obtain more insight into data sources. Asking the right questions to understand how the data can be used. Evaluating the results of machine learning algorithms - determining their explainability. Determining the feasibility of a use case given the business problem and the available data. Assessing the effectiveness and accuracy of data sources. Performing prompt engineering tasks with specific use cases. Monitoring and analyzing model performance. Interested? Qualified candidates should send their resumes to nveerla@vsoftconsulting.com V-Soft Consulting Group is recognized among the top 100 fastest growing staffing companies in North America, V-Soft Consulting Group is headquartered in Louisville, KY with strategic locations in India, Canada and the U.S. V-Soft is known as an agile, innovative technology services company holding several awards and distinctions and has a wide variety of partnerships across diverse technology stacks. As a valued V-Soft Consultant, you’re eligible for full benefits (Medical, Dental, Vision), a 401(k) plan, competitive compensation and more. V-Soft is partnered with numerous Fortune 500 companies, exceptionally positioned to advance your career growth. V-Soft Consulting provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. For more information or to view all our open jobs, please visit www.vsoftconsulting.com or call (844) 425-8425. #INDSP",
        "url": "https://www.linkedin.com/jobs/view/3967786970",
        "summary": "V-Soft Consulting is seeking a Data Scientist with 3+ years of experience in advanced analytics, applying scientific data analytics methods, preferably to automotive industry datasets. The role involves working with large data sets, collaborating with business users, evaluating machine learning algorithms, and ensuring model performance.",
        "industries": [
            "Automotive",
            "Technology",
            "Consulting"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Oracle",
            "SQL Server",
            "NoSQL",
            "R",
            "Machine Learning",
            "Clustering",
            "Decision Tree Learning",
            "Artificial Neural Networks",
            "Deep Learning",
            "RNN",
            "CNN",
            "LSTM",
            "Tensor Flow",
            "Keras",
            "Java",
            "C++",
            "Natural Language Processing",
            "AWS",
            "Athena",
            "Glue",
            "SageMaker",
            "QuickSight",
            "LangChain",
            "Llama-Index",
            "GitOps",
            "Prompt Engineering"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Oracle",
            "SQL Server",
            "NoSQL",
            "R",
            "Machine Learning",
            "Clustering",
            "Decision Tree Learning",
            "Artificial Neural Networks",
            "Deep Learning",
            "RNN",
            "CNN",
            "LSTM",
            "Tensor Flow",
            "Keras",
            "Java",
            "C++",
            "Natural Language Processing",
            "AWS",
            "Athena",
            "Glue",
            "SageMaker",
            "QuickSight",
            "LangChain",
            "Llama-Index",
            "GitOps"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "Java",
            "C++",
            "R"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401(k)"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New Orleans, LA",
        "job_id": 3969039638,
        "company": "The Times-Picayune | Nola.com",
        "title": "Data Scientists #REQ_00202713",
        "created_on": 1720587681.042294,
        "description": "Ochsner Clinic Foundation seeks Data Scientists. Worksite is in New Orleans. Remote work options with travel to New Orleans 1-2 times per year max for a week of onsite meetings with all remote workers. Applicants should apply online at www.ochsner.org/careers",
        "url": "https://www.linkedin.com/jobs/view/3969039638",
        "summary": "Ochsner Clinic Foundation is seeking Data Scientists to join their team in New Orleans. The position offers remote work options with occasional travel to New Orleans for team meetings.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Research"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving"
        ],
        "hard_skills": [
            "Data Analysis",
            "Statistical Modeling",
            "Machine Learning",
            "Data Visualization"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": "Master's Degree",
            "fields": [
                "Data Science",
                "Statistics",
                "Computer Science",
                "Biostatistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York, NY",
        "job_id": 3967788747,
        "company": "ConsultNet Technology Services and Solutions",
        "title": "Data Scientist",
        "created_on": 1720587682.6066585,
        "description": "New York, NY (Hybrid) - 2*days Contract: 12+ months **Long Term Project** As a Data Scientist Product Owner, you design and implement data models to solve critical business problems and collaborate with stakeholders to translate technical findings into actionable insights. You lead data strategy development, ensuring effective data collection, cleaning, and utilization. Staying current with data science trends, you recommend their application within the organization and communicate complex results clearly to diverse audiences. Proactively identifying new data-driven opportunities, you manage relationships with solution delivery partners and lead a scrum team, maximizing business value. Ideal candidates have 5+ years of experience, expertise in data models, statistical methods, machine learning, and excellent communication skills.",
        "url": "https://www.linkedin.com/jobs/view/3967788747",
        "summary": "Data Scientist Product Owner responsible for designing data models, collaborating with stakeholders, leading data strategy development, staying current with trends, and communicating complex results to diverse audiences.  Manages relationships with partners and leads a scrum team. Requires 5+ years of experience in data models, statistical methods, and machine learning, along with excellent communication skills.",
        "industries": [
            "Data Science",
            "Technology",
            "Analytics",
            "Business Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Leadership",
            "Strategic Thinking",
            "Relationship Management",
            "Teamwork"
        ],
        "hard_skills": [
            "Data Modeling",
            "Statistical Methods",
            "Machine Learning",
            "Data Strategy Development",
            "Data Collection",
            "Data Cleaning",
            "Data Utilization",
            "Data Science Trends",
            "Scrum"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Charlotte, NC",
        "job_id": 3967720055,
        "company": "LTIMindtree",
        "title": "Machine Learning Engineer",
        "created_on": 1720587684.0650473,
        "description": "About Us: LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com. Job Title: ML Engineer Work Location Charlotte, NC / Atlanta, GA Job Description: Key Responsibilities Leverage distributed training systems to build scalable machine learning pipelines for model training and deployments in ITOT Products space Design and implement solutions to optimize distributed training execution in terms of model hyperparameter optimization model traininginference latency and systemlevel bottlenecks Research and impalement state of the art LLM models for different business use cases including finetuning and serving the LLMs Ensure ML Model performance uptime and scale maintaining high standards of code quality and thoughtful design quality and monitoring Optimize integration between popular machine learning libraries and cloud ML and data processing frameworks Build Deep Learning models and algorithms with optimal parallelism and performance on CPUs GPUs MS or PhD in Computer Science Software Engineering Electrical Engineering or related fields 3 years of industry experience with Python in a programming intensive role 2 years of experience with one or more of the following machine learning topics classification clustering optimization recommendation system graph mining deep learning 3 years of industry experience with distributed computing frameworks such as Spark Kubernetes ecosystem etc 3 years of industry experience with popular ml frameworks such as Spark MLlib Keras Tensorflow PyTorch HuggingFace Transformers and libraries like scikitlearn spacy gensim CoreNLP etc 3 years of industry experience with major cloud computing services Background or experience in building and scaling Generative AI Applications specifically around frameworks like Langchain PGVector Pinecone AzureML Prior experience in building data products and established a track record of innovation would be a big plus An effective communicator you shall be an ambassador for Machine Learning engineering at external forums and have the ability to explain technical concepts to a nontechnical audience Preferred Qualifications Proficient PythonPySpark coding experience Proficient in containerization services Proficient in Azure ML to deploy the models Experience with working in CICD framework Motivation to make downstream modelers work smoother Background or experience in building and scaling Generative AI Applications specifically around frameworks like Langchain PGVector Pinecone AzureML Industry experience with popular ml frameworks such as Spark MLlib Keras Tensorflow PyTorch HuggingFace Transformers and libraries like scikitlearn spacy gensim CoreNLP etc Experience in designing scalable services controller architecture using FastAPI\" Disclaimer :L&T Infotech has an accommodation process in place and provides accommodations for applicants with disabilities. If you require a specific accommodation because of a disability or a medical need during our recruitment processes, please let us know so that arrangements can be made for the appropriate accommodations to be in place. Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks: Comprehensive Medical Plan Covering Medical, Dental, Vision Short Term and Long-Term Disability Coverage 401(k) Plan with Company match Life Insurance Vacation Time, Sick Leave, Paid Holidays Paid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office : In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",
        "url": "https://www.linkedin.com/jobs/view/3967720055",
        "summary": "LTIMindtree is seeking an ML Engineer to leverage distributed training systems and build scalable machine learning pipelines for model training and deployments in ITOT Products space. The ideal candidate will have 3+ years of experience with Python, distributed computing frameworks (Spark, Kubernetes), popular ML frameworks (Spark MLlib, Keras, Tensorflow, PyTorch, HuggingFace Transformers), and major cloud computing services. Experience with building Generative AI applications using frameworks like Langchain, PGVector, Pinecone, and AzureML is highly preferred. The role will involve research, implementation, optimization, and integration of state-of-the-art LLM models for various business use cases. Excellent communication skills are essential to explain technical concepts to non-technical audiences.",
        "industries": [
            "Technology",
            "Consulting",
            "Digital Solutions",
            "IT",
            "FinTech",
            "Generative AI"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Analytical",
            "Critical Thinking",
            "Decision Making",
            "Time Management",
            "Leadership"
        ],
        "hard_skills": [
            "Python",
            "Spark",
            "Kubernetes",
            "Spark MLlib",
            "Keras",
            "Tensorflow",
            "PyTorch",
            "HuggingFace Transformers",
            "Scikit-learn",
            "Spacy",
            "Gensim",
            "CoreNLP",
            "Azure ML",
            "Langchain",
            "PGVector",
            "Pinecone",
            "FastAPI",
            "Containerization",
            "CICD"
        ],
        "tech_stack": [
            "Spark",
            "Kubernetes",
            "Azure ML",
            "Langchain",
            "PGVector",
            "Pinecone",
            "FastAPI",
            "Docker",
            "Jenkins",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "PySpark"
        ],
        "experience": 3,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Computer Science",
                "Software Engineering",
                "Electrical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive Medical Plan",
            "Dental",
            "Vision",
            "Short Term and Long-Term Disability Coverage",
            "401(k) Plan",
            "Company match",
            "Life Insurance",
            "Vacation Time",
            "Sick Leave",
            "Paid Holidays",
            "Paid Paternity and Maternity Leave"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3968765193,
        "company": "USAJOBS",
        "title": "Data Scientist",
        "created_on": 1720587685.6625156,
        "description": "Duties As a Data Scientist for CIA, you will organize and interpret data to inform U.S. decision-makers, drive successful operations, and shape CIA technology and resource investments. Through CIA's global mission, the Agency has access to unique and highly specialized data sets. You will work with advanced hardware, software, and techniques to develop computational algorithms and statistical methods that find patterns and relationships in large volumes of data and use AI techniques to include deep learning and machine learning. You will also create scalable, high performance, and repeatable computational solutions which realize their algorithmic approaches. Data Scientists clearly communicate their conclusions to a diverse audience and become experts through Agency-sponsored continuing education, attendance at academic, and technical conferences as well as collaboration with the Intelligence Community. Requirements Conditions of Employment You must be physically in the United States or one of its territories when you submit your resume via MyLINK. You must be registered for the Selective Service, if applicable. You must be a U.S. citizen and at least 18 years of age (dual-national US citizens are eligible). You must be willing to move to the Washington, DC area. You must successfully complete a thorough medical and psychological exam, a polygraph interview, and a comprehensive background investigation. For further requirements information, please visit: https://www.cia.gov/careers/how-we-hire/requirements/ Qualifications Minimum Qualifications Experience in a science, technology, engineering or mathematics (STEM) related field, such as: Computational Social Science Computer Science Artificial Intelligence Data Analytics Economics Engineering Geospatial Analysis Mathematics Operations Research Quantitative Finance Statistics Experience with real world data through thesis research, internships, or work experience Creativity Initiative Integrity Leadership abilities Problem solving skills Ability to work in a diverse team environment Ability to meet the minimum requirements for joining CIA , including U.S. citizenship and a background investigation Desired Qualifications Advanced degree in a data science equivalent field or sub-field Experience working with data rich problems through research or programs Experience with computer programming or user experience/user interface Ability to successfully complete projects with large or incomplete data and provide solutions Strong written and verbal communication skills Experience with applying AI techniques to real world data through thesis research, internships, or work experience Good fundamental understanding of a range of AI techniques and ability to match techniques to problems Education Bachelor's degree preferably in a quantitative science, engineering, or social sciences field. At least a 3.0 GPA on a 4-point scale",
        "url": "https://www.linkedin.com/jobs/view/3968765193",
        "summary": "The CIA is seeking a Data Scientist to analyze data, develop algorithms and statistical models, and communicate findings to decision-makers. This role involves working with advanced technologies and AI techniques like deep learning and machine learning. Strong communication, problem-solving, and teamwork skills are essential. ",
        "industries": [
            "Intelligence",
            "Government",
            "Data Science"
        ],
        "soft_skills": [
            "Creativity",
            "Initiative",
            "Integrity",
            "Leadership",
            "Problem Solving",
            "Teamwork",
            "Communication"
        ],
        "hard_skills": [
            "Computational Social Science",
            "Computer Science",
            "Artificial Intelligence",
            "Data Analytics",
            "Economics",
            "Engineering",
            "Geospatial Analysis",
            "Mathematics",
            "Operations Research",
            "Quantitative Finance",
            "Statistics",
            "Computer Programming",
            "User Experience",
            "User Interface",
            "AI Techniques",
            "Deep Learning",
            "Machine Learning"
        ],
        "tech_stack": [
            "AI Techniques",
            "Deep Learning",
            "Machine Learning"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Quantitative Science",
                "Engineering",
                "Social Sciences"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Atlanta, GA",
        "job_id": 3967140282,
        "company": "Fetcherr",
        "title": "Data Scientist Engineer",
        "created_on": 1720587687.17919,
        "description": "We're looking for a Data Scientist Engineer to help us grow our data science team's capabilities. The ideal candidate is a data developer with a relevant experience who is self-driven, motivated, independent, and sharp. You will take an active part in all development phases, including research, design, development, testing and deployment using technologies like Python, Docker, Airflow, Kubernetes and more. Requirements: You’ll be a great fit if… You’re a team player, ready to help others meeting aggressive timelines and motivate the team to meet the product deadlines B.SC or Master’s degree in Computer Science / Statistics / Math / Engineering Have 3+ years of experience developing / doing data science projects with Python Fluent with libraries like pandas, numpy, scipy Have a good understanding of data structures and databases Follow best software engineering practices Have a readiness and willingness to continuously learn while working Great if you have them Reinforcement Learning experience Good intuition in Mathematical Optimization problems Experience in MLOps",
        "url": "https://www.linkedin.com/jobs/view/3967140282",
        "summary": "We are seeking a Data Scientist Engineer to join our data science team. This role involves all development phases, including research, design, development, testing, and deployment using technologies such as Python, Docker, Airflow, and Kubernetes.  The ideal candidate is a team player with 3+ years of experience developing data science projects with Python and familiarity with libraries like pandas, numpy, scipy, and data structures/databases. They should be proficient in software engineering best practices and possess a continuous learning mindset. Additional desired skills include Reinforcement Learning experience, Mathematical Optimization problem intuition, and experience in MLOps.",
        "industries": [
            "Technology",
            "Data Science",
            "Machine Learning",
            "Software Development"
        ],
        "soft_skills": [
            "Team Player",
            "Self-Driven",
            "Motivated",
            "Independent",
            "Sharp",
            "Continuous Learning",
            "Problem Solving"
        ],
        "hard_skills": [
            "Python",
            "Docker",
            "Airflow",
            "Kubernetes",
            "Pandas",
            "NumPy",
            "SciPy",
            "Data Structures",
            "Databases",
            "Software Engineering Best Practices",
            "Reinforcement Learning",
            "Mathematical Optimization",
            "MLOps"
        ],
        "tech_stack": [
            "Python",
            "Docker",
            "Airflow",
            "Kubernetes"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "B.SC",
            "fields": [
                "Computer Science",
                "Statistics",
                "Math",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greater Chicago Area",
        "job_id": 3963333589,
        "company": "Renewance Inc",
        "title": "Data Scientist / Machine Learning Engineer",
        "created_on": 1720587688.757407,
        "description": "Business Description: Renewance Inc. is a pioneering technology company that provides cradle-to-grave stewardship solutions for industrial batteries in the energy and motive industries. Our innovative RenewanceConnect product is a cloud-based software platform designed to optimize service transactions. Our comprehensive services encompass asset management (monitoring, operations & maintenance), battery commissioning, battery decommissioning, warranty management, regulatory compliance, and a marketplace facilitating used batteries' transactions after being graded by Renewance. Job Description: Renewance is seeking a talented and experienced Data Scientist to join our engineering team. The ideal candidate will be responsible for developing machine learning tools integrated with RenewanceConnect. These tools will provide educated guidance on all aspects of battery life cycle management, leveraging both internal and external data sources. Responsibilities: Model Development: Develop, train, and refine machine learning models using internal and external data sources. Implement natural language processing (NLP) techniques to enable chatbots to interact effectively with users. Ensure models are optimized for accuracy, performance, and scalability. Data Management: Collect, clean, and preprocess data from various sources, including internal databases, external APIs, and public datasets. Create and maintain data catalogs for efficient data access and management. Ensure data integrity and compliance with regulatory standards. Integration and Deployment: Work closely with the engineering team to integrate machine learning models into the RenewanceConnect platform. Monitor and evaluate the performance of deployed models, making necessary adjustments and improvements. Collaboration: Collaborate with cross-functional teams, including product managers, software engineers, and business analysts, to understand user requirements and deliver effective solutions. Provide training and support to internal teams on how to use and leverage the machine learning tool. Research and Innovation: Stay up to date with the latest advancements in machine learning and data science. Propose and implement innovative solutions to improve battery life cycle management processes. Requirements: Master’s or Ph.D. in Data Science, Computer Science, Statistics, or a related field. Proven experience as a Data Scientist, preferably with experience in the energy or battery industry. Strong proficiency in machine learning frameworks (e.g. XGBoost, PyTorch, TensorFlow) and Python. Experience with NLP and chatbot development. Familiarity with cloud platforms (e.g., AWS) and data management tools. Excellent problem-solving skills and the ability to work in a fast-paced, collaborative environment. Strong communication skills to convey complex technical concepts to non-technical stakeholders. Benefits: Annual Bonus Paid Time Off (PTO): Enjoy 15 days of paid time off annually to recharge and relax. 401(k): While we currently do not offer matching, our 401(k) plan provides a valuable savings opportunity for your retirement. Insurance Plans: Basic Life, Accidental Death & Dismemberment (AD&D), Short-term Disability, Long-term Disability Health Plans: Choose between our Preferred Provider Organization (PPO) plan or opt for a Health Savings Account (HSA) plan that suits your needs. Dental and Vision Plans: Access comprehensive dental and vision coverage to ensure your overall well-being. Renewance is an equal-opportunity employer and values diversity in the workplace. We encourage candidates from all backgrounds to apply. If you are passionate about shaping the future of sustainable energy solutions and possess the skills and experience outlined above, we invite you to join our team and contribute to the success of Renewance. To apply, please submit your resume detailing your relevant experience and why you are an ideal candidate for the Data Scientist / Machine Learning Engineer position at Renewance.",
        "url": "https://www.linkedin.com/jobs/view/3963333589",
        "summary": "Renewance Inc. is seeking a Data Scientist to develop machine learning tools for their cloud-based platform RenewanceConnect, which optimizes battery life cycle management. The role involves developing, training, and deploying machine learning models, managing data from various sources, integrating models into the platform, and collaborating with cross-functional teams. The ideal candidate has proven experience in data science, particularly in the energy or battery industry, and strong proficiency in machine learning frameworks (e.g., XGBoost, PyTorch, TensorFlow) and Python.",
        "industries": [
            "Energy",
            "Technology",
            "Software",
            "Battery",
            "Industrial"
        ],
        "soft_skills": [
            "Problem-solving",
            "Collaboration",
            "Communication",
            "Data Management",
            "Research",
            "Innovation"
        ],
        "hard_skills": [
            "Machine Learning",
            "Natural Language Processing (NLP)",
            "Chatbot Development",
            "XGBoost",
            "PyTorch",
            "TensorFlow",
            "Python",
            "Data Collection",
            "Data Cleaning",
            "Data Preprocessing",
            "Data Catalogs",
            "Data Integrity",
            "Data Compliance",
            "Cloud Platforms (AWS)",
            "Data Management Tools"
        ],
        "tech_stack": [
            "RenewanceConnect",
            "Machine Learning",
            "Natural Language Processing (NLP)",
            "Chatbots",
            "XGBoost",
            "PyTorch",
            "TensorFlow",
            "Python",
            "AWS",
            "Data Management Tools"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master’s",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Annual Bonus",
            "Paid Time Off (PTO)",
            "401(k)",
            "Life Insurance",
            "Accidental Death & Dismemberment (AD&D)",
            "Short-term Disability",
            "Long-term Disability",
            "Health Insurance (PPO & HSA)",
            "Dental Insurance",
            "Vision Insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3969222941,
        "company": "Augment Jobs",
        "title": "Machine Learning Engineer",
        "created_on": 1720587690.3294199,
        "description": "Overview: We are seeking a skilled and motivated Machine Learning Engineer to join our team. As a Machine Learning Engineer, you will be responsible for designing, implementing, and deploying machine learning models and systems. You will work closely with data scientists, software engineers, and cross-functional teams to build scalable and efficient machine learning pipelines that drive business insights and enhance our products. This role requires strong programming skills, expertise in machine learning algorithms, and the ability to translate data science prototypes into production-ready solutions. Roles And Responsibilities Machine Learning Development: Develop and implement machine learning models and algorithms for various applications, such as classification, regression, clustering, and recommendation systems. Collaborate with data scientists to preprocess data, feature engineering, and model selection. Optimize models for performance, scalability, and deployment in production environments. Infrastructure and Tooling: Build and maintain scalable machine learning infrastructure and pipelines for data processing, model training, evaluation, and deployment. Implement monitoring and logging systems to ensure model performance and reliability. Collaboration and Integration: Work closely with software engineers to integrate machine learning models into production systems and applications. Collaborate with cross-functional teams (including data scientists, product managers, and business stakeholders) to understand requirements and deliver effective solutions. Experimentation and Evaluation: Design and conduct experiments to evaluate model performance and iterate on improvements. Implement A/B testing frameworks to validate the effectiveness of machine learning models and algorithms. Documentation and Communication: Document code, models, and processes to ensure reproducibility and maintainability. Present findings and insights to technical and non-technical stakeholders, explaining complex concepts in an understandable manner. Skills And Qualifications Proven experience as a Machine Learning Engineer or similar role, with a strong background in machine learning, statistics, and software development. Proficiency in programming languages such as Python, Java, or Scala, and familiarity with machine learning libraries/frameworks (e.g., TensorFlow, PyTorch, scikit-learn). Experience with building and deploying machine learning pipelines in cloud environments (e.g., AWS, Azure, GCP). Solid understanding of data structures, algorithms, and distributed computing principles. Knowledge of software engineering best practices (e.g., version control, testing, code reviews) and agile development methodologies. Education And Experience Bachelor’s or Master’s degree in Computer Science, Engineering, Mathematics, or a related field. Demonstrated experience in developing and deploying machine learning solutions in real-world applications. Relevant certifications (e.g., AWS Certified Machine Learning Specialty, Google Cloud Professional Machine Learning Engineer) are advantageous. Compensation The compensation package includes a competitive base salary commensurate with experience and qualifications. Additional benefits such as performance bonuses, stock options, and healthcare coverage will be provided. The exact compensation will be determined based on the candidate's expertise and alignment with the company's strategic goals. Company Culture Our company fosters a collaborative and innovative environment where teamwork and creativity thrive. We value diversity and inclusivity and provide opportunities for continuous learning and professional growth. The Machine Learning Engineer will have the opportunity to make a significant impact by leveraging machine learning to solve complex problems and drive innovation. Application Process Interested candidates are encouraged to submit a resume and cover letter outlining their qualifications and interest in the position. We welcome applicants who are passionate about machine learning, software engineering, and building scalable solutions that deliver business value. This job description outlines the key responsibilities, required skills, and compensation details for the Machine Learning Engineer position, aiming to attract qualified candidates who can design, implement, and deploy machine learning models and systems effectively to drive business insights and enhance products.",
        "url": "https://www.linkedin.com/jobs/view/3969222941",
        "summary": "We are seeking a skilled and motivated Machine Learning Engineer to join our team. As a Machine Learning Engineer, you will be responsible for designing, implementing, and deploying machine learning models and systems. You will work closely with data scientists, software engineers, and cross-functional teams to build scalable and efficient machine learning pipelines that drive business insights and enhance our products.",
        "industries": [
            "Technology",
            "Software Development",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Motivated",
            "Teamwork",
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Creativity",
            "Passion",
            "Innovation"
        ],
        "hard_skills": [
            "Machine Learning",
            "Statistics",
            "Software Development",
            "Python",
            "Java",
            "Scala",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "AWS",
            "Azure",
            "GCP",
            "Data Structures",
            "Algorithms",
            "Distributed Computing",
            "Version Control",
            "Testing",
            "Code Reviews",
            "Agile Development"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "AWS",
            "Azure",
            "GCP"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Performance Bonuses",
            "Stock Options",
            "Healthcare Coverage"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Cambridge, MA",
        "job_id": 3970149633,
        "company": "Takeda",
        "title": "Associate Data Scientist",
        "created_on": 1720587693.106187,
        "description": "By clicking the “Apply” button, I understand that my employment application process with Takeda will commence and that the information I provide in my application will be processed in line with Takeda’s Privacy Notice and Terms of Use. I further attest that all information I submit in my employment application is true to the best of my knowledge. Job Description Join Takeda as an Associate Data Scientist out of our Cambridge, MA location. The Associate Data Scientist role is a collaborative, hands-on position that leverages data science to optimize the delivery of key information to business stakeholders. This is a core position of the Data Science team, which operates as a unique center of excellence that partners with franchises across Takeda’s US Business Unit. Our story is one of high impact with immediate results, leveraging our data, creativity, and perseverance with purpose to support better patient outcomes. As an Associate Data Scientist, you will play a key role in expanding our influence by building and implementing machine learning models and supporting their field execution. This is a rare opportunity where your contributions will have a meaningful impact. Many rare disease patients endure a years-long journey before receiving an accurate diagnosis and appropriate treatment. The models you will develop will enable delivery of the right information, at the right time, for the right HCP treating the right patient. The Data Scientist will directly impact patient outcomes by supporting faster diagnosis, treatment, and improved access to life-changing therapies. How You Will Contribute Analytics Complete analytics (e.g., machine learning, artificial intelligence, advanced statistics) to support patient journey analysis and related analyses of interactions within the healthcare ecosystem Implement the ideal methodology to apply for each analysis or process based on data availability and limitations; demonstrate curiosity in proposing different approaches with the manager Implement repeatable, interpretable, dynamic, and scalable machine learning models that can be seamlessly incorporated into existing workflows Derive insights from research and analyses to address the needs of business stakeholders in close collaboration with the manager Process and analyses extensive health-related datasets, including Structured, Semi-structured, and Unstructured data Collaboration Demonstrate curiosity by seeking different points of view and how analytics impact the business Connect technical and data skills to identify improvements throughout the project lifecycle Deliver analyses and reports in a timely manner for stakeholder readouts, internal project meetings, planning processes, and other business needs Work closely with the manager to scope data and technical requirements throughout the project lifecycle Project Management Fulfill assigned role within a project team while delivering expected results Proactively work with manager to balance conflicting individual priorities and readily adapt to evolving business environments and stakeholder needs Ensure ethics and compliance guidelines are consistently met Collect, aggregate, and document project artifacts, including models, visualizations, outcomes Minimum Requirements/Qualifications Bachelor’s Degree in Computer Science, Engineering, Economics, Data Science, Marketing Analytics, Statistics or a relevant field required 2+ years of full-time data analytics experience required Experience in Machine Learning, including predictive modeling, clustering, feature selection methods, and regularization techniques required Strong statistics background with hypothesis testing, multivariate linear regression, nonparametric methods Proficiency in Python and SQL required Familiar with data visualization tools (e.g., Tableau, PowerBI) highly preferred Experience with causal inference, such as bootstrapping, regression discontinuity, synthetic controls Understanding of data models, databases and, and the art of storytelling through data Knowledgeable of experimental design, such as A/B testing, power calculations Demonstrated ability to translate business needs into data analytics concepts and vice versa Hands-on approach with a proven track record of successfully implementing and executing data-driven initiatives Travel Requirement 10% domestic travel. This may vary based on Takeda's work location and prioritized projects. More About Us At Takeda, we are transforming patient care through the development of novel specialty pharmaceuticals and best-in-class patient support programs. Takeda is a patient-focused company that will inspire and empower you to grow through life-changing work. Certified as a Global Top Employer, Takeda offers stimulating careers, encourages innovation, and strives for excellence in everything we do. We foster an inclusive, collaborative workplace, in which our teams are united by an unwavering commitment to deliver Better Health and a Brighter Future to people around the world. Takeda Compensation And Benefits Summary We understand compensation is an important factor as you consider the next step in your career. We are committed to equitable pay for all employees, and we strive to be more transparent with our pay practices. For Location USA - MA - Cambridge - Kendall Square - 500 U.S. Base Salary Range $84,000.00 - $132,000.00 The estimated salary range reflects an anticipated range for this position. The actual base salary offered may depend on a variety of factors, including the qualifications of the individual applicant for the position, years of relevant experience, specific and unique skills, level of education attained, certifications or other professional licenses held, and the location in which the applicant lives and/or from which they will be performing the job. The actual base salary offered will be in accordance with state or local minimum wage requirements for the job location. U.S. based employees may be eligible for short-term and/ or long-term incentives. U.S. based employees may be eligible to participate in medical, dental, vision insurance, a 401(k) plan and company match, short-term and long-term disability coverage, basic life insurance, a tuition reimbursement program, paid volunteer time off, company holidays, and well-being benefits, among others. U.S. based employees are also eligible to receive, per calendar year, up to 80 hours of sick time, and new hires are eligible to accrue up to 120 hours of paid vacation. EEO Statement Takeda is proud in its commitment to creating a diverse workforce and providing equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, parental status, national origin, age, disability, citizenship status, genetic information or characteristics, marital status, status as a Vietnam era veteran, special disabled veteran, or other protected veteran in accordance with applicable federal, state and local laws, and any other characteristic protected by law. Locations USA - MA - Cambridge - Kendall Square - 500 Worker Type Employee Worker Sub-Type Regular Time Type Full time",
        "url": "https://www.linkedin.com/jobs/view/3970149633",
        "summary": "Takeda is seeking an Associate Data Scientist to join their Data Science team in Cambridge, MA. This role involves leveraging data science to optimize information delivery for business stakeholders, focusing on patient journey analysis and healthcare ecosystem interactions. The ideal candidate will have experience in machine learning, predictive modeling, statistics, Python, and SQL, and will be familiar with data visualization tools. Responsibilities include implementing machine learning models, deriving insights from data analysis, and collaborating with stakeholders to address business needs. This position offers the opportunity to directly impact patient outcomes by supporting faster diagnosis, treatment, and access to therapies.",
        "industries": [
            "Pharmaceuticals",
            "Healthcare",
            "Data Science",
            "Biotechnology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Curiosity",
            "Project Management",
            "Time Management",
            "Adaptability",
            "Teamwork",
            "Communication",
            "Presentation Skills"
        ],
        "hard_skills": [
            "Machine Learning",
            "Predictive Modeling",
            "Clustering",
            "Feature Selection",
            "Regularization Techniques",
            "Statistics",
            "Hypothesis Testing",
            "Multivariate Linear Regression",
            "Nonparametric Methods",
            "Python",
            "SQL",
            "Tableau",
            "PowerBI",
            "Causal Inference",
            "Bootstrapping",
            "Regression Discontinuity",
            "Synthetic Controls",
            "Data Modeling",
            "Databases",
            "Data Visualization",
            "Experimental Design",
            "A/B Testing",
            "Power Calculations"
        ],
        "tech_stack": [
            "Machine Learning",
            "Python",
            "SQL",
            "Tableau",
            "PowerBI"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Computer Science",
                "Engineering",
                "Economics",
                "Data Science",
                "Marketing Analytics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 132000,
            "min": 84000
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "401(k) Plan",
            "Company Match",
            "Short-Term Disability",
            "Long-Term Disability",
            "Life Insurance",
            "Tuition Reimbursement",
            "Paid Volunteer Time Off",
            "Company Holidays",
            "Well-being Benefits",
            "Sick Time",
            "Paid Vacation"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959966162,
        "company": "Insight Global",
        "title": "Data Scientist",
        "created_on": 1720587698.8173842,
        "description": "Title : Data Scientist Duration : 12 month contract, potential to convert to FTE / extend Location : REMOTE (CST or EST most likely) Schedule : Mon-Fri day shift Hourly Pay : $55-65/hr Must Haves Bachelors Degree Experience as a Data Scientist in an enterprise level environment Experience creating Machine Learning /AI Algorithms (targeting 8yrs+ but client is flexible based on education & expertise) 3yrs+ Cloud Experience (preferably GCP) Python scripting and knowledgeable of multiple libraries Nice to Have Neo4j Google Cloud Healthcare / Health Insurance experience Portfolio showcasing work examples Day to Day Insight Global Health is hiring a Data Scientist to support one of our top Healthcare/Health Insurance clients. Day to Day responsibilities will include developing models / brainstorming ideas for new models, creating ML/AI algorithms, creating a relational database, and uncovering actionable business insights.",
        "url": "https://www.linkedin.com/jobs/view/3959966162",
        "summary": "Insight Global Health is seeking a Data Scientist to work on a 12-month contract with potential for extension or conversion to full-time. The role is remote with a preference for CST or EST time zones, and involves developing machine learning and AI algorithms, creating relational databases, and uncovering actionable business insights for a top healthcare/health insurance client.",
        "industries": [
            "Healthcare",
            "Health Insurance",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Communication",
            "Collaboration",
            "Critical thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "AI",
            "Algorithm Development",
            "Relational Database",
            "Python",
            "Cloud Computing",
            "GCP"
        ],
        "tech_stack": [
            "Python",
            "GCP",
            "Neo4j"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 65,
            "min": 55
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Columbus, OH",
        "job_id": 3971512062,
        "company": "Bath & Body Works",
        "title": "Data Scientist",
        "created_on": 1720587701.6919293,
        "description": "Description At Bath & Body Works, everyone belongs. We are committed to creating a diverse, equitable and inclusive culture focused on delivering exceptional fragrances and experiences to our customers. We focus on recruiting, retaining, and advancing diverse talent where our associate population is as diverse as the communities we serve, live and work. In addition, we work to improve our communities and our planet in a way that will make us proud for years to come because we believe the world is a brighter, happier place when everyone has access to the things that make them happy. The Data Scientist is primarily responsible for leading development initiatives to create or expand on predictive modeling methodologies and automated modeling pipelines to support multiple business areas including Marketing, Finance, MP&A, etc. In addition to methodology creation, the Data Scientist will be highly skilled at identifying relevant data sources, collecting data and developing feature datasets to be used in modeling initiatives. Furthermore, the Data Scientist will be expected to communicate findings and collaborate with business teams on activation strategies to implement results. Responsibilities Serve as leading data science strategist to develop new methodologies and models to address current and future business needs. Interact with brand partners with respect to modeling and analytics. Extract, cleanse, and transform data for predictive modeling. Develop and execute automated, production-grade predictive model pipelines. Develop complex queries and automated scripts using Python & SQL. Fully manage projects end to end from identifying business opportunities to developed POC to creating automated modeling pipeline. Work with business partners to incorporate and implement results into current and future strategies. Communicate findings and recommendations to various partners across the organization. Complete hypothesis tests, sample size, and power calculations. Stay current with business results, strategies, industry standards, and tried and tested methodologies. Qualifications At least six (6) years of modeling and analytical experience in Python/R/SAS in a fast paced and professional environment required Advanced experience in pattern recognition, clustering, statistics, and predictive modeling techniques Proficient writing advanced SQL Proficient with Artificial Intelligence/Machine Learning techniques Proficient in working with cloud data warehouses (Snowflake) Experience in retail, consumer packaged goods, and/or customer marketing Data visualization experience using Power BI, Tableau, Qlikview or similar technology Ability to work effectively in dynamic, research-oriented environment with multiple concurrent projects Education Bachelor’s degree in data science, statistics, mathematics or relevant field required. Master’s Degree in data science, statistics, mathematics, or relevant field desired. Core Competencies Lead with Curiosity & Humility Build High Performing Teams for Today & Tomorrow Influence & Inspire with Vision & Purpose Observe, Engage & Connect Strive to Achieve Operational Excellence Deliver Business Results Benefits We invite you to join Gingham Nation, where we invest in our associates through competitive compensation, benefits, and development opportunities, so they can continue to be their best at work, at home, and in their communities. Benefits offered to our eligible associates include a no cost mental health and well-being program, health coverage with a variety of plans to choose from, flexible and affordable saving programs, paid time off and a merchandise discount. Visit bbwbenefits.com for details. The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties and skills required. We will consider for employment all qualified applicants, including those with arrest records, conviction records, or other criminal histories, in a manner consistent with the requirements of any applicable state and local laws. Please see links: Los Angeles Fair Chance In Hiring Ordinance, Philadelphia Fair Chance Law, San Francisco Fair Chance Ordinance. We are an equal opportunity and affirmative action employer. We do not make employment decisions based on an individual’s race, color, religion, gender, gender identity, national origin, citizenship, age, disability, sexual orientation, marital status, pregnancy, genetic information, protected veteran status or any other legally protected status, and we comply with all laws concerning nondiscriminatory employment practices. We are committed to providing reasonable accommodations for associates and job applicants with disabilities. Our management team is dedicated to ensuring fulfillment of this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, associate activities and general treatment during employment. We only hire individuals authorized for employment in the United States.",
        "url": "https://www.linkedin.com/jobs/view/3971512062",
        "summary": "The Data Scientist will lead initiatives to create and expand predictive modeling methodologies and automated modeling pipelines. They will also identify relevant data sources, collect data, and develop feature datasets. The role requires strong communication and collaboration skills to communicate findings and work with business teams on implementation strategies.",
        "industries": [
            "Retail",
            "Consumer Packaged Goods",
            "Customer Marketing"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Strategic Thinking",
            "Leadership",
            "Project Management"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SAS",
            "SQL",
            "Machine Learning",
            "Artificial Intelligence",
            "Snowflake",
            "Power BI",
            "Tableau",
            "QlikView"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SAS",
            "SQL",
            "Snowflake",
            "Power BI",
            "Tableau",
            "QlikView"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SAS",
            "SQL"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Data Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Mental health and well-being program",
            "Health coverage",
            "Saving programs",
            "Paid time off",
            "Merchandise discount"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3962934819,
        "company": "o9 Solutions, Inc.",
        "title": "Data Scientist (Senior)",
        "created_on": 1720587706.3951612,
        "description": "Be part of something revolutionary At o9 Solutions, our mission is clear: be the Most Valuable Platform (MVP) for enterprises. With our AI-driven platform — the o9 Digital Brain — we integrate global enterprises’ siloed planning capabilities, helping them capture millions and, in some cases, billions of dollars in value leakage. But our impact doesn’t stop there. Businesses that plan better and faster also reduce waste, which drives better outcomes for the planet, too. We're on the lookout for the brightest, most committed individuals to join us on our mission. Along the journey, we’ll provide you with a nurturing environment where you can be part of something truly extraordinary and make a real difference for companies and the planet. About the role o9 Solutions is looking for an experienced, talented, and motivated Lead Data Scientist to come join our global team in NA or EMEA. As part of this Data Science team, you will be involved in the end-to-end delivery of our supply chain planning products and building advanced forecasting models with Predictive Analytics, Machine Learning and AI with algorithms such as R, and Python. These models will have used cases for Demand Planning, Supply Planning, Market Mix Modeling, Price Elasticity, New Product Planning, Store Assortment, Market Optimization, and more! You will be key in understanding the customers supply chain problems, designing solutions, developing, and deploying models, validating, and maintaining those models. A successful candidate will bring a Master’s in Computer Science, Mathematics, Statistics, Economics, Engineering, and 5+ years of experience in hands-on modeling in R or Python, in a supply chain forecasting capacity. You will enjoy working directly with customers and our larger o9 Data Science team in India and NA. What you’ll do for us: Research, design, build, deploy, and validate new and existing machine learning models and predictive analytics for advanced forecasting in supply chain demand planning that will drive our customers growth from insights that are allow for better decision making Apply a variety of machine learning techniques (clustering, regression, neural nets, time series, optimizations etc.) to their real-world advantages/drawbacks for insights internally and externally Collaborate with solution architects, business operations specialists, engineers, data scientists, product managers, and internal/external business teams to make sure the models are aligned with business objectives and customer needs Develop machine learning models for segmentation and optimization Provide visualization of complex data sets that includes mathematical models, algorithms, and robust analytics Produce recommendations and use statistical techniques that answer key product questions Provide on-going support for development of demand planning forecasting and predictive analysis. Be a storyteller to explain the “why and how’” of your data driven recommendations to cross-functional teams and customers Guide junior data scientists and oversee their activities to ensure proper alignment/execution of their activities, and maintain high coding standards and best practices within organization What you’ll bring: Experience: 5+ years of data science and data analytics experience. 5+ years’ experience in supply chain planning analysis that specialize in: Demand Planning, Predictive Analysis, Demand Forecasting, Supply Planning, Inventory Market Optimization, Store Segmentation, Market Mix Optimization, New Product Planning, or similar. Experience in building scalable ML frameworks for demand sensing including identifying and collecting relevant input data, feature engineering, tuning, and testing. Experience developing experimental and analytics plans for data modeling processes with the ability to accurately determine and resolve problems Experience gathering data requirements for statistical predictive analytics research that drives market research, product innovation, and implementation in a supply chain space Strong presentation and communications skills with ability to communicate complex analytical or technical concepts to audiences with limited analytical or technical background Experience in time series forecasting in scale using heuristic based hierarchical best-fit models using algorithms like exponential smoothing, ARIMA, prophet and custom parameter tuning Education: Master’s in Computer Science, Mathematics, Statistics, Economics, Engineering, or related field Skills: R, Python, Pyspark, Machine Learning, SQL, building models in platforms like Power BI or Tableau Characteristics: You thrive in a fast paced, challenging environment, where this is much white space and problem solving is at the heart of what drives your analysis We really value team spirit: Transparency and frequent communication is key. At o9, this is not limited by hierarchy, distance, or function Preferred Experience Exposure to distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, or related Big Data technologies Experience with Deep Learning frameworks such as Keras, Tensorflow or PyTorch is preferable Experience in implementing planning applications will be a plus What we’ll do for you Competitive salary Tech tools: Complementary Mac or PC laptop. Enjoy yourself: Unlimited paid time off. Stock options to eligible candidates High growth organization - very strong entrepreneurial culture and no corporate politics Support network: Work with a team you can learn from and every day. Diversity: We pride ourselves on our international working environment Social: Fun after-work activities like Friday Socials. If you’re in the office, feel free to join these events in person. Food and drink: Enjoy healthy snacks, fresh fruit, teas and coffees on us. Work Life Balance: https://youtu.be/IHSZeUPATBA?feature=shared Feel part of A team: https://youtu.be/QbjtgaCyhes?feature=shared Impact the planet positively: https://www.youtube.com/watch?v=-ylSC6LNZy0 This position at o9 Solutions has an annual salary range of $90,000 - $105,000. Additionally, you may be eligible to participate in our medical, retirement, and other company-sponsored benefits. *The above information reflects the expected base salary range, although the lower and upper bounds may vary based on location, skills, experience, certifications, licenses, or other relevant factors How the process works Apply by clicking the button below. You’ll be contacted by our recruiter, who’ll fill you in on all things o9, give you some background about the role and get to know you. They’ll contact you either via video call or phone call - whatever you prefer. During the interview phase, you will meet with the Hiring Manager for 30 minutes. The recruiter will contact you after the interview to let you know if we’d like to progress your application. Your application has progressed! Meet with a new panel for a final round of interviews for 30 minutes each. Our recruiter will let you know if you’re the successful candidate. Good luck! More about us With the latest increase in our valuation from $1.1B to $3.7B, o9 Solutions is one of the fastest-growing technology companies in the world today. Our mission is to digitally transform planning and decision-making for the enterprise and the planet. Our culture is high-energy and drives us to aim 10x in everything we do. Our platform, the o9 Digital Brain, is the premier AI-powered, cloud-native platform driving the digital transformations of major global enterprises including Google, Walmart, ABInBev, Starbucks, and many others. Our headquarters are located in Dallas, with offices in Amsterdam, Paris, London, Barcelona, Madrid, Milan, Munich, Bangalore, Tokyo, Seoul, Sao Paulo and Toronto. o9 is an equal opportunity employer and seeks applicants of diverse backgrounds and hires without regard to race, colour, gender, religion, national origin, citizenship, age, sexual orientation or any other characteristic protected by law",
        "url": "https://www.linkedin.com/jobs/view/3962934819",
        "summary": "o9 Solutions is seeking a Lead Data Scientist to join their global team. The role involves developing and deploying machine learning models for supply chain forecasting, collaborating with cross-functional teams, and providing insights to customers. The ideal candidate has 5+ years of experience in data science and supply chain planning, with expertise in demand planning, predictive analytics, and machine learning techniques. They will be responsible for building scalable ML frameworks, gathering data requirements, presenting findings, and guiding junior data scientists.",
        "industries": [
            "Supply Chain Management",
            "Retail",
            "Manufacturing",
            "Logistics",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Collaboration",
            "Problem Solving",
            "Teamwork",
            "Leadership",
            "Storytelling"
        ],
        "hard_skills": [
            "Machine Learning",
            "Predictive Analytics",
            "Demand Planning",
            "Supply Planning",
            "Inventory Optimization",
            "Market Mix Optimization",
            "New Product Planning",
            "Time Series Forecasting",
            "R",
            "Python",
            "Pyspark",
            "SQL",
            "Power BI",
            "Tableau",
            "Map/Reduce",
            "Hadoop",
            "Hive",
            "Spark",
            "Gurobi",
            "Keras",
            "Tensorflow",
            "PyTorch"
        ],
        "tech_stack": [
            "Machine Learning",
            "Predictive Analytics",
            "R",
            "Python",
            "Pyspark",
            "SQL",
            "Power BI",
            "Tableau",
            "Map/Reduce",
            "Hadoop",
            "Hive",
            "Spark",
            "Gurobi",
            "Keras",
            "Tensorflow",
            "PyTorch"
        ],
        "programming_languages": [
            "R",
            "Python",
            "Pyspark",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Statistics",
                "Economics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 105000,
            "min": 90000
        },
        "benefits": [
            "Competitive Salary",
            "Tech Tools",
            "Unlimited Paid Time Off",
            "Stock Options",
            "High Growth Organization",
            "Support Network",
            "Diversity",
            "Social Events",
            "Food and Drink",
            "Work Life Balance",
            "Medical",
            "Retirement"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Melbourne, FL",
        "job_id": 3964720111,
        "company": "Cromulence",
        "title": "Machine Learning/Artificial Intelligence Engineer",
        "created_on": 1720587707.8266025,
        "description": "Cromulence is seeking a Machine Learning/Artificial Intelligence Engineer to join the team. Responsibilities: Research, design, and develop state-of-the-art language models tailored specifically for software engineering and cybersecurity tasks Collaborate closely with cross-functional teams including software engineers, machine learning engineers, and domain experts to understand requirements and implement solutions Experiment with different architectures, training methodologies, and datasets to improve the performance and efficiency of language models for code generation Conduct thorough evaluations and benchmarks to assess the quality, robustness, and scalability of developed models Stay abreast of the latest advancements in natural language processing, machine learning, and software development to continually refine and innovate our approaches Requirements: Master’s or Bachelor’s degree in Computer Science, Electrical Engineering, Statistics, or a related field with a focus on natural language processing, machine learning, or artificial intelligence Active Top Secret security clearance required Proven track record of research and practical experience in developing and deploying language models, particularly for code generation tasks Strong programming skills in Python and experience with deep learning frameworks such as TensorFlow or PyTorch Solid understanding of software engineering principles and experience with software development lifecycle processes Excellent communication skills with the ability to effectively collaborate with interdisciplinary teams and communicate complex technical concepts to non-technical stakeholders Strong analytical and problem-solving abilities with a passion for pushing the boundaries of what’s possible with language models Preferred Qualifications: Experience working with large-scale datasets and distributed computing frameworks Knowledge of common malware families, exploit techniques, and evasion tactics used by threat actors Familiarity with version control systems (e.g., Git) and continuous integration/continuous deployment (CI/CD) pipelines Knowledge of assembly language programming (x86, ARM, MIPS) and familiarity with scripting languages (Python, PowerShell) for automation and tool development Security Clearance: A current U.S. government security clearance is required. Qualified applicants may be subject to a security investigation and must meet minimum qualifications for access to classified information. As a result, U.S. Citizenship is required for this role. Applicants may be subject to additional security requirements Benefits: A successful company begins with happy employees. Cromulence takes our company culture seriously and works hard to maintain an atmosphere that rewards people for getting the best results. What we offer to all our employees: Extremely competitive base salary and bonuses Full benefits: Medical, Dental, Vision, STD, LTD, 4 weeks of paid parental leave (all 100% paid for by Cromulence) 401 (K) with a hefty company matching program 4 weeks of Paid time off (PTO) 11 paid holidays Flexible work hours and remote work when possible Continuing education benefits Additional perks like company retreats, DEF CON trips, well-stocked kitchens & breakrooms, a sweet historic downtown office, and more! Cromulence is a growing cybersecurity company located in historic downtown Melbourne, Florida. We specialize in Computer Network Operations Tools, Cybersecurity Competitions, advanced Program Analysis Research & Development, and Vulnerability Research. We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by federal, state or local laws. Cromulence Participates in E-Verify. Powered by JazzHR 9goY38j0QP",
        "url": "https://www.linkedin.com/jobs/view/3964720111",
        "summary": "Cromulence is seeking a Machine Learning/Artificial Intelligence Engineer to research, design, and develop language models for software engineering and cybersecurity. Responsibilities include collaborating with cross-functional teams, experimenting with model architectures, conducting evaluations, and staying updated on advancements. The ideal candidate will have a strong background in NLP, ML, and AI, proven experience with language models, and solid programming skills in Python and deep learning frameworks like TensorFlow or PyTorch. Preferred qualifications include experience with large-scale datasets, knowledge of malware families and exploit techniques, and familiarity with version control and CI/CD pipelines. ",
        "industries": [
            "Cybersecurity",
            "Software Development",
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Network Operations",
            "Vulnerability Research"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical Thinking",
            "Passion for Innovation",
            "Teamwork",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "Deep Learning",
            "Natural Language Processing",
            "Machine Learning",
            "Artificial Intelligence",
            "Software Engineering",
            "Code Generation",
            "Software Development Lifecycle",
            "Git",
            "CI/CD",
            "Assembly Language (x86, ARM, MIPS)",
            "PowerShell",
            "Scripting"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "Git",
            "CI/CD",
            "x86",
            "ARM",
            "MIPS",
            "PowerShell"
        ],
        "programming_languages": [
            "Python",
            "Assembly Language (x86, ARM, MIPS)",
            "PowerShell"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Electrical Engineering",
                "Statistics",
                "Natural Language Processing",
                "Machine Learning",
                "Artificial Intelligence"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Base Salary",
            "Bonuses",
            "Medical",
            "Dental",
            "Vision",
            "STD",
            "LTD",
            "Parental Leave",
            "401(K) Matching",
            "Paid Time Off",
            "Paid Holidays",
            "Flexible Work Hours",
            "Remote Work",
            "Continuing Education",
            "Company Retreats",
            "DEF CON Trips",
            "Well-Stocked Kitchens",
            "Breakrooms",
            "Historic Downtown Office"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Sterling, VA",
        "job_id": 3971285572,
        "company": "iZeal, Inc",
        "title": "ML Engineer",
        "created_on": 1720587709.3387525,
        "description": "iZeal, Inc. is currently seeking an ML Engineer for our client's requirements. The salary depends on experience. Position: ML Engineer Location: Phoenix, AZ. Job Description: Experience with developing machine learning models and have the right data science skills with problem solving, research and framing into ML problems. Experience with deploying machine learning models into production environments and familiar with MLOps practices, be able to write clean, and production level code. Experience with building Python libraries and APIs (written in Python) Experience with machine learning solutions within merchandising related space domain (assortment, item selection, pricing etc) in mandatory Educational Qualification: Minimum Bachelor's in Computer Science & Engineering or Equivalent Degree.",
        "url": "https://www.linkedin.com/jobs/view/3971285572",
        "summary": "iZeal, Inc. is seeking an ML Engineer with experience in developing and deploying machine learning models, building Python libraries and APIs, and working with machine learning solutions in the merchandising space. The role requires proficiency in MLOps practices and clean code writing.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Retail",
            "E-commerce"
        ],
        "soft_skills": [
            "Problem Solving",
            "Research",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "Machine Learning",
            "Model Development",
            "Model Deployment",
            "MLOps",
            "Python",
            "API Development",
            "Merchandising",
            "Assortment",
            "Item Selection",
            "Pricing"
        ],
        "tech_stack": [
            "Python",
            "MLOps"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science & Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3970060318,
        "company": "ALOIS Solutions",
        "title": "Data Scientist",
        "created_on": 1720587710.992897,
        "description": "Job Responsibilities: Design, develop and implement solutions for a wide range of NLP use cases involving classification, extraction and search on unstructured text data Create and maintain state of the art scalable NLP solutions in Python/ Java/ Scala for multiple business problems. Choosing most appropriate NLP technique(s) based on business needs and available data Performing data exploration and innovative feature engineering Training and tuning a variety of NLP models / solutions which include regular expressions, traditional NLP models as well as SOTA transformer based models Augmenting models by integrating domain specific ontologies and/or external databases Reporting and Monitoring the solution outcome Work experience with document-oriented databases such as MongoDB Collaborate with ML engineering team to deploy NLP solutions in production - both on premise as well as cloud deployment Interact with clients and internal business teams to perform solution feasibility as well as design and develop solutions Open to working across different domains – Insurance, Healthcare and Financial Services etc. Qualifications: 4+ Years Education: Engineering graduate from Top Tier Universities is a plus Required Skills: Experience (including graduate school) on training machine learning models, applying and developing text mining and NLP techniques Exposure to OCR and computer vision Experience in extracting content from documents is preferred Experience (including graduate school) with Natural Language Processing techniques is required Hands on experience with Natural Language Processing tools such as Stanford CORE-NLP, NLTK, spaCy, Gensim, Textblob etc. Experience/ Familiarity with document clustering in supervised un un-supervised scenarios Expertise in at least two of the state of the art techniques in NLP like BERT, GPT, XL Net etc. Applied experience of machine learning algorithms using Python Organized, self-motivated, disciplined and detail oriented Production level coding experience in Python is required Ability to read recent ML research papers and adapt those models to solve real-world problems Experience with any deep learning framework, including Tensorflow, Caffe, MxNet, Torch, Theano Experience with optimization on GPUs (a plus) Hands on experience with using cloud technologies on AWS/ Microsoft Azure is preferred",
        "url": "https://www.linkedin.com/jobs/view/3970060318",
        "summary": "This role involves designing, developing, and implementing NLP solutions for various business use cases. You'll work with unstructured text data, create scalable NLP solutions using Python, Java, or Scala, and collaborate with ML engineers to deploy these solutions in production. Experience with machine learning, text mining, NLP, document-oriented databases (MongoDB), and cloud technologies (AWS/Azure) is essential. Familiarity with OCR, computer vision, and document clustering is preferred. The ideal candidate is organized, self-motivated, and able to adapt research models to real-world problems.",
        "industries": [
            "Technology",
            "Financial Services",
            "Healthcare",
            "Insurance",
            "Machine Learning",
            "Natural Language Processing"
        ],
        "soft_skills": [
            "Organized",
            "Self-Motivated",
            "Disciplined",
            "Detail-Oriented",
            "Collaborative",
            "Problem Solving",
            "Communication",
            "Adaptability"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "Scala",
            "Machine Learning",
            "Text Mining",
            "NLP",
            "OCR",
            "Computer Vision",
            "Document Clustering",
            "BERT",
            "GPT",
            "XLNet",
            "TensorFlow",
            "Caffe",
            "MxNet",
            "Torch",
            "Theano",
            "AWS",
            "Azure",
            "MongoDB"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "Scala",
            "MongoDB",
            "AWS",
            "Azure",
            "TensorFlow",
            "Caffe",
            "MxNet",
            "Torch",
            "Theano",
            "BERT",
            "GPT",
            "XLNet",
            "Stanford CORE-NLP",
            "NLTK",
            "spaCy",
            "Gensim",
            "Textblob"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3968151181,
        "company": "AllCloud",
        "title": "Machine Learning Engineer",
        "created_on": 1720587712.5282197,
        "description": "ML Engineer Location: US (Eastern Time) - Home based Job Type: Full-time, Permanent About AllCloud AllCloud is a global professional services company providing organizations with cloud enablement and transformation tools. As an AWS Premier Consulting Partner and audited MSP, a Salesforce Platinum Partner, and a Snowflake Premier Partner, AllCloud helps clients connect their front and back offices by building a new operating model to harness the benefits of cloud technology and data and analytics. Job Summary We are looking for a savvy Machine Learning/Data Engineer to join our growing team of data experts. The hire will be primarily responsible for AI/ML projects on AWS leveraging native services as well as custom built models to deliver predictive insights to our customers. In addition, this hire will also support migrating to the cloud, optimizing our customers’ databases and data flows, and enriching our operational and functional data flow with AI/ML algorithms. The ideal candidate is confident in data in any form or scale and happy to learn and teach new data tools. The candidate enjoys optimizing data systems and building them from the ground up. The Machine Learning Engineer will support new systems designs and migrate existing ones, working closely with solutions architects, project managers, and data scientists. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or re-designing our customers’ data architecture to support our next generation of products and data initiatives, and machine learning systems. Responsibilities Keep our customers’ data separated and secure to meet compliance and regulations requirements. Design, Build and Operate the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud (mainly AWS) migration and ‘big data’ technologies. Optimize various RDBMS engines in the cloud and solve customers' security, performance, and operation problems. Design, Build and Operate large, complex data lakes that meet functional / non-functional business requirements. Optimize various data types ingestion, storage, processing, and retrieval from near real-time events and IoT to unstructured data as images, audio, video and documents, and in between. Use Jupyter Notebooks to build and deploy ML models. Leverage AWS AI/ML pre built solutions to accelerate work for customers Work with customers and internal stakeholders, including the Executive, Product, Data, Software Development, and Design teams, to assist with data-related technical issues and support their data infrastructure and business needs. Summary of Key Requirements We seek a candidate with 3+ years of experience in a Data Scientist/Machine Learning Engineer role who has attained a Bachelor's (Graduate preferred) degree in Computer Science, Mathematics, Informatics, Information Systems, or another quantitative field. They should also have experience using the following software/tools: Experience with big data tools: Spark, ElasticSearch, Hadoop, Kafka, Kinesis etc. Experience with relational SQL and NoSQL databases, such as MySQL or Postgres and DynamoDB or Cassandra. Experience with AWS cloud services: EC2, RDS, EMR, Redshift etc. Experience with functional and scripting languages: Python, Java, Scala, etc. Experience with various ML models for classification, scoring and more. Experience with Deep Learning Neural Networks (Convolution, NLP etc.) Experience with AWS AI/ML Services Experience with Python coding Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Experience supporting and working with external customers in a dynamic environment. Certifications AWS Machine Learning Specialty (Strongly Preferred) AWS Solutions Architect - Associate (Strongly Preferred) Why work for us? Our team inspires progress in each other and in our customers through our relentless pursuit of excellence; you will work with leaders who promote learning and personal development. AllCloud is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics or any other basis forbidden under federal, provincial, or local law.",
        "url": "https://www.linkedin.com/jobs/view/3968151181",
        "summary": "AllCloud seeks a Machine Learning/Data Engineer to build and manage data infrastructure and ML models on AWS for clients.  The role involves optimizing databases, data flows, and implementing predictive insights using native AWS services and custom models.  The ideal candidate has 3+ years of experience and a background in Computer Science, Math, or related fields.",
        "industries": [
            "Cloud Computing",
            "Data Analytics",
            "Artificial Intelligence",
            "Machine Learning",
            "Professional Services"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Self-directed",
            "Learning",
            "Teaching"
        ],
        "hard_skills": [
            "SQL",
            "AWS",
            "Spark",
            "ElasticSearch",
            "Hadoop",
            "Kafka",
            "Kinesis",
            "MySQL",
            "Postgres",
            "DynamoDB",
            "Cassandra",
            "EC2",
            "RDS",
            "EMR",
            "Redshift",
            "Python",
            "Java",
            "Scala",
            "Jupyter Notebooks",
            "Deep Learning",
            "Neural Networks",
            "Convolution",
            "NLP",
            "Message Queuing",
            "Stream Processing",
            "Data Transformation",
            "Data Structures",
            "Metadata",
            "Dependency Management",
            "Workload Management"
        ],
        "tech_stack": [
            "AWS",
            "Spark",
            "ElasticSearch",
            "Hadoop",
            "Kafka",
            "Kinesis",
            "MySQL",
            "Postgres",
            "DynamoDB",
            "Cassandra",
            "EC2",
            "RDS",
            "EMR",
            "Redshift",
            "Jupyter Notebooks"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Informatics",
                "Information Systems",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Learning and Personal Development"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967784624,
        "company": "Eight Sleep",
        "title": "Data Scientist",
        "created_on": 1720587714.3431437,
        "description": "Eight Sleep is the first sleep fitness company. At Eight Sleep we design products at the forefront of sleep innovation. Our mission is to make people’s sleep count for more, using innovative technology, minimalistic design, and proven clinical science to personalize and improve each night for everybody—changing the way people sleep forever and for better. Our temperature-regulated technology, the Pod, is an absolute game changer. It improves people's health and happiness by changing the way they sleep. The Pod was recognized by TIME's “Best Inventions of the Year.” It is available for purchase in North America and internationally. Backed by leading Silicon Valley investors including Valor Equity Partners, Founders Fund, Khosla Ventures and Y Combinator, we’ve raised over $150 million (Series C) to date. We were recognized as one of Fast Company’s Most Innovative Companies in Consumer Electronics in 2019, 2022, and 2023. We are looking to hire an experienced Data Scientist who has a track record working with human data in the consumer wellness or digital health space. This role will be responsible for core data intelligence features, exploratory data analysis, user-facing insight generation, and publication of findings to the world. This position is ideal for a data scientist looking to work on a massive amount of human data with a highly collaborative R&D team in a fast paced setting. Your work will positively impact hundreds of thousands of members by improving their sleep and health. How You’ll Contribute Improve core intelligent features such as Pod temperature actuation Develop user-facing insights that link behavior, physiology, and Pod actuation Data analysis of research studies that lead to new features, including data engineering of study data Collaborate with Product, Software, and Marketing to productionize features What You Need To Succeed Bachelor’s degree in Data Science, Statistics, Mathematics, Computer Science, or equivalent 4+ years of industry experience as a data scientist, including: 1+ years of working with time-series human physiology data 2+ years of machine learning experience, including classical techniques and deep learning 2+ years applying statistics to real world data Proficient in the following languages and tools: Python or R; able to run common statistical tests (e.g. t-tests, ANOVA, multiple regression, linear mixed models) Data visualization tools (e.g. plotly, seaborn, ggplot2, matplotlib) SQL and Github Experience shipping features into production Able to clearly communicate, is attentive to detail, and is adaptable to changes in a fast-paced environment Why you’ll love Eight We’re a tight-knit, passionate team that’s working to impact people’s lives by improving the way they sleep Leadership is committed to employees’ wellness and career development You’ll get a better night's sleep every night; all full-time employees receive the Pod Flexible PTO 100% employer contribution for medical/dental/vision insurance Role ownership, and uncapped growth opportunities At Eight Sleep we continually celebrate the diverse community different individuals cultivate. As an equal opportunity employer, we stay true to our values by ensuring everyone feels they can flourish and grow. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status",
        "url": "https://www.linkedin.com/jobs/view/3967784624",
        "summary": "Eight Sleep, a sleep fitness company, seeks a Data Scientist with experience in human data analysis for consumer wellness or digital health. This role involves building data intelligence features, generating user-facing insights, analyzing research studies, collaborating with various teams, and deploying features into production. Responsibilities include improving core intelligent features like Pod temperature actuation, linking behavior and physiology, data analysis for new features, and collaborating with Product, Software, and Marketing teams. Ideal candidates possess a Bachelor's degree in a relevant field and 4+ years of experience, including 1+ year with time-series human physiology data, 2+ years with machine learning (classical and deep learning), 2+ years applying statistics, proficiency in Python or R, data visualization tools, SQL, GitHub, and experience deploying features. Eight Sleep offers benefits like the Pod for employees, flexible PTO, 100% employer-paid medical/dental/vision insurance, role ownership, and growth opportunities.",
        "industries": [
            "Sleep Technology",
            "Consumer Wellness",
            "Digital Health",
            "Biotechnology",
            "Healthcare",
            "Technology",
            "Consumer Electronics"
        ],
        "soft_skills": [
            "Communication",
            "Attention to detail",
            "Adaptability",
            "Collaboration",
            "Problem-solving",
            "Analytical thinking"
        ],
        "hard_skills": [
            "Data Science",
            "Statistics",
            "Mathematics",
            "Computer Science",
            "Time-series analysis",
            "Human physiology data",
            "Machine learning",
            "Deep learning",
            "Classical machine learning",
            "Statistical modeling",
            "Data visualization",
            "Python",
            "R",
            "SQL",
            "GitHub",
            "Data engineering",
            "Product development",
            "Software development",
            "Marketing"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "GitHub",
            "Plotly",
            "Seaborn",
            "ggplot2",
            "Matplotlib"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Statistics",
                "Mathematics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Pod for employees",
            "Flexible PTO",
            "100% employer-paid medical/dental/vision insurance",
            "Role ownership",
            "Growth opportunities"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Charlotte, NC",
        "job_id": 3971514623,
        "company": "New York Technology Partners",
        "title": "ML (Machine Learning) Engineer",
        "created_on": 1720587715.905798,
        "description": "Job Title: ML (Machine Learning) Engineer Location: Charlotte, NC / Malvern, PA (Hybrid) Position Type: Contract Job Description: We are seeking Full Stack ML Engineers to support the Hyper Personalization program for our Wealth client, a key initiative aimed at enhancing personalization within financial services. This role requires strong delivery-focused individuals with a deep understanding of the AWS tech stack and financial services personalization. Responsibilities: • Integrate AI/ML models with multiple data sources: Ensure seamless data flow in and out of models. • Fine-tune existing models: Optimize performance and adapt models to evolving requirements. • Build and maintain data pipelines : Design and implement ETL processes to support model integration. • Monitor and manage ML models in production: Implement MLOps practices for model monitoring, tracking, and maintenance. • Collaborate with cross-functional teams: Work closely with data scientists, data engineers, and other stakeholders to deliver robust ML solutions. • Drive architecture and engineering best practices: Lead efforts to establish and enforce best practices in building the integration framework. Technical Skills: • Proficiency in Python and SQL databases: Essential for data manipulation and integration tasks. • Experience with AWS cloud services: Including but not limited to: o SageMaker o Lambda o Glue o S3 o IAM o CodeCommit o CodePipeline o Bedrock • Experience with data pipeline and workflow management tools: Such as Apache Airflow or AWS Step Functions. • Understanding of ETL techniques, data modeling, and data warehousing concepts: To build efficient data pipelines. • Familiarity with AI/ML platforms and tools: Including TensorFlow, PyTorch, MLflow, and others. • Knowledge of MLOps practices: Including model monitoring, data drift detection, and pipeline automation. • Experience with Docker and AWS ECR: For containerization of ML applications.\" If you believe you are qualified for this position and are currently in the job market or interested in making a change, please email me the resume along with contact details at roshni@nytpcorp.com",
        "url": "https://www.linkedin.com/jobs/view/3971514623",
        "summary": "Full Stack ML Engineer to enhance personalization within financial services. Responsible for integrating AI/ML models with data sources, fine-tuning existing models, building data pipelines, monitoring and managing models, collaborating with cross-functional teams, and driving engineering best practices.",
        "industries": [
            "Financial Services",
            "Technology"
        ],
        "soft_skills": [
            "Delivery-focused",
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Analytical",
            "Leadership"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "AWS",
            "SageMaker",
            "Lambda",
            "Glue",
            "S3",
            "IAM",
            "CodeCommit",
            "CodePipeline",
            "Bedrock",
            "Apache Airflow",
            "AWS Step Functions",
            "ETL",
            "Data Modeling",
            "Data Warehousing",
            "TensorFlow",
            "PyTorch",
            "MLflow",
            "MLOps",
            "Model Monitoring",
            "Data Drift Detection",
            "Pipeline Automation",
            "Docker",
            "AWS ECR"
        ],
        "tech_stack": [
            "AWS",
            "SageMaker",
            "Lambda",
            "Glue",
            "S3",
            "IAM",
            "CodeCommit",
            "CodePipeline",
            "Bedrock",
            "Apache Airflow",
            "AWS Step Functions",
            "TensorFlow",
            "PyTorch",
            "MLflow",
            "Docker",
            "AWS ECR"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Tennessee, United States",
        "job_id": 3960504923,
        "company": "HFR",
        "title": "Data Scientist",
        "created_on": 1720587717.6470969,
        "description": "HFR, Inc. Position Available: Data Scientist Location: Nashville, TN (or surrounding area) Company Description: HFR, Inc. (HFR) was founded in 1992 and specializes in the areas of hedge fund/alternative investment data collection, indexation and statistical analysis. HFR is the global leader for hedge fund benchmark indices. Responsibilities: Member of the firm’s Index team, responsible for using a variety of advanced data techniques and designing predictive modeling processes to develop new index methodologies and index families. Duties include: ·        Research and development of new approaches to index construction and return analysis. ·        Assist with the construction, engineering and maintenance of portfolios of hedge funds for creation of strategy, sub-strategy, geographic & thematic index products · Gathering, cleaning, and processing raw data · Designing predictive models and machine learning algorithms to mine return data sets · Developing tools and processes to monitor, analyze and improve data accuracy · Building data visualization tools, dashboards, and reports · Writing programs to systemize processes · Assist in the design of quantitative index methodologies ·        Display skills to work both independently and within team oriented environment, efficiently completing work on deadlines and effectively incorporating feedback on results. Qualifications Required: ·        Degree in math, statistics, computer science or other quantitative discipline ·        Experience in data science or other data analytics role ·        Advanced knowledge of Alteryx preferred ·        Strong programming skills and experience with Python, R language ·        Proficient with Hadoop, MySQL, Tensorflow, Spark ·        Machine learning, other data modeling skills · Self-confident, adaptable, and team oriented · Ability to take direction, multi task and meet deadlines · Ability to work in a fast paced environment ·        Solid written and oral communications skills ·        Solid organizational skills with a strong attention to detail HFR, Inc. is an equal opportunity employer",
        "url": "https://www.linkedin.com/jobs/view/3960504923",
        "summary": "HFR, Inc. is seeking a Data Scientist to join their Index team. The role involves developing new index methodologies and families using advanced data techniques and predictive modeling. Responsibilities include research, data gathering and processing, model design, data accuracy monitoring, tool development, and process automation.",
        "industries": [
            "Financial Services",
            "Hedge Funds",
            "Data Analytics",
            "Investment Management"
        ],
        "soft_skills": [
            "Self-confidence",
            "Adaptability",
            "Teamwork",
            "Communication",
            "Organization",
            "Attention to detail",
            "Time management",
            "Problem-solving",
            "Analytical thinking",
            "Critical thinking",
            "Research"
        ],
        "hard_skills": [
            "Data science",
            "Data analytics",
            "Predictive modeling",
            "Machine learning",
            "Data mining",
            "Data visualization",
            "Data accuracy monitoring",
            "Data processing",
            "Data cleaning",
            "Index construction",
            "Return analysis",
            "Portfolio construction",
            "Programming",
            "Python",
            "R",
            "Hadoop",
            "MySQL",
            "Tensorflow",
            "Spark",
            "Alteryx"
        ],
        "tech_stack": [
            "Alteryx",
            "Python",
            "R",
            "Hadoop",
            "MySQL",
            "Tensorflow",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Math",
                "Statistics",
                "Computer Science",
                "Quantitative Disciplines"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3967683790,
        "company": "Rise Technical",
        "title": "Data Scientist (ML/Remote Sensing)",
        "created_on": 1720587719.0739348,
        "description": "Data Scientist (ML/Remote Sensing) Houston – Texas (Hybrid) $80,000 - $120,000 + 401k + PTO + Healthcare + Dental + Equity + Bonuses Are you a Data Scientist with machine learning and remote sensing experience, looking to work for an exciting start-up company who offer excellent hands on training and structured progression? On offer is a long term permanent role working for a rapidly growing company with an excellent facility and the opportunity to develop your technical skillset and grow into senior positions in the future. My client are an exciting data intelligence start-up leveraging AI satellites to monitor, analyse and deliver intelligence data to customers in asset management, renewable energy, defense and military sectors. In this position you will work under the direction of senior staff to design and implement algorithms for information extraction and fusion from a variety of data sources. You will also assist with developing and maintaining Python-based applications for processing live data streams on Google Cloud. This is a great opportunity for a Data Scientist to join an exciting, high growth company who will support career development and offer structured career progression. The Person: *Experience Python *Understanding of machine learning tools *Geospatial or remote sensing experience/ knowledge *US citizen The Role: *Help build Google Cloud Platform data processing pipelines *Apply machine learning, image processing & statistics to problem solving *Work closely with senior scientists and engineers on specialist projects",
        "url": "https://www.linkedin.com/jobs/view/3967683790",
        "summary": "Data Scientist with machine learning and remote sensing experience to work for a start-up company leveraging AI satellites to monitor, analyze and deliver intelligence data. You'll design and implement algorithms for information extraction and fusion from various data sources, develop and maintain Python-based applications for processing live data streams on Google Cloud, and help build data processing pipelines.",
        "industries": [
            "Data Intelligence",
            "AI",
            "Satellite Imagery",
            "Asset Management",
            "Renewable Energy",
            "Defense",
            "Military"
        ],
        "soft_skills": [
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Teamwork",
            "Learning"
        ],
        "hard_skills": [
            "Machine Learning",
            "Remote Sensing",
            "Image Processing",
            "Statistics",
            "Python",
            "Google Cloud Platform",
            "Data Processing Pipelines",
            "Algorithms",
            "Information Extraction",
            "Data Fusion"
        ],
        "tech_stack": [
            "Google Cloud Platform",
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 120000,
            "min": 80000
        },
        "benefits": [
            "401k",
            "PTO",
            "Healthcare",
            "Dental",
            "Equity",
            "Bonuses"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Irving, TX",
        "job_id": 3958560898,
        "company": "7-Eleven",
        "title": "Fuels Data Scientist II",
        "created_on": 1720587720.5635555,
        "description": "▶ About This Opportunity Responsibilities JOB SUMMARY: As a Fuel Pricing Data Scientist, you will uncover key insights on how customers engage with 7-Eleven. Part of a rapidly growing team, you will apply data science methods and analytics to real business situations across retail fuel pricing. This role will enable fuel pricing decision making by developing key insights into our customer engagement and translating these insights into large scale predictive modelling and analytics solutions. KEY DUTIES AND RESPONSIBILITES: Design, develop, and implements different ML frameworks/solutions and data pipelines to solve business problems/opportunities related to fuel pricing. Adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action  Create and build predictive models and analytic systems aimed at solving fuel pricing problem/opportunity statements.  Automates data pipelines and develops/utilizes different libraries for statistical algorithms that measure and predict KPI's related to fuel pricing and customer behavior/buying preferences.  Create actionable insight reports supported with data visualizations, and support A/B testing methodologies.  Utilize AI to predict customer behavior.  Price Optimization, Anomaly detection, customer retention, clustering, time series, sales forecasting, discount analysis, inventory and cost analysis, market basket and affinity analysis. Qualifications EDUCATION: Masters YEARS OF RELEVANT WORK EXPERIENCE: 5+ years",
        "url": "https://www.linkedin.com/jobs/view/3958560898",
        "summary": "As a Fuel Pricing Data Scientist at 7-Eleven, you will leverage data science methods and analytics to drive fuel pricing decisions. This involves building ML frameworks and data pipelines, optimizing products and processes, creating predictive models, automating data pipelines, and analyzing customer behavior. You'll also generate insights reports with data visualizations and support A/B testing methodologies. ",
        "industries": [
            "Retail",
            "Data Science",
            "Fuel",
            "Convenience Stores",
            "E-commerce"
        ],
        "soft_skills": [
            "Data Analysis",
            "Problem Solving",
            "Decision Making",
            "Communication",
            "Collaboration",
            "Creativity"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Pipelines",
            "Predictive Modeling",
            "Statistical Algorithms",
            "Data Visualization",
            "A/B Testing",
            "AI",
            "Price Optimization",
            "Anomaly Detection",
            "Customer Retention",
            "Clustering",
            "Time Series Analysis",
            "Sales Forecasting",
            "Discount Analysis",
            "Inventory Analysis",
            "Cost Analysis",
            "Market Basket Analysis",
            "Affinity Analysis"
        ],
        "tech_stack": [
            "Machine Learning",
            "Data Pipelines",
            "Predictive Modeling",
            "Statistical Algorithms",
            "Data Visualization",
            "AI"
        ],
        "programming_languages": [],
        "experience": 5,
        "education": {
            "min_degree": "Masters",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Boston, MA",
        "job_id": 3965103719,
        "company": "CodaMetrix",
        "title": "Data Scientist III (LLM Researcher)",
        "created_on": 1720587723.6785088,
        "description": "CodaMetrix is revolutionizing Revenue Cycle Management with its AI-powered autonomous coding solution, a multi-specialty AI-platform that translates clinical information into accurate sets of medical codes. CodaMetrix’s autonomous coding supports improved patient care and drives efficiency under fee-for-service and value-based care models. We are passionate about getting doctors away from the keyboard and back to clinical care Job Description The Data Scientist III will join our Fundamental Research team and report to our Chief Data Scientist. The Fundamental Research team is responsible for inventing, developing, and deploying AI-driven solutions using healthcare data to improve administrative and clinical functions in delivering care. Responsibilities Design and implement creative solutions for a broad range of NLP problems in the healthcare domain Train and tune large language models for best trade-offs for the application Characterize performance of solutions for adequate speed and scale Incorporate an expansive set of unit tests to provide reasonable test coverage and protection from regression Collaborate with engineering and production teams for incorporating NLP capabilities into the product Document solutions clearly and work with the QA team to ensure proper testing Function within an agile scrum team, embracing all tenets of scrum Requirements PhD in Computer Science, Electrical Engineering, Mathematics, or related fields Familiarity with state-of-the-art NLP techniques including large language models Strong technical credentials in NLP, machine learning and deep learning including a track record of publications in relevant conferences and high impact journals Solid fundamentals in problem solving, algorithm design, complexity analysis, mathematics and statistics Proficiency in a major programming language (Python, Java, Scala or similar) Superior verbal and written communication and presentation skills Beneficial Experience Familiarity and hands-on experience with healthcare data is a plus Hands-on experience with cloud-based computing solutions such as AWS is a plus Full-Time Employee Benefits Learn more about how we take care of our team. Insurance: We cover 80% of the cost of medical and dental insurance and offer vision insurance Retirement: CMX offers a 401(k) plan that eligible employees can contribute to one month after their first day Life: We offer employer-paid life insurance and short-term and long-term disability insurance Flexibility: We have an unlimited PTO policy so you can take the time you need to relax and rejuvenate Learning: All new hires complete our 7-week Fellowship program to learn about each of our departments Development: We provide annual performance evaluations and outline a clear path for promotions Engagement: We host recurring events like Meditation Mondays, CMX Connections and Socials Recognition: We recognize quarterly You've Been Awesome winners and celebrate our team's service milestones Background Check All candidates will be required to complete a background check upon acceptance of a job offer. Equal Employment Opportunity Our company, as well as our products, are made better because we embrace diverse skills, perspectives, and ideas. CodaMetrix is an Equal Employment Opportunity Employer and all qualified applicants will receive consideration for employment. Powered by JazzHR KNASfhacU4",
        "url": "https://www.linkedin.com/jobs/view/3965103719",
        "summary": "CodaMetrix seeks a Data Scientist III to join its Fundamental Research team and contribute to AI-driven solutions for revenue cycle management. The role involves designing NLP solutions for healthcare, training large language models, ensuring performance and scalability, and collaborating with engineering and production teams. The ideal candidate possesses a PhD in related fields, expertise in NLP, machine learning, and deep learning, strong technical skills, and excellent communication abilities.",
        "industries": [
            "Healthcare",
            "Technology",
            "Artificial Intelligence",
            "Revenue Cycle Management"
        ],
        "soft_skills": [
            "Problem Solving",
            "Algorithm Design",
            "Communication",
            "Collaboration",
            "Presentation",
            "Teamwork"
        ],
        "hard_skills": [
            "NLP",
            "Machine Learning",
            "Deep Learning",
            "Large Language Models",
            "Python",
            "Java",
            "Scala",
            "AWS",
            "Healthcare Data"
        ],
        "tech_stack": [
            "NLP",
            "Machine Learning",
            "Deep Learning",
            "Large Language Models",
            "AWS"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala"
        ],
        "experience": 0,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Computer Science",
                "Electrical Engineering",
                "Mathematics",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "401(k)",
            "Life Insurance",
            "Disability Insurance",
            "Unlimited PTO",
            "Fellowship Program",
            "Performance Evaluations",
            "Promotion Opportunities",
            "Meditation Mondays",
            "CMX Connections",
            "Socials",
            "Quarterly Recognition",
            "Service Milestone Celebrations"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "McKinney, TX",
        "job_id": 3971526711,
        "company": "Insight Global",
        "title": "Data Scientist",
        "created_on": 1720587726.9391227,
        "description": "This role will require you to go onsite 3 days a week in McKinney! Required Skills and Experience * -2+ years of experience in a Data Science role -SQL and Python/R experience for coding -Strong understanding of statistics -Understand of Machine Learning models -Masters Degree in a quantitative field - Data Science, Software Engineering, Computer Science, etc -Strong communicator and knows how to present findings to shareholders and leadership teams. Nice to Have Skills and Experience -Experience working in retail or whole distribution industries -Sales related Data Science projects Job Description * Insight Global is seeking a Data Scientist to join a whole sale distribution client onsite in McKinney, TX 3 days a week. This resource will be working on a project focused on using Data Science and Machine Learning to segment customers into different buckets to guide the sales teams on which customers to focus on to help the business be more profitable. Responsibilities include: - Attending daily stand up meetings with the Data Science team to share progress, talk through roadblocks and collaborate on a go forward plan. -Coding in Python and SQL 50% of the time -Communicating with stakeholders and leaders on project progress and how to enhance results. -Creating new models -Enhancing existing models",
        "url": "https://www.linkedin.com/jobs/view/3971526711",
        "summary": "Insight Global is looking for a Data Scientist to work on a project focused on customer segmentation using Data Science and Machine Learning to guide sales teams. The role involves coding in Python and SQL, collaborating with a team, and communicating project progress to stakeholders.",
        "industries": [
            "Retail",
            "Wholesale Distribution",
            "Data Science",
            "Software Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Presentation",
            "Problem Solving"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "R",
            "Statistics",
            "Machine Learning"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Machine Learning"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "R"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Data Science",
                "Software Engineering",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Texas, United States",
        "job_id": 3961637556,
        "company": "CloudSeekers",
        "title": "Machine Learning Engineer",
        "created_on": 1720587728.7222798,
        "description": "Job Title: Machine Learning Engineer Job Type: Full Time Remote Policy: Onsite or Remote Location: Remote, United States, Texas. $140-200k Skills Required: Python Machine Learning Scala Apache Spark Reinforcement Learning AWS About the Job: I am representing an innovative and rapidly growing company that is seeking a highly skilled Machine Learning Engineer. My client specializes in low-latency software and distributed systems, and they are looking to expand their talented team with someone who can contribute significantly to their mission. This role involves working on their cutting-edge media ad-buying platform, which is in the process of scaling their Data Science practice from the ground up. The platform provides advanced data science tools for optimizing ad campaigns in terms of content, timing, scheduling, and bid optimization. This company’s self-managed platform revolutionizes the way media advertising is bought, optimized, and evaluated for effectiveness. As an Idealab company, my client benefits from the backing of experienced industry leaders in programmatic advertising and digital media. They empower their clients to purchase ads across a broad media landscape, including major networks such as Hulu, Roku, PlutoTV, and the ad-supported tier of HBO Max. Additionally, they maintain a strategic partnership with NBCUniversal to advance performance advertising within the media sector. Key Responsibilities:Develop and maintain production-level code in Python.Enhance the speed and efficiency of machine learning inference processes at scale.Collaborate effectively with a highly skilled engineering and data science team.Contribute to the ongoing improvement and innovation of the platform’s capabilities. Qualifications: Proficiency in writing and reviewing production-level Python code.Excellent written communication skills.Strong desire to thrive in a fast-growing Series A startup environment, characterized by uncertainty and rapid iteration.Ability to own and scale new products, embracing an experimental and iterative development process. Preferred Qualifications: Experience in the media industry. Familiarity with systems requiring low latency (Experience with big data technologies such as Scala, Apache Spark, Apache Beam, and AWS Athena.This is an exceptional opportunity to join a forward-thinking team and make a significant impact in the media advertising landscape. If you are passionate about machine learning and eager to contribute to a groundbreaking platform, we would love to hear from you!4o",
        "url": "https://www.linkedin.com/jobs/view/3961637556",
        "summary": "This role involves working on a cutting-edge media ad-buying platform that optimizes ad campaigns. You will be developing and maintaining production-level code in Python, enhancing machine learning inference processes at scale, and collaborating with a team of engineers and data scientists.",
        "industries": [
            "Media",
            "Advertising",
            "Technology",
            "Software"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Adaptability",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "Scala",
            "Apache Spark",
            "Reinforcement Learning",
            "AWS",
            "Low Latency Systems",
            "Big Data Technologies",
            "Apache Beam",
            "AWS Athena"
        ],
        "tech_stack": [
            "Python",
            "Scala",
            "Apache Spark",
            "Apache Beam",
            "AWS Athena",
            "AWS"
        ],
        "programming_languages": [
            "Python",
            "Scala"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 200000,
            "min": 140000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3970079173,
        "company": "ALOIS Solutions",
        "title": "Data Scientist",
        "created_on": 1720587730.174692,
        "description": "Hello Applicant - I hope this message finds you in good health. We have a Fulltime/Perm role available with my direct client, where, in addition to a base salary, you will have access to health/medical/dental benefits, PTO, and much more. Job Title: Data scientist Location: remote Duration: Full-time/permanent Job Responsibilities: Design, develop and implement solutions for a wide range of NLP use cases involving classification, extraction and search on unstructured text data Create and maintain state of the art scalable NLP solutions in Python/ Java/ Scala for multiple business problems. Choosing most appropriate NLP technique(s) based on business needs and available data Performing data exploration and innovative feature engineering Training and tuning a variety of NLP models / solutions which include regular expressions, traditional NLP models as well as SOTA transformer based models Augmenting models by integrating domain specific ontologies and/or external databases Reporting and Monitoring the solution outcome Work experience with document-oriented databases such as MongoDB Collaborate with ML engineering team to deploy NLP solutions in production - both on premise as well as cloud deployment Interact with clients and internal business teams to perform solution feasibility as well as design and develop solutions Open to working across different domains – Insurance, Healthcare and Financial Services etc. Qualifications: 4+ Years Education: Engineering graduate from Top Tier Universities is a plus Required Skills: Experience (including graduate school) on training machine learning models, applying and developing text mining and NLP techniques Exposure to OCR and computer vision Experience in extracting content from documents is preferred Experience (including graduate school) with Natural Language Processing techniques is required Hands on experience with Natural Language Processing tools such as Stanford CORE-NLP, NLTK, spaCy, Gensim, Textblob etc. Experience/ Familiarity with document clustering in supervised un un-supervised scenarios Expertise in at least two of the state of the art techniques in NLP like BERT, GPT, XL Net etc. Applied experience of machine learning algorithms using Python Organized, self-motivated, disciplined and detail oriented Production level coding experience in Python is required Ability to read recent ML research papers and adapt those models to solve real-world problems Experience with any deep learning framework, including Tensorflow, Caffe, MxNet, Torch, Theano Experience with optimization on GPUs (a plus) Hands on experience with using cloud technologies on AWS/ Microsoft Azure is preferred",
        "url": "https://www.linkedin.com/jobs/view/3970079173",
        "summary": "This is a full-time permanent Data Scientist role focusing on NLP use cases.  Responsibilities include designing, developing, and implementing NLP solutions using Python, Java, or Scala, performing data exploration and feature engineering, training and tuning models (including transformers), augmenting models with ontologies and external databases, collaborating with ML engineers for deployment, and interacting with clients and internal teams.",
        "industries": [
            "Insurance",
            "Healthcare",
            "Financial Services"
        ],
        "soft_skills": [
            "Organized",
            "Self-motivated",
            "Disciplined",
            "Detail-oriented"
        ],
        "hard_skills": [
            "NLP",
            "Text Mining",
            "Machine Learning",
            "Python",
            "Java",
            "Scala",
            "Regular Expressions",
            "BERT",
            "GPT",
            "XLNet",
            "Stanford CORE-NLP",
            "NLTK",
            "spaCy",
            "Gensim",
            "Textblob",
            "Document Clustering",
            "TensorFlow",
            "Caffe",
            "MxNet",
            "Torch",
            "Theano",
            "AWS",
            "Azure",
            "OCR",
            "Computer Vision"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "Scala",
            "Stanford CORE-NLP",
            "NLTK",
            "spaCy",
            "Gensim",
            "Textblob",
            "BERT",
            "GPT",
            "XLNet",
            "TensorFlow",
            "Caffe",
            "MxNet",
            "Torch",
            "Theano",
            "AWS",
            "Azure"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Engineering Graduate",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health/Medical/Dental benefits",
            "PTO"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greer, SC",
        "job_id": 3967124457,
        "company": "CEI",
        "title": "Data Scientist (24900)",
        "created_on": 1720587731.7003655,
        "description": "Data Scientist Hybrid in Greer, SC (MUST BE LOCAL TO THE CAROLINAS) 12 Month Contract $58/hr-$67/hr Top Skills Required - SQL Oracle Python Experience using statistical computer languages (python) to manipulate data and draw insights from large data sets. Experience using a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and knowledge of their real-world advantages/drawbacks. Experience using deep learning architectures (RNN, CNN, LSTM, etc.) and frameworks (Tensor flow, Keras, etc.) Experience in natural language processing Experience using database technologies including SQL, Oracle, SQL Server, or NoSQL databases. Experience using cloud technology and services specifically in AWS including Athena, Glue, Sagemaker, and QuickSight Experience with at least one common OpenSource high-level LLM-framework (e.g. LangChain, Llama-Index), evaluation techniques and agentic principles Familiarity with modern software development, devops strategies and tooling (GitOps) Experience using machine learning models in the automotive industry would be nice to have. A day in the life includes: Working with large data sets and prepping the data for consumption Assessing the effectiveness and accuracy of data sources Working with business users to obtain more insight into data sources. Asking the right questions to understand how the data can be used. Evaluating the results of machine learning algorithms – determining their explainability Determining the feasibility of a use case given the business problem and the available data. Monitoring and analyzing model performance Performing prompt engineering tasks with specific use cases",
        "url": "https://www.linkedin.com/jobs/view/3967124457",
        "summary": "Data Scientist contract role in Greer, SC (local to Carolinas) focusing on data manipulation, machine learning, deep learning, natural language processing, and cloud technology in AWS. Experience with LLM frameworks, GitOps, and automotive industry is a plus.",
        "industries": [
            "Automotive",
            "Data Science",
            "Technology",
            "Machine Learning"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Analytical Thinking",
            "Critical Thinking",
            "Data Storytelling"
        ],
        "hard_skills": [
            "SQL",
            "Oracle",
            "Python",
            "Statistical Modeling",
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing",
            "SQL Server",
            "NoSQL Databases",
            "AWS",
            "Athena",
            "Glue",
            "Sagemaker",
            "QuickSight",
            "LangChain",
            "Llama-Index",
            "GitOps",
            "Prompt Engineering"
        ],
        "tech_stack": [
            "SQL",
            "Oracle",
            "Python",
            "AWS",
            "Athena",
            "Glue",
            "Sagemaker",
            "QuickSight",
            "LangChain",
            "Llama-Index",
            "GitOps"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 67,
            "min": 58
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Madison, WI",
        "job_id": 3965060164,
        "company": "Rentable",
        "title": "Data Scientist",
        "created_on": 1720587733.340404,
        "description": "We're Changing the Rentals Industry We're a profitable, growth-stage company building industry-leading martech and data SaaS products for the rentals industry. While originally known for building and operating one of the U.S.'s largest rental marketplaces - Rentable, we recently launched a martech product and a competitive intelligence software - ApartmentIQ, both with high growth rates. We're a 100% remote team of 90 spread across the U.S. from coast to coast. We operate on a strict no a**holes policy, and are proud to have built a community of highly performant people that take our work seriously, but not ourselves. And, we're looking for exceptional people to help further accelerate our growth. While we've raised $30MM+ to date from some of the world's best investors, we're profitable with a strong balance sheet and an indefinite runway. We pride ourselves on achieving rapid growth without having to incinerate capital. If you like the idea of joining an industry-changing company made up of people who genuinely like each other, Rentable could be a great fit for you. The Role We are actively seeking a skilled individual to join our product team as a Data Scientist for ApartmentIQ. This role is tailored for those passionate about data and who possess strong analytical skills to extract valuable insights from complex datasets, and love finding the fastest path to get there. You know that data doesn't tell the full story, so the Data Scientist will collaborate with cross-functional teams across product, engineering, and customer experience to drive data-driven decision-making and develop product capabilities used directly by end users. In this dynamic and fast-paced environment, you will need to be a strategic thinker with excellent organizational skills, follow-up abilities, and effective verbal and written communication. Your ability to handle multiple challenges in parallel, synthesize and show your work, and make recommendations amid uncertainty, will be key to your success in this role. This role requires a strategic thinker who is adept at synthesizing information and making recommendations in uncertain environments. A strong voice for data-driven decision-making, the ability to work autonomously, and natural curiosity are essential. Responsibilities: Apply advanced statistical techniques and machine learning algorithms to analyze large datasets, identify patterns, and predict future trends. Develop predictive models to forecast key performance measures and customer behavior, iterating based on usage data and feedback. Create data visualizations, dashboards, and reports to communicate insights to both technical and non-technical stakeholders. Collaborate with product and engineering teams to integrate your solutions into the product, assess model performance (accuracy, precision, recall, AUC-ROC), and refine algorithms over time. Lead discussions and presentations on data-driven insights with stakeholders, showing your work and facilitating decision-making across key stakeholders. Though we are a remote workplace, our teams do travel to meet up several times per year in addition to our annual all-company retreat, Rentapalooza. Qualifications Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or related field. Minimum of 4 years of experience as a Data Scientist, demonstrating a strong ability to leverage data in business settings. Proficient in Python or R, and familiar with libraries for data manipulation and analysis. Solid understanding of statistical concepts and machine learning algorithms (e.g., regression, classification, clustering). Skilled in data visualization tools (e.g., Matplotlib, Seaborn, Tableau) and big data technologies (e.g., Hadoop, Spark). Experience with SQL, database technologies, deep learning frameworks (e.g., TensorFlow, PyTorch), and NLP techniques. Relevant certifications in machine learning, data science, or cloud computing are a plus. Excellent organizational skills, effective communication, and the ability to manage multiple projects simultaneously. High degree of attention to detail, and motivated to take initiative in analyzing, experimenting, and learning. Experience within the MultiFamily/PropTech industry highly preferred. Why Rentable: 100% remote workplace Competitive Compensation Package Stock Options Open Vacation Policy Medical, Dental, and Vision Insurance 100% paid Short-Term Disability, Long-Term Disability, and Life Insurance Program 401k Program No A**hole policy If you need assistance and/or a reasonable accommodation in the application or recruiting process, please contact your recruiter. Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.",
        "url": "https://www.linkedin.com/jobs/view/3965060164",
        "summary": "Rentable, a profitable, growth-stage company building martech and data SaaS products for the rental industry, is seeking a Data Scientist to join their product team for ApartmentIQ. This role involves analyzing large datasets, developing predictive models, creating data visualizations, and collaborating with cross-functional teams to drive data-driven decisions. The ideal candidate will have a strong background in statistics, machine learning, and data visualization, with experience in Python/R, SQL, big data technologies, and deep learning frameworks.",
        "industries": [
            "Rental Industry",
            "MarTech",
            "SaaS",
            "Real Estate",
            "PropTech",
            "MultiFamily"
        ],
        "soft_skills": [
            "Analytical Skills",
            "Strategic Thinking",
            "Organizational Skills",
            "Communication Skills",
            "Collaboration",
            "Problem Solving",
            "Decision Making",
            "Data-Driven",
            "Autonomous Work",
            "Curiosity"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Data Manipulation",
            "Data Analysis",
            "Statistical Concepts",
            "Machine Learning Algorithms",
            "Regression",
            "Classification",
            "Clustering",
            "Data Visualization",
            "Matplotlib",
            "Seaborn",
            "Tableau",
            "Hadoop",
            "Spark",
            "Deep Learning",
            "TensorFlow",
            "PyTorch",
            "NLP Techniques"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Matplotlib",
            "Seaborn",
            "Tableau",
            "Hadoop",
            "Spark",
            "TensorFlow",
            "PyTorch"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Compensation Package",
            "Stock Options",
            "Open Vacation Policy",
            "Medical, Dental, and Vision Insurance",
            "100% paid Short-Term Disability",
            "Long-Term Disability",
            "Life Insurance Program",
            "401k Program",
            "Remote Work"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York City Metropolitan Area",
        "job_id": 3959683839,
        "company": "Gauntlet",
        "title": "Data Scientist",
        "created_on": 1720587735.0537992,
        "description": "Gauntlet leads the field in quantitative research and optimization of DeFi economics. We manage market risk, optimize growth, and ensure economic safety for protocols facilitating the majority of spot trading, borrowing, and lending activity across all of DeFi, protecting and optimizing the largest protocols and networks in the industry. As of January 2024 Gauntlet manages risk and incentives covering over $13 billion in customer TVL. Gauntlet continually publishes cutting-edge research that informs our risk models, alerts, and analysis, and is among the most cited institution — including academic institutions — in terms of peer-reviewed papers addressing DeFi as a subject. We’re a Series B company with around 60 employees, operating remote-first with a home base in New York City. Gauntlet’s mission is to drive adoption and understanding in the financial systems of the future. Building with decentralized systems creates novel challenges for mechanism designers, smart contract developers, and end-users of financial products, which are not seen in traditional software development and investing contexts. Gauntlet is dedicated to enhancing our industry’s understanding of this new domain, and revealing how to safely navigate the true bleeding edge of 21st century financial innovation. In order to grow our impact in the DeFi space we are looking to hire experienced Data Scientists to help new and established protocols better understand the systems they’ve built. This role will require establishing a strong ability to analyze and interpret data; as well as the ability to collaborate with and manage external clients. You will be working directly with the premier and innovative DeFi protocols and developing expert-level knowledge and experience of the mechanisms that underpin the DeFi industry. Responsibilities Perform in depth novel research into how to make premier DeFi protocols safer and more efficient through mechanism design, data analysis, and dynamic parameter optimization Take ownership of client engagements, scoping out work, managing client relationships, and delivering value to clients through your research and work Draft and write engaging research for public consumption both to grow Gauntlet’s Brand as well as to satisfy client requirements Build and deploy easy-to-understand and visually compelling dashboards for internal and external consumption Qualifications 4+ years of professional experience Extremely clear and effective communication and client management skills Proven track record of drawing deep insights from complex datasets Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Ability to work independently working towards abstract goals Experience working with pricing models, financial products and/or different asset classes Bonus Points Experience working in the crypto industry is a big plus Enthusiasm for the space, especially DeFi, is very much desired Experience with derivatives style products Experience managing external client relationships Published or presented research in the space Benefits and Perks Remote first - work from anywhere in the US & CAN! Regular in-person company retreats and cross-country \"office visit\" perk 100% paid medical, dental and vision premiums for employees Laptop, monitor, keyboard and mouse setup provided $1,000 WFH stipend Monthly reimbursement for home internet, phone, and cellular data Unlimited vacation 100% paid parental leave of 12 weeks Fertility benefits Opportunity for incentive compensation Please note at this time our hiring is reserved for potential employees who are able to work within the contiguous United States and Canada. Should you need alternative accommodations, please note that in your application. The national pay range for this role is $135,000 - $180,000 base plus additional On Target Earnings potential by level and equity in the company. Our salary ranges are based on paying competitively for a company of our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide. Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.",
        "url": "https://www.linkedin.com/jobs/view/3959683839",
        "summary": "Gauntlet is hiring Data Scientists to research and optimize DeFi protocols, ensuring safety and efficiency. The role involves analyzing complex datasets, working with clients, and publishing research. Experience in data analysis, scripting languages, and financial products is essential. Benefits include remote work, health insurance, generous leave, and equity in the company.",
        "industries": [
            "Finance",
            "Technology",
            "Blockchain",
            "Decentralized Finance (DeFi)"
        ],
        "soft_skills": [
            "Communication",
            "Client Management",
            "Collaboration",
            "Problem Solving",
            "Independent Work",
            "Data Interpretation",
            "Research",
            "Presentation"
        ],
        "hard_skills": [
            "Data Analysis",
            "SQL",
            "Python",
            "R",
            "Pricing Models",
            "Financial Products",
            "Asset Classes",
            "Mechanism Design",
            "Dynamic Parameter Optimization",
            "Dashboard Development"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "R",
            "Dashboards"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R"
        ],
        "experience": 4,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 180000,
            "min": 135000
        },
        "benefits": [
            "Remote Work",
            "Company Retreats",
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Laptop",
            "Monitor",
            "Keyboard",
            "Mouse",
            "WFH Stipend",
            "Internet Reimbursement",
            "Unlimited Vacation",
            "Parental Leave",
            "Fertility Benefits",
            "Incentive Compensation",
            "Equity"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Malvern, PA",
        "job_id": 3969235918,
        "company": "BeaconFire Inc.",
        "title": "Machine Learning Engineer",
        "created_on": 1720587736.53069,
        "description": "_ML-Engineer Location: MALVERN Job Description: \"Local Grade : C2 JD: Full Stack ML Engineers Overview: We are seeking Full Stack ML Engineers to support the Hyper Personalization program for our Wealth client, a key initiative aimed at enhancing personalization within financial services. This role requires strong delivery-focused individuals with a deep understanding of the AWS tech stack and financial services personalization. Responsibilities: • Integrate AI/ML models with multiple data sources: Ensure seamless data flow in and out of models. • Fine-tune existing models: Optimize performance and adapt models to evolving requirements. • Build and maintain data pipelines: Design and implement ETL processes to support model integration. • Monitor and manage ML models in production: Implement MLOps practices for model monitoring, tracking, and maintenance. • Collaborate with cross-functional teams: Work closely with data scientists, data engineers, and other stakeholders to deliver robust ML solutions. • Drive architecture and engineering best practices: Lead efforts to establish and enforce best practices in building the integration framework. Technical Skills: • Proficiency in Python and SQL databases: Essential for data manipulation and integration tasks. • Experience with AWS cloud services: Including but not limited to: o SageMaker o Lambda o Glue o S3 o IAM o CodeCommit o CodePipeline o Bedrock • Experience with data pipeline and workflow management tools: Such as Apache Airflow or AWS Step Functions. • Understanding of ETL techniques, data modeling, and data warehousing concepts: To build efficient data pipelines. • Familiarity with AI/ML platforms and tools: Including TensorFlow, PyTorch, MLflow, and others. • Knowledge of MLOps practices: Including model monitoring, data drift detection, and pipeline automation. • Experience with Docker and AWS ECR: For containerization of ML applications.\"",
        "url": "https://www.linkedin.com/jobs/view/3969235918",
        "summary": "Full Stack ML Engineer responsible for integrating AI/ML models with multiple data sources, fine-tuning models, building and maintaining data pipelines, monitoring ML models in production, collaborating with cross-functional teams, and driving architecture and engineering best practices within the Hyper Personalization program for a Wealth client.",
        "industries": [
            "Financial Services",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Delivery Focused",
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Teamwork",
            "Leadership"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "AWS",
            "SageMaker",
            "Lambda",
            "Glue",
            "S3",
            "IAM",
            "CodeCommit",
            "CodePipeline",
            "Bedrock",
            "Apache Airflow",
            "AWS Step Functions",
            "ETL",
            "Data Modeling",
            "Data Warehousing",
            "TensorFlow",
            "PyTorch",
            "MLflow",
            "MLOps",
            "Model Monitoring",
            "Data Drift Detection",
            "Pipeline Automation",
            "Docker",
            "AWS ECR"
        ],
        "tech_stack": [
            "AWS",
            "SageMaker",
            "Lambda",
            "Glue",
            "S3",
            "IAM",
            "CodeCommit",
            "CodePipeline",
            "Bedrock",
            "Apache Airflow",
            "AWS Step Functions",
            "TensorFlow",
            "PyTorch",
            "MLflow",
            "Docker",
            "AWS ECR"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Cleveland, OH",
        "job_id": 3965154773,
        "company": "Forsyth Barnes",
        "title": "Data Scientist",
        "created_on": 1720587739.6715677,
        "description": "Role: Data Scientist Location: Clevland, Ohio – Hybrid 3 days per week on-site Job Type: Contract Pay Rate: up to $70 per hour Contract Length: 6 months Contract to hire Sector: Retail Contact: alex.shemar@forsythbarnes.com Overview: Forsyth Barnes is partnered with a Large-scale Scale Manufacturing Company, they are expanding their Data science team, and the role is supporting the Data science Directors in planning, designing, and creating forecasting from Time series data such as demand, revenue, and Pricing. You will be helping enhance the models and play a role that will support the company to align with its future goals. Requirements: 3-5 years experience in a Data scientist role where forecasting has been a main part of the projects. Strong background in Time series Modelling and forecasting projects. The ideal candidate would have manufacturing experience. Strong and deep understanding of forecasting and time series modeling Good understanding of Python and or R alongside good SQL skills Ideally, you will have experience with Clustering/Grouping in Time Series We Cannot Provide any sponsorship for this role.",
        "url": "https://www.linkedin.com/jobs/view/3965154773",
        "summary": "A Large-scale Manufacturing company is seeking a Data Scientist to support their Data Science Directors in planning, designing, and creating forecasting from Time series data such as demand, revenue, and Pricing. The role will involve enhancing existing models and contributing to the company's future goals.",
        "industries": [
            "Manufacturing",
            "Retail"
        ],
        "soft_skills": [
            "Planning",
            "Designing",
            "Forecasting",
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Analytical Thinking"
        ],
        "hard_skills": [
            "Time Series Modeling",
            "Forecasting",
            "Python",
            "R",
            "SQL",
            "Clustering",
            "Grouping",
            "Statistical Modeling"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 70,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Boston, MA",
        "job_id": 3959861848,
        "company": "Marlee (Fingerprint For Success)",
        "title": "Expression of Interest - Machine Learning Engineer",
        "created_on": 1720587741.4582899,
        "description": "We are inviting professionals in high-growth industries who are thinking about their next move or looking for a new opportunity to join our expanding talent pool. The Marlee Talent Pool is a pilot project designed to: Help job seekers get discovered by our partners based on their anticipated hiring needs Provide optional support and resources for job seekers in their career endeavours Help individuals understand, and bring out the best in themselves and each other The Marlee Talent Pool process: Once you express your interest, you will be asked to complete the Marlee work style assessment which measures 48 key attitudes and motivations in the context of work. On completion, you will be automatically added to our growing talent pool and contacted as new opportunities arise. About Marlee (Fingerprint For Success) Backed by 20+ years of research, Marlee’s revolutionary predictive analytics have achieved over 90% reliability in forecasting personal and team motivations, behaviours, and performance. Ultimately, we help people find purpose and fulfillment at work, and help build and scale high-performing teams. Keep in mind that joining our talent pool does not guarantee a job offer. We aim to balance your technical skills with the results of your Marlee work style assessment to match the hiring needs of our partners. Your feedback is a gift! Write to us via: to help co-create the future of recruitment, together. Powered by JazzHR 7ZQUS54TAs",
        "url": "https://www.linkedin.com/jobs/view/3959861848",
        "summary": "Marlee Talent Pool is a pilot project connecting job seekers with companies based on individual work style assessments and anticipated hiring needs. The project uses predictive analytics to match individuals' skills and motivations with suitable opportunities.",
        "industries": [
            "Recruitment",
            "Human Resources",
            "Talent Acquisition",
            "Analytics",
            "Software",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem Solving",
            "Adaptability",
            "Motivation",
            "Self-Awareness",
            "Career Development",
            "Collaboration",
            "Growth Mindset"
        ],
        "hard_skills": [],
        "tech_stack": [
            "Predictive Analytics"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Career support and resources"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Bel Air, MD",
        "job_id": 3959392480,
        "company": "Harford Community College",
        "title": "Data Scientist",
        "created_on": 1720587742.9533389,
        "description": "The Institutional Effectiveness (IE) department supports departments and activities throughout the College using a combination of applied research and technical skills. The ability to organize, problem solve, and communicate well is essential. The Data Scientist position acts as an internal consultant, collaboratively developing solutions to research requests. In addition, the Data Scientist develops and oversees processes for internal and external reporting, including state and federal reporting, and is required to maintain high ethical standards regarding research practices and privacy protections by applying principles of human research subjects protections and applicable laws such as FERPA. Duties include programming business intelligence reports; designing and deploying surveys; developing research designs to evaluate the efficacy of operational changes; acquiring data from various sources, both internal and external to the College; providing statistical analysis; creating written reports and presentations; assisting with external reporting such as IPEDS and state submissions; serving as a research and data expert on college committees; and performing other duties as assigned by the supervisor. The Data Scientist trains end-users to locate and use IE data resources, and engages in collaborative problem solving and contributing ideas for improvement. Required Education - Bachelor’s degree Required Experience - Minimum of 1 year of related experience is required, including statistical research and data extraction and analysis, and creating reports and presentations. This is an exempt, professional staff position. Employees of Harford Community College, including instructors for online and virtual courses, must be residents of Maryland or the contiguous states of Delaware, Pennsylvania, Virginia, West Virginia or the District of Columbia; non-residents are expected to relocate to meet this requirement. This is an in-person position requiring a physical presence on campus. Applicants must be currently authorized to work in the United States, as the College does not offer Visa sponsorship for this position",
        "url": "https://www.linkedin.com/jobs/view/3959392480",
        "summary": "The Data Scientist position at Harford Community College involves collaborating with departments to develop research solutions, designing surveys, analyzing data, creating reports and presentations, training end-users, and contributing to improvement initiatives. The role requires a minimum of 1 year of experience in statistical research, data analysis, reporting, and presentation development.",
        "industries": [
            "Higher Education",
            "Research",
            "Data Analysis",
            "Statistics"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Organization",
            "Research",
            "Training",
            "Presentation",
            "Analytical",
            "Data Analysis",
            "Statistical",
            "Reporting"
        ],
        "hard_skills": [
            "Statistical Research",
            "Data Extraction",
            "Data Analysis",
            "Reporting",
            "Presentations",
            "Business Intelligence",
            "Survey Design",
            "Research Design",
            "Data Acquisition",
            "IPEDS",
            "FERPA"
        ],
        "tech_stack": [
            "Business Intelligence",
            "Survey Tools"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Nampa, ID",
        "job_id": 3965749793,
        "company": "Gymreapers",
        "title": "Data Scientist, Supply Chain Analytics",
        "created_on": 1720587744.4581573,
        "description": "Employment Status: Full-time, benefits eligible Location: Perfereabley Nampa, ID (on-site); Open to Remote Schedule: M-F, 8-5/flex according to business needs Compensation: Who We Are Gymreapers is a direct-to-consumer e-commerce brand creating premium lifting gear, apparel, and equipment for men and women. Our supportive lifting gear has been featured in Men’s Health, Barbend, Powerlifting Technique, and more. The Gymreapers brand has been listed twice on the Inc Magazine’s list of 5,000 fastest growing businesses: 2022 at #291 and 2021 at #521. Our CEO, Roc Pilon, recently was named Entrepreneur of the Year by Ernst and Young! Benefits/Perks Competitive Pay Paid Time Off (PTO) Company paid holiday’s 50% Employee Discount on Gymreapers.com!! 100% Employer Paid: Medical, Dental and Vision, Short-term and Long-term disability, Life insurance for both employee and spouse/dependents Health Savings Account (HSA) employee option Job Summary: Gymreapers is looking to add a Forecasting and Demand Planning professional to our powerful and fast-paced supply chain team. Headquartered in Nampa, Idaho we work tirelessly to support our customers, athletes, and gym-goers on all fronts, all around the world. In this role you will build, develop and implement the overall demand planning and forecasting strategy for the business. This role will also offer query and reporting visualization expertise, supporting the business with live data correlated to company goals and key areas. This is an exciting opportunity for anyone who enjoys creating a strategic vision, and being hands on in the execution of it. Typical Duties and Responsibilities: Develop reporting, analytics and models that support supply chain decisions through the creation of queries, visualization and dashboards Establish a demand planning strategy with the intent to reduce stock outs on inventory through forecasting variance reduction and inaccuracy elimination Be the subject matter expert around machine learning, statistical, and econometric time series techniques alongside hybrids of these to develop accurate, granular demand forecasts Partner closely with Finance, Marketing, Sales, Procurement and Operations to develop data queries, reporting, and visualizations to assist with optimal buying decisions, and the mitigation of risks within the Supply Chain Delivering and supporting production code driving business-critical decision-making systems Required Skills and Abilities: Bachelors or Masters in a quantitative subject (i.e. computer science, economics, operations research, statistics, etc.) or a related field such as Industrial Engineering, Statistics, Mathematics, Computer Science, etc 3+ years of practical experience working in data science systems (ideally in e-commerce) Experience delivering robust and maintainable production codebases that autonomously deliver data science models to downstream systems Experience in statistical/econometric time series modeling (ARIMA, Exponential Smoothing/ETS, GLMs/GAMs, Dynamic Factor Models, etc.), machine learning (XGBoost/LightGBM, RNNs, Transformers, etc.), or hybrid time series techniques (ES-RNN, N-BEATS, TFT) Proficiency in Python, SQL, Git Proficiency in using data visualization tools such as Tableau, or Bi-Reports Passion for driving outsized business impact through applied science, humility, and collaboration Our Core Values Grow or Die Customer Obsession Extreme Ownership Nothing is Given // Everything is Earned Be Humble 1% Better Everyday Live with Integrity Sacrifice Gymreapers LLC is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national or ethnic origin, disability, as well as any other characteristic protected by federal, provincial, or local law. Powered by JazzHR CwsO3johTZ",
        "url": "https://www.linkedin.com/jobs/view/3965749793",
        "summary": "Gymreapers, a rapidly growing e-commerce company specializing in premium lifting gear, seeks a Forecasting and Demand Planning professional to join their supply chain team. This role involves building, implementing, and developing the company's demand planning and forecasting strategy, using machine learning, statistical, and econometric time series techniques to create accurate forecasts and reports. The ideal candidate will have 3+ years of experience in data science, proficiency in Python, SQL, Git, and data visualization tools, and a passion for driving business impact through applied science and collaboration.",
        "industries": [
            "E-commerce",
            "Retail",
            "Fitness",
            "Sports"
        ],
        "soft_skills": [
            "Analytical",
            "Strategic",
            "Collaborative",
            "Problem-solving",
            "Communication",
            "Data-driven",
            "Passionate"
        ],
        "hard_skills": [
            "Demand Planning",
            "Forecasting",
            "Machine Learning",
            "Statistical Modeling",
            "Econometric Time Series Techniques",
            "Data Visualization",
            "Data Analysis",
            "Querying",
            "Reporting",
            "Data Science",
            "Python",
            "SQL",
            "Git",
            "Tableau"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Git",
            "Tableau",
            "ARIMA",
            "Exponential Smoothing/ETS",
            "GLMs/GAMs",
            "Dynamic Factor Models",
            "XGBoost",
            "LightGBM",
            "RNNs",
            "Transformers",
            "ES-RNN",
            "N-BEATS",
            "TFT"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Economics",
                "Operations Research",
                "Statistics",
                "Industrial Engineering",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Pay",
            "Paid Time Off (PTO)",
            "Company Paid Holidays",
            "Employee Discount",
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Short-term Disability",
            "Long-term Disability",
            "Life Insurance",
            "Health Savings Account (HSA)"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Eglin Air Force Base, FL",
        "job_id": 3960269498,
        "company": "SAIC",
        "title": "Data Scientist",
        "created_on": 1720587746.24448,
        "description": "SAIC is seeking a Data Scientist in Eglin AFB, FL! At the AFRL Munitions Directorate, we dream big. We look for people with a passion for science and engineering. We want to deliver world class research and weapons concepts to continually give the United States warfighter the advantage on the ground, in the air, or in space. We hope you want to do the same. As a Data Scientist you will work directly with munitions scientists to design and build AFRL’s leading-edge data lake. You will: Research, test, and evaluate the best-of-breed data collection mechanisms we’ll leverage to curate modeling and simulation, terminal seeker sciences, aerodynamics, guidance, navigation, and control data. Architect science and technology data collection strategies that automates ingest and indexing to transform data into quarriable intelligence Develop machine learning and unsupervised learning models and dataset statistics. Build robust visualization dashboards that summarizes contextual insights and celebrates S&T data intelligence. Author data state surveys that highlight and demonstrate data lake utilization. Qualifications - External DoD SECRET Clearance is required to start Understand best practices of dataflow transit and curation of raw endpoint data to intelligent enrichment. Experience with implementing mechanisms that dynamically index, tag, and add metadata to a fully searchable database. Experience with deploying data analytics tools and techniques. Adept at recognizing data patterns, trends, and insights. Open to exploring bespoke solutions to get the most out of AFRL's data and resources Experience with large scale data storage, retrieval, and processing solutions, such as Apache Spark. Data collection in a research laboratory context. Data stream processing with tools such as Apache Kafka. Developing visualizations that help users gain novel insights and actionable intelligence from their data. Experience with accessing the performance and suitability of trained machine learning model’s performance on new data. Assessing performance and suitability of trained machine learning model’s performance on new data. B.S. in Computer Science or Data Science & 9+ years of experience, OR Master's degree & 7+ years of experience. Desired certifications to include: Certified Analytics Professional (CAP) Data Science Council of America (DASCA) Principal Data Scientist (PDS) Microsoft Certified Data Scientist or AI Fundamentals TensorFlow Developer SAS Certified Professional in AI and Machine Learning. About SAIC SAIC® is a premier Fortune 500® technology integrator focused on advancing the power of technology and innovation to serve and protect our world. Our robust portfolio of offerings across the defense, space, civilian and intelligence markets includes secure high-end solutions in mission IT, enterprise IT, engineering services and professional services. We integrate emerging technology, rapidly and securely, into mission critical operations that modernize and enable critical national imperatives. We are approximately 24,000 strong; driven by mission, united by purpose, and inspired by opportunities. SAIC is an Equal Opportunity Employer, fostering a culture of diversity, equity and inclusion, which is core to our values and important to attract and retain exceptional talent. Headquartered in Reston, Virginia, SAIC has annual revenues of approximately $7.4 billion. For more information, visit saic.com. For ongoing news, please visit our newsroom. Policies: SAIC accepts applications on an ongoing basis and there is no deadline. Covid Policy: SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.",
        "url": "https://www.linkedin.com/jobs/view/3960269498",
        "summary": "SAIC is seeking a Data Scientist to work at the AFRL Munitions Directorate in Eglin AFB, FL. The role involves building and managing a data lake, developing machine learning models, and creating data visualizations. The ideal candidate has a strong background in data science, including experience with Apache Spark, Apache Kafka, and machine learning model performance evaluation. A DoD SECRET clearance is required.",
        "industries": [
            "Defense",
            "Aerospace",
            "Technology",
            "Data Science",
            "Research and Development"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Analytical thinking",
            "Teamwork",
            "Collaboration",
            "Creativity",
            "Innovation",
            "Adaptability",
            "Attention to detail"
        ],
        "hard_skills": [
            "Data lake design and implementation",
            "Data collection and curation",
            "Data analytics",
            "Machine learning",
            "Unsupervised learning",
            "Data visualization",
            "Apache Spark",
            "Apache Kafka",
            "Data stream processing",
            "Machine learning model performance evaluation",
            "Data state surveys"
        ],
        "tech_stack": [
            "Apache Spark",
            "Apache Kafka",
            "Machine Learning",
            "Data Visualization"
        ],
        "programming_languages": [],
        "experience": 9,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Computer Science",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York City Metropolitan Area",
        "job_id": 3970343445,
        "company": "Selby Jennings",
        "title": "Machine Learning Engineer",
        "created_on": 1720587751.0357976,
        "description": "A leading trading firm specializing in cutting-edge financial technologies and innovative trading strategies. We leverage advanced machine learning algorithms to analyze vast amounts of financial data, optimize trading decisions, and deliver exceptional performance in the financial markets. We are seeking a talented and experienced Machine Learning Engineer to join our team. You will play a crucial role in developing and implementing machine learning models to enhance our trading strategies, improve prediction accuracy, and drive profitable trading outcomes. Key Responsibilities: Design, develop, and implement machine learning models to analyze financial data and optimize trading strategies. Collaborate with data scientists, traders, and software engineers to identify opportunities for applying machine learning techniques to trading problems. Perform data preprocessing, feature engineering, and model evaluation to ensure the accuracy and robustness of machine learning models. Research and implement state-of-the-art machine learning algorithms and techniques to improve trading performance. Monitor and maintain deployed machine learning models to ensure they continue to perform optimally in a live trading environment. Develop and maintain software tools and frameworks to support the efficient deployment and scaling of machine learning models. Qualifications: Bachelor's or Master's degree in Computer Science or related field. Proven experience as a Machine Learning Engineer or in a similar role, preferably within the financial industry. Strong programming skills in languages such as Python, C++, or Java. Experience with machine learning frameworks and libraries such as TensorFlow, PyTorch, Scikit-learn, etc. Solid understanding of statistical analysis, probability theory, and financial markets. Familiarity with data preprocessing, feature engineering, and model evaluation techniques. Excellent problem-solving skills and the ability to work independently and as part of a team. Strong communication skills and the ability to explain complex technical concepts to non-technical stakeholders.",
        "url": "https://www.linkedin.com/jobs/view/3970343445",
        "summary": "A leading trading firm is seeking a Machine Learning Engineer to design, develop, and implement machine learning models for trading strategies, optimize trading decisions, and enhance prediction accuracy. Responsibilities include collaborating with data scientists, traders, and software engineers, performing data preprocessing, feature engineering, and model evaluation, researching and implementing state-of-the-art algorithms, monitoring and maintaining deployed models, and developing software tools.",
        "industries": [
            "Financial Services",
            "Trading",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Analysis",
            "Statistical Analysis",
            "Probability Theory",
            "Financial Markets",
            "Data Preprocessing",
            "Feature Engineering",
            "Model Evaluation",
            "Python",
            "C++",
            "Java",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn"
        ],
        "tech_stack": [
            "Machine Learning",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn"
        ],
        "programming_languages": [
            "Python",
            "C++",
            "Java"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Oakland, CA",
        "job_id": 3961446316,
        "company": "World Wide Technology",
        "title": "Data Scientist",
        "created_on": 1720587754.07799,
        "description": "Data Scientist Location: Remote, but needs to be local to Oakland, CA Duration: 6 Months + Qualifications for Data Scientist Strong problem solving skills with an emphasis on product development. Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets. Experience working with and creating data architectures. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages drawbacks. Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. Excellent written and verbal communication skills for coordinating across teams. A drive to learn and master new technologies and techniques. Experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative fi eld, and is familiar with the following software tools: Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc. Knowledge and experience in statistical and data mining techniques: GLM Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience using web services: Redshift, S3, Spark, , etc. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Experience with distributed data computing tools: Map Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Experience visualizing presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc. Top Daily Responsibilities: Support Data-Science and other analytics as needed. Develop SQL queries and data sets Develop business and client facing reports Skills a Top Candidate Should Have: Knowledge and experience in statistical and datamining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience using web services: Redshift, S3, Spark, Digital Ocean, etc. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Experience with distributed data computing tools: MapReduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Experience visualizing presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc. Desired Skills: Strong problem-solving skills with an emphasis on product development. Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets. Experience working with and creating data architectures. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) with applications. Excellent written and verbal communication skills for coordinating across teams. A drive to learn and master new technologies and techniques. We’re looking for someone with experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative fi eld, and is familiar with software.",
        "url": "https://www.linkedin.com/jobs/view/3961446316",
        "summary": "We are seeking a Data Scientist with a minimum of a Master's degree in a quantitative field to join our team. This role will focus on product development, requiring strong problem-solving skills and experience manipulating data, building statistical models, and using advanced machine learning techniques.  The ideal candidate will have experience with distributed data computing tools and data visualization techniques. This is a 6+ month contract position located remotely but requiring proximity to Oakland, CA.",
        "industries": [
            "Data Science",
            "Analytics",
            "Product Development",
            "Technology"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Learning",
            "Data Visualization"
        ],
        "hard_skills": [
            "SQL",
            "R",
            "Python",
            "Machine Learning",
            "Statistical Modeling",
            "Clustering",
            "Decision Trees",
            "Neural Networks",
            "Regression",
            "Simulation",
            "Scenario Analysis",
            "Text Mining",
            "Social Network Analysis",
            "GLM",
            "Random Forest",
            "Boosting",
            "Data Architecture",
            "Distributed Computing",
            "Hadoop",
            "Hive",
            "Spark",
            "MapReduce",
            "Gurobi",
            "MySQL",
            "Redshift",
            "S3",
            "Digital Ocean",
            "Google Analytics",
            "Site Catalyst",
            "Coremetrics",
            "Adwords",
            "Crimson Hexagon",
            "Facebook Insights",
            "Periscope",
            "Business Objects",
            "D3",
            "ggplot",
            "C",
            "C++",
            "Java",
            "JavaScript"
        ],
        "tech_stack": [
            "SQL",
            "R",
            "Python",
            "Hadoop",
            "Hive",
            "Spark",
            "MapReduce",
            "Gurobi",
            "MySQL",
            "Redshift",
            "S3",
            "Digital Ocean",
            "Google Analytics",
            "Site Catalyst",
            "Coremetrics",
            "Adwords",
            "Crimson Hexagon",
            "Facebook Insights",
            "Periscope",
            "Business Objects",
            "D3",
            "ggplot"
        ],
        "programming_languages": [
            "SQL",
            "R",
            "Python",
            "C",
            "C++",
            "Java",
            "JavaScript"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Statistics",
                "Mathematics",
                "Computer Science",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Irving, TX",
        "job_id": 3959667295,
        "company": "Ascendion",
        "title": "Machine Learning Engineer",
        "created_on": 1720587755.5792625,
        "description": "About Ascendion Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: Build the coolest tech for world’s leading brands Solve complex problems - and learn new skills Experience the power of transforming digital engineering for Fortune 500 clients Master your craft with leading training programs and hands-on experience Experience a community of change makers! Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. About the Role: Job Title: Machine Learning Engineer Knowledge and Skills: 5+ years of experience as a Machine Learning Engineer. Analytics, AI, machine learning, natural language processing (NLP), natural language understanding (NLU), large language models (LLMs) Generative AI prompt engineering and tuning Design of AI/ML model performance metrics and optimization Intermediate to Advanced level Python coding SQL Intents, entities, dialogs, actions, and related chat bot concepts are a plus Strong ability to learn AI concepts and experiment with new libraries and ML models for various use cases Self-starter with excellent communication skills Location: Irving, TX Salary Range: The salary for this position is between $100,000 - $130,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate. Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System] Want to change the world? Let us know. Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk",
        "url": "https://www.linkedin.com/jobs/view/3959667295",
        "summary": "Ascendion, a full-service digital engineering solutions company, seeks a Machine Learning Engineer with 5+ years of experience in analytics, AI, machine learning, NLP, NLU, LLMs, generative AI prompt engineering, and model performance metrics. Strong Python coding, SQL, and chatbot concepts are desired. This role offers a competitive salary between $100,000 - $130,000 annually, along with a comprehensive benefits package including medical, dental, vision, 401(k), disability insurance, personal days, vacation time, holidays, and a learning management system. Located in Irving, TX, this position presents an opportunity to join a culture of innovation and contribute to cutting-edge technology for Fortune 500 clients.",
        "industries": [
            "Software Engineering",
            "Digital Engineering",
            "Technology",
            "Cloud Computing",
            "Data Analytics",
            "Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Self-Starter",
            "Teamwork",
            "Innovation",
            "Creativity",
            "Learning"
        ],
        "hard_skills": [
            "Machine Learning",
            "Analytics",
            "AI",
            "NLP",
            "NLU",
            "LLMs",
            "Generative AI",
            "Prompt Engineering",
            "Model Optimization",
            "Python",
            "SQL",
            "Chatbot Concepts",
            "Intents",
            "Entities",
            "Dialogs",
            "Actions"
        ],
        "tech_stack": [
            "Machine Learning",
            "AI",
            "NLP",
            "NLU",
            "LLMs",
            "Generative AI",
            "Python",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 130000,
            "min": 100000
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "401(k) Retirement Plan",
            "Long-Term Disability Insurance",
            "Short-Term Disability Insurance",
            "Personal Days",
            "Paid Time Off",
            "Paid Vacation Time",
            "Paid Holidays",
            "Floating Holiday",
            "Ascendion Learning Management System"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3963448451,
        "company": "Texas Instruments",
        "title": "Data Scientist, People Analytics",
        "created_on": 1720587757.1963906,
        "description": "We can't predict what the future holds, but we know Texas Instruments will have a part in shaping it. Texas Instruments is seeking a Data Scientist. In this role you will be responsible for designing, developing and programming methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client services and product enhancement. As a Data Scientist, you will interact across the organization to identify questions and issues for data analysis and experiments. You will develop and code software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. You will also identify meaningful insights from large data and metadata sources; interpret and communicate insights and findings from analysis and experiments to product, service, and business managers. Our People Analytics' mission is to inform decisions that translate to enhanced performance & employee experience. You will help us accomplish this through a combination of your unique skills in social science research and advanced analytics. You will improve global business outcomes through research and analysis of workforce and human resource data with an emphasis on projects that are repeatable, scalable, predictive, innovative and equitable. To achieve project goals, you will have access to create and evaluate data from assessments, surveys, internal systems, and outside research. You will consult with global HR and business leaders on a broad range of topics, including performance, training, talent selection, retention, diversity and inclusion, compensation, and workforce planning. The output of your work directly translates to continued improvements in areas such as minimizing bias in global hiring and internal promotion programs, predicting and mitigating turnover, evaluating effectiveness of development opportunities and employee recognition, identifying traits and behaviors of successful leadership and strong technical execution within TI. As a Data Scientist, Some Of Your Responsibilities Include Analyze and predict the behaviors of employees and candidates with scientific rigor. Design and conduct quantitative and qualitative research using primary and secondary data to solve problems. Measure impact of HR processes and decisions with data, surveys, and evidence. Connect global stakeholders with the data they need, when they need it. Listen to employee experiences to drive positive, transparent, and equitable change. Consult with the business to translate needs into hypotheses. Explore new ideas and trends within TI’s human capital. Act as a steward of ethical data usage and protect against errors, misunderstanding, and misuse. Texas Instruments will not sponsor job applicants for visas or work authorization for this position. Minimum Requirements Advanced degree (MS/MA or PhD) in a related field (e.g., Industrial-Organizational Psychology, People Analytics, Business Analytics, Statistics, Economics, Data Science, Applied Math, etc.). Experience with advanced data analytics, building predictive statistical models, or analyzing workforce behavior. Strong proficiency in statistical languages such as R or Python. Experience in managing relational databases and writing SQL queries. Preferred Skills And Abilities Statistics: building predictive models, using supervised and unsupervised learning methods, creating forecasts. Programming: Using R or Python to automate manual processes, combining and manipulating large datasets. Data engineering: Ability to clean, validate, integrate, and evaluate large datasets from disparate and unstructured sources. Social science research: applying analytical methods toward workforce behavior such as psychometrics, reliability and validity assessments, organizational network analyses, and job analyses. Project management: consulting on high-stakes projects, action planning, collaborating with functional teams of diverse perspectives, navigating ambiguous situations. Communication: brainstorming with clients regarding business needs and presenting complex ideas and findings to stakeholders. About Texas Instruments As a global semiconductor company, we design, manufacture, test and sell analog and embedded processing chips to nearly 100,000 customers. Our products enable electronics everywhere and in things you experience every day - from health care, smart homes and connected cars to drones, smart phones and more. Our passion to create a better and more sustainable world by making electronics more affordable through semiconductors drives us to make our technology smaller, more efficient, more reliable and more affordable.",
        "url": "https://www.linkedin.com/jobs/view/3963448451",
        "summary": "Texas Instruments is seeking a Data Scientist to analyze workforce and human resource data, focusing on projects that are repeatable, scalable, predictive, innovative, and equitable. The role involves applying advanced data analytics and statistical modeling techniques to predict employee behavior, measure the impact of HR processes, and drive positive change in areas like hiring, promotion, turnover, training, and leadership development.",
        "industries": [
            "Semiconductors",
            "Technology",
            "Human Resources",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Project Management",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Creativity",
            "Innovation",
            "Presentation Skills",
            "Stakeholder Management",
            "Leadership",
            "Teamwork",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Data Analytics",
            "Predictive Modeling",
            "Statistical Modeling",
            "Workforce Behavior Analysis",
            "R",
            "Python",
            "SQL",
            "Relational Databases",
            "Data Engineering",
            "Data Cleaning",
            "Data Validation",
            "Data Integration",
            "Data Evaluation",
            "Psychometrics",
            "Reliability and Validity Assessments",
            "Organizational Network Analyses",
            "Job Analyses"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SQL",
            "Relational Databases"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "MS/MA or PhD",
            "fields": [
                "Industrial-Organizational Psychology",
                "People Analytics",
                "Business Analytics",
                "Statistics",
                "Economics",
                "Data Science",
                "Applied Math"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3967782467,
        "company": "IntagHire",
        "title": "Data Scientist (ML Ops, Airflow) with Oil/Gas experience - Onsite in Houston, TX",
        "created_on": 1720587761.3061848,
        "description": "Data Scientist role with Python, Airflow, and ML Ops. Perm position located onsite in Houston, Texas. Oil/Gas experience required. Compensation range is $120K to $140K max with a benefits package. About the Role: We are currently looking for a highly skilled and motivated Data Scientis t to join our team and collaborate with one of our Fortune 200 oil and gas clients in Houston, TX. As a Data Scientist, your primary responsibilities will be to develop and implement predictive models using statistical and machine learning techniques to address specific business problems for our client. The preferred candidate will possess a robust foundation in data science, machine learning, and a keen interest in tackling intricate challenges within the oil and gas sector. However, we are also open to considering recent graduates who demonstrate the potential and eagerness to acquire the requisite skill set. A data science background and relevant education will also be highly advantageous for this role. This position requires the candidate to be on-site at our client's office in Houston, TX. Responsibilities: Develop and implement predictive models using statistical and machine learning techniques. Analyze large, complex datasets from various sources, including drilling logs, seismic data, and production data. Collaborate with cross-functional teams to develop and deploy machine learning models in production. Utilize Python to clean, manipulate, and analyze complex datasets. Develop and maintain data pipelines using Airflow and Kube KUB. Develop and maintain model deployment pipelines using Machine Learning Ops. Continuously monitor and improve the performance of deployed models. Creating reports and presentations for technical and non-technical audiences. Keep up-to-date with the latest developments in machine learning and data science to identify opportunities to apply new techniques to solve business problems. Requirements: Bachelor's or advanced degree in Computer Science, Data Science, or related field (recent graduates welcome). Excellent team leadership/project management skills Strong analytical abilities Proven experience in model deployment. Familiarity with Airflow and Kube KUB is preferred. Strong knowledge of machine learning techniques and tools. Experience with ML Ops is a huge plus. Familiarity with the Oil & Gas industry is a plus Strong communication and interpersonal skills. Ability to work independently and as part of a team. If you are an experienced Data Scientist with a Python background and a passion for developing and deploying machine learning models in production, we encourage you to apply for this exciting opportunity. Tags: oil/gas, ML Ops, Python, Kube, Airflow, Airflow, Airflow, oil, gas, petroleum",
        "url": "https://www.linkedin.com/jobs/view/3967782467",
        "summary": "Data Scientist role in Houston, TX for a Fortune 200 oil and gas client. Responsibilities include developing and implementing predictive models using statistical and machine learning techniques, analyzing large datasets, collaborating with cross-functional teams, deploying models in production using ML Ops, and maintaining data pipelines with Airflow and Kube KUB.",
        "industries": [
            "Oil & Gas",
            "Data Science",
            "Machine Learning",
            "Software Engineering"
        ],
        "soft_skills": [
            "Team leadership",
            "Project management",
            "Analytical abilities",
            "Communication",
            "Interpersonal skills",
            "Ability to work independently",
            "Ability to work as part of a team"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "Statistical modeling",
            "Data analysis",
            "Data pipeline development",
            "Airflow",
            "Kube KUB",
            "ML Ops",
            "Model deployment"
        ],
        "tech_stack": [
            "Python",
            "Airflow",
            "Kube KUB",
            "ML Ops"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Related field"
            ]
        },
        "salary": {
            "max": 140000,
            "min": 120000
        },
        "benefits": [
            "Benefits package"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Francisco Bay Area",
        "job_id": 3965382818,
        "company": "Compass Regulatory",
        "title": "Machine Learning Engineer",
        "created_on": 1720587767.7718647,
        "description": "We’re Compass Regulatory, an early stage technology startup building the regulatory and compliance platform for the ag industry. We help agriculture companies – starting with crop input developers and retailers – easily track and execute their regulatory work, letting them bring new products to market faster while reducing the risk of costly errors. Our team comes from some of the leading companies in the AgTech industry, and has received investment from notable SaaS and AgTech investors. We are seeking a talented and ambitious Machine Learning Engineer to join our growing technical team (currently three engineers). In this role you will: Collaborate with the founding team to explore and unlock new product opportunities Bridge research and implementation in building end-to-end systems integrating human data and QC, model design, implementation, and evaluation, and production inference services Tackle real problems for eager customers requiring highly accurate and reliable solutions Work with the Head of Engineering and Data Science to shape product and development roadmaps to balance technical debt and feature delivery Share in building a technical community that promotes curiosity and innovation What you bring 4+ years of relevant experience as a data scientist, machine learning engineer, or scientific software engineer Masters degree in a technical field or two additional years of experience solving applied problems with software and quantitative reasoning Eagerness to own core data and ML technologies supporting key product areas Track record of collaborating with cross-functional teams to ship data-intensive features Experience with Python, Docker, LLM output evaluation and fine-tuning, multi-modal AI models or workflows, OpenAI and similar API endpoints Preferred: experience in AgTech What we offer A chance to use your technical skills to improve our food and agriculture system A passionate and supportive team eager to learn from each other and our customers Opportunity to join our ambitious venture at an early stage Competitive salary, equity options, healthcare + FSA, commuter benefits, company-sponsored gym access at our office, and 401k program Location SF Bay Area (hybrid) Compensation and Additional Information We take a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into two zones based on a cost of labor index for that geographic area. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future. Zone 1 (San Francisco/Oakland/San Jose; New York; Los Angeles; Seattle): $150,000-190,000 Zone 2 (All other): $130,000-170,000 This role is also eligible to participate in the company's equity plan subject to the terms of the applicable plans and policies. Additional benefits include time off and retirement plan eligibility further detailed in company policies. We are an equal opportunity employer and do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. We consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.",
        "url": "https://www.linkedin.com/jobs/view/3965382818",
        "summary": "Compass Regulatory, an early-stage technology startup, is looking for a Machine Learning Engineer to join their team. This role will involve collaborating with the founding team to develop new product opportunities, build end-to-end systems integrating human data and QC, tackle real problems for customers, and shape product and development roadmaps. The ideal candidate will have 4+ years of relevant experience, a Masters degree in a technical field, strong Python and Docker skills, experience with LLM output evaluation and fine-tuning, multi-modal AI models or workflows, and OpenAI/similar API endpoints. Experience in AgTech is preferred. The company offers a competitive salary, equity options, healthcare + FSA, commuter benefits, company-sponsored gym access, and a 401k program.",
        "industries": [
            "Agriculture",
            "AgTech",
            "Technology",
            "Software",
            "SaaS",
            "Compliance",
            "Regulatory",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Ambitious",
            "Collaborative",
            "Eager",
            "Problem-solving",
            "Analytical",
            "Curious",
            "Innovative",
            "Teamwork",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "Docker",
            "LLM Output Evaluation",
            "LLM Fine-tuning",
            "Multi-modal AI Models",
            "Multi-modal AI Workflows",
            "OpenAI API",
            "Similar API Endpoints"
        ],
        "tech_stack": [
            "Python",
            "Docker",
            "LLM",
            "OpenAI",
            "Multi-modal AI"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Technical"
            ]
        },
        "salary": {
            "max": 190000,
            "min": 130000
        },
        "benefits": [
            "Competitive Salary",
            "Equity Options",
            "Healthcare",
            "FSA",
            "Commuter Benefits",
            "Gym Access",
            "401k Program"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Raritan, NJ",
        "job_id": 3970163323,
        "company": "US Tech Solutions",
        "title": "Data Scientist",
        "created_on": 1720587771.0059533,
        "description": "*Job Title: Data Scientist *Location: Raritan , New Jersey, Hybrid role *Duration: 12 months contract, Full-Time * Employment Type: W-2 Job Description: · This role supports the manufacturing science and technology team supporting clinical/commercial manufacturing. · This role is responsible for process data collection, monitoring, and analysis, change control management, deviation management, and writing of technical documents. Support provided by this individual is critical to succesful manufacturing and release of batches at internal and external manufacturing sites. Responsibilities: · Must have experience with Data Management, Data Entry/Collecting, and Change Management/Change Control exp · Must have Data Scientist exp (gathering & collecting data) · Will be trained on internal systems · Must have working knowledge of Tableau, extremely helpful · Pharma exp highly preferred (maybe FDA exp) · Pure Manufacturing data exp (CART) Experience: · Strong data scientist (creative with ways of mining, gathering, and analyzing) · Flexible to build strenghts on multiple systems/projects/focus areas · Entry level role, interested in gaining initial experience in pharma and cell therapy in particular, open to learning about key quality and data systems · 0-2 years of experience Skills: · GMP knowledge Education: · BS in science/engineering discipline About US Tech Solutions: US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com. US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Recruiter Details: Name: Azhar Email: Azhar@ustechsolutionsinc.com Internal Reference Id: 24-15703",
        "url": "https://www.linkedin.com/jobs/view/3970163323",
        "summary": "This is a 12-month contract Data Scientist position supporting the manufacturing science and technology team at a pharmaceutical company. The role involves process data collection, monitoring, and analysis, change control management, deviation management, and writing technical documents.  Experience with data management, data entry/collection, and change management is required.  Pharmaceutical experience and knowledge of Tableau are highly preferred.  The role is entry-level and open to individuals with 0-2 years of experience.",
        "industries": [
            "Pharmaceuticals",
            "Manufacturing",
            "Biotechnology",
            "Cell Therapy",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Skills",
            "Teamwork",
            "Adaptability",
            "Flexibility",
            "Learning Agility"
        ],
        "hard_skills": [
            "Data Management",
            "Data Entry",
            "Data Collection",
            "Change Management",
            "Change Control",
            "Data Analysis",
            "Tableau",
            "GMP",
            "CART"
        ],
        "tech_stack": [
            "Tableau"
        ],
        "programming_languages": [],
        "experience": 2,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Atlanta Metropolitan Area",
        "job_id": 3970033758,
        "company": "Bose Corporation",
        "title": "Senior Data Scientist",
        "created_on": 1720587775.0119674,
        "description": "ABOUT BOSE You know the moment. It’s the first notes of that song you love, the intro to your favorite movie, or simply the sound of someone you love saying “hello.” It’s in these moments that sound matters most. Innovation is more than what we do. It’s who we are — constantly learning and constantly curious. We never stop imagining what better sound sounds like. We’re music fanatics and audio engineers. We’re explorers and inventors and dreamers. And we’re passionate down to our bones about making whatever you’re listening to a little more magical. ABOUT THE ROLE At Bose, we aim to bring products into the world that people truly love, and we don’t stop until the details are just right. Data science, machine learning, and analytics are a crucial part of this mission. These capabilities fuel the creation of new and innovative products, helping us to bring the right products to the right customers, and allow us to astonish customers with carefully crafted and personalized experiences. We are looking for a Senior Data Scientist, ideally with a background in demand forecasting and time-series, to join our Data Science team within our Data and Analytics CoE. As a data scientist within the CoE, your mission will be to develop world-class AI, data science, machine learning, and related solutions to solve for our biggest challenges. Within this role you will focus on driving the strategy for and building the next generation of supply chain and demand forecasting models. You will work with a cross-functional team of data scientists and partner with teams from across Bose to influence decisions that will drive a significant impact to our bottom-line and our customers. Responsibilities: Engage with business partners and stakeholders to understand business problems and translate them into data science solutions. Coordinate and collaborate with data science, data engineering, analytic engineering, and other resources to achieve business goals. Work cross-functionally with sales, product, marketing, and engineering on optimization opportunities and insights. Lead and contribute to the end-to-end development and deployment of predictive and prescriptive models, with a focus on supply chain and demand forecasting. Explore large datasets using modeling, analysis, and visualization techniques. Communicate results, analyses, and methodologies to technical and non-technical senior level stakeholders. Ability to mentor, coach, and lead others. Contribute to and help build ML/AI vision to support business strategy. ABOUT YOU MS or PhD in Data Science, Machine Learning, Applied Mathematics/Statistics, or a related field. 8-10 years of experience applying data science, AI/machine learning, and analytics techniques to business problems. 4+ years of experience leading data science projects Must have 3+ years working in demand forecasting - exp in the CE space strongly preferred. Experience with machine learning and causal modeling techniques, with a focus on time-series forecasting. Experience solving real-world problems using programming languages such as SQL, Spark, and Python, and deploying solutions to enterprise systems Excellent strategic thinking, communication, collaboration, and problem-solving skills, including working with and articulating results to senior business stakeholders. Experience with and understanding of project management tools and principles Ideal candidates will have experience in cold-start and in-market demand forecasting. “Our goal is to create an atmosphere where every candidate feels supported and empowered in the interviewing process. Diversity and inclusion are integral to our success, and we believe that providing reasonable accommodation is not only a legal obligation but also a fundamental aspect of our commitment to being an employer of choice. We recognize that individuals may have different needs and requirements based on their abilities, and we provide reasonable accommodations to ensure ideal conditions are met during the application process. If you believe you need a reasonable accommodation, please send a note to wellbeing@bose.com” #LI-RD1",
        "url": "https://www.linkedin.com/jobs/view/3970033758",
        "summary": "Bose seeks a Senior Data Scientist with expertise in demand forecasting and time-series analysis to join their Data Science team. This role involves building and deploying AI and machine learning solutions to improve supply chain and demand forecasting, collaborating with cross-functional teams, and communicating results to stakeholders. Ideal candidates will have experience in cold-start and in-market demand forecasting.",
        "industries": [
            "Electronics",
            "Consumer Goods",
            "Retail",
            "Technology",
            "Audio",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Strategic Thinking",
            "Leadership",
            "Mentorship",
            "Project Management"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "AI",
            "Demand Forecasting",
            "Time-Series Analysis",
            "SQL",
            "Spark",
            "Python",
            "Causal Modeling"
        ],
        "tech_stack": [
            "SQL",
            "Spark",
            "Python"
        ],
        "programming_languages": [
            "SQL",
            "Spark",
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Data Science",
                "Machine Learning",
                "Applied Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Texas, United States",
        "job_id": 3969095118,
        "company": "Tiger Analytics",
        "title": "Senior Data Scientist- Marketing",
        "created_on": 1720587777.9368386,
        "description": "Tiger Analytics is pioneering what AI and analytics can do to solve some of the toughest problems faced by organizations globally. We develop bespoke solutions powered by data and technology for several Fortune 100 companies. We have offices in multiple cities across the US, UK, India, and Singapore, and a substantial remote global workforce. We are also market leaders in AI and analytics consulting in the retail & CPG industry with over 40% of our revenues coming from the sector. This is our fastest-growing sector, and we are beefing up our talent in the space. We are looking for a Senior Data Scientist with a good blend of data analytics background, who holds solid knowledge of email marketing, online marketing, and retail personalization. quick learner, and has strong coding capabilities to add to our team. Responsibilities Work on the latest applications of data science to solve business problems in Ecommerce with the digital marketing analytics space of Retail Effectively communicate the analytics approach and how it will meet and address objectives to business partners Responsible for designing and maintaining email campaigns, offer optimization, CLTV estimation, affinity modeling, propensity modeling Lead data analytic and modeling approaches; integrate solutions collaboratively into applications and tools with data engineers, business leads, analysts, and developers Create repeatable, interpretable, dynamic, and scalable models seamlessly incorporated into analytic data products Collaborate, coach, and learn with a growing team of experienced Data Scientists Stay connected with external sources of ideas through conferences and community engagements Support demands from regulators, investor relations, etc., to develop innovative solutions to meet objectives utilizing cutting-edge techniques and tools Requirements 4+ years of Data Science experience required Graduate Degree in Data Science, Computer Science, or a related field is required Extensive knowledge in email marketing, online marketing, and retail personalization Strong marketing modeling capability in email campaigns, offer optimization, CLTV, affinity modeling, propensity modeling Strong Python coding with production experience is preferred, ML ops knowledge and experience is a plus Excellent domain knowledge in retail/Ecom marketing Ability to apply various analytical models to business use cases Exceptional communication and collaboration skills to understand business partner needs and deliver solutions Bias for action, with the ability to deliver outstanding results through task prioritization and time management Be proactive, curious, can-do attitude, flexible personality Benefits This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",
        "url": "https://www.linkedin.com/jobs/view/3969095118",
        "summary": "Tiger Analytics is seeking a Senior Data Scientist with 4+ years of experience to lead data analytic and modeling approaches in the retail/ecom marketing space. The role involves designing and maintaining email campaigns, offer optimization, CLTV estimation, affinity modeling, and propensity modeling. Strong Python coding, ML ops knowledge, and excellent communication skills are required. The position offers significant career development opportunities in a fast-growing and challenging environment.",
        "industries": [
            "Retail",
            "Ecommerce",
            "CPG",
            "AI",
            "Analytics",
            "Marketing",
            "Digital Marketing"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Proactive",
            "Curious",
            "Flexible",
            "Time Management",
            "Leadership"
        ],
        "hard_skills": [
            "Data Science",
            "Email Marketing",
            "Online Marketing",
            "Retail Personalization",
            "Marketing Modeling",
            "Email Campaigns",
            "Offer Optimization",
            "CLTV",
            "Affinity Modeling",
            "Propensity Modeling",
            "Python",
            "ML Ops"
        ],
        "tech_stack": [
            "Python",
            "ML Ops"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Graduate Degree",
            "fields": [
                "Data Science",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Career Development",
            "Entrepreneurial Environment",
            "Individual Responsibility"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Addison, TX",
        "job_id": 3967133728,
        "company": "IDR, Inc.",
        "title": "Data Scientist (347353)",
        "created_on": 1720587779.410759,
        "description": "IDR is seeking a Data Scientist to join one of our top clients in the North Dallas area. This is a long-term opportunity, so if you are looking for an opportunity to join a large organization and work within an ever-growing, team-oriented culture, please apply today! Responsibilities for the Data Scientist: Lead development of end-to-end analytics projects for our client’s manufacturing, leasing, and supply chain groups from conception through delivery, driving effective collaboration and alignment with business stakeholders Work closely with business leaders, project stakeholders, and subject matter experts to understand and optimize key business processes. Apply your SQL, data transformation, and data modeling skills to turn data into actionable insights and optimized solutions Partner with data engineers on technical design of complex data sourcing, transformation, and aggregation logic to meet business analytics needs and deliver value. Leverage generative AI in analytical work where applicable Work with data analysts to translate business requirements into impactful data visualizations and data models in platforms like Qliksense, Tableau, PowerBI, and other analytics tools Required Skills for the Data Scientist: Bachelor’s Degree in quantitative field such as Mathematics, Economics, Computer Science, Information Management, Statistics, Finance or Accounting. Masters and/or PhD preferred 5+ years relevant experience in related analytics, data science, and business intelligence Prior experience working for an industrial manufacturing and/or supply chain company 4+ years experience with Python and R Experience with data visualizations and data models in platforms like Qliksense, Tableau, PowerBI, and other analytics tools is preferred Excellent Communication and the ability to effectively communicate data stories to key stakeholders What’s in it for you? Competitive compensation package Full Benefits; Medical, Vision, Dental, and more! Opportunity to get in with an industry leading organization Close-knit and team-oriented culture Why IDR? 20+ Years of Proven Industry Experience in 4 major markets Employee Stock Ownership Program Dedicated Engagement Manager who is committed to you and your success Medical, Dental, Vision, and Life Insurance ClearlyRated’s Best of Staffing® Client and Talent Award winner 10 years in a row",
        "url": "https://www.linkedin.com/jobs/view/3967133728",
        "summary": "Data Scientist needed for a long-term opportunity with a large organization in North Dallas. Responsibilities include leading end-to-end analytics projects for manufacturing, leasing, and supply chain groups, working with stakeholders to optimize business processes, collaborating with data engineers and analysts, and using generative AI. Required skills include a Bachelor's degree in a quantitative field, 5+ years of relevant experience, prior experience in industrial manufacturing and/or supply chain, 4+ years of experience with Python and R, data visualization experience in Qliksense, Tableau, PowerBI, and other tools, and excellent communication skills.",
        "industries": [
            "Manufacturing",
            "Leasing",
            "Supply Chain",
            "Industrial"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Analytical Thinking",
            "Teamwork",
            "Leadership",
            "Project Management"
        ],
        "hard_skills": [
            "SQL",
            "Data Transformation",
            "Data Modeling",
            "Generative AI",
            "Python",
            "R",
            "Data Visualization",
            "Qliksense",
            "Tableau",
            "PowerBI"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "R",
            "Qliksense",
            "Tableau",
            "PowerBI",
            "Generative AI"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Mathematics",
                "Economics",
                "Computer Science",
                "Information Management",
                "Statistics",
                "Finance",
                "Accounting"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive compensation package",
            "Medical",
            "Vision",
            "Dental",
            "Opportunity to get in with an industry leading organization",
            "Close-knit and team-oriented culture",
            "Employee Stock Ownership Program",
            "Medical",
            "Dental",
            "Vision",
            "Life Insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "The Woodlands, TX",
        "job_id": 3964651912,
        "company": "Linde",
        "title": "Data Scientist",
        "created_on": 1720587781.0329266,
        "description": "Linde Inc. Data Scientist The Woodlands, TX, United States | req17816 What you will enjoy doing* This is a unique opportunity to collaborate with a diverse team of technical experts to solve a variety of complex problems in a fun and dynamic environment. With flexibility to use the latest tools and technology, imagination and creativity are the only limitations on your impact You will be a member of the Digital Americas organization. Digital Americas is a multi-disciplinary technical team comprised of data scientists, software engineers and operations research experts- the team serves Linde’s global business units and is tasked with creating analytics and decision support software solutions for complex problems You will collaborate with business partners to understand product requirements and define appropriate technical solutions Lead technical development of cutting-edge analytics and decision support tools Stay abreast of new technology and actively contribute ideas for new programs Balance development of new solutions with replication and support of existing tools What Makes You Great BS in Industrial Engineering, Chemical Engineering, Computer Science, Statistics or Operations Research with a specialization in data science or analytics; Master's degree preferred Excellent analytical and problem-solving skills Passion for technology with a strong emphasis on user experience and business value Ability to succinctly convey complex solutions to business stakeholders and executive leadership Willingness to work in an agile and dynamic environment Availability to travel up to 30%, domestic and international Deep knowledge of machine learning and/or operations research theory with practical development experience is preferred, but not required, as well as strong programming skills in Python or at least one major programming language, and experience with data visualization Experience deploying solutions to cloud providers, preferably Azure, as well as designing and using relational databases, NoSQL data stores and data historians is also preferred Why you will love working with us Linde is a leading global industrial gases and engineering company with 2023 sales of $33 billion. We live our mission of making our world more productive every day by providing high-quality solutions, technologies and services which are making our customers more successful and helping to sustain, decarbonize and protect our planet. The company serves a variety of end markets such as chemicals & energy, food & beverage, electronics, healthcare, manufacturing, metals and mining. Linde's industrial gases and technologies are used in countless applications including production of clean hydrogen and carbon capture systems critical to the energy transition, life-saving medical oxygen and high-purity & specialty gases for electronics. Linde also delivers state-of-the-art gas processing solutions to support customer expansion, efficiency improvements and emissions reductions. Linde employees learn and abide the Linde Code of Ethics and Code of Conduct by demonstrating honesty, integrity, professionalism in all communications, actions, and decisions. What we offer you! At Linde, the sky is not the limit. If you’re looking to build a career where your work reaches beyond your job description and betters the people with whom you work, the communities we serve, and the world in which we all live, at Linde, your opportunities are limitless. Be Linde. Be Limitless. Every day is an opportunity: an opportunity to learn, to grow, to share success, and to contribute to one of the world’s leading industrial gas and engineering companies. Seize the opportunity: take your next step with us and join our team. In addition to competitive compensation we offer a wide range of medical options to suit everyone’s needs. Other benefits include; educational and professional development, employee discount program, 401K, pension plan, and life insurance, just to name a few. Have we inspired you? Let´s talk about it We are looking forward to receiving your complete application. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, protected veteran status, pregnancy, sexual orientation, gender identity or expression, or any other reason prohibited by applicable law. Linde Inc. acts responsibly towards its shareholders, business partners, employees, society and the environment in every one of its business areas, regions and locations across the globe. The company is committed to technologies and products that unite the goals of customer value and sustainable development. The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position. Therefore employees assigned may be required to perform additional job tasks required by the manager.",
        "url": "https://www.linkedin.com/jobs/view/3964651912",
        "summary": "Linde Inc. is seeking a Data Scientist to join their Digital Americas team. The role involves collaborating with business partners to develop cutting-edge analytics and decision support tools. The ideal candidate will have a strong understanding of machine learning and/or operations research, experience with Python programming, and familiarity with cloud providers (Azure).",
        "industries": [
            "Industrial Gases",
            "Engineering",
            "Chemicals",
            "Energy",
            "Food & Beverage",
            "Electronics",
            "Healthcare",
            "Manufacturing",
            "Metals",
            "Mining"
        ],
        "soft_skills": [
            "Collaboration",
            "Problem-solving",
            "Analytical Skills",
            "Communication",
            "User Experience",
            "Business Value",
            "Teamwork",
            "Flexibility",
            "Creativity",
            "Leadership",
            "Communication",
            "Problem-solving"
        ],
        "hard_skills": [
            "Machine Learning",
            "Operations Research",
            "Python",
            "Data Visualization",
            "Azure",
            "Relational Databases",
            "NoSQL",
            "Data Historians"
        ],
        "tech_stack": [
            "Python",
            "Azure",
            "Relational Databases",
            "NoSQL",
            "Data Historians"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Industrial Engineering",
                "Chemical Engineering",
                "Computer Science",
                "Statistics",
                "Operations Research"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Compensation",
            "Medical Options",
            "Educational & Professional Development",
            "Employee Discount Program",
            "401K",
            "Pension Plan",
            "Life Insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Herndon, VA",
        "job_id": 3963955382,
        "company": "Idexcel",
        "title": "Machine Learning Engineer",
        "created_on": 1720587782.5243258,
        "description": "The Machine Learning (ML) Practice team is a specialized customer-facing ML team at Idexcel facing an increasing demand for Large Language Model (LLM)-based solutions. We work with customers to help them shape their long-term initiatives working alongside engineering, product, and developer relations, and internal subject matter expert (SME) teams. The ideal candidate will enjoy being part of a broader team of technologists that love empowering customers, collaborating with teammates, and satisfying your curiosity working with the latest trends in LLMs, Data Science and ML. Responsibilities · Develop LLM solutions on customer data such as RAG architectures on enterprise knowledge repos, querying structured data with natural language, and content generation. · Set up and configure the Retrieval Augmented Generation (RAG) for the Large Language Model (LLM) · Collaborate with the Business Analyst and other team members to understand the defined use cases and ensure the RAG configuration aligns with the project requirements. · Develop and implement strategies for efficient and accurate retrieval of relevant information from various data sources. · Optimize the RAG system to enhance the performance and accuracy of the LLM in generating summaries and responses based on the retrieved information. · Coordinate with the Fine-tuning Developer to ensure seamless integration between the RAG system and the fine-tuned LLM. · Document the RAG system's architecture, configuration, and best practices for maintainability and future enhancements. Experience Experience with the latest techniques in natural language processing, including vector databases, fine-tuning large language models (LLMs), and deploying LLMs using tools such as Anthropic, Llama, Hugging Face, Langchain, and OpenAI. · 3+ years of hands-on industry data science experience, using typical machine learning and data science tools including pandas, scikit-learn, gensim, nltk, and TensorFlow/PyTorch · Should have experience building chatbots using platforms or frameworks like Amazon Lex, Microsoft Bot Framework, Google Dialog Flow. · Should be good at designing and implementing conversational flows, intent recognition, and entity extraction. · Natural Language Processing (NLP) Skills: - Text preprocessing: tokenization, stemming, lemmatization, stop word removal - Named Entity Recognition (NER) - Sentiment analysis - Intent classification - Language understanding and generation. · Machine Learning and Deep Learning: - Supervised and unsupervised learning techniques. Neural network architectures (e.g., Recurrent Neural Networks, Long Short-Term Memory) - Model training, evaluation, and deployment. · Should possess knowledge of building context-aware models. · Graduate degree in a quantitative discipline (Computer Science, Engineering, Statistics, Operations Research) or equivalent practical experience · Experience communicating and teaching technical concepts to non-technical and technical audiences alike",
        "url": "https://www.linkedin.com/jobs/view/3963955382",
        "summary": "Idexcel's Machine Learning Practice team is seeking a skilled Data Scientist with experience in Large Language Models (LLMs) to build RAG architectures for enterprise knowledge repositories. The ideal candidate will have hands-on experience with NLP techniques, vector databases, fine-tuning LLMs, and deploying LLMs using tools like Anthropic, Llama, Hugging Face, Langchain, and OpenAI. They will also be proficient in machine learning, deep learning, and building context-aware models. The role involves collaborating with teams to understand use cases, design conversational flows, implement NLP tasks, and optimize RAG systems for LLM performance. ",
        "industries": [
            "Information Technology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Consulting"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Technical Communication",
            "Teaching"
        ],
        "hard_skills": [
            "LLMs",
            "RAG",
            "Vector Databases",
            "Fine-Tuning LLMs",
            "Anthropic",
            "Llama",
            "Hugging Face",
            "Langchain",
            "OpenAI",
            "Pandas",
            "Scikit-learn",
            "Gensim",
            "NLTK",
            "TensorFlow",
            "PyTorch",
            "Amazon Lex",
            "Microsoft Bot Framework",
            "Google Dialog Flow",
            "Text Preprocessing",
            "Tokenization",
            "Stemming",
            "Lemmatization",
            "Stop Word Removal",
            "Named Entity Recognition",
            "Sentiment Analysis",
            "Intent Classification",
            "Language Understanding",
            "Language Generation",
            "Supervised Learning",
            "Unsupervised Learning",
            "Recurrent Neural Networks",
            "Long Short-Term Memory",
            "Model Training",
            "Model Evaluation",
            "Model Deployment",
            "Context-Aware Models"
        ],
        "tech_stack": [
            "LLMs",
            "RAG",
            "Vector Databases",
            "Anthropic",
            "Llama",
            "Hugging Face",
            "Langchain",
            "OpenAI",
            "Pandas",
            "Scikit-learn",
            "Gensim",
            "NLTK",
            "TensorFlow",
            "PyTorch",
            "Amazon Lex",
            "Microsoft Bot Framework",
            "Google Dialog Flow"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Graduate",
            "fields": [
                "Computer Science",
                "Engineering",
                "Statistics",
                "Operations Research"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York City Metropolitan Area",
        "job_id": 3808225435,
        "company": "Paragon Alpha - Hedge Fund Talent Business",
        "title": "Data Scientist/Analyst - Equities Trading Pod - Multi-Strat - $600K",
        "created_on": 1720587784.1770244,
        "description": "Paragon Alpha are partnered with a Consumer Equities PM at a large multi-strat, who is looking for a Data Scientist/Analyst to come into his growing trading team. The systematic strategy requires a sophisticated research and data eco-system, and they need a Data Scientist to conduct research and analysis across global companies in consumers, trying to find alternative ways of viewing various data sets. Stack: Python, Pandas, SQL, The incumbent will be tasked with rudimentary research, partnering close with QRs, and working with onboarding data sets, and conducting analytics with Python libraries. If this sounds of interest, then please do apply.",
        "url": "https://www.linkedin.com/jobs/view/3808225435",
        "summary": "A Consumer Equities PM at a large multi-strategy firm is seeking a Data Scientist/Analyst to join their growing trading team. The role involves conducting research and analysis on global consumer companies, focusing on alternative data sets and leveraging Python, Pandas, and SQL. The Data Scientist will collaborate with quantitative researchers (QRs) and handle data onboarding and analytics.",
        "industries": [
            "Financial Services",
            "Investment Management",
            "Data Science",
            "Quantitative Finance"
        ],
        "soft_skills": [
            "Research",
            "Analysis",
            "Collaboration",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "Pandas",
            "SQL"
        ],
        "tech_stack": [
            "Python",
            "Pandas",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3969182471,
        "company": "East 57th Street Partners",
        "title": "Data Scientist",
        "created_on": 1720587785.8110602,
        "description": "🚀 We're Hiring! Our esteemed client is on the lookout for a talented individual to fill a crucial role in their dynamic team. Here's why you should be excited about this opportunity: ✅ 100% Remote Position: Embrace the flexibility of working from anywhere! This role offers the perfect balance between work and life, allowing you to excel in your professional journey without compromising on your personal time. 💼 Competitive Salary & Benefits: We understand the value of our employees. That's why this position comes with an attractive salary package and a comprehensive benefits plan, ensuring you feel valued and supported. 🌐 Quarterly Travel to Corporate Headquarters: While enjoying the perks of remote work, you'll also have the unique opportunity to travel to our client's corporate headquarters once every quarter. This is a fantastic chance to connect with the team, engage in collaborative projects, and immerse yourself in the company culture. 📈 Grow Your Career: This role isn't just a job; it's a pathway to professional growth and development. Our client is committed to nurturing talent and providing opportunities for career advancement. Are you ready to take the next step in your career with a role that offers the best of both worlds? Apply now and become a part of something truly remarkable! Data Scientist Data Scientists are tasked with analyzing and interpreting complex digital data, such as usage statistics, to assist in business decision-making. This role requires a blend of statistical prowess, data mining ability, and analytical thinking to find patterns and insights hidden in vast datasets. Data Scientists often work closely with business stakeholders to turn data into critical information that can guide organizational decisions. Their expertise in machine learning and predictive modeling is vital for organizations looking to leverage data for a competitive advantage. Responsibilities: Develop and implement databases, data collection systems, data analytics, and other strategies that optimize statistical efficiency and quality. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes. Identify, analyze, and interpret trends or patterns in complex data sets. Work with management to prioritize business and information needs. Locate and define new process improvement opportunities. Collaborate with engineering and product development teams. Requirements: Proven experience as a Data Scientist or Data Analyst. Experience in data models and reporting packages. Ability to analyze large datasets. Strong verbal and written communication skills. An analytical mind and inclination for problem-solving. Attention to detail.",
        "url": "https://www.linkedin.com/jobs/view/3969182471",
        "summary": "We are looking for a Data Scientist to analyze and interpret complex digital data to assist in business decision-making. You will develop and implement databases, data collection systems, and data analytics, use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes. This is a 100% remote position with quarterly travel to corporate headquarters.",
        "industries": [
            "Data Science",
            "Analytics",
            "Technology",
            "Business"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Analytical Thinking",
            "Collaboration"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Modeling",
            "Predictive Modeling",
            "Data Collection",
            "Statistical Analysis",
            "Machine Learning"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Remote Work",
            "Competitive Salary",
            "Comprehensive Benefits",
            "Quarterly Travel"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3959212850,
        "company": "InfoVision Inc.",
        "title": "Data Scientist",
        "created_on": 1720587787.433895,
        "description": "Job Title: Data Scientist Location: Dallas, TX Duration: Long-term Data Scientist: 5+ years’ experience – Need Phd in any technical field Independently create and/or Assist lead data scientists in developing various kinds of machine learning models for personalized customer service domain using state of the art ML algorithms such as GBM, XGBoost, Deep Learning etc. on CPU and GPU environments Conduct pre-modeling activities such as data clean up, exploratory data analysis, scaling/normalization, feature engineering, etc. with data in Google Cloud Platform ecosystem, notebooks Proficient with standard Data Science Libraries such as NumPy, Pandas and Deep learning. In addition, proficiency in libraries for GPUs is a huge plus Knowledge of Pytorch or Tensorflow and experience with modern neural NLP approaches is a plus. Developing test cases and executing test cases for developed ML models Assist in performance/load testing/monitoring of the deployed models Documenting the models, features and any decisions made during modeling Assist ML engineers during solution deployment on on-prem and AWS for authoring/making changes to API wrappers Ability to rapidly learn the current state of the project and independently work with minimal assistance after the initial ramp up time",
        "url": "https://www.linkedin.com/jobs/view/3959212850",
        "summary": "Data Scientist needed with 5+ years of experience and a PhD in a technical field to develop machine learning models for personalized customer service. Responsibilities include data cleaning, feature engineering, model development using GBM, XGBoost, and deep learning, model testing, deployment assistance, and documentation. Experience with Google Cloud Platform, PyTorch or TensorFlow, and modern NLP approaches are preferred.",
        "industries": [
            "Technology",
            "Data Science",
            "Machine Learning",
            "Customer Service"
        ],
        "soft_skills": [
            "Independent",
            "Analytical",
            "Problem-solving",
            "Communication",
            "Documentation",
            "Collaboration",
            "Time Management",
            "Learning",
            "Detail-oriented"
        ],
        "hard_skills": [
            "Machine Learning",
            "GBM",
            "XGBoost",
            "Deep Learning",
            "Data Cleaning",
            "Exploratory Data Analysis",
            "Feature Engineering",
            "Scaling/Normalization",
            "NumPy",
            "Pandas",
            "PyTorch",
            "TensorFlow",
            "Neural NLP",
            "Model Testing",
            "Performance/Load Testing",
            "Monitoring",
            "API Wrappers",
            "Google Cloud Platform"
        ],
        "tech_stack": [
            "Google Cloud Platform",
            "NumPy",
            "Pandas",
            "PyTorch",
            "TensorFlow"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Technical"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Suitland, MD",
        "job_id": 3968764181,
        "company": "USAJOBS",
        "title": "Data Scientist",
        "created_on": 1720587789.0996177,
        "description": "Duties Performs advanced queries using database and analytical tools (e.g. SQL Server) and programming languages (e.g. Python, R, and Java) to analyze data and develop data-analytical visualizations. Provides data science expertise to a wide range of highly complex initiatives and projects focused on the development of cutting-edge tools and resources to easily access, store, analyze, and exchange complex, high-quality data. Defines data requirements and integration of enabling technologies to collect, extract, engineer, and transform data from traditional and non-traditional sources. Analyzes a variety of data sources to provide data-driven insights to the organization to streamline processes and evaluate the effectiveness of the program operations in meeting established goals and objectives Designs, implements, and evaluates large, complex analytical applications, projects, and studies, applying a combination of computational and machine learning methods to new or Big Data using next generation analytical tools. Requirements Conditions of Employment Applicants must meet all qualification requirements by the closing date of this announcement. U.S. Citizen. Suitable for Federal employment. Registered for Selective Service, if applicable (www.sss.gov). Time-in-grade/band requirements must be met by closing date. This is a BARGAINING unit position. This position may be covered by one or more of the following bargaining units: American Federation of Government Employees (AFGE) Local 2782(HQ). If you have specific questions, please contact the HR Specialist. This is an open continuous announcement. The initial cutoff date for referral is 6/17/24. After this date, the cut off dates are as follows: 7/16/24 and 8/16/24. Qualifications This vacancy is advertised under 2 different announcements. Please read the 'Who May Apply' section carefully to determine your eligibility. If you are not eligible under this announcement, please see 24-BOC-12386287-DHA-KC. Minimum Education Requirement Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. OR Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience. AND Specialized Experience: For the GS-12 , you must have one year of experience at a level of difficulty and responsibility equivalent to the GS-11 in the Federal service. Experience for this position includes: participating in research and statistical analysis on available data and evaluates the effectiveness of statistical programs/applications; modifying instructions, methodologies, and/or guidelines as necessary to achieve program objectives; developing program material and documentation; developing or presenting training to internal or external audiences on data science topics; participating in the analysis of management information requirements to develop program or administrative reporting systems including the systems specifications, data gathering and analytical techniques, and systems evaluation methodology; performing queries using various types of database and analytical tools (e.g., SQL Server). Education cannot be substituted for experience at this grade level. Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer. Additional Information If hired for this position with the Census Bureau, at its headquarters office located in Suitland, Maryland, you will be expected to temporarily telework to maximum extent while the headquarters building is being renovated. Once renovations are completed for your area, you will be notified when to return to the office. At that time, you will be expected to work from your duty station, and you may be eligible to telework, up to 8 days a pay period depending on your respective work schedule, with approval from your supervisor. Additionally, the following links provide information on various hiring authorities that may enable you to apply through merit assignment procedures, or be eligible for a non-competitive appointment. VEOA 30% or more disabled Persons with Disabilities CTAP ICTAP The Department of Commerce provides reasonable accommodations to applicants with disabilities. If you need a reasonable accommodation for any part of the application and hiring process, please notify the Human Resources Office. The decision on granting reasonable accommodation will be on a case-by-case basis. TTY users can contact the Human Resources Office via the Federal Relay Service, 1-800-877-8339.",
        "url": "https://www.linkedin.com/jobs/view/3968764181",
        "summary": "The U.S. Census Bureau is seeking a Data Scientist to analyze data and develop data-driven insights to streamline processes and evaluate the effectiveness of program operations. The position requires expertise in data science, database querying (SQL Server), programming languages (Python, R, Java), and analytical tools. The candidate will also design, implement, and evaluate large, complex analytical applications, projects, and studies using machine learning methods.",
        "industries": [
            "Government",
            "Data Science",
            "Research",
            "Statistics"
        ],
        "soft_skills": [
            "Analytical",
            "Problem-Solving",
            "Communication",
            "Presentation",
            "Collaboration",
            "Teamwork",
            "Data-Driven",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "SQL Server",
            "Python",
            "R",
            "Java",
            "Machine Learning",
            "Data Analysis",
            "Data Visualization",
            "Statistical Analysis",
            "Data Engineering"
        ],
        "tech_stack": [
            "SQL Server",
            "Python",
            "R",
            "Java",
            "Machine Learning"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Java"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Telework"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Raritan, NJ",
        "job_id": 3970925081,
        "company": "Source One Technical Solutions",
        "title": "Data Scientist",
        "created_on": 1720587790.1911693,
        "description": "Source One is a consulting services company and we’re currently looking for the following individual to work as a consultant with our direct client, a global pharmaceutical company in Raritan, NJ. The role is hybrid No C2C, Sponsorship, or Third Party! Title: Scientist III Research & Development Location: Raritan, NJ (Hybrid) Contract Duration: 6 months, with likely extension w2 Hourly Rate: $60.00-$70.00 per hour Description: This role supports the manufacturing science and technology team supporting clinical/commercial manufacturing. This role is responsible for process data collection, monitoring, and analysis, change control management, deviation management, and writing of technical documents. Support provided by this individual is critical to successful manufacturing and release of batches at internal and external manufacturing sites. Education: Bachelor's degree required BS in science/engineering discipline Required Skills Minimum of 3 years industry experience. Must have experience with Data Management, Data Entry/Collecting, and Change Management/Change Control exp Must have Data Scientist exp (gathering & collecting data) Must have GMP knowledge Will be trained on internal systems Must have working knowledge of Tableau, extremely helpful Pharma exp highly preferred (maybe FDA exp) Pure Manufacturing data exp (CART)",
        "url": "https://www.linkedin.com/jobs/view/3970925081",
        "summary": "A Scientist III Research & Development role at a global pharmaceutical company in Raritan, NJ, supporting the manufacturing science and technology team. The role involves data collection, monitoring, analysis, change control, deviation management, and technical documentation. ",
        "industries": [
            "Pharmaceuticals",
            "Consulting",
            "Manufacturing",
            "Science",
            "Engineering"
        ],
        "soft_skills": [
            "Data Management",
            "Data Collection",
            "Change Management",
            "Change Control",
            "Technical Writing"
        ],
        "hard_skills": [
            "Data Management",
            "Data Entry",
            "Change Management",
            "Change Control",
            "GMP",
            "Tableau"
        ],
        "tech_stack": [
            "Tableau"
        ],
        "programming_languages": [],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 70,
            "min": 60
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Texas, United States",
        "job_id": 3960512480,
        "company": "NewSpace Technical",
        "title": "Machine Learning Engineer",
        "created_on": 1720587791.7866752,
        "description": "Machine Learning Engineer, TX USA - *US Citizens / Green Card Holders Only* Hybrid Work (3 days in the office) NewSpace Technical are on the hunt for a Machine Learning Engineer or AI specialist with at least 3 years of experience. If you've been working closely with technical teams in a fast-paced commercial environment, dealing with highly distributed systems and real-time, low latency software, we want to hear from you! Get ready to take on exciting challenges and be a part of innovative space operations...🚀🛰️ What We Need from You: A love for solving mathematical problems and doing research. Enjoyment in applying mathematical theories to solve real-world commercial problems. What You'll Be Doing: Design and deploy cutting-edge mathematical models and algorithms. Building simulation models for mission-critical space operations. Develop tools to streamline data collection and analysis. Analyze and interpret space simulation data for algorithm development. Qualifications and Skills: A Bachelor’s, Master’s, or Ph.D. in Computer Science, Mathematics, Physics, Statistics, or a similar field. Commercial experience with optimization techniques. Proficiency in Python for data science. Familiarity with ML libraries like TensorFlow, Keras, or PyTorch. Experience with Jupyter Notebook or similar tools. If you are interested and want to know more, please reach out and apply today. Email: angela.olmo@newspacetechnical.com",
        "url": "https://www.linkedin.com/jobs/view/3960512480",
        "summary": "NewSpace Technical is seeking a Machine Learning Engineer or AI specialist with 3+ years of experience in a fast-paced commercial environment. Responsibilities include designing and deploying mathematical models and algorithms, building simulation models for space operations, developing data collection and analysis tools, and interpreting simulation data for algorithm development. The ideal candidate will have a degree in Computer Science, Mathematics, Physics, Statistics, or a related field and experience with optimization techniques, Python for data science, ML libraries like TensorFlow, Keras, or PyTorch, and Jupyter Notebook.",
        "industries": [
            "Aerospace",
            "Space Technology",
            "Machine Learning",
            "Artificial Intelligence",
            "Data Science"
        ],
        "soft_skills": [
            "Problem Solving",
            "Research",
            "Analytical",
            "Communication",
            "Teamwork"
        ],
        "hard_skills": [
            "Mathematical Modeling",
            "Algorithm Design",
            "Simulation Modeling",
            "Data Analysis",
            "Optimization Techniques",
            "Python",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Jupyter Notebook"
        ],
        "tech_stack": [
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Jupyter Notebook"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Physics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Las Cruces, NM",
        "job_id": 3959542971,
        "company": "ANSER",
        "title": "Associate Data Scientist",
        "created_on": 1720587793.3812678,
        "description": "Overview ANSER enhances national and homeland security by strengthening public institutions. We provide thought leadership for complex issues through independent analysis and we deliver practical, useful solutions. ANSER values collaboration, integrity, and initiative and we are client focused in all that we do. Because we were established for the purpose of public service and not for profit, we measure our success in the impact of our service. Position Overview As a data scientist, you can turn complex data sets into useful information to solve global challenges. Responsibilities Use leadership and analytical skills to improve GEOINT data understanding. Work closely with your customer to understand their questions and needs, and then evaluate their data-rich environment to find the pieces of their information puzzle. Mentor teammates, develop algorithms, write scripts, build predictive analytics, use automation, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help senior leadership make informed decisions. Provide your customer with a deep understanding of their data, what it all means, and how they can use it. Required Skills Possess an active TS/SCI security clearance Possess active CI Polygraph 3+ years of experience with data science and BA or BS degree Experience with using scripting languages to conduct common data analysis tasks for exploration, conditioning, and advanced analytics Knowledge of visual programming or object-oriented modeling workflows to automate data acquisition Ability to manipulate data from multiple structured and unstructured data sources Ability to identify and appropriately evaluate a wide range of existing methods, models and algorithms in familiar domains for a variety of mission driven problems while recognizing the capabilities and limitations of each method. Demonstrated strong writing and oral communication skills. Ability to work independently Desired Skills Bachelor’s or Master’s degree in a field relevant to data science, data analytics, and/or data visualization. Experience with Apache Hadoop, HUE, Hive, Pig, Spark, Elasticsearch, Kibana, or Tableau Knowledge of programming languages, including Java, Python, R, or SQL Experience with using JEMA Experience with GEOINT domain including geospatial intelligence or remote sensing, GEOINT databases, including GIMS, BVI, or CRATE, and ABI and multi-INT fusion Disclaimer In compliance with the Americans with Disabilities Act Amendment Act (ADA), if you have a disability and would like to request an accommodation in order to apply for a position with ANSER, please call 703-416-2000 or e-mail Recruiting@anser.org. ANSER is proud to be an Equal Opportunity Employer. We seek individuals from a broad variety of backgrounds with varying levels of experience who have a desire to do meaningful work. We recruit, employ, train, compensate, and promote regardless of race, color, gender, gender identity, religion, national origin, ancestry, disability, age, veteran status, sexual orientation, or any other characteristic protected by law.",
        "url": "https://www.linkedin.com/jobs/view/3959542971",
        "summary": "ANSER seeks a Data Scientist with TS/SCI clearance and CI Polygraph to analyze complex data sets, develop algorithms, build predictive analytics, and provide insights to senior leadership. The role involves working with GEOINT data, understanding customer needs, and using various tools and frameworks to turn data into actionable answers.",
        "industries": [
            "National Security",
            "Homeland Security",
            "Intelligence",
            "Defense",
            "Government",
            "Consulting"
        ],
        "soft_skills": [
            "Leadership",
            "Analytical Skills",
            "Communication Skills",
            "Problem Solving",
            "Teamwork",
            "Mentorship",
            "Independent Work"
        ],
        "hard_skills": [
            "Data Science",
            "Data Analysis",
            "Scripting",
            "Data Visualization",
            "Algorithm Development",
            "Predictive Analytics",
            "Automation",
            "Data Acquisition",
            "Data Manipulation",
            "Structured and Unstructured Data",
            "GEOINT",
            "Geospatial Intelligence",
            "Remote Sensing",
            "Data Fusion",
            "Writing",
            "Oral Communication"
        ],
        "tech_stack": [
            "Apache Hadoop",
            "HUE",
            "Hive",
            "Pig",
            "Spark",
            "Elasticsearch",
            "Kibana",
            "Tableau",
            "Java",
            "Python",
            "R",
            "SQL",
            "JEMA",
            "GIMS",
            "BVI",
            "CRATE",
            "ABI"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "R",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Data Science",
                "Data Analytics",
                "Data Visualization"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Charlotte, NC",
        "job_id": 3961908143,
        "company": "Vaco",
        "title": "Data Scientist- Python/SQL",
        "created_on": 1720587795.2062902,
        "description": "Job Summary: We are currently looking for Data Scientist candidates that will play a critical role in the monitoring, maintenance and creation of both pre-existing and new statistical and predictive models related to the used vehicle wholesale (auction), appraisal, and retail business. This individual will also play a role in leveraging microservices/APIs, writing and improving software code, and being jack-of-all-trades creative problem solver. This role, based in Charlotte, NC will be instrumental in the development of company analytical models and critical to the growth of EchoPark, the companys exclusively pre-owned dealership concept. Responsibilities:? Perform high quality, sophisticated analysis in support of internal projects related to pricing, inventory sourcing, inventory management, and logistics (which vehicles should we ship to which stores). Develop new predictive models to enhance revenue and business understanding. This includes the design, implementation and interpretation of complex statistical analyses. Present analysis, models, and insights to internal stakeholders and end users. Monitor health of?existing models and recommend?enhancements to meet?business needs. Work collectively with analytics product managers, data engineers, software developers, and analytics engineers (i.e. DevOps) to glean insights and needs from the business, brainstorm best solutions, create front end visualizations for internal users, build/leverage data pipelines, build and test statistical models, productionalize code/models/APIs, and monitor performance. Qualifications: Expertise in two or more of the following areas: mathematical programming, statistics, forecasting, machine learning combinatorial optimization.? Excellent business acumen and creative problem solver Ability to structure and analyze large data sets. Expert programmer in Python & SQL with knowledge of data science packages, experience with Dash a plus.? Proficient in Microsoft Office Products. Experience with cloud platforms (preferably Azure but AWS acceptable as well) High level of comfort in a *NIX environment. Excellent written, verbal, and presentation-based communication skills. Experience with MicroStrategy and/or other reporting platforms a plus. Experience with some type of source code management (ex: Git) 3 - 5 years minimum of relevant work experience. Master's or PhD or in Economics, Social Science, Operations Research or other applied quantitative discipline. Desired Skills and Experience Job Summary: We are currently looking for Data Scientist candidates that will play a critical role in the monitoring, maintenance and creation of both pre-existing and new statistical and predictive models related to the used vehicle wholesale (auction), appraisal, and retail business. This individual will also play a role in leveraging microservices/APIs, writing and improving software code, and being jack-of-all-trades creative problem solver. This role, based in Charlotte, NC will be instrumental in the development of company analytical models and critical to the growth of EchoPark, the companys exclusively pre-owned dealership concept. Responsibilities:? Perform high quality, sophisticated analysis in support of internal projects related to pricing, inventory sourcing, inventory management, and logistics (which vehicles should we ship to which stores). Develop new predictive models to enhance revenue and business understanding. This includes the design, implementation and interpretation of complex statistical analyses. Present analysis, models, and insights to internal stakeholders and end users. Monitor health of?existing models and recommend?enhancements to meet?business needs. Work collectively with analytics product managers, data engineers, software developers, and analytics engineers (i.e. DevOps) to glean insights and needs from the business, brainstorm best solutions, create front end  visualizations for internal users, build/leverage data pipelines, build and test statistical models, productionalize code/models/APIs, and monitor performance. Qualifications: Expertise in two or more of the following areas: mathematical programming, statistics, forecasting, machine learning combinatorial optimization.? Excellent business acumen and creative problem solver Ability to structure and analyze large data sets. Expert programmer in Python & SQL with knowledge of data science packages, experience with Dash a plus.? Proficient in Microsoft Office Products. Experience with cloud platforms (preferably Azure but AWS acceptable as well) High level of comfort in a *NIX environment. Excellent written, verbal, and presentation-based communication skills. Experience with MicroStrategy and/or other reporting platforms a plus. Experience with some type of source code management (ex: Git) 3 - 5 years minimum of relevant work experience. Master's or PhD or in Economics, Social Science, Operations Research or other applied quantitative discipline.",
        "url": "https://www.linkedin.com/jobs/view/3961908143",
        "summary": "Data Scientist to develop and maintain statistical and predictive models for used vehicle wholesale (auction), appraisal, and retail business. This role involves leveraging microservices/APIs, writing code, and solving problems creatively. ",
        "industries": [
            "Automotive",
            "Retail",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Presentation",
            "Business Acumen"
        ],
        "hard_skills": [
            "Mathematical Programming",
            "Statistics",
            "Forecasting",
            "Machine Learning",
            "Combinatorial Optimization",
            "Python",
            "SQL",
            "Data Science Packages",
            "Dash",
            "Microsoft Office",
            "Azure",
            "AWS",
            "Linux",
            "Git",
            "MicroStrategy"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Dash",
            "Azure",
            "AWS",
            "Git",
            "MicroStrategy"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Economics",
                "Social Science",
                "Operations Research",
                "Applied Quantitative Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3970214100,
        "company": "Cloudflare",
        "title": "Machine Learning Engineer - Threat Intelligence",
        "created_on": 1720587796.7893858,
        "description": "About Us At Cloudflare, we are on a mission to help build a better Internet. Today the company runs one of the world’s largest networks that powers millions of websites and other Internet properties for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine’s Top Company Cultures list and ranked among the World’s Most Innovative Companies by Fast Company. We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us! About The Team The Threat Intelligence team is responsible for helping teams build security intelligence into our security suite of products. The team fuses threat intelligence from a swath of external sources with intelligence mined from Cloudflare's world class data to provide threat intelligence used across a number of Cloudflare products. The team's core disciplines are data engineering, data science, devops, and security. We use data science and machine learning to process large volumes of data and build intelligence into Cloudflare's products. What You'll Do We are seeking a Machine Learning Engineer to join our team. The successful candidate will work on designing, developing, and implementing Machine Learning algorithms and models to deploy scalable Machine Learning models. This is a hands-on position where the candidate will have the opportunity to work in our security portfolio that includes our Email Security products. This role will initially primarily support Cloudflare Email Security in improving and creating new innovative models to better detect spam, phishing, or other malicious emails. The candidate should have strong foundational machine learning knowledge. Day to day responsibilities include: Collaborate with our Data Scientists to integrate and deploy scalable Machine Learning models Collaborate with analysts to understand new email attack techniques then design and deploy models to detect these techniques Implement Machine Learning models in production systems and monitor their performance in real-time. Continuously improve the performance and scalability of existing Machine Learning models. Identify, diagnose and resolve issues in production environments Contribute to our MLOps Platform to ensure the platform's evolution Examples Of Desirable Skills, Knowledge And Experience Thorough understanding of machine learning concepts such as what types of models perform best again what types of data Desire to see a project through all the way from model creation, training, productionalized deployment, through automated retraining from feedback Demonstrated ability to deliver and listen to feedback. Proven ability to deliver performance (what) with the right behaviors (how) Bonus Points These are things which the role is likely to require; we’re happy to help you learn on the job, but prior experience is beneficial Experience with deploying Deep Learning models in production systems Experience with development and deployment of Natural Language Processing (NLP) applications Wide machine learning knowledge from linear regression through LLMs Compensation Compensation may be adjusted depending on work location. There are multiple levels open on the team, both mid & senior level. For Bay Area-based hires: Estimated annual salary of $140,000 - $172,000 For New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $133,000 - $163,000 For Colorado-based hires: Estimated annual salary of $115,000 - $160,000 Available Locations: Remote US Equity This role is eligible to participate in Cloudflare’s equity plan. Benefits Cloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S. Health & Welfare Benefits Medical/Rx Insurance Dental Insurance Vision Insurance Flexible Spending Accounts Commuter Spending Accounts Fertility & Family Forming Benefits On-demand mental health support and Employee Assistance Program Global Travel Medical Insurance Financial Benefits Short and Long Term Disability Insurance Life & Accident Insurance 401(k) Retirement Savings Plan Employee Stock Participation Plan Time Off Flexible paid time off covering vacation and sick leave Leave programs, including parental, pregnancy health, medical, and bereavement leave What Makes Cloudflare Special? We’re not just a highly ambitious, large-scale technology company. We’re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet. Project Galileo : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare’s enterprise customers--at no cost. Athenian Project : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration. Path Forward Partnership : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one. 1.1.1.1 : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here’s the deal - we don’t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers. Sound like something you’d like to be a part of? We’d love to hear from you! This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license. Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer. Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.",
        "url": "https://www.linkedin.com/jobs/view/3970214100",
        "summary": "Cloudflare is seeking a Machine Learning Engineer to join their Threat Intelligence team. The role involves designing, developing, and deploying Machine Learning models for Cloudflare's Email Security products to improve spam and phishing detection. The ideal candidate will have strong foundational machine learning knowledge, experience with deploying Deep Learning and NLP models, and a desire to contribute to the MLOps platform.",
        "industries": [
            "Cybersecurity",
            "Information Technology",
            "Software Development",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Attention to Detail",
            "Feedback Delivery",
            "Teamwork",
            "Adaptability"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing (NLP)",
            "Model Deployment",
            "Data Science",
            "Production Systems",
            "MLOps",
            "Scalability",
            "Performance Optimization",
            "Real-Time Monitoring",
            "Issue Resolution"
        ],
        "tech_stack": [
            "Cloudflare Email Security",
            "Machine Learning Models",
            "Deep Learning Models",
            "Natural Language Processing (NLP) Applications",
            "MLOps Platform"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 172000,
            "min": 115000
        },
        "benefits": [
            "Medical/Rx Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Flexible Spending Accounts",
            "Commuter Spending Accounts",
            "Fertility & Family Forming Benefits",
            "On-demand mental health support",
            "Employee Assistance Program",
            "Global Travel Medical Insurance",
            "Short and Long Term Disability Insurance",
            "Life & Accident Insurance",
            "401(k) Retirement Savings Plan",
            "Employee Stock Participation Plan",
            "Flexible paid time off",
            "Parental leave",
            "Pregnancy health leave",
            "Medical leave",
            "Bereavement leave"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3963959459,
        "company": "ClifyX",
        "title": "Data Scientist",
        "created_on": 1720587802.4428964,
        "description": "Data Scientist- -Walnut Creek (Recruiter for Client Flex - Aisha simpson) Job Description: Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our products Partner with teams to solve problems and identify trends and opportunities Inform, influence, support, and execute our product decisions and product launches Forecasting and goaling, designing and evaluating experiments, building and analyzing dashboards and reports, and evaluating and defining metrics Conduct exploratory analysis including proposing roadmap items, user behaviors, and long-term trends, identifying new levers to help move key metric, and building models of user behaviors for analysis Manage product leadership: influencing product teams through presentation of data-based recommendations, communicating state of business, experiment results Complete Data Infrastructure activities including Hadoop and Hive, MySQL, Oracle, and Vertica, and automating analyses and authoring pipelines via SQL Possess knowledge of statistics including hypothesis testing and regression Basic Qualifications: Minimum 2 years' experience in Python Minimum 2 years' experience in SQL Minimum 2 years' experience in Hadoop High School Diploma/GED",
        "url": "https://www.linkedin.com/jobs/view/3963959459",
        "summary": "Data Scientist to analyze user interactions, identify trends, inform product decisions, conduct exploratory analysis, and manage product leadership through data-driven recommendations. Requires expertise in quantitative analysis, data mining, and data presentation.",
        "industries": [
            "Technology",
            "Software",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Presentation Skills",
            "Influence",
            "Data Storytelling",
            "Analytical Thinking",
            "Critical Thinking",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "Quantitative Analysis",
            "Data Mining",
            "Data Presentation",
            "Trend Analysis",
            "Forecasting",
            "Experiment Design",
            "Dashboard Building",
            "Report Creation",
            "Metric Definition",
            "Exploratory Analysis",
            "User Behavior Analysis",
            "Modeling",
            "Hadoop",
            "Hive",
            "MySQL",
            "Oracle",
            "Vertica",
            "SQL",
            "Automation",
            "Pipelines",
            "Statistics",
            "Hypothesis Testing",
            "Regression"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Hadoop",
            "Hive",
            "MySQL",
            "Oracle",
            "Vertica"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "High School Diploma/GED",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Bellevue, WA",
        "job_id": 3969281585,
        "company": "Syren Cloud Inc",
        "title": "Data Scientist (W2/FTE only)",
        "created_on": 1720587803.9092731,
        "description": "eBay Data Scientist Bellevue, WA (Hybrid) Team Overview The Shipping Science team develops the underlying models that drive delivery estimates and packaging optimizations for eBay globally. Join a full-stack team that takes ownership not only of developing robust models, but owning the pipeline and managing the technology stack that allows eBay to scale our inference engine at web-scale. We collaborate with other researchers, engineers, and product teams to develop improvements to our shipping platforms that drive efficiency and a better user experience for buyers and sellers. While our close work with product and engineering drives our results-oriented culture, learning and experimentation are keys to ensuring we develop the best solutions possible. Job Responsibilities Seek scientifically valid solutions that deliver real value to eBay customers Build machine learning models and data pipelines to deliver insightful yet practical solutions across web-scale data. Work with multiple teams to help promote standard scientific methodologies and processes in your field Present key technical and novel research work in public forums and conferences Basic Qualifications 5 years of industrial experience with one or more of the following: classification, regression, NLP, GBM, unsupervised learning, transit time estimation, Deep-Learning, GNN. Experience in big data processing, e.g., Hadoop, SQL, Spark/PySpark Experience with Python, Java, or Scala, and PyTorch. Demonstrated experience developing and deploying large scale ML models.",
        "url": "https://www.linkedin.com/jobs/view/3969281585",
        "summary": "eBay is seeking a Data Scientist to join their Shipping Science team in Bellevue, WA. The team develops models for delivery estimates and packaging optimization. The role involves building machine learning models and data pipelines, collaborating with other teams, presenting research, and promoting scientific methodologies.  The ideal candidate has 5+ years of experience with classification, regression, NLP, GBM, unsupervised learning, transit time estimation, Deep Learning, GNN, experience with big data processing tools like Hadoop, SQL, Spark/PySpark, and proficiency in Python, Java, or Scala, and PyTorch. ",
        "industries": [
            "E-commerce",
            "Retail",
            "Logistics",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Presentation",
            "Problem-solving",
            "Analytical thinking",
            "Scientific methodology"
        ],
        "hard_skills": [
            "Classification",
            "Regression",
            "NLP",
            "GBM",
            "Unsupervised learning",
            "Transit time estimation",
            "Deep Learning",
            "GNN",
            "Hadoop",
            "SQL",
            "Spark",
            "PySpark",
            "Python",
            "Java",
            "Scala",
            "PyTorch"
        ],
        "tech_stack": [
            "Hadoop",
            "SQL",
            "Spark",
            "PySpark",
            "Python",
            "Java",
            "Scala",
            "PyTorch"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New Orleans, LA",
        "job_id": 3970390677,
        "company": "Ochsner Health",
        "title": "Data Scientist",
        "created_on": 1720587807.890638,
        "description": "We've made a lot of progress since opening the doors in 1942, but one thing has never changed - our commitment to serve, heal, lead, educate, and innovate. We believe that every award earned, every record broken and every patient helped is because of the dedicated employees who fill our hallways. At Ochsner, whether you work with patients every day or support those who do, you are making a difference and that matters. Come make a difference at Ochsner Health and discover your future today! This job uses advanced and predictive data analytics using machine learning and artificial intelligence technology for healthcare innovation and outcomes. Performs analysis using data science techniques on structured and unstructured data sets and develops algorithms for targeted business needs. Pilots the delivery of patient-centered and personalized advanced analytics solutions that improve contract performance, program effectiveness, and clinical, financial, and utilization outcomes across the continuum of care. Implements advanced scientific techniques, forecasting, and machine learning to predict financial and clinical outcomes in order to guide investments that improve health outcomes and reduce costs. To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform the essential duties. This job description is a summary of the primary duties and responsibilities of the job and position. It is not intended to be a comprehensive or all-inclusive listing of duties and responsibilities. Contents are subject to change at the company’s discretion. Education Required: Bachelor’s degree in data science, computer science, mathematics, statistics, or economics. Preferred: Master’s degree in data science, computer science, mathematics, statistics, or economics. Work Experience Required: 2 years of experience in data science or analytics in healthcare. Preferred: 3 years of experience in data science or analytics in healthcare. Knowledge Skills And Abilities (KSAs) Effective verbal and written communication skills and ability to present information clearly and professionally. Strong interpersonal skills. Strong analytic, problem solving, story-telling and troubleshooting skills. Proficient with computer languages, such as R/Python, SQL, and SAS. Ability to communicate and present technical concepts, including creating dashboards to aid in explaining analysis to a non-technical audience. Knowledge of data visualization, charts, dashboards, and reporting tools. Ability to pay exceptional attention to detail. Ability to support key business initiatives through positive relationships, effective communication, and cross-team collaboration. Job Duties Leads the design and deployment of computational algorithms, statistical methods, and predictive models. Uses machine learning techniques and statistical test, including Pearson correlation, Ttests and Anova statistical tests, for hypothesis testing to assess outcomes of interventions and clinical program. Uses supervised and unsupervised machine learning techniques such as regression, random forest, xgboost, clustering or causal inference techniques, such as hierarchical modeling and propensity score matching, to deliver analytics solutions and researches new methods to evaluate, improve and implement machine learning models to be used in clinical, operational, and corporate areas. Follows best practices for data science and software development (version control, testing, containerization) to create deployable models and repeatable analyses. Heads the creation and dissemination of data mining approaches that facilitate rapid, streamlined detection of outliers, novel patterns of association, and latent, causal connections in high-dimensional data sets. Serve as quantitative subject matter expert (SME) and mentor to colleagues and teammates, providing guidance related to project/program design, statistical methodology, model input/output selection, and interpretation of results. Works directly and maintains a relationship with aligned business partners in requirements definition, project scoping, timeline management, and documentation. Fosters relationships with internal and external stakeholders through regular engagement, communication, and consistent delivery of analytic work products. Authors technical reports, statistical analysis plans (SAP), white papers, enterprise presentations, and peer-reviewed abstracts, posters, and journal articles. Collaborates with data management team to identify required data assets and, in turn, to automate their sourcing, integration, and analysis. Performs other related duties as assigned. The above statements describe the general nature and level of work only. They are not an exhaustive list of all required responsibilities, duties, and skills. Other duties may be added, or this description amended at any time. Remains knowledgeable on current federal, state and local laws, accreditation standards or regulatory agency requirements that apply to the assigned area of responsibility and ensures compliance with all such laws, regulations and standards. This employer maintains and complies with its Compliance & Privacy Program and Standards of Conduct, including the immediate reporting of any known or suspected unethical or questionable behaviors or conduct; patient/employee safety, patient privacy, and/or other compliance-related concerns. The employer is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status. Physical and Environmental Demands The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Sedentary Work - Exerting up to 10 pounds of force occasionally (Occasionally: activity or condition exists up to 1/3 of the time) and/or a negligible amount of force frequently (Frequently: activity or condition exists from 1/3 to 2/3 of the time) to lift, carry, push, pull, or otherwise move objects. Sedentary work involves sitting most of the time but may involve walking or standing for brief periods of time. Jobs are sedentary if walking and standing are required only occasionally and all other sedentary criteria are met. Normal routine involves no exposure to blood, body fluid or tissue and as part of their employment, incumbents are not called upon to perform or assist in emergency care or first aid. The incumbent has no occupational risk for exposure to communicable diseases. Because the incumbent works within a healthcare setting, there may be occupational risk for exposure to hazardous medications or hazardous waste within the environment through receipt, transport, storage, preparation, dispensing, administration, cleaning and/or disposal of contaminated waste. The risk level of exposure may increase depending on the essential job duties of the role. Are you ready to make a difference? Apply Today! Ochsner Health does not consider an individual an applicant until they have formally applied to the open position on this careers website. Individuals who reside in and will work from the following areas are not eligible for remote work position: Colorado, California, Hawaii, Maryland, New York, Washington, and Washington D.C. Ochsner Health endeavors to make our site accessible to all users. If you would like to contact us regarding the accessibility of our website, or if you need an accommodation to complete the application process, please contact our HR Employee Solution Center at 504-842-4748 (select option 1) or careers@ochsner.org . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We are committed to the principles of equal employment opportunity and providing a workplace that is free from discrimination based on race, color, creed, religion, pregnancy status, pregnancy-related conditions, national origin, ancestry, mental or physical disability, medical condition, age, veteran status, military status, citizenship status, marital status, familial status, sexual orientation, gender, gender identity or expression, genetic information, political affiliation, unemployment status, or any other characteristic protected under applicable federal, state or local law. These protections extend to applicants and all employment related decisions. View the EEO is the Law poster and its supplement , as well as the pay transparency policy for more information. Affirmative Action Policy Statement",
        "url": "https://www.linkedin.com/jobs/view/3970390677",
        "summary": "This role focuses on advanced data analytics in healthcare, using machine learning and AI to improve outcomes. The analyst will perform data science techniques on structured and unstructured data, develop algorithms for specific business needs, and deliver personalized analytics solutions to enhance contract performance, program effectiveness, and clinical, financial, and utilization outcomes. The position also involves using predictive modeling to guide investments that improve health outcomes and reduce costs.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Analytics",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Interpersonal skills",
            "Analytical",
            "Problem Solving",
            "Storytelling",
            "Troubleshooting",
            "Detail oriented",
            "Collaboration",
            "Relationship building"
        ],
        "hard_skills": [
            "R",
            "Python",
            "SQL",
            "SAS",
            "Data Visualization",
            "Dashboards",
            "Reporting",
            "Machine Learning",
            "Regression",
            "Random Forest",
            "XGBoost",
            "Clustering",
            "Causal Inference",
            "Hierarchical Modeling",
            "Propensity Score Matching",
            "Statistical Testing",
            "Pearson Correlation",
            "T-Tests",
            "Anova",
            "Data Mining",
            "Version Control",
            "Testing",
            "Containerization"
        ],
        "tech_stack": [
            "Machine Learning",
            "AI",
            "R",
            "Python",
            "SQL",
            "SAS",
            "Data Visualization",
            "Dashboards",
            "Reporting",
            "Regression",
            "Random Forest",
            "XGBoost",
            "Clustering",
            "Causal Inference",
            "Hierarchical Modeling",
            "Propensity Score Matching",
            "Statistical Testing",
            "Pearson Correlation",
            "T-Tests",
            "Anova",
            "Data Mining",
            "Version Control",
            "Testing",
            "Containerization"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL",
            "SAS"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Mathematics",
                "Statistics",
                "Economics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Portland, OR",
        "job_id": 3970708948,
        "company": "Team Remotely Inc",
        "title": "Data Scientist Engineer",
        "created_on": 1720587809.5172596,
        "description": "This is a remote position. Data Scientist Engineer (1 year experience, remote) Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $58K-$68K Per Annum. Skills and Abilities: Strong knowledge of R or Python for data analysis and modeling. Proficiency in statistical programs such as R, SAS, MATLAB, or Python. Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology). Basic understanding of SQL, Javascript, XML, JSON, and HTML. Ability to learn new methods quickly and work under deadlines. Excellent teamwork and communication skills. Strong analytical and problem-solving abilities. Basic understanding of SQL, Javascript, XML, JSON, and HTML. Preferred: Knowledge of actuarial concepts and life, health, and/or annuity products. Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc. Familiarity with Microsoft DeployR. Exposure to insurance risk analysis. Basic experience in computational finance, econometrics, statistics, and math. Knowledge of SQL and VBA. Familiarity with R or Python for predictive modeling",
        "url": "https://www.linkedin.com/jobs/view/3970708948",
        "summary": "This is a remote, full-time data scientist position with a salary range of $58,000 to $68,000 per year. The role requires 1 year of experience and is open to US/Canada residents only. The position is part of a talent pool for potential future openings.",
        "industries": [
            "Insurance",
            "Actuarial Science",
            "Finance",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Teamwork",
            "Communication",
            "Analytical",
            "Problem-Solving",
            "Learning"
        ],
        "hard_skills": [
            "R",
            "Python",
            "SAS",
            "MATLAB",
            "VBA",
            "Access",
            "Oracle",
            "SQL",
            "Javascript",
            "XML",
            "JSON",
            "HTML",
            "GLM",
            "Decision Trees",
            "Time Series",
            "Regression",
            "Microsoft DeployR",
            "Risk Analysis",
            "Computational Finance",
            "Econometrics",
            "Statistics",
            "Math"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SAS",
            "MATLAB",
            "VBA",
            "Access",
            "Oracle",
            "SQL",
            "Javascript",
            "XML",
            "JSON",
            "HTML",
            "Microsoft DeployR"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SAS",
            "MATLAB",
            "SQL",
            "Javascript"
        ],
        "experience": 1,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 68000,
            "min": 58000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Bellevue, WA",
        "job_id": 3959429177,
        "company": "T-Mobile",
        "title": "Data Scientists – Finance",
        "created_on": 1720587811.594844,
        "description": "Career Band: L08 Be unstoppable with us! T-Mobile is synonymous with innovation–and you could be part of the team that disrupted an entire industry! We reinvented customer service, brought real 5G to the nation, and now we’re shaping the future of technology in wireless and beyond. Our work is as exciting as it is rewarding, so consider the career opportunity below as your invitation to grow with us, make big things happen with us, above all, #BEYOU with us. Together, we won’t stop! Position summary T-Mobile is America’s supercharged Un-carrier, delivering an advanced 4G LTE and transformative nationwide 5G network that will offer reliable connectivity for all. Data Scientists – Finance located in Bellevue, WA will prepare monthly and quarterly updates for existing models related to jump deferrals, Apple Forever Valuations, and Fair Market Value of Devices, and support the Modeling and Valuation team in adhoc data analytics. Position duties and responsibilities include, but are not limited to: Operate the model, coordinate with stake holders, and run a process to estimate the liability associated with the Jump Program. Update the Jump liability program to increase efficiency for various stakeholders. Provide adhoc analytics on various valuations. Perform data analytics and statistical analysis to support forecast of device values. Provide data analytics and statistical analysis to support the estimate of the Apple Forever Liability. Work with various stakeholders to prepare a model to forecast credit losses on T-Mobile service contracts. Understand key data architecture and changes to the company to provide insights to various stakeholders with respect to data and valuation estimates. Telecommuting is permitted, but applicants must live within a reasonable commuting distance. Minimal amount of travel for training or conferences may be required periodically. Skill requirements: Applying statistical and mathematical methodologies including Linear Regression, Logistic Regression, Decision Tree, Cluster Analysis, and Hypothesis Testing to perform segmentation, prediction, forecast, and exploratory analysis. Utilizing SAS, R, Python, or other statistical/analytical model building/programming languages to perform statistical analysis. Writing SQL code to extract, combine, and manipulate large amounts of data from multiple data sources to create analytical data samples. Estimating value of various assets in financial models using key information extracted from data. Translating and communicating complex mathematical results to a broad audience. Experience and education requirements: PRIMARY REQUIREMENTS: Master’s degree in Measurement and Statistics, Applied Statistics, Financial Engineering, or related field, and 1 year of relevant work experience. ALTERNATIVE REQUIREMENTS: Bachelor’s degree in Measurement and Statistics, Applied Statistics, Financial Engineering, or related field, and 3 years of relevant work experience. Additional: Location: Bellevue, WA This position is eligible for the employee referral program. How to apply: Visit www.tmobile.jobs. Create a candidate profile, and apply to REQ276604. OTHER: Work hours: 40 hours/week. Washington Pay Range: $120,250.63 - $151,800.00/year. The pay range above is the general base pay range for a successful candidate in the state listed. The successful candidate’s actual pay will be based on various factors, such as work location, qualifications, and experience. At T-Mobile, employees in regular, non-temporary roles are eligible for an annual bonus or periodic sales incentive or bonus, based on their role. Most Corporate employees are eligible for a year-end bonus based on company and/or individual performance and which is set at a percentage of the employee’s eligible earnings in the prior year. Certain positions in Customer Care are eligible for monthly bonuses based on individual and/or team performance, while Retail and Business Sales roles are eligible for monthly or quarterly sales incentives. And since we are ALL owners, EVERY employee at T-Mobile is eligible for an Annual Stock Grant. For information about T-Mobile’s amazing benefits, check out https://careers.t-mobile.com/culture-and-benefits/. At least 18 years of age Legally authorized to work in the United States Travel : Travel Required (Yes/No):No DOT Regulated : DOT Regulated Position (Yes/No):No Safety Sensitive Position (Yes/No):No At T-Mobile, our benefits exemplify the spirit of One Team, Together! A big part of how we care for one another is working to ensure our benefits evolve to meet the needs of our team members. Full and part-time employees have access to the same benefits when eligible. We cover all of the bases, offering medical, dental and vision insurance, a flexible spending account, 401(k), employee stock grants, employee stock purchase plan, paid time off and up to paid 12 holidays - which total about 4 weeks for new full-time employees and about 2.5 weeks for new part-time employees annually - paid parental and family leave, family building benefits, back-up care, enhanced family support, childcare subsidy, tuition assistance, college coaching, short and long term disability, voluntary AD&D coverage, voluntary accident coverage, voluntary life insurance, voluntary disability insurance, and voluntary long-term care insurance. We don't stop there- eligible employees can receive mobile service & home internet discounts, pet insurance, and access to commuter and transit programs! To learn about T-Mobile’s amazing benefits, check out www.t-mobilebenefits.com. Never stop growing! As part of the T-Mobile team, you know the Un-carrier doesn’t have a corporate ladder–it’s more like a jungle gym of possibilities! We love helping our employees grow in their careers, because it’s that shared drive to aim high that drives our business and our culture forward. By applying for this career opportunity, you’re living our values while investing in your career growth–and we applaud it. You’re unstoppable! T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated. Talent comes in all forms at the Un-carrier. If you are an individual with a disability and need reasonable accommodation at any point in the application or interview process, please let us know by emailing ApplicantAccommodation@t-mobile.com or calling 1-844-873-9500. Please note, this contact channel is not a means to apply for or inquire about a position and we are unable to respond to non-accommodation related requests.",
        "url": "https://www.linkedin.com/jobs/view/3959429177",
        "summary": "T-Mobile is seeking a Data Scientist - Finance to develop and maintain models for the Jump Program, Apple Forever Valuations, and Fair Market Value of Devices. The role involves data analysis, statistical modeling, and communication of results to stakeholders.",
        "industries": [
            "Telecommunications",
            "Wireless",
            "Technology",
            "Finance"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Analytical Thinking",
            "Problem Solving",
            "Data Visualization",
            "Presentation Skills"
        ],
        "hard_skills": [
            "Linear Regression",
            "Logistic Regression",
            "Decision Tree",
            "Cluster Analysis",
            "Hypothesis Testing",
            "SAS",
            "R",
            "Python",
            "SQL",
            "Financial Modeling"
        ],
        "tech_stack": [
            "SAS",
            "R",
            "Python",
            "SQL"
        ],
        "programming_languages": [
            "SAS",
            "R",
            "Python",
            "SQL"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Measurement and Statistics",
                "Applied Statistics",
                "Financial Engineering"
            ]
        },
        "salary": {
            "max": 151800,
            "min": 120250
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Flexible Spending Account",
            "401(k)",
            "Employee Stock Grants",
            "Employee Stock Purchase Plan",
            "Paid Time Off",
            "Paid Holidays",
            "Paid Parental Leave",
            "Family Building Benefits",
            "Back-Up Care",
            "Enhanced Family Support",
            "Childcare Subsidy",
            "Tuition Assistance",
            "College Coaching",
            "Short and Long Term Disability",
            "Voluntary AD&D Coverage",
            "Voluntary Accident Coverage",
            "Voluntary Life Insurance",
            "Voluntary Disability Insurance",
            "Voluntary Long-Term Care Insurance",
            "Mobile Service Discount",
            "Home Internet Discount",
            "Pet Insurance",
            "Commuter and Transit Programs"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3962398371,
        "company": "Apexon",
        "title": "Senior Data Scientist (Remote)",
        "created_on": 1720587812.8372812,
        "description": "Senior Data Scientist (Remote) We are looking for Senior Data Scientist with more than 15+ years of experience with excellent client-facing and communication skills. You'll work directly with SVPs from sales and marketing, manage a team of data scientists, and must be willing to work in PST hours. Key Responsibilities: Perform exploratory data analysis to derive membership growth insights from experimental and observational data (both cross-sectional and longitudinal). Leverage your expertise in machine learning, causal inference, complex systems modeling, and behavioral decision theory to attract new members. Engage with sales, marketing, underwriting, and actuarial teams to understand their business challenges and design scalable solutions. Collaborate closely with consultants, data analysts, data scientists, data engineers, and full-stack developers to implement models and new algorithms into customer-facing applications. Support experimental design to validate findings or test hypotheses, ensure compliance with regulatory and security policies, and monitor the performance of decision systems and statistical models. Qualifications: 5-10 years of programming experience. At least 5 years of experience in statistical analysis and modeling. Bachelor's degree in Mathematics, Statistics, Engineering, Social/Physical/Life Science, Business, or related field OR 2 years of experience in data analytics or a directly related field. Preferred Qualifications: 5 years of experience with SQL. 7 years of experience in machine learning.5 years of experience with artificial intelligence tools.5 years of experience in statistical modeling. 4 years of experience in data simulation.4 years of experience with data visualization tools.4 years of experience with Open Source Tools (e.g., R, Python). 4 years of experience with Tableau. 4 years of experience with business intelligence tools.4 years of experience with Excel.1 year of experience with SPSS. 4 years of experience with statistical analysis software. 4 years of experience with Access.",
        "url": "https://www.linkedin.com/jobs/view/3962398371",
        "summary": "Senior Data Scientist role focused on membership growth, requiring 15+ years of experience, strong client-facing skills, and management experience. Responsibilities include data analysis, machine learning, model development, collaboration with various teams, experimental design, and model performance monitoring.",
        "industries": [
            "Data Science",
            "Analytics",
            "Technology",
            "Financial Services",
            "Insurance"
        ],
        "soft_skills": [
            "Communication",
            "Client-Facing",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Team Management"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "Causal Inference",
            "Complex Systems Modeling",
            "Behavioral Decision Theory",
            "Statistical Modeling",
            "SQL",
            "Artificial Intelligence",
            "Data Simulation",
            "Data Visualization",
            "R",
            "Python",
            "Tableau",
            "Business Intelligence",
            "Excel",
            "SPSS",
            "Statistical Analysis Software",
            "Access"
        ],
        "tech_stack": [
            "SQL",
            "R",
            "Python",
            "Tableau",
            "Business Intelligence Tools",
            "Excel",
            "SPSS",
            "Statistical Analysis Software",
            "Access"
        ],
        "programming_languages": [
            "R",
            "Python"
        ],
        "experience": 15,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Mathematics",
                "Statistics",
                "Engineering",
                "Social/Physical/Life Science",
                "Business",
                "Data Analytics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Williamsport, MD",
        "job_id": 3965736645,
        "company": "Analytic Recruiting Inc.",
        "title": "Research Data Scientist",
        "created_on": 1720587815.8478239,
        "description": "A large manufacturing company is seeking a Senior Research Data Scientist to develop their analytics strategy: encompassing the acquisition, processing of service data and application to preventive maintenance and control of their vehicles. This person will be responsible for end-to-end model deployment and require an expertise in math, statistics and building ML models. Location: Williamsport, MD Salary: Up to 160k base + bonus Visa sponsorship is NOT AVAILABLE Responsibilities: Collaborate with business experts and external partners to acquire business understanding needed to conduct analysis Automate collection processes and identify valuable data sources Carry out preprocessing of structured and unstructured data. Discover trends and patterns by analyzing large amounts of information Build ML algorithms and predictive models Present information using data visualization techniques Introduce solutions and strategies for business value generation Collaborate with operations, sales, engineering, supply chain, finance, product development, etc Requirements: PhD in Economics, Mathematics, Computer Science, Statistics, Information Management, Engineering or related 5+ years’ experience as a data scientist Modeling, database design and management for structured and unstructured data (SQL Server, Netezza, IBM DB2, HDFS, Spark) Experience with computer vision or classification models Excellent communication and presentation skills to sell use cases and research results. Strong math skills (e.g. statistics, algebra) and experience using statistical packages for analyzing datasets (SPSS, SAS, etc.). Knowledge of and experience with data mining, segmentation, ML and optimization techniques (SPSS, R, CPLEX, etc.). Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy Experience with data visualization and reporting packages (Cognos, PowerBI, etc.), databases (SQL, etc.), programming (Python, Scala, etc.) Ability to effectively present information and respond to questions from leaders and peers.",
        "url": "https://www.linkedin.com/jobs/view/3965736645",
        "summary": "A large manufacturing company seeks a Senior Research Data Scientist to develop their analytics strategy focused on vehicle service data acquisition, processing, and applying it to predictive maintenance and control. The role involves end-to-end model deployment, requiring expertise in math, statistics, and machine learning.",
        "industries": [
            "Manufacturing",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Collaboration",
            "Analytical",
            "Problem Solving",
            "Business Understanding",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Machine Learning",
            "Model Building",
            "Data Acquisition",
            "Data Processing",
            "Data Analysis",
            "Data Visualization",
            "Data Mining",
            "Segmentation",
            "Optimization",
            "SQL Server",
            "Netezza",
            "IBM DB2",
            "HDFS",
            "Spark",
            "Computer Vision",
            "Classification Models",
            "Statistics",
            "Algebra",
            "SPSS",
            "SAS",
            "R",
            "CPLEX",
            "Cognos",
            "PowerBI",
            "Python",
            "Scala"
        ],
        "tech_stack": [
            "SQL Server",
            "Netezza",
            "IBM DB2",
            "HDFS",
            "Spark",
            "SPSS",
            "SAS",
            "R",
            "CPLEX",
            "Cognos",
            "PowerBI",
            "Python",
            "Scala"
        ],
        "programming_languages": [
            "Python",
            "Scala",
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Economics",
                "Mathematics",
                "Computer Science",
                "Statistics",
                "Information Management",
                "Engineering"
            ]
        },
        "salary": {
            "max": 160000,
            "min": 0
        },
        "benefits": [
            "Bonus"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Gwynedd, PA",
        "job_id": 3966847792,
        "company": "Johnson & Johnson",
        "title": "Engineer, Machine Learning Research and Development",
        "created_on": 1720587819.2667496,
        "description": "Johnson & Johnson Innovative Medicine is currently seeking an Engineer, Machine Learning Research and Development to join our Data Integration and Predictive Technologies Team located in Spring House, PA or Malvern, PA. At Johnson & Johnson,we believe health is everything. Our strength in healthcare innovation empowers us to build aworld where complex diseases are prevented, treated, and cured,where treatments are smarter and less invasive, andsolutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com/ . For more than 130 years, diversity, equity & inclusion (DEI) has been a part of our cultural fabric at Johnson & Johnson and woven into how we do business every day. Rooted in Our Credo, the values of DEI fuel our pursuit to create a healthier, more equitable world. Our diverse workforce and culture of belonging accelerate innovation to solve the world's most pressing healthcare challenges. We know that the success of our business - and our ability to deliver meaningful solutions - depends on how well we understand and meet the diverse needs of the communities we serve. Which is why we foster a culture of inclusion and belonging where all perspectives, abilities and experiences are valued and our people can reach their potential. At Johnson & Johnson, we all belong. In this role you will work as an individual contributor possessing expertise in applied modeling applicable to biopharmaceutical development working in global and a diverse team of talents. This role requires skills to collaborate with scientists and seek opportunities where modeling can make valuable contributions by using model outcomes to drive robust biologics product and process design and optimization. Crafts and provides collaborative, fit for purpose machine learning and artificial-intelligence applications to enable data driven decisions. Ensures output of models meets project teams needs and invigorates generation of intellectual property that solidifies and improves the company's ability to deliver and accelerating development to meet patient needs. Key Responsibilities Build novel machine learning models focused to help development project teams deliver best process at launch. Deliver solutions with user functionality to enable project teams to use models and consult with model builders. Working with scientists, engineers, and IT architects to define user requirements for data blocks and build data pipelines to assemble, clean, coordinate, integrate, visualize, and interpret data needs for modeling. Advise project teams on data driven decision making including design of experiments, investigations, transforming historical data to knowledge. Define and develop future of a modeling culture to enable development data collection, modeling for off-, at-, in-line applications. A minimum of a BS degree in a core science field, (biology, chemistry, engineering, physics, bioinformatics) or related with at least 4 years work experience; OR a MS or equivalent with at least 2 years of work experience; OR a PhD or equivalent with 0-1 year of work experience is required. Experience in applied modeling to uncover solutions and drive decision making is required. Experience utilizing a strategic approach to apply the appropriate modeling techniques and leveraging recent published content and literature to stay current is required. Strong focus collaborating across global teams and excellent communication skills are required. Advanced skills with one or more programming languages are required. (Examples may include .net, Java, Perl, C , Matlab, Julia or Python) Experience wrangling and transforming high dimensional big data from established data warehouse is required. Proficiency with statistics, algorithm design, understand model quality attributes is required. Creative thinking, ability to generate new insights and concepts to drive data science in BioTherapeutics is required. Experience with collaboration tools is preferred. (Examples may include; JIRA, git, scrum, confluence) Experience in pharmaceutical development is preferred. Experience with agile and waterfall approach to SDLC is preferred. Experience applying machine learning modeling to support biopharmaceutical industry is preferred. Understanding, applications for LLM (Large Language Models) is preferred. Experience in Azure or Amazon Web Services (AWS), and/or full-stack development is preferred. Hands on experience and knowledge of Biologic Process, Molecular Biology, Biochemistry, Chemistry and working knowledge of GxP is preferred. Working knowledge of model verification and validation is preferred. Applied PAT and or in-line applications (Chemo-metrics, Raman spectroscopy) is preferred. This position may be located in either Spring House, PA or Malvern PA, and may require domestic and international travel up to approximately 15%. Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability. For more information on how we support the whole health of our employees throughout their wellness, career and life journey, please visit www.careers.jnj.com . IND7",
        "url": "https://www.linkedin.com/jobs/view/3966847792",
        "summary": "Johnson & Johnson is seeking an Engineer, Machine Learning Research and Development to join their Data Integration and Predictive Technologies Team in Spring House, PA or Malvern, PA. The role involves developing novel machine learning models for biopharmaceutical development, collaborating with scientists and engineers, and driving data-driven decisions. The ideal candidate will have experience in applied modeling, programming languages, big data wrangling, and statistics.",
        "industries": [
            "Biotechnology",
            "Pharmaceutical",
            "Healthcare",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Decision Making",
            "Creative Thinking",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "Applied Modeling",
            "Programming Languages",
            "Data Wrangling",
            "Data Analysis",
            "Statistics",
            "Algorithm Design",
            "Model Validation",
            "Data Pipelines",
            "Data Visualization",
            "Data Integration",
            "Biopharmaceutical Development"
        ],
        "tech_stack": [
            "Azure",
            "Amazon Web Services (AWS)",
            "JIRA",
            "Git",
            "Scrum",
            "Confluence",
            "Matlab",
            "Julia",
            "Python",
            ".NET",
            "Java",
            "Perl",
            "C",
            "LLM (Large Language Models)",
            "Full-Stack Development"
        ],
        "programming_languages": [
            ".NET",
            "Java",
            "Perl",
            "C",
            "Matlab",
            "Julia",
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Biology",
                "Chemistry",
                "Engineering",
                "Physics",
                "Bioinformatics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greater Minneapolis-St. Paul Area",
        "job_id": 3962894541,
        "company": "True Source",
        "title": "Python/Machine Learning Engineer",
        "created_on": 1720587820.778206,
        "description": "Minneapolis or Chicago candidates only please! Scope: First engineer on team Goal is to find someone that has technical vision Understand full stack concepts Expertise in product engineering, connecting APIs to downstream systems Connecting things to upstream systems a plus Bonus would be front end design. Understand those concepts Don’t need AI researchers…have that figured out. Needs someone who can crank through engineering. Don’t need academics Hands on coder who lead through example. Good mentorship. Bringing up interns. 20% mentoring and building out team, 80% hands on Move towards director of engineering Years of experience doesn’t matter – what can you deliver? Uses portkey to manage models…need to build and manage those for what they need them to do Azure and Python. Open on tech. Have to be self-directed to learn solution and not have someone telling you how to do it. Understand business goal, make right tech selection, and implement it correctly This is the product to enhance and eventually replace the service desk",
        "url": "https://www.linkedin.com/jobs/view/3962894541",
        "summary": "We are seeking a highly motivated and skilled engineer to join our team as the first engineer. The ideal candidate will have a strong technical vision, a deep understanding of full-stack concepts, and expertise in product engineering, particularly in connecting APIs to downstream systems. Experience connecting to upstream systems is a plus.  The role will involve 80% hands-on coding and 20% mentoring and team building. This position has the potential to grow into a Director of Engineering role.  We are looking for someone who is self-directed, able to learn new solutions quickly, and can make informed technical decisions based on business goals.  Experience with Portkey for model management and Azure/Python is preferred. Front-end design experience is a bonus.",
        "industries": [
            "Software Development",
            "Technology",
            "Information Technology",
            "Product Development"
        ],
        "soft_skills": [
            "Technical Vision",
            "Self-Directed",
            "Problem Solving",
            "Leadership",
            "Mentorship",
            "Team Building",
            "Communication",
            "Decision Making"
        ],
        "hard_skills": [
            "Full-Stack Development",
            "API Integration",
            "Product Engineering",
            "Downstream Systems",
            "Upstream Systems",
            "Front-End Design",
            "Portkey",
            "Azure",
            "Python"
        ],
        "tech_stack": [
            "Portkey",
            "Azure",
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3969892385,
        "company": "ClearML",
        "title": "AI/ML Engineer",
        "created_on": 1720587824.8297932,
        "description": "AI/ML Engineer ClearML is a unified, open source platform for continuous machine learning (ML), trusted by forward-thinking Data Scientists, ML Engineers, DevOps, and decision makers at leading Fortune 500, enterprises, academia, and innovative start-ups worldwide. We enable customers to build continuous ML workflows -- from experiment management and orchestration through data management and scheduling, followed by provisioning and serving -- to achieve the fastest time to ML production, fastest time to value, and increased performance. We help data science, ML engineering, and DevOps teams easily develop, orchestrate, and automate ML workflows at scale. Our frictionless, unified, end-to-end MLOps suite enables users and customers to focus on developing their ML code and automation, ensuring their work is reproducible and scalable. ClearML is trusted by brands such as NVIDIA, Philips, Samsung, Hyundai and Bosch. As a member of the machine Learning team at ClearML, you will have the opportunity to contribute to our mission of transforming the ML space -- bridging software, machine learning, and automation . Our team is focused on improving the customer experience of our MLOPs platform and tools through data-driven insights, research, and development. By joining ClearML, you will have the chance to be a part of a dynamic team that is dedicated to advancing the field of machine learning and helping ML engineers train high-performing, fair, and reproducible models. Overview: We are an open source end-to-end AI platform, built by developers for developers. We're looking for a Machine Learning engineer to join our growing team. In this role, you will collaborate across our development and product teams and will have a chance to collaborate with our MLOPs experts working in the exciting areas of machine learning, deep learning, NLP, computer vision and DevOps. The ideal candidate will be an ML Engineer who wants to learn how to analyze large amounts of raw information to find patterns and use them to optimize model performance. You will work with our team to learn to build ML/DL data pipelines to extract valuable business insights, analyze trends, and help us make better decisions. We expect you to be highly analytical with a knack for analysis, math, and statistics, and a passion for machine learning and research. Critical thinking and problem-solving skills are also required. Responsibilities: Build scalable infrastructure for training, evaluating, and serving models Research and analyze valuable data sources and automate processes Perform preprocessing of structured and unstructured data Review large amounts of information to discover trends and patterns Create predictive models and machine-learning algorithms Organize and present information using data visualization techniques Develop and suggest solutions and strategies to business challenges Work together with engineering and product development teams to build and test ML/DL solutions stretching the entire spectrum of ML operationalization from data processing, model training, hyperparameter tuning, deployment, and model management. Requirements: 2+ years of machine learning experience to include building production-grade machine learning models in industry /research settings Strong programming skills in Python and deep-learning Experience building end-to-end scalable ML infrastructure with on-premise / cloud platforms. Familiar with Kubernetes and/or similar container system Strong math and analytical skills, with business acumen Strong communication and presentation skills Good problem-solving abilities BSc or BA degree in Computer Science, Engineering or other relevant area; graduate degree in Data Science or other quantitative field is preferred",
        "url": "https://www.linkedin.com/jobs/view/3969892385",
        "summary": "ClearML, an open source platform for continuous machine learning, seeks an AI/ML Engineer to join their growing team. This role involves building scalable ML infrastructure, analyzing data, creating predictive models, and collaborating with development and product teams to implement ML/DL solutions. The ideal candidate will have strong programming skills in Python and experience with building end-to-end ML infrastructure, coupled with a passion for machine learning and research.",
        "industries": [
            "Software",
            "Machine Learning",
            "Artificial Intelligence",
            "Data Science",
            "MLOps"
        ],
        "soft_skills": [
            "Analytical",
            "Communication",
            "Problem-solving",
            "Critical Thinking",
            "Presentation",
            "Collaboration"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "Deep Learning",
            "Data Preprocessing",
            "Model Training",
            "Model Evaluation",
            "Model Serving",
            "Data Analysis",
            "Data Visualization",
            "Hyperparameter Tuning",
            "Model Management",
            "Kubernetes",
            "Containerization"
        ],
        "tech_stack": [
            "ClearML",
            "Kubernetes",
            "Python",
            "Machine Learning",
            "Deep Learning"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "BSc or BA",
            "fields": [
                "Computer Science",
                "Engineering",
                "Data Science",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3965714950,
        "company": "Analytic Recruiting Inc.",
        "title": "Data Scientist - Healthcare Claims Payment Integrity",
        "created_on": 1720587828.903429,
        "description": "Leading provider of healthcare claims integrity seeking a Data Scientist that looks through large amounts of claims data to identify cases of fraud, waste, and abuse to discover or recover funds for clients (private and government clients). This candidate must be high level individual contributor with entrepreneurial spirit. PYTHON CODING EXPERTS ONLY MUST HAVE EXPERIENCE WITH HEALTHCARE CLAIMS, Ivy league education preferred. Location: Remote Keywords: Healthcare Claims, Data Science, Python coding, Fraud Waste and Abuse, Payment Integrity Responsibilities: Applying SQL and machine learning to develop fraud, waste and abuse models looking at claims data Presenting results to technical, business and executive level customers Visualizing results and building user centric dashboards Defining technical and data requirements to address business problems Qualifications Quant degree Experience working with healthcare claims and/or medical records. Significant experience in data analytics with demonstrable successes. Actual hands-on experience is more important than formal education Experience in developing and deploying solutions written in Python or SQL Strong experience in defining business requirements and presenting results to business users Prior experience deploying analytical models to production Email ilana@analyticrecruiting.com with updated resume and questions",
        "url": "https://www.linkedin.com/jobs/view/3965714950",
        "summary": "A Data Scientist is needed to identify healthcare claims fraud, waste, and abuse using SQL and machine learning. This role requires strong Python skills, healthcare claims experience, and a demonstrable track record in data analytics. The individual will develop fraud detection models, present findings to stakeholders, visualize results, and define technical requirements.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Fraud Detection",
            "Claims Processing",
            "Analytics",
            "Insurance"
        ],
        "soft_skills": [
            "Communication",
            "Presentation",
            "Problem Solving",
            "Entrepreneurial Spirit",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Machine Learning",
            "Data Analytics",
            "Data Visualization",
            "Dashboarding",
            "Healthcare Claims",
            "Medical Records",
            "Fraud Detection",
            "Waste and Abuse"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "Machine Learning"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Quant",
            "fields": [
                "Data Science",
                "Statistics",
                "Mathematics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Kennesaw, GA",
        "job_id": 3965969441,
        "company": "Copeland",
        "title": "Data Scientist",
        "created_on": 1720587831.9938636,
        "description": "About Us We are a global climate technologies company engineered for sustainability. We create sustainable and efficient residential, commercial and industrial spaces through HVACR technologies. We protect temperature-sensitive goods throughout the cold chain. And we bring comfort to people globally. Best-in-class engineering, design and manufacturing combined with category-leading brands in compression, controls, software and monitoring solutions result in next-generation climate technology that is built for the needs of the world ahead. Whether you are a professional looking for a career change, an undergraduate student exploring your first opportunity, or recent graduate with an advanced degree, we have opportunities that will allow you to innovate, be challenged and make an impact. Join our team and start your journey today! If you are a Data Scientist professional looking for an opportunity to grow, Copeland has an opening for you! Based in either our Sidney, Ohio or St. Louis, Missouri location, you will assist with developing ground-breaking insights dedicated to improving the quality of people's lives around the world, by protecting the food cold-chain while helping us to be better stewards of the world's energy reserves. You will work Copeland's Data Scientists and Engineers around the world as a motivator for change by developing innovative product forecasting, data-driven product, and efficiency improvement services for internal and external customers. As a Data Scientist, You Will Implement solutions to solve sophisticated business and engineering problems using machine learning, econometrics and operations research techniques Build customer-focused analytics with data scientist peers Discover opportunities to improve systems, processes and enterprises through data analytics and automation Generate reports for decision-making using data visualization tools Establish and maintain collaboration with other internal teams to apply cloud and edge-computing capabilities for production and proprietary algorithms Develop in-depth business and domain understanding Translate analytics techniques published in peer-review journals and conference proceedings into practical solutions for challenges at hand Required Education, Experience, & Skills Bachelor's or Master's degree in Econometrics, Operations Research, Engineering or Quantitative fields Must have strong interest in applying, deploying and scaling data driven solutions across business domains (e.g. Finance, Sales and Marketing), Supply Chain and customer-facing projects Must have experience in data wrangling and modeling in Python or similar language and collaborate using Git Must be proficient in verifying raw data integrity through automation and classic extract-transform-load (ETL) techniques Proficient in robust statistics, hypothesis testing, experimental design Have knowledge in forecasting and/or time series analysis (e.g. ARIMAX and deep learning techniques) Experience with modelling techniques for sophisticated systems and machine learning Excellent verbal and written communication skills Ability to work on virtual teams with members around the globe Ability to translate ambiguous business problem into actionable analytics and data science tasks Preferred Education, Experience, & Skills Master's or Doctorate's degree in Econometrics, Operations Research, Engineering or Quantitative field Proven knowledge in applying forecasting and/or analytics to tackle practical problems through peer-review journal publications, conference proceedings or graduate thesis Demonstrated experience in proposing an original and innovative initiative, executing the idea and presenting the findings with other domain expert(s) Proven experience in managing project(s) or research and acted as a change agent Experience in game theory, data envelopment analysis, mathematical programming, scheduling, queuing theory Experience with Docker, Azure DevOps, Agile sprints Familiar with basic SQL commands (e.g. windowing function, group-by aggregate, pivot) Ability and interest in translating highly complex and abstract concepts to internal and external stakeholders with minimum analytics knowledge Flexible Work Schedule – Remote Work Option and Core Hours This role has the flexibility of a remote work option up to three days a week and a core hour schedule. You can choose to flex your start and stop times given you are working during the core hours of 9:00am - 3:00pm. Our teams work together to ensure our chosen work schedules enable our creativity and productivity as we serve the needs of our customers. Our Commitment to Our People Across the globe, we are united by a singular Purpose: Sustainability is no small ambition. That’s why everything we do is geared toward a sustainable future—for our generation and all those to come. Through groundbreaking innovations, HVACR technology and cold chain solutions, we are reducing carbon emissions and improving energy efficiency in spaces of all sizes, from residential to commercial to industrial. Our employees are our greatest strength. We believe that our culture of passion, openness, and collaboration empowers us to work toward the same goal - to make the world a better place. We invest in the end-to-end development of our people, beginning at onboarding and through senior leadership, so they can thrive personally and professionally. Flexible and competitive benefits plans offer the right options to meet your individual/family needs: medical insurance plans, dental and vision coverage, 401(k), tuition reimbursement, and more. We provide employees with flexible time off plans, including paid parental leave (maternal and paternal), vacation and holiday leave. Together, we have the opportunity – and the power – to continue to revolutionize the technology behind air conditioning, heating and refrigeration, and cultivate a better future. Learn more about us and how you can join our team! Our Commitment to Our People Across the globe, we are united by a singular Purpose: Sustainability is no small ambition. That’s why everything we do is geared toward a sustainable future—for our generation and all those to come. Through groundbreaking innovations, HVACR technology and cold chain solutions, we are reducing carbon emissions and improving energy efficiency in spaces of all sizes, from residential to commercial to industrial. Our employees are our greatest strength. We believe that our culture of passion, openness, and collaboration empowers us to work toward the same goal - to make the world a better place. We invest in the end-to-end development of our people, beginning at onboarding and through senior leadership, so they can thrive personally and professionally. Flexible and competitive benefits plans offer the right options to meet your individual/family needs: medical insurance plans, dental and vision coverage, 401(k) and more. We provide employees with flexible time off plans, including paid parental leave, vacation and holiday leave. Together, we have the opportunity – and the power – to continue to revolutionize the technology behind air conditioning, heating and refrigeration, and cultivate a better future. Learn more about us and how you can join our team! Our Commitment to Diversity, Equity & Inclusion At Copeland, we believe having a diverse, equitable and inclusive environment is critical to our success. We are committed to creating a culture where every employee feels welcomed, heard, respected, and valued for their experiences, ideas, perspectives and expertise. Ultimately, our diverse and inclusive culture is the key to driving industry-leading innovation, better serving our customers and making a positive impact in the communities where we live. Work Authorization Copeland will only employ those who are legally authorized to work in the United States. This is not a position for which sponsorship will be provided. Individuals with temporary visas such as E, F-1 with OPT or CPT, H-1, H-2, L-1, B, J or TN, or who need sponsorship for work authorization now or in the future, are not eligible for hire. Equal Opportunity Employer Copeland is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, race, color, religion, national origin, age, marital status, political affiliation, sexual orientation, gender identity, genetic information, disability or protected veteran status. We are committed to providing a workplace free of any discrimination or harassment. If you have a disability and are having difficulty accessing or using this website to apply for a position, please contact: copeland.careers@copeland.com",
        "url": "https://www.linkedin.com/jobs/view/3965969441",
        "summary": "Copeland, a global climate technologies company, is seeking a Data Scientist to develop data-driven solutions for improving the quality of life and protecting the cold chain. The role involves implementing machine learning, econometrics, and operations research techniques, building customer-focused analytics, discovering opportunities for improvement, generating reports, and collaborating with internal teams. Remote work option is available up to three days a week.",
        "industries": [
            "Climate Technology",
            "HVAC",
            "Refrigeration",
            "Cold Chain Logistics",
            "Data Science",
            "Engineering",
            "Sustainability",
            "Energy"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Decision Making",
            "Data Visualization",
            "Teamwork",
            "Initiative",
            "Project Management",
            "Change Management",
            "Presentation Skills"
        ],
        "hard_skills": [
            "Machine Learning",
            "Econometrics",
            "Operations Research",
            "Python",
            "Git",
            "Data Wrangling",
            "Data Modeling",
            "ETL",
            "Statistics",
            "Hypothesis Testing",
            "Experimental Design",
            "Forecasting",
            "Time Series Analysis",
            "ARIMAX",
            "Deep Learning",
            "Modeling",
            "SQL",
            "Docker",
            "Azure DevOps",
            "Agile"
        ],
        "tech_stack": [
            "Python",
            "Git",
            "SQL",
            "Docker",
            "Azure DevOps",
            "Agile"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Econometrics",
                "Operations Research",
                "Engineering",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental",
            "Vision",
            "401(k)",
            "Tuition Reimbursement",
            "Flexible Time Off",
            "Paid Parental Leave",
            "Vacation",
            "Holiday Leave"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3919924268,
        "company": "Syntricate Technologies",
        "title": "Data Scientist with Gen AI experience - Llama",
        "created_on": 1720587833.4831169,
        "description": "Hi, Hope you are doing well Number of position : 3 Only Full Time no C2C and No Contract Full-time I, Shakib (i3 infotek) would like to share a job opportunity as Data Scientist based in Bentonville, AR // Dallas, TX (Onsite) location for a Full-time position. In case, if you are not comfortable with this location, please share your preference with contact details for further requirements *** Kindly find the JD below and let me know if you are available for the same. Job tittle - Data Scientist Job Location: Bentonville, AR // Dallas, TX (Onsite) Duration: Full-time Job Description AI/Client model deployment/implementation skills are must for Walmart Expertise with classical Client algorithm like K-NN, LSH, logistic regression, linear regression, SVM, Random forest and clustering. Good understanding of Client & DL algorithms and frameworks (Scikit-learn,Spacy, Tensorflow/Keras/ PyTorch) Experience in deep learning Algorithms like MLP, CNN, RNN, LSTMs and GANs, Transformers and LLMs. Excellent programming skills in Python Expertise in Google Cloud and operationalization of models using MLOPs. Proven experience in deploying real-time AI/Client models using Google Cloud Platform. Strong programming skills in Python and PySpark. Proficiency with SQL and relational databases, data warehouses, and BigQuery. Experience in scaling marketing-related AI/Client solutions such as cross/upsell, recommended systems, and category propensity. Experience in deploying and managing Large scale Machine Learning Models is a plus Expertise with classical Client algorithm like K-NN, LSH, logistic regression, linear regression, SVM, Random forest and clustering. Good understanding of Client & DL algorithms and frameworks (Scikit-learn,Spacy, Tensorflow/Keras/ PyTorch) Experience in deep learning Algorithms like MLP, CNN, RNN, LSTMs and GANs, Transformers and LLMs. Excellent programming skills in Python Expertise in Google Cloud and operationalization of models using MLOPs. Experience in scheduling jobs for automated training and inference of AI/Client models using airflow or any other workflow orchestration platform. Proficiency in collecting data from different data sources, data cleaning, preprocessing, and feature engineering. Understanding of regression, classification, and unsupervised Client algorithms. Experience in mentoring junior associates in scaling AI/Client models. Excellent problem-solving and analytical skills. Strong written and verbal communication skills, with the ability to present and explain complex concepts to both technical and non-technical audiences. Please reply me with your updated resume and required details: Full Name Best number to reach you: Work Authorization/Visa Status Current Location: Expected Compensation Best time to call you: Waiting for your earliest response Sincerely, Mohd Shakib Sr. Technical Recruiter Direct: 781-896-2153 Address: 1500 District Avenue, Ste. 4135, Burlington, MA 01803",
        "url": "https://www.linkedin.com/jobs/view/3919924268",
        "summary": "Data Scientist position at Walmart in Bentonville, AR or Dallas, TX. Requires strong AI/ML skills, expertise in classical and deep learning algorithms, Google Cloud proficiency, and experience with MLOps.  Candidate should be proficient in Python, PySpark, SQL, and BigQuery. Experience with scaling marketing-related AI/ML solutions is a plus. ",
        "industries": [
            "Retail",
            "E-commerce",
            "Technology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical",
            "Communication",
            "Presentation",
            "Mentoring"
        ],
        "hard_skills": [
            "K-NN",
            "LSH",
            "Logistic Regression",
            "Linear Regression",
            "SVM",
            "Random Forest",
            "Clustering",
            "Scikit-learn",
            "Spacy",
            "Tensorflow",
            "Keras",
            "PyTorch",
            "MLP",
            "CNN",
            "RNN",
            "LSTMs",
            "GANs",
            "Transformers",
            "LLMs",
            "Python",
            "PySpark",
            "SQL",
            "BigQuery",
            "Google Cloud",
            "MLOPs",
            "Airflow",
            "Data Cleaning",
            "Preprocessing",
            "Feature Engineering",
            "Regression",
            "Classification",
            "Unsupervised Learning"
        ],
        "tech_stack": [
            "Google Cloud",
            "MLOPs",
            "Airflow",
            "Scikit-learn",
            "Spacy",
            "Tensorflow",
            "Keras",
            "PyTorch"
        ],
        "programming_languages": [
            "Python",
            "PySpark",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3961911033,
        "company": "Airbnb",
        "title": "Staff Data Scientist, Marketplace",
        "created_on": 1720587835.0759425,
        "description": "Airbnb was born in 2007 when two Hosts welcomed three guests to their San Francisco home, and has since grown to over 4 million Hosts who have welcomed more than 1 billion guest arrivals in almost every country across the globe. Every day, Hosts offer unique stays and experiences that make it possible for guests to connect with communities in a more authentic way. The Community You Will Join You will join a team dedicated to driving innovation and optimizing our dynamic Marketplace. As a member of the Marketplace Data Science team, you will tackle challenges at the core of our business, including pricing, supply management, and fee strategies. Collaborating with leaders across the company, you will play a key role in shaping the future of our marketplace. The Difference You Will Make As a Staff Data Scientist, you will be responsible for building data products, inference frameworks, and intelligence to enable the growth of our marketplace. Your work will include: Specifying and estimating models to determine the specific supply that would be most incremental to Airbnb’s growth Delivering data and insights to enable the company’s supply growth efforts Providing mentorship to other data scientists and exemplifying a high bar for technical excellence A Typical Day Crafting models: You will develop models to accurately forecast key marketplace metrics, enabling proactive decision-making and strategic planning. Advanced causal inference: Utilizing cutting-edge causal inference techniques, you will quantify the impact of changes in supply and demand on the marketplace, informing targeted improvements and interventions. Cross-functional collaboration: You will actively collaborate with teams across product, engineering, and operations to integrate data science insights into initiatives aimed at enhancing supply acquisition, retention, and success. Stakeholder engagement: You will engage with stakeholders to understand their business objectives and provide data-driven solutions tailored to these goals. Your Expertise 9+ years of relevant industry experience and a Master’s degree or PhD in a quantitative field Strong fluency in Python or R for hands-on IC work and SQL for advanced data analysis at scale Experience with causal inference and machine learning techniques, ideally in a multi-sided platform setting Proven ability to succeed in collaborative environments with cross-functional stakeholders and also in independent work environments Proven ability to communicate clearly and effectively to audiences of varying technical levels Your Location: This position is US - Remote Eligible. The role may include occasional work at an Airbnb office or attendance at offsites, as agreed to with your manager. While the position is Remote Eligible, you must live in a state where Airbnb, Inc. has a registered entity. Click here for the up-to-date list of excluded states. This list is continuously evolving, so please check back with us if the state you live in is on the exclusion list. If your position is employed by another Airbnb entity, your recruiter will inform you what states you are eligible to work from. Our Commitment To Inclusion & Belonging Airbnb is committed to working with the broadest talent pool possible. We believe diverse ideas foster innovation and engagement, and allow us to attract creatively-led people, and to develop the best products, services and solutions. All qualified individuals are encouraged to apply. We strive to also provide a disability inclusive application and interview process. If you are a candidate with a disability and require reasonable accommodation in order to submit an application, please contact us at: reasonableaccommodations@airbnb.com. Please include your full name, the role you’re applying for and the accommodation necessary to assist you with the recruiting process. We ask that you only reach out to us if you are a candidate whose disability prevents you from being able to complete our online application. How We'll Take Care Of You Our job titles may span more than one career level. The actual base pay is dependent upon many factors, such as: training, transferable skills, work experience, business needs and market demands. The base pay range is subject to change and may be modified in the future. This role may also be eligible for bonus, equity, benefits, and Employee Travel Credits. Pay Range $192,000—$243,000 USD",
        "url": "https://www.linkedin.com/jobs/view/3961911033",
        "summary": "Airbnb is seeking a Staff Data Scientist to join their Marketplace Data Science team. The role involves developing data products, inference frameworks, and intelligence to support the growth of Airbnb's marketplace. Responsibilities include building models to forecast key metrics, utilizing causal inference techniques to quantify the impact of supply and demand changes, collaborating with cross-functional teams, and engaging with stakeholders to provide data-driven solutions.",
        "industries": [
            "E-commerce",
            "Travel",
            "Hospitality",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Decision Making",
            "Analytical Thinking",
            "Strategic Thinking",
            "Mentorship"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Causal Inference",
            "Machine Learning",
            "Model Building",
            "Forecasting",
            "Data Analysis"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Machine Learning",
            "Causal Inference"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 9,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 243000,
            "min": 192000
        },
        "benefits": [
            "Bonus",
            "Equity",
            "Benefits",
            "Employee Travel Credits"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Atlanta Metropolitan Area",
        "job_id": 3964766146,
        "company": "Compunnel Inc.",
        "title": "Machine Learning Engineer",
        "created_on": 1720587836.4713147,
        "description": "Primary Skills: Machine Learning Strong AI ML Data Science experience, Data Engineering and ML background with Google Cloud platforms Extensive experience in On prem to Cloud migration projects in AI ML Experience in Databricks ML Experience in Cloudera Data Science Work Bench Data Science ,Machine Learning Roles & Responsibilities Data mining or extracting usable data from valuable data sources Using machine learning tools to select features, create and optimize classifiers Carrying out pre-processing of structured and unstructured data Enhancing data collection procedures to include all relevant information for developing analytic systems Processing, cleansing, and validating the integrity of data to be used for analysis High Maturity Practices ,Data Science ,Machine Learning ,SQL Analysing large amounts of information to find patterns and solutions Developing prediction systems and machine learning algorithms Presenting results in a clear manner Propose solutions and strategies to tackle business challenges",
        "url": "https://www.linkedin.com/jobs/view/3964766146",
        "summary": "This role requires a data scientist with strong machine learning, AI, and data engineering experience, particularly with Google Cloud platforms. The individual will be involved in data mining, feature selection, classifier creation, data preprocessing, data collection enhancement, data integrity validation, pattern analysis, prediction system development, and presenting results to stakeholders. Experience with Databricks, Cloudera Data Science Workbench, SQL, and a focus on high maturity practices is also essential.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Cloud Computing",
            "Software Development"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Presentation Skills",
            "Analytical Skills",
            "Data Analysis"
        ],
        "hard_skills": [
            "Machine Learning",
            "AI",
            "Data Science",
            "Data Engineering",
            "Google Cloud Platforms",
            "Databricks",
            "Cloudera Data Science Workbench",
            "SQL",
            "Data Mining",
            "Feature Selection",
            "Classifier Creation",
            "Data Preprocessing",
            "Data Collection Enhancement",
            "Data Integrity Validation",
            "Pattern Analysis",
            "Prediction System Development"
        ],
        "tech_stack": [
            "Google Cloud Platform",
            "Databricks",
            "Cloudera Data Science Workbench",
            "SQL"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": [
                "Data Science",
                "Machine Learning",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Alpharetta, GA",
        "job_id": 3964393542,
        "company": "Derex Technologies Inc",
        "title": "Senior Data Scientist",
        "created_on": 1720587839.5807223,
        "description": "Company Description Derex Technologies Inc specializes in providing IT consulting, staffing solutions and software services. Globally headquartered in Harrison New Jersey since 1996 Derex delivers the highest quality technology professionals and an array of customized IT talent solutions designed to improve productivity and drive results to global clients throughout North America. With over two decades of unparalleled experience, Derex provides supports to its clientele, across such industries as Systems Integration, Banking and Finance, Telecommunications, Pharmaceutical and Life Sciences, Energy, Healthcare, Technology, Transportation, and local and federal Government agencies. Job Description Position: Senior Data Scientist Location: Onsite in Alpharetta – GA Job Summary : Experience : 10+ years relevant – locals preferred. Required Skills : Database Design ,Python ,Machine Learning ,Artificial Intelligence As a Senior Data Scientist, you will be responsible for leveraging advanced technologies and data analytics to drive business insights and solutions. With a focus on database design, Python, machine learning, and artificial intelligence, you will play a crucial role in enhancing our data-driven decision-making processes. This position requires 10 years of experience in relevant fields. Roles & Responsibilities Lead the development and implementation of geospatial data models and solutions to support business objectives. Oversee the design and maintenance of databases to ensure efficient data storage and retrieval. Provide expertise in Python programming to automate data processing and analysis tasks. Utilize machine learning algorithms to analyze geospatial data and generate predictive insights. Apply artificial intelligence techniques to enhance the accuracy and efficiency of geospatial analyses. Collaborate with cross-functional teams to integrate geospatial data into broader business strategies. Conduct thorough data quality assessments to ensure the reliability and accuracy of geospatial datasets. Develop and maintain documentation for geospatial data models, processes, and workflows. Train and mentor junior analysts in geospatial analysis techniques and best practices. Present findings and recommendations to stakeholders in a clear and concise manner. Stay updated with the latest advancements in geospatial technologies and methodologies. Ensure compliance with data privacy and security regulations in all geospatial data handling processes. Contribute to the continuous improvement of geospatial analysis tools and methodologies. Qualifications : Possess strong experience in database design and management, ensuring efficient data storage and retrieval. Demonstrate proficiency in Python programming for automating data processing and analysis tasks Have a solid understanding of machine learning algorithms and their application in geospatial data analysis. Show expertise in artificial intelligence techniques to enhance geospatial analyses. Exhibit excellent problem-solving skills and the ability to work collaboratively with cross-functional teams. Display strong communication skills for presenting findings and recommendations to stakeholders. Maintain a proactive approach to staying updated with advancements Regards, Manoj Derex Technologies INC Contact : 973-834-5005 Ext 206 Additional Information All your information will be kept confidential according to EEO guidelines.",
        "url": "https://www.linkedin.com/jobs/view/3964393542",
        "summary": "Derex Technologies is seeking a Senior Data Scientist with 10+ years of experience to develop and implement geospatial data models and solutions. The role involves database design, Python programming, machine learning, and AI to drive business insights and solutions. The ideal candidate will have expertise in geospatial data analysis and a strong understanding of database management, Python, machine learning algorithms, and AI techniques. They will be responsible for leading the development of geospatial data models, overseeing database maintenance, automating data processing, generating predictive insights, collaborating with cross-functional teams, conducting data quality assessments, training junior analysts, and presenting findings to stakeholders.",
        "industries": [
            "IT Consulting",
            "Staffing Solutions",
            "Software Services",
            "Systems Integration",
            "Banking and Finance",
            "Telecommunications",
            "Pharmaceutical and Life Sciences",
            "Energy",
            "Healthcare",
            "Technology",
            "Transportation",
            "Government"
        ],
        "soft_skills": [
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Presentation",
            "Training",
            "Mentoring"
        ],
        "hard_skills": [
            "Database Design",
            "Python",
            "Machine Learning",
            "Artificial Intelligence",
            "Geospatial Data Analysis",
            "Data Quality Assessment",
            "Data Storage",
            "Data Retrieval",
            "Data Processing",
            "Predictive Modeling"
        ],
        "tech_stack": [
            "Python",
            "Machine Learning",
            "Artificial Intelligence",
            "Geospatial Data"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 10,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967167413,
        "company": "Apexon",
        "title": "Data Scientist",
        "created_on": 1720587841.0427833,
        "description": "About Apexon Apexon is a digital-first technology services firm specializing in accelerating business transformation and delivering human-centric digital experiences. We have been meeting customers wherever they are in the digital lifecycle and helping them outperform their competition through speed and innovation.Apexon brings together distinct core competencies – in AI, analytics, app development, cloud, commerce, CX, data, DevOps, IoT, mobile, quality engineering and UX, and our deep expertise in BFSI, healthcare, and life sciences – to help businesses capitalize on the unlimited opportunities digital offers. Our reputation is built on a comprehensive suite of engineering services, a dedication to solving clients’ toughest technology problems, and a commitment to continuous improvement. Backed by Goldman Sachs Asset Management and Everstone Capital, Apexon now has a global presence of 15 offices (and 10 delivery centers) across four continents. We enable #HumanFirstDIGITAL You'll Be Responsible For (Responsibilities) Responsible for collecting, cleaning, and organizing data for analysis. They work with large datasets, ensuring data accuracy and quality. They also assist in feature selection and data preprocessing, which involves transforming raw data into a suitable format for machine learning algorithms. Our Commitment To Diversity & Inclusion Did you know that Apexon has been Certified™ by Great Place To Work®, the global authority on workplace culture, in each of the three regions in which it operates: USA (for the fourth time in 2023), India (seven consecutive certifications as of 2023), and the UK. Apexon is committed to being an equal opportunity employer and promoting diversity in the workplace. We take affirmative action to ensure equal employment opportunity for all qualified individuals. Apexon strictly prohibits discrimination and harassment of any kind and provides equal employment opportunities to employees and applicants without regard to gender, race, color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. You can read about our Job Applicant Privacy policy here Job Applicant Privacy Policy (apexon.com) Our Perks And Benefits Our benefits and rewards program has been thoughtfully designed to recognize your skills and contributions, elevate your learning/upskilling experience and provide care and support for you and your loved ones. As an Apexer, you get continuous skill-based development, opportunities for career advancement, and access to comprehensive health and well-being benefits and assistance. We Also Offer Health Insurance with Dental & Vision 401K Plan Life Insurance, STD & LTD Paid Vacations & Holidays Paid Parental Leave FSA Dependent & Limited Purpose care Learning & Development",
        "url": "https://www.linkedin.com/jobs/view/3967167413",
        "summary": "Apexon is a technology services firm specializing in digital transformation and delivering digital experiences. They offer services in AI, analytics, app development, cloud, commerce, CX, data, DevOps, IoT, mobile, quality engineering, and UX. Their expertise is in BFSI, healthcare, and life sciences. They have 15 offices and 10 delivery centers across four continents.",
        "industries": [
            "Technology Services",
            "Digital Transformation",
            "AI",
            "Analytics",
            "App Development",
            "Cloud Computing",
            "Commerce",
            "Customer Experience (CX)",
            "Data Management",
            "DevOps",
            "Internet of Things (IoT)",
            "Mobile Development",
            "Quality Engineering",
            "User Experience (UX)",
            "BFSI (Banking, Financial Services, and Insurance)",
            "Healthcare",
            "Life Sciences"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Data Analysis",
            "Organization",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Data Collection",
            "Data Cleaning",
            "Data Organization",
            "Data Analysis",
            "Feature Selection",
            "Data Preprocessing",
            "Machine Learning Algorithms"
        ],
        "tech_stack": [
            "AI",
            "Analytics",
            "App Development",
            "Cloud",
            "Commerce",
            "CX",
            "Data",
            "DevOps",
            "IoT",
            "Mobile",
            "Quality Engineering",
            "UX"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Dental",
            "Vision",
            "401K Plan",
            "Life Insurance",
            "STD",
            "LTD",
            "Paid Vacations",
            "Paid Holidays",
            "Paid Parental Leave",
            "FSA Dependent Care",
            "Limited Purpose Care",
            "Learning & Development"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Morrisville, NC",
        "job_id": 3964049680,
        "company": "Lenovo",
        "title": "AI Data Scientist",
        "created_on": 1720587844.601439,
        "description": "We are Lenovo. We do what we say. We own what we do. We WOW our customers. Lenovo is a US$62 billion revenue global technology powerhouse, ranked #217 in the Fortune Global 500, employing 77,000 people around the world, and serving millions of customers every day in 180 markets. Focused on a bold vision to deliver smarter technology for all, Lenovo has built on its success as the world’s largest PC company by further expanding into growth areas that fuel the advancement of ‘New IT’ technologies (client, edge, cloud, network, and intelligence) including server, storage, mobile, software, solutions, and services. This transformation together with Lenovo’s world-changing innovation is building a more inclusive, trustworthy, and smarter future for everyone, everywhere. To find out more visit www.lenovo.com, and read about the latest news via our StoryHub. We are looking for a skilled AI Data Scientist to support Intel projects focused on optimizing AI and machine learning workloads on Intel hardware. In this role, you will leverage OpenVINO and Intel software optimization techniques to enhance the performance of AI models. You will also collaborate with technical writers to create content on accelerating traditional ML algorithms on Intel hardware and migrating algorithms from CUDA to SYCL. Key Responsibilities Utilize OpenVINO and Intel software optimization techniques to optimize AI and ML workloads on Intel hardware Conduct use and testing of OpenVINO for AI and ML tasks Collaborate with technical writers to create content on accelerating traditional ML algorithms on Intel hardware Coordinate with technical writers to develop content on migrating algorithms from CUDA to SYCL Benchmark AI performance using MLPerf on Intel hardware Analyze and interpret complex data to derive actionable insights Communicate findings and recommendations to technical and non-technical stakeholders Expert support on customer engagements Requirements Basic Qualifications: Bachelor's degree in Computer Science, Data Science, or similar At least 3 years experience in AI, machine learning, and data analysis At least 1 years experience with TensorFlow, scikit-learn, and PyTorch At least 1 year experience with data visualization tools Preferred Qualifications Master's degree in Computer Science, Data Science, or Similar Proficiency in OpenVINO and Intel software optimization techniques Knowledge of CUDA and SYCL programming models Knowledge in traditional ML algorithms and their acceleration on Intel hardware We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class.",
        "url": "https://www.linkedin.com/jobs/view/3964049680",
        "summary": "Lenovo is seeking an AI Data Scientist to optimize AI and ML workloads on Intel hardware. This role involves using OpenVINO and Intel software optimization techniques, creating content on ML algorithm acceleration, and migrating algorithms from CUDA to SYCL. Responsibilities include benchmark AI performance, analyze data, communicate findings, and provide expert support to customers.",
        "industries": [
            "Technology",
            "Computer Hardware",
            "Software",
            "Data Science",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Data Interpretation",
            "Technical Writing",
            "Presentation Skills"
        ],
        "hard_skills": [
            "OpenVINO",
            "Intel Software Optimization Techniques",
            "TensorFlow",
            "Scikit-learn",
            "PyTorch",
            "Data Visualization Tools",
            "CUDA",
            "SYCL",
            "MLPerf",
            "Traditional ML Algorithms",
            "AI Model Optimization",
            "Machine Learning Workloads",
            "Benchmarking",
            "Data Analysis"
        ],
        "tech_stack": [
            "OpenVINO",
            "Intel Software Optimization Techniques",
            "TensorFlow",
            "Scikit-learn",
            "PyTorch",
            "CUDA",
            "SYCL",
            "MLPerf"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Washington, DC",
        "job_id": 3960907078,
        "company": "U.S. Department of Justice, Office of Justice Programs (OJP)",
        "title": "Data Scientist",
        "created_on": 1720587847.9423995,
        "description": "How to Apply Resumes will not be accepted over email. Applications must be submitted online. Click on \"Apply\" to learn about the application requirements for this position. This position is located in the U.S. Department of Justice (DOJ), Office of Justice Programs (OJP), Bureau of Justice Statistics (BJS). Responsibilities Develops and maintains the scripts and processes required to extract, transform, review and move data and metadata through the Bureau of Justice Statistics (BJS) database of record. Explores new technologies and techniques to create efficient process around data extraction, loading, transformation, governance, and cataloguing. Serves as an advisor to Bureau statisticians in solving complex and far-reaching data management issues and problems for a wide range of systems, applications and customers that use statistical methods and techniques. Leverages innovative project management methodologies (e.g., scaled Agile framework) to complete projects within a complex environment that requires coordination with multiple stakeholders across multiple organizations. Develops standard queries, reports and presentations that translate complex analytics concepts, findings and limitations into plain language for nontechnical audiences. Develops algorithms and tools to support data manipulation and processing as well as the use of data visualization techniques to articulate findings. Conducts planning, development, implementation, and administration of systems for the acquisition, storage, and retrieval of data. Ensures that product-related training and documentation are developed and made available to customers before related projects are completed. Analyzes feasibility studies, proposals and in-depth analyses of current requirements and forecast trends for future needs.",
        "url": "https://www.linkedin.com/jobs/view/3960907078",
        "summary": "This position at the Bureau of Justice Statistics (BJS) involves developing and maintaining scripts and processes for data extraction, transformation, and movement. You will explore new technologies, advise statisticians on data management, and utilize project management methodologies. You'll also create reports and presentations for non-technical audiences, develop algorithms and tools, and conduct planning and administration of data systems.",
        "industries": [
            "Government",
            "Statistics",
            "Data Science",
            "Data Management",
            "Justice"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Project Management",
            "Analytical Thinking",
            "Technical Writing"
        ],
        "hard_skills": [
            "Data Extraction",
            "Data Transformation",
            "Data Loading",
            "Data Governance",
            "Data Cataloguing",
            "Data Visualization",
            "Querying",
            "Reporting",
            "Presentation",
            "Algorithm Development",
            "Data Manipulation",
            "Data Processing",
            "Statistical Methods",
            "Project Management"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3964650005,
        "company": "InterEx Group",
        "title": "Senior Data Scientist",
        "created_on": 1720587851.3634987,
        "description": "Senior Data Scientist Senior Data Scientist – Manufacturing – NYC Senior Data Scientist Tech stack: Machine Learning, Python, R, TensorFlow, PyTorch, SQL, Big Data Technologies, Cloud Platforms (AWS, Azure). In 2011, our client revolutionized the manufacturing industry with advanced data-driven solutions. Now expanding their presence in NYC, they are seeking passionate Senior Data Scientists to drive innovation and lead transformative projects. The Data, Analytics & Machine Learning (DAML) Team, is a dedicated squad of professionals transforming the company’s data to enhance user experience. As a Senior Data Scientist (Tech stack: Machine Learning, Python, R, TensorFlow, PyTorch, SQL, Big Data Technologies, Cloud Platforms (AWS, Azure)) you would be joining a team that includes data scientists, data engineers, and BI professionals. Successful Senior Data Scientists will demonstrate strong expertise in Machine Learning, Python, R, TensorFlow, PyTorch, SQL, and Big Data Technologies. Additional training will be provided to enhance skills, turning weaknesses into strengths. All Senior Data Scientist positions come with the following benefits: Stock options worth $40,000 annually, vested over four years. 25 vacation days plus public holidays. Flexible work hours and early Fridays during summer months. $12,000 yearly training budget, including industry conferences. 5 days monthly allocated for innovative projects. Gym membership with yoga classes, summer BBQs, and birthday bonuses. Location: NYC, USA / Remote Salary: $150,000 - $180,000 + Bonus + Retirement + Benefits To apply, send your CV to S.al-saffar@interex-group.com at InterEx. InterEx Group excels in Data, ERP, and CRM, committed to advancing your career! INT/DE/BEL/441658",
        "url": "https://www.linkedin.com/jobs/view/3964650005",
        "summary": "Senior Data Scientist role at a manufacturing company revolutionizing the industry with data-driven solutions. Join a team of data scientists, data engineers, and BI professionals to drive innovation and lead transformative projects. Responsibilities include developing and deploying machine learning models, analyzing large datasets, and collaborating with stakeholders.",
        "industries": [
            "Manufacturing",
            "Data & Analytics",
            "Machine Learning"
        ],
        "soft_skills": [
            "Passionate",
            "Innovative",
            "Transformative",
            "Collaboration",
            "Communication"
        ],
        "hard_skills": [
            "Machine Learning",
            "Python",
            "R",
            "TensorFlow",
            "PyTorch",
            "SQL",
            "Big Data Technologies",
            "Cloud Platforms"
        ],
        "tech_stack": [
            "Machine Learning",
            "Python",
            "R",
            "TensorFlow",
            "PyTorch",
            "SQL",
            "Big Data Technologies",
            "AWS",
            "Azure"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 180000,
            "min": 150000
        },
        "benefits": [
            "Stock options",
            "Vacation days",
            "Flexible work hours",
            "Training budget",
            "Innovative project time",
            "Gym membership",
            "Yoga classes",
            "Summer BBQs",
            "Birthday bonuses"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Addison, TX",
        "job_id": 3938223553,
        "company": "ICONMA",
        "title": "Data Scientist",
        "created_on": 1720587852.7459698,
        "description": "Strong background in working with text data using natural language processing (NLP) including classification modeling, unsupervised modeling techniques such as clustering and topic modeling. Should have a background in working with transformer models. Strong Python coding skills are a must. Should have strong SQL skills, data mining, analytics, wrangling and data cleaning skills and strong feature engineering and entity/parts of speech tagging. Should have a strong understanding of word embeddings and finding like patterns in text with cosine similarity. Background in ElasticSearch or building semantic search solutions a plus Required Skills Qualified individuals should have a keen interest in combining data science skills to engineer automation solutions, help drive decisions, and are passionate about breaking down complex business problems and providing well-design data science solutions that makes a significant impact. 2 - 4 years of professional experience in NLP programming Experience with finetuning Large Language Models (LLMs) or writing language models from scratch. Demonstrated background in NLP and machine learning. Preference for degrees in computer science, information retrieval, statistics, applied math, or other quantitative field Demonstrated track record of publication in peer reviewed journals and conferences Track-record of having developed Client algorithms Experience in deep learning - phonetics (valued) Experience on modern deep learning approaches to NLP: Word/paragraph embedding’s, structured prediction, sentiment analysis, disambiguation Ability to consistently deliver results across shifting priorities and deadlines in fast paced environment Ability to work with a ‘sense of urgency’ in order to meet critical deadlines Desired Skills Advanced degree in Data Science with a focus in NLP valued Experience with BERT family of models, open source foundational LLMs such as LLAMA, Falcon or Mistral. Ability to indirectly manage peer level associates who are part of problem-solving teams Background in teaching NLP algorithms to beginners and advanced Data Scientists Experience with large scale data analysis tools such as Spark, Hadoop Background in machine learning techniques NLP programming in R and or Python / Anaconda Background with moving large data sets across Hadoop, SQL, ORACLE Solid background in statistical learning techniques for NLP (HMMs, CRFs, SVMs, LDA, LSI, MRFs) Must have Client/NLP algorithm implementation experience as well as the ability to create / modify standard algorithms (e.g. change objectives, work-out the math and implement) NLP programming in R and or Python / Anaconda Background with moving large data sets across Hadoop, SQL, ORACLE Solid background in statistical learning techniques for NLP (HMMs, CRFs, SVMs, LDA, LSI, MRFs) Must have Client/NLP algorithm implementation experience as well as the ability to create / modify standard algorithms (e.g. change objectives, work-out the math and implement) As an equal opportunity employer, ICONMA provides an employment environment that supports and encourages the abilities of all persons without regard to race, color, religion, gender, sexual orientation, gender identity or express, ethnicity, national origin, age, disability status, political affiliation, genetics, marital status, protected veteran status, or any other characteristic protected by federal, state, or local laws.",
        "url": "https://www.linkedin.com/jobs/view/3938223553",
        "summary": "NLP Data Scientist needed with 2-4 years experience in NLP programming and a strong background in Python, SQL, data wrangling, and feature engineering. Experience with transformer models, fine-tuning LLMs, and creating language models from scratch is preferred.  This role will focus on building automation solutions, driving decisions, and solving complex business problems using NLP techniques.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Natural Language Processing",
            "Software Development",
            "Finance",
            "Technology"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Decision-making",
            "Collaboration",
            "Critical Thinking",
            "Time Management",
            "Adaptability",
            "Teamwork",
            "Passionate"
        ],
        "hard_skills": [
            "NLP",
            "Classification Modeling",
            "Unsupervised Modeling",
            "Clustering",
            "Topic Modeling",
            "Transformer Models",
            "Python",
            "SQL",
            "Data Mining",
            "Analytics",
            "Data Wrangling",
            "Data Cleaning",
            "Feature Engineering",
            "Entity Recognition",
            "Parts of Speech Tagging",
            "Word Embeddings",
            "Cosine Similarity",
            "ElasticSearch",
            "Semantic Search",
            "Fine-tuning LLMs",
            "Building Language Models",
            "Deep Learning",
            "Phonetics",
            "Word/Paragraph Embeddings",
            "Structured Prediction",
            "Sentiment Analysis",
            "Disambiguation",
            "BERT",
            "LLAMA",
            "Falcon",
            "Mistral",
            "Spark",
            "Hadoop",
            "R",
            "Anaconda",
            "HMMs",
            "CRFs",
            "SVMs",
            "LDA",
            "LSI",
            "MRFs"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "ElasticSearch",
            "BERT",
            "LLAMA",
            "Falcon",
            "Mistral",
            "Spark",
            "Hadoop",
            "R",
            "Anaconda"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "R"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Information Retrieval",
                "Statistics",
                "Applied Math",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Louisville, CO",
        "job_id": 3964438176,
        "company": "Arcfield",
        "title": "Artificial Intelligence/Machine Learning Engineer",
        "created_on": 1720587854.2196152,
        "description": "Overview Arcfield is a leading provider of full lifecycle, mission-focused systems engineering and integration capabilities to the U.S. government and its allies. The company has more than 60 years of proven experience providing advanced engineering and analysis, IT and C5ISR capabilities to support our nation’s most critical national security missions. Headquartered in Chantilly, VA and with 16 offices around the world, Arcfield employs approximately 1,200 engineers, analysts, IT specialists, and other professionals who put our customers’ missions first, helping them solve their most complex challenges through innovations in modeling, simulation and analysis, digital transformation and C5ISR. Visit arcfield.com for more details. Responsibilities Who We Are Atmospheric & Space Technology Research Associates, L.L.C. (dba Orion Space Solutions) was born out of the vision for applying fundamental space physics knowledge to address real-world problems. Founded in 2005, and based in Louisville, Colorado, Orion Space Solutions is a leader in the “New Space” small satellite industry. We leverage our scientific and engineering expertise to develop unique solutions to address complex space physics challenges, including instrumentation, modeling capabilities, and data analytics; Orion Space Solutions turns science into data, data into knowledge. We are scientists, researchers, engineers and businesspeople dedicated to solving global problems that affect how people live, work and play on our planet and in space through applied science backed by empirical knowledge. If you want to be part of a highly collaborative team, work in an amazing environment surrounded by the best and the brightest, solving BIG problems for our planet, read on. This Opportunity Due to our growing success, we are seeking a talented professional to join our team and fill the role of Artificial Intelligence/Machine Learning Engineer located at our offices in Louisville, Colorado. This position seeks an individual with senior level experience in Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) to elevate our science efforts and support our team. In this role you will be able to translate analysis into recommendations that can be shared and acted upon. Develop solutions to routine technical problems. Contribute to completion of technical tasks. Contacts are primarily with immediate supervisor, project leaders, and other professionals in the section or group. Your Impact Apply your knowledge in AI, ML, and DL to improve the way we interact with data. Your passion for developing DL models to analyze data and translating those into recommendations will be critical when working with various teams across the organization. Understanding and applying supervised and unsupervised strategies to real-world science problems keeps your imagination engaged even when not at work. You will be expected to develop training/validation/test data sets, preprocessing scripts, AI models, and evaluation metrics scripts. Additionally, you will be expected to support the development of the infrastructure to support future AI/ML use cases. Qualifications Basic Qualifications BS in Math, Computer Science, Engineering, or similar data science field and 2-4 years of experience or MS and 0-2 years of experience Experience in programming in Python 1-3 years’ experience (each higher-level degree may substitute for two years of experience) Experience with Artificial Intelligence, Machine Learning, and Deep Learning for Generative AI and Predictive AI Experience with Docker and Kubernetes Preferred Qualifications Experience in programming in R, C, or C++ Knowledge of Extract, Translate, and Load (ETL) techniques and procedures Master’s Degree in Math, Computer Science, Engineering, or similar data science field Ability to obtain security clearance Equal Pay Act This is the projected compensation range for this position. There are differentiating factors that can impact a final salary/hourly rate, including, but not limited to, Contract Wage Determination, relevant work experience, skills and competencies that align to the specified role, geographic location (For Remote Opportunities), education and certifications as well as Federal Government Contract Labor categories. In addition, Arcfield invests in its employees beyond just compensation. Arcfield ’s benefits offerings include, dependent upon position, Health Insurance, Life Insurance, Paid Time Off, Holiday Pay, Short Term and Long-Term Disability, Retirement and Savings, Learning and Development opportunities, wellness programs as well as other optional benefit elections. Min: $78,577.41 Max: $188,820.30 EEO Statement EEO Arcfield proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active-Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.",
        "url": "https://www.linkedin.com/jobs/view/3964438176",
        "summary": "Orion Space Solutions is seeking an Artificial Intelligence/Machine Learning Engineer with 2-4 years of experience (or MS and 0-2 years) to develop AI, ML, and DL models to analyze data and translate those into recommendations. The role involves developing training/validation/test data sets, preprocessing scripts, AI models, and evaluation metrics scripts, as well as supporting the development of infrastructure for future AI/ML use cases.",
        "industries": [
            "Aerospace",
            "Space Technology",
            "Research & Development",
            "Data Science",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Analytical Skills",
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Data Analysis",
            "Technical Writing"
        ],
        "hard_skills": [
            "Python",
            "Docker",
            "Kubernetes",
            "Artificial Intelligence",
            "Machine Learning",
            "Deep Learning",
            "Generative AI",
            "Predictive AI",
            "ETL"
        ],
        "tech_stack": [
            "Python",
            "Docker",
            "Kubernetes",
            "AI",
            "ML",
            "DL",
            "Generative AI",
            "Predictive AI",
            "ETL"
        ],
        "programming_languages": [
            "Python",
            "R",
            "C",
            "C++"
        ],
        "experience": 2,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Math",
                "Computer Science",
                "Engineering",
                "Data Science"
            ]
        },
        "salary": {
            "max": 188820,
            "min": 78577
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Paid Time Off",
            "Holiday Pay",
            "Short Term and Long-Term Disability",
            "Retirement and Savings",
            "Learning and Development opportunities",
            "Wellness programs"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3963302019,
        "company": "Smarxion",
        "title": "Data Scientist/Machine Learning Engineer",
        "created_on": 1720587855.844443,
        "description": "What you'll do Deploy and manage on-premise and cloud-based Machine Learning tools Build ML Ops processes to support the development of ML pipelines and the production deployment of models Benchmark and optimize algorithms to provide users with top performance. Develop ML Ops processes to support training and deployment of models based on DevOps and CI/CD principles Partner with Data Scientists to test, validate and deploy Machine Learning and Optimization models Extend existing ML Frameworks, API connectivity and libraries to meet user needs Establish processes by which models can be trained and retrained Partner closely with stakeholders like Data Scientists, Data Engineers, Quality Assurance analysts Required qualifications: 5+ years of experience in an ML Engineer role Experience deploying ML platforms and tools both on-premise and in cloud Bachelor's degree in Computer Science, Information Systems or another applicable field is preferred Experience building and optimizing ML pipelines using DevOps and CI/CD principles Experience training and validating ML pipelines based on model output 3+ years of experience using the following platforms/technologies: Azure or AWS cloud environments Code repository and notebook solutions (Git, Jupyter, etc.) Knowledge of C-family and Python languages, SQL",
        "url": "https://www.linkedin.com/jobs/view/3963302019",
        "summary": "This role involves deploying and managing Machine Learning tools in on-premise and cloud environments, building ML Ops processes for pipeline development and model production, optimizing algorithms for performance, and collaborating with Data Scientists to test, validate, and deploy models. The position requires strong experience in ML engineering, cloud platforms (Azure/AWS), DevOps/CI/CD, and programming languages (C-family, Python, SQL).",
        "industries": [
            "Technology",
            "Machine Learning",
            "Artificial Intelligence",
            "Software Development",
            "Data Science"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-Solving",
            "Optimization",
            "Performance Analysis",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "ML Ops",
            "Model Deployment",
            "Algorithm Optimization",
            "DevOps",
            "CI/CD",
            "Azure",
            "AWS",
            "Git",
            "Jupyter",
            "C-family Languages",
            "Python",
            "SQL"
        ],
        "tech_stack": [
            "Azure",
            "AWS",
            "Git",
            "Jupyter"
        ],
        "programming_languages": [
            "C-family Languages",
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Information Systems"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Alpharetta, GA",
        "job_id": 3963436710,
        "company": "CHEP",
        "title": "Insights Data Scientist",
        "created_on": 1720587859.080427,
        "description": "Position Purpose: The Insights and Strategy team for CHEP Americas is responsible for developing, communicating, and leading the execution of macroeconomic and market analysis used across the business to inform strategic decision making and operational performance. CHEP Americas is currently looking to fill the role of Insights Data Science Manager. The Insights Data Science Manager’s primary focus is to support the development of statistical models connecting macroeconomic and market activities to company performance. They will also create and manage the process for communicating these insights to key stakeholders. Major/Key Accountabilities: Develop and implement advanced statistical models to forecast market trends, consumer behavior, and business outcomes. Use predictive analytics to inform strategic decisions and identify growth opportunities within ideal customer profiles. Analyze diverse data sets to uncover patterns, correlations, and insights. Leverage modeling outcomes to provide actionable recommendations for strategic positioning and operational improvements. Use modeling techniques to analyze competitors’ strategies and predict future market movements. Provide insights on potential competitive advantages and threats. Craft detailed reports and presentations that distill complex models and analyses into understandable and actionable insights. Engage with teams across the organization to provide analytical and modeling support. Ensure that strategic projects are grounded in solid data analysis and predictive insights. Scope: Number of regions: 3 (U.S., Canada and LATAM) Number of locations: Alpharetta, GA USA Challenges/Problem Solving: Problem solving relates to the requirement in the role to analyze, reason and arrive at conclusions to solve problems, identify business opportunities and record learnings. This can be range between routine and patterned (day-to-day within procedures) or more complex in nature requiring analytical and innovative solutions. Authority/Decision Making: Working autonomously with limited day-to-day interaction with line manager Working in a matrixed environment Recommends budgetary spend Key Contacts: Internal - Marketing, Strategy, Senior Leadership, Commercial, Retails and Operations. External - N/A Qualifications: Programming skills: R, Python (Pandas, NumPy, SciPy) Experience with Nielsen Discover platform and consumer packaged goods industry Experience: Experience in a role focused on quantitative analysis, statistical modelling, or data science, preferably with exposure to strategic analysis or market research. Demonstrated experience in developing and implementing predictive models and conducting complex data analyses in a business context. A portfolio of projects that showcases the ability to turn data and modelling into strategic insights and recommendations. Ability to analyze and apply learnings to business context and effectively communicate insights to business Skills and Knowledge: Statistical modeling, programming, and cross-functional communication skills. Languages: Essential - English Desirable - Spanish Base pay starting at $92,000.00/annual Salary ranges provided take into account a wide variety of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications, geographic differentials and other business and organizational needs. Therefore, actual amounts offered may be higher or lower than the range provided. If you have questions, please speak to your Talent Acquisition Partner about the flexibility and detail of our compensation philosophy. Dependent on the position offered, other forms of compensation may be part of a total offering beyond medical & retirement benefits and may include other monetary incentives or business benefits.",
        "url": "https://www.linkedin.com/jobs/view/3963436710",
        "summary": "The Insights Data Science Manager role at CHEP Americas involves developing and implementing advanced statistical models to forecast market trends, consumer behavior, and business outcomes. This role uses predictive analytics to inform strategic decisions and identify growth opportunities, analyzes diverse data sets to uncover patterns and insights, and crafts detailed reports and presentations to communicate actionable insights. The position requires experience in quantitative analysis, statistical modeling, and data science, preferably with exposure to strategic analysis or market research.",
        "industries": [
            "Consumer Packaged Goods",
            "Supply Chain",
            "Logistics",
            "Data Science",
            "Market Research",
            "Analytics",
            "Strategy"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical",
            "Strategic Thinking",
            "Collaboration",
            "Presentation Skills",
            "Time Management",
            "Project Management",
            "Decision Making"
        ],
        "hard_skills": [
            "R",
            "Python",
            "Pandas",
            "NumPy",
            "SciPy",
            "Statistical Modeling",
            "Predictive Analytics",
            "Data Analysis",
            "Market Trend Forecasting",
            "Consumer Behavior Analysis",
            "Business Outcome Forecasting",
            "Competitive Analysis",
            "Report Writing",
            "Presentation Development"
        ],
        "tech_stack": [
            "Nielsen Discover",
            "R",
            "Python",
            "Pandas",
            "NumPy",
            "SciPy"
        ],
        "programming_languages": [
            "R",
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Statistics",
                "Data Science",
                "Mathematics",
                "Economics",
                "Business Analytics"
            ]
        },
        "salary": {
            "max": 92000,
            "min": 92000
        },
        "benefits": [
            "Medical",
            "Retirement"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967153931,
        "company": "ISoftech Inc",
        "title": "Data Scientist",
        "created_on": 1720587860.7308724,
        "description": "Ability to obtain and maintain Public trust clearance required • Bachelor’s degree in data science, computer science, analytics or other field. • 10 years’ experience in: o Data and analytics projects using data applications to develop insights from large datasets o Handling large datasets • 2 years’ experience in: o JIRA, GitHub and Confluence o Statistical software and database management software packages (e.g., R, Python, SAS) o Cloud platforms o Relational databases and data warehousing (e.g., OLAP, dimensional modeling) o Creating dashboards that contain visuals and tables using Tableau with Databricks o Creating and maintaining datasets from disparate data sources and providing analysis utilizing SQL and Databricks o Agile methodology. • Create and maintain datasets from disparate data sources and provide analysis there of using SQL and Databricks within an Azure Cloud Environment • Utilizing Tableau in a Databricks Azure Cloud Environment, create dashboards containing visuals (e.g.: charts, graphs) and tables that allow end-users to slice-and-dice data to gain insights to various business processes",
        "url": "https://www.linkedin.com/jobs/view/3967153931",
        "summary": "Data Scientist with 10+ years experience in data analytics and handling large datasets. Proven expertise in using data applications to extract insights, working with cloud platforms, relational databases, and data warehousing. Strong skills in R, Python, SAS, SQL, Databricks, Tableau, and Agile methodology.",
        "industries": [
            "Data Science",
            "Analytics",
            "Information Technology",
            "Government"
        ],
        "soft_skills": [
            "Analytical Skills",
            "Problem Solving",
            "Communication Skills",
            "Collaboration",
            "Data Visualization"
        ],
        "hard_skills": [
            "Data Analytics",
            "Data Applications",
            "Large Datasets",
            "JIRA",
            "GitHub",
            "Confluence",
            "R",
            "Python",
            "SAS",
            "Cloud Platforms",
            "Relational Databases",
            "Data Warehousing",
            "OLAP",
            "Dimensional Modeling",
            "Tableau",
            "Databricks",
            "SQL",
            "Agile Methodology",
            "Azure Cloud"
        ],
        "tech_stack": [
            "JIRA",
            "GitHub",
            "Confluence",
            "R",
            "Python",
            "SAS",
            "Tableau",
            "Databricks",
            "SQL",
            "Azure Cloud"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SAS",
            "SQL"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Analytics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Boston, MA",
        "job_id": 3969887366,
        "company": "Synergy Interactive",
        "title": "Machine Learning Engineer",
        "created_on": 1720587862.2758772,
        "description": "Responsibilities: Design and implement machine learning models and algorithms to address business challenges. Develop, test, and deploy AI solutions in production environments. Collaborate with data scientists, software engineers, and product managers to integrate AI capabilities into products. Analyze large datasets to extract actionable insights and inform decision-making. Continuously monitor and improve the performance of deployed models. Stay up-to-date with the latest advancements in AI and machine learning technologies. Document processes, models, and results for future reference and reproducibility. Provide technical guidance and mentorship to junior team members. Basic Qualifications: Bachelor's or Master's degree in Computer Science, Engineering, Mathematics, or a related field. 3+ years of experience in machine learning, artificial intelligence, or a related field. Proficiency in programming languages such as Python, R, or Java. Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Strong understanding of statistical analysis and data mining techniques. Experience with data preprocessing, feature engineering, and model evaluation. Ability to work in a fast-paced environment and manage multiple projects simultaneously. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills.",
        "url": "https://www.linkedin.com/jobs/view/3969887366",
        "summary": "This job involves designing and implementing machine learning models for business challenges, developing and deploying AI solutions, collaborating with data scientists and engineers, analyzing large datasets, monitoring model performance, staying up-to-date with AI advancements, documenting processes, and mentoring junior team members.",
        "industries": [
            "Technology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Software Development",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Attention to Detail",
            "Time Management",
            "Mentorship"
        ],
        "hard_skills": [
            "Machine Learning",
            "Artificial Intelligence",
            "Python",
            "R",
            "Java",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Statistical Analysis",
            "Data Mining",
            "Data Preprocessing",
            "Feature Engineering",
            "Model Evaluation"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "scikit-learn"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Java"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3964686094,
        "company": "Buyers Edge Platform",
        "title": "Data Scientist",
        "created_on": 1720587870.3047771,
        "description": "Who are we? Buyers Edge Platform stands at the forefront of revolutionizing the foodservice industry through technology, purchasing power and partnerships. We are dedicated to empowering stakeholders across the entire foodservice ecosystem (operators, distributors, manufacturers) with efficiency and unprecedented visibility. With a diverse portfolio of over a dozen brands, our mission is clear: to reduce costs, streamline the foodservice supply chain, and propel the industry from manual to automated. Today, we are one of the largest players in foodservice, with over 200K operator locations across North America and over $50 billion of aggregated spend volume. Our commitment to foodservice excellence is proven in four distinct areas of value: Digital Procurement Network, Fresh Solutions, Supply Chain Management, and Software. Buyers Edge Platform is not just a provider – we are a strategic partner on the journey towards a more efficient, connected, and automated future for the foodservice industry. This position is remote and based around East Coast working hours. We are unable to offer work sponsorship for this role. We are seeking an experienced Data Scientist that enjoys diving into vast datasets, tackling intricate data preprocessing tasks, and conveying complex systems and algorithms to stakeholders. As a pivotal member of our organization, you will be at the forefront of developing cutting-edge machine learning algorithms, crafting robust data pipelines, and deriving valuable insights, including predictive suggestions on purchased data. Your impact: Machine Learning Algorithm Development and Predictive Modeling: Utilize your expertise in machine learning to develop algorithms that analyze and interpret large datasets. Design and implement models that provide valuable insights, predictive suggestions, and accurate forecasting on consumer behavior, product preferences, and market trends. Data Pipeline Development and Data Handling: Design, implement, and maintain data pipelines to extract, transform, and load data from various sources. Process and manipulate large amounts of data efficiently, ensuring data integrity, quality, and availability. Implement data preprocessing techniques as part of the data pipeline to prepare datasets for analysis and modeling. Data Analysis and Exploration: Conduct thorough data analysis and exploration to identify patterns, trends, and anomalies within large datasets. Utilize statistical techniques and visualization tools to uncover meaningful insights and drive data-driven decision-making. Independent Problem Solving: Work independently on complex systems and algorithms, demonstrating strong problem-solving skills and the ability to handle challenges effectively. Take ownership of projects and drive them to successful completion, meeting both technical and business objectives. Communication and Stakeholder Engagement: Effectively communicate complex technical concepts and the results of your analyses to stakeholders. Articulate the intricacies of systems, algorithms, and insights in a clear and concise manner, enabling stakeholders to make informed decisions. Collaboration and Teamwork: Collaborate with cross-functional teams, including data engineers, business analysts, and domain experts, to gather requirements, understand business objectives, and align data science initiatives with organizational goals. About you: Bachelor's or Master’s degree in computer science, statistics, mathematics, or a related field. 2-5 years’ experience in a data science role. Proficiency in programming languages such as Python. Pandas experience required. Strong knowledge of machine learning algorithms and libraries (e.g., scikit-learn, TensorFlow, PyTorch). Experience working with large datasets and developing data pipelines for data extraction, transformation and loading. Proficiency in pandas for efficient data handling and manipulation. Strong analytical and problem-solving skills with the ability to think creatively and propose innovative solutions. Attention to detail and a passion for working with complex datasets. Excellent written and verbal communication skills, with the ability to effectively communicate complex technical concepts to both technical and non-technical stakeholders. Experience presenting finding and insights to stakeholders at various levels of the organization. Demonstrated ability to work independently on complex systems and algorithms. Strong teamwork and collaboration skills, with the ability to work effectively with cross-functional teams and stakeholders. What's in this for you? Amazing coverages to start. Medical, dental, and vision coverages are just the beginning! We also offer ancillary plans, such as flexible spending accounts for both health and dependent care, critical illness, accident, and voluntary life as well as company paid life and long-term-disability plans! On top of this, we also offer a 401(k) plan with company match. Invest in your success. We will provide you with a thorough training and development program; and offer competitive compensation. Live well = Work well. Relax with our Personal Responsibility Paid Time Off policy where you don’t have to accrue time off in order to take it! We also offer half-day Summer Fridays! We welcome all. We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race, color, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth and pregnancy-related conditions), gender identity or expression (including transgender status), sexual orientation, marital status, military service and veteran status, physical or mental disability, genetic information, or any other characteristic protected by applicable federal, state or local laws and ordinances.",
        "url": "https://www.linkedin.com/jobs/view/3964686094",
        "summary": "Buyers Edge Platform is seeking a Data Scientist to develop cutting-edge machine learning algorithms, craft robust data pipelines, and derive valuable insights from large datasets. The role involves designing and implementing predictive models on consumer behavior, product preferences, and market trends, developing and maintaining data pipelines, conducting data analysis and exploration, and collaborating with cross-functional teams.",
        "industries": [
            "Foodservice",
            "Technology",
            "Supply Chain Management",
            "Software"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Teamwork",
            "Analytical",
            "Creative",
            "Detail-Oriented"
        ],
        "hard_skills": [
            "Machine Learning",
            "Python",
            "Pandas",
            "Scikit-learn",
            "TensorFlow",
            "PyTorch",
            "Data Pipelines",
            "Data Extraction",
            "Data Transformation",
            "Data Loading",
            "Data Analysis",
            "Data Visualization",
            "Statistical Techniques"
        ],
        "tech_stack": [
            "Python",
            "Pandas",
            "Scikit-learn",
            "TensorFlow",
            "PyTorch"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Flexible Spending Accounts",
            "Critical Illness",
            "Accident",
            "Life Insurance",
            "Long-Term Disability",
            "401(k) with Company Match",
            "Paid Time Off",
            "Summer Fridays"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3971392878,
        "company": "Offered.ai",
        "title": "Data Scientist",
        "created_on": 1720587871.8900833,
        "description": "Click the 'Apply' button to learn more about RingCentral and the role. Then, you can choose to apply directly with RingCentral or use AI to assist your application powered by Offered. Say hello to possibilities. It’s not everyday that you consider starting a new career. We’re RingCentral, and we’re happy that someone as talented as you is considering this role. First, a little about us, we’re the $2 billion global leader in cloud-based communications and collaboration software. We are fundamentally changing the nature of human interaction— giving people the freedom to connect powerfully and personally from anywhere, at any time, on any device. This is where you and your skills come in. We’re currently looking for: Responsible for applying data mining techniques, completing statistical analysis and building high-quality prediction systems integrated with RingCentral’s products. To succeed in this role you must meet the following requirements: Analyzing complex processes and translating them into business and functional requirements for Analytics use by RingCentral’s customers Working closely with Network Operations, Systems Operations, Product, Sales and Marketing teams to understand business problems and develop suitable predictive models Data collection, data mining, cleansing and verifying the integrity of data that is fed to predictive models Performing ad-hoc data analysis and presenting results in clear manner Utilizing cutting-edge technology including Hadoop, Hive, Machine Learning and Deep Learning to ingest network and call data for products including Glip, RC Meetings and multiple databases Developing predictive models based on network traffic data and call data to analyze outages and possible security exploits using machine learning and deep learning Designing and developing predictive and prescriptive models for churn prediction and product adoption depending on customer usage data Analyzing the network and system level security threats depending on data and network logs for telephony and RC Meetings applications Desired Qualifications: U.S. Master’s degree in Computer Science, Electrical Engineering or a related field, or foreign equivalent, plus two (2) years of related experience, or a U.S. Bachelor’s degree or equivalent in Computer Science, Electrical Engineering or a related field plus five (5) years of related experience, is required. Experience with data MySQL, Hadoop, Redshift, Statistics, Machine Learning, Java, Python, R, Linux, Informatica Power Center, Salesforce, Oracle Netsuite, Streamsets, and Tableau is required. What we offer: Comprehensive medical, dental, vision, disability, life insurance Health Savings Account (HSA), Flexible Spending Account (FSAs) and Commuter benefits 401K match and ESPP Paid time off and paid sick leave Wellness programs including 1:1 coaching and meditation guidance Paid parental and pregnancy leave and new parent gift boxes Family-forming benefits (IVF, Preservation, Adoption etc.) Emergency backup care (Child/Adult/Pets) Parental support for children with developmental and learning disabilities Pet insurance Employee Assistance Program (EAP) with counseling sessions available 24/7 Free legal services that provide legal advice, document creation and estate planning Employee bonus referral program Student loan refinancing assistance Employee perks and discounts program RingCentral’s work culture is the backbone of our success. And don’t just take our word for it: we are recognized as a Best Place to Work by Glassdoor, the Top Work Culture by Comparably and hold local BPTW awards in every major location. Bottom line: We are committed to hiring and retaining great people because we know you power our success. RingCentral offers on-site, remote and hybrid work options optimized for the ways we work and live now. About RingCentral RingCentral, Inc. (NYSE: RNG) is a leading provider of business cloud communications and contact center solutions based on its powerful Message Video PhoneTM (MVPTM) global platform. More flexible and cost effective than legacy on-premises PBX and video conferencing systems that it replaces, RingCentral® empowers modern mobile and distributed workforces to communicate, collaborate, and connect via any mode, any device, and any location. RingCentral is headquartered in Belmont, California, and has offices around the world. RingCentral is an equal opportunity employer that truly values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. This posting is pursuant to and is in compliance with the applicable federal rules of the U.S. Department of Labor regulations. Benefits may include, but are not limited to, health and wellness, 401k, ESPP, vacation, parental leave, and more! The salary may vary depending on your location, skills, and experience. We hire for this role frequently. There is no application deadline for this role.",
        "url": "https://www.linkedin.com/jobs/view/3971392878",
        "summary": "RingCentral, a global leader in cloud-based communications and collaboration software, is seeking a Data Scientist to develop predictive models and analyze data related to network traffic, call data, customer usage, and security threats. This role involves utilizing cutting-edge technologies like Hadoop, Hive, Machine Learning, and Deep Learning to build high-quality prediction systems integrated with RingCentral's products.",
        "industries": [
            "Software",
            "Technology",
            "Telecommunications",
            "Cloud Computing",
            "Data Science",
            "Machine Learning",
            "Deep Learning",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Data Analysis",
            "Presentation Skills"
        ],
        "hard_skills": [
            "Data Mining",
            "Statistical Analysis",
            "Predictive Modeling",
            "Hadoop",
            "Hive",
            "Machine Learning",
            "Deep Learning",
            "MySQL",
            "Redshift",
            "Statistics",
            "Java",
            "Python",
            "R",
            "Linux",
            "Informatica Power Center",
            "Salesforce",
            "Oracle Netsuite",
            "Streamsets",
            "Tableau"
        ],
        "tech_stack": [
            "Hadoop",
            "Hive",
            "Machine Learning",
            "Deep Learning",
            "MySQL",
            "Redshift",
            "Java",
            "Python",
            "R",
            "Linux",
            "Informatica Power Center",
            "Salesforce",
            "Oracle Netsuite",
            "Streamsets",
            "Tableau"
        ],
        "programming_languages": [
            "Java",
            "Python",
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Electrical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Disability",
            "Life Insurance",
            "Health Savings Account",
            "Flexible Spending Account",
            "Commuter Benefits",
            "401K Match",
            "ESPP",
            "Paid Time Off",
            "Paid Sick Leave",
            "Wellness Programs",
            "Parental Leave",
            "Pregnancy Leave",
            "New Parent Gift Boxes",
            "Family-Forming Benefits",
            "Emergency Backup Care",
            "Parental Support",
            "Pet Insurance",
            "Employee Assistance Program",
            "Legal Services",
            "Employee Bonus Referral Program",
            "Student Loan Refinancing Assistance",
            "Employee Perks and Discounts Program"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3962840124,
        "company": "GlobalLogic",
        "title": "Senior Data Scientist",
        "created_on": 1720587873.2124805,
        "description": "Description: Master machine learning algorithms including forecasting, clustering, classification, reinforcement learning, deep learning, etc Data extraction/transformation/loading, text mining, and statistical analysis experience is required 5+ years’ experience with Python, R, Matlab, VBA, and Java Scripts. Requirements: Master or PhD Degree (Preferred) or Bachelor in Electrical Engineering, Computer Science, Math, Statistics, etc. 5+ years of machine learning experience in a professional role Must have proven records of papers published in wireless analytics space in IEEE or other effective journals Preferences: Perform data analytics and quantitative modeling for devices and wireless networks to improve device performance, quality, user quality of experience, and quality of service. Perform device analytics on device performance, RF performance, device quality, device antenna performance, device readiness, etc. Statistical modeling of wireless network and device QoS/KPI/KQI, user behaviors. Visualize the analytical results using data visualization tools. Job Responsibilities: 5+ years’ experience with Spark, Hadoop, MySQL, MS Excel, VBA, TeraData SQL, and MS SQL. Expertise in system performance fine-tuning of the database schema is required Strong analytical capabilities, creativity, and critical thinking required Good mobile telecommunications industry knowledge, including experience with handset manufacturers, network equipment vendors, and/or chipset vendors What We Offer Exciting Projects: Come take your place at the forefront of digital transformation! With clients across all industries and sectors, we offer an opportunity to work on market-defining products using the latest technologies. Collaborative Environment: You can expand your skills by collaborating with a diverse team of highly talented people in an open, laidback environment — or even abroad in one of our global centers or client facilities! Work-Life Balance: GlobalLogic prioritizes work-life balance, which is why we offer flexible work schedules and opportunities to work from home. Professional Development: We provide continuing education classes, professional certification and training (technical, soft skills, language, and communication skills) to help you realize your professional goals. Being part of a global organization, there are additional learning opportunities through international knowledge exchanges. Excellent Benefits: We provide our employees with competitive salaries, health and life insurance, short-term and long-term disability insurance, a matched contribution 401K plan, flexible spending accounts, and PTO and holidays About GlobalLogic GlobalLogic is a leader in digital engineering. We help brands across the globe design and build innovative products, platforms, and digital experiences for the modern world. By integrating experience design, complex engineering, and data expertise—we help our clients imagine what’s possible, and accelerate their transition into tomorrow’s digital businesses. Headquartered in Silicon Valley, GlobalLogic operates design studios and engineering centers around the world, extending our deep expertise to customers in the automotive, communications, financial services, healthcare and life sciences, manufacturing, media and entertainment, semiconductor, and technology industries. GlobalLogic is a Hitachi Group Company operating under Hitachi, Ltd. (TSE: 6501) which contributes to a sustainable society with a higher quality of life by driving innovation through data and technology as the Social Innovation Business.",
        "url": "https://www.linkedin.com/jobs/view/3962840124",
        "summary": "GlobalLogic is looking for a Machine Learning Engineer with 5+ years' experience in machine learning, data extraction/transformation/loading, text mining, statistical analysis, and proficiency in Python, R, Matlab, VBA, and JavaScript. The ideal candidate will have a Master's or PhD degree in Electrical Engineering, Computer Science, Math, Statistics, or a related field.  They should have a proven track record of publishing papers in wireless analytics in IEEE or other journals.  The position involves performing data analytics and quantitative modeling for devices and wireless networks, device analytics, statistical modeling of wireless networks and devices, and visualizing analytical results. Experience with Spark, Hadoop, MySQL, MS Excel, VBA, TeraData SQL, and MS SQL is required.  Strong analytical capabilities, creativity, critical thinking, and knowledge of the mobile telecommunications industry are essential.",
        "industries": [
            "Telecommunications",
            "Technology",
            "Wireless",
            "Data Analytics",
            "Machine Learning"
        ],
        "soft_skills": [
            "Analytical skills",
            "Creativity",
            "Critical thinking",
            "Communication skills"
        ],
        "hard_skills": [
            "Machine Learning",
            "Forecasting",
            "Clustering",
            "Classification",
            "Reinforcement Learning",
            "Deep Learning",
            "Data Extraction",
            "Data Transformation",
            "Data Loading",
            "Text Mining",
            "Statistical Analysis",
            "Python",
            "R",
            "Matlab",
            "VBA",
            "JavaScript",
            "Spark",
            "Hadoop",
            "MySQL",
            "MS Excel",
            "TeraData SQL",
            "MS SQL",
            "System Performance Tuning",
            "Data Visualization"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Matlab",
            "VBA",
            "JavaScript",
            "Spark",
            "Hadoop",
            "MySQL",
            "MS Excel",
            "TeraData SQL",
            "MS SQL"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Matlab",
            "VBA",
            "JavaScript"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor",
            "fields": [
                "Electrical Engineering",
                "Computer Science",
                "Math",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "Health and life insurance",
            "Short-term and long-term disability insurance",
            "Matched contribution 401K plan",
            "Flexible spending accounts",
            "PTO and holidays",
            "Flexible work schedules",
            "Work from home opportunities",
            "Continuing education classes",
            "Professional certification and training",
            "International knowledge exchanges"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3960911769,
        "company": "Augment Jobs",
        "title": "AI Research Scientist",
        "created_on": 1720587874.681692,
        "description": "Job Description We are seeking a talented and innovative AI Research Scientist to join our research team. As an AI Research Scientist, you will conduct cutting-edge research in artificial intelligence, machine learning, and related fields. You will collaborate with a multidisciplinary team to develop novel algorithms, models, and systems that address challenging problems and drive innovation in AI technologies. Roles And Responsibilities Research and Development: Conduct research in artificial intelligence, machine learning, deep learning, and other AI-related fields; explore new methodologies, algorithms, and techniques. Algorithm Design: Design and develop novel AI algorithms, models, and architectures to solve complex problems and improve performance in specific domains. Data Analysis: Analyze large-scale datasets to derive insights, identify patterns, and validate hypotheses; preprocess and curate data for machine learning experiments. Model Training and Evaluation: Implement and experiment with machine learning models and algorithms using frameworks such as TensorFlow, PyTorch, or similar; evaluate model performance and optimize for accuracy and efficiency. Prototyping and Experimentation: Develop prototypes and proof of concepts to demonstrate the feasibility and effectiveness of new AI techniques and applications. Collaboration and Communication: Collaborate with cross-functional teams including software engineers, data scientists, and product managers; communicate research findings and insights effectively. Publication and Thought Leadership: Publish research findings in top conferences and journals; contribute to the scientific community through presentations, papers, and open-source contributions. Ethical AI Development: Ensure ethical considerations are integrated into AI research and development processes; promote responsible AI practices and transparency. Skills And Qualifications PhD or Master’s degree in Computer Science, Artificial Intelligence, Machine Learning, or related field; significant research experience may substitute for formal education. Proven track record (X years) of conducting research in AI, machine learning, deep learning, or related fields, with a strong publication record in top-tier conferences or journals. Expertise in developing and implementing AI algorithms and models using frameworks such as TensorFlow, PyTorch, or similar. Solid understanding of statistical methods, data analysis techniques, and experimental design principles. Proficiency in programming languages such as Python, C++, or Java for algorithm development and experimentation. Strong analytical and problem-solving skills, with the ability to innovate and drive technical solutions independently. Excellent communication and collaboration skills, with the ability to work effectively in a team environment. Passion for AI research, with a desire to push the boundaries of knowledge and technology in artificial intelligence. Compensation Competitive salary based on experience and qualifications. Comprehensive benefits package including health insurance, retirement plans, and professional development opportunities. Flexible work schedule and potential for remote work options. Application Process Interested candidates are invited to submit a resume and cover letter outlining their qualifications, research experience in AI, and why they are interested in joining [Company Name]. We look forward to reviewing your application and discussing how your research expertise can contribute to our AI research initiatives and technological advancements. This job description for an AI Research Scientist role emphasizes responsibilities related to AI research, algorithm design, data analysis, model training, and ethical AI development within an organization. It aims to attract candidates with strong research credentials, expertise in AI technologies, and a passion for advancing the field of artificial intelligence. Adjustments can be made based on specific company needs or additional requirements for the role.",
        "url": "https://www.linkedin.com/jobs/view/3960911769",
        "summary": "We are seeking a talented and innovative AI Research Scientist to join our research team. You will conduct cutting-edge research in artificial intelligence, machine learning, and related fields. You will collaborate with a multidisciplinary team to develop novel algorithms, models, and systems that address challenging problems and drive innovation in AI technologies.",
        "industries": [
            "Artificial Intelligence",
            "Machine Learning",
            "Deep Learning",
            "Computer Science",
            "Technology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-Solving",
            "Innovation",
            "Analytical",
            "Teamwork",
            "Passion",
            "Ethical"
        ],
        "hard_skills": [
            "TensorFlow",
            "PyTorch",
            "Python",
            "C++",
            "Java",
            "Algorithm Design",
            "Machine Learning",
            "Deep Learning",
            "Data Analysis",
            "Statistical Methods",
            "Experimental Design",
            "Model Training",
            "Data Preprocessing"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch"
        ],
        "programming_languages": [
            "Python",
            "C++",
            "Java"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master’s degree",
            "fields": [
                "Computer Science",
                "Artificial Intelligence",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Retirement Plans",
            "Professional Development",
            "Flexible Work Schedule",
            "Remote Work Options"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3959974310,
        "company": "SLB",
        "title": "Data Scientist",
        "created_on": 1720587876.1335876,
        "description": "Full-time or part-time: Full-time Job title: Data Scientist Job Location: 1430 Enclave Parkway, Houston, TX 77077 Job Description : Conduct undirected research and tackle open-ended data problems and questions. Invent new algorithms to solve data problems. Research and assess next-generation technologies for machinery diagnostics and prognostics and data-driven modeling and optimization of complex systems. Demonstrate advanced working knowledge and experience with machine learning algorithms and population-based meta-heuristic optimization methods. Generate innovative ideas, establish new research directions, and shape and execute technical projects. Maintain state-of-the-art knowledge and contribute to technical discussions and reviews as an expert in related areas of responsibility. Apply theoretical knowledge to solve industrial problems. Apply engineering knowledge in developing data-driven algorithms for anomaly detection, failure prediction and optimization. Collaborate with field and product engineers to identify key health monitoring parameters of a system. Process large multivariate data sets collected from equipment operations, manufacturing tests and diagnostic routines. Communicate ideas, plans and results effectively via oral and written reports. Minimum Education & Experience Requirements: Must have a Master’s Degree, or foreign educational equivalent, in Computer Science, Management Information Systems, or other closely related IT field. Must have 4 years of postbaccalaureate experience as a Software Engineer, Developer, Data Analyst or a closely related IT role. The 4 years of experience must include experience with AngularJS; Typescript; Python; Plotly; Linux; Perl; Flask; API; SQL; Anova (Analysis of Variance); Regression and Correlation Analysis; Exponential Smoothing; Tableau; ETL; Data Visualization (Dash); Microservices; and Git. Must have a Master’s Degree, or foreign educational equivalent, in Computer Science, Management Information Systems, or other closely related IT field. Must have 4 years of postbaccalaureate experience as a Software Engineer, Developer, Data Analyst or a closely related IT role. The 4 years of experience must include experience with AngularJS; Typescript; Python; Plotly; Linux; Perl; Flask; API; SQL; Anova (Analysis of Variance); Regression and Correlation Analysis; Exponential Smoothing; Tableau; ETL; Data Visualization (Dash); Microservices; and Git.",
        "url": "https://www.linkedin.com/jobs/view/3959974310",
        "summary": "Data Scientist to conduct research, invent algorithms, and analyze data for machinery diagnostics and prognostics. Requires 4+ years of experience with AngularJS, Typescript, Python, Plotly, Linux, Perl, Flask, API, SQL, Anova, Regression, Exponential Smoothing, Tableau, ETL, Data Visualization, Microservices, and Git.",
        "industries": [
            "Technology",
            "Engineering",
            "Manufacturing",
            "Data Science",
            "Research"
        ],
        "soft_skills": [
            "Research",
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Innovation"
        ],
        "hard_skills": [
            "Machine Learning",
            "Metaheuristic Optimization",
            "Anomaly Detection",
            "Failure Prediction",
            "Optimization",
            "Multivariate Data Analysis",
            "Data Visualization"
        ],
        "tech_stack": [
            "AngularJS",
            "Typescript",
            "Python",
            "Plotly",
            "Linux",
            "Perl",
            "Flask",
            "API",
            "SQL",
            "Anova",
            "Regression",
            "Exponential Smoothing",
            "Tableau",
            "ETL",
            "Data Visualization",
            "Microservices",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "Perl",
            "SQL"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Master's Degree",
            "fields": [
                "Computer Science",
                "Management Information Systems",
                "IT"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Huntsville, AL",
        "job_id": 3959952863,
        "company": "Spry Methods, Inc.",
        "title": "Junior Data Scientist",
        "created_on": 1720587877.9180684,
        "description": "Who We’re Looking For (Position Overview): Spry Methods is on the search for a Junior Data Scientist to join our team in Huntsville, AL. What Your Day-To-Day Looks Like (Position Responsibilities): Assist in the development and deployment of machine learning models Analyze data to uncover patterns and insights Support data preprocessing and feature engineering activities Collaborate with cross-functional teams to implement data-driven solutions What You Need to Succeed (Minimum Requirements): Top Secret Clearance is Required Bachelor’s degree in Data Science, Statistics, or related field 1-3 years of experience in data science Proficiency with Python, R, and machine learning libraries Strong analytical and problem-solving skills AWS Associate level certification highly desired",
        "url": "https://www.linkedin.com/jobs/view/3959952863",
        "summary": "Spry Methods is seeking a Junior Data Scientist in Huntsville, AL. Responsibilities include developing and deploying machine learning models, analyzing data, data preprocessing, feature engineering, and collaborating with cross-functional teams. Requires Top Secret Clearance, a Bachelor's degree in Data Science, Statistics, or a related field, 1-3 years of experience, proficiency in Python, R, and machine learning libraries, strong analytical and problem-solving skills, and AWS Associate level certification is highly desired.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Analytics",
            "Software Development",
            "Defense",
            "Government"
        ],
        "soft_skills": [
            "Analytical",
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "R",
            "Machine Learning",
            "AWS",
            "Data Preprocessing",
            "Feature Engineering"
        ],
        "tech_stack": [
            "Python",
            "R",
            "AWS"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greater Cleveland",
        "job_id": 3964850140,
        "company": "Forsyth Barnes",
        "title": "Forecasting Data Scientist",
        "created_on": 1720587879.4037197,
        "description": "Title: Data Scientist (Time-Series Forecasting) Location: Cleveland, Ohio (3 days/week) Salary: Up to $135,000 For this role we cannot work with C2C agencies or provide sponsorship such as an H1B. We are currently working with a global manufacturing & retail client that is looking to add some additional talent into their Data Science & Analytics organization. In this position they are looking for a candidate with a focus on Time-Series Modelling that would work on use cases across the enterprise. Key Requirements: 3-5 years of experience working professionally within Data Science or Advanced Analytics Positions 3+ years of experience working with Python, SAS or R and SQL 1+ years specializing in time-series forecasting methods such as ARIMA, Tide, Prophet, etc Preferred experience working within a Manufacturing or Retail Business Bachelor’s degree in Mathematics, Statistics, Computer Science or related field required. Preferred Master’s or PhD.",
        "url": "https://www.linkedin.com/jobs/view/3964850140",
        "summary": "A global manufacturing and retail company is seeking a Data Scientist specializing in Time-Series Forecasting to work on various use cases across the enterprise. This role requires 3-5 years of experience in Data Science or Advanced Analytics, 3+ years in Python, SAS or R and SQL, and 1+ years specializing in time-series forecasting methods like ARIMA, Tide, Prophet, etc. Preference is given to candidates with experience in manufacturing or retail industries. A Bachelor's degree in Mathematics, Statistics, Computer Science or related field is required, with a Master's or PhD preferred. The position is based in Cleveland, Ohio, with a salary of up to $135,000.",
        "industries": [
            "Manufacturing",
            "Retail"
        ],
        "soft_skills": [],
        "hard_skills": [
            "Python",
            "SAS",
            "R",
            "SQL",
            "ARIMA",
            "Tide",
            "Prophet"
        ],
        "tech_stack": [
            "Time-Series Forecasting"
        ],
        "programming_languages": [
            "Python",
            "SAS",
            "R",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 135000,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Charlotte, NC",
        "job_id": 3963997776,
        "company": "Eliassen Group",
        "title": "Data Scientist",
        "created_on": 1720587883.4732592,
        "description": "Our client, a utility industry leader, needs a dedicated Data Scientist to provide expertise, guidance, and hands-on support in translating complex data into key strategic insights. Due to client requirement, applicants must be willing and able to work on a w2 basis. For our w2 consultants, we offer a great benefits package that includes Medical, Dental, and Vision benefits, 401k with company matching, and life insurance. Responsibilities of the Data Scientist: Support data science consulting efforts Help translate complex data into key strategy insights and actions Present business narratives as told be data and present to business stakeholders Develop and test heuristics, create and run models, perform data exploration and data mining Solve predictive and prescriptive problems Requirements of the Data Scientist: Master's degree in analytics, computer science, or equivalent and 5+ years of experience Solid background and understanding of advanced mathematics, statistical and machine learning models, and algorithms Experience building and delivering enterprise scale software Understanding and ability to use SQL and python for accessing and wrangling data Effective communication skills with the ability to liaise between business and technical teams Please be advised- If anyone reaches out to you about an open position connected with Eliassen Group, please confirm that they have an Eliassen.com email address and never provide personal or financial information to anyone who is not clearly associated with Eliassen Group. If you have any indication of fraudulent activity, please contact InfoSec@eliassen.com.",
        "url": "https://www.linkedin.com/jobs/view/3963997776",
        "summary": "A utility industry leader is seeking a Data Scientist to translate complex data into strategic insights, build models, and present findings to stakeholders. Requires a Master's degree in analytics or computer science and 5+ years of experience.",
        "industries": [
            "Utility",
            "Data Science",
            "Consulting"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Presentation",
            "Collaboration"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Statistical Modeling",
            "Data Mining",
            "Predictive Modeling",
            "Prescriptive Modeling",
            "SQL",
            "Python"
        ],
        "tech_stack": [
            "SQL",
            "Python"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Analytics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401k with company matching",
            "Life Insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "McLean, VA",
        "job_id": 3959942896,
        "company": "Noblis",
        "title": "Data Scientist (All Levels)",
        "created_on": 1720587887.5269563,
        "description": "Responsibilities Noblis is seeking a technical thinker and doer to work as a Data Scientist within a highly dynamic and impactful operating environment located in McLean, VA. The Data Scientist Will Acquire data from primary or secondary data sources and maintain databases/data systems. Structure large data sets to find usable information using Information Technology. Design, develop, implement and databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality. Troubleshoot data; Provide quality assurance of imported data, working with quality assurance analyst if necessary. Identify, analyze, and interpret trends or patterns in complex data sets; Make predictions based on data trends. Assess tests and implement new or upgraded software and assist with strategic decisions on new systems. Help establish key performance indicators to measure the effectiveness of business decisions. Monitor performance and quality control plans to identify improvements; Support initiatives for data integrity and normalization. Collaborate with programmers, engineers, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance. Assist with establishing and prioritizing business and information needs. Conduct data lifecycle analysis to include requirements, activities and design; Define new data collection and analysis processes. Create appropriate documentation for stakeholders to effectively communicate trends, patterns, and predictions using relevant data. Manage and design the data environments, including data sources, security, and metadata; Evaluate changes and updates to data systems; Provide technical expertise on data storage structures, data mining, and data cleansing. Use graphs, infographics and other methods to visualize data. Required Qualifications Active TS/SCI with Polygraph. Experience using ML and data science packages such as PyTorch, TensorFlow, or scikit-learn and developing and training machine learning models; Experience leveraging various computing resources such as GPU clusters and cloud-based compute servers. Experience with databases such as PostgreSQL, MySQL, Oracle, MongoDB Programming knowledge in some of the following languages: Python, SQL, Java. Experience working with Docker, Kubernetes Proficiency with git and pull request workflows. Experience performing extract, transform, load (ETL) development for data pipelines. Ability to perform API service development. Demonstrated experience working with IC Agencies. Knowledge of IC systems, processes, data, and policies. Knowledge and application of agile techniques and methodologies. Experience mentoring or training (through formal or informal means) members of the team. Skill Levels Senior Expert (SME): Bachelor’s Degree in associated field and 14+ years of relevant experience; Master’s Degree in associated field and 11+ years of relevant experience; PhD and 10+years of relevant experience. Compensation $166,800 - $260,625 Expert: Bachelor’s Degree in associated field and has 10+ years of relevant experience; Master’s Degree and 9+ years of relevant experience; PhD and 8+ years of relevant experience. Compensation $138,000 - $215,625 Senior: Bachelor’s Degree in associated field and has 6+ years of relevant experience; Master’s Degree and 5+ years of relevant experience; PhD and 4+ years of relevant experience. Compensation $114,100 - $178,300 Junior: Bachelor’s Degree in associated field and 1+ years of relevant experience. Compensation $70,800 - $133,750 Desired Qualifications Strong communication skills, written and verbal. Overview Noblis and our wholly owned subsidiaries, Noblis ESI , and Noblis MSD tackle the nation's toughest problems and apply advanced solutions to our clients' most critical missions. We bring the best of scientific thought, management, and engineering expertise together in an environment of independence and objectivity to deliver enduring impact on federal missions. Noblis works with a wide range of government clients in the defense, intelligence and federal civil sectors. Learn more at Noblis -About Us Why work at a Noblis company? Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public. Noblis has won numerous workplace awards . Noblis maintains a drug-free workplace. Salary Range Explanation At Noblis we recognize and reward your contributions, provide you with growth opportunities, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, and work-life programs. Our award programs acknowledge employees for exceptional performance and superior demonstration of our service standards. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in our benefit programs. Other offerings may be provided for employees not within this category. We encourage you to learn more about our total benefits by visiting the Benefits page on our Careers site. Salary at Noblis is determined by various factors, including but not limited to, the combination of education, certifications, knowledge, skills, competencies, and experience, internal and external equity, location, and clearance level, as well as contract-specific affordability and organizational requirements and applicable employment laws. The projected compensation range for this position is provided within the posting and are based on full time status. Part time staff receive a prorated salary based on regularly scheduled hours. The estimated minimum and maximum displayed represents the broadest range for this position (inclusive of high geographic and high clearance requirements), and is just one component of Noblis’ total compensation package for employees. Posted Salary Range USD $70,800.00 - USD $260,625.00 /Yr. Equal Employment Opportunity Noblis is an Equal Opportunity Employer. Employment decisions are made without regard to race (as well as because of or on the basis of traits historically associated with race, including hair texture, hair type, and protective hairstyles such as braids, locks, and twists), color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, pregnancy, childbirth, lactation and related medical conditions, genetic factors, military/veteran status, or other characteristics protected by law. Noblis is committed to the full inclusion of all qualified individuals. As part of this commitment, Noblis will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact employee-relations@noblis.org .",
        "url": "https://www.linkedin.com/jobs/view/3959942896",
        "summary": "Noblis seeks a Data Scientist with TS/SCI clearance to work in McLean, VA. Responsibilities include data acquisition, structuring, analysis, modeling, visualization, and collaboration with engineers and leaders. Strong ML/data science skills (PyTorch, TensorFlow, scikit-learn), experience with databases (PostgreSQL, MySQL, Oracle, MongoDB), programming (Python, SQL, Java), Docker, Kubernetes, and ETL development are required. Compensation varies based on experience level.",
        "industries": [
            "Defense",
            "Intelligence",
            "Federal Civil"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical",
            "Decision-Making",
            "Teamwork",
            "Mentoring"
        ],
        "hard_skills": [
            "Data Acquisition",
            "Data Structuring",
            "Data Analysis",
            "Data Modeling",
            "Data Visualization",
            "Machine Learning",
            "PyTorch",
            "TensorFlow",
            "Scikit-learn",
            "PostgreSQL",
            "MySQL",
            "Oracle",
            "MongoDB",
            "Python",
            "SQL",
            "Java",
            "Docker",
            "Kubernetes",
            "ETL Development",
            "API Development",
            "Data Governance",
            "Agile Methodologies"
        ],
        "tech_stack": [
            "PyTorch",
            "TensorFlow",
            "Scikit-learn",
            "PostgreSQL",
            "MySQL",
            "Oracle",
            "MongoDB",
            "Docker",
            "Kubernetes"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "Java"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 260625,
            "min": 70800
        },
        "benefits": [
            "Health Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Financial Benefits",
            "Retirement Benefits",
            "Paid Leave",
            "Professional Development",
            "Tuition Assistance",
            "Work-Life Programs"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York, NY",
        "job_id": 3959843799,
        "company": "Noom",
        "title": "Lead Data Scientist",
        "created_on": 1720587891.4082525,
        "description": "Noom is a digital healthcare company that connects people to content, coaching, community, and clinicians to build healthy habits and promote better living. We’re a mission-driven, high-growth organization that’s powered by science, technology, and world-class talent. Our Engineering team is seeking a Lead Data Scientist to own and scale the data products that measure and drive revenue and growth for the company. Our ideal candidate is an independent, proactive team player who is both a technical expert with a deep understanding of statistical modeling and a strong communicator who enjoys actively collaborating with stakeholders across a variety of functions. This individual does their best work when in a high impact, high visibility role, is comfortable with ambiguity, and thrives in a fast paced environment. What You’ll Be Doing Build, develop, improve, debug, and maintain our eRev/LTV models, pipelines, and dashboards Proactively identify, investigate, and present LTV trends and strategic opportunities across different products and LOBs Own the long term vision and roadmap for the LTV data products, ensuring the data models scale appropriately as the business evolves Work closely with cross-functional stakeholders including Growth, Marketing, Finance, and executive leadership to support a variety of LTV use cases and empower decision-making at all levels of the business Serve as the subject matter expert and go-to person for technical questions about the team's eRev/LTV data Level up the Data Science team, by mentoring and collaborating with other members of the team, and proactively seeking out opportunities to coordinate mentorship or expand knowledge within and across teams What We’re Looking For 6+ years of experience in a technical Data Science role, or a combination of equivalent DS and graduate academic experience proven track record of leading initiatives leveraging statistical analysis, predictive modeling, and machine learning that deliver measurable impact spanning multiple teams or workstreams Strong competency with SQL and Python to aggregate, transform, and analyze data and conduct statistical analysis Extensive experience building successful stakeholder relationships across a range of teams and levels The ability to distill down complex data concepts and systems to technical and non-technical stakeholders alike, both in writing and live conversations Experience building predictive models using statistical and ML techniques and working closely with Engineering to bring your models to production Preferred Qualifications: Experience with digital consumer subscription products You have expertise in survival models, advanced LTV modeling, and growth accounting Experience working in a number of cross functional areas, ranging from Product to Marketing to Finance Experience managing not just your workload & prioritization but also that of other DSs (either in a manager or “tech lead” type role) First-hand experience in data modeling and writing your own data pipelines Base Salary The US base salary range for this full-time position is $187,000 - $253,000 Our salary ranges are determined by role, level, and location. The range displayed on each job posting is based on Noom’s estimate as of the date of publication and reflects the minimum and maximum target for the position across all US locations. The actual placement of the candidate within the range is based on factors including but not limited to relevant experience, assessment of functional skills and behavioral competencies, scope, and location. This range is not inclusive of any discretionary bonus or equity package. Other Elements Of The Rewards Package Noom currently offers a comprehensive and generous total rewards package. This package generally includes discretionary performance-based bonus, stock awards, healthcare & retirement benefits, paid holidays, paid time off, disability benefits and various wellness programs, etc. Location By applying to this position you will have an opportunity to share your preferred working location from the following: In-office Locations: New York, NY, USA Princeton, NJ, USA Remote location(s): United States. Your recruiter can share more about the specific compensation package for your preferred location during the hiring process More About Noom At Noom, we believe that the individual is the greatest force for good, not just in their health but in unlocking their fullest potential. We apply the same principles inside Noom. Across our dynamic organization, we empower our teams to execute on big ideas and we start and end each day with responsibility to make the world a healthier place. Fortune, Inc ., Glassdoor, and Crain’s have all named Noom a Best Place to Work including being named on Fortune’s lists for Best Workplaces in New York, Best Workplaces in Technology, Best Workplaces for Women, and Best Workplaces for Millennials . Noom is proud to be an Equal Opportunity Employer, and all applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, caste, national origin, physical or mental disability, protected veteran status, age, or any other characteristic protected by applicable law. Noom is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities. To request reasonable accommodation, please email accommodations-help@noom.com. To help protect against potential hiring scams, please be aware that all email communications from the Noom Talent team and/or hiring managers will come only from an @noom.com email address. Our assessment process includes multiple phone and/or video interview rounds, and we will never ask you for personal payment, require you to purchase equipment, or extend a job offer without the completion of this interview process. If you are unsure about the validity of a Noom job posting on another website, we strongly encourage you to instead apply directly through our website.",
        "url": "https://www.linkedin.com/jobs/view/3959843799",
        "summary": "Lead Data Scientist to own and scale data products measuring and driving revenue and growth for Noom. Requires expertise in statistical modeling, LTV modeling, and predictive modeling.  The role involves building and maintaining eRev/LTV models, pipelines, and dashboards, identifying LTV trends and opportunities, and working with cross-functional teams to empower decision-making.",
        "industries": [
            "Healthcare",
            "Technology",
            "Digital Health",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Teamwork",
            "Leadership",
            "Proactive",
            "Independent",
            "Strategic Thinking",
            "Analytical",
            "Decision Making",
            "Ambiguity Tolerance",
            "Mentoring"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "Statistical Modeling",
            "Machine Learning",
            "Predictive Modeling",
            "Survival Models",
            "LTV Modeling",
            "Growth Accounting",
            "Data Pipelines",
            "Data Analysis"
        ],
        "tech_stack": [
            "SQL",
            "Python"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 253000,
            "min": 187000
        },
        "benefits": [
            "Performance-Based Bonus",
            "Stock Awards",
            "Healthcare",
            "Retirement Benefits",
            "Paid Holidays",
            "Paid Time Off",
            "Disability Benefits",
            "Wellness Programs"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967154122,
        "company": "Sun Life",
        "title": "Data Scientist",
        "created_on": 1720587892.9739804,
        "description": "You are as unique as your background, experience and point of view. Here, you’ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world. Job Description: At Sun Life, we look for optimistic people who want to make life brighter for our Clients. We understand the value of diverse cultures, perspectives, and identities, and want you to bring your full and authentic self to work. Every day, you’ll be empowered and challenged by working with dynamic colleagues to find new and innovative ways to make Sun Life the best benefits company in America. The opportunity: The Data Scientist will provide advanced analytics support within the Business Analytics function that applies the power of data with machine learning to improve business outcomes across the Health and Risk Solutions business. This team is expected to work closely with the other functional teams, in particular the Distribution, Client Management and Sales Enablement teams. This position reports to the Associate Director, Sales Growth within the Health and Risk Solutions business. Responsibilities include helping to develop and monitor predictive model and AI solutions to support our pricing, underwriting and clinical review processes, as assigned. Additional responsibilities may include applying machine learning techniques to streamline and automate aspects of these processes, and promoting a culture of data-driven, risk-based decisions. How you will contribute: Apply basic to intermediate data science techniques to solve business problems across a broad range of data analysis functions including predictive analysis, data modeling, visualization, and data profiling. Utilize multiple sources of data, including structured and unstructured data, along with broad range of machine learning techniques to improve insights of the models. Support the development of new modeling techniques and procedures. Develop and maintain high-quality, robust predictive models and AI solutions using advanced analytic techniques Extract and analyze internal and external data sources to help answer key business problems related to risk assessment. What you will bring with you : Ability to work with a diverse range of people Experience with a broad range of data science programming languages, applications and data environments (e.g., Python, R, SQL) BS/MS in a statistical, mathematical, or technical field (e.g., computer science, actuarial science) 2+ years of experience in developing and implementing data science techniques Healthcare or health insurance experience preferred. Strong knowledge of data science including conditioning, modeling, and visualization Strong knowledge of the fundamental data science and AI underpinnings of data science Commitment to data compliance, model governance and security protocols Strong business acumen to understand why and how the work we do will impact our business stakeholders Strong communication skills, with an ability to explain technical concepts to a non-technical audience Demonstrated academic or industry experience in field of Information Retrieval, NLP and/or generative AI. Do you see yourself in this role even if you haven’t checked all the boxes above? We welcome all talented candidates and are committed to a culture that represents diversity in all forms. If you think you might thrive in this setting, we would love to hear from you. Not ready to apply yet but want to stay in touch? Join our talent community to stay connected until the time is right for you! Life is brighter when you work at Sun Life Excellent benefits and wellness programs to support the three pillars of your well-being – mental, physical and financial – including generous vacation and sick time, market-leading paid family, parental and adoption leave, a partially-paid sabbatical program, medical plans, company paid life and AD&D insurance as well as disability programs and more Retirement and Stock Purchase programs to help build and enhance your future financial security including a 401(k) plan with an employer-paid match as well as an employer-funded retirement account A flexible work environment with a friendly, caring, collaborative and inclusive culture Great Place to Work® Certified in Canada and the U.S. Named as a “Top 10” employer by the Boston Globe's “Top Places to Work” two years running All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. If you are a California resident, the salary range for this position is: Southern region: $82,500-$123,800 annually Central region: $87,000-$130,500 annually Northern region: $93,000-$139,500 annually If you are a Colorado resident , the salary range for this position is $78,700-$118,100 annually. If you are a New York resident , the salary range for this position is $93,000-$139,500 annually. If you are Washington resident , the salary range for this position is $87,000-$130,500 annually. We consider various factors in determining actual pay including your skills, qualifications, and experience. In addition to salary, this position is eligible for incentive awards based on individual and business performance as well as a broad range of competitive benefits. Sun Life Financial is a leading provider of group insurance benefits in the U.S., helping people protect what they love about their lives. More than just a name, Sun Life symbolizes our brand promise of making life brighter -for our customers, partners, and communities. Join our talented, diverse workforce and launch a rewarding career. Visit us at www.sunlife.com/us to learn more. At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs. Our Affirmative Action Program affirms our commitment to make reasonable accommodation to the known physical or mental limitation of otherwise-qualified individuals with disabilities or special disabled veterans, unless the accommodation would impose an undue hardship on the operation of our business. Please email recruitingUS@sunlife.com to request an accommodation. At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs. For applicants residing in California, please read our employee California Privacy Policy and Notice. Job Category: Advanced Analytics Posting End Date: 28/07/2024 All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",
        "url": "https://www.linkedin.com/jobs/view/3967154122",
        "summary": "Sun Life is seeking a Data Scientist to join their Health and Risk Solutions team. This role will focus on applying machine learning to improve business outcomes across various functions, including pricing, underwriting, and clinical reviews. Responsibilities include developing predictive models, AI solutions, and automating processes. The ideal candidate will have experience with data science programming languages, applications, and data environments (e.g., Python, R, SQL), along with a strong understanding of data science techniques and AI underpinnings. Healthcare or health insurance experience is preferred. The role offers excellent benefits, a flexible work environment, and a commitment to diversity and inclusion.",
        "industries": [
            "Insurance",
            "Financial Services",
            "Healthcare"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Decision Making",
            "Adaptability",
            "Teamwork",
            "Time Management"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Machine Learning",
            "Predictive Modeling",
            "AI",
            "Data Modeling",
            "Data Visualization",
            "Data Profiling",
            "Risk Assessment",
            "Information Retrieval",
            "NLP",
            "Generative AI",
            "Data Compliance",
            "Model Governance",
            "Data Security"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Machine Learning",
            "AI",
            "Data Modeling",
            "Data Visualization",
            "Data Profiling",
            "Information Retrieval",
            "NLP",
            "Generative AI",
            "Data Compliance",
            "Model Governance",
            "Data Security"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "BS/MS",
            "fields": [
                "Statistics",
                "Mathematics",
                "Computer Science",
                "Actuarial Science"
            ]
        },
        "salary": {
            "max": 139500,
            "min": 78700
        },
        "benefits": [
            "Vacation",
            "Sick Time",
            "Paid Family Leave",
            "Parental Leave",
            "Adoption Leave",
            "Sabbatical Program",
            "Medical Plans",
            "Life Insurance",
            "AD&D Insurance",
            "Disability Programs",
            "Retirement Plan",
            "401(k) Plan",
            "Employer Match",
            "Employer-Funded Retirement Account",
            "Flexible Work Environment",
            "Wellness Programs",
            "Stock Purchase Programs"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3963301889,
        "company": "Burtch Works",
        "title": "Machine Learning Engineer",
        "created_on": 1720587896.336734,
        "description": "Overview- Reporting to the Director of Machine Learning Engineering the role requires a skilled Machine Learning Engineer to design, build, and deploy machine learning models that will help us derive actionable insights and solve complex problems. The ideal candidate will have a strong background in data science, programming, and machine learning algorithms and will be passionate about leveraging data to drive business decisions. Responsibilities Build and deploy production grade Machine Learning models. Work in the full lifecycle of ML model development, from data preparation and feature engineering to model training, evaluation, and deployment. Deep technical proficiency in applying a variety of machine learning algorithms, techniques, and frameworks to solve complex business challenges. Assemble modules into end-to-end systems, ensuring seamless integration and functionality. Collaborate closely with Data Scientists to facilitate highly productive experimentation, model construction, and validation, fostering a sense of teamwork and shared success. Exceptional programming skills in Python, with popular deep learning and natural language processing (NLP) tools and libraries, including Scikit-learn, Pandas, PyTorch, TensorFlow, or other leading deep learning frameworks, NLTK and spaCy for natural language processing tasks Leverage Jupyter Notebooks for prototyping, experimentation, and collaboration. Contribute to the continuous improvement of our machine learning systems by staying abreast of advancements in software engineering and machine learning. Technical Skills Strong expertise in programming languages - Python, R, or Scala and technologies like Tensorflow, PyTorch, Kubernetes, Spark, Airflow, Kafka and Opensource LLMs. Experience in working with petabyte scale data sets and developing ML frameworks in Databricks, Snowflake or similar large platforms. Proficiency in machine learning and familiarity with open-source machine learning ecosystems. Proficiency with CI/CD solutions in the context of MLOps and LLMOps including automation with IaC (ex: terraform). Soft Skills Excellent communication and collaboration skills. Strategic thinker with a strong analytical mindset and problem-solving abilities.",
        "url": "https://www.linkedin.com/jobs/view/3963301889",
        "summary": "This role requires a skilled Machine Learning Engineer to design, build, and deploy machine learning models to derive actionable insights and solve complex problems. The ideal candidate will have a strong background in data science, programming, and machine learning algorithms.",
        "industries": [
            "Machine Learning",
            "Data Science",
            "Software Engineering",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Analytical",
            "Problem-solving",
            "Strategic thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Science",
            "Python",
            "R",
            "Scala",
            "Tensorflow",
            "PyTorch",
            "Kubernetes",
            "Spark",
            "Airflow",
            "Kafka",
            "Opensource LLMs",
            "Databricks",
            "Snowflake",
            "CI/CD",
            "MLOps",
            "LLMOps",
            "IaC",
            "Terraform"
        ],
        "tech_stack": [
            "Tensorflow",
            "PyTorch",
            "Kubernetes",
            "Spark",
            "Airflow",
            "Kafka",
            "Databricks",
            "Snowflake",
            "Terraform",
            "Jupyter Notebooks",
            "Scikit-learn",
            "Pandas",
            "NLTK",
            "spaCy"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Scala"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": [
                "Data Science",
                "Machine Learning",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959103297,
        "company": "US Tech Solutions",
        "title": "NLP Data Scientist",
        "created_on": 1720587897.945784,
        "description": "Duration: 6 months Contract Job Description: We're seeking a talented and innovative NLP/Information Retrieval Scientist to join our team. In this role, you will play a pivotal part in enhancing Large Language Models (LLMs) to provide more accurate, context-aware, and creatively curated responses with real-world applications. Responsibilities: As an NLP/Information Retrieval Scientist, you will develop and to improve the usability and creativity of our LLM responses. You will collaborate closely with our multidisciplinary team of researchers and engineers to not only advance the technical aspects but also bring real-world relevance and creativity into our language models. The successful candidate will use the latest innovations in NLP and LLM to propose software solutions to improve customer experience. The NLP Data Scientist will design and test algorithms, conduct prototyping to evaluate possible scenarios leveraging computational and statistical techniques for the development of novel approaches for Text and Image Data. Experience: · Experience working with agricultural/biological scientific data is highly desired. • Drive for translating business problems into research initiatives that deliver business value. • Creativity in defining challenging exploratory projects. Skills: • Plus 3 years of work experience • Expertise with NLP or Information • Proficiency in Python or in another high-level programming language • Experience in developing statistical, and machine learning models for environmental and agronomical applications. • Familiarity with LLM • Experience analyzing and presenting complex data and proven problem-solving abilities. • Strong publication record in leading scientific journals Education: • Ph.D. (or MS with 4+ years of post MS experience), Computer Science, Electrical Engineering, Physics, Mathematics, Statistics or an Analytics discipline. About US Tech Solutions: US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com. US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Recruiter Details: Name: James Email: pjames@ustechsolutionsinc.com Internal Id: 24-14903",
        "url": "https://www.linkedin.com/jobs/view/3959103297",
        "summary": "We are seeking an NLP/Information Retrieval Scientist to enhance Large Language Models (LLMs) for accurate, context-aware, and creative responses with real-world applications. Responsibilities include developing and improving LLM usability and creativity, collaborating with researchers and engineers to advance technical aspects and bring real-world relevance, proposing software solutions to enhance customer experience, designing and testing algorithms, conducting prototyping using computational and statistical techniques for novel text and image data approaches.  Experience with agricultural/biological scientific data is preferred. The ideal candidate will have a proven track record of translating business problems into research initiatives, defining challenging exploratory projects, and analyzing and presenting complex data.",
        "industries": [
            "Information Technology",
            "Research & Development",
            "Agriculture",
            "Biotechnology"
        ],
        "soft_skills": [
            "Creativity",
            "Problem-Solving",
            "Collaboration",
            "Communication",
            "Analytical Thinking",
            "Presentation Skills",
            "Innovation"
        ],
        "hard_skills": [
            "NLP",
            "Information Retrieval",
            "Large Language Models (LLMs)",
            "Python",
            "Statistical Modeling",
            "Machine Learning",
            "Data Analysis",
            "Data Presentation"
        ],
        "tech_stack": [
            "LLMs",
            "Python",
            "Machine Learning"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Ph.D.",
            "fields": [
                "Computer Science",
                "Electrical Engineering",
                "Physics",
                "Mathematics",
                "Statistics",
                "Analytics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New Jersey, United States",
        "job_id": 3967436890,
        "company": "Acunor",
        "title": "Data Scientist for NLP",
        "created_on": 1720587899.611554,
        "description": "Job Responsibilities Design, develop and implement solutions for a wide range of NLP use cases involving classification, extraction and search on unstructured text data Create and maintain state of the art scalable NLP solutions in Python/ Java/ Scala for multiple business problems. This involves: Choosing most appropriate NLP technique(s) based on business needs and available data Performing data exploration and innovative feature engineering Training and tuning a variety of NLP models / solutions which include regular expressions, traditional NLP models as well as SOTA transformer based models Augmenting models by integrating domain specific ontologies and/or external databases Reporting and Monitoring the solution outcome Work experience with document-oriented databases such as MongoDB Collaborate with ML engineering team to deploy NLP solutions in production - both on premise as well as cloud deployment Interact with clients and internal business teams to perform solution feasibility as well as design and develop solutions Open to working across different domains Insurance, Healthcare and Financial Services etc. Qualifications: Number of Years of Work Experience: 1-6 years Education: Engineering graduate from Top Tier Universities is a plus Required Skills Experience (including graduate school) on training machine learning models, applying and developing text mining and NLP techniques Exposure to OCR and computer vision Experience in extracting content from documents is preferred Experience (including graduate school) with Natural Language Processing techniques is required Hands on experience with Natural Language Processing tools such as Stanford CORE-NLP, NLTK, spaCy, Gensim, Textblob etc. Experience/ Familiarity with document clustering in supervised un un-supervised scenarios Expertise in at least two of the state of the art techniques in NLP like BERT, GPT, XL Net etc. Applied experience of machine learning algorithms using Python Organized, self-motivated, disciplined and detail oriented Production level coding experience in Python is required Ability to read recent ML research papers and adapt those models to solve real-world problems Experience with any deep learning framework, including Tensorflow, Caffe, MxNet, Torch, Theano Experience with optimization on GPUs (a plus) Hands on experience with using cloud technologies on AWS/ Microsoft Azure is preferred",
        "url": "https://www.linkedin.com/jobs/view/3967436890",
        "summary": "This job requires a skilled NLP engineer with 1-6 years of experience to design, develop, and implement NLP solutions for various industries. The role involves choosing appropriate NLP techniques, performing data exploration, training and tuning models, integrating domain-specific ontologies, reporting results, and collaborating with ML engineers for production deployment. The ideal candidate has a strong understanding of NLP techniques, experience with tools like Stanford CORE-NLP, NLTK, spaCy, Gensim, and Textblob, expertise in BERT, GPT, or XLNet, and experience with machine learning algorithms in Python.",
        "industries": [
            "Insurance",
            "Healthcare",
            "Financial Services"
        ],
        "soft_skills": [
            "Organized",
            "Self-motivated",
            "Disciplined",
            "Detail oriented"
        ],
        "hard_skills": [
            "NLP",
            "Classification",
            "Extraction",
            "Search",
            "Python",
            "Java",
            "Scala",
            "Regular Expressions",
            "Data Exploration",
            "Feature Engineering",
            "Machine Learning Models",
            "Transformers",
            "BERT",
            "GPT",
            "XLNet",
            "Ontologies",
            "Databases",
            "Reporting",
            "Monitoring",
            "MongoDB",
            "Cloud Deployment",
            "AWS",
            "Microsoft Azure",
            "OCR",
            "Computer Vision",
            "Document Clustering",
            "Tensorflow",
            "Caffe",
            "MxNet",
            "Torch",
            "Theano",
            "GPU Optimization"
        ],
        "tech_stack": [
            "Python",
            "Java",
            "Scala",
            "Stanford CORE-NLP",
            "NLTK",
            "spaCy",
            "Gensim",
            "Textblob",
            "MongoDB",
            "AWS",
            "Microsoft Azure",
            "Tensorflow",
            "Caffe",
            "MxNet",
            "Torch",
            "Theano"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "Scala"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Diego, CA",
        "job_id": 3967692671,
        "company": "THOR Solutions, LLC",
        "title": "Data Scientist II",
        "created_on": 1720587901.1538334,
        "description": "THOR Solutions is actively seeking a Data Scientist to support the Naval Information Warfare Center Pacific (NIWC PAC) in San Diego, CA . The candidate will provide engineering support services for the Office of the Chief Engineer (CHENG), Code 50E in support of NIWC Pacific’s mission objectives. Typical Responsibilities Develop and implement techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. Visualize, interpret, and report data findings. Create dynamic data reports. Location: Full time onsite at NIWC in San Diego, CA. Salary: $124K - $152K/year Typical Physical Activity: Desk/computer work in an office environment. May involve: repetitive motion. Security Clearance Eligibility Required: This position requires a DoD Top Secret or Secret security clearance. A qualified candidate must either already possess an active or interim TS or Secret security clearance (preferred), or be eligible to obtain one as a precondition to hire. Typical Knowledge, Skills, and Abilities: Bachelor’s degree in related field, or a similar discipline, from an accredited institution. At least three (3) to five (5) years of relevant professional experience, preferably obtained in a US Navy/DoD environment. Overall experience should include: Software integration or testing, including analyzing and implementing test plans and scripts. Frequent scripting language use, such as Python and R and using packages commonly used in data science applications or advanced analytics Data science, data mining, statistics, or graph algorithms to support analytics objectives. Applying complex mathematical and statistical concepts. Applying statistical and operations research methods and tools. Employing spreadsheets for data manipulation and visualization. Proficiency with common productivity software such as Microsoft Office, Adobe Pro, MS Teams and SharePoint. Excellent communication skills. An ideal candidate will have relevant industry certifications, such as CompTIA MTA, CCSK, CompTIA A+, CompTIA Security+, EMCDSA, CCDH, HCAHD, CISSP, CCP, MCPD, MCSD, MCSW, or CCAH. THOR is proud to be an Affirmative Action/Equal Opportunity Employer. THOR considers all qualified applicants for employment without regard to age, race, ethnicity, color, religion, sex, sexual orientation, gender identity or expression, national origin, genetics, disability status, or status as a protected veteran. THOR complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment. Equal Employment Opportunity (EEO) is the law. Please be aware that many of our positions require the ability to obtain a security clearance. Security clearances may only be granted to U.S. citizens. Founded in 2009, THOR Solutions, LLC (THOR) is a rapidly growing Center for Veteran’s Excellence (CVE) verified Service Disabled Veteran Owned Small Business (SDVOSB) providing mission critical support across the Department of Defense, federal civilian agencies and commercial maritime industry, worldwide. THOR provides innovative and tailored expertise in multidisciplinary engineering, project and program management, business and financial management, technical support, integrated logistics support, training support, fleet support, corporate operations support, assessments and studies. THOR is privileged to deliver service solutions to the nation’s most complex military, public sector and industry challenges. THOR is proud to be an Affirmative Action/Equal Opportunity Employer. THOR considers all qualified applicants for employment without regard to age, race, ethnicity, color, religion, sex, sexual orientation, gender identity or expression, national origin, genetics, disability status, or status as a protected veteran. THOR complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment. THOR is proud to be a Veteran-Friendly Employer . THOR does not discriminate against a qualified applicant because of their status as a protected veteran, or their relationship or association with a protected veteran. This includes spouses and other family members. If you are an individual with a disability and would like to request a reasonable accommodation as part the employment selection process, please contact us at If you would like to view a copy of THOR’s affirmative action plan, please email",
        "url": "https://www.linkedin.com/jobs/view/3967692671",
        "summary": "THOR Solutions is hiring a Data Scientist to support the Naval Information Warfare Center Pacific (NIWC PAC) in San Diego, CA. The candidate will utilize data-oriented programming languages and visualization software to transform raw data into meaningful information. They will also apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. The ideal candidate will have relevant industry certifications and at least 3-5 years of experience, preferably in a US Navy/DoD environment.",
        "industries": [
            "Defense",
            "Government",
            "Information Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical",
            "Critical Thinking",
            "Decision Making"
        ],
        "hard_skills": [
            "Data Mining",
            "Data Modeling",
            "Natural Language Processing",
            "Machine Learning",
            "Python",
            "R",
            "Data Science",
            "Statistics",
            "Graph Algorithms",
            "Spreadsheets",
            "Microsoft Office",
            "Adobe Pro",
            "MS Teams",
            "SharePoint"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Microsoft Office",
            "Adobe Pro",
            "MS Teams",
            "SharePoint"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Mathematics",
                "Statistics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 152000,
            "min": 124000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3961906635,
        "company": "Altea Healthcare",
        "title": "Machine Learning Engineer/Scientist",
        "created_on": 1720587902.614259,
        "description": "Machine Learning Scientist/Engineer - Text to SQL ALTEA Healthcare is a leading healthcare organization committed to revolutionizing the delivery of outpatient/post-acute care. We are seeking an experienced Machine Learning Scientist/Engineer with deep subject matter expertise in working with LLMs and SQL to join our team. As an important member of the AI team, this person will contribute significantly to designing, implementing, and deploying GenAI applications, to improve care delivery and quality for post-acute patients. This person will lead the design and development work to build a system that can convert natural language queries to handle the use cases like building SQL query statements for searching tables in DB or searching for cohorts with specific medical criteria. The ideal candidate possesses a deep understanding of LLM techniques, database management systems, SQL Query optimization, and a passion for building intelligent systems in healthcare. Responsibilities : Develop a system that converts natural language queries into a structured format for searching SQL tables or documents Use/fine-tune language models to interpret and convert natural language queries into SQL statements Develop a mechanism to summarize SQL tables into user-level summary text, providing concise and meaningful insights from retrieved data Help build a scalable system capable of efficiently handling a large volume of queries, ensuring high performance and minimal latency Optimize SQL queries to ensure efficient data retrieval Develop system evaluation processes that ensure accuracy, fairness, reproducibility, and scalability Document system architecture, design decisions, and codebase to facilitate future maintenance and enhancements Requirements: Bachelor’s/Master’s degree in Computer Science, Data Science, Machine Learning, or a related field At least 2+ years of experience with Pytorch/TensorFlow, NLP libraries (such as NLTK, spaCy), Hugging Face Transformers, Langchain, VectorDB At least 3+ years of experience writing SQL queries, including complex joining queries Demonstrated experience with Text-to-SQL projects Experience with building ML pipelines using prompt engineering/optimization and RAG Good understanding of SQL and experience working with relational database management systems (Microsoft SQL Server) Experience with query optimization techniques Ability to work independently and collaboratively, manage priorities, and deliver high-quality results within project timelines Familiarity with cloud-based data warehousing platforms Preferred experience working with Electronic Health Records (EHR) Job Type: Full-time Pay: Competitive pay and benefits and extremely valuable startup stock options Schedule: Full Time Work Location: Hybrid position in Houston preferred, with remote options available for exceptionally qualified candidates. Benefits: 401(k) Dental insurance Health insurance Vision insurance",
        "url": "https://www.linkedin.com/jobs/view/3961906635",
        "summary": "ALTEA Healthcare seeks a Machine Learning Scientist/Engineer with expertise in LLMs and SQL to build GenAI applications for post-acute care. The role involves developing a system that converts natural language queries into structured SQL statements for data retrieval and summarization, ensuring accuracy, performance, and scalability. This position requires experience with NLP libraries, Hugging Face Transformers, Langchain, VectorDB, SQL query optimization, and building ML pipelines.",
        "industries": [
            "Healthcare",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Pytorch",
            "TensorFlow",
            "NLP",
            "NLTK",
            "spaCy",
            "Hugging Face Transformers",
            "Langchain",
            "VectorDB",
            "SQL",
            "Prompt Engineering",
            "RAG",
            "Query Optimization",
            "System Evaluation",
            "Documentation"
        ],
        "tech_stack": [
            "Pytorch",
            "TensorFlow",
            "NLP",
            "NLTK",
            "spaCy",
            "Hugging Face Transformers",
            "Langchain",
            "VectorDB",
            "SQL",
            "Microsoft SQL Server",
            "Cloud-based data warehousing platforms",
            "EHR"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "401(k)",
            "Dental Insurance",
            "Health Insurance",
            "Vision Insurance",
            "Startup Stock Options"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3961904670,
        "company": "Altea Healthcare",
        "title": "Machine Learning Engineer (MLOps)",
        "created_on": 1720587904.1468515,
        "description": "Machine Learning Engineer, MLOps ALTEA Healthcare is a leading healthcare organization committed to revolutionizing the delivery of outpatient/post-acute care. We are seeking an experienced Machine Learning Engineer to join our team. The ideal candidate will have a strong background in deploying scalable ML models, including predictive/classification and NLP/NLU models. As an important member of the AI team, this person will contribute significantly to designing, implementing, and deploying various AI/ML product features to improve care delivery and quality for post-acute patients. Responsibilities: Develop and deploy production-ready ML models, with a focus on scalability and monitoring across a broad range of applications within healthcare Write efficient, maintainable, and scalable Python code Collaborate with machine learning scientists and data engineers to translate prototype code to production-ready code Set up and maintain end-to-end pipelines including data ingress, egress, model inference, and model retraining Build high-performance deployment architectures and model monitoring systems Incorporate feedback from cross-functional teams and refine the ML-driven applications through quick iteration cycles Maintain best practices of MLOps practices within the healthcare industry Document the system architecture, design decisions, and codebase to facilitate future maintenance and enhancements. Requirements: Bachelor’s or Master’s degree in Engineering, Computer Science, or equivalent experience At least 3+ years of relevant experience as an MLOps Engineer 2+ years of experience doing MLOps, model monitoring, drift detection, and model retraining Azure Machine Learning Studio Experience with transformer-based models and NLP, preferably in a healthcare context Extensive experience with TensorFlow or PyTorch, and familiarity with HuggingFace Track record of fine-tuning, running large-scale training jobs, and managing model servers like vLLM, TGI, or TorchServe Strong proficiency in LangChain, vectorDB and cloud platforms (Azure), model experimentation tools like MLflow, and monitoring tools like Grafana/Splunk, and CI/CD like airflow, gitlab, and Big Data management like Spark, Kafka Ability to work independently and collaboratively, manage priorities, and deliver high-quality results within project timelines Job Type: Full-time Pay: Competitive pay and benefits and extremely valuable startup stock options Schedule: Full Time Work Location: Hybrid position in Houston preferred, with remote options available for exceptionally qualified candidates. Benefits: 401(k) Dental insurance Health insurance Vision insurance",
        "url": "https://www.linkedin.com/jobs/view/3961904670",
        "summary": "ALTEA Healthcare seeks an experienced Machine Learning Engineer with a strong background in deploying scalable ML models, including predictive/classification and NLP/NLU models. The ideal candidate will contribute to designing, implementing, and deploying AI/ML product features to improve care delivery for post-acute patients.",
        "industries": [
            "Healthcare",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Time management",
            "Organization",
            "Analytical thinking",
            "Critical thinking",
            "Adaptability",
            "Teamwork",
            "Independence"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "Deep Learning",
            "NLP",
            "NLU",
            "TensorFlow",
            "PyTorch",
            "HuggingFace",
            "Azure Machine Learning Studio",
            "MLOps",
            "Model Monitoring",
            "Drift Detection",
            "Model Retraining",
            "LangChain",
            "VectorDB",
            "Azure",
            "MLflow",
            "Grafana",
            "Splunk",
            "Airflow",
            "GitLab",
            "Spark",
            "Kafka",
            "CI/CD"
        ],
        "tech_stack": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "HuggingFace",
            "Azure Machine Learning Studio",
            "LangChain",
            "VectorDB",
            "Azure",
            "MLflow",
            "Grafana",
            "Splunk",
            "Airflow",
            "GitLab",
            "Spark",
            "Kafka"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Engineering",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "401(k)",
            "Dental insurance",
            "Health insurance",
            "Vision insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3965440370,
        "company": "innoVet Health (SDVOSB)",
        "title": "Senior Data Scientist with AL/ML experience in Healthcare",
        "created_on": 1720587907.0630383,
        "description": "InnoVet Health, a small and growing business that provides health IT professional services to the Department of Veterans Affairs (VA) is looking for a Data Scientist with advanced analytics experience who can turn requirements and research questions into reports, clear insights, predictions, and business intelligence. The position offers stimulating advanced analytics activities (AI/ML/NLP), in a rich healthcare environment, interacting with senior staff. This position is full-time and does not require relocating (work remotely). The pay, benefits, and growth potential are competitive. Responsibilities Collect, elaborate, and manage requirements from VA customers. Actively participate in setting up and managing new studies. Acquire and analyze raw data: assessing quality, profiling, cleansing, performing exploratory data analysis. Design and develop diagnostic and predictive models and machine learning algorithms (e.g., logistic regression, random forest, decision tree, etc.) using large data sets. Train and evaluate these models using strong statistical knowledge. Deploy models to operational settings with understanding of the providers workflows Interpret and present results to providers and business customers Manage relationship with VA client Contribute to InnoVet Health growth activities Qualifications BS degree in data science, statistics, or computer/information science or similar area a minimum 3-5+ years of advanced data analysis (AI/ML) experience Proven experience in statistics, AI, and Machine Learning applications Knowledge of Python, R, Scala, and associated libraries. Depth and breadth in text representation techniques, NLP frameworks, and statistics. Proficiency in visualization tools (PowerBI, ggplot, seaborn) Excellent problem-solving, collaboration and communication (verbal and writing) skills with fluency in MS Office. Passion for continuous learning as data science evolves. Healthcare, research, and consulting experience preferred Green card or US citizen required. Please no 1099 or corp-to-corp or international outsourcing or staffing agencies. Salary: commensurate with experience Job Type: Full-time Benefits: 401(k) 401(k) matching Dental insurance Health insurance Paid time off Referral program Vision insurance Schedule: 8 hour shift Monday to Friday Supplemental pay types: Bonus pay Application Question(s): This position requires either U.S. Citizenship or valid Green Card. Please answer 2 if you are a US citizen, 1 if you have a valid green card, 0 if neither. Please make sure to answer this question. Education: Bachelor's (Required) Experience: Programing: 5 years (Preferred) Data visualization: 10 years (Preferred) Healthcare data science: 2 years (Preferred) Data science: 6 years (Required) NLP: 5 years (Preferred) AI/ML in healthcare: 5 years (Required) ETL and SQL: 3 years (Required) Non-Academic work: 6 years (Required)",
        "url": "https://www.linkedin.com/jobs/view/3965440370",
        "summary": "InnoVet Health, a healthcare IT services provider to the VA, seeks a Data Scientist with advanced analytics experience (AI/ML/NLP). This role involves collecting and analyzing data, building predictive models, deploying them, and presenting results to clients. The position requires strong programming skills in Python, R, Scala, and NLP expertise. It offers competitive pay, benefits, and growth opportunities.",
        "industries": [
            "Healthcare",
            "Information Technology",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Problem-solving",
            "Collaboration",
            "Communication",
            "Presentation",
            "Relationship Management",
            "Continuous Learning"
        ],
        "hard_skills": [
            "Data Analysis",
            "AI",
            "Machine Learning",
            "Logistic Regression",
            "Random Forest",
            "Decision Tree",
            "Python",
            "R",
            "Scala",
            "NLP",
            "Text Representation Techniques",
            "Statistical Modeling",
            "Data Visualization",
            "PowerBI",
            "ggplot",
            "Seaborn",
            "MS Office"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Scala",
            "PowerBI",
            "ggplot",
            "Seaborn"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Scala"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Statistics",
                "Computer Science",
                "Information Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "401(k)",
            "401(k) matching",
            "Dental insurance",
            "Health insurance",
            "Paid time off",
            "Referral program",
            "Vision insurance",
            "Bonus pay"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, Texas Metropolitan Area",
        "job_id": 3970933948,
        "company": "VLink Inc",
        "title": "Machine Learning Engineer",
        "created_on": 1720587908.5380125,
        "description": "Must have skills: Python, scikit learn, vader sentiment, pandas, pyspark, ML (Regression, Classification etc.), NLP – Must have strong exp in MLOps. Roles and responsibilities: 10+ years’ experience Work and collaborate with data science and engineering teams to deploy and scale models and algorithms. Operationalize complex machine learning models into production including end to end deployment. Understand standard Machine Learning algorithms (Regression, Classification) & Natural Language processing concepts (sentiment generation, topic modeling, TFIDF) . Working knowledge of standard ML packages like scikit learn, vader sentiment, pandas, pyspark. Design, Develop and maintain adaptable data pipelines to maintain use case specific data. Integrate ML use cases in business pipelines & work closely with upstream & downstream teams to ensure smooth handshake of information. Develop & maintain pipelines to generate & publish model performance metrics that can be utilized by Model owners for Model Risk Oversight's model review cadence. Support the operationalized models and develop runbooks for maintenance.",
        "url": "https://www.linkedin.com/jobs/view/3970933948",
        "summary": "This role requires a data scientist with extensive experience in MLOps, specifically deploying and scaling ML models in production. The ideal candidate will have strong expertise in Python, ML algorithms, NLP, and related libraries like scikit-learn, vader sentiment, pandas, and pyspark. The responsibilities include operationalizing models, developing data pipelines, integrating ML use cases, and generating model performance metrics.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Software Development",
            "Technology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Analytical Thinking",
            "Technical Skills",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Python",
            "scikit-learn",
            "vader sentiment",
            "pandas",
            "pyspark",
            "ML",
            "Regression",
            "Classification",
            "NLP",
            "MLOps",
            "Sentiment Generation",
            "Topic Modeling",
            "TFIDF",
            "Data Pipelines",
            "Model Performance Metrics",
            "Model Risk Oversight",
            "Runbook Development"
        ],
        "tech_stack": [
            "Python",
            "scikit-learn",
            "vader sentiment",
            "pandas",
            "pyspark",
            "MLOps"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3961531012,
        "company": "EPSoft",
        "title": "Senior Data Scientist",
        "created_on": 1720587910.0803392,
        "description": "Role: Data Scientist Location: Dallas, TX/Atlanta, GA (Relocation is fine) Duration: Long Term Tax Terms: W2, Full-Time only. If you are not interested in W2/1099/Full-Time, please don't apply Note: Only Looking for consultants with 8+ years of experience. Requirements Bachelor’s or Master’s degree in Data Science, Statistics, Mathematics, Computer Science, or a related field. Ph.D. preferred. Proven experience as a Data Scientist or in a similar role, with a strong portfolio of completed projects. Proficiency in programming languages such as Python, R, and SQL. Experience with data visualization tools (e.g., Tableau, Power BI, matplotlib, ggplot2). Strong knowledge of machine learning frameworks (e.g., TensorFlow, Keras, scikit-learn). Excellent understanding of statistical methods, data mining techniques, and predictive modeling. Familiarity with big data technologies (e.g., Hadoop, Spark) is a plus. Strong problem-solving skills and ability to work with complex datasets. Excellent communication and interpersonal skills. Experience with natural language processing (NLP) and deep learning. Knowledge of cloud platforms (e.g., AWS, Azure, Google Cloud) and data warehousing solutions. Familiarity with version control systems (e.g., Git). Experience in a specific industry (e.g., finance, healthcare, e-commerce) can be advantageous.",
        "url": "https://www.linkedin.com/jobs/view/3961531012",
        "summary": "Data Scientist with 8+ years experience required for long-term W2 full-time role in Dallas, TX or Atlanta, GA.  Requires strong background in Python, R, SQL, data visualization, machine learning, statistical methods, and big data technologies.  Experience with NLP, deep learning, cloud platforms, and data warehousing is a plus.  PhD preferred.",
        "industries": [
            "Data Science",
            "Statistics",
            "Mathematics",
            "Computer Science",
            "Finance",
            "Healthcare",
            "E-commerce"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Interpersonal"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Power BI",
            "matplotlib",
            "ggplot2",
            "TensorFlow",
            "Keras",
            "scikit-learn",
            "Hadoop",
            "Spark",
            "NLP",
            "Deep Learning",
            "AWS",
            "Azure",
            "Google Cloud",
            "Git"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Power BI",
            "matplotlib",
            "ggplot2",
            "TensorFlow",
            "Keras",
            "scikit-learn",
            "Hadoop",
            "Spark",
            "AWS",
            "Azure",
            "Google Cloud",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Data Science",
                "Statistics",
                "Mathematics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York City Metropolitan Area",
        "job_id": 3965702535,
        "company": "Faction Imaging Inc",
        "title": "Machine Learning Engineer",
        "created_on": 1720587912.9780056,
        "description": "Faction imaging is developing the next generation of a widely used medical imaging modality. This role is for a consultant with extensive experience in reinforcement learning and the application of machine learning to image processing. It will involve conducting research, ideation and prototype development. Applicants must demonstrate extensive technical expertise, drive and the ability to solve unstructured problems creatively within a multi-disciplinary team. This is an opportunity to apply machine learning techniques to advance a critical medical imaging procedure performed millions of times per year in the United States alone. Qualifications: BSc in computer science or a related field required PhD or MSc in Machine Learning, Artificial Intelligence, Computer Science, Mathematics or a related technical field is preferred Experience developing reinforcement learning algorithms Experience developing image segmentation and classification algorithms Experience with Python, C++, Java or other related language Familiarity with machine learning tools such as PyTorch and Tensorflow Responsibilities: Phase 1: Research and Ideation Definition of image optimization and image processing algorithm specifications Investigation of known approaches to analogous problems Creation of a software development roadmap, including strategies for model training Phase 2: Prototype Model Development and Performance Evaluation Time Commitment: Part time Location: Hybrid in-person (New York, NY) and remote Compensation: Competitive",
        "url": "https://www.linkedin.com/jobs/view/3965702535",
        "summary": "Faction Imaging is seeking a machine learning consultant with expertise in reinforcement learning and image processing to conduct research, ideation, and prototype development for a next-generation medical imaging modality. The role involves applying machine learning techniques to optimize and enhance image processing algorithms, leading to advancements in a critical medical procedure performed millions of times annually.",
        "industries": [
            "Healthcare",
            "Medical Imaging",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Problem Solving",
            "Creativity",
            "Teamwork",
            "Communication"
        ],
        "hard_skills": [
            "Reinforcement Learning",
            "Image Segmentation",
            "Image Classification",
            "Python",
            "C++",
            "Java",
            "PyTorch",
            "Tensorflow"
        ],
        "tech_stack": [
            "PyTorch",
            "Tensorflow"
        ],
        "programming_languages": [
            "Python",
            "C++",
            "Java"
        ],
        "experience": 0,
        "education": {
            "min_degree": "BSc",
            "fields": [
                "Computer Science",
                "Machine Learning",
                "Artificial Intelligence",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967125871,
        "company": "Validate Health",
        "title": "Consulting Data Scientist with Healthcare Experience (Small, Fun Team 🤓)",
        "created_on": 1720587914.8679173,
        "description": "The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers. Responsibilities Analyze raw data: assessing quality, cleansing, structuring for downstream processing Design accurate and scalable prediction algorithms Collaborate with engineering team to bring analytical prototypes to production Generate actionable insights for business improvements Qualifications Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.) At least 1 - 2 years' of experience in quantitative analytics or data modeling Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms Fluency in a programming language (Python, C,C++, Java, SQL) Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)",
        "url": "https://www.linkedin.com/jobs/view/3967125871",
        "summary": "We are seeking a data analyst with strong analytical skills to extract valuable insights from complex data sets, design predictive algorithms, and collaborate with the engineering team. The ideal candidate will have experience in quantitative analytics, machine learning, and big data frameworks.",
        "industries": [
            "Data Analysis",
            "Analytics",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Cleansing",
            "Data Structuring",
            "Predictive Modeling",
            "Machine Learning",
            "Clustering",
            "Classification",
            "Algorithm Design",
            "Python",
            "C",
            "C++",
            "Java",
            "SQL",
            "Cassandra",
            "Hadoop",
            "Spark",
            "Tableau"
        ],
        "tech_stack": [
            "Python",
            "C",
            "C++",
            "Java",
            "SQL",
            "Cassandra",
            "Hadoop",
            "Spark",
            "Tableau"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++",
            "Java",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Mathematics",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3963345879,
        "company": "Trustech",
        "title": "Senior Data Scientist",
        "created_on": 1720587916.2297637,
        "description": "A company is building a Lab Research group to build tools that have never been done before. this Senior Data Scientist will have experience building Transformers, working with LLM's and Multi-Modal projects. Responsibilities Building transformers and working with encoding data types in the transformers. Building and deploying LLM, integrating other data modalities into other LLM's. Working with multiple data pipelines from cameras, text, video, etc. Qualifications Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.) At least 2 years' of experience in related field Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms Fluency in a programming language Python and toolkits Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)",
        "url": "https://www.linkedin.com/jobs/view/3963345879",
        "summary": "Senior Data Scientist to build novel tools using Transformers, LLMs, and multi-modal data. Responsibilities include building and deploying LLMs, integrating diverse data modalities, and working with data pipelines from cameras, text, and video. Requires experience with Transformers, LLMs, predictive modeling, machine learning, clustering, classification, and big data frameworks.",
        "industries": [
            "Technology",
            "Research and Development",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical thinking",
            "Communication",
            "Collaboration",
            "Creativity"
        ],
        "hard_skills": [
            "Transformers",
            "LLMs",
            "Multi-modal Data",
            "Predictive Modeling",
            "Machine Learning",
            "Clustering",
            "Classification",
            "Python",
            "Cassandra",
            "Hadoop",
            "Spark",
            "Tableau"
        ],
        "tech_stack": [
            "Transformers",
            "LLMs",
            "Cassandra",
            "Hadoop",
            "Spark",
            "Tableau"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Statistics",
                "Mathematics",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Cambridge, MA",
        "job_id": 3958004399,
        "company": "MORSE Corp",
        "title": "Data Scientist",
        "created_on": 1720587920.690441,
        "description": "MORSE is searching for a Data Scientist with expertise in data analysis, data science, and algorithm development in one or more of a variety of fields including visual classification, big data, natural language processing, machine translation, time sequenced data, and advanced metrics. You will be part of teams performing Test and Evaluation (T&E) of AI and machine learning models and algorithms to give national security customers insights into the capabilities of applying AI to solve real world problems. Responsibilities: Perform data analysis, test and evaluation of existing machine learning algorithms, and development of advanced algorithms to model physical and autonomous systems, Work with MORSE's current team of engineers to transition algorithms to software applications and real-time embedded systems. Support the transition of the developed algorithms to software using one or more programming languages such as Python, C, C++, Java, or MATLAB. Work with customers, stakeholders, and other vendors to present concepts, analyses, and test results Present a path forward and solutions to solve complex data problems Research and identify new methods for machine learning and data analysis Requirements: US CITIZENSHIP REQUIRED and the ability to obtain a U.S. Security Clearance Masters or Ph.D in Data Science, Computer Science, Engineering, Applied Mathematics, Physics, Physical or Biological Sciences or a related field 3+ years of experience in Data Science or Analysis Solid understanding of data analysis, physics, linear algebra, statistics, algorithms, optimization, and/or machine learning methods Proficiency in one or more programming languages like Python, Matlab, C, or C++ Demonstrated experience with large, multidimensional, or complex data sets in one or more of the following areas: parsing, cleaning, storage strategies, provenance tracking, database formats, and parallelized data transformations Good communication skills Self-starter and driven Prior experience in defense is a plus MORSE is an innovative, employee-owned, tech company specializing in solving multi-disciplinary problems faced by the US National Security Ecosystem. Our specially selected team of engineers, software developers and scientists develop algorithms, software, and hardware in the domains of AI, Manned and Unmanned Vehicles, Mission Planning, and Warfighter Situational Awareness. The team at MORSE takes pride in being the smart team that is easy to work with. We focus on steady, long-term success while maintaining a collaborative, enjoyable work experience for its employees. Our team values work-life balance through flexibility and other programs, along with a comprehensible benefits package for employees and families. For more information, please visit www.morsecorp.com.",
        "url": "https://www.linkedin.com/jobs/view/3958004399",
        "summary": "MORSE is seeking a Data Scientist to perform data analysis, test, and evaluation of AI and machine learning models and algorithms. The ideal candidate will have experience with data analysis, algorithm development, and proficiency in programming languages like Python, C, C++, Java, and MATLAB. Experience with large datasets, communication skills, and the ability to obtain a U.S. Security Clearance are required.",
        "industries": [
            "Defense",
            "National Security",
            "Aerospace",
            "AI",
            "Machine Learning",
            "Software Development",
            "Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Self-starter",
            "Driven",
            "Teamwork",
            "Problem Solving"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "Algorithm Development",
            "Python",
            "C",
            "C++",
            "Java",
            "MATLAB",
            "Data Cleaning",
            "Data Storage",
            "Database Formats",
            "Parallelized Data Transformations"
        ],
        "tech_stack": [
            "Python",
            "C",
            "C++",
            "Java",
            "MATLAB",
            "AI",
            "Machine Learning",
            "Data Analysis"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++",
            "Java",
            "MATLAB"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Engineering",
                "Applied Mathematics",
                "Physics",
                "Physical Sciences",
                "Biological Sciences"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Employee Owned",
            "Work-Life Balance",
            "Flexibility",
            "Comprehensible Benefits Package"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3969110689,
        "company": "Ardent Blue Technologies",
        "title": "Machine Learning Engineer",
        "created_on": 1720587922.494884,
        "description": "Machine Learning Engineer - Remote Ardent Blue Technologies is a software development and staff augmentation company doing business since 2011. We have secured well recognized Fortune 500 clients in a number of domains including game development, game/film/architecture tools, game anti-cheat, IoT, VR and others. We are presently assisting our client with their trading analysis platform; developing new tools to bring advanced financial trading approaches to the masses. Based in NYC, the platform consists of Web and Native applications. Our client seeks an ML/AI software engineer to develop a financial AI algorithm for traders. Collaborating with the lead NLP Engineer, you will build the backend of a conversational interface to parse financial documents and answer trading-related queries. Responsibilities include developing and optimizing scalable systems using advanced ML models and RAG for high-volume query processing. RESPONSIBILITIES: Build an end-to-end chat interface for financial user queries and natural language responses. Optimize financial data indexing with advanced preprocessing tools and vector embedding models. Develop a scalable backend for the NLP chat interface. Create ML models for analyzing financial data in response to natural language queries. Ensure a fully tested codebase for reliable system performance. Communicate ongoing requirements and future goals with the team. Oversee software deployment using Docker and AWS. QUALIFICATIONS: 6+ years work experience in software development Minimum two years of professional experience in coding, building and deploying NLP/ML systems. Experience with RAG, vector embeddings, LLMs, and chatbot development. Strong analytical thinking and problem-solving skills. Proficiency in Python, including ML libraries and tools (e.g., vector embedding, RAG, cloud-based APIs). Familiarity with RAG models, chat bots, VectorDB, Git, AWS EC2/S3/ECS, and Docker is a plus.",
        "url": "https://www.linkedin.com/jobs/view/3969110689",
        "summary": "Ardent Blue Technologies is seeking an experienced ML/AI software engineer to develop a financial AI algorithm for a trading analysis platform. The role involves building a conversational interface to parse financial documents and answer trading-related queries, optimizing data indexing, developing a scalable backend, and creating ML models for analyzing financial data. The ideal candidate will have 6+ years of software development experience, 2+ years of NLP/ML system development experience, and proficiency in Python, ML libraries, and cloud-based APIs.",
        "industries": [
            "Software Development",
            "Financial Technology (FinTech)",
            "Artificial Intelligence (AI)",
            "Natural Language Processing (NLP)",
            "Trading",
            "Data Science"
        ],
        "soft_skills": [
            "Analytical Thinking",
            "Problem-Solving",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "ML Libraries",
            "RAG",
            "Vector Embeddings",
            "LLMs",
            "Chatbot Development",
            "Financial Data Analysis",
            "Docker",
            "AWS"
        ],
        "tech_stack": [
            "RAG",
            "Vector Embeddings",
            "LLMs",
            "Chatbots",
            "VectorDB",
            "Git",
            "AWS EC2",
            "AWS S3",
            "AWS ECS",
            "Docker"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Boston, MA",
        "job_id": 3962779831,
        "company": "Gecko Robotics",
        "title": "Machine Learning Engineer",
        "created_on": 1720587924.0917747,
        "description": "What We Do Gecko Robotics is helping the world's most important organizations ensure the availability, reliability, and sustainability of critical infrastructure. Gecko's complete and connected solutions combine wall-climbing robots, industry-leading sensors, and an AI-powered data platform to provide customers with a unique window into the current and future health of their physical assets. This enables real-time decision making to increase the efficiency and safety of operations, promote mission readiness, and protect the environment and civilization from the effects of infrastructure failure. Role at a Glance As a Machine Learning Engineer at Gecko, you will be working with Gecko's unique dataset to develop and deploy machine learning models to solve critical business problems. You will work deeply on problems such as: classifying valid vs. invalid signals; taking accurate measurements from valid signals; and identifying damage mechanisms such as cracks, corrosion, or laminations across a large collection of signals. Gecko owns a growing repository of mechanical integrity data, including large volumes of ultrasonic, imagery, and other data points concerning the integrity of critical infrastructure assets worldwide. Gecko is expanding our Machine Learning team to better leverage the vast data store we have collected over time. This is a chance to be one of the first dedicated engineers in an area we expect to grow significantly over the next few years, within a space that is ripe for innovation and solving problems in a way they haven't been attempted before. What you will do Develop novel (supervised and unsupervised) ML models to help solve important business problems, becoming an expert in unique domains like ultrasonic digital signal processing for non-destructive testing. Roll out models to production by developing integrations with mission critical analytical tools and building the necessary ML Ops infrastructure to support high quality iteration. Help Gecko identify new problems we could tackle with AI/ML (such as defect detection, automated repair planning, and more) and help cultivate necessary training sets to start solving those problems. Technologies We Use Python, PyTorch, Numpy Docker, GCP, Cloud Run, Batch, Collab Ultrasonic DSP We use a variety of technologies, but our Software teams primarily operate using Python, React, and Typescript with Google Cloud Platform (GCP) as our cloud provider. This is a non-exhaustive list and we are tech agnostic in our interview process, so we encourage you to apply regardless of your background. About You Required Skills 5+ years of engineering experience, with at least 3+ years in a dedicated machine learning role Practical knowledge of machine learning algorithms and frameworks suitable for time-series analysis and anomaly detection in signal data Ability to read and implement ML papers Knowledge of at least 1 machine learning framework (i.e. PyTorch) and has seen at least one ML model in production Familiarity with MLOps concepts A strong sense of intellectual curiosity, and the desire to dive deep into exploratory projects alongside production ready deployments Preference for projects with high ownership, and the ability to work effectively both autonomously and on teams Desire to have a high impact at a fast-moving startup as a key contributor on a new project and fast-growing team Exceptional communication skills and commitment to receiving and providing continuous feedback Bachelor's degree in Computer Science or closely related field (or equivalent experience) Preferred Skills Experience with PyTorch Experience with MLOps tools such as MLFlow Machine Learning work in ultrasonic signals, audio signals, or another unconventional domain Evidence of clear impact and growth in a fast-growing startup environment Who We Are At Gecko, our people are our greatest investment. In addition to competitive compensation packages, we offer company equity, 401(k) matching, gender-neutral parental leave, full medical, dental, and vision insurance, mental health and wellness support, ongoing professional development, family planning assistance, and flexible paid time off. Gecko values collaboration, innovation, and partnership, and we believe we do our best work when we're together in person. We're an office-first culture but understand that sometimes you may need to work from home. Many people are in the office five days a week, others need a bit more flexibility. Ultimately, we care about the outcomes we achieve - and creating a culture of autonomy and trust that enables that impact. Gecko is committed to creating a culture of inclusion and belonging, and we are proud to be an equal opportunity employer. We believe it is our collective responsibility to uphold these values and encourage candidates from all backgrounds to join us in our mission to protect today's infrastructure and give form to tomorrow's. All qualified applicants will be treated with respect and receive equal consideration for employment without regard to race, color, creed, religion, sex, gender identity, sexual orientation, national origin, disability, uniform service, veteran status, age, or any other protected characteristic per federal, state, or local law. If you are passionate about what you do and want to use your talents to support our critical mission, we'd love to hear from you.",
        "url": "https://www.linkedin.com/jobs/view/3962779831",
        "summary": "Gecko Robotics is seeking a Machine Learning Engineer to develop and deploy ML models for solving business problems related to critical infrastructure integrity. The role involves analyzing ultrasonic, imagery, and other data, creating models for signal classification, measurement, and damage identification. The ideal candidate has 5+ years of engineering experience, with 3+ years in ML, expertise in time-series analysis and anomaly detection, and experience with PyTorch. The position offers competitive compensation, equity, benefits, and a collaborative work environment.",
        "industries": [
            "Infrastructure",
            "Engineering",
            "Robotics",
            "Technology",
            "Data Science",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Curiosity",
            "Problem Solving",
            "Autonomous Work",
            "Teamwork",
            "Ownership"
        ],
        "hard_skills": [
            "Machine Learning",
            "Time-Series Analysis",
            "Anomaly Detection",
            "Signal Processing",
            "PyTorch",
            "MLOps",
            "Ultrasonic",
            "Digital Signal Processing",
            "Non-Destructive Testing",
            "Python",
            "Docker",
            "GCP",
            "Cloud Run",
            "Batch",
            "Collab",
            "React",
            "Typescript"
        ],
        "tech_stack": [
            "Python",
            "PyTorch",
            "Numpy",
            "Docker",
            "GCP",
            "Cloud Run",
            "Batch",
            "Collab",
            "Ultrasonic DSP",
            "React",
            "Typescript"
        ],
        "programming_languages": [
            "Python",
            "Typescript"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Compensation",
            "Equity",
            "401(k) Matching",
            "Gender-Neutral Parental Leave",
            "Medical",
            "Dental",
            "Vision",
            "Mental Health Support",
            "Professional Development",
            "Family Planning Assistance",
            "Flexible Paid Time Off"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3964315661,
        "company": "Hugging Face",
        "title": "Machine Learning Engineer, Fast Optimized Inference - US Remote",
        "created_on": 1720587928.5838592,
        "description": "Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better. We have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA. About the role: As a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage. We are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction. Objectives of this role: Develop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference). Utilize existing library frameworks to create scalable software solutions for industrial purposes. Enhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation. Manage the production environment by monitoring availability and ensuring overall system health. We run our own tools About you: If you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment. More about Hugging Face We are actively working to build a culture that values diversity, equity, and inclusivity . We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We value development. You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education. We care about your well-being . We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also flexible parental leave and paid time off. We support our employees wherever they are . While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed. We want our teammates to be shareholders . All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside. We support the community . We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.",
        "url": "https://www.linkedin.com/jobs/view/3964315661",
        "summary": "Hugging Face is seeking a Machine Learning Engineer to develop specialized software for specific machine learning (ML) use cases with broad applications. The ideal candidate will be proficient in Python, Rust, and Cuda kernels frameworks (Transformers, Keras, or PyTorch), and have a passion for AI. Responsibilities include building scalable software solutions, enhancing the reliability and quality of the software suite, and managing the production environment. Hugging Face offers a competitive salary, equity, benefits, and a collaborative and stimulating work environment.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Software Development"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Critical thinking",
            "Passionate",
            "Innovative",
            "Teamwork",
            "Adaptability"
        ],
        "hard_skills": [
            "Python",
            "Rust",
            "Cuda",
            "Transformers",
            "Keras",
            "PyTorch",
            "Machine Learning",
            "Software Development"
        ],
        "tech_stack": [
            "Transformers",
            "Keras",
            "PyTorch",
            "Cuda",
            "Python",
            "Rust"
        ],
        "programming_languages": [
            "Python",
            "Rust",
            "Cuda"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Flexible Working Hours",
            "Remote Options",
            "Parental Leave",
            "Paid Time Off",
            "Equity",
            "Conference Reimbursement",
            "Training & Education Reimbursement",
            "Workstation Setup"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greenville, SC",
        "job_id": 3969676568,
        "company": "HKA Enterprises",
        "title": "Data Scientist 192840",
        "created_on": 1720587930.0455947,
        "description": "Job Description NO 1099 OR CORP TO CORP FOR THIS CONTRACT POSITION. NO RELOCATION ASSISTANCE OFFERED. Client Title: Data Scientist Shift: 8 AM until 5 PM – Monday-Friday Term of Contract: Long-term/ongoing with no end date Pay Range OR Rate: USD 50.72-USD 69.74 DOE PTO, Sick Pay, and Holiday Pay are offered . THIS IS NOT A REMOTE POSITION Looking for a local candidate or someone who is willing to relocate. This position requires a minimum of 40% onsite attendance: 2 days each week. Job Requirements Overview Of Position Working with large data sets and prepping the data for consumption Assessing the effectiveness and accuracy of data sources Working with business users to obtain more insight into data sources. Asking the right questions to understand how the data can be used. Evaluating the results of machine learning algorithms Determining the feasibility of a use case given the business problem and the available data. Monitoring and analyzing model performance Performing prompt engineering tasks with specific use cases Required Skills Working with large data sets Python to manipulate data Machine learning: (clustering, decision tree learning, artificial neural networks, etc.) Experience using deep learning architectures (RNN, CNN, LSTM, etc.) and frameworks (Tensor flow, Kera’s, etc.) Experience in natural language processing Experience using database technologies including SQL, Oracle, SQL Server, or NoSQL databases. Experience using cloud technology and services specifically in AWS including Athena, Glue, Sagemaker, and QuickSight Experience with at least one common OpenSource high-level LLM-framework (e.g. LangChain, Llama-Index), evaluation techniques and agentic principles Familiarity with modern software development, Devops strategies and tooling (GitOps) Experience using machine learning models in the automotive industry would be nice to have. Travel: Possibly 5 percent Internationally or Domestically Position Purpose/Scope Accelerates and supports the ongoing activities in the field of Artificial Intelligence and Computer vision for multiple use cases for quality improvement in manufacturing. Deals with large volumes of data and understands and explores data critical to the business. Drives data for future company processes and products. Works with different company business units to understand the business demands with respect to Artificial Intelligence and Quality Assessment. Conducts advanced analytical tasks, designs deep learning models, data mining, and computer vision to enable company to improve its products, services, and processes. Position Responsibilities Analyzes business-critical data and recommends improvements. Works with large data sets consisting of predominantly images and conducts advanced analytics tasks. Assess the effectiveness and accuracy of new data sources and data-gathering techniques. Works with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Develops custom data models and algorithms to apply to data sets. Coordinates with different functional teams to implement models and monitor outcomes. Develops processes and tools to monitor and analyze model performance and data accuracy. Serves as an internal consultant to other developers and engineers as needed, providing assistance in all phases of product life-cycle development. Advises developers and engineers on the latest data analytics technologies and assists the team in process matters related to development/support and provides the necessary on-the-job training and development of associates/contractors within the team. Maintains accurate, meaningful, and updated technical and non-technical documentation pertaining to all aspects of area(s) of responsibility. Performs other duties as assigned by the Operations Supervisor Education Position Competencies: Bachelor’s degree in computer science, mathematics/statistics, or a related field, required. Master’s preferred Experience 3+ years post-university experience in advanced analytics in the field of data science, applying scientific data analytics methods preferably to automotive industry datasets. 1+ years proven experience completing projects with a set of various data sources 3+ years of knowledge in using statistical computer languages (Python, SLQL, etc) to manipulate data and draw insights from large data sets 1+ years of knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Intermediate knowledge of deep learning architectures (RNN, CNN, LSTM, etc.) and frameworks (Tensor flow, Keras, etc.) 3+ years of knowledge of in one or more of the following programming languages: Python, Java, C++ 3+ years of knowledge and experience in Computer Science and in database technologies including SQL, Oracle, SQLServer, SAP HANA and NoSQL databases 3+ years of experience in statistical languages and tools in particular R 3+ years of experience in problem solving skills with an emphasis on product development #ENGTEC #CB",
        "url": "https://www.linkedin.com/jobs/view/3969676568",
        "summary": "Data Scientist needed for long-term contract, 2 days/week onsite, to work with large datasets, develop machine learning models, and improve manufacturing processes through AI and computer vision.  Experience in automotive industry data is a plus.",
        "industries": [
            "Automotive",
            "Manufacturing",
            "Artificial Intelligence",
            "Computer Vision",
            "Data Science"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Analytical Thinking",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing",
            "Data Mining",
            "Computer Vision",
            "AWS",
            "Athena",
            "Glue",
            "Sagemaker",
            "QuickSight",
            "LangChain",
            "Llama-Index",
            "Git",
            "R",
            "Oracle",
            "SQL Server",
            "NoSQL",
            "TensorFlow",
            "Keras",
            "SLQL",
            "C++",
            "Java"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "AWS",
            "Athena",
            "Glue",
            "Sagemaker",
            "QuickSight",
            "LangChain",
            "Llama-Index",
            "TensorFlow",
            "Keras",
            "R",
            "Oracle",
            "SQL Server",
            "NoSQL"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "R",
            "C++",
            "Java"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 6974,
            "min": 5072
        },
        "benefits": [
            "PTO",
            "Sick Pay",
            "Holiday Pay"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3963944874,
        "company": "Newfire Global Partners",
        "title": "Senior Data Scientist",
        "created_on": 1720587933.0108314,
        "description": "Take the opportunity to work with highly professional people with remarkable ideas on their minds! Newfire Global Partners is a rapidly growing, privately-held, American company that provides advisory and technology services to some of the world’s most innovative companies. From 2022 to 2024, Inc. Magazine has recognized Newfire as one of the fastest-growing companies in America. Headquartered in Boston with operations spanning four continents (including teams in Argentina, Brazil, Canada, Costa Rica, Columbia, Croatia, Malaysia, Mexico, Ukraine, United States, and others), our global staff of nearly 1,000 professionals represents top talent worldwide in the areas of software development, product management, data science & data engineering, and CEO & board advisory services. Our core values are demonstrated by a commitment to continuous improvement, open communication & trust, and respect for the individual. You Perfectly Match If you have: A bachelor's or Master's degree in a quantitative field, such as Data Science, Economics, Statistics, Engineering, or a related discipline. 5-10 years of hands-on experience in a data science role, with a demonstrated track record of success in applying statistical modeling and machine learning techniques to real-world problems. Strong understanding of the US healthcare landscape , including familiarity with common terminology, data sources, and regulatory requirements. Proven experience developing, deploying, and evaluating risk adjustment models in a production environment, ideally within the healthcare sector . Demonstrated proficiency in building and refining GLM models, including the ability to identify and address statistical anomalies and edge cases. Proficient in model training and maintenance, including model drift Ability to effectively translate complex customer and business needs into actionable evaluation frameworks that guide model development and validation. Proficiency in Python and the scikit-learn library, with the ability to write clean, efficient code and leverage advanced statistical techniques. Excellent written and verbal communication skills, with the ability to tailor complex technical concepts to diverse audiences, including non-technical stakeholders. Nice to have: Experience scaling models and analysis across large datasets Proficient in Spark/PySpark Your day-to-day activities: Lead the technical development and maintenance of data-driven solutions that continuously improve the accuracy and efficiency of population and payer health analytics. Contribute expertise to the design and implementation of software that seamlessly integrates healthcare episodes of care risk adjustment methodologies into the value platform. Leverage state-of-the-art tools and technologies to analyze complex datasets, build predictive models, and generate actionable insights. Partner with analysts, software engineers, and product managers to translate business needs into effective data solutions and ensure seamless integration across the platform.",
        "url": "https://www.linkedin.com/jobs/view/3963944874",
        "summary": "Newfire Global Partners is looking for a data scientist with 5-10 years of experience in the US healthcare sector. The ideal candidate will have experience building and refining GLM models, applying statistical modeling and machine learning techniques to real-world problems, and developing risk adjustment models in a production environment. They should also be proficient in Python and the scikit-learn library, and have experience scaling models and analysis across large datasets.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Technology",
            "Software Development",
            "Consulting"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Skills",
            "Collaboration",
            "Technical Skills",
            "Presentation Skills",
            "Leadership",
            "Teamwork",
            "Data Analysis"
        ],
        "hard_skills": [
            "Statistical Modeling",
            "Machine Learning",
            "GLM Models",
            "Risk Adjustment Models",
            "Data Science",
            "Python",
            "Scikit-learn",
            "Spark",
            "PySpark",
            "Healthcare Data",
            "US Healthcare Landscape",
            "Data Analysis",
            "Model Development",
            "Model Validation",
            "Model Deployment"
        ],
        "tech_stack": [
            "Python",
            "Scikit-learn",
            "Spark",
            "PySpark"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Economics",
                "Statistics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Huntsville, AL",
        "job_id": 3962831922,
        "company": "FNA",
        "title": "Data Scientist",
        "created_on": 1720587934.5524702,
        "description": "Department: Global Services Location: Huntsville, Alabama - On Site in USG Facility (Hybrid working conditions are at the approval of local authorities) Term: Full time | Contingent Upon Successful Background Check Number of Positions: 1 Position 1 Start Date: Immediate Citizenship: US Citizen Clearance: Public Trust - Background Check - HSI Suitability Check ________________________ Why this role is important The Data Scientist will develop the methodologies and tools needed to enhance the government’s goal of developing more intelligence and investigative leads, of better quality. You will choose the best approach for the project; brief methodologies and outcomes, and create new ‘norms’ for investigative support processes. Your impact will be made on important casework being conducted by the federal government. About the role The Data Scientist will be an on-site presence supporting the the US Government, with the following: Execute FNA’s Augmented Targeting Cycle of Analyze, Detect, and Dismantle (AD2) for the HSI Client inclusive of leveraging advanced network science and machine learning capabilities to enable more effective targeting Provide repeatable solutions for exploiting quantitative and qualitative / unstructured data from various sources and preparing it for analytics and applying it to the AD2 solution Execute ETL tasks and data cleansing, ensuring multiple sources of data are suitable for analytical driven solutions Support targeting tasks and create a repeatable solution or process for creating opportunities for information collection by agents, given a complement of government provided data enriched through targeted PAI, web, and dark web data collection Support targeting tasks and create a repeatable process for simulating the outcome of effects based targeting courses of action Support the identification of threat elements use of obfuscation measures, where organizational or individual behavior is incongruent with declared or otherwise labeled behavior expectations. Why join FNA? Own and deliver meaningful work, making a global impact Rapidly advance your career, thinking and skills in a high growth tech company Collaborate with a diverse international team of innovative and high-achieving colleagues Annual stipend for personal and professional development International team off-sites in sunny locations We reward curiosity, initiative, execution and reliability with opportunity Who we’re looking for Five or more years of experience in designing, developing, and deploying advanced analytics in support of knowledge discovery/link analysis for law enforcement purposes Five or more years of experience in extract, transform and load (ETL) processes on data from open web, dark web, and websites hosted outside of the United States Five or more years of experience in data ingestion, data sciences, integration, and fusion in response to new and expanding requirements Bachelor’s degree from an accredited University in a quantitative discipline such as computer science, data science, statistics, or mathematics Capability to clearly explain complex problem solving techniques and solutions to non-technical audiences Demonstrable understanding of the different types of US Government information and intelligence collection (HUMINT, SIGINT, GEOINT, etc) Demonstrable aptitude to utilize data analytics to create trend analysis Capability to come up with outside the box ideas to effectively guide the customer towards data driven solutions to relevant requirements and problems Proficiency in established defense and intelligence analytics software, including Palantir, SemanticAI, IBM i2 Analyst Notebook, etc is a plus Proficiency or experience with information dashboard software (Tableau, Power BI, Kibana), is a plus Defense or Intelligence community experience (five years or greater), a plus. _____________________________________________________________________ Government Specified Tasks Analytic Work Product development. Discuss product requirements as determined by the approach to produce work products, such as a dashboard-like summary (or presentations) of comprehensive analysis on movement and activities of weapons and/or systems of high-risk areas. Products can include the utilization of tools such as Tableau/Power BI/Kibana. Analytical work products. Comprehensive summary and evaluation of strategic analysis that will support operational and intelligence gaps, transformational methodologies, and exploratory data sets. Products can include regional or large scale trend analysis on export commodities (or entities) of interest. Lead Enhancement. Develop lead packages to include an information sheet on suspect and/or entities of interest and/or active and developing threats. Data management. Identify process gaps in data management related to HSI counterproliferation law enforcement activity, access new data, clean/normalize/disambiguate new data, data storage. Categorize extracted data based on its origin, utility, and urgency and build query-able databases. Source Analysis. Conduct open source (e.g., social media exploitation and dark web scraping) to identify and determine new data sources to expand trend analysis on regional or global trade on weapons and/or systems of interest for the counterproliferation mission. Trend Analysis - Identify trends, detect high-risk areas for weapons proliferation and prioritize enforcement approaches by applying advanced analytics, including link and forensic analysis. Data Validation/Assessment. Conduct evaluation and verification of the data sets and the associated results (e.g., trend analysis) to determine the risk factors and magnitude of error. About FNA FNA is a leader in advanced network analytics and simulation. Our software is used to uncover hidden connections and anomalies in large, complex datasets, to predict the impact of stress events, and to optimally configure financial systems and infrastructures. FNA is trusted by the world’s largest central banks, government authorities, commercial banks and financial infrastructures.",
        "url": "https://www.linkedin.com/jobs/view/3962831922",
        "summary": "This is a full-time, on-site Data Scientist role at FNA in Huntsville, Alabama, supporting the US Government's efforts to enhance intelligence and investigative leads. Responsibilities include executing FNA's Augmented Targeting Cycle of Analyze, Detect, and Dismantle (AD2), providing data analytics solutions, and supporting targeting tasks. The ideal candidate has 5+ years of experience in advanced analytics, ETL processes, data sciences, and a bachelor's degree in a quantitative discipline. Proficiency in Palantir, SemanticAI, IBM i2 Analyst Notebook, Tableau, Power BI, and Kibana is a plus. Defense or Intelligence community experience is also highly valued.",
        "industries": [
            "Government",
            "Intelligence",
            "Law Enforcement",
            "Data Analytics",
            "Software"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Analytical thinking",
            "Data analysis",
            "Trend analysis",
            "Collaboration",
            "Initiative",
            "Reliability"
        ],
        "hard_skills": [
            "Network science",
            "Machine learning",
            "Data cleansing",
            "ETL",
            "Data ingestion",
            "Data fusion",
            "Link analysis",
            "Open web data",
            "Dark web data",
            "Quantitative analysis",
            "Data management",
            "Data validation",
            "Trend analysis",
            "Forensic analysis",
            "Social media exploitation",
            "Dark web scraping",
            "Tableau",
            "Power BI",
            "Kibana",
            "Palantir",
            "SemanticAI",
            "IBM i2 Analyst Notebook",
            "HUMINT",
            "SIGINT",
            "GEOINT"
        ],
        "tech_stack": [
            "Palantir",
            "SemanticAI",
            "IBM i2 Analyst Notebook",
            "Tableau",
            "Power BI",
            "Kibana"
        ],
        "programming_languages": [],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Annual stipend for personal and professional development",
            "International team off-sites"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Orlando, FL",
        "job_id": 3962141818,
        "company": "DCS Corp",
        "title": "Data Scientist",
        "created_on": 1720587936.1624784,
        "description": "We are currently hiring a Data Scientist to join our Orlando, FL team to support development of advanced ground vehicle technologies for manned and unmanned platforms for the US Army Combat Capabilities Development Command (CCDC) Soldier Center. As a Data Scientist with DCS, you will perform analysis of human subjects research data for a wide array of Soldier Center programs. Essential Job Functions Work with the data collection and analysis team to create comprehensive data collection and analysis plans. Support the human subjects research team to incorporate elements of the data collection and analysis plans into test protocols and test reports. Analyze human subjects research data to support completion of research objectives. Types of analysis to be performed include classification, regression, cluster analysis, time series analysis, etc. Code development for pre and post processing of data and subsequent analysis. Creation of data visualizations. Provide written explanations of data processing and analysis performed in support of its relevance to research goals. Position will require occasional travel to support test and integration events. Required Skills Due to the sensitivity of customer related requirements, U.S. Citizenship is required. Must be able to obtain Secret clearance. Bachelor's Degree in Computer Science, Data Science, Informatics, or similar with 5 years of experience. Coding proficiency (ex. Python, R, MATLAB). Experience with the application of Machine Learning (ML) to Natural Language Processing (NLP) (ex. Text Classification). Experience with collaborate version control platforms (ex. GitLab, GitHub, BitBucket, Jupyter Notebook). Desired Skills Familiarity/experience developing or working with military systems. Familiarity/experience with Human Subjects Research, Institutional Review Board (IRB) processes, and Human Use Committee (HUC) procedures.",
        "url": "https://www.linkedin.com/jobs/view/3962141818",
        "summary": "Data Scientist to support development of advanced ground vehicle technologies for manned and unmanned platforms for the US Army Combat Capabilities Development Command (CCDC) Soldier Center.",
        "industries": [
            "Defense",
            "Military",
            "Research",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical",
            "Time Management"
        ],
        "hard_skills": [
            "Data Collection",
            "Data Analysis",
            "Classification",
            "Regression",
            "Cluster Analysis",
            "Time Series Analysis",
            "Coding",
            "Machine Learning",
            "Natural Language Processing",
            "Text Classification",
            "Version Control",
            "Military Systems",
            "Human Subjects Research",
            "Institutional Review Board (IRB)",
            "Human Use Committee (HUC)"
        ],
        "tech_stack": [
            "Python",
            "R",
            "MATLAB",
            "GitLab",
            "GitHub",
            "BitBucket",
            "Jupyter Notebook"
        ],
        "programming_languages": [
            "Python",
            "R",
            "MATLAB"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Informatics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Philadelphia, PA",
        "job_id": 3970711625,
        "company": "Team Remotely Inc",
        "title": "Junior Python Developer",
        "created_on": 1720587937.8126214,
        "description": "This is a remote position. Junior Python Developer (1 year experience, remote) Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum. Description: In this role, you will work closely with senior developers and other cross-functional teams to develop and maintain high-quality Python applications. As a Junior Python Developer, you will have the opportunity to learn and grow your skills while contributing to exciting projects. Responsibilities: Collaborate with senior developers to design and develop Python applications. Write clean, efficient, and maintainable code that follows best practices. Participate in code reviews and provide constructive feedback. Debug and fix issues in the existing codebase. Assist in testing and quality assurance processes. Stay updated with the latest trends and technologies in Python development. Requirements: Bachelor's degree in Computer Science, Software Engineering, or a related field. Strong knowledge of Python programming language. Familiarity with web frameworks such as Django or Flask. Experience with version control systems, preferably Git. Basic understanding of front-end technologies (HTML, CSS, JavaScript). Good problem-solving and analytical skills. Excellent communication and teamwork abilities. Self-motivated and eager to learn. Nice to have: Experience with database systems such as MySQL, PostgreSQL, or MongoDB. Knowledge of RESTful APIs and integration. Familiarity with cloud platforms such as AWS or Azure. Understanding of agile development methodologies. Benefits: Flexible vacation, unlimited paid holidays, and paid sick days 401(k) with up to 2% employer match Health, vision, and dental insurance",
        "url": "https://www.linkedin.com/jobs/view/3970711625",
        "summary": "This is a remote, full-time Junior Python Developer role where you'll collaborate with senior developers to design, develop, and maintain Python applications. You'll be working on projects like creating clean, efficient, and maintainable code, participating in code reviews, debugging and fixing issues, testing, and staying updated with the latest Python trends. ",
        "industries": [
            "Software Development",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem-solving",
            "Analytical",
            "Self-motivation",
            "Eager to learn"
        ],
        "hard_skills": [
            "Python",
            "Django",
            "Flask",
            "Git",
            "HTML",
            "CSS",
            "JavaScript",
            "MySQL",
            "PostgreSQL",
            "MongoDB",
            "RESTful APIs",
            "AWS",
            "Azure",
            "Agile Development"
        ],
        "tech_stack": [
            "Python",
            "Django",
            "Flask",
            "Git",
            "HTML",
            "CSS",
            "JavaScript",
            "MySQL",
            "PostgreSQL",
            "MongoDB",
            "RESTful APIs",
            "AWS",
            "Azure"
        ],
        "programming_languages": [
            "Python",
            "JavaScript"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Software Engineering"
            ]
        },
        "salary": {
            "max": 67000,
            "min": 57000
        },
        "benefits": [
            "Flexible vacation",
            "Unlimited paid holidays",
            "Paid sick days",
            "401(k) with up to 2% employer match",
            "Health, vision, and dental insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Francisco, CA",
        "job_id": 3962250239,
        "company": "Infinitus Systems, Inc.",
        "title": "Data Scientist (Senior) - AI Analytics",
        "created_on": 1720587939.1416755,
        "description": "Infinitus is at the forefront of process automation in healthcare, dedicated to reducing costs and complexity through innovative NLP solutions. We are hiring a full-stack data scientist to support our LLM efforts and AI innovation located in San Francisco. Infinitus is leading the way in changing healthcare by automating routine backend phone calls, saving healthcare providers time to focus on what matters most–their patients. The Data Science team at Infinitus plays a pivotal role in advancing our mission through the adoption of a data-driven methodology for crafting both NLP product and business strategies, establishing and evaluating key performance indicators, and continuously driving improvements to our AI platform. Collaborating intimately with teams in Product, Business, Design, Engineering, and the larger Data team, our Data Scientists employ methods such as experimentation, statistical analysis, machine learning, causal analysis, and data storytelling. This collaborative effort aims to expand our comprehension of user interactions with our AI platform and to make strategic choices that enhance business outcomes. Responsibilities Designing and developing new methodologies for assessing and monitoring advancements in our suite of cutting-edge AI and NLP products. Conducting and promoting strategic analyses to guide the direction of our AI innovations. Crafting ML and NLP models inline with our automation goals to foster business growth. Structuring and evaluating experiments to ascertain the effectiveness of novel LLM and ML functionalities. Requirements Strong desire to improve healthcare through automation. Advanced degree in a computational field such as: computer science, math, linguistics, statistics, economics, or equivalent experience. 5+ years of experience in applying data science techniques to drive technical product development and decision-making Strong ability in managing stakeholders, communicating complex concepts to diverse audiences, crafting compelling stories and driving decisions Expertise in Python together with relational data modeling and SQL Expertise in machine learning, statistical methods and experimental design and analysis. Infinitus Systems, Inc. is an early stage startup building a voice automation platform to enable businesses to communicate with each other efficiently. Infinitus has raised $51.4M to date and is backed by Kleiner Perkins, Coatue Management and Google Ventures. Healthcare is one of the biggest contributors to the US GDP and we are on a mission to reduce the complexity and spend on healthcare backoffices. At Infinitus, you will have a unique perspective on the development of cutting edge technology while working with major players across the healthcare industry in the US. Infinitus is made up of engineers, product managers, AI trainers, and operations specialists who collaborate on all kinds of projects. We not only encourage each other to do our best work, we also share our pet pictures, our favorite recipes, and stories from our vacations. At Infinitus Systems, we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, and any other characteristic protected by applicable law. Infinitus Systems believes that diversity and inclusion among our teammates is critical to our success as a global company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool.",
        "url": "https://www.linkedin.com/jobs/view/3962250239",
        "summary": "Infinitus is seeking a full-stack data scientist to join their team in San Francisco and work on NLP solutions for healthcare automation.  This role involves designing and developing new methodologies for assessing and monitoring AI and NLP products, conducting strategic analyses to guide AI innovation, crafting ML and NLP models, and structuring and evaluating experiments.  Infinitus is an early-stage startup with $51.4M in funding backed by Kleiner Perkins, Coatue Management and Google Ventures. They are focused on reducing complexity and spend in healthcare backoffices.",
        "industries": [
            "Healthcare",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing",
            "Software"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Leadership",
            "Problem Solving",
            "Strategic Thinking",
            "Data Storytelling",
            "Experimentation"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Relational Data Modeling",
            "Machine Learning",
            "Statistical Methods",
            "Experimental Design",
            "Causal Analysis"
        ],
        "tech_stack": [
            "NLP",
            "AI",
            "LLM",
            "ML"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Advanced Degree",
            "fields": [
                "Computer Science",
                "Math",
                "Linguistics",
                "Statistics",
                "Economics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Houston, TX",
        "job_id": 3967508598,
        "company": "ShiftCode Analytics, Inc.",
        "title": "Data Scientist",
        "created_on": 1720587943.6845946,
        "description": "DATA SCIENTIST 6+ MONTHS CONTRACT HOUSTON, TEXAS FULLY ONSITE ROLE NEED LOCAL PROFILES ONLY VISA- USC/GC ONLY CLIENT DOMAIN- ENERGY Requirements 5+ years of practical experience framing and solving business problems in supply chain, logistics, or operations with probability / statistics, visualization, inferential or predictive models 5+ years professional experience programming production code in Python Software engineering skills - best practices of software design, API design, knowledge of design patterns, version control, and production considerations such as performance, logging, maintainability, refactoring, testing and debugging Hands on experience with MLOps Experience building solutions in AWS is a plus Educational background in Statistics, Applied Mathematics, or scientific field is a plus Ability to adapt in a rapidly changing environment Ability to communicate insights and approaches in a simple, actionable manner Ability to work independently and with team members from different backgrounds Excellent attention to detail and problem-solving skills Responsibilities Include Work independently on data science / Client projects for multiple business functions Identify and frame the data science / Client opportunity from understanding the business problem / opportunity Gather, cleanse, and transform internal and external data Analyze data and deliver insights via visualizations and dashboards Create, productionize, and maintain models / solutions that address business problems Present, explain and defend results from analysis and modeling, and approach taken Participate in strategic planning discussions around optimizations, data science and big data analytics",
        "url": "https://www.linkedin.com/jobs/view/3967508598",
        "summary": "A 6+ month contract position for a Data Scientist with 5+ years of experience in supply chain, logistics, or operations using probability/statistics and predictive modeling. The role requires proficiency in Python, MLOps, AWS, and strong communication skills. Responsibilities include data analysis, model building, and presenting insights to stakeholders.",
        "industries": [
            "Energy",
            "Supply Chain",
            "Logistics",
            "Operations"
        ],
        "soft_skills": [
            "Communication",
            "Problem-Solving",
            "Adaptability",
            "Teamwork",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Python",
            "Statistics",
            "Data Analysis",
            "Predictive Modeling",
            "Visualization",
            "MLOps",
            "AWS",
            "Software Engineering",
            "API Design",
            "Design Patterns",
            "Version Control",
            "Performance Optimization",
            "Logging",
            "Maintainability",
            "Refactoring",
            "Testing",
            "Debugging"
        ],
        "tech_stack": [
            "Python",
            "AWS",
            "MLOps"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Applied Mathematics",
                "Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Somerset, NJ",
        "job_id": 3962245804,
        "company": "Terumo Medical Corporation",
        "title": "Senior Data Scientist Machine Learning Engineer",
        "created_on": 1720587945.396881,
        "description": "Job Summary: This Senior Data Scientist, Machine Learning Engineer will leverage cloud computing technologies to develop, deploy, and manage predictive models that support decision-making processes across the Terumo organization. The role demands a strategic approach to ownership, involving collecting, cleaning, and preprocessing large datasets, designing and building predictive models using machine learning algorithms, and deploying models in a cloud environment. The Senior Data Scientist, Machine Learning Engineer will be responsible for continuously monitoring model performance and making necessary adjustments to improve accuracy and efficiency. This role includes defining and executing ownership strategies, ensuring models are integrated seamlessly into business processes, and aligning with organizational goals. Job Details: Data Exploration and Preprocessing: Collect, clean, and preprocess large datasets to prepare them for analysis. Identify patterns, outliers, and trends within the data, ensuring high data quality and integrity. Take ownership of the data lifecycle, from ingestion to processing, ensuring best practices and compliance. Model Development: Design and build predictive models using machine learning algorithms. Experiment with various algorithms and tuning parameters to optimize model performance. Lead the strategy for selecting appropriate modeling techniques and tools, ensuring alignment with business needs and technological capabilities. Cloud Deployment: Deploy models in a cloud environment, ensuring they are scalable, reliable, and secure. Utilize cloud services (e.g., AWS, Azure, Google Cloud) for computing resources, data storage, and model hosting. Develop and implement a comprehensive deployment strategy, emphasizing reliability, security, and scalability. Performance Monitoring: Continuously monitor model performance, making adjustments as needed to improve accuracy and efficiency. Implement A/B testing and other techniques to validate models. Establish and oversee a robust performance monitoring framework, ensuring proactive issue identification and resolution. Collaboration: Work closely with data engineers, cloud architects, and business analysts to integrate predictive models into business processes. Provide insights and recommendations based on model outputs. Champion cross-functional collaboration, driving initiatives that enhance organizational knowledge and data-driven decision-making. Documentation and Reporting: Document the modeling process, including data sources, model choices, and parameter configurations. Prepare reports and visualizations to communicate findings to non-technical stakeholders. Lead efforts to maintain comprehensive and transparent documentation, facilitating knowledge sharing and continuous improvement. Leadership and Strategic Initiatives: Define and execute the ownership strategy for machine learning initiatives, ensuring alignment with Terumo's overall business strategy. Mentor and guide junior data scientists and team members, fostering a culture of excellence and continuous learning. Proactively identify and drive strategic initiatives that leverage data science to create competitive advantages for Terumo. Position Requirements: Knowledge, Skills and Abilities (KSAs) Experience with big data technologies (Databricks) and understanding of data design patterns (medallion architecture). Familiarity with DevOps practices for data science, including CI/CD pipelines for model deployment. Certifications in cloud computing platforms and machine learning are a plus. Excellent analytical and problem-solving skills and ability to work with large, complex data sets. Outstanding written and verbal presentation skills to effectively communicate complex concepts to a variety of stakeholders. Experience with forecasting methodologies and ability to work with limited information to create forecasts. Advanced proficiency with data mining, mathematics, and statistical analysis. Advanced pattern recognition and predictive modeling experience. Knowledge of machine learning frameworks (scikit-learn, TensorFlow, PyTorch) and data visualization tools (e.g., Matplotlib, Seaborn, Tableau). Experience with agile methodology, working closely with the SCRUM master to plan sprints, run retrospectives, participate in standups, and other planning meetings. Independent work capability, with minimal direction required. Strong teamwork skills, adept at working cross-functionally. Background Experiences Bachelor’s/Master’s in Computer Science, Data Science, Statistics, or equivalent work experience. Minimum 7 years’ experience in data science, with experience in predictive modeling and unsupervised machine learning. Experience in programming languages (such as Python or C#) and familiarity with SQL required Experience deploying data/code to cloud computing platforms (such as AWS, Azure, Google Cloud) and their data analytics services preferred.",
        "url": "https://www.linkedin.com/jobs/view/3962245804",
        "summary": "This role involves developing, deploying, and managing predictive models for decision-making across the Terumo organization using cloud computing technologies. Responsibilities include data collection, cleaning, preprocessing, model design, and deployment in a cloud environment. The Senior Data Scientist, Machine Learning Engineer will also monitor model performance, collaborate with other teams, document processes, and lead strategic initiatives related to data science.",
        "industries": [
            "Healthcare",
            "Technology",
            "Data Science",
            "Machine Learning",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Strategic thinking",
            "Ownership",
            "Problem-solving",
            "Analytical",
            "Communication",
            "Presentation",
            "Collaboration",
            "Teamwork",
            "Leadership",
            "Mentorship",
            "Independent work",
            "Forecasting"
        ],
        "hard_skills": [
            "Data Exploration",
            "Data Preprocessing",
            "Data Cleaning",
            "Data Integrity",
            "Data Lifecycle Management",
            "Data Ingestion",
            "Pattern Recognition",
            "Outlier Detection",
            "Trend Analysis",
            "Predictive Modeling",
            "Machine Learning Algorithms",
            "Model Optimization",
            "Cloud Deployment",
            "Scalability",
            "Reliability",
            "Security",
            "Performance Monitoring",
            "A/B Testing",
            "Model Validation",
            "Data Visualization",
            "Documentation",
            "Reporting",
            "Agile Methodology",
            "SCRUM",
            "Sprints",
            "Standups",
            "Retrospectives",
            "Data Design Patterns",
            "Medallion Architecture",
            "DevOps",
            "CI/CD Pipelines",
            "Cloud Computing Platforms",
            "Machine Learning Certifications"
        ],
        "tech_stack": [
            "Databricks",
            "AWS",
            "Azure",
            "Google Cloud",
            "scikit-learn",
            "TensorFlow",
            "PyTorch",
            "Matplotlib",
            "Seaborn",
            "Tableau"
        ],
        "programming_languages": [
            "Python",
            "C#",
            "SQL"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor's/Master's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Smithfield, RI",
        "job_id": 3959386655,
        "company": "Kforce Inc",
        "title": "Machine Learning/Gen AI Engineer",
        "created_on": 1720587948.451834,
        "description": "Responsibilities Kforce has a client that is seeking a Machine Learning/Gen AI Engineer in Smithfield, RI. Responsibilities: Development in Machine Learning System Working on Gen AI solutions with Large Language Models, LangChain, LlamaIndex, Prompt Engineering and Fine tuning Developing Python-based APIs required (FastAPI/Flask) Building feature engineering pipelines, deploying AI models, and optimizing model inference Design and develop machine learning and deep learning systems using appropriate ML algorithms/frameworks Working with security, data, and AI pipeline technologies (RDS/Postgres, Snowflake, Airflow) and infrastructure as Code (Terraform, Python, Ansible, CFT) Using AWS services: Deploy the models in SageMaker, cloud-based data platforms like Snowflake or RDS for analytics data hosting. EC2/EKS compute set-up Work with data to create models and perform statistical analysis, train, and retrain models to optimize performance Run machine learning tests and experiments Requirements Bachelor's degree or equivalent experience 3 to 5 years of hands-on development experience in Machine Learning System Experience with search engine platforms like Apache SOLR, Elastic Search or OpenSearch would be a big plus Superior SQL skills and experience performing deep data analysis on multiple database platforms Experience with working on Gen AI solutions with Large Language Models, LangChain, LlamaIndex, Prompt Engineering and Fine tuning Solid experience with developing python-based APIs required (FastAPI/Flask) Experience as a Machine Learning engineer building feature engineering pipelines, deploying AI models, and optimizing model inference Experience working with security, data, and AI pipeline technologies (RDS/Postgres, Snowflake, Airflow) and infrastructure as Code (Terraform, Python, Ansible, CFT) Demonstrated work experience using AWS services Strong programming skills in Python, Java The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future. We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave. Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law. This job is not eligible for bonuses, incentives or commissions. Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "url": "https://www.linkedin.com/jobs/view/3959386655",
        "summary": "Kforce is seeking a Machine Learning/Gen AI Engineer in Smithfield, RI. Responsibilities include development of ML systems, Gen AI solutions with Large Language Models, LangChain, LlamaIndex, Prompt Engineering and Fine tuning, Python-based APIs, feature engineering pipelines, AI model deployment, and optimization. Experience with AWS services, security, data, and AI pipeline technologies is required. The role involves statistical analysis, model training, and testing.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Software Development",
            "Data Science"
        ],
        "soft_skills": [
            "Problem-solving",
            "Analytical Thinking",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Machine Learning",
            "Gen AI",
            "Large Language Models",
            "LangChain",
            "LlamaIndex",
            "Prompt Engineering",
            "Fine Tuning",
            "Python",
            "FastAPI",
            "Flask",
            "API Development",
            "Feature Engineering",
            "Model Deployment",
            "Model Optimization",
            "Deep Learning",
            "ML Algorithms",
            "RDS",
            "Postgres",
            "Snowflake",
            "Airflow",
            "Terraform",
            "Ansible",
            "CFT",
            "AWS",
            "SageMaker",
            "EC2",
            "EKS",
            "SQL",
            "Data Analysis",
            "Statistical Analysis",
            "Java"
        ],
        "tech_stack": [
            "Python",
            "FastAPI",
            "Flask",
            "AWS",
            "SageMaker",
            "Snowflake",
            "RDS",
            "Postgres",
            "Airflow",
            "Terraform",
            "Ansible",
            "CFT",
            "LangChain",
            "LlamaIndex",
            "Apache SOLR",
            "ElasticSearch",
            "OpenSearch"
        ],
        "programming_languages": [
            "Python",
            "Java"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical/dental/vision insurance",
            "HSA",
            "FSA",
            "401(k)",
            "Life insurance",
            "Disability insurance",
            "ADD insurance",
            "Paid time off"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959680713,
        "company": "US Anesthesia Partners",
        "title": "Data Scientist",
        "created_on": 1720587950.0566025,
        "description": "We are in search of a talented Data Scientist with a robust background in applied data science within the healthcare sector. This role requires expertise in leveraging healthcare claims data and processes, with a strong emphasis on Revenue Cycle Management (RCM) Analytics, to derive actionable insights. The ideal candidate will possess exceptional analytical skills, the ability to navigate through ambiguity, and a strong commitment to transforming data into tangible results by moving up the data-to-wisdom ladder. Job Highlights: Analyze healthcare claims data to identify trends, anomalies, and opportunities for optimization, focusing on RCM analytics. Develop predictive models and algorithms to forecast and enhance healthcare billing and payment workflows. Collaborate with cross-functional teams to conceptualize and implement data-driven solutions addressing various business challenges. Apply statistical techniques and machine learning algorithms to extract actionable insights from complex healthcare datasets. Communicate findings and recommendations effectively to stakeholders through clear and concise presentations and reports, emphasizing data visualization skills to transform complex data into insightful visuals. Stay abreast of industry trends and best practices in healthcare analytics, data science, and RCM processes. Qualifications: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related field or equivalent experience. Master's degree preferred. Minimum of 1 year of practical experience working with healthcare claims data and processes, with a focus on RCM. Knowledge of healthcare data standards, regulations, and interoperability frameworks (e.g., HIPAA, HL7) is required. Proficiency in programming languages such as R or Python for data analysis and modeling. Proficiency in SQL for querying databases. Ability to use data to answer questions, avoid statistical traps, and ascend the data-to-wisdom ladder. Strong problem-solving skills with the ability to work independently and in a team environment. Excellent communication and interpersonal skills, with a demonstrated ability to present data visually and effectively. Anesthesia Partners, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, gender identity, sexual orientation, pregnancy, status as a parent, national origin, age, disability (physical or mental), family medical history or genetic information, political affiliation, military service, or other non-merit based factors.",
        "url": "https://www.linkedin.com/jobs/view/3959680713",
        "summary": "Data Scientist focused on healthcare claims data analysis and Revenue Cycle Management (RCM) analytics. Analyze claims data, develop predictive models, collaborate with teams, and communicate findings effectively. Requires experience with healthcare claims, RCM, data standards, and programming languages like R or Python.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Analytics",
            "Revenue Cycle Management"
        ],
        "soft_skills": [
            "Analytical Skills",
            "Communication Skills",
            "Problem-Solving Skills",
            "Teamwork",
            "Data Visualization",
            "Presentation Skills",
            "Collaboration",
            "Ambiguity Tolerance",
            "Commitment"
        ],
        "hard_skills": [
            "RCM Analytics",
            "Healthcare Claims Data Analysis",
            "Predictive Modeling",
            "Machine Learning Algorithms",
            "Statistical Techniques",
            "Data Visualization",
            "R",
            "Python",
            "SQL",
            "HIPAA",
            "HL7"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SQL",
            "HIPAA",
            "HL7"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Data Science",
                "Statistics",
                "Mathematics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3960657448,
        "company": "SmartIPlace",
        "title": "Data Scientist (Mid) -Remote [w2 role]",
        "created_on": 1720587951.6750636,
        "description": "Title: Data Scientist (Mid) -Remote Work Type: Remote with video interviews Client Requirements: Only USC or GC candidates Duration: 6 months Industry: Agriculture Experience: 4 years of experience as a Data Scientist Expertise in NLP and LLM to propose software solutions for customer experience improvement Proficiency in Python Experience in designing and testing algorithms, prototyping, and developing novel approaches for text and image data using computational and statistical techniques Familiarity with developing statistical and machine learning models for environmental and agronomical applications",
        "url": "https://www.linkedin.com/jobs/view/3960657448",
        "summary": "Remote Data Scientist role focused on improving customer experience through NLP and LLM solutions in the agriculture industry. Requires 4+ years experience, Python proficiency, and expertise in developing statistical and machine learning models for environmental and agronomical applications.",
        "industries": [
            "Agriculture"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration"
        ],
        "hard_skills": [
            "NLP",
            "LLM",
            "Python",
            "Algorithm Design",
            "Testing",
            "Prototyping",
            "Statistical Modeling",
            "Machine Learning",
            "Environmental Applications",
            "Agronomical Applications",
            "Text Data Analysis",
            "Image Data Analysis"
        ],
        "tech_stack": [
            "NLP",
            "LLM",
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Seattle, WA",
        "job_id": 3966161405,
        "company": "Phaidra",
        "title": "AI Research Scientist",
        "created_on": 1720587952.9949787,
        "description": "About Phaidra Phaidra is building the future of industrial automation. The world today is filled with static, monolithic infrastructure. Factories, power plants, buildings, etc. operate the same they've operated for decades — because the controls programming is hard-coded. Thousands of lines of rules and heuristics that define how the machines interact with each other. The result of all this hard-coding is that facilities are frozen in time, unable to adapt to their environment while their performance slowly degrades. Phaidra creates AI-powered control systems for the industrial sector, enabling industrial facilities to automatically learn and improve over time. Specifically: We use reinforcement learning algorithms to provide this intelligence, converting raw sensor data into high-value actions and decisions. We focus on industrial applications, which tend to be well-sensorized with measurable KPIs — perfect for reinforcement learning. We enable domain experts (our users) to configure the AI control systems (i.e. agents) without writing code. They define what they want their AI agents to do, and we do it for them. Our team has a track record of applying AI to some of the toughest problems. From achieving superhuman performance with DeepMind's AlphaGo, to reducing the energy required to cool Google's Data Centers by 40%, we deeply understand AI and how to apply it in production for massive impact. Phaidra is based in the USA but 100% remote; we do not have a physical office. We hire employees internationally with the help of our partner, OysterHR. Our team is currently located throughout the USA, Canada, UK, Norway, Italy, Spain, Portugal, Japan, Singapore, and India. Please only apply to one opening. If you are a better fit for another opening, our team will move your application. Candidates who apply to multiple openings will not be considered.** Who You Are Research Scientists at Phaidra lead our efforts in developing novel algorithmic architecture towards the end goal of bringing intelligent control systems to industrial sector. Having pioneered research in the world's leading academic and industrial labs as PhDs, post-docs or professors, Research Scientists join Phaidra to work collaboratively within and across research fields. Drawing on expertise from a variety of disciplines including reinforcement learning, deep learning, robotics and multi-agent reinforcement learning, our Research Scientists are at the forefront of groundbreaking research and applying them to real-world. We are seeking a team member located in one of the following areas: the UK, Norway, Italy, Spain, Portugal, Ireland, the US, or Canada. Responsibilities Design, implement and evaluate models, agents and software prototypes of perceptual processing. Report and present research findings and developments including status and results clearly and efficiently both internally and externally, verbally and in writing. Participate in and organize ambitious collaborative research projects. Work with external collaborators and maintain relationships with relevant research labs and key individuals as appropriate. Mentor and guide Research Engineers to apply research findings and developments to industrial domains. Key Qualifications PhD in a technical field or equivalent practical experience, with demonstrated knowledge in one of the following: Reinforcement Learning Deep Learning Control Theory Multi-Agent RL Extensive research in the fields of {ModelBased, ModelFree, Safe}RL, Control Theory. Share our company values: curiosity, ownership, transparency & directness, outcome-based performance, and customer empathy. Preferred Skills & Experience PhD in machine learning Relevant experience to the position. A proven track record of publications. A real passion for AI and applying to industrial systems to improve resource efficiency. Our Stack Python PyTorch, scipy Kubernetes, Docker, Ray GCP Onboarding In your first 30 days... You will be immersed in an onboarding program that introduces you to Phaidra and our product. You will spend time in the research team and get introduced to the different tracks of research that we perform. You will learn how other teams operate, interact, and approach problems. You will read various parts of our handbook and familiarize yourself with the documentation culture at Phaidra. You will set up your development environment and get introduced to various parts of our code base. By your first 60 days... You will have a solid understanding of what Phaidra does and how we do it. You will have met with team members across Phaidra and started building relationships that will help you be successful at your job. You will have a good understanding of our research tracks, which allowed you to form a plan for your first project, or maybe, you have already started one. By your first 90 days... You will have been fully integrated in the team and with team members across the company. You will have started to contribute to knowledge sharing throughout Phaidra. Your project is in full swing and you might have some early results already. General Interview Process All of our interviews are held via Google Meet, and an active camera connection is required. Initial screening interview with a People Operations team member (30 minutes) Meeting with Hiring Manager (30 minutes) Meeting with Research team member (60 minutes) Meeting with Research team member (60 minutes) Culture fit interview with Phaidra's co-founders (30 minutes) Base Salary UK Residents: £56,000-£91,200/year Canada Residents: CA$83,200-CA$138,000/year US Residents: $68,800-$135,600/year Salary ranges for other countries (Italy, Spain, Portugal, Norway, Ireland) will vary based on the market rate for the location. This position will also include equity. These are best faith estimates of the base salary range for this position. Multiple factors such as experience, education, level, and location are taken into account when determining compensation. Benefits & Perks Fast-paced and team-oriented environment where you will be instrumental in the direction of the company. Phaidra is a 100% remote company with a digital nomad policy. Competitive compensation & equity. Outsized responsibilities & professional development. Training is foundational; functional, customer immersion, and development training. Medical, dental, and vision insurance (exact benefits vary by region). Unlimited paid time off, with a minimum of 20 days off per year requirement. Paid parental leave (exact benefits vary by region). Home office setup allowance, coworking space stipend, and company MacBook. Please note that Phaidra's benefits and perks listed above do not apply to temporary employees such as interns. On being Remote We are thoughtful about remote collaboration. We look to the pioneers - like Gitlab - for inspiration and best practices to create a stellar remote work environment. We have a documentation-first culture and actively practice asynchronous communication in everything we do. Our team stays connected through tools like Slack and video chat. Most teams meet daily, and we have dedicated all-hands meetings weekly to build strong relationships. We hold virtual team building events once per quarter - and even hold virtual socials to watch rocket launches! We have had all-company summits in locations like Seattle, Athens, Goa, and Barcelona. Equal Opportunity Employment Phaidra is an Equal Opportunity Employer; employment with Phaidra is governed on the basis of merit, competence, and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability, or any other legally protected status. We welcome diversity and strive to maintain an inclusive environment for all employees. If you need assistance with completing the application process, please contact us at hiring@phaidra.ai. E-Verify Notice Phaidra participates in E-Verify, an employment authorization database provided through the U.S. Department of Homeland Security (DHS) and Social Security Administration (SSA). As required by law, we will provide the SSA and, if necessary, the DHS, with information from each new employee's Form I-9 to confirm work authorization for those residing in the United States. Additional Information About E-Verify Can Be Found Here. WE DO NOT ACCEPT APPLICATIONS FROM RECRUITERS.",
        "url": "https://www.linkedin.com/jobs/view/3966161405",
        "summary": "Phaidra develops AI-powered control systems for industrial facilities using reinforcement learning. They enable users to configure AI agents without coding, leveraging their expertise in deep learning and robotics to improve efficiency and performance. They are a remote-first company with a global team and offer competitive compensation, equity, and comprehensive benefits.",
        "industries": [
            "Industrial Automation",
            "Artificial Intelligence",
            "Machine Learning",
            "Robotics",
            "Software Development",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Teamwork",
            "Leadership",
            "Mentorship",
            "Presentation",
            "Organization",
            "Time Management",
            "Self-Motivation"
        ],
        "hard_skills": [
            "Reinforcement Learning",
            "Deep Learning",
            "Control Theory",
            "Multi-Agent Reinforcement Learning",
            "Model-Based RL",
            "Model-Free RL",
            "Safe RL",
            "Python",
            "PyTorch",
            "SciPy",
            "Kubernetes",
            "Docker",
            "Ray",
            "GCP"
        ],
        "tech_stack": [
            "Python",
            "PyTorch",
            "SciPy",
            "Kubernetes",
            "Docker",
            "Ray",
            "GCP"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "PhD",
            "fields": [
                "Technical Field",
                "Machine Learning",
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 135600,
            "min": 68800
        },
        "benefits": [
            "Competitive compensation",
            "Equity",
            "Remote work",
            "Digital nomad policy",
            "Unlimited paid time off",
            "Paid parental leave",
            "Medical, dental, and vision insurance",
            "Home office setup allowance",
            "Coworking space stipend",
            "Company MacBook",
            "Training",
            "Professional development"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3960229352,
        "company": "Stealth",
        "title": "Machine Learning Engineer [28376]",
        "created_on": 1720587954.694725,
        "description": "The company is an applied behavioral research company working at the intersection of ML, social sciences, and recommendation systems / Prediction - as - a - service. The company enables businesses to build privacy preserving recommendation and behavioral technologies competitive to big tech without the use of interpretable raw customer data. We’re looking to develop the next generation of privacy preserving machine learning products that understand and predict behavior at scale. Our products and research teams need to handle information at a massive scale across a number of unstructured dimensions. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, privacy, artificial intelligence, and NLP. Job Qualification: ● Bachelor’s degree or equivalent practical experience. ● 5+ years of experience with software development in one or more programming languages, and with data structures/algorithms. ● 5+ years with two or more languages/softwares included but not limited to: Python, Apache, Presto, R, ML/optimization, Scala ● 5+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, NLP, data mining or artificial intelligence ● 5+ years of experience with ML/AI algorithms and tools, deep learning and/or natural language processing. Responsibilities: ● You enjoy partnering with data science teams to deploy and scale advanced algorithms ● You strive to write elegant code, and you're comfortable with picking up new technologies independently ● You enjoy collaborating with colleagues/partners internally and externally ● You are passionate about building intuitive data models and an expert in distributed data processing patterns ● You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks What you will do: ● Engineer efficient, adaptable, and scalable data pipelines to process structured and unstructured data ● Maintain and rethink existing datasets and pipelines to service a wider variety of use cases ● Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules-based models ● Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)",
        "url": "https://www.linkedin.com/jobs/view/3960229352",
        "summary": "Applied behavioral research company seeking a Software Engineer with 5+ years of experience in software development, data structures/algorithms, Python, Apache, Presto, R, ML/optimization, Scala, machine learning, recommendation systems, pattern recognition, NLP, data mining or artificial intelligence, and ML/AI algorithms and tools. Responsibilities include engineering scalable data pipelines, maintaining and rethinking datasets, developing classifiers and tools, and adapting machine learning methods for parallel environments.",
        "industries": [
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science",
            "Research",
            "Software Development",
            "Technology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Adaptability",
            "Independent Learning",
            "Analytical Thinking",
            "Teamwork",
            "Passionate",
            "Nimble",
            "Risk Taking"
        ],
        "hard_skills": [
            "Software Development",
            "Data Structures",
            "Algorithms",
            "Python",
            "Apache",
            "Presto",
            "R",
            "ML/Optimization",
            "Scala",
            "Machine Learning",
            "Recommendation Systems",
            "Pattern Recognition",
            "NLP",
            "Data Mining",
            "Artificial Intelligence",
            "ML/AI Algorithms",
            "Deep Learning",
            "Natural Language Processing",
            "Data Pipelines",
            "Distributed Computing",
            "Parallel Processing",
            "Data Regression",
            "Rules-Based Models"
        ],
        "tech_stack": [
            "Python",
            "Apache",
            "Presto",
            "R",
            "ML/Optimization",
            "Scala",
            "Machine Learning",
            "Recommendation Systems",
            "Data Mining",
            "Artificial Intelligence",
            "Deep Learning",
            "Natural Language Processing",
            "Data Pipelines",
            "Distributed Computing",
            "Parallel Processing"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Scala"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Miami-Fort Lauderdale Area",
        "job_id": 3959695889,
        "company": "Stagewood Consortium, Inc",
        "title": "AI/Machine Learning Data Scientist",
        "created_on": 1720587959.650084,
        "description": "ONLY VIEWING MIAMI-DATE APPLICANTS About the Company StageWood Consortium, a South Florida-based startup dedicated to revolutionizing the entertainment industry through a new social media platform, is seeking a dynamic and enthusiastic AI/Machine Learning Data Engineer. In this role, you will engage in hands-on data platforms and applications, fostering teamwork and collaboration with both development and marketing teams. Job Description We are seeking a highly skilled AI/Machine Learning Data Engineer to develop and enhance the recommendation engine and virtual assistant that powers our social media platform. This role requires a deep understanding of machine learning algorithms and a passion for data-driven problem solving. Local Applicants Only Remote or hybrid work options are not available. This is an ONSITE position. Monday to Friday, from 9 am to 5 pm. Key Responsibilities: Collaborate with cross-functional teams to seamlessly integrate new and existing systems. Develop, prototype, and launch advanced recommendation systems that enhance user interaction and content personalization. Design for scalability, performance, and robustness. Deliver reliable and user-friendly solutions. Outline internal automation, tools, and infrastructure. Preferred Skills: Highly motivated with a passion for creating and supporting great products. Stay on top of the latest advancements in data science and machine learning. Propose and implement innovative solutions to improve project outcomes. Strong analytical skills and practical understanding of Computer Science fundamentals. Knowledge of professional software engineering practices, including software design, integration, and deployment technologies (CI/CD, DevOps, unit testing, git). Familiarity with AWS Cloud Platform and Fluentbit. Conduct periodic code reviews with the development team. Requirements: Education: Enrolled or completed a bachelor's degree in computer science or a related field. Experience: At least 1-3 years of experience in an internship or professional work. Knowledge of SPARQL, Gremlin, AWS Neptune Graph Database and AWS Personalize Knowledge of modern Backend tech stack (Javascript/Typescript, with a preference for Nest.JS). Backend engineering experience using modern web technologies (TypeScript, React, Node/Fastify, PostgreSql). Bonus Skills: Knowledge of modern frontend technologies. Familiarity with Github Actions, Docker, and general experience with CI. Bi-weekly hourly salary rate: T-0 Intern Engineer: $15/hour T-1 Junior Engineer: $20/hour T-2 Engineer: $25/hour T-3 Engineer: $30/hour If you are passionate about software and data science, have a keen interest in the entertainment industry, and meet the above qualifications, we encourage you to apply. Join StageWood Consortium on its journey to redefine social media in the entertainment sector!",
        "url": "https://www.linkedin.com/jobs/view/3959695889",
        "summary": "StageWood Consortium, a South Florida-based startup, is seeking an AI/Machine Learning Data Engineer to develop and enhance their recommendation engine and virtual assistant for their social media platform. This is an onsite position requiring 1-3 years of experience, strong analytical skills, knowledge of AWS Cloud Platform, Fluentbit, SPARQL, Gremlin, AWS Neptune Graph Database, AWS Personalize, and modern backend technologies like Javascript/Typescript, Nest.JS, TypeScript, React, Node/Fastify, and PostgreSql. The salary range is $15-$30/hour depending on experience level.",
        "industries": [
            "Entertainment",
            "Social Media",
            "Technology",
            "Data Science",
            "Software Development"
        ],
        "soft_skills": [
            "Dynamic",
            "Enthusiastic",
            "Teamwork",
            "Collaboration",
            "Passionate",
            "Problem Solving",
            "Analytical",
            "Motivated",
            "Innovative"
        ],
        "hard_skills": [
            "Machine Learning",
            "Recommendation Systems",
            "Data Platforms",
            "Scalability",
            "Performance",
            "Robustness",
            "Automation",
            "Software Design",
            "Integration",
            "Deployment Technologies",
            "CI/CD",
            "DevOps",
            "Unit Testing",
            "Git",
            "AWS Cloud Platform",
            "Fluentbit",
            "SPARQL",
            "Gremlin",
            "AWS Neptune Graph Database",
            "AWS Personalize",
            "Javascript",
            "Typescript",
            "Nest.JS",
            "TypeScript",
            "React",
            "Node",
            "Fastify",
            "PostgreSql",
            "Github Actions",
            "Docker",
            "CI"
        ],
        "tech_stack": [
            "AWS Cloud Platform",
            "Fluentbit",
            "SPARQL",
            "Gremlin",
            "AWS Neptune Graph Database",
            "AWS Personalize",
            "Javascript",
            "Typescript",
            "Nest.JS",
            "TypeScript",
            "React",
            "Node",
            "Fastify",
            "PostgreSql",
            "Github Actions",
            "Docker"
        ],
        "programming_languages": [
            "Javascript",
            "Typescript",
            "Python",
            "R"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 30,
            "min": 15
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Ohio, United States",
        "job_id": 3970389617,
        "company": "Worldpay",
        "title": "AI/ML Engineer",
        "created_on": 1720587961.260063,
        "description": "Job Description As an AI/ML Engineer in the AI and Innovation Team within the Office of the Chief Technology Officer (OCTO), you will play a pivotal role in advancing the company's generative AI capabilities. This position involves contributing to the development of a sandbox environment for experimentation, building and programming AI solutions using large language models (LLMs), and actively participating in the creation of impactful use cases. The AI/ML Engineer will work under the guidance of the Senior Director, collaborating with cross-functional teams to integrate AI solutions across the organization. Key Responsibilities AI Solutions Development: Assist in developing and maintaining scalable and secure AI solutions within a sandbox environment. Contribute to the programming and refinement of AI applications using LLMs and other AI technologies. Use Case Implementation: Collaborate in building and documenting sample use cases that demonstrate the practical applications and benefits of generative AI within the company. Collaborative Teamwork: Work closely with a diverse team of developers and QA specialists to foster a culture of innovation and continuous improvement. Engage with internal teams to identify and implement AI-driven enhancements in existing workflows. Quality Assurance: Participate in the rigorous testing and validation of AI models and solutions to ensure high standards of quality and performance are met. Continuous Learning and Improvement: Stay updated with the latest industry trends and advancements in AI technology. Implement feedback and contribute to continuous improvement processes to refine AI methodologies. Qualifications Bachelor’s degree in Computer Science, Engineering, or a related field. Minimum of 2-4 years of experience in AI/ML development. Demonstrated proficiency in AI/ML programming languages and frameworks (e.g., Python, TensorFlow, PyTorch). Familiarity with developing and maintaining applications within cloud environments. Strong analytical and problem-solving skills, with a proven ability to contribute to complex projects. Excellent communication skills, capable of collaborating effectively across diverse teams. Preferred Skills Experience working in highly regulated industries such as payments Familiarity with agile development methodologies and best practices Experience in sandbox environment development for AI experimentation What We Offer Competitive salary and benefits package. Opportunity to work on cutting-edge technology projects within a leading company in the payments sector. A dynamic work environment where innovation and continuous improvement are at the forefront. Professional growth opportunities in a supportive and collaborative team. How To Apply Please submit your resume and a cover letter outlining your specific qualifications and interest in the role. Join us at Worldpay where your expertise in AI/ML engineering will help shape the future of technological innovation in our company. Privacy Statement Worldpay is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how Worldpay protects personal information online, please see the Online Privacy Notice. EEOC Statement Worldpay is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics. The EEO is the Law poster is available here supplement document available here For positions located in the US, the following conditions apply. If you are made a conditional offer of employment, you will be required to undergo a drug test. ADA Disclaimer: In developing this job description care was taken to include all competencies needed to successfully perform in this position. However, for Americans with Disabilities Act (ADA) purposes, the essential functions of the job may or may not have been described for purposes of ADA reasonable accommodation. All reasonable accommodation requests will be reviewed and evaluated on a case-by-case basis. Sourcing Model Recruitment at Worldpay works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. Worldpay does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company. #pridepass",
        "url": "https://www.linkedin.com/jobs/view/3970389617",
        "summary": "As an AI/ML Engineer, you will contribute to developing a generative AI sandbox environment, building AI solutions using large language models (LLMs), and creating impactful use cases. You will work closely with cross-functional teams to integrate AI solutions across the organization.",
        "industries": [
            "Payments",
            "Technology",
            "Finance"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Analytical",
            "Continuous Improvement"
        ],
        "hard_skills": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "AI/ML",
            "Cloud Computing",
            "Agile Development",
            "Sandbox Environment Development"
        ],
        "tech_stack": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "LLMs",
            "Generative AI",
            "Cloud Computing",
            "Sandbox Environment"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Engineering",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "Benefits package",
            "Opportunity to work on cutting-edge technology projects",
            "Dynamic work environment",
            "Professional growth opportunities",
            "Supportive and collaborative team"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Columbus, OH",
        "job_id": 3970048740,
        "company": "KellyMitchell Group",
        "title": "Senior Data Scientist",
        "created_on": 1720587962.6101005,
        "description": "Job Summary: Our client is seeking a Senior Data Scientist who will dive into the company's customer, product, channel, and digital data to uncover opportunities for consumer experience optimization and customer value delivery. The ideal candidate will enable stakeholders with actionable, intuitive performance insights that provides the business with direction for growth. This job is located in Columbus, Ohio. Duties: Synthesize data from the company's analytics tools into actionable insights about customer and prospect behavior, digital sales and servicing performance, and customer value delivery Clearly communicate recommendations to internal stakeholders and senior leadership Actively participate in cross-functional initiatives and collaborate with team members to achieve and measure project success Provide opportunity analysis, measurement plans, dashboards, and post-release and testing analyses Extract and analyze data using analytics tools such as Python, R, and/or SAS Create compelling, intuitive dashboards to enable the business with critical metrics, with a focus on data automation, anomaly detection, and actionable data visualizations Partner with Digital, Marketing, Product and IT partners to evaluate the success of new initiatives Collaborate with Fraud and Risk partners to identify and mitigate threats to the company's assets Apply visualization techniques to internal and external data sources to make accurate and actionable analyses in a timely fashion Be a partner in the building of KPIs and metrics that help to gauge the health and success of the company's digital and Omni assets and initiatives Create self-service dashboards for internal business partners to learn, understand, have access to, and derive insights from data, metrics, and KPIs Apply automation techniques to manual processes to create efficiency, improve accuracy, and build upon successes that create a suite of self-service assets Desired Skills/Experience: Master's degree in Computer Science or Information Systems, Decision Sciences, Statistics, Operations Research, Applied Mathematics, Engineering, or a STEM degree, or a Bachelor's degree with a minimum of 3+ years of work experience in analytics or data science Business intelligence and data mining tools such as Tableau and Tableau Server Direct experience with SQL programming and large database applications such as Oracle, DB2, SQL Server, SPSS, Teradata, and Hadoop Ability to quickly grasp complex technical concepts and make them easily understandable through various communication mediums like visualizations and presentations Benefits: Medical, Dental, & Vision Insurance Plans 401K offered",
        "url": "https://www.linkedin.com/jobs/view/3970048740",
        "summary": "Our client is seeking a Senior Data Scientist to analyze customer, product, channel, and digital data to identify opportunities for customer experience optimization and value delivery. The ideal candidate will provide actionable insights to guide business growth.",
        "industries": [
            "Data Science",
            "Analytics",
            "Business Intelligence",
            "Customer Experience",
            "Digital Marketing",
            "Financial Services"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Presentation Skills",
            "Leadership",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SAS",
            "SQL",
            "Tableau",
            "Tableau Server",
            "Oracle",
            "DB2",
            "SQL Server",
            "SPSS",
            "Teradata",
            "Hadoop",
            "Data Visualization",
            "Data Mining",
            "Business Intelligence",
            "Analytics"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SAS",
            "SQL",
            "Tableau",
            "Tableau Server",
            "Oracle",
            "DB2",
            "SQL Server",
            "SPSS",
            "Teradata",
            "Hadoop"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SAS",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Information Systems",
                "Decision Sciences",
                "Statistics",
                "Operations Research",
                "Applied Mathematics",
                "Engineering",
                "STEM"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "401K"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Seattle, WA",
        "job_id": 3963944474,
        "company": "Stackline",
        "title": "Data Scientist - Analytics",
        "created_on": 1720587964.0848093,
        "description": "Stackline is the first full-funnel connected commerce platform for the world's most innovative brands. Business leaders, product innovators, performance marketers, and analysts trust Stackline as the single source of commerce truth. Fueled by our proprietary neural network, our market insights, revenue metrics, behavior analyses, and autonomous functionality create the actions that determine success or failure. Founded in 2014 in Seattle, we have offices in Minneapolis, New York, Salt Lake City, and London. Since November 2020, Stackline has raised $180 million in strategic investments from Goldman Sachs Growth Equity and TA Associates. Stackline is on a mission to fuel the future of commerce by bringing brands and customers closer together. About The Role: Ready to embark on your next big adventure? Join us as a Data Scientist at Stackline where you will thrive in our dynamic, team-oriented atmosphere, contributing your skills to develop practice Machine Learning solutions. This role involves delving into vast data pipelines, analyzing over a billion data points each week, and collaborating closely with Data Engineers, Software Engineers, and Product Management team. This hands-on analytical position requires not only your coding expertise, but also your dedication to architecting, developing, and testing innovative models that make a tangible difference. If you’re ready to make a meaningful impact, apply now to be part of our exciting journey! What You Will Do: Independently create innovative Machine Learning pipelines and collaborate with leadership and stakeholders to test and validate data outputs. Provide prompt and accurate responses to both internal and external inquiries about our datasets and models. Apply technical proficiency to process complex and intricate datasets, establish quality control procedures, and derive actionable insights. Utilize data effectively to extract insights and devise innovative strategies, offering actionable recommendations to stakeholders in data science, engineering, and product teams. Collaborate with cross-functional teams to identify new opportunities requiring the application of modern data science and Machine Learning techniques. Design and implement innovative models and experiments using cutting edge analytical, mathematical, and machine learning methods to drive growth in new company domains. Document data sources and processes for data analysis and modeling. Who We Are Looking For: Masters in Mathematics, Physics, Computer Science, Engineering, or another technical field. 3+ years of direct industry work experience in one or more of the following areas: data science, data analytics or data engineering. 3+ years of experience with Machine Learning, statistics and probability, algorithm development, and data analytics. Strong proficiency with programming and querying languages like Python and SQL. Experience deploying solutions at scale after prototyping. Demonstrated experience in Machine Learning tools such as Tensorflow,PyTorch, Spark ML, or related frameworks. Experience with distributed version control (e.g. git). Bonus Points If You Have: Prior experience with big data technologies such as Hadoop or Spark. Demonstrated experience designing and building new ideas, working closely with technical teams from concept generation through implementation. D.‍ in Engineering, Physics, Mathematics, Computer Science, or another technical field. Experience working in a startup, retail, digital advertising, or e-commerce environment. **Active candidates only - no recruiters or recruiting agencies** Benefits and Perks: It’s important that each and every employee feels they are supported and can complete their life’s best work today and in the future. As part of that, we are committed to doing our part in addressing pay gaps and discrepancies by providing pay transparency for all of our roles. Actual salaries are just one component of the compensation package and may vary above or below the range based on job-related knowledge, skills, experience, geographical location, and performance. The pay range for this position located in Seattle is $160,000 - $180,000 per year. Other rewards may include annual bonuses, short- and long-term incentives, and other team-specific awards. In addition we provide a robust benefits and perks package that includes: Comprehensive benefits plan covering medical, dental, and vision Fertility benefits Company 401k plan plus matching Company paid Life Insurance 20 days of Paid Time Off annually 9 Paid company holidays 100% Paid Parental leave - 20 weeks for birthing mothers and 12 weeks for all other parents Summer Fridays early close at 2pm Fully stocked kitchen snacks with weekly fresh fruit Stackline is committed to creating a diverse environment and is proud to be an equal opportunity employer. We encourage applicants from all backgrounds to apply. All qualified applicants will receive consideration for employment without regard to race, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.",
        "url": "https://www.linkedin.com/jobs/view/3963944474",
        "summary": "Stackline is seeking a Data Scientist to join their team and contribute to developing Machine Learning solutions. This role involves analyzing large datasets, collaborating with engineers and product managers, and developing innovative models to drive growth. Responsibilities include creating Machine Learning pipelines, responding to data inquiries, processing intricate datasets, extracting insights, identifying new opportunities, and documenting data processes.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "E-commerce",
            "Retail",
            "Digital Advertising",
            "Analytics",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Analytical",
            "Innovative",
            "Teamwork",
            "Leadership",
            "Data-driven"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Machine Learning",
            "Statistics",
            "Probability",
            "Algorithm Development",
            "Data Analytics",
            "TensorFlow",
            "PyTorch",
            "Spark ML",
            "Git",
            "Hadoop",
            "Spark"
        ],
        "tech_stack": [
            "Machine Learning",
            "TensorFlow",
            "PyTorch",
            "Spark ML",
            "Hadoop",
            "Spark",
            "Python",
            "SQL",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Mathematics",
                "Physics",
                "Computer Science",
                "Engineering",
                "Technical Fields"
            ]
        },
        "salary": {
            "max": 180000,
            "min": 160000
        },
        "benefits": [
            "Comprehensive benefits plan covering medical, dental, and vision",
            "Fertility benefits",
            "Company 401k plan plus matching",
            "Company paid Life Insurance",
            "20 days of Paid Time Off annually",
            "9 Paid company holidays",
            "100% Paid Parental leave - 20 weeks for birthing mothers and 12 weeks for all other parents",
            "Summer Fridays early close at 2pm",
            "Fully stocked kitchen snacks with weekly fresh fruit"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Phoenix, AZ",
        "job_id": 3970259787,
        "company": "Republic Services",
        "title": "Data Scientist I",
        "created_on": 1720587967.410216,
        "description": "About The Company Republic Services, Inc. (NYSE: RSG) is a leader in the environmental services industry. We provide customers with the most complete set of products and services, including recycling, waste, special waste, hazardous waste and field services. Our industry-leading commitments to advance circularity and support decarbonization are helping deliver on our vision to partner with customers to create a more sustainable world. In 2023, Republic’s total company revenue was $14.9 billion, and adjusted EBITDA was $4.4 billion. We serve 13 million customers and operate more than 1,000 locations, including collection and transfer stations, recycling and polymer centers, treatment facilities, and landfills. Although we operate across North America, the collection, recycling, treatment, or disposal of materials is a local business, and the dynamics and opportunities differ in each market we serve. By combining local operational management with standardized business practices, we drive greater operating efficiencies across the company while maintaining day-to-day operational decisions at the local level, closest to the customer. Our customers, including small businesses, major corporations and municipalities, want a partner with the expertise and capabilities to effectively manage their multiple recycling and waste streams. They choose Republic Services because we are committed to exceeding their expectations and helping them achieve their sustainability goals. Our 41,000 team members understand that it's not just what we do that matters, but how we do it. Our Company Values Guide Our Daily Actions Safe: We protect the livelihoods of our colleagues and communities. Committed to Serve: We go above and beyond to exceed our customers’ expectations. Environmentally Responsible: We take action to improve our environment. Driven: We deliver results in the right way. Human-Centered: We respect the dignity and unique potential of every person. We are proud of our high employee engagement score of 86. We have an inclusive and diverse culture where every voice counts. In addition, our team positively impacted 4.6 million people in 2023 through the Republic Services Charitable Foundation and local community grants. These projects are designed to meet the specific needs of the communities we serve, with a focus on building sustainable neighborhoods. STRATEGY Republic Services’ strategy is designed to generate profitable growth. Through acquisitions and industry advancements, we safely and sustainably manage our customers’ multiple waste streams through a North American footprint of vertically integrated assets. We focus on three areas of growth to meet the increasing needs of our customers: recycling and waste, environmental solutions and sustainability innovation. With our integrated approach, strengthening our position in one area advances other areas of our business. For example, as we grow volume in recycling and waste, we collect additional material to bolster our circularity capabilities. And as we expand environmental solutions, we drive additional opportunities to provide these services to our existing recycling and waste customers. Recycling and Waste We continue to expand our recycling and waste business footprint throughout North America through organic growth and targeted acquisitions. The 13 million customers we serve and our more than 5 million pick-ups per day provide us with a distinct advantage. We aggregate materials at scale, unlocking new opportunities for advanced recycling. In addition, we are cross-selling new products and services to better meet our customers’ specific needs. Environmental Solutions Our comprehensive environmental solutions capabilities help customers safely manage their most technical waste streams. We are expanding both our capabilities and our geographic footprint. We see strong growth opportunities for our offerings, including PFAS remediation, an increasing customer need. SUSTAINABILITY INNOVATION Republic’s recent innovations to advance circularity and decarbonization demonstrate our unique ability to leverage sustainability as a platform for growth. The Republic Services Polymer Center is the nation’s first integrated plastics recycling facility. This innovative site processes rigid plastics from our recycling centers, producing recycled materials that promote true bottle-to-bottle circularity. We also formed Blue Polymers, a joint venture with Ravago, to develop facilities that will further process plastic material from our Polymer Centers to help meet the growing demand for sustainable packaging. We are building a network of Polymer Centers and Blue Polymer facilities across North America. We continue to advance decarbonization at our landfills. As demand for renewable energy continues to grow, we have 70 landfill gas-to-energy projects in operation and plan to expand our portfolio to 115 projects by 2028. RECENT RECOGNITION Barron’s 100 Most Sustainable Companies CDP Discloser Dow Jones Sustainability Indices Ethisphere’s World’s Most Ethical Companies Fortune World’s Most Admired Companies Great Place to Work Sustainability Yearbook S&P Global POSITION SUMMARY: The Data Scientist I drives internal data analytics projects. The role collaborates with executive leaders to deliver analytical solutions to business problems. Initiatives vary from descriptive analyses to the development and implementation of advanced statistical, machine learning, and AI models. The Data Scientist I effectively communicates both technical and business concepts across all levels of the organization, and they influence decision making through presentation of data-based recommendations. Principal Responsibilities Builds statistical and machine-learning models to enhance understanding of trends and predict future performance Participates in end-to-end data science project lifecycle – data mining and exploration, model development and evaluation, solution deployment in production, measurement, and tracking Performs time-series analyses, hypothesis testing, and causal analyses to statistically assess relative impact and extract trends across all relevant functional areas Transforms data into actionable insights and recommendations Designs experiments and interprets the results to draw detailed and actionable conclusions Researches and resolves data inquiries and requests Documents requirements for data science and reporting projects Designs, validates, and evaluates solutions using R, Python, SQL, and other programming tools Performs other job-related duties as assigned. Knowledge / Skills / Abilities Proficiency with programming in Python or R in data science and/or statistical analysis settings. Proficiency with relational databases and the ability to write SQL queries. Proficiency with Excel and PowerBI. Qualifications Master's degree preferred. 2 years of experience working with large databases to perform complex analysis. 2 years of experience with statistics and multivariate analytical techniques including multivariate regression, logistic regression, cluster analysis, design of experiments, machine learning, and decision trees. Minimum Qualifications Bachelor’s Degree in an analytical field (Mathematics, Computer Science, Information Management, Statistics, Engineering). 2 years of experience with advanced programming in Python or R and SQL, conducting complex statistical analysis and building machine learning algorithms with large databases. Rewarding Compensation And Benefits Eligible employees can elect to participate in: Comprehensive medical benefits coverage, dental plans and vision coverage. Health care and dependent care spending accounts. Short- and long-term disability. Life insurance and accidental death & dismemberment insurance. Employee and Family Assistance Program (EAP). Employee discount programs. Retirement plan with a generous company match. Employee Stock Purchase Plan (ESPP). The statements used herein are intended to describe the general nature and level of the work being performed by an employee in this position, and are not intended to be construed as an exhaustive list of responsibilities, duties and skills required by an incumbent so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of the Company. EEO STATEMENT:Republic Services is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, protected veteran status, relationship or association with a protected veteran (spouses or other family members), genetic information, or any other characteristic protected by applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3970259787",
        "summary": "Republic Services is seeking a Data Scientist I to drive internal data analytics projects, collaborate with executives, and develop analytical solutions to business problems. The role involves building statistical and machine learning models, performing time-series analyses, and translating data into actionable insights. The ideal candidate will possess proficiency in Python or R, SQL, and data mining techniques, along with experience in multivariate analysis, machine learning, and decision trees.",
        "industries": [
            "Environmental Services",
            "Waste Management",
            "Recycling",
            "Sustainability",
            "Data Analytics",
            "Machine Learning",
            "AI"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Influence",
            "Presentation",
            "Problem Solving",
            "Decision Making",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Data Mining",
            "Statistical Modeling",
            "Machine Learning",
            "Multivariate Regression",
            "Logistic Regression",
            "Cluster Analysis",
            "Design of Experiments",
            "Decision Trees",
            "Time-Series Analysis",
            "Hypothesis Testing",
            "Causal Analysis",
            "Excel",
            "PowerBI"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Excel",
            "PowerBI"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Mathematics",
                "Computer Science",
                "Information Management",
                "Statistics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Benefits",
            "Dental Plans",
            "Vision Coverage",
            "Health Care Spending Accounts",
            "Dependent Care Spending Accounts",
            "Short-Term Disability",
            "Long-Term Disability",
            "Life Insurance",
            "Accidental Death & Dismemberment Insurance",
            "Employee and Family Assistance Program",
            "Employee Discount Programs",
            "Retirement Plan with Company Match",
            "Employee Stock Purchase Plan"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3969880476,
        "company": "Lokavant",
        "title": "Senior Data Scientist",
        "created_on": 1720587968.8491173,
        "description": "About Lokavant Lokavant is reshaping how clinical trial teams execute studies with its Clinical Intelligence Platform and novel AI feasibility software, Spectrum. With Spectrum, study teams can predict, optimize, and control trial timelines and costs in real time, enabling iterative feasibility analysis and mid-study course correction. Lokavant is on a mission to help the research industry utilize data and advanced AI to surface insights that improve trial performance and outcomes. About the Opportunity ﻿ Key Responsibilities Keep up to date with industry trends in clinical trial data and analytics, data science, and artificial intelligence, and apply this knowledge in daily work Hands on data collection, preprocessing and analysis Presenting information internally and externally using data visualization techniques Design, develop and apply state-of-the-art methods within AI and machine learning to solve complex problems related to clinical trials Act as an AI thought leader, including the creation of whitepapers, presentations, executive briefings, reports, and other materials to support AI solutions and services Guide life science clients with high autonomy in AI strategy and development, including understanding needs, performing exploratory data analysis, building and validating models, and deploying models into cloud environments Iterate on and/or create repeatable, reusable processes and scalable data systems that meet technical and deployment challenges Maintain and uphold data science best practices on new methodologies, technologies, industry trends, and open-source packages Minimum Requirements 4+ years of experience in Data Science Experience working in an Agile software development environment Proactive and motivated professional who is comfortable with ambiguity and thrives in a rapidly changing start-up environment while being able to learn quickly and autonomously 4+ years of programming experience with one or more analytics tools (Python/R and SQL) Machine Learning and predictive modeling skills: Ability to build and manage models to predict future outcomes using data that is often incomplete and/or imperfect and spread across disparate sources. Demonstrated capabilities in analyzing heterogeneous datasets; Ability to identify trends, identify outliers and find patterns. Preferred (nice-to-have) Qualifications Experience in life sciences or healthcare industries, with a focus on clinical trial data standards (e.g. CDISC, FHIR, HL7, etc.) and/or e-clinical systems and technologies (e.g. EDC, CTMS, IRT, etc.) Experience with Jupyter Notebooks and/or Shiny applications Experience working in a cloud environment and using cloud-based services Experience using LLMs, LangChain, RAG, and knowledge graphs for agentic text extraction and inference Experience with causal methods such as Bayesian networks, IPW, G-computation, and/or TMLE Salary Range: $150,000 - $180,000 + equity and bonus Employee Benefits Competitive salary and annual performance bonus Full medical, dental, and vision benefits, including mental health and telehealth Employee stock options 401(k) retirement savings plan with company match Flexible paid time off policy Flexible remote work policy Generous paid parental leave policy Short and long-term disability insurance Basic and supplemental life and AD&D insurance Health Advocate program Employee Assistance Program (EAP) Healthcare & dependent care Flexible Spending Accounts (FSA) Discounts on auto, home, and pet insurance Team-building events and outings Learning and professional development opportunities Employee referral program Lokavant is an equal opportunity employer, indiscriminate of race, color, religion, ethnicity, ancestry, national origin, sex, gender, gender identity, sexual orientation, age, marital status, veteran status, disability, medical condition, or any other protected characteristic. We celebrate diversity and are committed to creating an inclusive environment for all employees.",
        "url": "https://www.linkedin.com/jobs/view/3969880476",
        "summary": "Lokavant is a company developing an AI-driven clinical intelligence platform (Spectrum) that helps predict, optimize, and control clinical trial timelines and costs. This role focuses on AI and machine learning to solve complex problems related to clinical trials, involving data collection, analysis, model building, and client guidance.",
        "industries": [
            "Healthcare",
            "Life Sciences",
            "Clinical Research",
            "Artificial Intelligence",
            "Data Science"
        ],
        "soft_skills": [
            "Proactive",
            "Motivated",
            "Ambiguity Tolerance",
            "Quick Learning",
            "Autonomous",
            "Communication",
            "Presentation Skills",
            "Leadership",
            "Client Interaction",
            "Problem-Solving",
            "Data Visualization"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Machine Learning",
            "Predictive Modeling",
            "Data Analysis",
            "Data Preprocessing",
            "Trend Analysis",
            "Outlier Detection",
            "Pattern Recognition",
            "Jupyter Notebooks",
            "Shiny Applications",
            "Cloud Computing",
            "LLMs",
            "LangChain",
            "RAG",
            "Knowledge Graphs",
            "Agentic Text Extraction",
            "Causal Methods",
            "Bayesian Networks",
            "IPW",
            "G-Computation",
            "TMLE"
        ],
        "tech_stack": [
            "Spectrum",
            "AI",
            "Machine Learning",
            "Python",
            "R",
            "SQL",
            "Jupyter Notebooks",
            "Shiny Applications",
            "Cloud Computing",
            "LLMs",
            "LangChain",
            "RAG",
            "Knowledge Graphs",
            "Bayesian Networks",
            "IPW",
            "G-Computation",
            "TMLE",
            "CDISC",
            "FHIR",
            "HL7",
            "EDC",
            "CTMS",
            "IRT"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 4,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 180000,
            "min": 150000
        },
        "benefits": [
            "Competitive Salary",
            "Annual Performance Bonus",
            "Medical Benefits",
            "Dental Benefits",
            "Vision Benefits",
            "Mental Health Benefits",
            "Telehealth",
            "Employee Stock Options",
            "401k with Company Match",
            "Flexible Paid Time Off",
            "Flexible Remote Work Policy",
            "Paid Parental Leave",
            "Short and Long-Term Disability Insurance",
            "Life and AD&D Insurance",
            "Health Advocate Program",
            "Employee Assistance Program",
            "Flexible Spending Accounts",
            "Discounts on Insurance",
            "Team-Building Events",
            "Learning and Development Opportunities",
            "Employee Referral Program"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Antonio, TX",
        "job_id": 3961096388,
        "company": "Vericast",
        "title": "Data Scientist - FI Solutions (Remote)",
        "created_on": 1720587983.1516762,
        "description": "Company Description Harland Clarke, a Vericast business, is a premier marketing solutions company that accelerates profitable revenue growth for the thousands of businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily. We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients. For more information, visit http://www.vericast.com or follow Vericast on LinkedIn. Job Description Vericast is a big data company. We receive on average over 100 billion intent signals daily, which assist in generating a deep understanding of a person's interest and in-market signals across 1,300 interest topics. This is coupled with strong geographic targeting, as over 30 billion location signals are collected daily from over one million retail stores and over 120 million households. Data Science plays a crucial role in delivering our solutions today and will play a more prominent role in our future. A typical data science project has a solid mathematical foundation, an exploratory dimension, and a data-driven workflow. This is also true at Vericast. Our data science projects have strong foundations on machine learning, data engineering, and modeling. We are building a privacy-centric future of digital advertising by focusing on web content. We are connecting web content to consumer interest and action, ultimately driving which ads are shown on a webpage. To continue our journey, we are seeking data science experts who are passionate about using cutting edge technology and conceiving innovative methods to solve unique and complex problems. As a Data Scientist - FI Solutions at Vericast, your contributions will help us stay at the forefront of the AdTech industry. We are seeking a Data Scientist - FI Solutions who is passionate about using cutting edge technology and data science methods to solve unique and complex problems within the Financial Services industry. The ideal candidate is innately curious about how data can be used to tell a story and inform decisions. You have honed your skills through a combination of education, work experience, and hobbies. You are excited about the complexity and challenges of creating intelligent, high-performance systems while working with a highly experienced and driven data science team. If this described you, we are interested. You can be an integral part of a cross-disciplinary team working on highly visible projects that improve performance and grow the intelligence in our Financial Services marketing product suite. Our day-to-day work is performed in a progressive, high-tech workspace where we focus on a friendly, collaborative, and fulfilling environment. Key Duties/Responsibilities Leverage richly populated feature stores to understand consumer and market behavior for Financial Institution (FI) clients, like banks and credit unions. 20% Implement a predictive model to determine whether a person or household is likely to open a lending or deposit account based on the advertising signals they've received. 20% Derive a set of new features that will help better understand the interplay between geography and audience features to improve model performance. 20% Work collaboratively with Data Engineering and Analytics teams to develop new products with applied AI and bring them to market. 20% Participate in planning, roadmap, and architecture discussions to help evolve our AI processes to improve revenue-generating products. 20% Qualifications EDUCATION Bachelor's of Science (BS) degree in quantitative discipline (Computer Science, Mathematics, Engineering, Statistics) (Required). Master's pf Science (MS) degree in relative field (Computer Science, Mathematics, Statistics) (Preferred). Experience 3-5 years of experience within the Data Science space. Experience working for or with a Financial Institution (FI) strongly preferred. Knowledge/Skills/Abilities Ability to churn through and gain insights from high volumes of data using distributed processing. Ability to create Data-Driven presentations and reports for technical and non-technical stakeholders. Expertise in analysis or design of experiments for standard and adhoc analysis, interpreting results to drive marketing strategies. Familiarity with Spark Framework within an On-Premise Big Data Environment. Good analytical skills, with expertise in analytical toolkits such as Regression, Tree-based Models, Cluster Analysis, Factor Analysis, Multivariate Regression, Statistical modeling, predictive analysis. Proficient in Python/PySpark collaborative development in an industry setting. Proven track record of leveraging data to optimize marketing campaigns and improve customer engagement. Understanding and experience with Machine Learning workflows and model productionalization. Additional Information Salary: $90,000 - $110,000 The ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities. Vericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K with company match, and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers! At Vericast, we don’t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community. As an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf.",
        "url": "https://www.linkedin.com/jobs/view/3961096388",
        "summary": "Vericast, a big data marketing solutions company, is seeking a Data Scientist - FI Solutions to help them improve their Financial Services marketing product suite. The ideal candidate will have 3-5 years of experience in data science, strong analytical skills, and experience working with Financial Institutions. Responsibilities include leveraging feature stores, implementing predictive models, developing new products with applied AI, and participating in planning and roadmap discussions. ",
        "industries": [
            "Marketing",
            "Financial Services",
            "Advertising Technology (AdTech)",
            "Big Data",
            "Data Science",
            "Machine Learning",
            "Analytics"
        ],
        "soft_skills": [
            "Passionate",
            "Curious",
            "Analytical",
            "Collaborative",
            "Communicative",
            "Strategic",
            "Problem-solving"
        ],
        "hard_skills": [
            "Distributed Processing",
            "Data-Driven Presentations",
            "Experiment Design and Analysis",
            "Spark Framework",
            "Regression",
            "Tree-based Models",
            "Cluster Analysis",
            "Factor Analysis",
            "Multivariate Regression",
            "Statistical Modeling",
            "Predictive Analysis",
            "Python",
            "PySpark",
            "Machine Learning",
            "Model Productionalization"
        ],
        "tech_stack": [
            "Spark Framework",
            "Python",
            "PySpark",
            "Machine Learning"
        ],
        "programming_languages": [
            "Python",
            "PySpark"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's of Science",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Engineering",
                "Statistics"
            ]
        },
        "salary": {
            "max": 110000,
            "min": 90000
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401K with company match",
            "Flexible PTO",
            "Life insurance",
            "Employee assistance",
            "Pet insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Texas, United States",
        "job_id": 3964192191,
        "company": "Harbor Health",
        "title": "Data Scientist",
        "created_on": 1720587986.3586874,
        "description": "Harbor Health is looking for a data scientist to become a member of our growing team! Harbor Health is an entirely new multi-specialty clinic group in Austin, TX utilizing a modern approach to co-create health with those who get, give, and pay for it, allowing everyone to fully flourish. Join us as we build a fully integrated system that connects care to a better payment model that truly puts the human being at the center. You will support the clinical, actuarial, product development, and operations teams to develop and deliver solutions that enable our unique care model and innovative health plan. Essential Duties and Responsibilities: Collaborate with the data science team to create and improve foundational models Collaborate with development teams to integrate machine learning models into production applications Design and develop analysis techniques to uncover patterns and anomalies in large-scale health data Integrate data from multiple data sources or functional areas, ensuring data accuracy and integrity, and updating as needed Assist with complex analysis requests from senior leadership or project teams Successful Data Scientists will have Master's degree in applied mathematics, statistics, data science, computer science, or related field with 2+ years of experience OR bachelor’s degree in one of those fields with 3+ years of experience Proven track record of designing and building statistical and machine learning models to solve complex problems Proficiency in SQL and Python – including Pandas, NumPy, TensorFlow, PyTorch, and other standard data science libraries Experience working in a cloud computing environment such as AWS, GCP, or similar Experience working with healthcare claims and electronic health record data Ability to engage business leaders to gain deep understanding of the problems to be solved and desired outcomes and collaborate with others to create a solution Open mind and desire to collaborate with others, consider different ideas, accept feedback, and find common ground on the best path forward Excellent oral and written communication skills including data visualization and the ability to clearly communicate complex findings to leaders in other departments Attention to detail and ability to manage schedules and deadlines independently Physical Requirements of the role include: This is a US-based remote role with occasional travel to other offices up to 10% If you are passionate about improving healthcare and you want to create something new together, we want you to be a part of our team! Powered by JazzHR PUR0hrze2h",
        "url": "https://www.linkedin.com/jobs/view/3964192191",
        "summary": "Harbor Health, a multi-specialty clinic group in Austin, TX, is seeking a Data Scientist to join their growing team. This role will involve developing and implementing machine learning models to support clinical, actuarial, product development, and operations teams. The ideal candidate will have a Master's degree in a relevant field with 2+ years of experience or a Bachelor's degree with 3+ years of experience, proficiency in SQL and Python, experience with cloud computing and healthcare data, strong communication skills, and the ability to collaborate effectively.",
        "industries": [
            "Healthcare",
            "Technology",
            "Data Science",
            "Machine Learning",
            "Analytics"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Data Visualization",
            "Attention to Detail",
            "Time Management",
            "Leadership",
            "Teamwork",
            "Open-Mindedness",
            "Critical Thinking"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "Pandas",
            "NumPy",
            "TensorFlow",
            "PyTorch",
            "Machine Learning",
            "Statistical Modeling",
            "Cloud Computing",
            "AWS",
            "GCP",
            "Healthcare Claims",
            "Electronic Health Records"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "Pandas",
            "NumPy",
            "TensorFlow",
            "PyTorch",
            "AWS",
            "GCP"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Applied Mathematics",
                "Statistics",
                "Data Science",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959976145,
        "company": "Sunrise AI",
        "title": "Data Scientist",
        "created_on": 1720587988.0059268,
        "description": "Sunrise AI builds autonomous AI agents for enterprise teams. Our suite of tools leverages AI and machine learning to empower GTM and RevOps teams to streamline operations, enhance decision-making, and optimize customer relationships. We prioritize trust and security, focusing solely on enterprise customers to ensure their proprietary data is leveraged optimally. This enables us to drive conversions for sales teams and protect against churn for customer success teams. Our vision is supported and funded by AI Fund (founded by Dr. Andrew Ng), a venture studio backed by NEA, Softbank, Sequoia, and Greylock, that bridges AI technologies and critical applications. We are seeking a talented and driven data scientist to join our founding team and collaborate with our initial cohort of enterprise design partners. This individual will play a crucial role in shaping the development of our product by building machine learning models, facilitating rapid prototyping, creating insightful visualizations, and developing LLM-based workflow automation prototypes. This is a part-time, contract position, with an expected 15-20 hours per week with the expectation of it becoming a full-time role later this year. Responsibilities for the Role Include: Lead the development and implementation of machine learning models to solve complex enterprise-level problems. Collaborate with cross-functional teams to understand business requirements from our design partners and translate them into technical solutions. Facilitate rapid prototyping to quickly iterate and improve upon existing models and algorithms. Develop and create visualizations to communicate data insights effectively using tools such as Python, Tableau, PowerBI, and QlikView. Design and develop LLM-based workflow automation prototypes to enhance operational efficiencies. Work closely with our enterprise design partners to understand their needs and refine our product accordingly. Must Haves for the Role Include: 5+ years of experience building machine learning models. 3+ years of experience creating visualizations using Python and tools such as Tableau, PowerBI, and QlikView. 1+ year of experience building applications using LLMs (Large Language Models). Strong analytical and problem-solving skills, with a keen attention to detail. Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders. Nice to Haves Include: 3+ years of hands-on experience using AWS. 3+ years of experience with MLOps (Machine Learning Operations). Previous experience in an early-stage start-up is highly desirable. Familiarity with enterprise sales and customer success functions. Available for hybrid work based in NYC. We are proud to be a part of the New York City Economic Development Council Founder Fellowship and Company Ventures’ Grand Central Tech Residency. At Sunrise AI, we believe in fostering a diverse and inclusive work environment where equal employment opportunities are available to all applicants. We value diversity and inclusion as crucial elements of our success as a company. Our selection process for employment is based on qualifications, merit, and business need, without regard to race, color, religion, sex, pregnancy (including childbirth, lactation, and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, or any other characteristic protected by applicable law.",
        "url": "https://www.linkedin.com/jobs/view/3959976145",
        "summary": "Sunrise AI is seeking a part-time Data Scientist to develop and implement machine learning models for enterprise-level problems, facilitate rapid prototyping, create visualizations, and develop LLM-based workflow automation prototypes. This is an opportunity to join a founding team and work with design partners to shape the product.",
        "industries": [
            "Artificial Intelligence",
            "Machine Learning",
            "Sales",
            "Customer Success",
            "Software",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical",
            "Detail-oriented",
            "Collaboration"
        ],
        "hard_skills": [
            "Machine Learning",
            "Python",
            "Tableau",
            "PowerBI",
            "QlikView",
            "LLMs",
            "AWS",
            "MLOps"
        ],
        "tech_stack": [
            "Python",
            "Tableau",
            "PowerBI",
            "QlikView",
            "LLMs",
            "AWS"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": null,
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Frisco, TX",
        "job_id": 3965434981,
        "company": "Maris Consulting Group℠",
        "title": "Data Scientist",
        "created_on": 1720587994.1059282,
        "description": "Location: Frisco, TX or Westbrook, ME Seeking an Data Scientist specializing in computer vision to join our innovative team. In this role, you will collaborate with engineering teams, clinical experts, and business stakeholders to deliver high performing embedded computer vision algorithms for innovative veterinary diagnostic instruments. Job Description Responsibilities: Develop and deploy embedded computer vision algorithms for veterinary diagnostic platforms Collaborate closely with cross-functional engineering teams, clinical experts, and business stakeholders to define requirements and develop project plans Lead the design, development, and implementation of computer vision solutions, from data annotation and model training to evaluation, monitoring, and deployment Utilize strong software engineering skills to develop scalable, maintainable, and efficient code for computer vision applications, ensuring high performance and reliability Work with embedded systems and NVIDIA GPUs to optimize and deploy algorithms for real-time processing and inference Stay current with advancements in computer vision, machine learning, and related fields, and incorporate relevant technologies and methodologies into projects. Provide technical guidance and mentorship to junior team members, fostering their growth and development in computer vision and machine learning. Qualifications: Bachelor's, Master's, or Ph.D. degree in Computer Science, Electrical Engineering, or a related field. Proven experience delivering computer vision solutions, with expertise in Python programming and deep learning frameworks such as TensorFlow or PyTorch. Demonstrated experience working across the full development lifecycle, from requirements development to model deployment on embedded hardware Strong software engineering skills, with experience delivering software in a production environment and familiarity with software development best practices. Familiarity with microscopy, digital cytology, or digital pathology is desirable Experience using Databricks is a plus Proficiency in AWS services for data processing, storage, and deployment. Excellent communication skills and the ability to work effectively in a collaborative team environment. DeWinter Group and Maris Consulting  is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.  We post pay scales which are based on our client pay ranges. DeWinter, Maris, and our clients have the right to modify the requirements of the role which can impact the pay ranges posted.",
        "url": "https://www.linkedin.com/jobs/view/3965434981",
        "summary": "Data Scientist specializing in computer vision to develop and deploy embedded computer vision algorithms for veterinary diagnostic platforms. Responsibilities include collaborating with engineering teams, clinical experts, and business stakeholders to define requirements, develop project plans, design, develop, and implement computer vision solutions. The role requires strong software engineering skills, experience working with embedded systems and NVIDIA GPUs, and staying up-to-date with advancements in computer vision and machine learning.",
        "industries": [
            "Veterinary",
            "Healthcare",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Leadership",
            "Mentorship"
        ],
        "hard_skills": [
            "Computer Vision",
            "Python",
            "TensorFlow",
            "PyTorch",
            "Software Engineering",
            "Embedded Systems",
            "NVIDIA GPUs",
            "Microscopy",
            "Digital Cytology",
            "Digital Pathology",
            "Databricks",
            "AWS"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "AWS",
            "Databricks",
            "NVIDIA GPUs"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Electrical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Oklahoma City Metropolitan Area",
        "job_id": 3962957788,
        "company": "Optimize Search Group",
        "title": "Data Scientist (100% onsite)",
        "created_on": 1720587995.6325285,
        "description": "Job Title: Data Scientist Duration: Direct Hire Location: Oklahoma City, OK (100% on-site) Job Description: The Data Scientist will apply statistical theory and methods to collect, interpret, and summarize data as well as make predictions and recommend actions based on data. Key Responsibilities Conducts statistical analyses to develop strategies Builds predictive models and machine-learning algorithms Identifies data patterns and trends Proposes solutions and strategies to business challenges Presents information using data visualization techniques Documents all processes and research Other duties and responsibilities as assigned Qualifications Excellent verbal and written communication skills Excellent organizational skills and attention to detail Able to multitask, prioritize, and manage time effectively Strong math skills Problem-solving aptitude Education/Experience Bachelor's degree in computer science, statistics, applied math or related field required. Master's degree preferred Extensive background in data mining and statistical analysis At least two years' experience with SQL and statistical software packages (Python, R, SAS) required Experience using business intelligence tools and data frameworks",
        "url": "https://www.linkedin.com/jobs/view/3962957788",
        "summary": "Data Scientist needed to conduct statistical analyses, build predictive models, identify data patterns, propose solutions, and present information using data visualization. Requires strong math skills, problem-solving aptitude, and experience with SQL, Python, R, SAS, and business intelligence tools.",
        "industries": [
            "Data Science",
            "Analytics",
            "Information Technology"
        ],
        "soft_skills": [
            "Communication",
            "Organizational Skills",
            "Attention to Detail",
            "Multitasking",
            "Prioritization",
            "Time Management",
            "Problem-Solving"
        ],
        "hard_skills": [
            "Statistical Analysis",
            "Data Mining",
            "Predictive Modeling",
            "Machine Learning",
            "Data Visualization",
            "SQL",
            "Python",
            "R",
            "SAS",
            "Business Intelligence",
            "Data Frameworks"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "R",
            "SAS",
            "Business Intelligence Tools",
            "Data Frameworks"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL",
            "SAS"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Applied Math"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Jacksonville, FL",
        "job_id": 3969885752,
        "company": "Phoenix Recruitment",
        "title": "Junior Data Scientist",
        "created_on": 1720587997.4606607,
        "description": "This is a remote position. Junior Data Scientist - US Only Experience: 1+ years Employment Type: Full-time, Remote Base Salary: $62K-$72K Phoenix Recruitment offers a variety of recruiting services to assist both employers and employees. They are specialized in marketing open positions, recruiting, and helping employers to find qualified candidates across various industries. Phoenix Recruitment has expertise in streamlining the hiring process. They can help ensure that the process is efficient, well organized, and compliant with relevant regulations. Responsibilities: Partner with engineers, product managers, and business partners to identify algorithmic problems, brainstorm possible approaches, and recommend the best path forward. Develop algorithms iteratively, building in the right level of complexity to solve the business problem at hand and support future improvements. Define success criteria for your models so that you can measure impact and changes over time. You'll be expected to communicate findings and drive continuous improvements. Collaborate with Software Engineers to implement algorithms in production that scale gracefully. Collaborate with stakeholders to prioritize projects and define requirements. Carry out analysis of data produced by our hardware systems and create insightful visualizations to share your findings. Contribute to internal libraries to help other teams with their data science needs including visualization, prediction, optimization, and inference. Requirements & Experience: Advanced proficiency with Python and libraries commonly used for data analysis, e.g., Pandas, NumPy, SciPy, and Diplomatist. Strong understanding of data modeling and statistical analysis. Knowledge of optimization and predictive modeling techniques and experience applying them to real-world problems. Skilled at translating a general question or problem into a clearly defined algorithmic solution. Ability to communicate clearly with both technical and non-technical audiences. Ability to work independently and manage multiple projects simultaneously. Nice to have: 1-year Experience with Data Bricks or PySpark 1 year Experience with product ionizing data models Why Phoenix Recruitment LLC? Phoenix Recruitment often has an extensive network of employers and candidates. This network allows them to tap into a pool of qualified candidates and connect them with suitable job opportunities. They can also leverage their connections to help employers find the right talent efficiently. Outsourcing the recruitment process to a specialized agency can save you time and resources, avoid delays, reduce administrative burdens, and increase the chances of finding the right fit for your organization.",
        "url": "https://www.linkedin.com/jobs/view/3969885752",
        "summary": "Junior Data Scientist role focused on developing and implementing algorithms to solve business problems, analyze data, and create visualizations. The role involves collaborating with engineers, product managers, and business partners to define and prioritize projects. Experience with Python, data modeling, statistical analysis, optimization, and predictive modeling is required. ",
        "industries": [
            "Data Science",
            "Software Development",
            "Technology",
            "Analytics",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Analytical Thinking",
            "Time Management",
            "Project Management",
            "Independent Work"
        ],
        "hard_skills": [
            "Python",
            "Pandas",
            "NumPy",
            "SciPy",
            "Diplomatist",
            "Data Modeling",
            "Statistical Analysis",
            "Optimization",
            "Predictive Modeling",
            "Visualization",
            "Data Bricks",
            "PySpark",
            "Product Ionizing Data Models"
        ],
        "tech_stack": [
            "Python",
            "Pandas",
            "NumPy",
            "SciPy",
            "Diplomatist",
            "Data Bricks",
            "PySpark"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 1,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 72000,
            "min": 62000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Austin, TX",
        "job_id": 3970270756,
        "company": "AMD",
        "title": "Machine Learning Performance Engineer",
        "created_on": 1720587999.1039078,
        "description": "WHAT YOU DO AT AMD CHANGES EVERYTHING We care deeply about transforming lives with AMD technology to enrich our industry, our communities, and the world. Our mission is to build great products that accelerate next-generation computing experiences - the building blocks for the data center, artificial intelligence, PCs, gaming and embedded. Underpinning our mission is the AMD culture. We push the limits of innovation to solve the world’s most important challenges. We strive for execution excellence while being direct, humble, collaborative, and inclusive of diverse perspectives. AMD together we advance_ The Role AMD is looking for an influential software engineer who is passionate about improving the performance of machine learning and high-performance compute workloads and benchmarks through optimizing dense linear algebra . You will be a member of a core team of incredibly talented industry specialists and will work with the very latest hardware and software technology. The Person The ideal candidate should be passionate about software engineering, dense linear algebra, and possess leadership skills to drive sophisticated issues to resolution. Able to communicate effectively and work optimally with different teams across AMD. Key Responsibilities Work with AMD’s architecture specialists to improve future products Apply a data minded approach to target optimization efforts Stay informed of software and hardware trends and innovations, especially pertaining to algorithms and architecture Design and develop new groundbreaking AMD technologies Participating in new ASIC and hardware bring ups Debugging/fix existing issues and research alternative, more efficient ways to accomplish the same work Develop technical relationships with peers and partners Preferred Experience Strong understanding of dense linear algebra Strong programming background, C/C++ preferred Ability to write high quality code with a keen attention to detail Experience with parallel programming and threading APIs Experience with Linux operating system development Experience with software development processes and tools such as debuggers, source code control systems (GitHub) and profilers is a plus Effective communication and problem-solving skills Motivating leader with good interpersonal skills Academic Credentials Bachelor’s or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, or equivalent At AMD, your base pay is one part of your total rewards package. Your base pay will depend on where your skills, qualifications, experience, and location fit into the hiring range for the position. You may be eligible for incentives based upon your role such as either an annual bonus or sales incentive. Many AMD employees have the opportunity to own shares of AMD stock, as well as a discount when purchasing AMD stock if voluntarily participating in AMD’s Employee Stock Purchase Plan. You’ll also be eligible for competitive benefits described in more detail here. AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process.",
        "url": "https://www.linkedin.com/jobs/view/3970270756",
        "summary": "AMD is seeking a Software Engineer to optimize machine learning and high-performance compute workloads and benchmarks by improving dense linear algebra. The role involves working with AMD's architecture specialists, staying informed of software and hardware trends, designing and developing new technologies, participating in ASIC and hardware bring-ups, debugging and researching alternative solutions, and collaborating with peers and partners.",
        "industries": [
            "Semiconductors",
            "Technology",
            "Computer Hardware",
            "Artificial Intelligence",
            "Software Development",
            "High Performance Computing",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Leadership",
            "Interpersonal",
            "Teamwork",
            "Data-minded",
            "Detail-oriented"
        ],
        "hard_skills": [
            "Dense Linear Algebra",
            "C/C++",
            "Parallel Programming",
            "Threading APIs",
            "Linux",
            "Software Development Processes",
            "Debuggers",
            "Source Code Control Systems",
            "Profilers",
            "GitHub"
        ],
        "tech_stack": [
            "C/C++",
            "Linux",
            "GitHub"
        ],
        "programming_languages": [
            "C",
            "C++"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Computer Engineering",
                "Electrical Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Annual Bonus",
            "Sales Incentive",
            "Stock Ownership",
            "Employee Stock Purchase Plan",
            "Competitive Benefits"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3969068931,
        "company": "Rise Technical",
        "title": "Senior Data Scientist",
        "created_on": 1720588000.4766133,
        "description": "Senior Data Scientist (Web3 & Blockchain) $150,000 - $200,000 + Bonus + Dental + vision + medical + life insurance + Unlimited PTO Fully remote (Covering EST time zone) Are you from a data or data science background, are highly proficient at data storytelling and have experience presenting to Tier 1 clients? Are you looking to make an impact in a leading boutique organization in the blockchain sector where you can autonomously innovate new data solutions and establish internal data warehousing in a fast growing market? On offer is the chance to join a well-respected Web3 consultancy that will allow you to blend your extensive data experience with your interest in blockchain technologies as they look to continue their rapid growth. Founded 5 years ago, this impressive company is behind some of the best known and most momentous Web3 projects of recent years and is looking to continue their impact within the industry through the launch of exciting projects via a new boutique consultancy firm. As the Lead Data Scientist, you will be leading data analysts and overseeing multiple clients’ projects. You will pull on-chain data and building dashboards for clients via Google Sheets documents, in order to tell stories with data, which in turn will be integral to successful fungible token design and go-to-market execution. You will also have the opportunity to establish an internal data warehouse. This is the perfect opportunity for someone with strong interest in telling stories through data to join a high growth company in a lead role, whilst receiving industry specific training and benefiting from career growth. The Role: * Manage and mentor Data Analysts * Work closely with Token Design Leads to tell stories through data & modelling * Pull on-chain data * Build new data solutions and infrastructure, and establish an internal data warehouse * Tell stories using data to non-technical stakeholders via dashboards * Fully remote working predominantly within an EST time zone. The person: * Strong background in data modelling with experience leading others * Looking for a fully remote Web3 role (must be available during EST hours) * Must be proficient in Google Sheets * Passionate about data storytelling * Experienced working within cloud infrastructure * Experience with API integrations * Experience building new data solutions and data infrastructure * Has basic Machine Learning capabilities * Must have strong interpersonal and communication skills. Reference Number: BBBH223826 To apply for this role or to be considered for further roles, please click \"Apply Now\" or contact Luca Browning at Rise Technical Recruitment. Rise Technical Recruitment Ltd acts an employment agency for permanent roles and an employment business for temporary roles. The salary advertised is the bracket available for this position. The actual salary paid will be dependent on your level of experience, qualifications and skill set. We are an equal opportunities employer and welcome applications from all suitable candidates.",
        "url": "https://www.linkedin.com/jobs/view/3969068931",
        "summary": "Lead Data Scientist role at a Web3 consultancy focusing on data storytelling, on-chain data analysis, dashboard building, and establishing an internal data warehouse. The role involves managing and mentoring data analysts, working with Token Design Leads, and presenting data insights to non-technical stakeholders.",
        "industries": [
            "Blockchain",
            "Web3",
            "Consultancy"
        ],
        "soft_skills": [
            "Data Storytelling",
            "Communication",
            "Interpersonal",
            "Leadership",
            "Mentoring",
            "Problem Solving",
            "Innovation"
        ],
        "hard_skills": [
            "Data Modelling",
            "On-Chain Data Analysis",
            "Dashboard Building",
            "Google Sheets",
            "Cloud Infrastructure",
            "API Integrations",
            "Data Warehousing",
            "Machine Learning"
        ],
        "tech_stack": [
            "Google Sheets",
            "Cloud Infrastructure",
            "API Integrations",
            "Data Warehousing"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 200000,
            "min": 150000
        },
        "benefits": [
            "Bonus",
            "Dental",
            "Vision",
            "Medical",
            "Life Insurance",
            "Unlimited PTO"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Sioux Falls, SD",
        "job_id": 3970709906,
        "company": "Team Remotely Inc",
        "title": "Junior Full Stack Developer React/Python",
        "created_on": 1720588006.9231906,
        "description": "(1 year experience,onsite) Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $58K-$68K Per Annum. Responsibilities: Architect, design, and implement solutions to complex engineering problems Provide coding expertise in Python (FastAPI and Django), React JS, TypeScript, SQL, NoSQL, and AWS to develop frontend and backend applications. Collaborate with other developers to deliver working software solutions Assist project management with planning, product roadmap planning, and release planning Assist with code reviews and technical reviews Qualifications: 1 year of professional experience with React JS and Python Bachelor's degree in computer science, engineering, or related Good communication skills, both oral and written Nice to Have experience: Mobile app development in React Native Thirst For Tech Learning Benefits 401(k) matching Flexible spending account Flextime Health insurance Health savings account Paid time off Relocation assistance Tuition reimbursement",
        "url": "https://www.linkedin.com/jobs/view/3970709906",
        "summary": "This job posting builds a talent pool for potential future full-time openings in software development.  The ideal candidate will have 1 year of experience with React JS and Python, and a bachelor's degree in a related field. They will be responsible for architecting, designing, and implementing solutions to complex engineering problems, collaborating with other developers, and assisting with project management tasks. The position offers a salary range of $58K-$68K per annum and includes benefits such as 401(k) matching, flexible spending accounts, flextime, health insurance, paid time off, relocation assistance, and tuition reimbursement.",
        "industries": [
            "Software Development",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Technical",
            "Project Management"
        ],
        "hard_skills": [
            "Python",
            "React JS",
            "TypeScript",
            "SQL",
            "NoSQL",
            "AWS",
            "FastAPI",
            "Django",
            "React Native"
        ],
        "tech_stack": [
            "Python",
            "React JS",
            "TypeScript",
            "SQL",
            "NoSQL",
            "AWS",
            "FastAPI",
            "Django",
            "React Native"
        ],
        "programming_languages": [
            "Python",
            "TypeScript"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 68000,
            "min": 58000
        },
        "benefits": [
            "401(k) matching",
            "Flexible spending account",
            "Flextime",
            "Health insurance",
            "Health savings account",
            "Paid time off",
            "Relocation assistance",
            "Tuition reimbursement"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3960922124,
        "company": "Harnham",
        "title": "Data Scientist",
        "created_on": 1720588014.3956697,
        "description": "Title: Data Scientist Location: 75201 - Dallas, TX Overview of Role: As a Data Scientist, you will be responsible for not only writing great code, but also being able to show why it matters and how it makes a direct impact on business results. We are looking for someone who has extensive experience building propensity & forecast models, as well having experience with sentiment and segmentation analysis. Company Description: Our client is focused on helping prospective and current students have better access to higher education opportunities across a nationwide university network. Our client is currently in a major growth phase and is looking to expand their data team due to this. Role Description: Define and scope potential AI/ML projects that will drive change within the organization. Design analytical approaches to existing problems and find solutions via model-building and analyzing business trends. Partner with business leaders and clients to identify issues that can be potentially solved with Data Science solutions Act as a data leader and mentor junior-level team members. Stay up to date on current data science trends and best practices. Create and deploy models. Skills and Experience: Bachelor's or Master's degree in a technical discipline such as computer science, mathematics, or engineering. 3+ years of experience as a Data Scientist or Machine Learning Engineer. Strong knowledge of Machine Learning and generative AI concepts. Ability to write strong code in Python and SQL. Knowledge and experience using tools like Databricks, NumPy, Pandas, PySpark, Tensorflow, etc. Familiarity with the education industry is a huge plus but not necessary. NLP experience with sentiment analysis is a must-have. Ability to speak to how previous projects have led to changes within your organization. Experience with Salesforce CRM is very helpful. Benefits: Health, Dental, and Vision Insurance 15+ Days of PTO Annually 401(k) Matching Program Tuition reimbursement program",
        "url": "https://www.linkedin.com/jobs/view/3960922124",
        "summary": "Data Scientist responsible for developing AI/ML solutions to drive business results, building propensity & forecast models, and conducting sentiment & segmentation analysis. Requires strong Python, SQL, and ML expertise with experience using tools like Databricks, NumPy, Pandas, PySpark, and TensorFlow. NLP and Salesforce CRM experience are valuable.",
        "industries": [
            "Education",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Leadership",
            "Mentorship",
            "Analytical Thinking"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "Machine Learning",
            "Generative AI",
            "Databricks",
            "NumPy",
            "Pandas",
            "PySpark",
            "TensorFlow",
            "NLP",
            "Sentiment Analysis",
            "Salesforce CRM"
        ],
        "tech_stack": [
            "Databricks",
            "NumPy",
            "Pandas",
            "PySpark",
            "TensorFlow",
            "Salesforce CRM"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "PTO",
            "401(k) Matching",
            "Tuition Reimbursement"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Philadelphia, PA",
        "job_id": 3970139712,
        "company": "iO Associates - US",
        "title": "AI Engineer",
        "created_on": 1720588016.0244813,
        "description": "We are seeking a talented AI Engineer with experience creating prompts for large language models (LLMs). The ideal candidate will have a strong background in AI, machine learning, and natural language processing (NLP), coupled with a knack for crafting prompts that generate content that is both engaging and factually accurate. You will play a critical role in shaping how our customer's AI tools interact with users, ensuring that the generated content meets their high standards of quality and relevance. Key Responsibilities: Prompt Engineering: Design, develop, and optimize prompts for LLMs to produce high-quality content. Experiment with different prompt structures and techniques to enhance content generation. Content Quality Assurance: Implement mechanisms to ensure the factual accuracy of the content generated by LLMs. Collaborate with subject matter experts to verify and validate the information produced by AI models. AI Model Development: Work with data scientists and researchers to train and fine-tune LLMs. Develop algorithms and methodologies to improve the performance and accuracy of AI-generated content. Research and Innovation: Stay updated with the latest advancements in AI, NLP, and machine learning technologies. Conduct research to explore new ways of enhancing LLM capabilities and content generation processes. Collaboration: Work closely with cross-functional teams including product managers, designers, and content creators to understand audience needs and content requirements. Provide technical insights and support to other team members. Documentation and Reporting: Document prompt engineering processes, methodologies, and best practices. Generate reports and presentations to communicate findings and progress to stakeholders. Qualifications: Proven experience in AI, machine learning, and NLP. Proficiency in programming languages such as Python and frameworks like TensorFlow, PyTorch, or similar. Strong understanding of large language models (e.g., GPT, BERT) and their applications. Excellent problem-solving skills and attention to detail. Ability to think creatively and design prompts that align with audience interests. Strong communication and teamwork skills. Preferred Qualifications: Experience in prompt engineering for LLMs. Familiarity with content generation tools and platforms. Background in data analysis and statistical modeling. Knowledge of ethical AI practices and considerations.",
        "url": "https://www.linkedin.com/jobs/view/3970139712",
        "summary": "This job description seeks an AI Engineer with expertise in prompt engineering for large language models (LLMs). Responsibilities include designing, optimizing, and testing prompts to ensure high-quality, factually accurate content generation. The ideal candidate will have a strong background in AI, machine learning, and NLP, as well as experience with frameworks like TensorFlow and PyTorch. They will collaborate with data scientists, subject matter experts, and cross-functional teams to improve LLM performance and ensure content aligns with user needs.",
        "industries": [
            "Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing",
            "Software Development",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem-solving",
            "Creativity",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "Prompt Engineering",
            "Large Language Models (LLMs)",
            "GPT",
            "BERT",
            "Content Generation",
            "Data Analysis",
            "Statistical Modeling"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "GPT",
            "BERT"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Alpharetta, GA",
        "job_id": 3964360576,
        "company": "Steneral Consulting",
        "title": "Need local Senior Data Scientist at GA",
        "created_on": 1720588017.3181798,
        "description": "Job Title - Senior Data Scientist Type - Onsite Location - Onsite Must be local Description - 8+ years consultant Required Skills : Database Design ,Python ,Machine Learning ,Artificial Intelligence Roles & Responsibilities Lead the development and implementation of geospatial data models and solutions to support business objectives. Oversee the design and maintenance of databases to ensure efficient data storage and retrieval. Provide expertise in Python programming to automate data processing and analysis tasks. Utilize machine learning algorithms to analyze geospatial data and generate predictive insights. Apply artificial intelligence techniques to enhance the accuracy and efficiency of geospatial analyses. Collaborate with cross-functional teams to integrate geospatial data into broader business strategies. Conduct thorough data quality assessments to ensure the reliability and accuracy of geospatial datasets. Develop and maintain documentation for geospatial data models, processes, and workflows. Train and mentor junior analysts in geospatial analysis techniques and best practices. Present findings and recommendations to stakeholders in a clear and concise manner. Stay updated with the latest advancements in geospatial technologies and methodologies. Ensure compliance with data privacy and security regulations in all geospatial data handling processes. Contribute to the continuous improvement of geospatial analysis tools and methodologies. Qualifications Possess strong experience in database design and management, ensuring efficient data storage and retrieval. Demonstrate proficiency in Python programming for automating data processing and analysis tasks Have a solid understanding of machine learning algorithms and their application in geospatial data analysis. Show expertise in artificial intelligence techniques to enhance geospatial analyses. Exhibit excellent problem-solving skills and the ability to work collaboratively with cross-functional teams. Display strong communication skills for presenting findings and recommendations to stakeholders. Maintain a proactive approach to staying updated with advancements",
        "url": "https://www.linkedin.com/jobs/view/3964360576",
        "summary": "Senior Data Scientist with 8+ years of consulting experience. Leads development and implementation of geospatial data models and solutions, oversees database design and maintenance, utilizes Python, machine learning and AI for geospatial analysis and insights. Requires strong database design, Python, machine learning, and AI skills.",
        "industries": [
            "Data Science",
            "Geospatial Analysis",
            "GIS",
            "Consulting"
        ],
        "soft_skills": [
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Mentoring"
        ],
        "hard_skills": [
            "Database Design",
            "Python",
            "Machine Learning",
            "Artificial Intelligence",
            "Geospatial Data Analysis"
        ],
        "tech_stack": [
            "Python",
            "Machine Learning",
            "Artificial Intelligence",
            "Geospatial Data Models",
            "Databases"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Monrovia, CA",
        "job_id": 3965547086,
        "company": "Terray Therapeutics",
        "title": "Senior Associate Data Scientist, Molecular Data Analysis",
        "created_on": 1720588023.9261444,
        "description": "Company Overview Terray Therapeutics is a venture-backed biotechnology company led by pioneers and long-time leaders in artificial intelligence, synthetic chemistry, automation, and nanotechnology. We're generating chemical data purpose-built to propel drug discovery into the information age — and we're doing it on a larger scale and faster than has ever before been possible. Our closed loop system generates precise chemical datasets at unrivaled scale that work seamlessly with AI to systematically map biochemical interactions between small molecules and causes of disease. Iterative cycles of virtual molecular design and experimentation power AI and machine learning models, which in turn guide the next cycle of design. With a chemistry engine that measures billions of interactions daily and becomes increasingly precise with every cycle, we can answer an unprecedented array of questions — deriving insights that enable us to predictably create drugs for patients in need. Position Summary Terray is currently seeking a motivated and creative senior associate data scientist. As an integral member of our Computational and Data Sciences (CDS) team, the candidate will be responsible for analyzing data and communicating outcomes from our wet-lab and computational discovery platforms. The core responsibilities of this position are: Work with wet-lab scientists to answer key questions using data from our wet-lab and computational discovery platforms Work with software engineers and other data scientists to incorporate these analyses and visualizations into software tools Leverage and develop tools for analyzing binding data from our proprietary molecule discovery platform to identify hits for program progression Interface with internal and external stakeholders on promising hits found on the discovery platform for multiple programs Experience and Qualifications Part of Terray's success is nurtured by a hands-on work environment where everyone is accountable, vested in a vision of excellence, and actively taking part in the success of the business. Terray supports a positive work environment where employees can feel engaged, recognized and empowered to be creative. Required Qualifications: BS/MS in Statistics, Data Science, or related quantitative field Highly proficient in Python and the PyData stack (numpy, pandas, scipy, scikit-learn, etc.) and at least one plotting package Experience working with large, real-world, scientific data Proficiency in the Linux environment, experience with database languages, and experience with version control practices and tools Wet-lab experience and chemistry knowledge are a plus High through screening and/or DEL data analysis experience are a plus Compensation Details $116,000-$174,000 per year, participation in the Company's option plan, 3% 401K contribution, company-paid health, dental, and vision benefits.",
        "url": "https://www.linkedin.com/jobs/view/3965547086",
        "summary": "Terray Therapeutics is a biotechnology company seeking a Senior Associate Data Scientist to analyze data and communicate results from wet-lab and computational discovery platforms. The role involves working with scientists to answer key questions, developing software tools with engineers, analyzing binding data to identify hits for drug discovery, and communicating with stakeholders on promising leads.",
        "industries": [
            "Biotechnology",
            "Pharmaceutical",
            "Artificial Intelligence",
            "Data Science"
        ],
        "soft_skills": [
            "Motivated",
            "Creative",
            "Communication",
            "Collaboration",
            "Problem-Solving"
        ],
        "hard_skills": [
            "Python",
            "PyData Stack",
            "NumPy",
            "Pandas",
            "SciPy",
            "Scikit-learn",
            "Data Visualization",
            "Linux",
            "Database Languages",
            "Version Control",
            "High-throughput Screening",
            "DEL Data Analysis",
            "Statistics",
            "Data Science",
            "Chemistry",
            "Machine Learning"
        ],
        "tech_stack": [
            "Python",
            "PyData Stack",
            "NumPy",
            "Pandas",
            "SciPy",
            "Scikit-learn",
            "Linux",
            "Database Languages",
            "Version Control"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "BS",
            "fields": [
                "Statistics",
                "Data Science",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 174000,
            "min": 116000
        },
        "benefits": [
            "Option Plan",
            "401K Contribution",
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Seattle, WA",
        "job_id": 3962798562,
        "company": "Supernormal",
        "title": "Machine Learning Engineer - Focus on Modeling",
        "created_on": 1720588028.6138973,
        "description": "About Us We're on a mission to transform spoken communication for individuals, teams and organizations of any size. Meetings may be our most information-rich channel for work, but suffer from a lack of structure and documentation. At Supernormal, we're solving this problem with focus, design and craft. We've been working on this since 2019 and have customers like Snap, Salesforce, Replay, Gitcoin, Pinterest and thousands more on this journey with us. Today, we are growing rapidly and are excited for new teammates to join who are the best at what they do. We're passionately building a team that is as diverse and creative as the millions of people we serve worldwide. Supernormal is a remote-first company and does not require co-location. We have annual team retreats and gather quarterly. About The Role Machine learning engineers at Supernormal build the AI that superpowers the core product experience for people's meetings including transcription, note generation, and task automation. The AI team builds reliable and secure services that use the most advanced AI models in the market to generate millions of high-quality meeting notes to a rapidly growing customer base. Our work revolves heavily around software engineering, too - we are looking for people with a drive to roll up their sleeves and get new models and features out to users as quickly as possible. What You'll Work On As an ML engineer with a focus on modeling at Supernormal, you will specialize in developing and refining models that power our AI solutions for meeting notes, question answering, and task completion. Your expertise will be critical in LLM API calls, custom model training and deployment, speech recognition, quality evaluation and fixes, and retrieval augmented generation. You will primarily focus on optimizing model performance, cost, latency, and quality. Some of the projects you'll work on include: Prompt engineering using state-of-the-art techniques to improve the core meeting assistant scenarios Building and shipping custom machine learning models to augment the AI stack, including improving transcript quality, reducing tokens sent to APIs, removing defects in LLM output, and extracting semi-structured data Training and deploying custom large language models from open source using state-of-the-art techniques (LoRA, RLHF, instruction-tuning, etc) Specializing in model optimization to enhance performance and efficiency Developing new product experiences using NLP & LLMs that get better based on user feedback & iteration while collaborating with product engineers & design team Defining and improving business & product metrics to optimize the quality and cost of AI usage Improving LLM-powered search and question answering (using RAG) over sets of meetings Advocating for, and building, new and better ways of doing things. You'll leave everything you touch just a bit better than you found it Requirements What you will bring We are a fast-moving startup building zero-to-one products on top of large language models. The ideal candidate is passionate about machine learning modeling, with a foundational understanding of algorithms and hands-on experience in developing and optimizing models. You exhibit proficiency in basic data analysis, feature engineering, and model evaluation, with a willingness to learn and grow in the field. AI/ML Experience: 2-3 years of demonstrated experience working on real-world machine learning projects. This includes proficiency in developing and optimizing machine learning models, along with skills in model evaluation, validation, and tuning. Familiarity with handling large datasets, data preprocessing, and feature engineering is essential. Experience in deploying models into production environments and monitoring their performance is highly desirable A Solid Educational Foundation: Bachelor's degree in Computer Science, Engineering, AI, Mathematics, or related field; Master's degree or PhD in related disciplines is a plus Software Engineering Skills: Proficiency in software development principles and best practices, such as version control, code review, and testing. Experience with collaborative development tools and platforms, such as GitHub, is essential. Familiarity with Agile methodologies and continuous integration/continuous deployment (CI/CD) pipelines is highly desirable Proficient in Python and SQL: our AI stack uses Python & PyTorch and interfaces with Ruby on Rails (bonus if you know it, but not required) and we write a lot of SQL queries on top of Snowflake to pull data What we'll expect of you A collaborative and open outlook — we're all about lifting each other up and getting better every day A willingness to get deep into a problem even when it seems impossible. You'll always have support from the team Confidence operating with high agency. We'll work together to decide what's important, but we'd love for you to bring (and build!) your own ideas You'll come in willing to learn why things are the way they are, then suggest a better way You'll understand that there's no difference between \"my idea\" and \"their idea.\" It's our ideas and we're all responsible for it You'll approach speed bumps and reviews through a \"how can the team level up?\" lens — let's all get better and learn, together What you can expect from us We're a fully distributed team spread between Pacific Time (Seattle) and Central European Time (Stockholm) with lots of places in between. We'll see you most days in Slack, Google Meet, GitHub issues, and Notion. Sometimes in person in a place with a warm breeze We're a friendly bunch and are happy to pair, talk through, or otherwise assist any time Honest and timely feedback. We're all better when we can have candid conversations about what is and isn't working A willingness to listen to your ideas: how can the codebase, our product, or team be better? A respect for your time outside of work. We all work hard here, but we never forget to rest and have fun Benefits 💰 Competitive salary, 401K 📈 Stock options 🏥 Full healthcare coverage (Medical, Dental, and Vision) 🚀 Totally remote. Not hybrid. Remote. No return-to-office here 🏠 WFH budget to make sure you have everything you need to do your best work ✈️ Annual team-wide offsite to someplace cool 🎓 Education credit (up to $500 per year) 🧳 Unlimited PTO (minimum 4 weeks)",
        "url": "https://www.linkedin.com/jobs/view/3962798562",
        "summary": "Supernormal is looking for an ML Engineer with a focus on modeling to develop and refine models for meeting notes, question answering, and task completion. This role will involve prompt engineering, custom model training and deployment, speech recognition, quality evaluation and fixes, and retrieval augmented generation. The ideal candidate will have 2-3 years of experience working on real-world machine learning projects, a strong educational foundation in computer science or related fields, and proficiency in software development principles. The role requires expertise in Python, PyTorch, SQL, and experience with large language models.",
        "industries": [
            "Software",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Meeting Technology"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Creativity",
            "Innovation",
            "Learning",
            "Feedback",
            "Agency",
            "Initiative"
        ],
        "hard_skills": [
            "Machine Learning",
            "Model Development",
            "Model Optimization",
            "Model Evaluation",
            "Data Analysis",
            "Feature Engineering",
            "Data Preprocessing",
            "Model Deployment",
            "Production Environments",
            "Python",
            "PyTorch",
            "SQL",
            "Ruby on Rails",
            "Snowflake",
            "Prompt Engineering",
            "Custom Model Training",
            "Speech Recognition",
            "Quality Evaluation",
            "Retrieval Augmented Generation",
            "LLM API Calls",
            "Large Language Models",
            "NLP",
            "Software Engineering",
            "Version Control",
            "Code Review",
            "Testing",
            "GitHub",
            "Agile Methodologies",
            "CI/CD Pipelines"
        ],
        "tech_stack": [
            "Python",
            "PyTorch",
            "Ruby on Rails",
            "Snowflake",
            "GitHub",
            "Google Meet",
            "Slack",
            "Notion"
        ],
        "programming_languages": [
            "Python",
            "SQL",
            "Ruby on Rails"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Engineering",
                "AI",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "401K",
            "Stock Options",
            "Full Healthcare Coverage",
            "Remote Work",
            "WFH Budget",
            "Annual Team Offsite",
            "Education Credit",
            "Unlimited PTO"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Fayetteville, NC",
        "job_id": 3968545166,
        "company": "The ACI Group, Inc.",
        "title": "Data Scientist (Secret Cleared)",
        "created_on": 1720588030.1812217,
        "description": "Data Scientist (Secret Cleared), Fayetteville, NC NO THIRD PARTY RECRUITERS PLEASE! Full-time On-Site in Fayetteville, NC Due to our government client requirements, we can only consider US Citizens with an Active Secret clearance. Salary Target: $100-115K Description Our client is seeking a Secret Cleared Data Scientist to support a SOCOM contract. The Data Scientist will have skills sets of both data analysts and data engineers. Will be responsible for designing, implementing, and maintaining a data pipeline. In addition, the data scientist shall interpret and analyze complex sets of data, as well as plan, execute, and manage ML projects with cloud-native platforms and advanced ML solutions. They understand some of the most challenging processes, technologies, and can leverage a vast array of methodologies in the field, such as data mining, natural language programming, and machine learning. Responsibilities Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific method. Coordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data. Experiment against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges. Coordinate with Data Engineers to build Data environments providing data identified by other data professionals. Apply and develop scientific methodology, statistics, and algorithms to discover and frame relevant problems, hypotheses, and opportunities. Develop predictive and prescriptive modeling, natural language processing (NLP), Robotic Process Automation (RPA), text mining and processing, clustering, forecasting methods, and other advanced statistical techniques. Design and automate processes to facilitate the manipulation and analysis of data. Manage and integrate data across dissimilar data sets. Analyze large-scale structured and unstructured data. Use frameworks such as Spark and Hadoop to conduct large-scale data processing. Perform statistical modeling and create data visualizations using products like Tableau, Microsoft Power BI and R Shiny. Research, design, and implement algorithms to solve complex problems. Program using R, Python (NumPy, SciPy, Pandas) or similar analytical languages. Perform data engineering, data processing and modeling techniques using cloud-based data management, data science, and ML platforms such as Databricks, IBM Cloud Pak, Cloudera, and Snowflake. Communicate complex concepts and hypothesis to a non-technical audience through digital storytelling. Requirements Minimum of 1 year of experience required. Bachelors degree in a STEM field is required. Masters degree is preferred in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields. Proficient with one or more programming languages (Java, C++, Python, R, etc.). Proficient in Agile Development and Git Operations. Demonstrated experience applying data science methods to real-world data problems. Clearance Requirements Requires an Active Secret Clearance, while Top Secret clearance eligible for SCI is preferred. Please Note: Only those individuals selected for an interview will be contacted. No calls, inquiries, or Third-Party Vendors please. We are an equal opportunity employer. We encourage applications from candidates of all backgrounds and experiences. (The ACI Group is unable to sponsor H1B Visas). $1000 Referral Bonus - www.aci.com. Since 1988, The ACI Group, a Baltimore-based staffing firm, has been committed to hiring the industry's leading professionals, and presenting exciting career opportunities. We have access to varied types of contract, permanent and contract-to-perm positions and offer a choice of employment options including a full benefits package.",
        "url": "https://www.linkedin.com/jobs/view/3968545166",
        "summary": "A Secret Cleared Data Scientist is needed to support a SOCOM contract. The role involves data analysis, engineering, and machine learning using cloud-native platforms. Responsibilities include interpreting and analyzing data, building data pipelines, developing predictive and prescriptive models, and communicating findings to non-technical audiences.",
        "industries": [
            "Government",
            "Defense",
            "Military",
            "Intelligence",
            "Security",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Teamwork",
            "Collaboration",
            "Time Management",
            "Organization",
            "Detail-Oriented",
            "Research",
            "Data Interpretation",
            "Decision Making"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Engineering",
            "Machine Learning",
            "Cloud Computing",
            "Data Mining",
            "Natural Language Processing",
            "Robotic Process Automation",
            "Text Mining",
            "Clustering",
            "Forecasting",
            "Statistical Modeling",
            "Data Visualization",
            "Tableau",
            "Microsoft Power BI",
            "R Shiny",
            "Algorithm Development",
            "Python",
            "R",
            "NumPy",
            "SciPy",
            "Pandas",
            "Java",
            "C++",
            "Spark",
            "Hadoop",
            "Databricks",
            "IBM Cloud Pak",
            "Cloudera",
            "Snowflake",
            "Agile Development",
            "Git"
        ],
        "tech_stack": [
            "Cloud Computing",
            "Machine Learning",
            "Data Engineering",
            "Data Science",
            "Databricks",
            "IBM Cloud Pak",
            "Cloudera",
            "Snowflake",
            "Spark",
            "Hadoop",
            "Tableau",
            "Microsoft Power BI",
            "R Shiny",
            "Python",
            "R",
            "NumPy",
            "SciPy",
            "Pandas",
            "Java",
            "C++",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Java",
            "C++"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "STEM",
                "Operations Research",
                "Industrial Engineering",
                "Applied Mathematics",
                "Statistics",
                "Physics",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 115000,
            "min": 100000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3959575176,
        "company": "Entefy",
        "title": "Machine Learning Engineer (Remote Position)",
        "created_on": 1720588034.4393573,
        "description": "Entefy’s Machine Learning Engineer is a highly visible position internally and externally. This is where your deep experience and great insights intersect with an amazing opportunity to shape the future of communication and digital interaction. Skills and Experience: We’re not looking for “good.” Entefy is on a mission for best. The success of this mission depends on its team members to be creatively analytical, insatiably curious, and absolutely fearless in tackling big challenges. Requirements 5+ years of experience in Machine Learning tools and algorithms specially in unstructured data classification and clustering Demonstrable expertise in MATLAB Proficient knowledge of and experience with AI systems Demonstrable expertise in multiple programming languages such as Python, C++, Java, etc Fluency in English and, at least, 1 other language Masters or PhD in Computer Science in Machine Learning or related field preferred Proficiency in Machine Learning open source tools Proficiency in Machine Translation Proficiency in Social Text Mining Proficiency in SQL and non-SQL database Proficiency in Data Visualization tools Visit www.entefy.com and www.entefy.com/blog",
        "url": "https://www.linkedin.com/jobs/view/3959575176",
        "summary": "Entefy seeks a Machine Learning Engineer with 5+ years of experience in Machine Learning tools and algorithms, particularly in unstructured data classification and clustering. The ideal candidate will have demonstrable expertise in MATLAB, AI systems, and multiple programming languages like Python, C++, and Java. A Master's or PhD in Computer Science with a focus on Machine Learning is preferred. Proficiency in Machine Learning open source tools, Machine Translation, Social Text Mining, SQL and non-SQL databases, and Data Visualization tools is also required.",
        "industries": [
            "Software",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Analytical",
            "Curious",
            "Fearless",
            "Creative",
            "Fluent in English and at least one other language"
        ],
        "hard_skills": [
            "Machine Learning",
            "Unstructured Data Classification",
            "Clustering",
            "MATLAB",
            "AI Systems",
            "Python",
            "C++",
            "Java",
            "Machine Learning Open Source Tools",
            "Machine Translation",
            "Social Text Mining",
            "SQL",
            "Non-SQL Databases",
            "Data Visualization"
        ],
        "tech_stack": [
            "MATLAB",
            "Python",
            "C++",
            "Java",
            "SQL",
            "Non-SQL Databases",
            "Machine Learning Open Source Tools"
        ],
        "programming_languages": [
            "Python",
            "C++",
            "Java"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Computer Science",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Columbia, SC",
        "job_id": 3959828751,
        "company": "State of South Carolina",
        "title": "Workforce Data Scientist - Columbia",
        "created_on": 1720588043.2401874,
        "description": "Job Responsibilities Business is booming in South Carolina! Are you ready to be a part of developing and connecting the next generation of workers in this state? Year after year, experts pick our state as one the best in the country for doing business. Just last year, South Carolina announced more than 14,000 new jobs and $10 billion in capital investment. Entrepreneurs are flocking to cities like Greenville, Charleston, Columbia, and Rock Hill to start and grow their businesses. And our hospitality industry is primed to take off as travelers from around the world continue to discover the beauty and accessibility of South Carolina's mountains and coast. Here at the South Carolina Department of Employment and Workforce (DEW), we are laser-focused on connecting every jobseeker who comes through our doors with their next great career opportunity! Are you looking for a meaningful position at an agency brimming with optimism and camaraderie that also offers job security, affordable health insurance, great retirement benefits, and work-life balance? If so, continue reading to discover your chance to make a difference at DEW! Job Description This position reports to the Labor Market Information Department in Columbia. Incumbent will assist in development and implementation of LMI initiatives. Produce content in a collaborative environment for reports, analyses, dashboards, and other reports under supervision of the unit manager. Provide support on matters of statistical methodology and analysis. Minimum And Additional Requirements College coursework in economics and statistics and/or substantial experience in the development and presentation of quantitative analysis Preferred Qualifications Bachelor's degree in a relevant discipline. Experience with SQL, Python, statistical software (e.g. R, SAS, SPSS, Stata), geographic information systems software (e.g. ArcGIS, QGIS), and/or business intelligence tools (e.g. Tableau, Power BI). Additional Comments Supplemental questions are considered part of your official application. Please complete the State application to include all current and previous work history and education. A resume will not be accepted nor reviewed to determine if an applicant has met the qualifications for the position.",
        "url": "https://www.linkedin.com/jobs/view/3959828751",
        "summary": "This position at the South Carolina Department of Employment and Workforce (DEW) involves assisting in the development and implementation of Labor Market Information (LMI) initiatives. The role will include producing content for reports, analyses, dashboards, and other reports, providing support on statistical methodology and analysis, and collaborating with the unit manager.",
        "industries": [
            "Government",
            "Employment",
            "Labor Market Analysis"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Analytical Skills",
            "Problem Solving",
            "Data Interpretation"
        ],
        "hard_skills": [
            "Statistical Methodology",
            "Quantitative Analysis",
            "SQL",
            "Python",
            "R",
            "SAS",
            "SPSS",
            "Stata",
            "ArcGIS",
            "QGIS",
            "Tableau",
            "Power BI"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "R",
            "SAS",
            "SPSS",
            "Stata",
            "ArcGIS",
            "QGIS",
            "Tableau",
            "Power BI"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Economics",
                "Statistics",
                "Relevant Discipline"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Job Security",
            "Affordable Health Insurance",
            "Great Retirement Benefits",
            "Work-Life Balance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Phoenix, AZ",
        "job_id": 3970727215,
        "company": "TechFetch.com - On Demand Tech Workforce hiring platform",
        "title": "ML Engineer",
        "created_on": 1720588044.9764428,
        "description": "\"ALL our jobs are US based and candidates must be in the US with valid US Work Authorization. Please apply on our website directly.\" iZeal, Inc. is currently seeking a ML Engineer for our client's requirements. The salary depends on experience. Position: ML EngineerLocation: Phoenix, AZ. Job Description Experience with developing machine learning models and have the right data science skills with problem solving, research and framing into ML problems. Experience with deploying machine learning models into production environments and familiar with MLOps practices, be able to write clean, and production level code. Experience with building Python libraries and APIs (written in Python) Experience with machine learning solutions within merchandising related space domain (assortment, item selection, pricing etc) in mandatory Educational Qualification: Minimum Bachelor's in Computer Science & Engineering or Equivalent Degree.",
        "url": "https://www.linkedin.com/jobs/view/3970727215",
        "summary": "iZeal, Inc. is looking for an ML Engineer with experience in developing and deploying machine learning models, particularly in the merchandising domain (assortment, item selection, pricing). The ideal candidate will have a strong background in data science, MLOps practices, Python library and API development, and a minimum Bachelor's degree in Computer Science & Engineering or equivalent.",
        "industries": [
            "Technology",
            "Data Science",
            "Machine Learning",
            "E-commerce",
            "Retail"
        ],
        "soft_skills": [
            "Problem Solving",
            "Research",
            "Communication"
        ],
        "hard_skills": [
            "Machine Learning",
            "Data Science",
            "MLOps",
            "Python",
            "API Development",
            "Merchandising",
            "Assortment Planning",
            "Item Selection",
            "Pricing"
        ],
        "tech_stack": [
            "Python",
            "MLOps"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science & Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Urbana, MD",
        "job_id": 3967504888,
        "company": "Syntricate Technologies",
        "title": "Data Scientist",
        "created_on": 1720588050.8193197,
        "description": "Required Skills Intermediate SQL o Selects, Filter, Joins, Group byo Table creationo Value update / delete Advanced Python o Writing efficient code o Modular / reusable code (functions)o Documenting codeo Classeso Processing pipelineso Pandaso Nice To Have Text data processing Document (PDF/Excel) processing General git experience General agile experience Nice To Have Experience GPT Databricks Spark \"",
        "url": "https://www.linkedin.com/jobs/view/3967504888",
        "summary": "This position requires intermediate SQL skills with experience in selects, filter, joins, group by, table creation, and value updates/deletes. Advanced Python skills are also essential, including efficient code writing, modularity, documentation, classes, processing pipelines, and Pandas.  Experience with text data processing, document processing (PDF/Excel), Git, and agile methodologies are preferred. Additional experience with GPT, Databricks, and Spark is considered a plus.",
        "industries": [
            "Data Science",
            "Software Development",
            "Analytics"
        ],
        "soft_skills": [
            "Efficient Code Writing",
            "Modularity",
            "Documentation",
            "Problem Solving"
        ],
        "hard_skills": [
            "SQL",
            "Selects",
            "Filter",
            "Joins",
            "Group By",
            "Table Creation",
            "Value Update",
            "Value Delete",
            "Python",
            "Pandas",
            "Document Processing",
            "Text Data Processing",
            "Git",
            "Agile"
        ],
        "tech_stack": [
            "SQL",
            "Python",
            "Pandas",
            "Databricks",
            "Spark"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Huntsville, AL",
        "job_id": 3964853273,
        "company": "Bay Systems Consulting, Inc. (BSC)",
        "title": "Data Scientist",
        "created_on": 1720588053.8637314,
        "description": "Data Scientist - Bay Systems Consulting - NASA/EASTII Your Role The Data Scientist will be focused on supporting and enhancing NASA’s analytics capabilities and executing rapid and agile projects that deliver advanced analytics capabilities tuned for NASA projects. They will be comfortable with complex data sources, and technical nuances of software and hardware. Data Scientists help customize agile projects to meet specific requirements, such as building custom data models, building custom data visuals, or helping connect to novel data sources and formats. Your Responsibilities Deliver on the technical requirements and success criteria for each data science project by working with the NASA customer and with platform databases, Alteryx, Tableau, Power BI and platform Engineers to understand and meet the customer’s needs Give presentations and answer detailed questions on the technical aspects of Alteryx, Tableau, MSSQL, or Power BI – architecture, operation, and capabilities Coach NASA customer data analysts & scientists, define best practices, and promote knowledge sharing to grow the team’s ability Configure the Alteryx, Tableau, or Power BI software to connect to data sources, visualize data and tailor the user interface to best represent the results for each unique type of NASA user. Your Background 4 years minimum experience in using/developing Tableau visualization, Power BI, or Alteryx products Deep understanding of the Microsoft Windows operating system and high proficiency in Microsoft Office 365 tools Experience working in technical areas including data science, structured data, analytics, SQL Bachelor’s degree in STEM field Excellent problem-solving skills Bonus Points For Having or pursuing Master’s degree in a STEM field Experience in designing software UI and UX focused on user needs and business use cases Experience with search and search platforms Experience with Machine Learning and/or Big Data Experience with unstructured data (NLP, text processing) Experience or formal training in databases and structured data",
        "url": "https://www.linkedin.com/jobs/view/3964853273",
        "summary": "The Data Scientist will support and enhance NASA's analytics capabilities by developing agile projects using Alteryx, Tableau, Power BI and MSSQL. They will work with NASA customers, platform engineers, and data analysts to understand and meet customer needs, configure software to connect to data sources, and deliver presentations and technical guidance.",
        "industries": [
            "Aerospace",
            "Data Science",
            "Consulting"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Teamwork",
            "Collaboration",
            "Coaching"
        ],
        "hard_skills": [
            "Alteryx",
            "Tableau",
            "Power BI",
            "MSSQL",
            "SQL",
            "Data Science",
            "Analytics",
            "Structured Data",
            "Microsoft Windows",
            "Microsoft Office 365"
        ],
        "tech_stack": [
            "Alteryx",
            "Tableau",
            "Power BI",
            "MSSQL"
        ],
        "programming_languages": [
            "SQL"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "STEM"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Greenville, SC",
        "job_id": 3939012702,
        "company": "Datasoft Technologies, Inc.",
        "title": "Data Scientist",
        "created_on": 1720588061.899129,
        "description": "Hybrid (2 Days onsite) About The Job Duration: Long-term renewable contract Location: Greenville, SC Pay rate: Hourly Job ID: 4907 This is a Full Time W2 position, no subcontracting or C2C. Overview: DataSoft Technologies, Inc. is seeking a Data Scientist to join our client in Greenville, SC. The Data Scientist accelerates and supports the ongoing activities in the field of Artificial Intelligence and Computer vision for multiple use cases for quality improvement in the area of manufacturing. Deals with large volumes of data, understands and explores data critical to company business. Drives data for future company processes and products. Works with different business units to understand the business demands with respect to Artificial Intelligence and Quality Assessment. Conducts advanced analytical tasks, designs deep learning models, data mining, and computer vision to enable company to improve its products, services and processes. Responsibilities: Analyzes business critical data and recommends improvements. Works with large data sets consisting of predominantly images and conducts advanced analytics tasks. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Works with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Develops custom data models and algorithms to apply to data sets. Coordinates with different functional teams to implement models and monitor outcomes. Develops processes and tools to monitor and analyze model performance and data accuracy. Serves as internal consultant to other developers and engineers as needed, providing assistance in all phases of product life-cycle development. Advises developers and engineers on latest data analytics technologies and assists the team in process matters as related to development/support and provides the necessary on the job training and development of associates/contractors within the team. Maintains accurate, meaningful and updated technical and non-technical documentation pertaining to all aspects of area(s) of responsibility. Performs other duties as assigned by Supervisor Qualifications: Bachelor degree in computer science, mathematics/statistics or related field. Advanced degree (Masters or PhD) in computer science, mathematics/statistics or a related field (preferred). 3+ years post-university experience in advanced analytics in the field of data science, applying scientific data analytics methods preferably to automotive industry datasets. 1+ years proven experience completing projects with a set of various data sources. Process/project management experience or training/certifications (preferred). 3+ years of knowledge in using statistical computer languages (Python, SLQL, etc) to manipulate data and draw insights from large data sets 1+ years of knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Intermediate knowledge of deep learning architectures (RNN, CNN, LSTM, etc.) and frameworks (Tensor flow, Keras, etc.) 3+ years of knowledge of in one or more of the following programming languages: Python, Java, C++ 3+ years of knowledge and experience in Computer Science and in database technologies including SQL, Oracle, SQLServer, SAP HANA and NoSQL databases 3+ years of experience in statistical languages and tools in particular R 3+ years of experience in problem solving skills with an emphasis on product development About Our Company DataSoft Technologies is a highly recognized provider of professional IT Consulting services in the US. Founded in 1994, DataSoft Technologies, Inc. provides staff augmentation services for Information Technology and Automotive Services. Our team member benefits include: Paid Holidays/Paid Time Off (PTO) Medical/Dental Insurance Group Accident/Critical Illness Insurance Life Insurance 401 (K)",
        "url": "https://www.linkedin.com/jobs/view/3939012702",
        "summary": "DataSoft Technologies is seeking a Data Scientist with 3+ years of experience in advanced analytics, applying scientific data analytics methods to automotive industry datasets.  The ideal candidate will have strong skills in Python, SQL, machine learning, deep learning architectures, and database technologies. The role will involve analyzing business-critical data, developing data models and algorithms, and collaborating with various teams to implement and monitor outcomes. The Data Scientist will also act as an internal consultant to other developers and engineers, providing assistance in all phases of product life-cycle development.",
        "industries": [
            "Information Technology",
            "Automotive"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Analytical Thinking",
            "Project Management"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Mining",
            "Machine Learning",
            "Deep Learning",
            "Artificial Intelligence",
            "Computer Vision",
            "Statistical Modeling",
            "Python",
            "SQL",
            "SLQL",
            "R",
            "Java",
            "C++",
            "Tensor Flow",
            "Keras",
            "Oracle",
            "SQLServer",
            "SAP HANA",
            "NoSQL"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "SLQL",
            "R",
            "Java",
            "C++",
            "Tensor Flow",
            "Keras",
            "Oracle",
            "SQLServer",
            "SAP HANA",
            "NoSQL",
            "Machine Learning",
            "Deep Learning",
            "Artificial Intelligence",
            "Computer Vision"
        ],
        "programming_languages": [
            "Python",
            "SLQL",
            "R",
            "Java",
            "C++"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Mathematics/Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Paid Holidays",
            "Paid Time Off",
            "Medical Insurance",
            "Dental Insurance",
            "Accident Insurance",
            "Critical Illness Insurance",
            "Life Insurance",
            "401(K)"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Jersey City, NJ",
        "job_id": 3905590651,
        "company": "MHK TECH INC",
        "title": "Junior Data Scientist",
        "created_on": 1720588063.3805394,
        "description": "Job Summary Develop new models using creativity and modern technical tools to advance prediction capabilities and tackle Caesars' hardest business problems. Primary focus will be to predict sport outcomes and support the Caesars Digital business unit. YOUR FOCUS Source interesting data (query 1st party data, purchase licensed data and/or scrape public sources) Engineer features through creative variable transformation techniques Explore and apply various machine learning techniques (i.e. XGBoost library) Standardize model product development with detailed documentation for operational execution Collaborate with domain experts to identify model enhancement opportunities and stress test models Collaborate with data science peers to identify model enhancement opportunities Manipulate large datasets to merge data across multiple source systems, ensure consistency and design for new model variables Research latest machine learning technologies and keep up with industry best practices in Data Science Conduct ad hoc analyses Required Qualifications MS or PhD in quantitative field or computer science Graduation from a top-tier program or other evidence of high performance/potential preferred Demonstrated experience in statistical and/or quantitative analysis, forecasting, predictive analytics, multivariate testing, outlier analysis and/or optimization algorithms Previous experience working in a cloud environment 2+ years relevant experience preferred Python coding experience required SQL coding experience required Intermediate -> Advanced knowledge of statistical modeling techniques and machine learning algorithms Ability to build accurate, sustainable prediction models Experience building and optimizing 'big data' data pipelines, datasets, and architecture Experience working with streaming data preferred Ability to quickly understand business problems and how they may be solved Strong analytical skill, aptitude for working with data, and creativity at finding new solutions to modeling problems Must possess very strong interpersonal, communication and consensus building skills; willing to work on developing and managing key relationships across the organization. Must be able to work in a deadline-oriented environment, ensuring decisions and management communication is occurring in a timely fashion across all geographical areas of operations Ability to uphold and demonstrate the highest level of integrity in all situations and recognize standards required by a regulated business",
        "url": "https://www.linkedin.com/jobs/view/3905590651",
        "summary": "Develop new predictive models using machine learning to solve business problems related to sports outcomes, specifically for the Caesars Digital business unit.",
        "industries": [
            "Gambling",
            "Sports Betting",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Creativity",
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Skills",
            "Time Management",
            "Interpersonal Skills",
            "Integrity"
        ],
        "hard_skills": [
            "Machine Learning",
            "Statistical Modeling",
            "Predictive Analytics",
            "Multivariate Testing",
            "Outlier Analysis",
            "Optimization Algorithms",
            "Data Pipelines",
            "Data Architecture",
            "Python",
            "SQL",
            "Cloud Computing"
        ],
        "tech_stack": [
            "XGBoost",
            "Cloud"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Quantitative Field",
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas-Fort Worth Metroplex",
        "job_id": 3963037736,
        "company": "Vuesol Technologies Inc",
        "title": "Data Science Manager/Operations Scientist",
        "created_on": 1720588068.1204252,
        "description": "Role: Sr. Data Scientist/Operations Research Scientist Need 12+ years Candidates only Experience: Master's/PhD degree in a quantitative discipline (e.g., Operations Research, Engineering, Computer Science, Applied Mathematics, Statistics, etc.) Experience with at least one Object Oriented programming language (e.g., C++, Java) Depth of knowledge in at least one OR skill area (e.g., optimization, simulation, statistics) Practical experience with data extraction, cleaning, and analysis Demonstrated aptitude for independent learning, logical analysis, problem identification, and problem solving Experience 2+ years of experience in a technical professional environment 2+ years of experience developing and implementing large scale optimization models using MIP and heuristics 2+ years of experience in Java Experience in using cloud platforms and parallel processing to scale model development/ deployment",
        "url": "https://www.linkedin.com/jobs/view/3963037736",
        "summary": "Senior Data Scientist/Operations Research Scientist role requiring 12+ years of experience.  Candidates must have a Master's or PhD in a quantitative field, proficiency in at least one object-oriented programming language, expertise in optimization, simulation, or statistics, experience with data handling, and a strong analytical mindset.  The role involves building and deploying large-scale optimization models using MIP and heuristics in a cloud environment.",
        "industries": [
            "Data Science",
            "Operations Research",
            "Analytics",
            "Software Development"
        ],
        "soft_skills": [
            "Independent Learning",
            "Logical Analysis",
            "Problem Identification",
            "Problem Solving"
        ],
        "hard_skills": [
            "Optimization",
            "Simulation",
            "Statistics",
            "Data Extraction",
            "Data Cleaning",
            "Data Analysis",
            "MIP",
            "Heuristics",
            "Cloud Platforms",
            "Parallel Processing"
        ],
        "tech_stack": [
            "Java",
            "C++"
        ],
        "programming_languages": [
            "Java",
            "C++"
        ],
        "experience": 12,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Operations Research",
                "Engineering",
                "Computer Science",
                "Applied Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3970278983,
        "company": "Samsara",
        "title": "Machine Learning Scientist",
        "created_on": 1720588071.423276,
        "description": "Who We Are Samsara (NYSE: IOT) is the pioneer of the Connected Operations™ Cloud, which is a platform that enables organizations that depend on physical operations to harness Internet of Things (IoT) data to develop actionable insights and improve their operations. At Samsara, we are helping improve the safety, efficiency and sustainability of the physical operations that power our global economy. Representing more than 40% of global GDP, these industries are the infrastructure of our planet, including agriculture, construction, field services, transportation, and manufacturing — and we are excited to help digitally transform their operations at scale. Working at Samsara means you’ll help define the future of physical operations and be on a team that’s shaping an exciting array of product solutions, including Video-Based Safety, Vehicle Telematics, Apps and Driver Workflows, Equipment Monitoring, and Site Visibility. As part of a recently public company, you’ll have the autonomy and support to make an impact as we build for the long term. About the role: The Samsara ML Experience team builds end-to-end ML applications to power various product pillars at Samsara. As an Applied Scientist, you will be responsible for developing ML solutions to enhance the safety, efficiency and sustainability of physical operations. You will work closely with engineering teams across ML, full-stack, and firmware, as well as cross-functional partners to deliver core infrastructure, services, and optimizations. This role is open to candidates residing in the US except the San Francisco Bay Area (125 mi. radius from 1 De Haro St, San Francisco) and NYC Metro Area (50 mi. radius from 131 W 55th St, New York). You should apply if: You want to impact the industries that run our world: Your efforts will result in real-world impact—helping to keep the lights on, get food into grocery stores, reduce emissions, and most importantly, ensure workers return home safely. You are the architect of your own career: If you put in the work, this role won’t be your last at Samsara. We set up our employees for success and have built a culture that encourages rapid career development, countless opportunities to experiment and master your craft in a hyper growth environment. You’re energized by our opportunity: The vision we have to digitize large sectors of the global economy requires your full focus and best efforts to bring forth creative, ambitious ideas for our customers. You want to be with the best: At Samsara, we win together, celebrate together and support each other. You will be surrounded by a high-calibre team that will encourage you to do your best. In this role, you will: Architect, build, and improve solutions for hybrid cloud-edge ML. Drive zero-to-one new ML initiatives in collaboration with cross-functional partners. Design, develop, and optimize services and system components for training, deploying, serving, and monitoring models. Stay connected to industry and academic research, adopting novel technologies that suit Samsara’s needs. Champion, role model, and embed Samsara’s cultural principles (Focus on Customer Success, Build for the Long Term, Adopt a Growth Mindset, Be Inclusive, Win as a Team) as we scale globally and across new offices. Minimum requirements for the role: MS or PhD in Computer Science or a related technical degree. 2+ years of experience as an Applied Scientist, Machine Learning Engineer, or similar role. Strong proficiency in one or more common languages (e.g., Python, C++, Golang, Java). Proficiency with common ML tools (e.g., Spark, TensorFlow, PyTorch). Experience building and deploying large-scale machine learning systems with feedback loops for continuous improvement. Comfortable with full-stack/backend development. An ideal candidate also has: Experience building, deploying, and optimizing ML models on the edge. Experience building end-to-end ML applications from scratch. Experience working closely with Product teams and Customers to design and iterate on ML models. Experience optimizing distributed model training with GPUs. Samsara’s Compensation Philosophy : Samsara’s compensation program is designed to deliver Total Direct Compensation (based on role, level, and geography) that is at or above market. We do this through our base salary + bonus/variable + restricted stock unit awards (RSUs) for eligible roles. For eligible roles, a new hire RSU award may be awarded at the time of hire, and additional RSU refresh grants may be awarded annually. We pay for performance, and top performers in eligible roles may receive above-market equity refresh awards which allow employees to achieve higher market positioning. The range of annual base salary for full-time employees for this position is below. Please note that base pay offered may vary depending on factors including your city of residence, job-related knowledge, skills, and experience. $109,480—$184,000 USD At Samsara, we welcome everyone regardless of their background. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, gender, gender identity, sexual orientation, protected veteran status, disability, age, and other characteristics protected by law. We depend on the unique approaches of our team members to help us solve complex problems. We are committed to increasing diversity across our team and ensuring that Samsara is a place where people from all backgrounds can make an impact. Benefits Full time employees receive a competitive total compensation package along with employee-led remote and flexible working, health benefits, Samsara for Good charity fund, and much, much more. Take a look at our Benefits site to learn more. Accommodations Samsara is an inclusive work environment, and we are committed to ensuring equal opportunity in employment for qualified persons with disabilities. Please email accessibleinterviewing@samsara.com or click here if you require any reasonable accommodations throughout the recruiting process. Flexible Working At Samsara, we embrace a flexible working model that caters to the diverse needs of our teams. Our offices are open for those who prefer to work in-person and we also support remote work where it aligns with our operational requirements. For certain positions, being close to one of our offices or within a specific geographic area is important to facilitate collaboration, access to resources, or alignment with our service regions. In these cases, the job description will clearly indicate any working location requirements. Our goal is to ensure that all members of our team can contribute effectively, whether they are working on-site, in a hybrid model, or fully remotely. All offers of employment are contingent upon an individual’s ability to secure and maintain the legal right to work at the company and in the specified work location, if applicable. Fraudulent Employment Offers Samsara is aware of scams involving fake job interviews and offers. Please know we do not charge fees to applicants at any stage of the hiring process. Official communication about your application will only come from emails ending in ‘@samsara.com’ or ‘@us-greenhouse-mail.io’. For more information regarding fraudulent employment offers, please visit our blog post here.",
        "url": "https://www.linkedin.com/jobs/view/3970278983",
        "summary": "Samsara, a pioneer in the Connected Operations™ Cloud, is seeking an Applied Scientist to develop ML solutions for enhancing safety, efficiency, and sustainability in physical operations. This role involves architecting hybrid cloud-edge ML solutions, driving new ML initiatives, designing and optimizing ML services, and staying current with industry and academic research. Ideal candidates have experience in building and deploying ML models on the edge, end-to-end ML application development, and collaborating with product teams and customers. The position offers a competitive salary range of $109,480 - $184,000 USD and a comprehensive benefits package.",
        "industries": [
            "Agriculture",
            "Construction",
            "Field Services",
            "Transportation",
            "Manufacturing"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Critical thinking",
            "Adaptability",
            "Growth mindset",
            "Customer focus",
            "Teamwork"
        ],
        "hard_skills": [
            "Machine Learning",
            "Python",
            "C++",
            "Golang",
            "Java",
            "Spark",
            "TensorFlow",
            "PyTorch",
            "Cloud computing",
            "Edge computing",
            "Distributed systems",
            "Model optimization",
            "GPU computing",
            "Full-stack development",
            "Backend development",
            "Data analysis"
        ],
        "tech_stack": [
            "Spark",
            "TensorFlow",
            "PyTorch",
            "Cloud computing",
            "Edge computing",
            "GPU computing"
        ],
        "programming_languages": [
            "Python",
            "C++",
            "Golang",
            "Java"
        ],
        "experience": 2,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Computer Science",
                "Related technical degrees"
            ]
        },
        "salary": {
            "max": 184000,
            "min": 109480
        },
        "benefits": [
            "Competitive total compensation",
            "Remote and flexible working",
            "Health benefits",
            "Samsara for Good charity fund"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3969896602,
        "company": "HubSpot",
        "title": "Machine Learning Engineer, AI Innovations Lab",
        "created_on": 1720588073.0861778,
        "description": "HubSpot Overview HubSpot is an all-in-one marketing, sales, and service software platform that helps businesses grow and succeed. With a user-friendly interface and powerful tools, HubSpot enables businesses to attract, engage, and delight customers, ultimately driving growth and increasing revenue. From marketing automation to CRM, HubSpot offers a comprehensive solution that empowers businesses to succeed in the digital age. Job Summary The Innovation Lab team is a product incubator within HubSpot. It is a multi-stack team consisting of BE, FE, Machine Learning Engineers, UX Designers, and Product Managers building like startups do. The Innovation Lab team sits within the newly formed AI Innovation Group and is tasked with employing state-of-the-art AI and ML technologies to rapidly develop and test prototypes. We build new products and inspire teams to enhance our customers' marketing, customer engagement, sales acquisition, and operations efforts. See an overview of the larger AI effort at HubSpot. Responsibilities Design and develop machine learning models for a range of ML tasks using techniques such as deep learning and natural language processing Implement and deploy machine learning algorithms in a scalable and efficient manner, working closely with software engineer Collaborate with product managers to define and refine requirements and use cases for new ML technologies. Analyze and preprocess a wide variety of data sources to extract relevant features and insights Conduct experiments and evaluations of machine learning models, using statistical methods and visualization tools to assess performance and identify areas for improvement Keep up to date with the latest research and trends in conversation intelligence, and contribute to the development of new algorithms and techniques Participate in code reviews, testing, and documentation activities, ensuring high quality and maintainability of the codebase Experience or interest in mentoring other team members and proactively sharing knowledge Requirements A degree in Computer Science, Engineering, or related fields, with a focus on machine learning, natural language processing, or speech analysis 3+ years of experience in developing and deploying machine learning models and algorithms, preferably in speech or text analysis domains Proficiency in Python programming and machine learning libraries such as TensorFlow, PyTorch, or Keras Familiarity with natural language processing and text analysis tools such as NLTK, huggingface and the use of other open-source text embedding modules Experience working with LLMs and/or search relevancy Familiarity with a variety of feature engineering techniques for both multi-modal analysis would be great Experience mentoring other team members and helping to define best practices for the group Excellent communication and collaboration skills, with the ability to work effectively in a fast-paced, interdisciplinary team environment. If you are passionate about leveraging machine learning to transform the way businesses interact with their customers in a collaborative work environment, come join us in HubSpot AI Group! Cash compensation range: 157600-236400 USD Annually This resource will help guide how we recommend thinking about the range you see. Learn more about HubSpot’s compensation philosophy. The cash compensation above includes base salary, on-target commission for employees in eligible roles, and annual bonus targets under HubSpot’s bonus plan for eligible roles. In addition to cash compensation, some roles are eligible to participate in HubSpot’s equity plan to receive restricted stock units (RSUs). Some roles may also be eligible for overtime pay. Individual compensation packages are based on a few different factors unique to each candidate, including their skills, experience, qualifications and other job-related reasons. We know that benefits are also an important piece of your total compensation package. To learn more about what’s included in total compensation, check out some of the benefits and perks HubSpot offers to help employees grow better. At HubSpot, fair compensation practices isn’t just about checking off the box for legal compliance. It’s about living out our value of transparency with our employees, candidates, and community. We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates, so please don’t hesitate to apply — we’d love to hear from you. If you need accommodations or assistance due to a disability, please reach out to us using this form. This information will be treated as confidential and used only for the purpose of determining an appropriate accommodation for the interview process. Germany Applicants: (m/f/d) - link to HubSpot's Career Diversity page here. About HubSpot HubSpot (NYSE: HUBS) is a leading customer relationship management (CRM) platform that provides software and support to help businesses grow better. We build marketing, sales, service, and website management products that start free and scale to meet our customers’ needs at any stage of growth. We’re also building a company culture that empowers people to do their best work. If that sounds like something you’d like to be part of, we’d love to hear from you. You can find out more about our company culture in the HubSpot Culture Code, which has more than 5M views, and learn about our commitment to creating a diverse and inclusive workplace, too. Thanks to the work of every employee globally, HubSpot was named the #2 Best Place to Work on Glassdoor in 2022, and has been recognized for award-winning culture by Great Place to Work, Comparably, Fortune, Entrepreneur, Inc., and more. Headquartered in Cambridge, Massachusetts, HubSpot was founded in 2006. Today, thousands of employees work across the globe in HubSpot offices and remotely. Visit our careers website to learn more about culture and opportunities at HubSpot. By submitting your application, you agree that HubSpot may collect your personal data for recruiting, global organization planning, and related purposes. HubSpot's Privacy Notice explains what personal information we may process, where we may process your personal information, our purposes for processing your personal information, and the rights you can exercise over HubSpot’s use of your personal information.",
        "url": "https://www.linkedin.com/jobs/view/3969896602",
        "summary": "HubSpot's Innovation Lab seeks a Machine Learning Engineer to develop and deploy AI/ML models for marketing, customer engagement, and sales efforts. The role involves designing models, collaborating with product managers, analyzing data, conducting experiments, and staying abreast of the latest research in conversation intelligence.",
        "industries": [
            "Software",
            "Technology",
            "Marketing",
            "Customer Relationship Management (CRM)",
            "Artificial Intelligence (AI)",
            "Machine Learning (ML)",
            "Sales",
            "Customer Engagement"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Teamwork",
            "Analytical",
            "Critical Thinking",
            "Mentoring",
            "Time Management"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing",
            "Speech Analysis",
            "Python",
            "TensorFlow",
            "PyTorch",
            "Keras",
            "NLTK",
            "Huggingface",
            "Text Embedding",
            "LLMs",
            "Search Relevancy",
            "Feature Engineering",
            "Multi-modal Analysis"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "Keras",
            "NLTK",
            "Huggingface"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Engineering",
                "Machine Learning",
                "Natural Language Processing",
                "Speech Analysis"
            ]
        },
        "salary": {
            "max": 236400,
            "min": 157600
        },
        "benefits": [
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Life Insurance",
            "Disability Insurance",
            "Paid Time Off",
            "Paid Parental Leave",
            "Employee Stock Purchase Plan",
            "401(k) Matching",
            "Tuition Reimbursement",
            "Professional Development",
            "Employee Assistance Program",
            "Wellness Programs",
            "Commuter Benefits"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Francisco Bay Area",
        "job_id": 3966697124,
        "company": "Barrington James",
        "title": "Senior Data Scientist",
        "created_on": 1720588077.5018911,
        "description": "Barrington James is currently seeking a Senior Data Scientist for one of our clients based in San Francisco. They are a leading company in the healthcare sector, leveraging AI and deep learning to revolutionize diagnostic tools. Their technology assists Radiologists in identifying diseases and medical issues with increased accuracy and at earlier stages. They are committed to addressing significant social impact opportunities in healthcare, and our technology is deployed globally. As a Senior Data Scientist to support model development for our core products and conduct applied R&D. The ideal candidate will have previous experience with production modeling, familiarity with various medical data modalities, and understanding of clinical applications. This role is potentially open to remote working, however, relocation assistance is available. Responsibilities Develop, validate, and optimize models that process medical images and electronic healthcare records (EHR) to power a range of clinical applications Design and build deployable software Collaborate with Data Science team, Engineering teams, Product Managers, Clinical teams, and Regulatory teams Write high-quality production code Requirements Graduate degree or equivalent in a STEM field, such as Applied Mathematics, Computer Science, Physics or other related degree or experience 5+ years of industry experience with production modeling Proficient in both classical and generative AI techniques, as well as machine learning, statistics and data analysis A strong background in computer vision (CV), natural language processing (NLP), and information processing Experience with programming in Python and working with frameworks such as PyTorch, NumPy, SciPy, Scikit-learn, Pandas, spaCy, OpenCV, Pydicom Understand and practice all requirements of EN ISO 13485:2016, ISO 13485:2016 MDSAP including 21 CFR 820, QMS Manual, Process Flows and Work Instructions. Experience with EN ISO 62304:2006 a plus. Ability to support Internal and External audits. Interested? If so, please apply with your CV, and we will be in touch to arrange a call.",
        "url": "https://www.linkedin.com/jobs/view/3966697124",
        "summary": "Barrington James is seeking a Senior Data Scientist for a healthcare company in San Francisco. The role involves developing, validating, and optimizing AI/deep learning models for medical image and EHR processing to power clinical applications.  The ideal candidate has 5+ years of industry experience with production modeling, proficiency in classical and generative AI techniques, CV, NLP, and information processing, and experience with Python, PyTorch, NumPy, SciPy, Scikit-learn, Pandas, spaCy, OpenCV, Pydicom. Familiarity with EN ISO 13485:2016, ISO 13485:2016 MDSAP, 21 CFR 820, QMS Manual, and EN ISO 62304:2006 is a plus. Relocation assistance is available, and the role may be remote.",
        "industries": [
            "Healthcare",
            "Technology",
            "Artificial Intelligence",
            "Medical Imaging",
            "Software"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Critical Thinking",
            "Analytical Thinking",
            "Teamwork",
            "Time Management"
        ],
        "hard_skills": [
            "AI",
            "Deep Learning",
            "Machine Learning",
            "Statistics",
            "Data Analysis",
            "Computer Vision",
            "Natural Language Processing",
            "Information Processing",
            "Python",
            "PyTorch",
            "NumPy",
            "SciPy",
            "Scikit-learn",
            "Pandas",
            "spaCy",
            "OpenCV",
            "Pydicom",
            "EN ISO 13485:2016",
            "ISO 13485:2016 MDSAP",
            "21 CFR 820",
            "QMS Manual",
            "EN ISO 62304:2006"
        ],
        "tech_stack": [
            "AI",
            "Deep Learning",
            "Machine Learning",
            "Computer Vision",
            "Natural Language Processing",
            "PyTorch",
            "NumPy",
            "SciPy",
            "Scikit-learn",
            "Pandas",
            "spaCy",
            "OpenCV",
            "Pydicom"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Graduate",
            "fields": [
                "Applied Mathematics",
                "Computer Science",
                "Physics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Relocation Assistance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967185872,
        "company": "GitLab",
        "title": "Machine Learning Engineer, AI Powered: Custom Models",
        "created_on": 1720588086.979745,
        "description": "The GitLab DevSecOps platform empowers 100,000+ organizations to deliver software faster and more efficiently. We are one of the world’s largest all-remote companies with 2,000+ team members and values that foster a culture where people embrace the belief that everyone can contribute. Learn more about Life at GitLab . An overview of this role The Custom Models team is responsible for allowing customers to deploy and customize the outputs of Generative AI models and fine-tune models for use within the GitLab product and beyond. They will work collaboratively with numerous teams to ensure a complete lifecycle of assessing models, fine-tuning models, evaluating models, storing models, deploying models, implementing models as underlying engines behind AI agents, and protecting these models through means of various hosting techniques. Why us? This isn't just a job; it's your chance to shape the future of AI at GitLab. Your expertise in backend development will be critical to your success. Ready to dive into the future of AI at GitLab? Apply now! We're excited to meet potential candidates like you and welcome a new star to our team. Let's shape the future together! What You’ll Do Develop improvements to models to generate new content using machine learning models in a secure, well-tested, and performant way. Work with highly complex data for feature development using machine learning models. Collaborate with product managers, engineers, and other stakeholders as a machine learning specialist. Advocate for improvements to product quality, security, and performance. Solve technical problems of moderate scope and complexity. Craft code that meets our internal standards for style, maintainability, and best practices for a high-scale machine-learning environment. Maintain and advocate for these standards through code review. Confidently ship small features and improvements with minimal guidance and support from other team members. Collaborate with the team on larger projects. Participate as a reviewer or project maintainer in one or more engineering projects. Participate in Tier 2 or Tier 3 weekday, weekend, and occasional night on-call rotations to assist with troubleshooting product operations, security operations, and urgent engineering issues. What You’ll Bring A relevant Master’s degree and 2 or more years of experience in ML or PhD degree with a focus on Machine Learning or Data Science. Professional experience with Python Experience with performance and optimization problems and a demonstrated ability to both diagnose and prevent these problems Comfort working in a highly agile, intensely iterative software development process Demonstrated ability to onboard and integrate with an organization long-term Positive and solution-oriented mindset Effective communication skills: Regularly achieve consensus with peers, and clear status updates An inclination towards communication, inclusion, and visibility Experience owning a project from concept to production, including proposal, discussion, and execution. Self-motivated and self-managing, with strong organizational skills. Demonstrated ability to work closely with other parts of the organization Share our Values , and work in accordance with those values Ability to thrive in a fully remote organization Two of more of Professional experience with prompt engineering and Retrieval Augmented Generation (RAG) Experience building, training, and implementing deep learning models. Experience with a deep learning framework such as PyTorch or TensorFlow Professional experience fine-tuning LLMs Design, construction or operation of MLOps infrastructure Bonus Qualifications Have contributed a Merge Request to GitLab Have contributed to ML open source projects About The Team The Custom Models team is a new team formed with internal GitLab team members from around the globe. Engineers are primarily located across various European countries, with some distributions in Australia, New Zealand, America, and Canada. This team is growing, and there are currently 7 positions available. The team works closely with these other teams within the organization: AI Framework MLOps Model Validation Duo Chat How GitLab will support you Benefits to support your health, finances, and well-being All remote , asynchronous work environment Flexible Paid Time Off Team Member Resource Groups Equity Compensation & Employee Stock Purchase Plan Growth and development budget Parental leave Home office support Please note that we welcome interest from candidates with varying levels of experience; many successful candidates do not meet every single requirement. Additionally, studies have shown that people from underrepresented groups are less likely to apply to a job unless they meet every single qualification. If you're excited about this role, please apply and allow our recruiters to assess your application. The base salary range for this role’s listed level is currently for residents of listed locations only. Grade level and salary ranges are determined through interviews and a review of education, experience, knowledge, skills, abilities of the applicant, equity with other team members, and alignment with market data. See more information on our benefits and equity . Sales roles are also eligible for incentive pay targeted at up to 100% of the offered base salary. California/Colorado/Hawaii/New Jersey/New York/Washington/DC pay range $112,000 — $240,000 USD Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process. Privacy Policy: Please review our Recruitment Privacy Policy. Your privacy is important to us. GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab’s policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab’s EEO Policy and EEO is the Law . If you have a disability or special need that requires accommodation , please let us know during the recruiting process .",
        "url": "https://www.linkedin.com/jobs/view/3967185872",
        "summary": "GitLab is seeking a Machine Learning Engineer to join their Custom Models team. This team is responsible for allowing customers to deploy and customize Generative AI models and fine-tune models for use within the GitLab product and beyond. The ideal candidate will have a relevant Master's degree or PhD in Machine Learning or Data Science with 2+ years of experience in ML. Responsibilities include developing improvements to models to generate new content, working with highly complex data for feature development, collaborating with product managers and engineers, advocating for improvements to product quality, security, and performance, solving technical problems of moderate scope and complexity, and confidently shipping small features and improvements. The position requires experience with Python, deep learning frameworks such as PyTorch or TensorFlow, and prompt engineering. The team is located globally with various team members across European countries, Australia, New Zealand, America, and Canada. ",
        "industries": [
            "Software Development",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Organization",
            "Self-Motivation",
            "Teamwork",
            "Leadership",
            "Advocacy",
            "Critical Thinking",
            "Analytical Skills",
            "Solution-Oriented"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "Deep Learning",
            "PyTorch",
            "TensorFlow",
            "Prompt Engineering",
            "Retrieval Augmented Generation (RAG)",
            "Model Fine-Tuning",
            "MLOps"
        ],
        "tech_stack": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "MLOps"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Machine Learning",
                "Data Science"
            ]
        },
        "salary": {
            "max": 240000,
            "min": 112000
        },
        "benefits": [
            "Health Insurance",
            "Flexible Paid Time Off",
            "Equity Compensation",
            "Employee Stock Purchase Plan",
            "Growth and Development Budget",
            "Parental Leave",
            "Home Office Support"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Kennesaw, GA",
        "job_id": 3959123247,
        "company": "Copeland",
        "title": "Data Scientist",
        "created_on": 1720588088.7710595,
        "description": "About Us We are a global climate technologies company engineered for sustainability. We create sustainable and efficient residential, commercial and industrial spaces through HVACR technologies. We protect temperature-sensitive goods throughout the cold chain. And we bring comfort to people globally. Best-in-class engineering, design and manufacturing combined with category-leading brands in compression, controls, software and monitoring solutions result in next-generation climate technology that is built for the needs of the world ahead. Whether you are a professional looking for a career change, an undergraduate student exploring your first opportunity, or recent graduate with an advanced degree, we have opportunities that will allow you to innovate, be challenged and make an impact. Join our team and start your journey today! If you are a Data Scientist professional looking for an opportunity to grow, Copeland has an opening for you! Based in either our Sidney, Ohio or St. Louis, Missouri location, you will assist with developing ground-breaking insights dedicated to improving the quality of people's lives around the world, by protecting the food cold-chain while helping us to be better stewards of the world's energy reserves. You will work Copeland's Data Scientists and Engineers around the world as a motivator for change by developing innovative product forecasting, data-driven product, and efficiency improvement services for internal and external customers. As a Data Scientist, You Will Implement solutions to solve sophisticated business and engineering problems using machine learning, econometrics and operations research techniques Build customer-focused analytics with data scientist peers Discover opportunities to improve systems, processes and enterprises through data analytics and automation Generate reports for decision-making using data visualization tools Establish and maintain collaboration with other internal teams to apply cloud and edge-computing capabilities for production and proprietary algorithms Develop in-depth business and domain understanding Translate analytics techniques published in peer-review journals and conference proceedings into practical solutions for challenges at hand Required Education, Experience, & Skills Bachelor's or Master's degree in Econometrics, Operations Research, Engineering or Quantitative fields Must have strong interest in applying, deploying and scaling data driven solutions across business domains (e.g. Finance, Sales and Marketing), Supply Chain and customer-facing projects Must have experience in data wrangling and modeling in Python or similar language and collaborate using Git Must be proficient in verifying raw data integrity through automation and classic extract-transform-load (ETL) techniques Proficient in robust statistics, hypothesis testing, experimental design Have knowledge in forecasting and/or time series analysis (e.g. ARIMAX and deep learning techniques) Experience with modelling techniques for sophisticated systems and machine learning Excellent verbal and written communication skills Ability to work on virtual teams with members around the globe Ability to translate ambiguous business problem into actionable analytics and data science tasks Preferred Education, Experience, & Skills Master's or Doctorate's degree in Econometrics, Operations Research, Engineering or Quantitative field Proven knowledge in applying forecasting and/or analytics to tackle practical problems through peer-review journal publications, conference proceedings or graduate thesis Demonstrated experience in proposing an original and innovative initiative, executing the idea and presenting the findings with other domain expert(s) Proven experience in managing project(s) or research and acted as a change agent Experience in game theory, data envelopment analysis, mathematical programming, scheduling, queuing theory Experience with Docker, Azure DevOps, Agile sprints Familiar with basic SQL commands (e.g. windowing function, group-by aggregate, pivot) Ability and interest in translating highly complex and abstract concepts to internal and external stakeholders with minimum analytics knowledge Flexible Work Schedule – Remote Work Option and Core Hours This role has the flexibility of a remote work option up to three days a week and a core hour schedule. You can choose to flex your start and stop times given you are working during the core hours of 9:00am - 3:00pm. Our teams work together to ensure our chosen work schedules enable our creativity and productivity as we serve the needs of our customers. Our Commitment to Our People Across the globe, we are united by a singular Purpose: Sustainability is no small ambition. That’s why everything we do is geared toward a sustainable future—for our generation and all those to come. Through groundbreaking innovations, HVACR technology and cold chain solutions, we are reducing carbon emissions and improving energy efficiency in spaces of all sizes, from residential to commercial to industrial. Our employees are our greatest strength. We believe that our culture of passion, openness, and collaboration empowers us to work toward the same goal - to make the world a better place. We invest in the end-to-end development of our people, beginning at onboarding and through senior leadership, so they can thrive personally and professionally. Flexible and competitive benefits plans offer the right options to meet your individual/family needs: medical insurance plans, dental and vision coverage, 401(k), tuition reimbursement, and more. We provide employees with flexible time off plans, including paid parental leave (maternal and paternal), vacation and holiday leave. Together, we have the opportunity – and the power – to continue to revolutionize the technology behind air conditioning, heating and refrigeration, and cultivate a better future. Learn more about us and how you can join our team! Our Commitment to Our People Across the globe, we are united by a singular Purpose: Sustainability is no small ambition. That’s why everything we do is geared toward a sustainable future—for our generation and all those to come. Through groundbreaking innovations, HVACR technology and cold chain solutions, we are reducing carbon emissions and improving energy efficiency in spaces of all sizes, from residential to commercial to industrial. Our employees are our greatest strength. We believe that our culture of passion, openness, and collaboration empowers us to work toward the same goal - to make the world a better place. We invest in the end-to-end development of our people, beginning at onboarding and through senior leadership, so they can thrive personally and professionally. Flexible and competitive benefits plans offer the right options to meet your individual/family needs: medical insurance plans, dental and vision coverage, 401(k) and more. We provide employees with flexible time off plans, including paid parental leave (maternal and paternal), vacation and holiday leave. Together, we have the opportunity – and the power – to continue to revolutionize the technology behind air conditioning, heating and refrigeration, and cultivate a better future. Learn more about us and how you can join our team! Our Commitment to Diversity, Equity & Inclusion At Copeland, we believe having a diverse, equitable and inclusive environment is critical to our success. We are committed to creating a culture where every employee feels welcomed, heard, respected, and valued for their experiences, ideas, perspectives and expertise. Ultimately, our diverse and inclusive culture is the key to driving industry-leading innovation, better serving our customers and making a positive impact in the communities where we live. Work Authorization Copeland will only employ those who are legally authorized to work in the United States. This is not a position for which sponsorship will be provided. Individuals with temporary visas such as E, F-1 with OPT or CPT, H-1, H-2, L-1, B, J or TN, or who need sponsorship for work authorization now or in the future, are not eligible for hire. Equal Opportunity Employer Copeland is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, race, color, religion, national origin, age, marital status, political affiliation, sexual orientation, gender identity, genetic information, disability or protected veteran status. We are committed to providing a workplace free of any discrimination or harassment. If you have a disability and are having difficulty accessing or using this website to apply for a position, please contact: copeland.careers@copeland.com",
        "url": "https://www.linkedin.com/jobs/view/3959123247",
        "summary": "Copeland, a global climate technologies company, is seeking a Data Scientist to join their team in either Sidney, Ohio or St. Louis, Missouri. The role will involve developing data-driven solutions to improve the quality of life by protecting the food cold-chain and optimizing energy usage. The Data Scientist will leverage machine learning, econometrics, and operations research to analyze data, identify opportunities for improvement, and generate reports for decision-making. The position requires a Bachelor's or Master's degree in a quantitative field, strong Python skills, and experience in data wrangling and modeling.",
        "industries": [
            "Climate Technology",
            "HVACR",
            "Cold Chain",
            "Sustainability",
            "Energy Efficiency",
            "Data Science",
            "Engineering",
            "Operations Research"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Analytical Thinking",
            "Decision-Making",
            "Initiative",
            "Project Management",
            "Time Management",
            "Adaptability",
            "Detail-Oriented",
            "Teamwork",
            "Creativity",
            "Motivation"
        ],
        "hard_skills": [
            "Machine Learning",
            "Econometrics",
            "Operations Research",
            "Python",
            "Data Wrangling",
            "Data Modeling",
            "Git",
            "Data Integrity",
            "ETL",
            "Statistics",
            "Hypothesis Testing",
            "Experimental Design",
            "Forecasting",
            "Time Series Analysis",
            "ARIMAX",
            "Deep Learning",
            "Modeling",
            "SQL",
            "Docker",
            "Azure DevOps",
            "Agile"
        ],
        "tech_stack": [
            "Python",
            "Git",
            "SQL",
            "Docker",
            "Azure DevOps",
            "Machine Learning",
            "Deep Learning",
            "ARIMAX"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Econometrics",
                "Operations Research",
                "Engineering",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Insurance",
            "Dental",
            "Vision",
            "401(k)",
            "Tuition Reimbursement",
            "Flexible Time Off",
            "Paid Parental Leave",
            "Vacation",
            "Holiday Leave"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Sunnyvale, CA",
        "job_id": 3243265084,
        "company": "AlphaVentus",
        "title": "AI Data Scientist",
        "created_on": 1720588091.704032,
        "description": "Job Title: Data Scientist with AI Experience Location: Nashville, TN (Relocation Required) Job Description: We are seeking a highly skilled and motivated Data Scientist with experience in Artificial Intelligence (AI) to join our dynamic team in Nashville, TN. As a Data Scientist, you will be responsible for leveraging advanced data analytics, machine learning, and AI techniques to solve complex business problems and drive data-driven decision-making within the organization. The ideal candidate will have a strong background in data science, a deep understanding of AI technologies, and the ability to communicate complex concepts to both technical and non-technical stakeholders. Key Responsibilities: Data Analysis and Modeling: Collect, clean, and preprocess large datasets from various sources. Develop and implement statistical models and machine learning algorithms to analyze and interpret data. Conduct exploratory data analysis to identify trends, patterns, and insights. AI and Machine Learning: Design, build, and deploy AI and machine learning models to solve business problems. Optimize and fine-tune models for performance and accuracy. Stay up-to-date with the latest advancements in AI and machine learning technologies. Data Visualization and Reporting: Create compelling data visualizations and dashboards to present insights and findings. Communicate results and recommendations to stakeholders through clear and concise reports. Collaborate with cross-functional teams to integrate data-driven insights into business strategies. Research and Innovation: Conduct research on emerging AI technologies and their potential applications. Experiment with new tools and techniques to improve data analysis and modeling processes. Contribute to the development of best practices and standards for data science and AI projects. Qualifications: Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, or a related field. Proven experience as a Data Scientist with a focus on AI and machine learning. Proficiency in programming languages such as Python, R, or similar. Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Strong analytical and problem-solving skills with the ability to interpret complex data. Excellent communication and presentation skills. Ability to work collaboratively in a team environment and manage multiple projects simultaneously. Willingness to relocate to Nashville, TN. Preferred Qualifications: Ph.D. in Data Science, AI, Machine Learning, or a related field. Experience with big data technologies (e.g., Hadoop, Spark). Knowledge of cloud platforms and services (e.g., AWS, Google Cloud, Azure). Experience with natural language processing (NLP) and computer vision. Familiarity with data engineering and ETL processes. What We Offer: Competitive salary and benefits package. Opportunities for professional development and career advancement. A collaborative and innovative work environment. Relocation assistance for the right candidate. If you are passionate about data science and AI, and you are ready to take on new challenges in a vibrant city like Nashville, we encourage you to apply. Join our team and be a part of shaping the future of our organization through data-driven innovation.",
        "url": "https://www.linkedin.com/jobs/view/3243265084",
        "summary": "This job posting seeks a Data Scientist with expertise in AI to join a team in Nashville, TN. The role involves using data analytics, machine learning, and AI techniques to solve business problems and inform decision-making. The ideal candidate possesses a strong data science background, deep AI understanding, and communication skills to convey complex concepts to both technical and non-technical audiences.",
        "industries": [
            "Technology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem-solving",
            "Analytical",
            "Collaboration",
            "Presentation",
            "Management"
        ],
        "hard_skills": [
            "Data Analysis",
            "Machine Learning",
            "AI",
            "Data Preprocessing",
            "Statistical Modeling",
            "Exploratory Data Analysis",
            "Python",
            "R",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Data Visualization",
            "Dashboards",
            "Reporting",
            "Research",
            "Hadoop",
            "Spark",
            "AWS",
            "Google Cloud",
            "Azure",
            "NLP",
            "Computer Vision",
            "ETL"
        ],
        "tech_stack": [
            "Python",
            "R",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Hadoop",
            "Spark",
            "AWS",
            "Google Cloud",
            "Azure"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor’s",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "Benefits package",
            "Professional development",
            "Career advancement",
            "Collaborative work environment",
            "Relocation assistance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967797724,
        "company": "MISTRAS Group, Inc.",
        "title": "Data Scientist II - Remote",
        "created_on": 1720588106.6485505,
        "description": "The Data Solutions Center of Excellence (COE) is a business segment of MISTRAS focused on providing software technology, implementation services and data analytics to a diverse group of customers operating globally. There are multiple divisions within the business segment with each focusing on a particular business or service line. The COE offers standalone software products and technical services to customers as well as complementing traditional MISTRAS inspection services with business intelligence capabilities. The Data Scientist II plays a vital role in our organization; helping us to extract valuable insights and information out of our growing data topology. The role requires a strong problem-solving mindset, firm communication, and an ability to learn/adapt quickly. Salary Range is $100-125K Major Responsibilities/Activities Determine which data are available and useful for the project Collect, categorize, and analyze data Create, validate, test, and update algorithms and models Use data visualization software to present findings Make business recommendations to stakeholders based on data analysis Coach/Mentor teammates in knowledge building and sharing Other duties as assigned. Qualifications & Skills Exceptional technical writing skills Exceptional data analysis, data cleansing/teasing skillset Ability to communicate complex data in a simple, actionable way Ability to visualize data in the most effective way possible for a given project or study Analytical and problem-solving skills Familiarity with data management tools Ability to work independently and with team members from different backgrounds Excellent attention to detail Willingness to learn new technologies and techniques Education & Experience Requirements A bachelor's or master's degree in data science, computer science, statistics, or a related field 3+ years data science experience Proven knowledge of AI/Machine Learning concepts and processes. Azure ML studio experience. Proficiency in programming languages such but not limited to Python, R Essential Physical Functions Frequent lifting up to 30 lbs. This job description reflects management's assignment of essential functions; it does not prescribe or restrict the tasks that may be assigned. MISTRAS strives to provide a positive work environment that values excellence in safety and quality, free from discrimination and harassment. Every MISTRAS employee plays a part in our Company’s success and making this a great place to work. We are committed to a work place where all employees are free to raise issues, concerns and questions for the improvement of our operations and work environment. Safety is the overriding priority in everything we do; all duties critical to safety, quality, and environmental protection are carried out in compliance with all requirements and with personal accountability. Note To Applicants Smoking is prohibited in all indoor areas of the Company unless designated smoking areas have been established by a particular location in accordance with applicable state and local law. Note to Rhode Island Applicants: The company is subject to Chapters 29-38 of Title 28 of the General Laws of Rhode Island, and is therefore covered by the states worker's compensation law. Initial ( if applicable) Massachusetts Applicants: I understand that it is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability. Initial ( if applicable): Maryland Applicants: I UNDERSTAND THAT UNDER MARYLAND LAW, AN EMPLOYER MAY NOT REQUIRE OR DEMAND, AS A CONDITION OF EMPLOYMENT, PROSPECTIVE EMPLOYMENT OR CONTINUED EMPLOYMENT, THAT ANY INDIVIDUAL SUBMIT TO OR TAKE A POLYGRAPH OR SIMILAR TEST. AN EMPLOYER WHO VIOLATES THIS LAW IS GUILTY OF A MISDEMEANOR AND SUBJECT TO A FINE NOT EXCEEDING $100. #AB1 Equal Opportunity Employer/Veterans/Disabled MISTRAS Group, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",
        "url": "https://www.linkedin.com/jobs/view/3967797724",
        "summary": "The Data Scientist II role at MISTRAS involves extracting valuable insights from data, creating and validating algorithms, and presenting findings to stakeholders. Key responsibilities include data collection, analysis, and visualization. The position requires strong problem-solving skills, communication abilities, and a willingness to learn new technologies.",
        "industries": [
            "Data Analytics",
            "Software Development",
            "Information Technology",
            "Inspection Services",
            "Business Intelligence"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Adaptability",
            "Teamwork",
            "Analytical thinking",
            "Attention to detail",
            "Communication"
        ],
        "hard_skills": [
            "Data analysis",
            "Data cleansing",
            "Data visualization",
            "Algorithm development",
            "Machine learning",
            "AI",
            "Python",
            "R",
            "Azure ML Studio",
            "Data management tools"
        ],
        "tech_stack": [
            "Azure ML Studio",
            "Python",
            "R"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 125000,
            "min": 100000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Miami, FL",
        "job_id": 3971529182,
        "company": "EBG",
        "title": "Lead Data Scientist",
        "created_on": 1720588107.9719868,
        "description": "Company Description EBG is an e-commerce solutions provider specializing in travel and entertainment, and also offering retail products and services, voluntary benefits and insurance. EBG powers a robust portfolio of technology solutions and operates a network of employer and membership-based platforms reaching a captive audience, providing leading brands with incremental distribution opportunities. EBG's expanded network reaches over 100 million users from participating companies and closed loop affinity and membership groups. EBG owns and operates one of the largest and most comprehensive employee savings programs in the country — serving over 40,000 corporate clients through its proprietary platforms TicketsatWork, Plum Benefits, Working Advantage and Beneplace. EBG is a b2b2c company headquartered in Miami (Aventura), with offices in New York, Orlando, Austin and Las Vegas. Job Description EBG has an opening for a talented and experienced Lead Data Scientist to join our dynamic team. The ideal candidate will have a passion for deriving actionable insights from complex datasets and a strong background in machine learning (supervised, semi-supervised & unsupervised), statistical analysis, and data visualization. Conduct exploratory data analysis to identify patterns, trends, and anomalies within large datasets. Develop predictive models and machine learning algorithms to solve business problems and improve decision-making processes. Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions. Clean, preprocess, and manipulate data to ensure accuracy, completeness, and consistency. Implement and deploy scalable solutions for data processing, model training, and evaluation. Interpret model results and communicate findings to stakeholders in a clear and concise manner. Stay updated on the latest advancements in data science, machine learning, and related fields. Mentor junior team members and provide guidance on best practices in data analysis and model development. Qualifications Master's degree or PhD in Data Science, Machine Learning, AI, Computer Science, Statistics, Mathematics, or a related field. PhD preferred Proven experience (3+ years post graduate) as a Sr. or Lead Data Scientist in a fast-paced, commercial environment Have developed algorithms or implemented solutions that include classification, predictive analytics, product recommendation, pattern recognition, sentiment analysis. (E-commerce experience preferred) Proficiency in machine learning (supervised, semi-supervised & unsupervised) Proficiency in Python, specifically using its data manipulation libraries Knowledge and experience with NLP (Natural Language Processing) algorithims and libraries within Python and related languages such as R or Scala. Strong knowledge of statistical analysis techniques, machine learning algorithms, and data visualization tools Experience with big data technologies such as Spark and TensorFlow is a plus Excellent problem-solving skills and ability to work independently as well as part of a team Strong communication and interpersonal skills, with the ability to explain complex concepts to non-technical stakeholders Experience working on teams, across functions and able to present to both technical and non-technical audiences and stakeholders Demonstrated ability to manage multiple projects simultaneously and prioritize tasks effectively Ability to travel on occasion EBG does not offer sponsorship Additional Information Entertainment Benefits Group offers outstanding employee benefits including: Medical, Dental & Vision 401k Match Short Term Disability, Long Term Disability (Company Paid) Basic Life and AD&D (Company Paid) Additional Voluntary Benefits (additional life, legal, critical care, and more) Flexible Work Arrangements 3 Weeks of PTO + 5 Personal Days Paid Holiday Break from Christmas to New Year Paid Holidays Fitness Centers (location dependent) Annual Day of Giving Company Bonus Program Share in the FUN! EBG gives $1000 per year in Tickets-At-Work gift cards to full-time employees to experience and enjoy the savings marketplace!",
        "url": "https://www.linkedin.com/jobs/view/3971529182",
        "summary": "Entertainment Benefits Group (EBG) is seeking a Lead Data Scientist with 3+ years of post-graduate experience to join their team. The role involves conducting exploratory data analysis, developing predictive models and machine learning algorithms, collaborating with cross-functional teams, cleaning and pre-processing data, implementing scalable solutions, interpreting model results, and staying updated on advancements in data science. EBG offers a competitive compensation package including medical, dental, vision, 401k match, disability insurance, life insurance, flexible work arrangements, PTO, paid holidays, fitness centers, a company bonus program, and Tickets-At-Work gift cards.",
        "industries": [
            "E-commerce",
            "Travel",
            "Entertainment",
            "Retail",
            "Benefits",
            "Insurance",
            "Technology",
            "Data Science",
            "Machine Learning"
        ],
        "soft_skills": [
            "Passion for data insights",
            "Strong communication and interpersonal skills",
            "Problem-solving skills",
            "Teamwork",
            "Ability to work independently",
            "Presentation skills",
            "Time management",
            "Prioritization"
        ],
        "hard_skills": [
            "Exploratory Data Analysis",
            "Machine Learning",
            "Statistical Analysis",
            "Data Visualization",
            "Predictive Modeling",
            "Classification",
            "Predictive Analytics",
            "Product Recommendation",
            "Pattern Recognition",
            "Sentiment Analysis",
            "Python",
            "Data Manipulation Libraries",
            "NLP (Natural Language Processing)",
            "R",
            "Scala",
            "Spark",
            "TensorFlow"
        ],
        "tech_stack": [
            "Python",
            "Spark",
            "TensorFlow",
            "NLP (Natural Language Processing)",
            "R",
            "Scala",
            "Data Manipulation Libraries"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Scala"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Machine Learning",
                "AI",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401k Match",
            "Short Term Disability",
            "Long Term Disability",
            "Basic Life and AD&D",
            "Additional Voluntary Benefits",
            "Flexible Work Arrangements",
            "PTO",
            "Personal Days",
            "Paid Holiday Break",
            "Paid Holidays",
            "Fitness Centers",
            "Annual Day of Giving",
            "Company Bonus Program",
            "Tickets-At-Work gift cards"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Framingham, MA",
        "job_id": 3970397453,
        "company": "Bose Corporation",
        "title": "Senior Data Scientist",
        "created_on": 1720588113.9496624,
        "description": "You know the moment. It’s the first notes of that song you love, the intro to your favorite movie, or simply the sound of someone you love saying “hello.” It’s in these moments that sound matters most. At Bose, we believe sound is the most powerful force on earth. We’ve dedicated ourselves to improving it for nearly 60 years. And we’re passionate down to our bones about making whatever you’re listening to a little more magical. The Corporate Strategy team at Bose works on some of the company’s most important business and growth initiatives. We work closely with executive leadership and cross-functional teams across the company to analyze market opportunities, create winning strategies, and inform important decisions with insightful, data-driven recommendations based on a deep knowledge of the business, customers, and external market factors. Job Description ABOUT BOSE You know the moment. It’s the first notes of that song you love, the intro to your favorite movie, or simply the sound of someone you love saying “hello.” It’s in these moments that sound matters most. Innovation is more than what we do. It’s who we are — constantly learning and constantly curious. We never stop imagining what better sound sounds like. We’re music fanatics and audio engineers. We’re explorers and inventors and dreamers. And we’re passionate down to our bones about making whatever you’re listening to a little more magical. About The Role At Bose, we aim to bring products into the world that people truly love, and we don’t stop until the details are just right. Data science, machine learning, and analytics are a crucial part of this mission. These capabilities fuel the creation of new and innovative products, helping us to bring the right products to the right customers, and allow us to astonish customers with carefully crafted and personalized experiences. We are looking for a Senior Data Scientist, ideally with a background in demand forecasting and time-series, to join our Data Science team within our Data and Analytics CoE. As a data scientist within the CoE, your mission will be to develop world-class AI, data science, machine learning, and related solutions to solve for our biggest challenges. Within this role you will focus on driving the strategy for and building the next generation of supply chain and demand forecasting models. You will work with a cross-functional team of data scientists and partner with teams from across Bose to influence decisions that will drive a significant impact to our bottom-line and our customers. Responsibilities Engage with business partners and stakeholders to understand business problems and translate them into data science solutions. Coordinate and collaborate with data science, data engineering, analytic engineering, and other resources to achieve business goals. Work cross-functionally with sales, product, marketing, and engineering on optimization opportunities and insights. Lead and contribute to the end-to-end development and deployment of predictive and prescriptive models, with a focus on supply chain and demand forecasting. Explore large datasets using modeling, analysis, and visualization techniques. Communicate results, analyses, and methodologies to technical and non-technical senior level stakeholders. Ability to mentor, coach, and lead others. Contribute to and help build ML/AI vision to support business strategy. About You MS or PhD in Data Science, Machine Learning, Applied Mathematics/Statistics, or a related field. 8-10 years of experience applying data science, AI/machine learning, and analytics techniques to business problems. 4+ years of experience leading data science projects Must have 3+ years working in demand forecasting - exp in the CE space strongly preferred. Experience with machine learning and causal modeling techniques, with a focus on time-series forecasting. Experience solving real-world problems using programming languages such as SQL, Spark, and Python, and deploying solutions to enterprise systems Excellent strategic thinking, communication, collaboration, and problem-solving skills, including working with and articulating results to senior business stakeholders. Experience with and understanding of project management tools and principles Ideal candidates will have experience in cold-start and in-market demand forecasting. “Our goal is to create an atmosphere where every candidate feels supported and empowered in the interviewing process. Diversity and inclusion are integral to our success, and we believe that providing reasonable accommodation is not only a legal obligation but also a fundamental aspect of our commitment to being an employer of choice. We recognize that individuals may have different needs and requirements based on their abilities, and we provide reasonable accommodations to ensure ideal conditions are met during the application process.\" Bose is an equal opportunity employer that is committed to inclusion and diversity. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, national origin, age, disability, veteran status, or any other legally protected characteristics. For additional information, please review: (1) the EEO is the Law Poster (http://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf); and (2) its Supplements (http://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm). Please note, the company's pay transparency is available at http://www.dol.gov/ofccp/pdf/EO13665_PrescribedNondiscriminationPostingLanguage_JRFQA508c.pdf. Bose is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the application or employment process, please send an e-mail to Wellbeing@bose.com and let us know the nature of your request and your contact information. Our goal is to create an atmosphere where every candidate feels supported and empowered in the interviewing process. Diversity and inclusion are integral to our success, and we believe that providing reasonable accommodation is not only a legal obligation but also a fundamental aspect of our commitment to being an employer of choice. We recognize that individuals may have different needs and requirements based on their abilities, and we provide reasonable accommodations to ensure ideal conditions are met during the application process. If you believe you need a reasonable accommodation, please send a note to wellbeing@bose.com",
        "url": "https://www.linkedin.com/jobs/view/3970397453",
        "summary": "Bose is looking for a Senior Data Scientist with expertise in demand forecasting and time-series analysis to join their Data Science team within their Data and Analytics CoE. This role focuses on developing AI and machine learning solutions to optimize supply chain and demand forecasting, ensuring the right products reach the right customers at the right time. The successful candidate will collaborate with cross-functional teams across the company, leverage data science techniques for business insights, and lead the development and deployment of predictive and prescriptive models.",
        "industries": [
            "Consumer Electronics",
            "Audio Equipment",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Strategic Thinking",
            "Leadership",
            "Mentoring",
            "Coaching"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "AI",
            "Demand Forecasting",
            "Time-Series Analysis",
            "Supply Chain Optimization",
            "SQL",
            "Spark",
            "Python",
            "Project Management"
        ],
        "tech_stack": [
            "AI",
            "Machine Learning",
            "SQL",
            "Spark",
            "Python"
        ],
        "programming_languages": [
            "SQL",
            "Spark",
            "Python"
        ],
        "experience": 8,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Data Science",
                "Machine Learning",
                "Applied Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3965428184,
        "company": "Stealth Startup",
        "title": "Machine Learning Engineer [28473]",
        "created_on": 1720588117.2756655,
        "description": "The company is an applied behavioral research company working at the intersection of ML, social sciences, and recommendation systems / Prediction - as - a - service. The company enables businesses to build privacy preserving recommendation and behavioral technologies competitive to big tech without the use of interpretable raw customer data. We’re looking to develop the next generation of privacy preserving machine learning products that understand and predict behavior at scale. Our products and research teams need to handle information at a massive scale across a number of unstructured dimensions. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, privacy, artificial intelligence, and NLP. Job Qualification: ● Bachelor’s degree or equivalent practical experience. ● 5+ years of experience with software development in one or more programming languages, and with data structures/algorithms. ● 5+ years with two or more languages/softwares included but not limited to: Python, Apache, Presto, R, ML/optimization, Scala ● 5+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, NLP, data mining or artificial intelligence ● 5+ years of experience with ML/AI algorithms and tools, deep learning and/or natural language processing. Responsibilities: ● You enjoy partnering with data science teams to deploy and scale advanced algorithms ● You strive to write elegant code, and you're comfortable with picking up new technologies independently ● You enjoy collaborating with colleagues/partners internally and externally ● You are passionate about building intuitive data models and an expert in distributed data processing patterns ● You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks What you will do: ● Engineer efficient, adaptable, and scalable data pipelines to process structured and unstructured data ● Maintain and rethink existing datasets and pipelines to service a wider variety of use cases ● Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules-based models ● Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)",
        "url": "https://www.linkedin.com/jobs/view/3965428184",
        "summary": "The company is looking for a software engineer with 5+ years of experience in software development, data structures/algorithms, Python, Apache, Presto, R, ML/optimization, Scala, machine learning, recommendation systems, pattern recognition, NLP, data mining or artificial intelligence, and ML/AI algorithms and tools, deep learning and/or natural language processing. The engineer will be responsible for engineering efficient, adaptable, and scalable data pipelines to process structured and unstructured data, maintaining and rethinking existing datasets and pipelines, developing highly scalable classifiers and tools leveraging machine learning, data regression, and rules-based models, and adapting standard machine learning methods to best exploit modern parallel environments.",
        "industries": [
            "Machine Learning",
            "Artificial Intelligence",
            "Data Science",
            "Technology",
            "Software Development",
            "Research"
        ],
        "soft_skills": [
            "Problem Solving",
            "Collaboration",
            "Communication",
            "Adaptability",
            "Teamwork",
            "Creativity",
            "Analytical Thinking",
            "Independent Thinking",
            "Passionate",
            "Risk Taking"
        ],
        "hard_skills": [
            "Software Development",
            "Data Structures",
            "Algorithms",
            "Python",
            "Apache",
            "Presto",
            "R",
            "ML/Optimization",
            "Scala",
            "Machine Learning",
            "Recommendation Systems",
            "Pattern Recognition",
            "NLP",
            "Data Mining",
            "Artificial Intelligence",
            "Deep Learning",
            "Natural Language Processing",
            "Data Pipelines",
            "Data Regression",
            "Rules-Based Models",
            "Distributed Computing",
            "Parallel Environments",
            "GPU"
        ],
        "tech_stack": [
            "Python",
            "Apache",
            "Presto",
            "R",
            "ML/Optimization",
            "Scala",
            "Machine Learning",
            "Recommendation Systems",
            "Pattern Recognition",
            "NLP",
            "Data Mining",
            "Artificial Intelligence",
            "Deep Learning",
            "Natural Language Processing",
            "Data Pipelines",
            "Data Regression",
            "Rules-Based Models",
            "Distributed Computing",
            "Parallel Environments",
            "GPU"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Scala"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Virginia Beach, VA",
        "job_id": 3965750503,
        "company": "K2 Integrity",
        "title": "Data Scientist",
        "created_on": 1720588125.9183662,
        "description": "K2 Integrity is looking for a highly motivated and focused Data Scientist to design, develop, and implement our Systemic Risk Analytics Framework for K2 Integrity’s market leading Anti-Financial Crime and Compliance solutions. This role will be involved in working with Product Management, R&D, Business, Data Science and Data Architecture teams to design, build, and deploy a leading-edge platform supporting a robust analytics framework for the identification and reporting of illicit activities and associated behavioral patterns of abuse. This will include development of risk models for individual entities, populations and jurisdictional detection and monitoring. Modern analytical techniques such as customer segmentation, identity resolution and identification, neural networks, and large language and machine learning models will be leveraged alongside defined operational summary statistics analysis and reporting. Responsibilities: Design, develop and implement a robust analytics framework and reporting capability in conjunction with your counterparts in the Systemic Risk Analytics function Partner with stakeholders to ideate and identify new “unknown unknown” risk typologies that can be codified into new risk models Work with data science counterparts and product management to define, develop, and implement new models and techniques to more effectively analyze data for known and unknown illicit behaviors with the chief goal of higher value alerts and reduction of false positives. Codify and implement developed compliance rules for analyzing payments and their associated beneficiaries, remitters and managing directors for identification of sanctions and other compliance risks. Partner to develop a robust KYC/CDD analytics solution in concert with internal systems and technology vendor partners to understand individual and systemic risk across entities, populations, and jurisdictions Implement appropriate data governance controls, policies and procedures to ensure data integrity and data lineage. Ensure automation for the operational execution of rules, models and reports. Implement an automated alerting function detecting data cleanliness and data availability issues Overall, increase the accuracy and effectiveness of investigations while reducing operational overhead and run rate cost Qualifications: Bachelor’s, master’s degree or Ph.D. in statistics or math, or equivalent quantitative field of study Demonstrated experience in developing, implementing, and managing operational analytical solutions or frameworks. (8+ years of experience) Demonstrated experience in optimization and automation of analytical models/rules including look back, audit, “What if?” and impact analysis testing and performance validations. Demonstrated programming skills with SAS, Spark, Python, R or equivalent languages Demonstrated use of Large Language Models such as ChatGPT or equivalent Demonstrated experience working with Anti-Financial Crime and Compliance technologies. For example: Transaction Monitoring Systems, KYC/CDD, Sanctions and Wire screening Applications, Network Analysis, Entity Resolution & Identification and Segmentation utilities or Case Management solutions Ability to work during Eastern Standard Time regular business hours Certified Analytics Professional (CAP), Data Science Council of America (DASCA), Principal Data Scientist (PDS), SAS Big Data Professional, Microsoft Certified Azure Data Scientist Associate, or equivalents Strong working knowledge and familiarity with Palantir Foundry applications, products, and solutions Powered by JazzHR bFkeu0BTkJ",
        "url": "https://www.linkedin.com/jobs/view/3965750503",
        "summary": "K2 Integrity seeks a Data Scientist to build and implement a Systemic Risk Analytics Framework for their Anti-Financial Crime and Compliance solutions. This role involves designing, developing, and deploying an analytics platform to detect illicit activities and patterns. The successful candidate will utilize advanced techniques like customer segmentation, identity resolution, neural networks, and large language models, along with traditional statistical analysis and reporting.",
        "industries": [
            "Financial Services",
            "Compliance",
            "Anti-Financial Crime",
            "Data Analytics",
            "Technology"
        ],
        "soft_skills": [
            "Motivated",
            "Focused",
            "Problem-Solving",
            "Analytical",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Stakeholder Management",
            "Data Governance"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Neural Networks",
            "Large Language Models",
            "Customer Segmentation",
            "Identity Resolution",
            "Statistical Analysis",
            "Risk Modeling",
            "Data Governance",
            "Data Integrity",
            "Automation",
            "Optimization",
            "SAS",
            "Spark",
            "Python",
            "R",
            "ChatGPT",
            "Palantir Foundry"
        ],
        "tech_stack": [
            "SAS",
            "Spark",
            "Python",
            "R",
            "ChatGPT",
            "Palantir Foundry",
            "Transaction Monitoring Systems",
            "KYC/CDD",
            "Sanctions and Wire screening Applications",
            "Network Analysis",
            "Entity Resolution & Identification",
            "Segmentation utilities",
            "Case Management solutions"
        ],
        "programming_languages": [
            "SAS",
            "Spark",
            "Python",
            "R"
        ],
        "experience": 8,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Statistics",
                "Math",
                "Quantitative Fields"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3966046165,
        "company": "Atropos Health",
        "title": "Staff Data Scientist (Machine Learning Engineer)",
        "created_on": 1720588127.8283827,
        "description": "About Atropos Health Atropos Health is the developer of GENEVA™ OS , the operating system for rapid healthcare evidence across a robust network of real-world data. Healthcare and life science organizations work with Atropos Health to close evidence gaps from bench to bedside, improving individual patient outcomes with data-driven care, expediting research that advances the field of medicine, and more. We aim to transform healthcare with timely, relevant real-world evidence. About The Role This is a hybrid role combining Data Science and Software Engineering. If you enjoy driving the development and deployment of data science products such as models, recommenders, databases in collaboration with Product and Clinical teams, this position is for you. We are looking for versatile data scientists who continuously seek product innovation and can deploy solutions with strong engineering skills to augment our automated Atropos Health workbench that generates rapid and reliable RWE. Responsibilities Work with Product, Clinical and Engineering stakeholder teams to understand product and clinical requirements and deliver product solutions that balance technical rigor with practical application Test, productionalize and maintain data science products with software engineering best practices including code management and documentation Articulate and deconstruct complex projects into workable solutions and identify appropriate data and methods Practice good judgment and solicit information to make good and timely design decisions Manage and drive projects, working with stakeholders to address dependencies and gaps Solicit user feedback and propose opportunities for product innovation (e.g. to add new functionalities, improve model performance, automate processes) Stay abreast of research and conduct literature and empirical research to propose appropriate solutions while sidestepping less promising ones Excellent writing skills – you may be asked to contribute to our technical blogs Minimum Qualifications Degree in Clinical Informatics, Bioinformatics, CS, Engineering, Epidemiology, Statistics, or a quantitative discipline Experience manipulating large data sets and developing and deploying models onto production infrastructure Fluency with Python, R, SQL, git, Linux and cloud infrastructure (AWS and Docker). You have published a Python or R package before and are familiar with virtual environments Sufficiently knowledgeable about healthcare to understand product needs Excellent problem-solving, project management and team collaboration skills Flexible thinking: you know how to re-frame problems to find practical solutions Additional skills in epidemiology, LLM’s, RWE, causal inference, recommenders, NLP, data engineering, MLOps or DevOps will be a plus Knowledge of relevant medical coding terminology (e.g., ICD, CPT, LOINC, RxNORM) is a plus Masters or PhD training in a quantitative field is a plus Reporting The Staff Data Scientist (Machine Learning Engineer) reports directly to the President, Neil Sanghavi. Location We are a remote first company! You must be currently authorized to work in the United States on a full-time basis. We cannot support visa sponsorship at this time. Our Core Values Bias to Action. We are driven by urgency and persistence, ensuring our actions contribute to the relentless pursuit of our mission. Intellectual Honesty. We are committed to the integrity of our work, seeking truth, and building transparent methodologies that go beyond industry norms. Compelled by Curiosity. We seek to solve the unknown, push boundaries, and do not accept the status quo. Impactful Innovation. We pioneer solutions that pursue equity and representation that have a transformative impact for our customers, users, and patients. Mindful Mentorship. We approach all interactions with an empathetic understanding, actively investing in the growth of each other and our customers. Perks Health & Wellness. Our benefit package includes employer paid Medical, Dental, Vision, Life, STD, and LTD insurance. Parental Leave. We offer up to twelve weeks of paid leave for new parents who have been at the company for 6+ months. Financial Wellness. Save for retirement through our 401k plan with Human Interest. Flexible Work Environment. We're a remote first company with a flexible vacation policy. Offsites. As a remote company we take time 2-3 times a year to get together in small teams and all together as a company. At Atropos, we are committed to fostering a diverse, inclusive, and equitable workplace where every individual feels valued, respected, and empowered to contribute their unique perspectives and talents. We are an equal-opportunity employer that does not discriminate on the basis of race, religion, national origin, age, gender, gender identity or expression, sexual orientation, genetics, disability, pregnancy, veteran status, or any other legally protected status. Compensation Range: $140K - $175K",
        "url": "https://www.linkedin.com/jobs/view/3966046165",
        "summary": "Atropos Health is seeking a Staff Data Scientist (Machine Learning Engineer) to develop and deploy data science products for healthcare and life science organizations. This hybrid role combines data science and software engineering, focusing on building models, recommenders, and databases to generate rapid and reliable real-world evidence (RWE). Responsibilities include collaborating with stakeholders to understand product and clinical requirements, testing and productionalizing data science products, and staying abreast of research in the field. This remote-first position requires expertise in Python, R, SQL, git, Linux, cloud infrastructure (AWS and Docker), and familiarity with healthcare data and medical coding terminology. Strong problem-solving, project management, and team collaboration skills are essential.",
        "industries": [
            "Healthcare",
            "Life Sciences",
            "Biotechnology",
            "Pharmaceuticals",
            "Data Science",
            "Software Engineering"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-solving",
            "Project Management",
            "Critical thinking",
            "Analytical thinking",
            "Decision-making",
            "Flexibility",
            "Teamwork",
            "Leadership",
            "Time management"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Git",
            "Linux",
            "AWS",
            "Docker",
            "Machine Learning",
            "Data Science",
            "Model Development",
            "Data Engineering",
            "Statistical Modeling",
            "Data Analysis",
            "Data Visualization",
            "Data Wrangling",
            "Software Engineering",
            "Cloud Computing",
            "Healthcare Data",
            "Medical Coding Terminology",
            "ICD",
            "CPT",
            "LOINC",
            "RxNORM"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Git",
            "Linux",
            "AWS",
            "Docker"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Clinical Informatics",
                "Bioinformatics",
                "Computer Science",
                "Engineering",
                "Epidemiology",
                "Statistics",
                "Quantitative Disciplines"
            ]
        },
        "salary": {
            "max": 175000,
            "min": 140000
        },
        "benefits": [
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Life Insurance",
            "Short-Term Disability Insurance",
            "Long-Term Disability Insurance",
            "Parental Leave",
            "401k",
            "Flexible Work Environment",
            "Vacation Policy",
            "Offsites"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Tampa, FL",
        "job_id": 3963389333,
        "company": "RIT Solutions, Inc.",
        "title": "Data Scientist",
        "created_on": 1720588130.87007,
        "description": "Remote Note: Must have Proven experience working with Epic EMR data, including extraction, transformation, and analysis. Strong background in implementing rules-based logic and RAG in a healthcare setting. As part of the Quality and Safety division, Data and Analytics (DnA) empowers NYC its partners with data, digital tools, AI capabilities, and insights to drive quality and performance improvements, support enterprise operations, and enhance patient outcomes. We are seeking an experienced Data Scientist This role requires a strong background in product development, innovative problem-solving, and analytical skills to translate complex healthcare challenges into actionable data solutions. We are seeking a highly skilled and motivated Data Scientist with expertise in Epic EMR (Electronic Medical Records) data to join our team. The successful candidate will play a critical role in leveraging Snowflake's data platform to accelerate the adoption of AI in health and hospital projects. This role involves implementing rules-based logic and creating structured data models for Retrieval-Augmented Generation (RAG) to support decision-making and improve operational efficiency and clinical outcomes. Key Responsibilities: Data Management and Analysis: Extract, clean, and analyze large datasets from Epic EMR and other healthcare data sources. Develop and maintain data pipelines to ensure the accurate and timely flow of data. Perform data validation and ensure data quality and integrity. Implementation of Rules-Based Logic: Develop and implement rules-based logic to support various healthcare use cases, including One Stop Benefits, Charge Capture Automation, and Denials Optimization. Create structured data models that facilitate the application of rules-based logic. RAG (Retrieval-Augmented Generation) Implementation: Design and implement structured data models for RAG to enhance data retrieval and generation processes. Develop dashboards and visualizations to present RAG insights and other key performance indicators to stakeholders. Utilize AI and Client techniques to enhance the accuracy and predictive capabilities of the RAG models. Collaboration and Communication: Work closely with cross-functional teams, including data engineers, developers, and healthcare professionals, to understand project requirements and deliver data-driven solutions. Communicate complex analytical results and insights to non-technical stakeholders in a clear and concise manner. Project Execution: SUMMARY OF ESSENTIAL DUTIES AND RESPONSIBILITIES: NYC Health + Hospitals is the largest public health care system in the United States. We are committed to providing equitable and high-quality healthcare services to all New Yorkers. Join our team and be part of a dynamic organization that is dedicated to improving public health through innovation and excellence in data and analytics. As part of the Quality and Safety division, Data and Analytics (DnA) empowers NYC Health + Hospitals and its partners with data, digital tools, AI capabilities, and insights to drive quality and performance improvements, support enterprise operations, and enhance patient outcomes. We are seeking an experienced Data Scientist This role requires a strong background in product development, innovative problem-solving, and analytical skills to translate complex healthcare challenges into actionable data solutions. We are seeking a highly skilled and motivated Data Scientist with expertise in Epic EMR (Electronic Medical Records) data to join our team. The successful candidate will play a critical role in leveraging Snowflake's data platform to accelerate the adoption of AI in health and hospital projects. This role involves implementing rules-based logic and creating structured data models for Retrieval-Augmented Generation (RAG) to support decision-making and improve operational efficiency and clinical outcomes. Key Responsibilities: Data Management and Analysis: Extract, clean, and analyze large datasets from Epic EMR and other healthcare data sources. Develop and maintain data pipelines to ensure the accurate and timely flow of data. Perform data validation and ensure data quality and integrity. Implementation of Rules-Based Logic: Develop and implement rules-based logic to support various healthcare use cases, including One Stop Benefits, Charge Capture Automation, and Denials Optimization. Create structured data models that facilitate the application of rules-based logic. RAG (Retrieval-Augmented Generation) Implementation: Design and implement structured data models for RAG to enhance data retrieval and generation processes. Develop dashboards and visualizations to present RAG insights and other key performance indicators to stakeholders. Utilize AI and Client techniques to enhance the accuracy and predictive capabilities of the RAG models. Collaboration and Communication: Work closely with cross-functional teams, including data engineers, developers, and healthcare professionals, to understand project requirements and deliver data-driven solutions. Communicate complex analytical results and insights to non-technical stakeholders in a clear and concise manner. Project Execution: Participate in agile development processes and contribute to sprint planning, reviews, and retrospectives. Ensure timely delivery of project milestones and adhere to project timelines. Preferred Skills Design and implement predictive models using various machine learning techniques, including both supervised and unserved algorithms. Utilize deep statistical analysis to understand and model complex public health data. Develop and deploy Large Language Models (LLMs) for creating chatbots and extracting insights, enhancing user engagement and information dissemination. Analyze clinical data to derive insights that improve patient care and clinical workflows. QUALIFICATIONS FOR THE JOB: (In addition to the minimum qualifications as per the corporate job description) Educational Level: Bachelor's Or Master's Degree In Data Science, Computer Science, Statistics, Or a Related Field. A Ph.D. Is a Plus. Knowledge, Skills, Abilities And Other Requirements: Proficiency in programming languages such as Python, R, and SQL. Experience with data visualization tools such as Tableau, Power BI, or similar. Familiarity with Snowflake or other cloud-based data platforms. Knowledge of ETL processes and tools. Experience with AI and Client techniques to enhance data analysis and RAG implementation. but not limited to SQL, Excel and/or SAAS Proficient in various data catalog and visualizations tools, including but not limited to Tableau, PowerBI, Informatica, and/or Snowflake Knowledgeable in electronic medical records, preferably EPIC Years Of Experience: Minimum of 5 years of experience in data science, with a focus on healthcare analytics. Proven experience working with Epic EMR data, including extraction, transformation, and analysis. Strong background in implementing rules-based logic and RAG in a healthcare setting.",
        "url": "https://www.linkedin.com/jobs/view/3963389333",
        "summary": "NYC Health + Hospitals is seeking a Data Scientist with proven experience in Epic EMR data extraction, transformation, and analysis. The role involves implementing rules-based logic and RAG (Retrieval-Augmented Generation) in a healthcare setting to enhance data retrieval and generation processes, support decision-making, and improve operational efficiency and clinical outcomes.",
        "industries": [
            "Healthcare",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Collaboration",
            "Analytical Skills",
            "Product Development",
            "Data-Driven",
            "Innovative",
            "Motivation",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Power BI",
            "Snowflake",
            "ETL",
            "AI",
            "Machine Learning",
            "Large Language Models (LLMs)",
            "Statistical Analysis",
            "Clinical Data Analysis",
            "Epic EMR",
            "Rules-Based Logic",
            "Retrieval-Augmented Generation (RAG)"
        ],
        "tech_stack": [
            "Epic EMR",
            "Snowflake",
            "Tableau",
            "Power BI",
            "Informatica"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Dallas, TX",
        "job_id": 3960808688,
        "company": "Topaz Labs",
        "title": "Machine Learning Engineer",
        "created_on": 1720588137.1607337,
        "description": "54,000 new photos are taken every second, and 600 hours of video are uploaded every minute. At Topaz Labs, we help over 1 million paying customers (including teams at Apple, Netflix, and NASA) maximize the visual quality of over 1 billion of these photos and videos. About Us Topaz Labs is a full-stack AI company that develops, trains, and deploys generative AI models for image and video enhancement. We’re the best in the world at improving image and video quality, and produce several award-winning desktop products that millions of people rely on. Image and video creation has exploded in the past few years and we’ve grown with it, but we still only process a tiny fraction of the world’s content. We’re building an elite team dedicated to bringing our technology to every image and video that needs it. We execute quickly, obsess about the customer experience, and promote from within. We’re also profitable with an infinite runway. About The Role As a Machine Learning Engineer you’ll partner with our deep learning research and engineering teams to build models that perform best-in-world image and video upscaling. From tweaking model parameters to productizing never before seen computer vision models, this role will bridge the gap between research and software engineering. We prototype, build, and deploy new products at a rapid pace, and you’ll help us build better AI products and tools for our millions of users. About You At least 3+ years of professional working experience in a related field Hands-on experience with performance optimization, e.g. with multithreading Hands-on experience implementing image processing / computer vision models Experience with MLops best practices Experience with large non-SQL datasets Expert knowledge of Python, C/C++ and proficiency with OpenCV Preferred Experience with OpenCV, ffmpeg, other media-specific libraries and frameworks Exposure to model optimization for local processing Interest in photography or videography Do you meet most but not 100% of the above? We’d still like to hear from you–we are passionate about developing a diverse team and culture, so please apply if you’re interested! This is a unique role for someone interested in making a deep impact at a high-growth tech software company. We offer strong base salary, plus significant ownership that scales with the company's growth. We also offer 100% covered medical/dental/vision for employees, 15 days annual PTO, 5 personal days plus holidays, and 401k matching. This is a full-time onsite role in Dallas, TX, and we will ask you to relocate if you're not in the area",
        "url": "https://www.linkedin.com/jobs/view/3960808688",
        "summary": "Topaz Labs, an AI company specializing in image and video enhancement, is seeking a Machine Learning Engineer to build models for best-in-world image and video upscaling.  The role involves working closely with research and engineering teams to bridge the gap between research and software engineering. This is a high-impact opportunity for someone interested in making a difference at a rapidly growing tech company.",
        "industries": [
            "Software",
            "Artificial Intelligence",
            "Image Processing",
            "Video Processing",
            "Computer Vision"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Performance Optimization",
            "Customer Experience"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Image Processing",
            "Computer Vision",
            "Model Optimization",
            "Python",
            "C/C++",
            "OpenCV",
            "MLops",
            "Multithreading",
            "Non-SQL Datasets",
            "ffmpeg",
            "Media Libraries"
        ],
        "tech_stack": [
            "OpenCV",
            "ffmpeg",
            "Python",
            "C/C++"
        ],
        "programming_languages": [
            "Python",
            "C/C++"
        ],
        "experience": 3,
        "education": {
            "min_degree": null,
            "fields": [
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical/Dental/Vision Insurance",
            "Paid Time Off",
            "Personal Days",
            "401k Matching"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "West Point, PA",
        "job_id": 3964879510,
        "company": "Merck",
        "title": "Senior AI/ML Data Scientist",
        "created_on": 1720588140.0800686,
        "description": "Job Description The Computational Toxicology group within the Nonclinical Drug Safety (NDS) division at our company is actively seeking an AI/ML data Scientist to contribute to the discovery and development of effective, safer therapeutics for patients. This key role will be instrumental in supporting NDS's broader mission to be at the forefront of AI/ML application and data science methodologies towards drug safety prediction. The ideal candidate will possess a strong foundation in Artificial Intelligence (AI)/Machine Learning (ML) and will be integral to the development of predictive ML models for safety and toxicology endpoints, using a variety of data modalities from drug discovery, preclinical development, clinical trials, and post-market surveillance. The candidate will implement AI methodologies to enable early safety hazard identification, generate viable hypotheses for mechanistic toxicology, and ensure the early adoption of these models into our company's discovery and development pipeline. Note: This position is available in West Point, PA; Boston, MA; or South San Francisco, CA. Key Job Duties Inform prioritization for in vitro and in vivo preclinical toxicology resources applying probabilistic, neural networks ML models, and generative AI methods. Utilize LLM and Generative AI approaches to generate hypothesis for mechanistic toxicology. Work collaboratively with colleagues across multiple sites and functional areas to deploy, utilize, and increase the visibility of ML approaches in selection of chemical series with a high probability of success, and/or enable prioritization of in vivo resources. Upscale NDS staff on the utility of predictive AI/ML approaches in drug safety Stay abreast with new AI approaches and regulatory landscape in the field of predictive toxicology. Education Master's (with 4+ years) or Ph.D. in computer science, computational biology, cheminformatics, biomedical engineering, and related data science fields and relevant experience Required Experience And Skills Fluency in python, R programing, standard python packages like pandas, numpy, matplotlib, and ML frameworks such as TensorFlow or PyTorch Experience with various statistical ML techniques, including both supervised, and unsupervised learning as well as DNN architecture is required. First-hand experience using Generative AI and LLM methods in related data science field would be advantageous. Experience with version control and related code reproducibility practices such as git, documentation Self-motivated with a high level of autonomy High interpersonal skills with a collaborative mindset Preferred Experience And Skills Prior experience with high-performance or cloud computing environments (e.g., AWS) and data lake platforms (e.g., Databricks) plus Experience with machine learning (ML) models deployment frameworks such as MLOps plus NOTICE FOR INTERNAL APPLICANTS In accordance with Managers' Policy - Job Posting and Employee Placement, all employees subject to this policy are required to have a minimum of twelve (12) months of service in current position prior to applying for open positions. If you have been offered a separation benefits package, but have not yet reached your separation date and are offered a position within the salary and geographical parameters as set forth in the Summary Plan Description (SPD) of your separation package, then you are no longer eligible for your separation benefits package. To discuss in more detail, please contact your HRBP or Talent Acquisition Advisor. #EligibleforERP #DATA2025 Employees working in roles that the Company determines require routine collaboration with external stakeholders, such as customer-facing commercial, or research-based roles, will be expected to comply not only with Company policy but also with policies established by such external stakeholders (for example, a requirement to be vaccinated against COVID-19 in order to access a facility or meet with stakeholders). Please understand that, as permitted by applicable law, if you have not been vaccinated against COVID-19 and an essential function of your job is to call on external stakeholders who require vaccination to enter their premises or engage in face-to-face meetings, then your employment may pose an undue burden to business operations, in which case you may not be offered employment, or your employment could be terminated. Please also note that, where permitted by applicable law, the Company reserves the right to require COVID-19 vaccinations for positions, such as in Global Employee Health, where the Company determines in its discretion that the nature of the role presents an increased risk of disease transmission. Current Employees apply HERE Current Contingent Workers apply HERE US And Puerto Rico Residents Only Our company is committed to inclusion, ensuring that candidates can engage in a hiring process that exhibits their true capabilities. Please click here if you need an accommodation during the application or hiring process. About We are an Equal Opportunity Employer, committed to fostering an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status, or other applicable legally protected characteristics. For more information about personal rights under the U.S. Equal Opportunity Employment laws, visit: EEOC Know Your Rights EEOC GINA Supplement Pay Transparency Nondiscrimination We are proud to be a company that embraces the value of bringing diverse, talented, and committed people together. The fastest way to breakthrough innovation is when diverse ideas come together in an inclusive environment. We encourage our colleagues to respectfully challenge one another’s thinking and approach problems collectively. Learn more about your rights, including under California, Colorado and other US State Acts U.S. Hybrid Work Model Effective September 5, 2023, employees in office-based positions in the U.S. will be working a Hybrid work consisting of three total days on-site per week, generally Tuesday, Wednesday and either Monday or Thursday, although the specific days may vary by site or organization, with Friday designated as a remote-working day, unless business critical tasks require an on-site presence. This Hybrid work model does not apply to, and daily in-person attendance is required for, field-based positions; facility-based, manufacturing-based, or research-based positions where the work to be performed is located at a Company site; positions covered by a collective-bargaining agreement (unless the agreement provides for hybrid work); or any other position for which the Company has determined the job requirements cannot be reasonably met working remotely. Please note, this Hybrid work model guidance also does not apply to roles that have been designated as “remote”. Under New York State, Colorado State, Washington State, and California State law, the Company is required to provide a reasonable estimate of the salary range for this job. Final determinations with respect to salary will take into account a number of factors, which may include, but not be limited to the primary work location and the chosen candidate’s relevant skills, experience, and education. Expected Salary Range $122,800.00 - $193,300.00 Available benefits include bonus eligibility, long term incentive if applicable, health care and other insurance benefits (for employee and family), retirement benefits, paid holidays, vacation, and sick days. A summary of benefits is listed here. Search Firm Representatives Please Read Carefully Merck & Co., Inc., Rahway, NJ, USA, also known as Merck Sharp & Dohme LLC, Rahway, NJ, USA, does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position specific. Please, no phone calls or emails. Employee Status Regular Relocation: Domestic/International VISA Sponsorship Yes Travel Requirements 10% Flexible Work Arrangements Hybrid Shift 1st - Day Valid Driving License No Hazardous Material(s) No Required Skills Cheminformatics, Data Modeling, Data Science, Data Visualization, Drug Discovery Process, Machine Learning, Machine Learning Algorithms, Machine Learning Model Management, Machine Learning Techniques, Project Management, Python (Programming Language), Python Automation, Python for Data Analysis, Software Development, Stakeholder Relationship Management Preferred Skills Computational Biology, Computational Toxicology Job Posting End Date 07/31/2024 A job posting is effective until 11:59:59PM on the day BEFORE the listed job posting end date. Please ensure you apply to a job posting no later than the day BEFORE the job posting end date. Job Posting End Date: 07/31/2024 A job posting is effective until 11:59:59PM on the day BEFORE the listed job posting end date. Please ensure you apply to a job posting no later than the day BEFORE the job posting end date. Requisition ID: R302078",
        "url": "https://www.linkedin.com/jobs/view/3964879510",
        "summary": "We are looking for an AI/ML data scientist to contribute to the discovery and development of effective, safer therapeutics for patients. This role will be instrumental in supporting our broader mission to be at the forefront of AI/ML application and data science methodologies towards drug safety prediction. The ideal candidate will possess a strong foundation in Artificial Intelligence (AI)/Machine Learning (ML) and will be integral to the development of predictive ML models for safety and toxicology endpoints, using a variety of data modalities from drug discovery, preclinical development, clinical trials, and post-market surveillance.",
        "industries": [
            "Pharmaceuticals",
            "Biotechnology",
            "Healthcare",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Critical Thinking",
            "Project Management",
            "Stakeholder Management",
            "Self-Motivation",
            "Autonomy"
        ],
        "hard_skills": [
            "Python",
            "R",
            "Pandas",
            "Numpy",
            "Matplotlib",
            "TensorFlow",
            "PyTorch",
            "Statistical Modeling",
            "Supervised Learning",
            "Unsupervised Learning",
            "DNN Architecture",
            "Generative AI",
            "LLM",
            "Git",
            "AWS",
            "Databricks",
            "MLOps",
            "Cheminformatics",
            "Data Modeling",
            "Data Visualization",
            "Drug Discovery Process",
            "Machine Learning",
            "Machine Learning Algorithms",
            "Machine Learning Model Management",
            "Machine Learning Techniques",
            "Software Development"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Pandas",
            "Numpy",
            "Matplotlib",
            "TensorFlow",
            "PyTorch",
            "AWS",
            "Databricks",
            "MLOps",
            "Git"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Computer Science",
                "Computational Biology",
                "Cheminformatics",
                "Biomedical Engineering",
                "Data Science"
            ]
        },
        "salary": {
            "max": 193300,
            "min": 122800
        },
        "benefits": [
            "Bonus Eligibility",
            "Long Term Incentive",
            "Health Care",
            "Insurance",
            "Retirement Benefits",
            "Paid Holidays",
            "Vacation",
            "Sick Days"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Gainesville, FL",
        "job_id": 3962462502,
        "company": "University of Florida",
        "title": "Data Scientist III",
        "created_on": 1720588145.046009,
        "description": "Classification Title Data Scientist III Job Description We are recruiting a Data Scientist in the Department of Health Outcomes and Biomedical Informatics (HOBI) at the University of Florida. The Data Scientist will participate in data-driven research activities under the guidance of Dr. Yi Guo, Associate Professor of in HOBI. The Data Scientist will work with large real-world clinical datasets (i.e., electronic health records) such as those in the OneFlorida+ Clinical Research Consortium, UF Health IDR, and Veterans Affairs. The Data Scientist will be responsible for (1) overseeing and managing data analysis projects using the above databases; (2) participation in design and implementation of data science research of using RWD; (3) development of data queries and data processing scripts to make raw data analytical ready for individual studies; (4) participating in data analyses and conducting result interpretation; and (5) contributing to scientific reports, conference papers, and journal articles. Duties Include CANCER INFORMATICS SHARED RESOURCE This position will be responsible for providing data analysis service for cancer related research in the UF Health Cancer Center, by selecting and applying appropriate analytical methods to answer questions and test hypotheses as specified by clinical researchers, administrators and clinicians. This position will require expertise in database study design, statistical methods and algorithms, as well as results interpretations. Expected projects will include design of research and operational databases, statistical analyses, and development of reporting infrastructures. Providing leadership to domain experts on issues related to principles of data science and analytical methods. Prioritizing and coordinating multiple tasks so as to achieve tight deadlines (as determined by commitments to funding agencies), and complying in a timely manner with administrative requests and requirements. Will interact with a range of experts in database modeling, and other advanced analytic processes as well as clinical and domain experts VETERANS AFFAIRS (VA) RESEARCH PROJECTS This position will be responsible for fulfilling any research project request from VA, focusing on database analysis. Expertise and responsibilities are similar to the ones listed in cancer informatics shared resource data analysis service. Project management, leadership and multi-disciplinary interaction are expected with this position. Expected Salary $90,000 Minimum Requirements A doctorate in a related field with one year of relevant experience in data science, statistics, biomedical informatics, analytics, or similar field. A Master’s degree with three years of relevant experience; or a bachelor’s degree and five years of relevant experience. Preferred Qualifications Doctorate or master’s degree in outcomes research, statistics, information systems, biomedical informatics or related field and two years of relevant experience. In-depth knowledge of health outcomes study design Experience with general statistical software (e.g. R, SAS) Excellent technical writing and communication skills Knowledge of basic principles of clinical and data science research. Ability to plan, organize and coordinate work assignments. Ability to work effectively and independently. Ability to communicate effectively verbally and in writing. Ability to establish and maintain effective working relationships with others. Special Instructions To Applicants In order to be considered, you must upload your cover letter and resume. Application must be submitted by 11:55 p.m. (ET) of the posting end date. This is a time limited position. The University of Florida is committed to non-discrimination with respect to race, creed, color, religion, age, disability, sex, sexual orientation, gender identity and expression, marital status, national origin, political opinions or affiliations, genetic information and veteran status in all aspects of employment including recruitment, hiring, promotions, transfers, discipline, terminations, wage and salary administration, benefits, and training. Health Assessment Required: No",
        "url": "https://www.linkedin.com/jobs/view/3962462502",
        "summary": "The University of Florida is seeking a Data Scientist III to join the Department of Health Outcomes and Biomedical Informatics (HOBI). The Data Scientist will participate in data-driven research activities focusing on large real-world clinical datasets (electronic health records) from sources like OneFlorida+ Clinical Research Consortium, UF Health IDR, and Veterans Affairs.  Key responsibilities include overseeing and managing data analysis projects, designing and implementing data science research, developing data queries and processing scripts, conducting data analysis and result interpretation, and contributing to scientific reports and publications. The role also involves providing data analysis services for cancer-related research at the UF Health Cancer Center, fulfilling research project requests from the VA, and leading and collaborating with domain experts.",
        "industries": [
            "Healthcare",
            "Biomedical Informatics",
            "Research",
            "Data Science",
            "Analytics",
            "Higher Education"
        ],
        "soft_skills": [
            "Communication",
            "Leadership",
            "Collaboration",
            "Project Management",
            "Time Management",
            "Organization",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Attention to Detail",
            "Independent Work"
        ],
        "hard_skills": [
            "Data Analysis",
            "Statistical Methods",
            "Database Design",
            "R",
            "SAS",
            "Data Querying",
            "Data Processing",
            "Data Visualization",
            "Result Interpretation",
            "Scientific Writing",
            "Report Writing",
            "Clinical Research",
            "Data Science Research",
            "Database Management"
        ],
        "tech_stack": [
            "R",
            "SAS",
            "Electronic Health Records (EHRs)",
            "OneFlorida+ Clinical Research Consortium",
            "UF Health IDR",
            "Veterans Affairs Databases"
        ],
        "programming_languages": [
            "R",
            "SAS"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Doctorate",
            "fields": [
                "Data Science",
                "Statistics",
                "Biomedical Informatics",
                "Analytics"
            ]
        },
        "salary": {
            "max": 90000,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Indianapolis, IN",
        "job_id": 3942397450,
        "company": "Eli Lilly and Company",
        "title": "Data Scientist - Advanced Analytics and Data Science",
        "created_on": 1720588150.8244417,
        "description": "At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our employees around the world work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for people who are determined to make life better for people around the world. Organization Overview At Lilly, we serve an extraordinary purpose. We make a difference for people around the globe by discovering, developing and delivering medicines that help them live longer, healthier, more active lives. Not only do we deliver breakthrough medications, but you also can count on us to develop creative solutions to support communities through philanthropy and volunteerism. Main Attributes: Strong analytical skills Problem-solving skills Excellent communication skills Attention to detail What You'll Be Doing: As a Data Scientist in Indianapolis, IN you will be responsible for analyzing complex data sets, developing predictive models, leveraging generative AI, and identifying insights that can be used to drive business decisions. You will work closely with cross-functional teams across the enterprise to understand business problems, develop hypotheses, and test those hypotheses with data. How You'll Succeed: Develop and implement machine learning algorithms to analyze large data sets Collaborate with stakeholders to understand business problems and provide data-driven solutions Communicate insights and recommendations to technical and non-technical stakeholders Conduct research to identify emerging trends and technologies Manage and prioritize multiple projects simultaneously Responsibilities: Solve complex business problems with advanced analytics and AI/ML methods Develop and implement predictive models Communicate insights and recommendations to stakeholders Collaborate with cross-functional teams Stay up-to-date with emerging trends and technologies in data science Ensure data quality and accuracy Basic Requirements: Ph.D. in Computer Science, Applied Mathematics focusing on Numerical Analysis, High Performance Computing, Operations Research, Physics, Engineering or quantitative related field OR Master in Computer Science/Computer Engineering or related field with at least 4 years related working experience. Experience with machine learning algorithms and statistical modeling Proficiency in programming languages such as Python or R Additional Preferences: Experience with machine learning algorithms and statistical modeling Proficiency in programming languages such as Python or R Excellent communication and presentation skills Strong problem-solving and analytical skills Ability to work with diverse data sources and data types Familiarity with data visualization Ability to work in a fast-paced, collaborative environment Experience with deep learning algorithms and reinforcement learning Familiarity with cloud computing platforms such as AWS or Azure Knowledge of generative AI applications Experience with data engineering and data pipeline development Strong leadership and project management skills Other Considerations This position is based in Indianapolis, IN Hybrid work schedule Eli Lilly and Company, Lilly USA, LLC and our wholly owned subsidiaries (collectively “Lilly”) are committed to help individuals with disabilities to participate in the workforce and ensure equal opportunity to compete for jobs. If you require an accommodation to submit a resume for positions at Lilly, please email Lilly Human Resources ( Lilly_Recruiting_Compliance@lists.lilly.com ) for further assistance. Please note This email address is intended for use only to request an accommodation as part of the application process. Any other correspondence will not receive a response. Lilly is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status. Our employee resource groups (ERGs) offer strong support networks for their members and help our company develop talented individuals for future leadership roles. Our current groups include: Africa, Middle East, Central Asia Network, African American Network, Chinese Culture Network, Early Career Professionals, Japanese International Leadership Network (JILN), Lilly India Network, Organization of Latinos at Lilly, PRIDE (LGBTQ + Allies), Veterans Leadership Network, Women’s Network, Working and Living with Disabilities. Learn more about all of our groups. #WeAreLilly",
        "url": "https://www.linkedin.com/jobs/view/3942397450",
        "summary": "Lilly, a global healthcare leader, seeks a Data Scientist in Indianapolis to analyze complex datasets, develop predictive models, utilize generative AI, and drive business decisions. The role involves collaborating with cross-functional teams, understanding business problems, developing hypotheses, and testing them with data. Key responsibilities include implementing machine learning algorithms, communicating insights, staying updated on data science trends, and ensuring data quality.",
        "industries": [
            "Healthcare",
            "Pharmaceuticals",
            "Biotechnology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Analytical skills",
            "Problem-solving skills",
            "Communication skills",
            "Attention to detail",
            "Collaboration",
            "Communication",
            "Presentation",
            "Leadership",
            "Project management"
        ],
        "hard_skills": [
            "Machine learning algorithms",
            "Statistical modeling",
            "Python",
            "R",
            "Data visualization",
            "Deep learning algorithms",
            "Reinforcement learning",
            "Cloud computing",
            "AWS",
            "Azure",
            "Generative AI",
            "Data engineering",
            "Data pipeline development"
        ],
        "tech_stack": [
            "Python",
            "R",
            "AWS",
            "Azure",
            "Generative AI"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Master",
            "fields": [
                "Computer Science",
                "Computer Engineering",
                "Applied Mathematics",
                "Numerical Analysis",
                "High Performance Computing",
                "Operations Research",
                "Physics",
                "Engineering",
                "Quantitative related field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Hybrid work schedule"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Baltimore, MD",
        "job_id": 3962062650,
        "company": "Pyramid Consulting, Inc",
        "title": "Senior Data Scientist",
        "created_on": 1720588153.7306652,
        "description": "Immediate need for a talented Senior Data Scientist. This is a 03-06+ months Contract opportunity with long-term potential and is located in Baltimore, MD (Remote). Please review the job description below and contact me ASAP if you are interested. Job ID: 24-22402 Pay Range: 80 -$85/hour. Employee benefits include, but are not limited to, health insurance (medical, dental, vision), 401(k) plan, and paid sick leave (depending on work location). Key Requirements and Technology Experience: Need someone very strong on the Data Science side. If the person is very strong in the data science/ML side, he will bring them on. The Data scientist will know ML. They will be using ML and AI technologies to solve business problems. Python will be very important since it will be the main programming language. AWS is OK to not have. Glue/snowflake/redshift is ok to not have. Machine Learning (use of SageMaker or use of any other tools like Data Robot, or any experience with ML Ops) Hands-on Python (must be very good and comfortable using it) Great communication Data Engineering/AWS – familiarity is ok. Our client is a leading Investment Management industry, and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration. Pyramid Consulting, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",
        "url": "https://www.linkedin.com/jobs/view/3962062650",
        "summary": "Senior Data Scientist contract position with potential for long-term employment.  The role focuses on using ML and AI technologies to solve business problems within the Investment Management industry.  Strong Python skills are required, and familiarity with AWS, Glue, Snowflake, Redshift, SageMaker, DataRobot, or ML Ops is a plus.",
        "industries": [
            "Investment Management"
        ],
        "soft_skills": [
            "Communication"
        ],
        "hard_skills": [
            "Machine Learning",
            "AI",
            "Python",
            "AWS",
            "Glue",
            "Snowflake",
            "Redshift",
            "SageMaker",
            "DataRobot",
            "ML Ops"
        ],
        "tech_stack": [
            "Python",
            "AWS",
            "SageMaker",
            "DataRobot",
            "ML Ops"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 85,
            "min": 80
        },
        "benefits": [
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "401(k) Plan",
            "Paid Sick Leave"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3960695417,
        "company": "Campus4Tech",
        "title": "As a Field Service Technician, are you considering pivoting your career to Data Scientist",
        "created_on": 1720588155.3262336,
        "description": "Are you a Field Service Technician seeking a transformative career change? This opportunity might be the perfect fit for you as you consider transitioning to Data Science Consulting. We are a staffing company specializing in training individuals for roles with our clients. Become an Data Science Consultant (Non-IT or Coding Required) Job Title: Data Science Location: USA/CANADA Visa Status: H4/L2/USC/Work authorization/EAD/CANADA Work permit/Citizen/PR, etc. Note: We provide comprehensive training and placement tailored to meet the requirements of our clients. This course is particularly advantageous for Field Service Technician due to their analytical skills, which are transferable to Data Science concepts. Regardless of your background, Are you a Field Service Technician looking to pivot your career towards Data Science Functional Consulting? Your opportunity for career advancement and an hourly pay ranging from $40/hr to $60/hr awaits! Our clients actively seek Data Science Consultants, and we offer an inclusive training program. Additionally, many positions provide the flexibility to work from the comfort of your home. Role Highlights Audience: Data Science Duration: Flexible schedule tailored to your needs Content Introduction to Data Science Python Basics for Data Science Data Cleaning and Exploratory Data Analysis (EDA) Statistical Analysis with Python Introduction to Machine Learning Advanced Machine Learning Introduction to Deep Learning and Neural Networks Capstone Project and Course Review Features Remote Work Opportunities: Many roles offer the convenience of remote work, enabling you to balance work and life seamlessly. Practical Experience: Engage in real-life projects to gain hands-on experience and enhance your practical skills. Opportunities for All: Data Science Consulting is not exclusive to IT or coding professionals. We welcome individuals from diverse educational backgrounds, providing a unique opportunity to embark on a fulfilling career. Take the First Step: Ready to become an Data Science Consultant and tap into a realm of lucrative opportunities? Please connect with us, Don't miss this chance to enhance your career and achieve financial success",
        "url": "https://www.linkedin.com/jobs/view/3960695417",
        "summary": "This job posting is for a data science consulting training program. It is targeted towards individuals seeking to transition from field service technician roles to data science consulting. The program offers comprehensive training and placement with clients, focusing on data science concepts, Python programming for data science, machine learning, and deep learning.  The training is designed for individuals with no prior IT or coding experience, and many roles offer the flexibility of remote work. The program emphasizes hands-on experience with real-life projects.",
        "industries": [
            "Data Science",
            "Consulting",
            "Staffing",
            "IT",
            "Training"
        ],
        "soft_skills": [
            "Analytical Skills",
            "Problem-Solving",
            "Communication",
            "Teamwork",
            "Time Management"
        ],
        "hard_skills": [
            "Python",
            "Data Cleaning",
            "Exploratory Data Analysis (EDA)",
            "Statistical Analysis",
            "Machine Learning",
            "Deep Learning",
            "Neural Networks"
        ],
        "tech_stack": [
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 60,
            "min": 40
        },
        "benefits": [
            "Remote Work",
            "Practical Experience"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3964309162,
        "company": "Understanding Recruitment",
        "title": "Machine Learning Engineer",
        "created_on": 1720588157.1259105,
        "description": "Position: Machine Learning Engineer – Distributed Systems Are you skilled in various parallelization models (pipeline, data, tensor parallelism) and training strategies (local and global optimization)? Do you excel in optimizing and refining complex systems? Join us as a Machine Learning Engineer focused on distributed systems. You will: Design and Implement robust and efficient systems for executing machine learning tasks on decentralized infrastructures. Optimize Algorithms to continuously enhance the performance and efficiency of ML training processes. Innovate by developing advanced methods and algorithms to address the challenges in distributed ML training. Collaborate and Ensure reproducibility in training processes across various ML domains. Contribute your expertise to technical reports and publications, influencing the broader ML community. What We’re Looking For: Proven Expertise in parallelizing model training across a range of hardware and network configurations. Advanced Skills in creating training systems for large-scale clusters using diverse parallelization models and optimization techniques. Deep Knowledge of networking protocols and communication backends essential for distributed systems. Strong Foundation in computational complexity, algorithms, and data structures. Experience working autonomously in research environments with a high degree of collaboration. Proficiency in Rust and significant involvement in major open-source projects as a maintainer or key contributor. Extra Points For: Published Research in distributed systems or machine learning. Familiarity with blockchain technologies. What’s in It for You: Competitive Salary : $300k - $400k, based on experience. Ready to take on a new challenge in distributed machine learning? Apply now and let's explore how you can make a significant impact!",
        "url": "https://www.linkedin.com/jobs/view/3964309162",
        "summary": "This position requires a Machine Learning Engineer with expertise in distributed systems. Responsibilities include designing and implementing efficient systems for ML tasks on decentralized infrastructures, optimizing training processes, innovating with advanced methods and algorithms, collaborating for reproducible training, and contributing to technical reports and publications. Ideal candidates have proven expertise in parallelizing model training, advanced skills in creating training systems for large-scale clusters, deep knowledge of networking protocols, a strong foundation in computational complexity, algorithms, and data structures, experience in research environments, proficiency in Rust, and significant involvement in open-source projects. Extra points for published research in distributed systems or ML and familiarity with blockchain technologies. The position offers a competitive salary of $300k - $400k based on experience.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-solving",
            "Critical thinking",
            "Research",
            "Innovation"
        ],
        "hard_skills": [
            "Distributed Systems",
            "Machine Learning",
            "Parallelization",
            "Optimization",
            "Algorithms",
            "Data Structures",
            "Networking Protocols",
            "Computational Complexity",
            "Rust"
        ],
        "tech_stack": [
            "Rust",
            "Blockchain"
        ],
        "programming_languages": [
            "Rust"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 400000,
            "min": 300000
        },
        "benefits": [
            "Competitive Salary"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Seattle, WA",
        "job_id": 3970052519,
        "company": "IntePros",
        "title": "Applied Scientist III",
        "created_on": 1720588160.2491362,
        "description": "Compensation Range: $60.00 - $70.50/hr Welcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together. Applied Scientist III IntePros is looking for an Applied Scientist III to work 100% remotely for our Premier Client located in Seattle, WA. This is an exciting role that will work to lead the development and implementation of a new trouble ticket classification model. Key Areas of Responsibility Develop a new ticket classification model using labeled, historical data Collaborate with internal teams to define model requirements, gather data, and interpret results. Implement a robust model testing regime to validate the effectiveness against predefined accuracy metrics. Establish and oversee a continuous improvement strategy for the classification model, including regular data benchmarking and revision schedules. Qualification Bachelors or Master’s degree in an analytically rigorous field (Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics). Experience as an ML engineer or data scientist role building and deploying ML models on the cloud. Experience writing code in Python and SQL, or similar, with documentation for efficient knowledge sharing and reproducibility. Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.",
        "url": "https://www.linkedin.com/jobs/view/3970052519",
        "summary": "IntePros is seeking an Applied Scientist III to work remotely and lead the development and implementation of a new trouble ticket classification model. Responsibilities include model development, collaboration with internal teams, robust model testing, and continuous improvement. The ideal candidate will possess a relevant degree, experience in ML engineering or data science, strong Python and SQL skills, and a track record of success in dynamic environments.",
        "industries": [
            "Technology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Ambiguity Tolerance",
            "Prioritization",
            "Results-Oriented",
            "Data Analysis"
        ],
        "hard_skills": [
            "Machine Learning",
            "Python",
            "SQL",
            "Data Modeling",
            "Model Development",
            "Model Testing",
            "Model Deployment",
            "Data Analysis",
            "Data Interpretation",
            "Data Benchmarking"
        ],
        "tech_stack": [
            "Python",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Statistics",
                "Computer Science",
                "Industrial Engineering",
                "Econometrics"
            ]
        },
        "salary": {
            "max": 7050,
            "min": 6000
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Mental Health",
            "Education and Professional Certification Fund"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967828794,
        "company": "Porch Group",
        "title": "Data Scientist - Pricing",
        "created_on": 1720588168.2245762,
        "description": "Porch Group is a leading vertical software and insurance platform and is positioned to be the best partner to help homebuyers move, maintain, and fully protect their homes. We offer differentiated products and services, with homeowners insurance at the center of this relationship. We differentiate and look to win in the massive and growing homeowners insurance opportunity by 1) providing the best services for homebuyers, 2) led by advantaged underwriting in insurance, 3) to protect the whole home. As a leader in the home services software-as-a-service (“SaaS”) space, we’ve built deep relationships with approximately 30 thousand companies that are key to the home-buying transaction, such as home inspectors, mortgage companies, and title companies. In 2020, Porch Group rang the Nasdaq bell and began trading under the ticker symbol PRCH. We are looking to build a truly great company and are JUST GETTING STARTED. Job Title: Data Scientist - Pricing Location: United States Workplace Type: Remote Job Summary HOA is a Managing General Agent (MGA) and insurance carrier hybrid with high margins and a capital efficient reinsurance strategy which limits retained risk. HOA operates in 15 states, including Texas, Arizona, North Carolina, South Carolina, Virginia, and Georgia. The company was founded in 2006 in Texas, a $10 billion homeowners insurance market, and was the 12th largest home insurer in Texas in 2019. HOA is licensed to operate in 31 states, positioning it for nationwide expansion as part of Porch. HOA, a business unit of Porch Group is seeking a talented Data Scientist specializing in rating algorithms for property insurance. The ideal candidate will play a crucial role in developing and refining our pricing models to accurately assess risk, optimize pricing strategies, and ensure a competitive advantage in the market. This position is part of our innovative Data Science team, which collaborates closely with our actuaries, product management, and other key business units. As a Data Scientist, you will leverage advanced statistical and machine learning techniques to drive data-driven decisions, contributing to our mission of providing superior insurance solutions. Your work will directly impact our ability to deliver competitive and fair pricing to our customers, ensuring regulatory compliance and supporting our growth in the insurance industry. What You Will Do As A Data Scientist Develop and enhance predictive models and algorithms for property insurance pricing using advanced statistical and machine learning techniques. Analyze large datasets to identify trends, patterns, and correlations that influence insurance risk and pricing. Collaborate with actuaries, product management, and business stakeholders to understand business requirements and translate them into actionable analytical solutions. Provide rate filing support by preparing and validating data for regulatory submissions, ensuring compliance with state insurance regulations. Implement and maintain data pipelines and infrastructure necessary for model development and deployment. Conduct rigorous testing and validation of models to ensure accuracy, reliability, and regulatory compliance. Monitor model performance over time, identify areas for improvement, and propose enhancements as needed. Stay current with industry trends and advancements in data science, machine learning, and insurance analytics. What You Will Bring As A Data Scientist Proven experience (3+ years) in developing and deploying pricing models within the insurance industry, preferably homeowners’ insurance. Advanced Degree or equivalent experience in a related field required: Computational Science, Actuarial Science, Math/Applied Math, Statistics/Applied Statistics, or another similar quantitative discipline. Experience with analytics and programming with R and/or Python (3+ years preferred). Strong understanding of insurance principles, risk assessment, and actuarial concepts. Experience with large-scale data analysis, data manipulation, and working with structured and unstructured data. Excellent communication skills with the ability to explain complex analytical concepts and results to non-technical stakeholders. Nice to have skills: Experience with additional programming languages (e.g. SQL) familiarity with insurance-specific tools and systems, and a deeper understanding of state regulatory environments The application window for this position is anticipated to close in 2 weeks (10 business days) from 7/3/24. Please know this may change based on business and interviewing needs. At this time, Porch Group does not consider applicants from the following states for remote positions: Alaska, Arkansas, Delaware, Hawaii, Iowa, Maine, Mississippi, Montana, New Hampshire, and West Virginia. What You Will Get As A Porch Group Team Member Pay Range*: $134,300 - $196,900 annually Please know your actual pay at Porch will reflect a number of factors among which are your work experience and skillsets, job-related knowledge, alignment with market and our Porch employees, as well as your geographic location. Additionally, you will be eligible to receive long-term incentive awards, subject to program guidelines and approvals. Our benefits package will provide you with comprehensive coverage for your health, life, and financial wellbeing. Our traditional healthcare benefits include three (3) Medical plan options, two (2) Dental plan options, and a Vision plan from which to choose. Critical Illness, Hospital Indemnity and Accident plans are offered on a voluntary basis. We offer pre-tax savings options including a partially employer funded Health Savings Account and employee Flexible Savings Accounts including healthcare, dependent care, and transportation savings options. We provide company paid Basic Life and AD&D, Short and Long-Term Disability benefits. We also offer Voluntary Life and AD&D plans. Both traditional and Roth 401(k) plans are available with a discretionary employer match. Headspace is part of our employer paid wellbeing program and provides employees and their families access to on demand guided meditation and mindfulness exercises, mental health coaching, clinical care and online access to confidential resources including will preparation. Brio Health is another employer paid wellbeing tool that offers quarterly wellness challenges and prizes. LifeBalance is a free resource to employees and their families for year-round discounts on things like gym memberships, travel, appliances, movies, pet insurance and more. Our wellness programs include flexible paid vacation, company-paid holidays of typically nine per year, paid sick time, paid parental leave, identity theft program, travel assistance, and fitness and other discounts programs. (NH1) What’s next? Submit your application and our Porch Group Talent Acquisition team will be reviewing your application shortly! If your resume gets us intrigued, we will look to connect with you for a chat to learn more about your background, and then possibly invite you to have virtual interviews. What's important to call out is that we want to make sure not only that you're the right person for us, but also that we're the right next step for you, so come prepared with all the questions you have! Porch is committed to building an inclusive culture of belonging that not only embraces the diversity of our people but also reflects the diversity of the communities in which we work and the customers we serve. We know that the happiest and highest performing teams include people with diverse perspectives that encourage new ways of solving problems, so we strive to attract and develop talent from all backgrounds and create workplaces where everyone feels seen, heard and empowered to bring their full, authentic selves to work. Porch is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable laws, regulations, and ordinances. Porch Group is an E-Verify employer. E-Verify is a web-based system that allows an employer to determine an employee's eligibility to work in the US using information reported on an employee's Form I-9. The E-Verify system confirms eligibility with both the Social Security Administration (SSA) and Department of Homeland Security (DHS). For more information, please go to the USCIS E-Verify website.",
        "url": "https://www.linkedin.com/jobs/view/3967828794",
        "summary": "Porch Group's Homeowners of America (HOA) is seeking a Data Scientist specializing in rating algorithms for property insurance. The role involves developing and refining pricing models, analyzing large datasets, collaborating with actuaries and product management, providing rate filing support, implementing data pipelines, and monitoring model performance. The ideal candidate will have proven experience in insurance pricing models, advanced degree in a quantitative field, expertise in R and Python, understanding of insurance principles, and experience with large-scale data analysis.",
        "industries": [
            "Insurance",
            "Software",
            "SaaS",
            "Home Services",
            "Financial Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Analytical Thinking",
            "Data-Driven Decision Making",
            "Regulatory Compliance",
            "Teamwork",
            "Time Management"
        ],
        "hard_skills": [
            "Predictive Modeling",
            "Machine Learning",
            "Statistical Analysis",
            "Data Analysis",
            "Data Manipulation",
            "Structured and Unstructured Data",
            "R",
            "Python",
            "SQL",
            "Insurance Principles",
            "Risk Assessment",
            "Actuarial Concepts"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SQL"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Advanced Degree",
            "fields": [
                "Computational Science",
                "Actuarial Science",
                "Math",
                "Applied Math",
                "Statistics",
                "Applied Statistics",
                "Quantitative Disciplines"
            ]
        },
        "salary": {
            "max": 196900,
            "min": 134300
        },
        "benefits": [
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Critical Illness",
            "Hospital Indemnity",
            "Accident Insurance",
            "Health Savings Account",
            "Flexible Savings Accounts",
            "Life Insurance",
            "Disability Insurance",
            "401(k) Plan",
            "Wellbeing Program",
            "Paid Vacation",
            "Company-Paid Holidays",
            "Paid Sick Time",
            "Paid Parental Leave",
            "Identity Theft Program",
            "Travel Assistance",
            "Fitness and Other Discounts Programs",
            "Long-Term Incentive Awards"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Phoenix, AZ",
        "job_id": 3959398846,
        "company": "Insight Global",
        "title": "Machine Learning Engineer",
        "created_on": 1720588169.7987127,
        "description": "Role: Machine Learning Engineer Location: hybrid in PHX AZ PR: 50- 58/hr max Duration: contract to potential conversion Must Haves: • 4 to 5+ years of overall, backend Python Development experience. • Must have previous experience working in Machine Learning environments and have experience working with tools/concepts such as LLMs (Large Language Models) and NLP (Natural Language Processing) • Familiarity with Rest APIs/Microservice Architecture. • Experience working with Relational & Non-Relational Databases such as Redis, Cassandra, PostgreSQL, etc. • Hands-on experience with data preprocessing, feature engineering, and model evaluation using Pandas, Numpy, and Scikit-learn. • Strong knowledge of machine learning algorithms, including supervised and unsupervised learning techniques • Experience working with Langchain technologies. Plusses: • Experience working within Cloud Environments such as AWS, GCP or Azure. • Experience working with Rasa. Day to Day: • One of our largest Banking clients is looking for a qualified Python Engineer to join their team. This person should have previous experience working in Machine learning environments. This person should also have experience working with tools/concepts such as LLMs (Large Language Models) and NLP (Natural Language Processing) This team’s focus is on chat automation through Machine Learning to enhance their customer interactions. This role involves tasks such as prompt engineering, building and fine-tuning ML models, developing reusable AI/ML components, and fostering your personal and professional growth.",
        "url": "https://www.linkedin.com/jobs/view/3959398846",
        "summary": "A Machine Learning Engineer is needed for a contract-to-hire position at a major bank in Phoenix, AZ. This role involves building chat automation systems using LLMs and NLP to enhance customer interactions. Responsibilities include prompt engineering, model development and tuning, and creating reusable AI/ML components. ",
        "industries": [
            "Banking",
            "Finance",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Self-Learning"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "LLMs",
            "NLP",
            "REST APIs",
            "Microservices",
            "Redis",
            "Cassandra",
            "PostgreSQL",
            "Pandas",
            "NumPy",
            "Scikit-learn",
            "Supervised Learning",
            "Unsupervised Learning",
            "Langchain",
            "AWS",
            "GCP",
            "Azure",
            "Rasa"
        ],
        "tech_stack": [
            "Python",
            "LLMs",
            "NLP",
            "REST APIs",
            "Microservices",
            "Redis",
            "Cassandra",
            "PostgreSQL",
            "Pandas",
            "NumPy",
            "Scikit-learn",
            "Langchain",
            "AWS",
            "GCP",
            "Azure",
            "Rasa"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 58,
            "min": 50
        },
        "benefits": [
            "Potential conversion to full-time employment"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3961435449,
        "company": "Lawrence Harvey",
        "title": "Senior Data Scientist (CAISO)",
        "created_on": 1720588175.6898623,
        "description": "Senior Data Scientist (CAISO) Our client is a well established start-up leading the way in energy, battery storage systems. About the Role: Development of simulation tools, forecasting methods, and data driven operation optimization algorithms for energy systems Understand various ISO (Independent System Operator) Work closely with cross-functional teams, data engineers, data scientists, and DevOps engineers. Implement metrics to verify model and algorithm effectiveness Senior Data Scientist experience: Must have Power markets or other commodity trading and/or operations domains Power system dispatching Knowledge in some of these: Deep learning, Neural networks, GLM/Regression, Random Forest, Boosting, Trees, Bayesian Optimization, etc. Expert in Python Role: Senior Data Scientist (CAISO) Location: Remote Package: $150-180k + Bonus, Equity, Benefits",
        "url": "https://www.linkedin.com/jobs/view/3961435449",
        "summary": "Senior Data Scientist role focused on developing simulation tools, forecasting methods, and optimization algorithms for energy systems. Requires experience in power markets, trading, and dispatching. Strong Python skills and expertise in various machine learning techniques are essential.",
        "industries": [
            "Energy",
            "Battery Storage",
            "Start-up",
            "Commodity Trading"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "Deep Learning",
            "Neural Networks",
            "GLM",
            "Regression",
            "Random Forest",
            "Boosting",
            "Trees",
            "Bayesian Optimization",
            "Simulation",
            "Forecasting",
            "Optimization Algorithms",
            "Data Driven Operations",
            "Metrics Implementation",
            "Power Markets",
            "Commodity Trading",
            "Power System Dispatching"
        ],
        "tech_stack": [
            "Python",
            "Deep Learning",
            "Neural Networks",
            "GLM",
            "Regression",
            "Random Forest",
            "Boosting",
            "Trees",
            "Bayesian Optimization"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Master's Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Statistics"
            ]
        },
        "salary": {
            "max": 180000,
            "min": 150000
        },
        "benefits": [
            "Bonus",
            "Equity"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Indiana, United States",
        "job_id": 3970025677,
        "company": "U.S. Department of Homeland Security",
        "title": "Artificial Intelligence (AI) Technology Expert",
        "created_on": 1720588177.105887,
        "description": "Help Help Requirements Conditions of Employment You must be a U.S. citizen to apply for this position. Males born after 12/31/1959 must be registered for Selective Service. You must successfully pass a background investigation. You must submit to a pre-employment drug test. You may be required to serve a one-year probationary period. Applying to this announcement certifies that you give permission for DHS to share your application with others in DHS for similar positions. While unusual, you may be required to work other than normal duty hours, which may include evenings, weekends, overtime, and/or on call and standby duty status. You may occasionally be required to travel away from the normal duty station on commercial or even military flights. You must be able to obtain and maintain a security clearance. Qualifications INDIVIDUAL OCCUPATIONAL REQUIREMENT This Position Has An Individual Occupational Requirement That Must Be Met Prior To Meeting The Specialized Experience. Applicant Must Possess IT-related Experience Demonstrating Each Of The Four (4) Competencies Listed Below Attention to Detail - Is thorough when performing work and conscientious about attending to detail. Customer Service - Works with clients and customers (that is, any individuals who use or receive the services or products that your work unit produces, including the general public, individuals who work in the agency, other agencies, or organizations outside the Government) to assess their needs, provide information or assistance, resolve their problems, or satisfy their expectations; knows about available products and services; is committed to providing quality products and services. Oral Communication - Expresses information (for example, ideas or facts) to individuals or groups effectively, taking into account the audience and nature of the information (for example, technical, sensitive, controversial); makes clear and convincing oral presentations; listens to others, attends to nonverbal cues, and responds appropriately. Problem Solving - Identifies problems; determines accuracy and relevance of information; uses sound judgment to generate and evaluate alternatives, and to make recommendations. NOTE: Your resume must explicitly indicate how you meet this requirement, otherwise you will be found ineligible. Specialized Experience To qualify for the GS-15 grade level you must possess and have documented in your resume, one year of specialized experience equivalent to the GS-14 grade level in Federal service or equivalent public or private sector experience performing the following tasks: Applying advanced technical skills in one or more of the following technical areas to successfully complete major projects that use Artificial Intelligence to achieve important mission goals: Human-Centered Design: Using human-centered research and interaction design practices to build systems that are intuitive for users to interact with and rely on underlying AI models and/or systems. Software Engineering: Developing and integrating applications at enterprise scale that leverage AI, machine learning, or algorithmic techniques as a key component of the overall system. AI Security: Addressing vulnerabilities and implementing strategies to mitigate security risks in systems incorporating AI and related technologies. AI/ML Engineering: Designing, implementing, training, and deploying models that utilize AI or machine learning, ensuring they are performant and meet responsible and ethical standards. Data Science: Developing, optimizing, and evaluating models including integrating them into systems to achieve key mission objectives. Product Management: Managing product life cycles that include AI technologies, while developing strategies and metrics to ensure successful delivery and adoption. Technologist: Applying cross-functional skills to advance projects that include AI components, resolving interdisciplinary challenges. Policy Development: Developing and implementing policies related to AI, ensuring compliance with ethical standards, policies, and responsible use guidelines. Executing modern technology practices, such as lean, agile, and human-centered methodologies to rapidly build technology systems at significant scale. Strategically navigating or demonstrating senior roles in projects of cross-functional or diverse teams that foster collaboration or achieve strategic goals. NOTE: Your resume must explicitly indicate how you meet this requirement, otherwise you will be found ineligible. All qualifications and eligibility requirements must be met by the closing date of the announcement. Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional, philanthropic, religious, spiritual, community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience. Shared Certificates: The Department of Homeland Security-HQ shares lists of applicants among DHS-components, and other government agencies hiring for similar roles. You may be referred for consideration to other agencies Hiring Managers throughout the Department for more than one position based on this application. By applying to this announcement, you understand your application materials may be shared with multiple Hiring Mangers throughout DHS-HQ, other DHS components, and other government agencies hiring for similar roles. If additional positions are filled from this announcement conditions of employment may differ. You will be notified if you are referred for additional positions. Current or Former Political Appointees: The Office of Personnel Management (OPM) must authorize employment offers made to current or former political appointees. If you are currently, or have been within the last 5 years, a political Schedule A, Schedule C, Non-career SES or Presidential Appointee employee in the Executive Branch, you must disclose this information to the Human Resources Office. Education There is no education requirement or education substitution for this position. Additional information The salary ranges vary according to the geographic area locality adjustments; therefore rates advertised represent base pay only as pay will depend upon the duty location of the selectee. Please see the 2024 General Schedule (opm.gov) locality pay tables for more information. The Department of Homeland Security encourages persons with disabilities to apply, to include persons with intellectual, severe physical or psychiatric disabilities, as defined by 5 CFR 213.3102(u), and or Disabled Veterans with a compensable service-connected disability of 30 percent or more as defined by 5 CFR 315.707. Veterans, Peace Corps, VISTA volunteers, and persons with disabilities possess a wealth of unique talents, experiences, and competencies that can be invaluable to the DHS mission. If you are a member of one of these groups, you may not have to compete with the public for federal jobs. To determine your eligibility for non-competitive appointment and to understand the required documentation, click on the links above or contact the servicing Human Resources Office listed at the bottom of this announcement. Pursuant to Executive Order 12564 and DHS policy, DHS is committed to maintaining a drug-free workplace and, therefore, conducts random and other drug testing of its employees in order to ensure a safe and healthy work environment. Headquarters personnel in safety- or security-sensitive positions are subject to random drug testing and all applicants tentatively selected for employment at DHS Headquarters are subject to drug testing resulting in a negative test result. You will be required to complete an OGE 450, Confidential Financial Disclosure Form. You may be required to serve a one-year probationary period. If you receive a conditional offer of employment for this position, you will be required to complete an Optional Form 306, Declaration of Federal Employment, and to sign and certify the accuracy of all information in your application, prior to entry on duty. False statements on any part of the application may result in withdrawal of offer of employment, dismissal after beginning work, fine, or imprisonment. Background Investigation: To ensure the accomplishment of our mission, DHS requires every employee to be reliable and trustworthy. To meet those standards, all selected applicants must undergo and successfully pass a background investigation as a condition of placement in this non-sensitive position. This review may include financial issues such as delinquency in the payment of debts, child support and/or tax obligations, as well as certain criminal offenses and illegal use or possession of drugs. Read more Help Help A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. Review our benefits Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.",
        "url": "https://www.linkedin.com/jobs/view/3970025677",
        "summary": "The Department of Homeland Security (DHS) is seeking a highly skilled and experienced individual to fill a GS-15 level position requiring expertise in Artificial Intelligence (AI) and related technologies. The ideal candidate will possess a strong understanding of AI principles and their applications within the DHS mission. Responsibilities include leading projects that leverage AI for mission-critical tasks, developing and implementing AI-driven solutions, and ensuring the ethical and secure use of AI technologies. The position involves collaborating with cross-functional teams, applying modern technology methodologies, and navigating complex projects to achieve strategic goals.",
        "industries": [
            "Government",
            "Security",
            "Technology",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Attention to Detail",
            "Customer Service",
            "Oral Communication",
            "Problem Solving",
            "Collaboration",
            "Strategic Thinking",
            "Leadership"
        ],
        "hard_skills": [
            "Artificial Intelligence",
            "Human-Centered Design",
            "Software Engineering",
            "AI Security",
            "AI/ML Engineering",
            "Data Science",
            "Product Management",
            "Technologist",
            "Policy Development",
            "Lean",
            "Agile",
            "Human-Centered Methodologies"
        ],
        "tech_stack": [
            "Artificial Intelligence (AI)",
            "Machine Learning",
            "AI/ML Engineering",
            "Data Science"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Comprehensive Benefits Package",
            "Health Insurance",
            "Retirement Plan",
            "Life Insurance",
            "Disability Insurance",
            "Paid Time Off",
            "Sick Leave",
            "Training and Development"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Seattle, WA",
        "job_id": 3958100472,
        "company": "Nordstrom",
        "title": "Data Scientist 2 - Marketing Analytics Team (Hybrid - Seattle)",
        "created_on": 1720588183.336185,
        "description": "Job Description Nordstrom is reinventing the retail industry through the power of data and artificial intelligence. The vision for Data Science & Analytics at Nordstrom is to be the best data-driven fashion retailer in the world, and we win by rigorous and thoughtful application data science to solve strategic business challenges. Nordstrom’s centralized Customer Analytics team focuses on supporting executive management with robust decision support data science. Here we build data science products and provide analytics consulting in support of strategic business decisions, including customer segmentation, marketing, company strategy, and digital experience. We work as the quantitative right-hand for the executive team with a passion for supporting data-driven decision making, a devotion to advanced techniques, along with a creative team spirit! We are looking for a creative, curious, and passionate Data Scientist to join our Marketing Analytics team as a Data Scientist II. In this hands-on role, you will build end-to-end data products and machine learning models that transform marketing data into actionable insights and directly inform marketing strategy and investments. The Data Scientist role on the Marketing Optimization Analytics team is responsible for building end-to-end Machine Learning based Analytic Data Products that will directly impact short-term and long-term marketing strategy. This person should utilize proper Data Science techniques and have experience across the full-stack. The role has an opportunity to tackle challenges from ideation to insights delivery, with visibility across the leadership organization. The ideal candidate is a creative self-starter and strong technical contributor who is always looking for new opportunities to solve business problems with data-driven tools. We welcome your curiosity about the business, your passion to unlock rich, nuanced insights from complicated data and the desire to communicate those insights in a way that builds confidence and drives positive business outcomes. We are committed to building teams that reflect the diversity of our customers and active inclusion is core to how Nordstrom wins . We’re an equal opportunity employer and encourage individuals from all backgrounds to apply. If the idea of making a difference in this vibrant intersection of fashion, data science, and technology excites you, join our world-class data science team! A day in the life... Develop and implement analytics applications to extract meaningful insights from large, disparate data sources using Python, R, SQL, and data visualization tools. Build and enhance customized marketing mix models to connect marketing activities to short-term and long-term business outcomes. Optimize marketing investments by leveraging data-driven insights from modeling, forecasting, simulations, and testing. Design and analyze controlled experiments and A/B tests to validate model performance. Liaise with our external measurement vendors (MMM, testing, tracking, etc. ) to ensure robustness of their models and our internal models. Build and deploy robust data models that facilitate scalable statistical modeling and deep dive analyses for marketing use cases. Collaborate with our partner teams to create data science products and solutions for stakeholders, translating questions to robust answers efficiently. Perform large-scale statistical analysis and develop and apply segmentation, predictive models, and forecasting models to key business problems. Work within and across teams to develop and deploy data products and data-driven software, to provide analytical insights. Collaborate with and support consulting analytics teams on needs for ad-hoc analyses. Lead code and documentation reviews, educating the adoption of Data Science/Machine Learning best practices within the center of excellence. Minimum Qualifications Include… 5+ years hands-on professional experience in Data Science and Analytics. 3-5+ years of strong coding skills in at least one statistical or programming language (e.g. R, Python) to import, process, summarize, and analyze data. Experience with utilizing data visualization tools to tell compelling data stories (e.g. Tableau, Shiny, Streamlit) Bachelor’s degree in mathematics, statistics, computer science, economics, operations research or in a quantitative field (or equivalent experience). Expertise in statistical modeling, experimental design, inferential statistics, and machine learning (with particular emphasis in causal measurement, marketing mix models, attribution models, and digital marketing analytics). Familiarity with marketing modeling techniques such as ad stock and carryover effects, the different types of transformations to capture diminishing returns effects in linear models, modeling approaches for capturing synergistic effects of media investments, creative decay/wear-in/wear-out, full funnel measurement. Experience in bridging bottoms-up marketing measurement (like MTA) with top-down approaches (like MMM), and validating these models using experiments. Proficiency with statistical and machine learning algorithms (e.g. regression, decision trees, collaborative filtering, clustering, survival analysis, graph theory, etc.). Proficient in extracting large data sets from various relational databases using SQL (Amazon Redshift, Oracle, Teradata preferred). Our ideal candidate has some combination of the following… MS or PhD in mathematics, statistics, computer science, economics, operations research or in a quantitative field (or equivalent experience). Strong background and proficiency with Causal Measurement methods (Synthetic Control, Causal Impact, Prophet, Causal ML) Ability to research new methodologies in causal measurement, experimental design and marketing attribution. Experience building Marketing Attribution models (Marketing Mix Models, Multi-touch attribution, etc.) Experience of building and maintaining operational models processing large quantity of data in real-world production environments such as SageMaker, AzureML or Kubernetes. Experience building and deploying data apps using R Shiny, Flask, Dash, Streamlit or similar tools Experience using statistical packages in R or Python (Python PYMC3, Causal Forest, strongly preferred) along with clear documentation. Passion and aptitude for turning sophisticated problems into concrete hypotheses that can be answered through meticulous data analysis and A/B testing. Comfortable with ambiguity and creativity in creating solutions for unstructured questions. Deep knowledge of statistical and machine learning algorithms and experience developing and deploying them to production-level systems (using Scikit-Learn, mlpy, MICE, Caret, PyTorch, Keras, or TensorFlow). Experience working in a highly-collaborative environment (e.g. code sharing, using revision control, contributing to team discussions/workshops, and document sharing). Experience developing and deploying data pipelines. Experience using engines such as Apache Spark or Hadoop to analyze large datasets. Experience with data ETL, RESTful APIs. Familiarity with e-commerce analytics topics (e.g., digital tactics, targeting and customer segmentation, lifetime value forecasting, and incremental response modeling, to name a few). You’ll love this Job if You… are a self-directed individual who operates with passion, urgency, focus, and discipline have problem solving skills that are unparalleled are an adaptable team player are detailed-oriented with a knack for precision and accuracy in numbers and analyses are someone who appreciates diversity in all its forms are someone who appreciates a company that values and encourages work-life balance “LOVE” the engineering and architecture portion of data science work gain satisfaction in deploying useful data products that make business impact We’ve got you covered… Our employees are our most important asset and that’s reflected in our benefits. Nordstrom is proud to offer a variety of benefits to support employees and their families, including: Medical/Vision, Dental, Retirement and Paid Time Away Life Insurance and Disability Merchandise Discount and EAP Resources A few more important points... The job posting highlights the most critical responsibilities and requirements of the job. It’s not all-inclusive. There may be additional duties, responsibilities and qualifications for this job. Nordstrom will consider qualified applicants with criminal histories in a manner consistent with all legal requirements. Applicants with disabilities who require assistance or accommodation should contact the nearest Nordstrom location, which can be identified at www.nordstrom.com. © 2022 Nordstrom, Inc Current Nordstrom employees: To apply, log into Workday, click the Careers button and then click Find Jobs. Pay Range Details The pay range(s) below are provided in compliance with state specific laws. Pay ranges may be different in other locations. Washington: $120,500 - $220,500 Annually This position may be eligible for performance-based incentives/bonuses. Benefits include 401k, medical/vision/dental/life/disability insurance options, PTO accruals, Holidays, and more. Eligibility requirements may apply based on location, job level, classification, and length of employment. Learn more in the Nordstrom Benefits Overview by copying and pasting the following URL into your browser: https://careers.nordstrom.com/pdfs/Ben_Overview_17-19.pdf",
        "url": "https://www.linkedin.com/jobs/view/3958100472",
        "summary": "Nordstrom seeks a Data Scientist II for its Marketing Analytics team. The role involves building end-to-end data products and machine learning models using Python, R, SQL, and visualization tools to optimize marketing investments and inform marketing strategy. The candidate must have 5+ years of experience in Data Science, 3-5+ years of coding experience in R/Python, and expertise in statistical modeling, experimental design, and machine learning. Strong communication skills, experience with marketing attribution models, and comfort with ambiguity are desired. ",
        "industries": [
            "Retail",
            "E-commerce",
            "Fashion",
            "Data Science",
            "Marketing",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Teamwork",
            "Adaptability",
            "Detail-Oriented",
            "Creativity",
            "Passion"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Shiny",
            "Streamlit",
            "Statistical Modeling",
            "Experimental Design",
            "Inferential Statistics",
            "Machine Learning",
            "Causal Measurement",
            "Marketing Mix Models",
            "Attribution Models",
            "Digital Marketing Analytics",
            "Ad Stock",
            "Carryover Effects",
            "Transformations",
            "Synergistic Effects",
            "Media Investments",
            "Creative Decay",
            "Wear-In",
            "Wear-Out",
            "Full Funnel Measurement",
            "MTA",
            "MMM",
            "Regression",
            "Decision Trees",
            "Collaborative Filtering",
            "Clustering",
            "Survival Analysis",
            "Graph Theory",
            "Amazon Redshift",
            "Oracle",
            "Teradata",
            "Causal Impact",
            "Prophet",
            "Causal ML",
            "Marketing Attribution",
            "SageMaker",
            "AzureML",
            "Kubernetes",
            "R Shiny",
            "Flask",
            "Dash",
            "Streamlit",
            "PYMC3",
            "Causal Forest",
            "Scikit-Learn",
            "mlpy",
            "MICE",
            "Caret",
            "PyTorch",
            "Keras",
            "TensorFlow",
            "Apache Spark",
            "Hadoop",
            "ETL",
            "RESTful APIs",
            "Digital Tactics",
            "Targeting",
            "Customer Segmentation",
            "Lifetime Value Forecasting",
            "Incremental Response Modeling"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Shiny",
            "Streamlit",
            "Amazon Redshift",
            "Oracle",
            "Teradata",
            "SageMaker",
            "AzureML",
            "Kubernetes",
            "R Shiny",
            "Flask",
            "Dash",
            "Streamlit",
            "PYMC3",
            "Causal Forest",
            "Scikit-Learn",
            "mlpy",
            "MICE",
            "Caret",
            "PyTorch",
            "Keras",
            "TensorFlow",
            "Apache Spark",
            "Hadoop"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Economics",
                "Operations Research",
                "Quantitative Field"
            ]
        },
        "salary": {
            "max": 220500,
            "min": 120500
        },
        "benefits": [
            "Medical/Vision",
            "Dental",
            "Retirement",
            "Paid Time Away",
            "Life Insurance",
            "Disability",
            "Merchandise Discount",
            "EAP Resources",
            "401k",
            "Performance-Based Incentives/Bonuses"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3961763759,
        "company": "Gentiva",
        "title": "Data Scientist - WFH",
        "created_on": 1720588193.3001807,
        "description": "Our Company Gentiva is an industry leader in hospice, palliative, home health, and personal home care. Our place is by the side of those who need us, offering physical, spiritual and emotional support to patients and their families so they may make the most of every moment. We believe that better care for caregivers and clinicians means better care for everyone, so we offer ongoing professional training, lower nurse-to-patient ratios, and comprehensive benefits for eligible employees. Here, you’ll join gifted colleagues who make a lasting difference in people’s lives every day. Overview We are looking for a Data Scientist to join our team. This position will directly report to the Vice President of Actuarial Services and is responsible for partnering with payers, providers and risk bearing entities to create a value based palliative care offering targeting patients approaching end of life. The role will be the first data scientist to join the team and will be instrumental in designing the function to drive value and differentiation in this exciting new business line. Brings industry leading data science tools and techniques to solve key business problems, such as: Identifying patients that would benefit from our care model Risk stratifying patients to align resources to needs Identifying appropriate time for transitioning to next level of care Work with stakeholders throughout the organization to identify opportunities for leveraging data to make models that can generate business insights Explain models and put results in easy to interpret manner such that non-analytic person can understand Build predictive models and machine learning algorithms to analyze large amounts of information to discover trends and patterns About You Bachelors degree in computer science, data science, statistics, mathematics, analytics or related field, master’s degree preferred 2+ years of progressively complex experience in machine learning and analytics Experience with large healthcare analytics projects Preferred experience working with project management tool like Jira Preferred experience with web services DataBricks, Spark, Oracle Cloud, and/or Azure Preferred to be proficient in at least 1 version control tool like git Preferred experience with NLP and Computer Vision tools and libraries such as OpenCV, spaCY, Transformers, Attention models We Offer Comprehensive Benefits Package: Health Insurance, 401k Plan, Tuition Reimbursement, PTO Opportunity to participate in a Fleet Program Competitive Salaries Mileage Reimbursement Professional growth and development opportunities Legalese This is a safety-sensitive position Employee must meet minimum requirements to be eligible for benefits Where applicable, employee must meet stage specific requirements We are proud to be an EEO employer We maintain a drug-free workplace ReqID: 2024-103796 Category: Administrative/Clerical Position Type: Full-Time Company: Gentiva Type of Service: Palliative Care Only",
        "url": "https://www.linkedin.com/jobs/view/3961763759",
        "summary": "Gentiva, a leader in hospice and palliative care, is seeking a Data Scientist to join their team. This role will involve using data science techniques to identify patients who would benefit from their care model, risk stratify patients, and identify appropriate care transitions. The successful candidate will have a background in machine learning and analytics, experience with large healthcare analytics projects, and preferred experience with web services like DataBricks, Spark, Oracle Cloud, and/or Azure.",
        "industries": [
            "Healthcare",
            "Hospice",
            "Palliative Care"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration",
            "Analytical Thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "Analytics",
            "Healthcare Analytics",
            "Predictive Modeling",
            "Data Visualization",
            "Project Management",
            "Data Wrangling",
            "Data Engineering",
            "Statistical Modeling"
        ],
        "tech_stack": [
            "DataBricks",
            "Spark",
            "Oracle Cloud",
            "Azure",
            "Jira",
            "Git",
            "OpenCV",
            "spaCY",
            "Transformers",
            "Attention Models"
        ],
        "programming_languages": [],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics",
                "Analytics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Health Insurance",
            "401k Plan",
            "Tuition Reimbursement",
            "PTO",
            "Fleet Program",
            "Mileage Reimbursement",
            "Professional growth and development opportunities"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York, United States",
        "job_id": 3961830031,
        "company": "myGwork - LGBTQ+ Business Community",
        "title": "Data Scientist – NLP, LLM and GenAI",
        "created_on": 1720588196.8066099,
        "description": "This inclusive employer is a member of myGwork – the largest global platform for the LGBTQ+ business community. About the Role: Grade Level (for internal use): 09 The Role: Data Scientist– NLP, LLM and GenAI S&P is a leader in risk management solutions leveraging automation and AI/ML. This role is a unique opportunity for hands-on entry-level ML scientists and NLP/Gen AI/ LLM scientists to grow into the next step in their career journey and apply her or his technical expertise in NLP, deep learning, GenAI, and LLMs to drive business value for multiple stakeholders while conducting cutting-edge applied research around LLMs, Gen AI, and related areas. Responsibilities: ML, Gen AI, NLP, LLM Model Development: Design and develop custom ML, Gen AI, NLP, LLM Models for batch and stream processing-based AI ML pipelines. Model components will include data ingestion, preprocessing, search and retrieval, Retrieval Augmented Generation (RAG), NLP/LLM model development, fine-tuning and prompt engineering and ensure the solution meets all technical and business requirements. Work closely with other members of data science, MlOps, technology teams in the design, development, and implementation of the ML model solutions. ML, NLP, LLM Model Evaluation: Work closely with the other data science team members to develop, validate, and maintain robust evaluation solutions and tools to evaluate model performance, accuracy, consistency, reliability, during development, UAT. Implement model optimizations to improve system efficiency. NLP, LLM, Gen AI Model Deployment: Work closely with the MLOps team for the deployment of machine learning models into production environments, ensuring reliability and scalability. Internal Collaboration: Collaborate closely with product teams, business stakeholders, Mlops, machine learning engineers, and software engineers to ensure smooth integration of machine learning models into production systems. Documentation: Write and Maintain comprehensive documentation of ML modeling processes and procedures for reference and knowledge sharing. Develop Models Based on Standards and Best Practices: Ensure that the models are designed and developed while adhering to specified standards, governance and best practices in ML model development as specified by senior Data Science and MLOps leads. Assist in Problem Solving: Troubleshoot complex issues related to machine learning model development and data pipelines and develop innovative solutions. What We’re Looking For: Bachelor's / Master’s in Computer Science, Mathematics or Statistics, Computational linguistics, Engineering, or a related field. Hands-on experience leveraging large sets of structured and unstructured data to develop data-driven tactical and strategic analytics and insights using ML, NLP, computer vision solutions. Demonstrated hands-on experience with Python, Hugging Face, TensorFlow, Keras, PyTorch, Spark or similar statistical tools. Expert in python programming. Hands-on experience developing natural language processing (NLP) models, ideally with transformer architectures. Knowledge of information search and retrieval at scale, using a range of solutions ranging from keyword search to semantic search using embeddings. Knowledge of developing or tuning Large Language Models (LLM) and Generative AI (GAI) Knowledge of NLP, LLMs (extractive and generative), fine-tuning and LLM model development. Familiar with higher level trends in LLMs and open-source platforms Nice to have: Experience with contributing to Github and open source initiatives or in research projects and/or participation in Kaggle competitions. Compensation/Benefits Information: S&P Global states that the anticipated base salary range for this position is $85,000 - $150,000. Base salary ranges may vary by geographic location. This role is eligible to receive S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires. About S&P Global Ratings At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions. S&P Global Ratings is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today. For more information, visit www.spglobal.com/ratings What’s In It For You? Our Purpose: Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People: We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values: Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits: We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our benefits include: Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, and Inclusion at S&P Global: At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy. ----------------------------------------------------------- Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. ----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning) Job ID: 298823 Posted On: 2024-06-21 Location: New York, New York, United States",
        "url": "https://www.linkedin.com/jobs/view/3961830031",
        "summary": "S&P Global is seeking a Data Scientist with expertise in NLP, LLMs, and Generative AI to develop and deploy custom ML models for risk management solutions. The role involves designing and implementing AI/ML pipelines, evaluating model performance, and collaborating with various teams for model deployment and integration. Strong Python programming skills and experience with NLP models, transformer architectures, and LLM fine-tuning are essential. The position offers a competitive salary range of $85,000 - $150,000 and a comprehensive benefits package.",
        "industries": [
            "Finance",
            "Risk Management",
            "Data Science",
            "Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Documentation",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "Hugging Face",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Spark",
            "NLP",
            "LLMs",
            "Transformer Architectures",
            "Fine-Tuning",
            "Prompt Engineering",
            "Retrieval Augmented Generation (RAG)",
            "Information Search and Retrieval",
            "Semantic Search",
            "Embeddings",
            "Generative AI",
            "Model Evaluation",
            "Model Optimization",
            "Model Deployment",
            "MLOps",
            "Data Ingestion",
            "Data Preprocessing"
        ],
        "tech_stack": [
            "Python",
            "Hugging Face",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Spark",
            "NLP",
            "LLMs",
            "Transformer Architectures",
            "Fine-Tuning",
            "Prompt Engineering",
            "Retrieval Augmented Generation (RAG)",
            "Information Search and Retrieval",
            "Semantic Search",
            "Embeddings",
            "Generative AI",
            "Model Evaluation",
            "Model Optimization",
            "Model Deployment",
            "MLOps",
            "Data Ingestion",
            "Data Preprocessing"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Mathematics",
                "Statistics",
                "Computational Linguistics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 150000,
            "min": 85000
        },
        "benefits": [
            "Health Insurance",
            "Flexible Time Off",
            "Retirement Plan",
            "Continuing Education Program",
            "Student Loan Contribution",
            "Financial Wellness Programs",
            "Family-Friendly Perks",
            "Retail Discounts",
            "Referral Incentive Awards"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967650892,
        "company": "asobbi",
        "title": "Machine Learning Product Engineer",
        "created_on": 1720588198.4208102,
        "description": "Company Overview: Our client is a leading provider of HPC and advanced technology solutions, specialising in AI infrastructure. They offer customisable cloud solutions designed to support AI teams at every stage of their projects. Primary Duties: Spearhead the creation, design, and supervision of innovative ML products targeting training and inference processes. Develop a comprehensive framework and GPU ML benchmarks for both internal and external applications, aiding marketing and customer-related efforts. Monitor and analyze competitor offerings in the ML/AI cloud service sector, providing insights into market trends. Craft integrations and accompanying documentation for the marketplace through open-source initiatives and collaborations with leading AI vendors. Aid in the development of product content (e.g., use cases, how-to guides) to facilitate customer onboarding. Ensure platform documentation is consistently updated with the latest features and enhancements. Support existing customers in utilizing the infrastructure to guarantee an outstanding user experience. Stay abreast of advancements in AI and machine learning, assessing and integrating new tools and frameworks beneficial to the team. Qualifications: Proficient in English, both written and spoken. Strong communication and interpersonal abilities. Capable of working independently and within a team in a dynamic environment. Deep understanding of the MLOps ecosystem and associated tools. Keen interest in developing the future generation of AI/ML tools. Enthusiastic about working in a fast-paced startup, multitasking, and prioritizing customer satisfaction. Background as a developer or in a similar role. Required Skills: Proficiency in Parallel Training and GPU Cluster Management: Extensive experience in parallel training techniques and managing large-scale training tasks on GPU clusters. Strong Analytical and Problem-Solving Abilities: Competent in tackling complex issues in model training and optimization. Leadership and Mentorship Experience: Demonstrated ability to lead projects and mentor team members. Effective Communication and Team Collaboration: Ability to clearly communicate technical concepts and work well with cross-functional teams. Innovative Mindset and Commitment to Continuous Learning: Dedicated to staying current with the latest AI and machine learning developments. Adaptability and Resilience: Skilled at navigating ambiguity and quickly adapting to a changing business environment.",
        "url": "https://www.linkedin.com/jobs/view/3967650892",
        "summary": "This role involves leading the development and supervision of innovative ML products for training and inference processes. It requires deep expertise in MLOps, parallel training, GPU cluster management, and a strong analytical mindset. The successful candidate will develop benchmarks, monitor competitors, craft integrations, and contribute to product documentation, all while staying current with the latest AI advancements.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Cloud Computing",
            "HPC",
            "Software Development"
        ],
        "soft_skills": [
            "Communication",
            "Interpersonal Skills",
            "Problem-Solving",
            "Leadership",
            "Mentorship",
            "Teamwork",
            "Collaboration",
            "Innovation",
            "Continuous Learning",
            "Adaptability",
            "Resilience"
        ],
        "hard_skills": [
            "Parallel Training",
            "GPU Cluster Management",
            "MLOps",
            "Model Training",
            "Model Optimization"
        ],
        "tech_stack": [
            "GPU Clusters",
            "MLOps Tools",
            "AI Frameworks"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3967707194,
        "company": "Newt Global",
        "title": "Data Scientist - Gen AI - Multilingual",
        "created_on": 1720588214.126802,
        "description": "Sr. Data Scientist - Gen AI Remote Contract Multilingual (Spanish / Portuguese) Looking for Sr. Data Scientist with deep expertise in machine learning, AI and a track record of developing production ML/AI solutions that are business impactful. As part of our team, you will be working side-by-side with high-impact engineers and strategic customers to solve complex problems. You will communicate trends and innovative solutions to stakeholders. You will work cross-functionally with several teams including engineering crews, product teams, and program management to deploy business solutions. Role Specific Requirements Responsibilities Business Understanding and Impact • Learns and understands project objectives and requirements from a business perspective. Assists senior leads with the assessment of a project, including risks, contingencies, requirements, assumptions, and constraints. Contributes to the development of a project plan. Shares insights with stakeholders based on direct work. Data Preparation and Understanding • Assists with initial data collection and familiarizes self with data in order to identify quality problems, discover insights into the data, and/or detect subsets to form hypotheses. • Understands which analysis techniques are appropriate for data and which key technologies and tools are necessary for data exploration (e.g., structured query language [SQL], Python). • Leverages data analysis knowledge to clean, transform, analyze, integrate, and organize data to the level required by the analysis techniques selected. Contributes to the description and exploration of data. • Develops foundational understanding of methodology and standard statistical options and when they should be used. Understands and follows ethics and privacy policies when collecting and preparing data. • Adheres to Microsoft's privacy policy related to collecting and preparing data. Identifies data integrity problems. Modeling and Statistical Analysis • Learns and understands various modeling techniques used within the team (e.g., linear regression, multiple regression, decision-tree building, neural network generation, support machines, derivatives). • Runs model tools on prepared dataset to create one or more models, seeking guidance as needed. • Contributes to the research, identification, prototyping, and productizing of machine learning (ML)/artificial intelligence (AI) techniques and algorithms. • Collaborates with project managers and development engineers to design machine learning and artificial intelligence-driven features in the product. Evaluation • Understands linkage between achieved model and business objectives. Assists with testing models on test applications and on real data or production data. • Analyzes model performance. Incorporates implicit and explicit customer feedback into model evaluation. • Conducts review of data analysis and modeling techniques to determine factors that may have been overlooked or need to be reexamined. Contributes to the summary of the review process. Industry and Research Knowledge/Opportunity Identification • Learns and understands the current state of the industry, including knowledge of tools, techniques, strategies, and processes that can be utilized to improve process efficiency and performance. • Maintains knowledge of current trends within the discipline. Attends internal research conferences and participates in on-hands training, when appropriate. Actively contributes to the body of thought leadership and intellectual property (IP) best practices. Coding and Debugging • Writes readable code for a specific feature, enhancement and/or model, seeking guidance when needed. Contributes to the development, testing, and implementation of changes to optimize code and improve the reliability of systems/solutions. • Develops an understanding of proper debugging techniques such as locating, isolating, and resolving errors and/or defects. • Understands known issues and learns from senior developers/team members. Develops foundational understanding of Agile methodology and when they should be used. Contributes to documentation for productionalisation. Business Management • Develops understanding of data structures and their relationship to Microsoft's customer business. Observes senior engineers and learns best practices in identifying growth opportunities, understanding strategy goals, customer- and product-strategy goals, and exploring opportunities for machine learning (ML) application, seeking guidance when needed. Understands business goals of the customer, per engagement basis. Customer/Partner Orientation",
        "url": "https://www.linkedin.com/jobs/view/3967707194",
        "summary": "We are seeking a Senior Data Scientist with proven expertise in machine learning and AI to develop impactful production ML/AI solutions. This role involves collaborating with engineers and customers to solve complex problems, communicate trends and solutions to stakeholders, and work across teams for deployment. The ideal candidate will have a strong understanding of data analysis techniques, statistical modeling, and industry trends, and will be comfortable with coding and debugging.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Analytical Skills",
            "Time Management",
            "Detail Oriented",
            "Teamwork",
            "Leadership",
            "Project Management"
        ],
        "hard_skills": [
            "Machine Learning",
            "AI",
            "Python",
            "SQL",
            "Linear Regression",
            "Multiple Regression",
            "Decision Tree Building",
            "Neural Network Generation",
            "Support Vector Machines",
            "Derivatives",
            "Data Analysis",
            "Statistical Modeling",
            "Data Cleaning",
            "Data Transformation",
            "Data Integration",
            "Data Organization",
            "Agile Methodology",
            "Debugging"
        ],
        "tech_stack": [
            "Python",
            "SQL"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Beavercreek, OH",
        "job_id": 3967906636,
        "company": "SIERTEK LTD",
        "title": "24.27 Data Scientist",
        "created_on": 1720588215.377579,
        "description": "SierTeK proudly serves our clients by providing expertise in the Program Management, Information Technology, and Administrative Support domains. Founded in 2007 as a minority and service-disabled veteran-owned company, we serve as prime- and subcontractor for a multitude of Federal Department of Defense contracts. By focusing on continual improvement, our services remain at the forefront of our industry, and we pride ourselves on delivering our services with the highest degree of integrity. SierTeK Ltd. is seeking a Data Scientist to support an opportunity remotely . Position Overview Section The employee shall meet all requirements per the basic contract and provide professionally and technically qualified individual(s) to perform all tasks in the following paragraphs to fulfill the requirements of this task order. This effort includes tasks and activities to be performed by the contractor to support the Internal Medicine Branch of USAFSAM Aerospace Medicine Consultation Division specifically to support cardiology data analysis. Essential Job Functions Design data modeling processes to create algorithms and predictive models and perform custom analysis and Identify trends in data sets. Manipulate large data sets and use them to identify trends and reach meaningful conclusions based on research protocols. Clean, aggregate, process, and organize data from disparate sources and transfer it to data warehouses while verifying the integrity of the data for analysis. Provide expertise concerning the validity of assumptions made and the criteria by which alternatives are recommended, as well as advise and recommend new techniques, innovations, and technical and scientific advancements which may serve as a means of overcoming aeromedical operational issues. Draft and/or edit study protocols, proposals, scientific abstracts, manuscripts, slide presentations, and posters as required. Collaborate with professional colleagues, academic partners, medical professionals and government officials to achieve research goals. Interact professionally with all levels of personnel within and outside of the organization. Organize review of relevant scientific literature and attend meetings, as required, with government organizations, academia, and meetings with other experts in their field. Signed Non-Disclosure Agreement (NDA) in place with their company based on the potential access to confidential, proprietary, and/or sensitive information. The NDA shall be provided to the Government Program Manager by start of performance. Minimum Position Requirements Master’s Degree in Data Science or related fields, for example Computer Science or Mathematics, with at least 2 years of experience in their field. Experience can be substituted with a PhD in Computer Science, Computational Geometry, or Data Science. Demonstrated experience of application of machine learning algorithm methods on a variety of data types and sources. Demonstrated experience of application of Topological Data Analysis methods on a variety of data types and source. Demonstrated proficiency in the Python programing language. Demonstrated expert knowledge in operations research and rigorous methods of scientific inquiry and analysis to include statistical analysis, machine learning, computer science, programming, and data storytelling. Highly Desired Qualifications Have experience presenting research at scientific meetings and published in peer reviewed journals in Computational Geometry, Topological Data Analysis or Computational Topology. Publications relating to the subject of Topological Data Analysis Knowledge and application of the Topological Hierarchical Decomposition algorithm Prior military experience, or previous experience working in a military research environment. SierTeK is an equal opportunity employer and values diversity. Employment is decided based on qualifications, merit, and business need. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected Veteran status, gender identity and sexual orientation. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, transfer, leaves of absence, compensation, and training. If you need assistance or accommodation due to a disability, you may contact us at 1+833.743.7835.",
        "url": "https://www.linkedin.com/jobs/view/3967906636",
        "summary": "SierTeK is seeking a Data Scientist with at least 2 years of experience (or a PhD) to support an opportunity remotely. The role involves designing data modeling processes, manipulating large data sets, identifying trends, cleaning and organizing data, providing expertise on data assumptions, drafting scientific documents, collaborating with colleagues and government officials, and reviewing scientific literature.  The ideal candidate will have experience presenting research and publishing in peer reviewed journals related to Computational Geometry, Topological Data Analysis or Computational Topology, and knowledge of the Topological Hierarchical Decomposition algorithm. ",
        "industries": [
            "Aerospace",
            "Defense",
            "Healthcare",
            "Research",
            "Data Science",
            "Computer Science",
            "Mathematics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Presentation",
            "Problem Solving",
            "Analytical Thinking",
            "Critical Thinking",
            "Research",
            "Teamwork",
            "Time Management",
            "Organization"
        ],
        "hard_skills": [
            "Data Modeling",
            "Algorithm Development",
            "Predictive Modeling",
            "Data Analysis",
            "Trend Identification",
            "Data Cleaning",
            "Data Aggregation",
            "Data Processing",
            "Data Organization",
            "Data Warehousing",
            "Data Integrity",
            "Statistical Analysis",
            "Machine Learning",
            "Computer Science",
            "Programming",
            "Data Storytelling",
            "Topological Data Analysis",
            "Python",
            "Computational Geometry",
            "Computational Topology",
            "Topological Hierarchical Decomposition"
        ],
        "tech_stack": [
            "Python",
            "Topological Data Analysis",
            "Machine Learning",
            "Data Warehousing",
            "Statistical Analysis",
            "Computational Geometry",
            "Computational Topology",
            "Topological Hierarchical Decomposition"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Master’s Degree",
            "fields": [
                "Data Science",
                "Computer Science",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Virginia Beach, VA",
        "job_id": 3969885751,
        "company": "Phoenix Recruitment",
        "title": "Junior Machine Learning Engineer",
        "created_on": 1720588219.2847154,
        "description": "This is a remote position. Junior Machine Learning Engineer - US Only Experience: 1+ years Employment Type: Full-time, Remote Base Salary: $65K-$75K Phoenix Recruitment offers a variety of recruiting services to assist both employers and employees. They are specialized in marketing open positions, recruiting, and helping employers to find qualified candidates across various industries. Phoenix Recruitment has expertise in streamlining the hiring process. They can help ensure that the process is efficient, well organized, and compliant with relevant regulations. Summary: As a Junior Machine Learning Engineer, you will have the opportunity to work on exciting projects, develop your skills, and contribute to the development and implementation of machine learning solutions. This is an excellent opportunity for individuals looking to kick-start their careers in machine learning and gain valuable experience in a collaborative and supportive environment. Responsibilities: Collaborate with senior engineers and data scientists to understand project requirements and develop machine learning models and algorithms. Assist in collecting, preprocessing, and analyzing data to uncover patterns and insights. Implement and optimize machine learning models, algorithms, and pipelines. Participate in model evaluation, validation, and performance tuning. Contribute to the development and improvement of existing machine learning infrastructure and frameworks. Stay up-to-date with the latest advancements in machine learning and actively participate in knowledge-sharing activities within the team. Collaborate with cross-functional teams to integrate machine learning solutions into production systems. Document technical processes, methodologies, and outcomes effectively. Qualifications: Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, or a related field. Solid understanding of machine learning fundamentals, algorithms, and statistical concepts. Proficiency in programming languages such as Python, Java, or C++. Familiarity with machine learning frameworks and libraries, such as TensorFlow, PyTorch, or scikit-learn. Experience with data preprocessing, feature engineering, and model evaluation techniques. Knowledge of deep learning architectures and techniques is a plus. Familiarity with big data processing tools (e.g., Hadoop, Spark) is advantageous. Strong problem-solving skills and the ability to work on multiple projects simultaneously. Excellent communication and collaboration skills. Self-motivated with a strong desire to learn and grow in machine learning. Why Phoenix Recruitment LLC? Phoenix Recruitment often has an extensive network of employers and candidates. This network allows them to tap into a pool of qualified candidates and connect them with suitable job opportunities. They can also leverage their connections to help employers find the right talent efficiently. Outsourcing the recruitment process to a specialized agency can save you time and resources, avoid delays, reduce administrative burdens, and increase the chances of finding the right fit for your organization.",
        "url": "https://www.linkedin.com/jobs/view/3969885751",
        "summary": "As a Junior Machine Learning Engineer, you will collaborate with senior engineers and data scientists to develop and implement machine learning solutions. You will collect, preprocess, and analyze data, implement and optimize models and algorithms, and participate in model evaluation and performance tuning. This is an excellent opportunity for individuals looking to kick-start their careers in machine learning and gain valuable experience in a collaborative environment.",
        "industries": [
            "Technology",
            "Machine Learning",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Self-Motivation"
        ],
        "hard_skills": [
            "Python",
            "Java",
            "C++",
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Hadoop",
            "Spark"
        ],
        "tech_stack": [
            "TensorFlow",
            "PyTorch",
            "Scikit-learn",
            "Hadoop",
            "Spark"
        ],
        "programming_languages": [
            "Python",
            "Java",
            "C++"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 75000,
            "min": 65000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Allen, TX",
        "job_id": 3961729914,
        "company": "Horizontal Talent",
        "title": "Data Scientist",
        "created_on": 1720588224.3547637,
        "description": "Job Description : The resource will guide the technical aspects of this data heavy project. They will work hand in hand with our solutions architect to ensure the proper data flows and denormalization is occurring. They need to have had previous experience in complex data analysis, organization, denormalization and transforms.",
        "url": "https://www.linkedin.com/jobs/view/3961729914",
        "summary": "This role involves guiding the technical aspects of a data-heavy project, ensuring proper data flows and denormalization. The ideal candidate will have experience in complex data analysis, organization, denormalization, and data transformations.",
        "industries": [
            "Data Analytics",
            "Data Science",
            "Software Engineering",
            "Information Technology"
        ],
        "soft_skills": [
            "Technical Guidance",
            "Collaboration",
            "Problem Solving"
        ],
        "hard_skills": [
            "Data Analysis",
            "Data Organization",
            "Denormalization",
            "Data Transformation"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "United States",
        "job_id": 3960100763,
        "company": "Veltris",
        "title": "Lead Data Scientist",
        "created_on": 1720588227.458422,
        "description": "3+ years of work experience in writing code in Python • Experience in using various Python libraries like Pandas, NumPy • Experience in writing good quality code in Python and code refactoring techniques (e.g., IDE’s – PyCharm, Visual Studio Code; Libraries – Pylint, pycodestyle, pydocstyle, Black) • Deep understanding of data structures, algorithms, and excellent problem-solving skills • Machine Learning libraries like Scikit-learn, XGBoost • Basic understanding in NLP. • Experience of working with Sequence Models in Deep Learning, like LSTMs, etc. • Deep Learning frameworks like TensorFlow, Keras, PyTorch • Deploying AI solutions into production environment • Experience of model training and serving on any of the cloud environments (AWS, GCP, Azure) • Strong working knowledge of source code control tools such as Git, Bitbucket • Prior experience of designing, developing and maintaining Machine Learning solution through its Life Cycle is highly advantageous",
        "url": "https://www.linkedin.com/jobs/view/3960100763",
        "summary": "This job description seeks a skilled Python developer with a strong foundation in data structures, algorithms, and machine learning. Experience with popular libraries like Pandas, NumPy, Scikit-learn, XGBoost, TensorFlow, Keras, and PyTorch is essential. The ideal candidate will have a deep understanding of NLP and sequence models, coupled with experience in deploying AI solutions in production environments (AWS, GCP, Azure). Knowledge of code version control tools like Git and Bitbucket is also required.",
        "industries": [
            "Technology",
            "Artificial Intelligence",
            "Machine Learning",
            "Software Development"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication"
        ],
        "hard_skills": [
            "Python",
            "Pandas",
            "NumPy",
            "PyCharm",
            "Visual Studio Code",
            "Pylint",
            "pycodestyle",
            "pydocstyle",
            "Black",
            "Data Structures",
            "Algorithms",
            "Machine Learning",
            "Scikit-learn",
            "XGBoost",
            "NLP",
            "LSTMs",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "AWS",
            "GCP",
            "Azure",
            "Git",
            "Bitbucket"
        ],
        "tech_stack": [
            "Python",
            "Pandas",
            "NumPy",
            "PyCharm",
            "Visual Studio Code",
            "Pylint",
            "pycodestyle",
            "pydocstyle",
            "Black",
            "Scikit-learn",
            "XGBoost",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "AWS",
            "GCP",
            "Azure",
            "Git",
            "Bitbucket"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Tulsa, OK",
        "job_id": 3960949307,
        "company": "ORS Nasco",
        "title": "Data Scientist",
        "created_on": 1720588228.8101509,
        "description": "ORS Nasco, LLC, Tulsa, OK. Develop dashboards and business reports to make strategic business decisions across different departments and business units. Conduct research, design, implementation, and validation of algorithms to analyze diverse data sources and the vast collection of data in the databases. Provide in-depth analysis to internal and external customers to identify patterns and to recognize trends. Interpret and analyze data using advanced statistical models and mathematical techniques such as data mining, churn segmentation, cluster analysis, regression analysis, and time series analysis. Implement data management systems of analytic frameworks to drive key business decisions for business leaders. Work with large sets of data to establish accurate and scalable analytics systems across varied applications such as SSRS, SSMS, SAS, R and Power BI. Utilize a variety of reporting tools and software to recommend and apply appropriate analytical and statistical methodologies to execute against a plan or business objective. Bachelor’s degree, or foreign equivalent, in management information systems or a closely related field. Knowledge of SSRS, SSMS, SAS, R, Power BI, Power Bi, and Birst. Domestic travel will be required not more than five times per year.",
        "url": "https://www.linkedin.com/jobs/view/3960949307",
        "summary": "This position is for a data analyst who will use their skills to develop dashboards and business reports, analyze data, implement data management systems, and work with various reporting tools. They will use various software and tools such as SSRS, SSMS, SAS, R and Power BI to execute against business objectives.",
        "industries": [
            "Information Technology",
            "Business Intelligence",
            "Data Analysis",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Decision Making",
            "Presentation",
            "Collaboration",
            "Strategic Thinking"
        ],
        "hard_skills": [
            "Data Mining",
            "Churn Segmentation",
            "Cluster Analysis",
            "Regression Analysis",
            "Time Series Analysis",
            "SSRS",
            "SSMS",
            "SAS",
            "R",
            "Power BI",
            "Birst"
        ],
        "tech_stack": [
            "SSRS",
            "SSMS",
            "SAS",
            "R",
            "Power BI",
            "Birst"
        ],
        "programming_languages": [
            "R"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Management Information Systems",
                "Closely Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Domestic Travel"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Raleigh, NC",
        "job_id": 3968556980,
        "company": "Trident Consulting",
        "title": "Senior Data Scientist",
        "created_on": 1720588238.675904,
        "description": "Trident Consulting is seeking a \" Senior Data Scientist II \" for one of our clients in Raleigh, NC/ Hybrid . A global leader in business and technology services Job Title : Senior Data Scientist Job Location : Raleigh, NC/ Hybrid Job Type : Contract Job Description: We develop the legal profession’s most innovative products for data analysis, visualization, and research. We use the latest techniques in AI, machine learning, and data visualization to uncover insights about legal matters, contracts and legal spend management. As a data scientist on our team, you will work on new product development in a small team environment writing production code in both run-time and build-time environments. You will help propose and build data-driven solutions for high-value customer problems by discovering, extracting, and modeling knowledge from large-scale natural language datasets including matter and contract repository, invoice/legal spend data and work management. You will prototype new ideas, collaborating with other data scientists as well as product designers, data engineers, front-end developers, and a team of expert legal data annotators. You will get the experience of working in a start-up culture with the large datasets and many other resources of an established company. RESPONSIBILITIES Develop and implement LLM-based applications tailored for in-house legal Fine-tune and deploy large language models to enhance their performance on legal text processing tasks Evaluate and help maintain our data assets and training/evaluation data sets Design and build pipelines for preprocessing, annotating, and managing legal document datasets Collaborate with legal experts to understand requirements and ensure models meet domain-specific needs Conduct experiments and evaluate model performance to drive continuous improvements Interface with other technical personnel or team members to finalize requirements. Work closely with other development team members to understand moderately complex product requirements and translate them into software designs. Successfully implement development processes, coding best practices, and code reviews for production environments. REQUIREMENTS Formal training in machine learning: dimensionality reduction, clustering, embeddings, and sequence classification algorithms Experience with deep learning frameworks such as PyTorch, Tensorflow and Hugging Face Transformers. Practical experience in Natural Language Processing methods and libraries such as spaCy, word2vec, TensorFlow, Keras, PyTorch, Flair, BERT Practical experience with large language models, prompt engineering, fine-tuning and benchmarking, using frameworks such as LangChain and LlamaIndex Strong Python background Knowledge of AWS, GCP, Azure, or other cloud platform Understanding of data modeling principles and complex data models. Proficiency with relational and NoSQL databases as well as vector stores (e.g., Postgres, Elasticsearch/OpenSearch, ChromaDB) Knowledge of Scala, Spark, Ray, or other distributed computing systems highly preferred Knowledge of API development, containerization, and machine learning deployment highly preferred Experience with ML Ops/AI Ops highly preferred PREFERRED QUALIFICATIONS MS in Data Science, Computer Science, Statistics, Machine Learning, or related field 2+ years of relevant work experience Or undergraduate degree in relevant field and 4+ years of relevant work experience About Trident: Trident Consulting is an award-winning IT/engineering staffing company founded in 2005 and headquartered in San Ramon, CA. We specialize in placing high-quality vetted technology and engineering professionals in contract and full-time roles. Trident's commitment is to deliver the best and brightest individuals in the industry for our clients' toughest requirements. Some of our recent awards include: • 2022, 2021, 2020 Inc. 5000 fastest-growing private companies in America • 2022, 2021 SF Business Times 100 fastest-growing private companies in Bay Area",
        "url": "https://www.linkedin.com/jobs/view/3968556980",
        "summary": "Trident Consulting is seeking a Senior Data Scientist II to develop innovative legal data analysis, visualization, and research products for a global leader in business and technology services. The role involves working in a small team environment, writing production code, and building data-driven solutions for high-value customer problems using AI, machine learning, and data visualization techniques. The candidate will be responsible for developing LLM-based applications, fine-tuning large language models, evaluating data assets, designing and building data pipelines, collaborating with legal experts, conducting experiments, and interfacing with other technical personnel.",
        "industries": [
            "Legal Technology",
            "Software Development",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Business and Technology Services"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Creativity",
            "Critical Thinking",
            "Detail Oriented",
            "Time Management",
            "Teamwork",
            "Adaptability"
        ],
        "hard_skills": [
            "Machine Learning",
            "Deep Learning",
            "Natural Language Processing",
            "Large Language Models",
            "Prompt Engineering",
            "Fine-tuning",
            "Benchmarking",
            "Python",
            "AWS",
            "GCP",
            "Azure",
            "Data Modeling",
            "Relational Databases",
            "NoSQL Databases",
            "Vector Stores",
            "Scala",
            "Spark",
            "Ray",
            "API Development",
            "Containerization",
            "Machine Learning Deployment",
            "ML Ops",
            "AI Ops"
        ],
        "tech_stack": [
            "PyTorch",
            "TensorFlow",
            "Hugging Face Transformers",
            "spaCy",
            "word2vec",
            "TensorFlow",
            "Keras",
            "PyTorch",
            "Flair",
            "BERT",
            "LangChain",
            "LlamaIndex",
            "Postgres",
            "Elasticsearch",
            "OpenSearch",
            "ChromaDB",
            "Spark",
            "Ray"
        ],
        "programming_languages": [
            "Python",
            "Scala"
        ],
        "experience": 2,
        "education": {
            "min_degree": "MS",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Machine Learning"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Phoenix, AZ",
        "job_id": 3963531072,
        "company": "Goodwill of Central and Northern Arizona",
        "title": "Data Scientist",
        "created_on": 1720588247.8538613,
        "description": "2626 W Beryl Ave Phoenix Arizona, 85021, Position Description: Strong background in SQL Server, PowerBI, SSRS, Tableau, technical writing, SSMS, Azure, Azure Data Studio, Fabric, Python, R, SQL, AWS and DAX. Essential Duties and Responsibilities: Utilizes advanced data analytics techniques to extract insights from complex datasets. Develops and implements machine learning models and algorithms to solve business problems. Creates and maintains data dictionary, data standards, Standard Operation Procedures (SOP), and database schema diagrams. Collaborates with cross-functional teams to understand business requirements and translates them into data-driven solutions. Designs and maintains data pipelines and workflows for efficient data extraction, transformation, and loading. Creates and maintains data visualizations and reports using PowerBI, SSRS, and Tableau. Provides technical documentation and communicates findings to stakeholders in a clear and concise manner. Stays up-to-date with the latest trends and technologies in data science, machine learning, and data warehousing. Maintains regular and consistent in-person attendance. Performs other related duties, as assigned. Minimum Qualifications (Education, Experience, Skills): Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or a related field. Strong proficiency in SQL Server, PowerBI, SSRS, Tableau, and other data visualization tools. Experience with technical writing and documentation. Proficiency in SSMS, Azure, Azure Data Studio, and Fabric. Knowledge of Python, R, SQL, and DAX. Familiarity with the Power Platform and data warehousing concepts. Excellent problem-solving skills and attention to detail. Ability to work independently and collaboratively in a fast-paced environment. Ability to pass a background check and drug screen, where applicable for position. Ability to speak and read English proficiently. You will be eligible for a comprehensive Total Rewards package, 1st of the month following 60 days of employment that includes the following: 5 Medical Plans Employer Funded Health Reimbursement Account (HRA) 3 Dental Plans Vision Plan 401K (Immediate participation upon hire) Employer Paid Life Insurance Employee Assistance Program (EAP) Paid Time Off; Sick and Vacation Paid Holidays These are just a few highlights of our key benefit offerings! Become a valuable part of our team and work for a company which has been named a Best Place to work by the Phoenix Business Journal 4 out of the last 5 years. Work for a company which has seen double digit growth year after year for nearly a decade. Work for a company which values diversity and is centered on success. Goodwill of Central & Northern Arizona - We Put People to Work! Goodwill of Central and Northern Arizona endeavors to make our website accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact HR Support at 602-535-4000, option 5, or RecruitingOperations@goodwillaz.org. We consider applicants for all positions without regard to race, color, religion, sex, sexual orientation, national origin, age, marital or veteran status, the presence of a non-job related medical condition or disability, or any other legally protected status. We will make reasonable accommodation and modification, including adaptive devices, to assist any person with a disability to apply for and, if hired, to perform the duties the position they seek. Assistance could include help in completing on-line application as well as providing alternative communication, e.g., Braille and Large Print. PHISHING SCAM WARNING: Goodwill of Central and Northern Arizona/Goodwill Industries of Monocacy Valley, Inc. (“GCNA/GIMV”) are among several companies recently made aware of a phishing scam involving con artists posing as hiring managers recruiting via email, text and social media. The imposters are creating misleading email accounts, conducting remote “interviews,” and making artificial job offers in order to collect personal and financial information from unsuspecting individuals. Please note that GCNA/GIMV only use company email addresses, which contain “@goodwillaz.org” or @gimv.org”, to communicate with candidates via email. The company also uses secure tools on our website to receive data from applicants and would never ask them to submit their personal banking information to apply for an open job. If you are contacted by someone about an open job at GCNA/GIMV, please verify the domain of the sender’s email address and that they are asking you to apply on this website. If you believe you have been a victim of a phishing scam, please visit the Department of Homeland Security’s Cyber Smart website (https://www.cisa.gov/be-cyber-smart/campaign) to learn how to report it.",
        "url": "https://www.linkedin.com/jobs/view/3963531072",
        "summary": "Data Analyst role at Goodwill of Central & Northern Arizona requiring strong SQL Server, PowerBI, SSRS, Tableau skills. Responsibilities include data analysis, machine learning model development, data pipeline design, report creation, and technical documentation. Requires proficiency in Python, R, and DAX. Offers comprehensive benefits package.",
        "industries": [
            "Non-profit",
            "Social Services",
            "Data Analysis",
            "Machine Learning",
            "Data Warehousing",
            "Technology"
        ],
        "soft_skills": [
            "Problem-solving",
            "Attention to detail",
            "Communication",
            "Collaboration",
            "Technical writing"
        ],
        "hard_skills": [
            "SQL Server",
            "PowerBI",
            "SSRS",
            "Tableau",
            "Python",
            "R",
            "SQL",
            "DAX",
            "SSMS",
            "Azure",
            "Azure Data Studio",
            "Fabric",
            "AWS",
            "Data Dictionary",
            "Data Standards",
            "SOP",
            "Database Schema Diagrams",
            "Machine Learning",
            "Data Pipelines",
            "Data Visualization"
        ],
        "tech_stack": [
            "SQL Server",
            "PowerBI",
            "SSRS",
            "Tableau",
            "Python",
            "R",
            "SQL",
            "DAX",
            "SSMS",
            "Azure",
            "Azure Data Studio",
            "Fabric",
            "AWS",
            "Power Platform"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical Plans",
            "Health Reimbursement Account (HRA)",
            "Dental Plans",
            "Vision Plan",
            "401K",
            "Life Insurance",
            "Employee Assistance Program (EAP)",
            "Paid Time Off",
            "Sick Leave",
            "Vacation",
            "Paid Holidays"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Piscataway, NJ",
        "job_id": 3964394381,
        "company": "First Soft Solutions LLC",
        "title": "Data Scientist",
        "created_on": 1720588250.7107668,
        "description": "We are actively hiring for Data Scientist with AI and ML Remote Primary Objective The individual, in this role, is expected to be comfortable working as a data Science expert and a quantitative researcher. The ideal candidate will have a keen interest in the study of business problems relevant to healthcare domain, and a passion for identifying and answering questions that help us solve the complex business problems. Job Responsibilities Experience working with large data sets, experience working with distributed computing tools Solid understanding of programming logic and various paradigms Ability to mine unstructured data, including Text Mining using statistical tools Develop and optimize deep learning models using PyTorch and TensorFlow to solve complex problems Collaborate with cross-functional teams to gather requirements, design solutions, and deploy scalable machine learning systems. Communicate findings to both business and technical audiences Ability to understand and analyze data models how the data is stored in relational databases Experience in predictive and prescriptive modeling such as Time Series forecasting, Optimization, Regression etc. Conduct experiments, perform data analysis, and iterate on models to improve performance and accuracy. Stay updated with the latest advancements in deep learning and contribute innovative ideas to enhance our Al capabilities. Mentor junior team members and contribute to a collaborative nd innovative environment. Experience in developing deep learning models using PyTorch and TensorFlow. Strong programming skills in Python and proficiency in relevant libraries and frameworks. Experience with cloud platforms (AWS, Azure, GCP) for deploying ML models is a plus",
        "url": "https://www.linkedin.com/jobs/view/3964394381",
        "summary": "We are seeking a Data Scientist with expertise in AI and ML to join our team. The ideal candidate will have a strong understanding of data science principles, experience working with large datasets and distributed computing tools, and proficiency in deep learning using PyTorch and TensorFlow. They will collaborate with cross-functional teams to solve complex business problems in the healthcare domain and contribute to a collaborative and innovative environment.",
        "industries": [
            "Healthcare",
            "Technology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Critical Thinking",
            "Analytical Thinking",
            "Research",
            "Mentorship"
        ],
        "hard_skills": [
            "Data Science",
            "Machine Learning",
            "Deep Learning",
            "PyTorch",
            "TensorFlow",
            "Python",
            "SQL",
            "Distributed Computing",
            "Text Mining",
            "Time Series Forecasting",
            "Optimization",
            "Regression",
            "AWS",
            "Azure",
            "GCP"
        ],
        "tech_stack": [
            "PyTorch",
            "TensorFlow",
            "Python",
            "SQL",
            "AWS",
            "Azure",
            "GCP"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Orlando, FL",
        "job_id": 3961302956,
        "company": "EBG",
        "title": "Lead Data Scientist",
        "created_on": 1720588259.0805886,
        "description": "Company Description EBG is an e-commerce solutions provider specializing in travel and entertainment, and also offering retail products and services, voluntary benefits and insurance. EBG powers a robust portfolio of technology solutions and operates a network of employer and membership-based platforms reaching a captive audience, providing leading brands with incremental distribution opportunities. EBG's expanded network reaches over 100 million users from participating companies and closed loop affinity and membership groups. EBG owns and operates one of the largest and most comprehensive employee savings programs in the country — serving over 40,000 corporate clients through its proprietary platforms TicketsatWork, Plum Benefits, Working Advantage and Beneplace. EBG is a b2b2c company headquartered in Miami (Aventura), with offices in New York, Orlando, Austin and Las Vegas. Job Description EBG has an opening for a talented and experienced Lead Data Scientist to join our dynamic team. The ideal candidate will have a passion for deriving actionable insights from complex datasets and a strong background in machine learning (supervised, semi-supervised & unsupervised), statistical analysis, and data visualization. Conduct exploratory data analysis to identify patterns, trends, and anomalies within large datasets. Develop predictive models and machine learning algorithms to solve business problems and improve decision-making processes. Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions. Clean, preprocess, and manipulate data to ensure accuracy, completeness, and consistency. Implement and deploy scalable solutions for data processing, model training, and evaluation. Interpret model results and communicate findings to stakeholders in a clear and concise manner. Stay updated on the latest advancements in data science, machine learning, and related fields. Mentor junior team members and provide guidance on best practices in data analysis and model development. Qualifications Master's degree or PhD in Data Science, Machine Learning, AI, Computer Science, Statistics, Mathematics, or a related field. PhD preferred Proven experience (3+ years post graduate) as a Sr. or Lead Data Scientist in a fast-paced, commercial environment Have developed algorithms or implemented solutions that include classification, predictive analytics, product recommendation, pattern recognition, sentiment analysis. (E-commerce experience preferred) Proficiency in machine learning (supervised, semi-supervised & unsupervised) Proficiency in Python, specifically using its data manipulation libraries Knowledge and experience with NLP (Natural Language Processing) algorithims and libraries within Python and related languages such as R or Scala. Strong knowledge of statistical analysis techniques, machine learning algorithms, and data visualization tools Experience with big data technologies such as Spark and TensorFlow is a plus Excellent problem-solving skills and ability to work independently as well as part of a team Strong communication and interpersonal skills, with the ability to explain complex concepts to non-technical stakeholders Experience working on teams, across functions and able to present to both technical and non-technical audiences and stakeholders Demonstrated ability to manage multiple projects simultaneously and prioritize tasks effectively Ability to travel on occasion EBG does not offer sponsorship Additional Information Entertainment Benefits Group offers outstanding employee benefits including: Medical, Dental & Vision 401k Match Short Term Disability, Long Term Disability (Company Paid) Basic Life and AD&D (Company Paid) Additional Voluntary Benefits (additional life, legal, critical care, and more) Flexible Work Arrangements 3 Weeks of PTO + 5 Personal Days Paid Holiday Break from Christmas to New Year Paid Holidays Fitness Centers (location dependent) Annual Day of Giving Company Bonus Program Share in the FUN! EBG gives $1000 per year in Tickets-At-Work gift cards to full-time employees to experience and enjoy the savings marketplace!",
        "url": "https://www.linkedin.com/jobs/view/3961302956",
        "summary": "Entertainment Benefits Group (EBG), an e-commerce solutions provider specializing in travel, entertainment, retail, voluntary benefits, and insurance, seeks a Lead Data Scientist. This role involves conducting exploratory data analysis, developing predictive models, collaborating with cross-functional teams, and implementing scalable solutions for data processing, model training, and evaluation. Ideal candidates will have a strong background in machine learning, statistical analysis, and data visualization, with a preference for experience in e-commerce. ",
        "industries": [
            "E-commerce",
            "Travel",
            "Entertainment",
            "Retail",
            "Benefits",
            "Insurance",
            "Technology",
            "Data Science",
            "Machine Learning",
            "AI",
            "Marketing"
        ],
        "soft_skills": [
            "Problem-solving",
            "Communication",
            "Interpersonal",
            "Presentation",
            "Collaboration",
            "Teamwork",
            "Project management",
            "Prioritization"
        ],
        "hard_skills": [
            "Machine Learning",
            "Statistical Analysis",
            "Data Visualization",
            "Python",
            "Data Manipulation Libraries",
            "NLP",
            "Natural Language Processing",
            "Spark",
            "TensorFlow"
        ],
        "tech_stack": [
            "Python",
            "Spark",
            "TensorFlow",
            "NLP"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Scala"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Data Science",
                "Machine Learning",
                "AI",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401k Match",
            "Short Term Disability",
            "Long Term Disability",
            "Basic Life and AD&D",
            "Additional Voluntary Benefits",
            "Flexible Work Arrangements",
            "PTO",
            "Personal Days",
            "Paid Holiday Break",
            "Paid Holidays",
            "Fitness Centers",
            "Annual Day of Giving",
            "Company Bonus Program",
            "Tickets-At-Work gift cards"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Hollywood, FL",
        "job_id": 3961585224,
        "company": "Vakula Technologies Inc",
        "title": "Machine Learning Operations (MLOps) Engineer - AWS (with LLM Focus)",
        "created_on": 1720588264.3903506,
        "description": "Responsibilities LLM-Optimized MLOps Infrastructure: Design and implement MLOps infrastructure on AWS tailored for LLMs, leveraging services like SageMaker, EC2 (with GPU instances), S3, ECS/EKS, Lambda, and more. LLM Deployment Pipelines: Build and manage CI/CD pipelines specifically for LLM deployment, addressing unique challenges like model size, inference optimization, and versioning. LLMOps Practices: Implement LLMOps best practices for monitoring model performance, drift detection, prompt management, and feedback loops for continuous improvement. RESTful API Development: Design and develop RESTful APIs to expose LLM capabilities to other applications and services, ensuring scalability, security, and optimal performance. Model Optimization: Apply techniques like quantization, distillation, and pruning to optimize LLM models for efficient inference on AWS infrastructure. Monitoring and Observability: Establish comprehensive monitoring and alerting mechanisms to track LLM performance, latency, resource utilization, and potential biases. Prompt Engineering and Management: Develop strategies for prompt engineering and management to enhance LLM outputs and ensure consistency and safety. Collaboration: Work closely with data scientists, researchers, and software engineers to integrate LLM models into production systems effectively. Cost Optimization: Continuously optimize LLMOps processes and infrastructure for cost-efficiency while maintaining high performance and reliability. Qualifications Experience: 3+ years of experience in MLOps or a related field, with hands-on experience in deploying and managing LLMs. AWS Expertise: Strong proficiency in AWS services relevant to MLOps and LLMs, including SageMaker, EC2 (with GPU instances), S3, ECS/EKS, Lambda, and API Gateway. LLM Knowledge: Deep understanding of LLM architectures (e.g., Transformers), training techniques, and inference optimization strategies. Programming Skills: Proficiency in Python and experience with infrastructure-as-code tools (e.g., Terraform, CloudFormation), REST API frameworks (e.g., Flask, FastAPI), and LLM libraries (e.g., Hugging Face Transformers). Monitoring: Familiarity with monitoring and logging tools for LLMs, such as Prometheus, Grafana, and CloudWatch. Containerization: Experience with Docker and container orchestration (e.g., Kubernetes, ECS) for LLM deployment. Problem Solving: Excellent problem-solving and troubleshooting skills in the context of LLMs and MLOps. Communication: Strong communication and collaboration skills to effectively work with cross-functional teams. ﻿",
        "url": "https://www.linkedin.com/jobs/view/3961585224",
        "summary": "This is a senior level role focused on building and managing MLOps infrastructure for Large Language Models (LLMs) on AWS. The role requires expertise in AWS services (SageMaker, EC2, S3, ECS/EKS, Lambda, API Gateway), LLM architecture and optimization techniques, and programming skills in Python, Terraform, CloudFormation, Flask/FastAPI, Hugging Face Transformers, Prometheus, Grafana, and CloudWatch. The ideal candidate will have 3+ years of experience in MLOps or a related field, with a deep understanding of LLMs and hands-on experience in deploying and managing them.",
        "industries": [
            "Artificial Intelligence",
            "Machine Learning",
            "Cloud Computing",
            "Software Development"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "MLOps",
            "AWS",
            "SageMaker",
            "EC2",
            "S3",
            "ECS",
            "EKS",
            "Lambda",
            "API Gateway",
            "LLM",
            "Transformers",
            "Python",
            "Terraform",
            "CloudFormation",
            "Flask",
            "FastAPI",
            "Hugging Face Transformers",
            "Prometheus",
            "Grafana",
            "CloudWatch",
            "Docker",
            "Kubernetes"
        ],
        "tech_stack": [
            "AWS",
            "SageMaker",
            "EC2",
            "S3",
            "ECS",
            "EKS",
            "Lambda",
            "API Gateway",
            "Terraform",
            "CloudFormation",
            "Flask",
            "FastAPI",
            "Hugging Face Transformers",
            "Prometheus",
            "Grafana",
            "CloudWatch",
            "Docker",
            "Kubernetes"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Sioux Falls, SD",
        "job_id": 3970710781,
        "company": "Team Remotely Inc",
        "title": "Data Scientist Engineer",
        "created_on": 1720588265.84579,
        "description": "Data Scientist Engineer (1year experience,onsite) Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum. Skills and Abilities: Strong knowledge of R or Python for data analysis and modeling. Proficiency in statistical programs such as R, SAS, MATLAB, or Python. Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology). Basic understanding of SQL, Javascript, XML, JSON, and HTML. Ability to learn new methods quickly and work under deadlines. Excellent teamwork and communication skills. Strong analytical and problem-solving abilities. Basic understanding of SQL, Javascript, XML, JSON, and HTML. Preferred: Knowledge of actuarial concepts and life, health, and/or annuity products. Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc. Familiarity with Microsoft DeployR. Exposure to insurance risk analysis. Basic experience in computational finance, econometrics, statistics, and math. Knowledge of SQL and VBA. Familiarity with R or Python for predictive modeling",
        "url": "https://www.linkedin.com/jobs/view/3970710781",
        "summary": "Data Scientist Engineer position seeking individuals with strong data analysis and modeling skills in R or Python. Experience with statistical programs like R, SAS, MATLAB, or Python is required. Familiarity with spreadsheets and database applications is also essential. Basic understanding of SQL, JavaScript, XML, JSON, and HTML is a must. Preferred candidates will have knowledge of actuarial concepts, experience with statistical modeling techniques, and familiarity with Microsoft DeployR.",
        "industries": [
            "Insurance",
            "Finance",
            "Technology"
        ],
        "soft_skills": [
            "Teamwork",
            "Communication",
            "Analytical",
            "Problem-solving",
            "Learning"
        ],
        "hard_skills": [
            "R",
            "Python",
            "SAS",
            "MATLAB",
            "VBA",
            "Access",
            "Oracle",
            "SQL",
            "JavaScript",
            "XML",
            "JSON",
            "HTML",
            "GLM",
            "Decision Trees",
            "Time Series",
            "Regression",
            "Microsoft DeployR",
            "Insurance Risk Analysis",
            "Computational Finance",
            "Econometrics",
            "Statistics",
            "Math"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SAS",
            "MATLAB",
            "VBA",
            "Access",
            "Oracle",
            "SQL",
            "JavaScript",
            "XML",
            "JSON",
            "HTML",
            "Microsoft DeployR"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SQL",
            "JavaScript"
        ],
        "experience": 1,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 67000,
            "min": 57000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Mateo, CA",
        "job_id": 3959955077,
        "company": "Roblox",
        "title": "Data Scientist - Discovery and Social",
        "created_on": 1720588273.3285584,
        "description": "Every day, tens of millions of people come to Roblox to explore, create, play, learn, and connect with friends in 3D immersive digital experiences– all created by our global community of developers and creators. At Roblox, we’re building the tools and platform that empower our community to bring any experience that they can imagine to life. Our vision is to reimagine the way people come together, from anywhere in the world, and on any device. We’re on a mission to connect a billion people with optimism and civility, and looking for amazing talent to help us get there. A career at Roblox means you’ll be working to shape the future of human interaction, solving unique technical challenges at scale, and helping to create safer, more civil shared experiences for everyone. WHY DATA SCIENCE & ANALYTICS? The Data Science & Analytics organization's mission is to increase our speed, frequency and acumen of making decisions at scale by instilling a data-influenced approach to building products. We cover a wide area of the data spectrum including analytical data engineering, product analytics, experimentation, causal inference, statistical modeling and machine learning. Aligned and partnering with product verticals, we use this extensive tool belt to discover new opportunities and unmet use cases, influence and shape the product roadmap and prioritization, build data products and measure impact on our community of players and developers. WHY DISCOVERY and SOCIAL? Content and co-experience are critical to our platform and drive user engagement. In this role, you will apply your expertise in data science, statistics, and causal inference to evaluate and improve content discovery and socialness within our ecosystem. You will collaborate with cross-functional teams to develop and implement data-driven strategies that maximize the impact of our product and engineering initiatives. This is an opportunity to have an ever growing learning mindset, staying up-to-date with the latest advancements in data science, and exploring a new problem space! You Will Deepen our understanding of friendships, co-experience, and content discovery and their impact towards our overall Roblox ecosystem. Conduct exploratory analysis to identify and advise XFN partners on opportunities for strategic investments. Design and implement experiments for new features and communicate results succinctly to non-technical audiences. Leverage advanced causal inference methodologies to measure the effectiveness of various initiatives, ranging from Roblox events to social features susceptible to network effects. Communicate insights and discuss recommendations with stakeholders translating complex technical concepts into actionable insights. Partner with different product teams to optimize user acquisition strategies through insights, strategy, and leadership. You Have An advanced or equivalent degree in a quantitative field such as Statistics, Economics, Computer Science, or a related field. At least 4+ years of relevant experience in Data Science, with a focus on consumer-facing product teams. Strong knowledge and practical application of statistical methods, causal inference techniques, and experimental design. Experience working with large datasets and proficiency in SQL, R/Python, and data visualization tools. Automate efforts and crunch substantial volumes of data in distributed systems using frameworks such as Spark, Hadoop or Flink Experience working on consumer-facing product teams, ideally on social networks or content recommendation systems. For roles that are based at our headquarters in San Mateo, CA: The starting base pay for this position is as shown below. The actual base pay is dependent upon a variety of job-related factors such as professional background, training, work experience, location, business needs and market demand. Therefore, in some circumstances, the actual salary could fall outside of this expected range. This pay range is subject to change and may be modified in the future. All full-time employees are also eligible for equity compensation and for benefits. Annual Salary Range $200,740—$253,430 USD Roles that are based in our San Mateo, CA Headquarters are in-office Tuesday, Wednesday, and Thursday, with optional in-office on Monday and Friday (unless otherwise noted). You’ll Love Industry-leading compensation package Excellent medical, dental, and vision coverage A rewarding 401k program Flexible vacation policy Roflex - Flexible and supportive work policy Roblox Admin badge for your avatar At Roblox HQ: Free catered lunches five times a week and several fully stocked kitchens with unlimited snacks Onsite fitness center and fitness program credit Annual CalTrain Go Pass Roblox provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. Roblox also provides reasonable accommodations for all candidates during the interview process.",
        "url": "https://www.linkedin.com/jobs/view/3959955077",
        "summary": "Roblox is seeking a Data Scientist to join their Discovery and Social team. This role focuses on improving content discovery and social interaction within the Roblox ecosystem. Responsibilities include conducting exploratory analysis, designing experiments, leveraging causal inference methodologies, and communicating insights to stakeholders. Ideal candidates will have at least 4+ years of experience in Data Science, a strong background in statistics, causal inference, and experimental design, proficiency in SQL, R/Python, and data visualization tools, and experience with large datasets and distributed systems like Spark, Hadoop, or Flink. The role is based in San Mateo, CA and offers a competitive salary and benefits package.",
        "industries": [
            "Technology",
            "Gaming",
            "Social Media",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Strategic Thinking",
            "Leadership",
            "Presentation Skills",
            "Decision Making",
            "Creativity"
        ],
        "hard_skills": [
            "Data Science",
            "Statistics",
            "Causal Inference",
            "Experimental Design",
            "SQL",
            "R",
            "Python",
            "Data Visualization",
            "Spark",
            "Hadoop",
            "Flink"
        ],
        "tech_stack": [
            "SQL",
            "R",
            "Python",
            "Spark",
            "Hadoop",
            "Flink",
            "Data Visualization Tools"
        ],
        "programming_languages": [
            "SQL",
            "R",
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Advanced Degree",
            "fields": [
                "Statistics",
                "Economics",
                "Computer Science",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 253430,
            "min": 200740
        },
        "benefits": [
            "Industry-leading Compensation",
            "Medical, Dental, and Vision Coverage",
            "401k Program",
            "Flexible Vacation Policy",
            "Flexible Work Policy",
            "Roblox Admin Badge",
            "Free Catered Lunches",
            "Fully Stocked Kitchens",
            "Onsite Fitness Center",
            "Fitness Program Credit",
            "Annual CalTrain Go Pass"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Ballwin, MO",
        "job_id": 3963995181,
        "company": "EyeCare Partners",
        "title": "Data Scientist",
        "created_on": 1720588277.7707908,
        "description": "EyeCare Partners is the nation’s leading provider of clinically integrated eye care. Our national network of over 300 ophthalmologists and 700 optometrists provides a lifetime of care to our patients with a mission to enhance vision, advance eye care and improve lives. Based in St. Louis, Missouri, over 650 ECP-affiliated practice locations provide care in 18 states and 80 markets, providing services that span the eye care continuum. For more information, visit www.eyecare-partners.com. Position Overview: We are seeking a talented Data Scientist with at least three years of experience to join our dynamic team. The ideal candidate will possess a deep understanding of data analytics, statistical modeling, and predictive analytics, with a proven track record of leveraging data-driven insights to drive business strategy and growth. Key Responsibilities Utilize Python or R, SQL, and other relevant programming languages to perform data manipulation, data cleansing, and exploratory data analysis on both structured and unstructured datasets. Develop and implement advanced statistical models and machine learning algorithms for marketing predictive modeling/analysis, capacity modeling, customer segmentation, A/B testing, decision trees, clustering, regression analysis, and forecasting. Collaborate closely with cross-functional teams to define key business objectives, identify data-driven opportunities, and develop actionable insights to drive strategic decision-making. Utilize business intelligence tools such as PowerBI to visualize data, create interactive dashboards, and communicate insights to internal and external stakeholders. Lead the design and execution of A/B testing experiments to optimize marketing campaigns, improve customer engagement, and enhance overall business performance. Drive continuous improvement through the evaluation of model performance, refinement of algorithms, and implementation of best practices in data science methodologies. Deliver engaging presentations to senior and executive leadership, effectively communicating complex technical concepts and actionable recommendations in a clear and concise manner. Stay current on emerging trends, tools, and techniques in data science, machine learning, and artificial intelligence, and evaluate their potential applications to enhance business outcomes. Qualifications Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics, or a related field. Minimum of three years of experience in a data science role, with a strong focus on statistical modeling, machine learning, and predictive analytics. Proficiency in Python or R, SQL, and other relevant programming languages and tools for data analysis and modeling. Working knowledge of business intelligence tools such as PowerBI or Tableau is a plus. Experience with marketing predictive modeling/analysis, customer segmentation, A/B testing, decision trees, clustering, regression analysis, and forecasting. Strong analytical skills and problem-solving abilities, with the ability to translate complex data into actionable insights and recommendations. Excellent communication and interpersonal skills, with the ability to collaborate effectively with internal and external stakeholders at all levels of the organization. Proven track record of delivering impactful data-driven solutions to drive business growth and innovation. #ECP",
        "url": "https://www.linkedin.com/jobs/view/3963995181",
        "summary": "EyeCare Partners is seeking a Data Scientist with at least 3 years of experience to analyze structured and unstructured data, develop statistical models and machine learning algorithms, collaborate with cross-functional teams, create dashboards in PowerBI, and optimize marketing campaigns. This role involves communicating insights to leadership and staying current with data science trends.",
        "industries": [
            "Healthcare",
            "Eye Care",
            "Data Science",
            "Analytics",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem-Solving",
            "Presentation",
            "Leadership"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Data Manipulation",
            "Data Cleansing",
            "Exploratory Data Analysis",
            "Statistical Modeling",
            "Machine Learning",
            "Predictive Analytics",
            "Marketing Predictive Modeling",
            "Capacity Modeling",
            "Customer Segmentation",
            "A/B Testing",
            "Decision Trees",
            "Clustering",
            "Regression Analysis",
            "Forecasting",
            "PowerBI",
            "Tableau",
            "Business Intelligence",
            "Data Visualization",
            "Data-Driven Insights",
            "Actionable Recommendations"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "PowerBI",
            "Tableau"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Data Science",
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Bentonville, AR",
        "job_id": 3960576627,
        "company": "InterSources Inc",
        "title": "Data Scientist with ML",
        "created_on": 1720588281.5055268,
        "description": "Responsibilities Data Scientist with ML Location - Bentonville, AR be ready to travel once as required (not frequent) monthly once or twice Long term Languages: SQL, Python, PySpark Cloud computing: experience with GCP preferred, especially with vertex AI. Skills and experiences: o 4 plus years of experience with developing machine learning models and have the right data science skills with problem solving, research and framing into ML problems. 4 plus years of experience with deploying machine learning models into production environments and familiar with MLOps practices, be able to write clean, and production level code. 5 plus years of experience with building Python libraries and APIs (written in Python) 3 plus years of experience with machine learning solutions within merchandising related space domain (assortment, item selection, pricing etc) in mandatory Notes: This is an independent contributor role from day 1 .master's degree is required. Resource can be hybrid but be ready to work during CST time zone and be ready to travel once as required (not frequent) This is a hands-on position and will be working with a team of customer data scientists & ML engineers. The person should be able to explain his or her work and be able to go through models/code. About Us InterSources Inc , a Certified Diverse Supplier, was founded in 2007 and offers innovative solutions to help clients with Digital Transformations across various domains and industries. Our history spans over 16 years and today we are an Award-Winning Global Software Consultancy solving complex problems with technology. We recognize that our employees and our clients are our strengths as the diverse talents and opportunities they bring to the table enable us to grow as a global platform and they are causally linked with our success. We provide strategic and technical advice, and we have expertise in areas covering Artificial Intelligence, Cloud Migration, Custom Software Development, Data Analytics Infrastructure & Cloud Solutions, Cyber Security Services, etc. We make reasonable accommodations for clients and employees and we do not discriminate based on any protected attribute including race, religion, color, national origin, gender sexual orientation, gender identity, age, or marital status. We also are a Google Cloud partner company. We align strategy with execution and provide secure service solutions by developing and using the latest technologies that thrive our resources to deliver industry-leading capabilities to our clients and customers, making it convenient for our clients to do business with InterSources Inc. Our teams also drive growth by refining technology-driven client experiences that put the users first, providing an unparalleled experience. This results in strengthening the core technologies of clients, enabling them to scale with flexibility, create seamless digital experiences and build lifelong relationships.",
        "url": "https://www.linkedin.com/jobs/view/3960576627",
        "summary": "InterSources Inc. seeks a Data Scientist with ML experience to develop and deploy machine learning models in a merchandising context. The role involves problem-solving, research, model building, and production deployment. This is a hands-on position working with customer data scientists and ML engineers, requiring strong communication skills and the ability to explain technical concepts. ",
        "industries": [
            "Software Development",
            "Data Analytics",
            "Artificial Intelligence",
            "Cloud Computing",
            "Merchandising",
            "Retail"
        ],
        "soft_skills": [
            "Problem Solving",
            "Research",
            "Communication",
            "Collaboration"
        ],
        "hard_skills": [
            "SQL",
            "Python",
            "PySpark",
            "Machine Learning",
            "MLOps",
            "GCP",
            "Vertex AI",
            "API Development"
        ],
        "tech_stack": [
            "GCP",
            "Vertex AI",
            "PySpark"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Master's Degree",
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New Jersey, United States",
        "job_id": 3969824126,
        "company": "Antal International",
        "title": "Machine Learning Application Engineer",
        "created_on": 1720588285.9323525,
        "description": "Machine Learning Application Engineer Location: New Jersey, USA / hybrid The Client How many chances in life do you get to be part of a company that has developed the technology and put together a best-in-class team to change the future of many industries? If you have the enthusiasm and drive to join such a company, have a passionate interest in AI, and are an application engineering professional, I would like to hear from you. Meeting the challenges faced by today’s engineering organizations requires making computer-based intelligence the central paradigm of design processes. Their software exploits the power of deep learning to assist leading engineering teams to quickly design outstanding products. Where traditional physical solvers would take days or weeks to evaluate a single design, their neural network-based predictive models allow engineers to test and optimize design ideas in real time. The ML Application Engineering Team Their mission is to support their customers in solving their most complex engineering challenges. They collaborate closely with engineering and design teams within the automotive, aerospace and energy industries, understand their challenges and pains, and help them identify solutions to accelerate their conception processes. They leverage their platform, and its components developed by their software engineers to unlock the value of the most complex Computer-Aided Engineering datasets and to create a direct impact on production design processes. Using 3D deep learning, they empower their customers to develop better products faster. What you will do As a key player in the team, your mission will be to establish trust and admiration from their customers by delivering high-quality technical work. While working towards this goal: You will run projects together with the customer’s engineering teams, develop tailored solutions and analyse data for each project using Python. You will apply their deep learning tools to different engineering/physics problems as well as deliver proofs-of-concept demonstrating how their technology creates value in computer-aided engineering workflows. They will be in contact with customers to demonstrate the value of the platform and transmit the company's vision. You will train their customers to make the most out of their licences and work with them to develop web applications and APIs putting 3D deep learning in production to accelerate their design processes. You will be part of their constant effort to further develop their deep-learning platform by collecting user feedback and relaying it to the product team. You will have the opportunity to work with global leaders and top research departments across different industries towards a new engineering revolution. Who you are A solid background in engineering, preferably aerospace or mechanical (mandatory). Strong experience in Python programming and proficiency in deep learning frameworks (mandatory). A Master's or PhD in Mechanical Engineering, Physics, or a related field. Enjoyment of customer-facing roles, with exceptional communication and teamwork skills. Eagerness to tackle real-world challenges using machine learning. Bonus points for industry experience in CAD/CFD/FEA modelling. You get A competitive salary and generous equity compensation plan - they are growing fast and want their employees to benefit from this growth Work with a world-class technology team The opportunity to contribute to changing the future of engineering - they are confident that their product will change the future of many industries. Work with people who care about you - they support each other and care about you so you can thrive Flexible hybrid schedule Benefits: 25 days of paid vacations per year, healthcare (medical/vision/dental), 401K matching A stimulating and inspiring work environment - they believe in continuous professional and personal growth And important Location: New Jersey, hybrid schedule Start date: May- June 2024 Travelling: This position might require travelling to customer locations. Only U.S. nationals, Green Card holders or candidates with valid working US visas will be considered for this role. The company does not provide any visa sponsorship. Please consider this important information before applying. Contact Peter Wharton [email protected]",
        "url": "https://www.linkedin.com/jobs/view/3969824126",
        "summary": "This role involves applying deep learning technology to solve complex engineering challenges in the automotive, aerospace, and energy industries. As a Machine Learning Application Engineer, you will work with customer engineering teams to develop tailored solutions, deliver proofs-of-concept, train customers on the platform, and contribute to its ongoing development.",
        "industries": [
            "Automotive",
            "Aerospace",
            "Energy"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Customer-Facing",
            "Eagerness to learn"
        ],
        "hard_skills": [
            "Python",
            "Deep Learning",
            "CAD",
            "CFD",
            "FEA"
        ],
        "tech_stack": [
            "Deep Learning",
            "3D Deep Learning",
            "Computer-Aided Engineering (CAE)",
            "Web Applications",
            "APIs"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Mechanical Engineering",
                "Physics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive Salary",
            "Equity Compensation",
            "Flexible Hybrid Schedule",
            "25 Days Paid Vacation",
            "Healthcare",
            "401K Matching",
            "Stimulating Work Environment"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Portland, OR",
        "job_id": 3970708958,
        "company": "Team Remotely Inc",
        "title": "Junior Python Django Developer",
        "created_on": 1720588290.3315034,
        "description": "This is a remote position. Junior Python Django Developer (1 year experience, remote) Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum. About The Job As a Python Django Developer, you will be responsible for developing and maintaining our SaaS product, utilizing Django, Django Rest Framework (DRF), Celery, and MySQL. Your role will involve creating efficient and scalable RESTful services, ensuring high-quality code, and collaborating with cross-functional teams to deliver a superior user experience. Responsibilities: Develop and maintain our SaaS product using Python and Django. Utilize Celery for task scheduling and distributed message passing. Write clean, maintainable, and efficient code, adhering to best practices and coding standards. Optimize application performance, scalability, and reliability. Troubleshoot and debug issues, identifying and implementing solutions. Collaborate with other team members on code reviews and continuous improvement. Stay updated with industry trends and advancements in Django, Python, and related technologies. Qualifications: Bachelor's degree in Computer Science, Software Engineering, or a related field (or equivalent experience). Proven experience as a Python Django Developer, preferably working on SaaS products. Strong proficiency in Python and Django framework. Familiarity with Celery for task scheduling and distributed systems. Proficiency in MySQL or other relational databases. Solid understanding of software development principles and best practices. Strong problem-solving skills and ability to troubleshoot and debug complex issues. Excellent communication and teamwork skills. Self-motivated and able to work independently, as well as in a team environment. Strong attention to detail and commitment to delivering high-quality work.",
        "url": "https://www.linkedin.com/jobs/view/3970708958",
        "summary": "This is a remote, full-time Junior Python Django Developer position seeking someone with 1 year of experience to develop and maintain a SaaS product using Django, Django Rest Framework (DRF), Celery, and MySQL. The role involves creating efficient and scalable RESTful services, ensuring high-quality code, and collaborating with cross-functional teams.",
        "industries": [
            "Software Development",
            "SaaS",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem-Solving",
            "Self-Motivation",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Python",
            "Django",
            "Django Rest Framework (DRF)",
            "Celery",
            "MySQL",
            "Software Development Principles",
            "Best Practices",
            "Troubleshooting",
            "Debugging"
        ],
        "tech_stack": [
            "Python",
            "Django",
            "Django Rest Framework (DRF)",
            "Celery",
            "MySQL",
            "SaaS"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Software Engineering"
            ]
        },
        "salary": {
            "max": 67000,
            "min": 57000
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Carrollton, TX",
        "job_id": 3970147788,
        "company": "Conch Technologies, Inc",
        "title": "Python Software Engineer",
        "created_on": 1720588305.5228524,
        "description": "HI, FULLTIME JOB Python Software Engineer Location – Carrolton, TX – hybrid project Fulltime role Key Skills Expert-level development skills in Python Experience with functional programming paradigms like Aspect Oriented Programming will be a plus. Fluency in formal language design concepts like type systems a plus. A proven track record of architecting complex systems to work efficiently and reliably in mission critical applications. Ability to recognize business risk and surface it to key decision-makers. Experience with quant research processes, methodologies, and tools a mandatory Experience with Financial Data a plus. Thanks and Regards, Markandeya Technical Recruiter Phone: 901.627.3002 Email: markandeya.k@conchtech.com URL: www.conchtech.com",
        "url": "https://www.linkedin.com/jobs/view/3970147788",
        "summary": "Python Software Engineer with expert-level Python development skills, experience in functional programming paradigms and formal language design concepts, proven track record in architecting complex systems for mission-critical applications, risk recognition abilities, and experience with quant research processes and financial data. ",
        "industries": [
            "Software Development",
            "Finance",
            "Technology"
        ],
        "soft_skills": [
            "Problem Solving",
            "Communication",
            "Decision Making",
            "Risk Management",
            "Analytical Skills",
            "Teamwork"
        ],
        "hard_skills": [
            "Python",
            "Aspect Oriented Programming",
            "Type Systems",
            "System Architecture",
            "Quant Research",
            "Financial Data"
        ],
        "tech_stack": [
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Mobile, AL",
        "job_id": 3963958618,
        "company": "ClifyX",
        "title": "Junior to Mid-level Data Scientist",
        "created_on": 1720588307.4383237,
        "description": "Hi, Client Flex Prashant Sir Contract 50-60 max W2 We have over 20+ Junior to Mid-level Data Scientist contract positions available all over US. Here's what you need: Bachelor's Degree or equivalent (12 years) work experience (If an, Associate's Degree with 6 years of work experience) Minimum of 1 year experience with Machine Learning, R, Python or Power BI Minimum of 1 year experience in Data Analysis and Data Visualization The Work: Data analysis using either an exploratory or hypothesis driven approaches. Predictive modeling using machine learning techniques such as generalized linear models and Bayesian inference, and Deep Learning. Work side-by-side with clients to provide bespoke data science consultations. Contribute to the development, and ongoing improvement of our in-house platforms. Provide data science expertise and support as required to the wider organization.",
        "url": "https://www.linkedin.com/jobs/view/3963958618",
        "summary": "Client Flex is seeking multiple Data Scientist contract positions across the US.  These roles require a Bachelor's Degree or equivalent experience, 1+ year of Machine Learning experience with R, Python, or Power BI, and 1+ year of Data Analysis and Visualization experience.  Responsibilities include exploratory and hypothesis-driven data analysis, predictive modeling with machine learning techniques (generalized linear models, Bayesian inference, deep learning), client consultations, platform development, and providing data science support.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Analytics",
            "Consulting"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Client Management",
            "Teamwork",
            "Analytical Thinking"
        ],
        "hard_skills": [
            "Machine Learning",
            "R",
            "Python",
            "Power BI",
            "Data Analysis",
            "Data Visualization",
            "Generalized Linear Models",
            "Bayesian Inference",
            "Deep Learning",
            "Predictive Modeling"
        ],
        "tech_stack": [
            "R",
            "Python",
            "Power BI"
        ],
        "programming_languages": [
            "R",
            "Python"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Data Science",
                "Statistics",
                "Computer Science",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 60,
            "min": 50
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Urbana, MD",
        "job_id": 3967504890,
        "company": "Syntricate Technologies",
        "title": "Data Scientist",
        "created_on": 1720588326.325539,
        "description": "Role 1 Data Scientist Urbana, MD Contract Role Description \"Python Spark Efficient data manipulation Tree based and NN based model training with large data Experience with OCR, layout model File parsing with various file typesLLM, RAG Experience with using REST API Great coding practice Communication Nice to have Databricks Sentiment analysis Insurance especially commercial claims experience / knowledge with medical or injuriesFrench / Swedish language (maybe BA can cover this requirement?) \" Competencies: Digital : Python for Data Science Experience (Years): 8-10 Role 2 Data Scientist Urbana, MD Contract \"Core technical experience: \" Intermediate SQL o Selects, Filter, Joins, Group byo Table creationo Value update / delete \" Advanced Python o Writing efficient code o Modular / reusable code (functions)o Documenting codeo Classeso Processing pipelineso Pandaso Nice To Have Text data processing Document (PDF/Excel) processing \" General git experience \" General agile experience Nice to have experience:\" GPT\" Databricks\" Spark \" Role 3 Data Scientist Urbana, MD Contract \"PythonSQL and general Database knowledgeHandle of PDF / Excel / Word filesLayout modelLLM, RAGExperience with using REST API Experience with software development (python application) Great coding practice Communication Nice to have Databricks Insurance / Cyber knowledge \" Regards, Ashutosh Pasbola Assistant Manager | Syntricate Technologies Inc. Direct: (phone number removed)| Fax: (phone number removed) Email: | Web: We're hiring! connect with us on and visit our Minority Business Enterprise (MBE) Certified | E-Verified Corporation | Equal Employment Opportunity (EEO) Employer This e-mail message may contain confidential or legally privileged information and is intended only for the use of the intended recipient(s). Any unauthorized disclosure, dissemination, distribution, copying or the taking of any action in reliance on the information herein is prohibited. Please notify the sender immediately by email if you have received this email by mistake and delete this e-mail from your system. You have received this email as we have your email address shared by you or from one of our data sources or from our member(s) or subscriber(s) list. If you do not want to receive any further emails or updates, please reply and request to .",
        "url": "https://www.linkedin.com/jobs/view/3967504890",
        "summary": "Data Scientist needed for contract position in Urbana, MD. Responsibilities include efficient data manipulation using Python Spark, model training with large data sets, experience with OCR, layout models, file parsing, LLM, RAG, REST API, and Databricks.  Experience with software development, good coding practices, and communication skills are desired.  Knowledge of insurance, especially commercial claims experience / knowledge with medical or injuries is preferred.  The ideal candidate will have 8-10 years of experience.",
        "industries": [
            "Insurance",
            "Data Science",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Great Coding Practice"
        ],
        "hard_skills": [
            "Python",
            "Spark",
            "SQL",
            "Pandas",
            "OCR",
            "Layout Models",
            "File Parsing",
            "LLM",
            "RAG",
            "REST API",
            "Databricks",
            "Sentiment Analysis",
            "Software Development",
            "Git",
            "Agile"
        ],
        "tech_stack": [
            "Python",
            "Spark",
            "SQL",
            "Pandas",
            "Databricks",
            "REST API"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 8,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Wilmington, DE",
        "job_id": 3964562437,
        "company": "IFF",
        "title": "Scientist R&D Data Analytics",
        "created_on": 1720588333.9855866,
        "description": "Job Description IFF is an industry leader in fragrance, food, beverage, health and biosciences. Here, science and creativity meet to create essential solutions for a better world. IFF Wilmington Delaware (at the Experimental Station Technology and Innovation Center) is a state-of-the-art biotechnology R&D lab. We have talented and creative teams applying cutting edge technology to address customer needs to meet the needs of a growing population, while protecting our environment for future generations. Together, we will #DoMoreGood for people and the planet. Learn more at iff.com. The position will be part of the Data Analytics group within Research and Development and be based at our Wilmington, DE site. As the successful candidate, you will play a crucial role as an R&D Data Engineer enabling the digital transformation of scientific investigations and processes. You will collaborate with Biotech scientists and fellow Data Analytics team members to deliver solutions that will transform how our Biotechnology research is performed. You will also be part of our central Digital Engineering team supporting data management and application development across IFF R&D. Partner with researchers to design robust data capture and visualizations of experimental results. Create database architecture, automated data pipelines, and insightful visualizations. Web application development, deployment, and administration. Participate in cross-functional teams designing new products in various areas. Prototype novel technical solutions aimed at improving the efficiency of IFF R&D. Job Requirements M.S. in Science, Engineering, or Mathematics with 3+ years of experience (B.S. 6+ years) Demonstrated experience delivering end-to-end digital solutions. Proficient in data science programming languages (Python, R, Spark). Proficient in SQL programming and database development (SQLServer, Oracle, PostgreSQL). Familiarity with AWS cloud services (S3, Lambda, Glue). Proficient in application containerization (Docker, Kubernetes). Familiar with version control methodologies (Git/Gitlab). Demonstrated ability to drive projects independently and contribute to multiple projects simultaneously. Experience with experimental science and a healthy curiosity to learn more. Strong teamwork, communication, and presentation skills. Preferred Experience Data or Software Engineering role in Biology, Chemistry, or other Life Science industry. Life Science application experience (KNIME, Benchling). Web application development experience (Django, Flask, React). Proficient with visual analytic software (Power BI, Spotfire). Knowledge of Snowflake data engineering.",
        "url": "https://www.linkedin.com/jobs/view/3964562437",
        "summary": "IFF, a leader in fragrance, food, beverage, health and biosciences, seeks a Data Engineer to join their R&D team in Wilmington, DE. This role will involve collaborating with Biotech scientists, building data capture and visualization solutions, designing database architectures, automating data pipelines, and developing web applications to support digital transformation in research.",
        "industries": [
            "Biotechnology",
            "Science",
            "Research and Development",
            "Engineering",
            "Data Science",
            "Software Engineering",
            "Life Sciences",
            "Chemistry",
            "Biology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Presentation",
            "Curiosity",
            "Problem Solving",
            "Collaboration",
            "Independent Work",
            "Project Management",
            "Technical Expertise",
            "Analytical Skills"
        ],
        "hard_skills": [
            "Python",
            "R",
            "Spark",
            "SQL",
            "SQLServer",
            "Oracle",
            "PostgreSQL",
            "AWS",
            "S3",
            "Lambda",
            "Glue",
            "Docker",
            "Kubernetes",
            "Git",
            "Gitlab",
            "KNIME",
            "Benchling",
            "Django",
            "Flask",
            "React",
            "Power BI",
            "Spotfire",
            "Snowflake"
        ],
        "tech_stack": [
            "Python",
            "R",
            "Spark",
            "SQL",
            "SQLServer",
            "Oracle",
            "PostgreSQL",
            "AWS",
            "S3",
            "Lambda",
            "Glue",
            "Docker",
            "Kubernetes",
            "Git",
            "Gitlab",
            "KNIME",
            "Benchling",
            "Django",
            "Flask",
            "React",
            "Power BI",
            "Spotfire",
            "Snowflake"
        ],
        "programming_languages": [
            "Python",
            "R",
            "Spark",
            "SQL"
        ],
        "experience": 3,
        "education": {
            "min_degree": "M.S.",
            "fields": [
                "Science",
                "Engineering",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Grapevine, TX",
        "job_id": 3961718790,
        "company": "Car Capital Technologies, Inc.",
        "title": "Senior Data Scientist",
        "created_on": 1720588350.8866818,
        "description": "Job Title: Senior Data Scientist / Senior Manager, Data Science / Director, Data Science Location: Grapevine TX, Southern CA, Possible Remote Key Responsibilities: Assess the impact of proposed credit policy changes using historical data and simulation (before/after impact) analysis. Provide recommendations/alternatives to Sr. Management around proposed policy changes based on impact analysis. Enhance existing credit policy framework/rules by applying statistical analysis techniques including machine learning methods and decision trees/regression/conditional probability analysis on historical data to minimize loss exposure and maximize application conversion/business efficiency. Lead development of key statistical modeling initiatives including, but not limited to, credit/application scorecards, cash flow/loss forecasting models, collateral valuation models, behavior/collection scoring models, etc. Monitor application trends to isolate areas of opportunity/risk associated with existing automated decision policy/logic. Manage changes to credit policy through internal decision engine change control / deployment process including translation of business rules into implementation/specifications. Independently test the accuracy of deployments in QA environment using both unit testing and batch testing methods. Build monitoring/tracking reports which assess the effectiveness of model expectations relative to actual performance. Ability to communicate clearly and liaison/develop strong partnerships with other internal resources to ensure on-time/successful implementation of risk management projects/priorities. Translate complex model development code/estimates/methods into clear specifications/requirements for successful implementation into platform workflow technology (i.e., implementation of models outside of statistical software development tool). Lead predictive value and cost/benefit assessment of new/alternative data sources from credit bureau and other alternative data vendors. Contribute to development/enhancement of corporate enterprise data warehouse (EDW), by analyzing existing variables/measures currently in place as well as developing new variables/measures with significant business insight/value. Ability to efficiently/effectively perform other ad-hoc research/analysis as assigned. Qualifications: Minimum 7 to 10 years of working/hands-on experience with statistical model development. Expert level technical experience using at least one statistical software tool (R, Python, SAS, etc.). Expert technical experience with SQL and ability to independently build datasets for advanced analysis and/or modeling exercise. Master’s degree in mathematics, Statistics, Economics/Econometrics, Computer Science, Decision Science, or other related field. Experience in auto or other consumer lending space. Experience with non-prime/deep subprime lending is a plus. Ability to build clear technical model/rule implementation specifications from model development code/process. Highly motivated self-starter with the ability to work independently/remotely. Excellent written and verbal communication skills across all levels and functions. Employee Benefits : Medical, Dental, and Vision coverage 401(k) plan Paid Time Off (PTO) and paid holidays Flexible Spending Accounts (medical & dependent care) Life Insurance Short-Term and Long-Term Disability Insurance Employee Assistance Program Additional Information : Pre-Employment Checks : Background check including credit report and employment references (must be favorable). Commitment to Diversity : Car Capital is an AA/EEO employer dedicated to equal opportunity and employee diversity.",
        "url": "https://www.linkedin.com/jobs/view/3961718790",
        "summary": "Senior Data Scientist / Senior Manager, Data Science / Director, Data Science role at Car Capital. Responsibilities include credit policy analysis, model development (credit scorecards, cash flow/loss forecasting, collateral valuation, behavior/collection scoring), data analysis, model implementation, and partnership with internal resources. Requires 7-10 years experience in statistical model development, expertise in R/Python/SAS, SQL, and a Master's degree in a related field. Experience in auto or consumer lending, particularly non-prime/deep subprime, is a plus.",
        "industries": [
            "Financial Services",
            "Automotive",
            "Data Science",
            "Analytics",
            "Risk Management"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Decision Making",
            "Leadership",
            "Time Management",
            "Self-Motivation",
            "Independent Work"
        ],
        "hard_skills": [
            "Statistical Modeling",
            "Machine Learning",
            "Decision Trees",
            "Regression",
            "Conditional Probability",
            "Credit Scorecards",
            "Cash Flow Forecasting",
            "Collateral Valuation",
            "Behavior Scoring",
            "Collection Scoring",
            "SQL",
            "R",
            "Python",
            "SAS"
        ],
        "tech_stack": [
            "R",
            "Python",
            "SAS",
            "SQL",
            "Decision Engine",
            "Credit Bureau Data",
            "Alternative Data Vendors",
            "Enterprise Data Warehouse (EDW)"
        ],
        "programming_languages": [
            "R",
            "Python",
            "SAS",
            "SQL"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Mathematics",
                "Statistics",
                "Economics",
                "Econometrics",
                "Computer Science",
                "Decision Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "401(k)",
            "Paid Time Off (PTO)",
            "Paid Holidays",
            "Flexible Spending Accounts",
            "Life Insurance",
            "Short-Term Disability",
            "Long-Term Disability",
            "Employee Assistance Program"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Sioux Falls, SD",
        "job_id": 3970715169,
        "company": "Team Remotely Inc",
        "title": "Junior Python Developer",
        "created_on": 1720588371.0055447,
        "description": "(1 year experience,onsite) Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $58K-$68K Per Annum. Description: In this role, you will work closely with senior developers and other cross-functional teams to develop and maintain high-quality Python applications. As a Junior Python Developer, you will have the opportunity to learn and grow your skills while contributing to exciting projects. Responsibilities: Collaborate with senior developers to design and develop Python applications. Write clean, efficient, and maintainable code that follows best practices. Participate in code reviews and provide constructive feedback. Debug and fix issues in the existing codebase. Assist in testing and quality assurance processes. Stay updated with the latest trends and technologies in Python development. Requirements: Bachelor's degree in Computer Science, Software Engineering, or a related field. Strong knowledge of Python programming language. Familiarity with web frameworks such as Django or Flask. Experience with version control systems, preferably Git. Basic understanding of front-end technologies (HTML, CSS, JavaScript). Good problem-solving and analytical skills. Excellent communication and teamwork abilities. Self-motivated and eager to learn. Nice to have: Experience with database systems such as MySQL, PostgreSQL, or MongoDB. Knowledge of RESTful APIs and integration. Familiarity with cloud platforms such as AWS or Azure. Understanding of agile development methodologies. Benefits: Flexible vacation, unlimited paid holidays, and paid sick days 401(k) with up to 2% employer match Health, vision, and dental insurance",
        "url": "https://www.linkedin.com/jobs/view/3970715169",
        "summary": "Junior Python Developer role working on developing and maintaining Python applications with a focus on Django or Flask frameworks. Collaboration with senior developers, code reviews, debugging, and staying updated with latest Python technologies are key responsibilities. Experience with version control systems (Git), front-end technologies (HTML, CSS, JavaScript), database systems (MySQL, PostgreSQL, MongoDB), RESTful APIs, cloud platforms (AWS or Azure), and agile development methodologies are considered advantageous.",
        "industries": [
            "Software Development",
            "Information Technology"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem-solving",
            "Analytical",
            "Self-motivation",
            "Eager to learn"
        ],
        "hard_skills": [
            "Python",
            "Django",
            "Flask",
            "Git",
            "HTML",
            "CSS",
            "JavaScript",
            "MySQL",
            "PostgreSQL",
            "MongoDB",
            "RESTful APIs",
            "AWS",
            "Azure",
            "Agile"
        ],
        "tech_stack": [
            "Python",
            "Django",
            "Flask",
            "Git",
            "HTML",
            "CSS",
            "JavaScript",
            "MySQL",
            "PostgreSQL",
            "MongoDB",
            "RESTful APIs",
            "AWS",
            "Azure"
        ],
        "programming_languages": [
            "Python",
            "JavaScript"
        ],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Software Engineering"
            ]
        },
        "salary": {
            "max": 68000,
            "min": 58000
        },
        "benefits": [
            "Flexible vacation",
            "Unlimited paid holidays",
            "Paid sick days",
            "401(k) with employer match",
            "Health insurance",
            "Vision insurance",
            "Dental insurance"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Burlington, NJ",
        "job_id": 3968232016,
        "company": "Burlington Stores, Inc.",
        "title": "Shortage Data Scientist I",
        "created_on": 1720588388.803469,
        "description": "LOCATION 1830 Route 130 North Burlington NJ US 08016 Overview The Shortage Data Scientist I will support the Director of Shortage Analysis in leveraging internal and external data to understand the drivers of merchandise shortage across the company. They will be a subject matter expert in measuring the impact of investments to reduce shortage and a key contributor to determining how best to allocate resources to reduce shortage. The Shortage Data Scientist will maintain a database of all shortage focused projects and track their expected and realized impact. They will be responsible for analyzing the impact of initiatives as well as other shortage trends to develop actionable insights. They will also help inform testing setups and ROI calculation for shortage initiatives. This person will support the Director in preparing to present shortage trends and findings following each inventory cycle. They will schedule and organize the applicable executive meetings and coordinate with cross-functional partners to organize materials. They will also prepare materials to communicate their findings in a clear and actionable manner to executive leadership. A Day In The Life: Maintain, clean and organize disparate datasets including a database of all shortage focused initiatives. Track and measure the targeted and actual impact of each shortage improvement initiative over time, leveraging AB testing and predictive modeling. Perform analyses on shortage trends and leverage data visualization tools to identify actionable insights and address executive questions on shortage drivers. Develop materials for post-PI executive results meetings to clearly communicate new trends and learnings following each inventory cycle. Schedule and support post-PI executive results meetings administratively. Act as a subject matter expert of the impact of shortage initiatives, consulting on testing design and rollout proposals, capital requests and any other areas needed. You'll Come With: Bachelor’s degree required, preferably in a STEM or data driven field. Training in data science preferred. 2-5 years of experience in data science and analytics. 1-2 years of AB testing and predictive modeling experience preferred. Retail experience preferred. Experience in using multiple data sources to model complex business situations. Experience cleaning, organizing, and maintaining disparate datasets Proficient in R or Python Proficient in data visualization tool such as PowerBI or Tableau Experience organizing, tracking, and monitoring the progress of complex initiatives. Strong written and verbal communication with emphasis on strong inter-personal skills. Experience working with multiple levels of management and in cross-functional environments. Proven ability to work independently to drive projects to completion. Retail experience with shortage focus preferred. Expert Excel skills. Proficient with PowerPoint. This position is a hybrid role & candidates must be able to be onsite in Burlington, NJ. Scope and Impact: Accountable for tracking, measuring, and reporting the impact of shortage reduction initiatives. Responsible for analyzing shortage trends and performing ad hoc analyses to understand the drivers of shortage. Responsible for consulting on AB testing and ROI forecasting to be used for shortage investments. This position has a significant role in ensuring executive leadership is informed of shortage trends and opportunities and that investments in shortage are data driven. Come join our team. You’re going to like it here! You will enjoy a competitive wage, flexible hours, and an associate discount. Burlington’s benefits package includes medical, dental and vision coverage including life and disability insurance. Full time associates are also eligible for paid time off, paid holidays and a 401(k) plan. We are a rapidly growing brand, and provide a variety of training and development opportunities so our associates can grow with us. Our teams work hard and have fun together! Burlington associates make a difference in the lives of customers, colleagues, and the communities where we live and work every day. Burlington Stores, Inc. is an equal opportunity employer committed to workplace diversity. \\ \\ Posting Number 2024-224859 Location US-NJ-Burlington Address 1830 Route 130 North Zip Code 08016 Workplace Type Hybrid Position Type Regular Full-Time Career Site Category Corporate Position Category Finance Evergreen Yes Min USD $80,000.00/Annual Mid USD $105,000.00/Annual",
        "url": "https://www.linkedin.com/jobs/view/3968232016",
        "summary": "The Shortage Data Scientist I will be responsible for analyzing shortage trends and drivers across the company, measuring the impact of investments to reduce shortage, and developing actionable insights. They will maintain a database of all shortage focused projects, track their expected and realized impact, and consult on testing design and rollout proposals.  This is a hybrid role located in Burlington, NJ.",
        "industries": [
            "Retail"
        ],
        "soft_skills": [
            "Communication",
            "Interpersonal skills",
            "Problem-solving",
            "Analytical",
            "Organization",
            "Project Management",
            "Collaboration"
        ],
        "hard_skills": [
            "Data Science",
            "Analytics",
            "AB Testing",
            "Predictive Modeling",
            "Data Visualization",
            "SQL",
            "R",
            "Python",
            "PowerBI",
            "Tableau",
            "Excel",
            "PowerPoint"
        ],
        "tech_stack": [
            "R",
            "Python",
            "PowerBI",
            "Tableau",
            "Excel",
            "PowerPoint"
        ],
        "programming_languages": [
            "R",
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "STEM",
                "Data Science"
            ]
        },
        "salary": {
            "max": 105000,
            "min": 80000
        },
        "benefits": [
            "Competitive Wage",
            "Flexible Hours",
            "Associate Discount",
            "Medical",
            "Dental",
            "Vision",
            "Life Insurance",
            "Disability Insurance",
            "Paid Time Off",
            "Paid Holidays",
            "401(k)",
            "Training and Development Opportunities"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New Orleans, LA",
        "job_id": 3969037816,
        "company": "The Times-Picayune | Nola.com",
        "title": "Research Scientist I",
        "created_on": 1720588423.5687745,
        "description": "Research Scientists are individuals holding a M.D. or equivalent terminal degree who play a major role in enabling research programs through collaborative and collegial interactions with faculty, postdoctoral fellows, graduate students and staff. The rank of the research scientist is a staff appointment. A research scientist may apply his/her effort entirely to research, or a combination of research, training, and lab managerial activities. The classification of Research Scientist I is the entry level position in the job hierarchy.",
        "url": "https://www.linkedin.com/jobs/view/3969037816",
        "summary": "Research Scientists with M.D. or equivalent degrees contribute to research programs through collaborations with faculty, fellows, students, and staff. This staff appointment can focus solely on research or combine research, training, and lab management.",
        "industries": [
            "Research",
            "Higher Education",
            "Healthcare",
            "Life Sciences"
        ],
        "soft_skills": [
            "Collaboration",
            "Collegiality",
            "Communication",
            "Teamwork",
            "Training",
            "Management"
        ],
        "hard_skills": [],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": "M.D. or equivalent terminal degree",
            "fields": [
                "Medicine",
                "Life Sciences",
                "Research"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Charlotte, NC",
        "job_id": 3967725930,
        "company": "Truist Wealth",
        "title": "Data Scientist",
        "created_on": 1720588424.9920168,
        "description": "Reporting to the Data & Analytics Manager, the Data Scientist is accountable for providing data analytics to Truist Wealth, across the full suite of products and client experience. While working with Sr. Data Scientist and the Data Scientist Team Leader the primary focus areas include portfolio, scenario, and strategic analysis, and ad-hoc Executive analytics. Other focus areas include marketing campaign response, evaluating success of strategic initiatives, account acquisition and management, delinquency and default, overall portfolio asset quality, and portfolio acquisitions and divestitures. Please Note: This role can be based in Charlotte or Atlanta. Following is a summary of the essential functions for this job. Other duties may be performed, both major and minor, which are not mentioned below. Specific activities may change from time to time. Translate business opportunities into data science problems by defining project scope and performance metrics to measure success Perform sophisticated data analytics (encompassing data mining, inferential statistical analysis, and predictive analytics, for example) utilizing internal and external data Work with Sr. Data Scientist and Data Scientist Team Leader to identify actionable insights that measurably improve business outcomes or reduces business risk through complex analysis that results in successfully presenting findings to key stakeholder Work with Sr. Data Scientist and Data Scientist Team Leader to story tell with data by creating clear, concise, and relevant presentations that leverage data visualization tools to highlight and communicate opportunity to business stakeholders Collect and prepare data for reporting, analysis, and ad hoc request which encompasses exploratory to advanced predictive and/or modeling analytics to identify data relationships, patterns, and trends. Collaborate and partner with teammates in Wealth Data and Analytics, EDO, Technology, and other business specific D&A teams to build best in class approaches to solve business and analytical problems, share best practices, and cross pollinate data knowledge Required Qualifications: The requirements listed below are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Bachelor’s Degree in a quantitative field related Mathematics, Statistics, Econometrics, Actuarial Science, Computer science, Engineering, or finance 3-5 years of relevant financial services, data & analytics experience, and experience developing statistics and machine learning models Strong verbal and written communication skills. Ability to communicate technical details at a level appropriate for the audience Attention to detail and a sense of ownership for deliverables. Ability to perform and deliver under very demanding and/or ambiguous situations Moderate reporting and automation experience leveraging BI and analytics applications Demonstrated problem solving skills and proven ability to perform and deliver under very demanding and/or ambiguous situations Demonstrated technical proficiency in one or more of the following languages SAS (base, enterprise guide or enterprise miner) and/or R/Python while working on projects to Probability and Statistics, Finance (financial ratios, interest rates, yield curve), or data mining. Hands-on experience working with large databases and deep understanding of one or many of the following: Decision trees, Linear and Nonlinear regressions, neural nets, ensembles, Market Basket analysis, Time series forecasting, deep learning, text mining and various model assessment & performance metrics Preferred Qualifications: Master’s degree in business and/or a quantitative field related Mathematics, Statistics, Econometrics, Actuarial Science, Computer science, or Engineering Experience with big data technology (Hadoop, Hive, Spark, etc.) and data processing pipeline. Back ground within Wealth Management",
        "url": "https://www.linkedin.com/jobs/view/3967725930",
        "summary": "Truist Wealth seeks a Data Scientist to provide data analytics across products and client experience. This role focuses on portfolio, scenario, and strategic analysis, ad-hoc executive analytics, marketing campaign response, and evaluation of strategic initiatives, account acquisition and management, delinquency and default, portfolio asset quality, and portfolio acquisitions and divestitures. This role can be based in Charlotte or Atlanta.",
        "industries": [
            "Financial Services",
            "Wealth Management",
            "Banking",
            "Data & Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Collaboration",
            "Attention to Detail",
            "Ownership",
            "Presentation",
            "Storytelling",
            "Technical Communication"
        ],
        "hard_skills": [
            "Data Mining",
            "Inferential Statistical Analysis",
            "Predictive Analytics",
            "Data Visualization",
            "Reporting",
            "Automation",
            "Machine Learning",
            "Decision Trees",
            "Linear and Nonlinear Regressions",
            "Neural Networks",
            "Ensembles",
            "Market Basket Analysis",
            "Time Series Forecasting",
            "Deep Learning",
            "Text Mining",
            "Model Assessment & Performance Metrics"
        ],
        "tech_stack": [
            "SAS",
            "R",
            "Python",
            "Hadoop",
            "Hive",
            "Spark",
            "BI and Analytics applications"
        ],
        "programming_languages": [
            "SAS",
            "R",
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Mathematics",
                "Statistics",
                "Econometrics",
                "Actuarial Science",
                "Computer Science",
                "Engineering",
                "Finance"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "San Francisco Bay Area",
        "job_id": 3967158261,
        "company": "BioPhase",
        "title": "Head of Biological Data Science",
        "created_on": 1720588426.2962697,
        "description": "Roles and Responsibilities: Lead the Biological Data Science department, managing a team of computational biologists, bioinformaticians, and data engineers. Collaborate with multidisciplinary teams of translational and pre-clinical scientists on experimental design and analytical approaches to inform preclinical R&D, therapeutic development, clinical development plans, trial designs, and trial results. Oversee strategic planning for developing bioinformatic analysis pipelines to support Epic Bio’s pre-clinical therapeutic and platform teams, and enable biomarker readouts for clinical trials. Provide expert guidance in planning, executing, and documenting computational analyses to support regulatory filings for novel therapeutic development. Supervise biostatistical analysis of clinical data in collaboration with the Clinical Operations team and external CROs to support clinical trial development. Communicate analysis results clearly and effectively to both experimental scientists and non-scientists across teams. Required Qualifications: Ph.D. in Bioinformatics, Computational Biology, Genetics/Genomics, Bioengineering, Computer Science, Biostatistics, or a related field. 5+ years of post-PhD experience in the biotech industry, ideally in gene therapy or related next-generation drug development fields such as biologics. Strong analytical and scientific background with experience leading a team of scientists and managing external vendors. Experience analyzing high-throughput sequencing datasets (e.g., CRISPR screens, RNA-seq, ATAC-seq, ChIP-seq, WGBS, scRNA-seq). Experience with clinical biostatistics, clinical trial development, and/or regulatory filings in therapeutic drug development. Proficiency in programming with Python and R. Demonstrated ability to communicate research results effectively at various levels (leadership, investors, scientific experts). Experience in experimental design and cross-team collaboration with experimental scientists. Preferred Qualifications: Expertise in gene regulation, epigenetics, CRISPR biology, and/or gene therapy. Theoretical knowledge and practical experience in machine learning/deep learning. Familiarity with protein engineering, including model-guided approaches to protein design and molecular dynamic simulations. Experience with regulatory submissions and interactions with health authorities, particularly the FDA. Familiarity with GitHub and AWS.",
        "url": "https://www.linkedin.com/jobs/view/3967158261",
        "summary": "Lead the Biological Data Science department at Epic Bio, a company focused on pre-clinical and clinical therapeutic development, particularly in gene therapy and next-generation drug development. This role involves managing a team of computational biologists, bioinformaticians, and data engineers, collaborating with multidisciplinary teams, overseeing strategic planning for bioinformatic pipelines, providing expert guidance on computational analysis for regulatory filings, supervising biostatistical analysis of clinical data, and effectively communicating analysis results to various audiences. ",
        "industries": [
            "Biotechnology",
            "Healthcare",
            "Pharmaceuticals",
            "Gene Therapy",
            "Clinical Research"
        ],
        "soft_skills": [
            "Leadership",
            "Communication",
            "Collaboration",
            "Strategic Planning",
            "Problem-Solving",
            "Project Management"
        ],
        "hard_skills": [
            "Bioinformatics",
            "Computational Biology",
            "Genetics",
            "Genomics",
            "Bioengineering",
            "Computer Science",
            "Biostatistics",
            "High-Throughput Sequencing",
            "CRISPR Screens",
            "RNA-Seq",
            "ATAC-Seq",
            "ChIP-Seq",
            "WGBS",
            "scRNA-Seq",
            "Clinical Biostatistics",
            "Clinical Trial Development",
            "Regulatory Filings",
            "Python",
            "R",
            "Machine Learning",
            "Deep Learning",
            "Protein Engineering",
            "Molecular Dynamics Simulations",
            "GitHub",
            "AWS"
        ],
        "tech_stack": [
            "Python",
            "R",
            "GitHub",
            "AWS",
            "CRISPR Screens",
            "RNA-Seq",
            "ATAC-Seq",
            "ChIP-Seq",
            "WGBS",
            "scRNA-Seq",
            "Machine Learning",
            "Deep Learning"
        ],
        "programming_languages": [
            "Python",
            "R"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Ph.D.",
            "fields": [
                "Bioinformatics",
                "Computational Biology",
                "Genetics/Genomics",
                "Bioengineering",
                "Computer Science",
                "Biostatistics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Bethlehem, PA",
        "job_id": 3971352358,
        "company": "PRI Technology",
        "title": "Data Engineer/Machine Learning",
        "created_on": 1720588433.220853,
        "description": "Requirements: Bachelor's or master's degree with 5+ years of experience in Computer Science, Data Science, Engineering, or a related field. 4+ years of experience in working with Python, SQL, PySpark and bash scripts. Proficient in software development lifecycle and software engineering practices. 2+ years of hands-on experience in using Databricks platform 3+ years of hands-on experience in operationalizing Machine Learning solutions which are used in live production processes. 2+ years of experience and proficiency in API development using FastAPI frameworks and familiarity with containerization technologies such as docker or Kubernetes. 3+ years of experience in developing and maintaining robust data pipelines data to be used by Data Scientists to build Client Models. 3+ years of experience working with Cloud Data Warehousing (Redshift, Snowflake, Databricks SQL or equivalent) platforms and experience in working with distributed framework like Spark. Solid understanding of machine learning life cycle, data mining, and ETL techniques. Experience with machine learning frameworks such as Keras or PyTorch and libraries such as scikit-learn, xgboost). Hands-on experience in building and maintaining tools and libraries which have been used by multiple teams across organization. Proficient in understanding and incorporating software engineering principles in design & development process. Hands on experience with CI/CD tools (e.g., Jenkins or equivalent), version control (Github, Bitbucket), Orchestration (Airflow, Prefect or equivalent) Excellent communication skills and ability to work and collaborate with cross functional teams across technology and business. Pluses only: Familiarity with deep learning frameworks and deploying deep learning models for production use cases. Familiarity in using GPU compute either for model training or inference. Understanding of Large language models (LLM) and MLOps lifecycle for operationalizing LLM models.",
        "url": "https://www.linkedin.com/jobs/view/3971352358",
        "summary": "This role requires a skilled Data Scientist or Machine Learning Engineer with a strong background in Python, SQL, PySpark, and Databricks. The ideal candidate will have extensive experience in building and operationalizing machine learning solutions for production use, data pipeline development, and API development with FastAPI.  Additionally, experience with cloud data warehousing, distributed frameworks like Spark, CI/CD, version control, and orchestration tools are essential. Strong communication skills and the ability to collaborate across teams are also highly valued.",
        "industries": [
            "Data Science",
            "Machine Learning",
            "Software Engineering",
            "Technology"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical",
            "Technical",
            "Organizational"
        ],
        "hard_skills": [
            "Python",
            "SQL",
            "PySpark",
            "Bash Scripting",
            "Databricks",
            "Software Development Lifecycle",
            "Software Engineering",
            "Machine Learning",
            "API Development",
            "FastAPI",
            "Docker",
            "Kubernetes",
            "Data Pipelines",
            "Cloud Data Warehousing",
            "Redshift",
            "Snowflake",
            "Databricks SQL",
            "Spark",
            "ETL",
            "Keras",
            "PyTorch",
            "Scikit-learn",
            "XGBoost",
            "CI/CD",
            "Jenkins",
            "Github",
            "Bitbucket",
            "Airflow",
            "Prefect"
        ],
        "tech_stack": [
            "Python",
            "SQL",
            "PySpark",
            "Bash",
            "Databricks",
            "FastAPI",
            "Docker",
            "Kubernetes",
            "Redshift",
            "Snowflake",
            "Spark",
            "Keras",
            "PyTorch",
            "Scikit-learn",
            "XGBoost",
            "Jenkins",
            "Github",
            "Bitbucket",
            "Airflow",
            "Prefect"
        ],
        "programming_languages": [
            "Python",
            "SQL"
        ],
        "experience": 5,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Computer Science",
                "Data Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Boise, ID",
        "job_id": 3959151039,
        "company": "Micron Technology",
        "title": "Data Scientist",
        "created_on": 1720588447.4600675,
        "description": "Our vision is to transform how the world uses information to enrich life for all . Micron Technology is a world leader in innovating memory and storage solutions that accelerate the transformation of information into intelligence, inspiring the world to learn, communicate and advance faster than ever. Draw from a broad background of data-mining techniques in mathematics, statistics, information technology, machine learning, data engineering, design of experiments, visualization, and text mining to discover patterns in data. Mine data to discover insights. Utilizes data-mining techniques, statistical analysis, mathematical optimization, visualizations, and text mining to discover insightful patterns in data. Uses strong understanding of business functional areas to develop clear data science-driven solutions. Develops, tunes, and deploys predictive models that explain or predict business outcomes. Collaborates with business SMEs, data engineers, and presents to leaders on data science solutions. May telecommute part-time. Employer will accept a Master's degree in Statistics, Industrial & Systems Engineering, Data Science, Computer Science, Mathematics or related field. Position requires completion of a university-level course, research project, internship, or thesis or 6 months of experience involving the following: Data science techniques and applications Statistical methods Artificial Intelligence and Machine Learning Programming in multiple languages including R and Python Optimization expertise As a world leader in the semiconductor industry, Micron is dedicated to your personal wellbeing and professional growth. Micron benefits are designed to help you stay well, provide peace of mind and help you prepare for the future. We offer a choice of medical, dental and vision plans in all locations enabling team members to select the plans that best meet their family healthcare needs and budget. Micron also provides benefit programs that help protect your income if you are unable to work due to illness or injury, and paid family leave. Additionally, Micron benefits include a robust paid time-off program and paid holidays. For additional information regarding the Benefit programs available, please see the Benefits Guide posted on micron.com/careers/benefits. Micron is proud to be an equal opportunity workplace and is an affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, citizenship status, disability, protected veteran status, gender identity or any other factor protected by applicable federal, state, or local laws. To learn about your right to work click here. To learn more about Micron, please visit micron.com/careers For US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron’s People Organization at hrsupport_na@micron.com or 1-800-336-8918 (select option #3) Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards. Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron.",
        "url": "https://www.linkedin.com/jobs/view/3959151039",
        "summary": "Micron Technology is seeking a Data Scientist to mine data, discover insights, and develop predictive models. This role requires experience with data-mining techniques, statistical analysis, mathematical optimization, visualizations, and text mining. The ideal candidate will have a Master's degree in Statistics, Industrial & Systems Engineering, Data Science, Computer Science, Mathematics or related field, and experience with data science techniques, statistical methods, AI/ML, programming in R and Python, and optimization expertise.",
        "industries": [
            "Semiconductor",
            "Technology",
            "Data Science"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Presentation Skills",
            "Analytical Skills",
            "Critical Thinking"
        ],
        "hard_skills": [
            "Data Mining",
            "Statistical Analysis",
            "Mathematical Optimization",
            "Visualization",
            "Text Mining",
            "Machine Learning",
            "AI",
            "R",
            "Python",
            "Optimization",
            "Data Science Techniques"
        ],
        "tech_stack": [
            "R",
            "Python"
        ],
        "programming_languages": [
            "R",
            "Python"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Statistics",
                "Industrial & Systems Engineering",
                "Data Science",
                "Computer Science",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Paid Family Leave",
            "Paid Time Off",
            "Paid Holidays"
        ]
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Indiana, United States",
        "job_id": 3970756927,
        "company": "Centers for Disease Control and Prevention",
        "title": "Public Notice for Direct Hire (Data Modernization) - Data Scientist",
        "created_on": 1720588450.310598,
        "description": "Duties Summary As a global leader in public health & health promotion, CDC is the agency Americans trust with their lives. In addition to our everyday work, each CDC employee has a role in supporting public health emergency management, whether through temporary assignments to emergency responses or sustaining other CDC programs and activities while colleagues respond. Join our team to use your talent, training, & passion to help CDC continue as the world's premier public health organization. Visit www.cdc.gov Requirements Qualifications Basic Qualifications: Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. or Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown above, plus additional education or appropriate experience. Minimum Qualifications: GS-7: At least 1 year of graduate-level education OR Superior academic achievement (See Education section) OR At least 1 year of specialized experience, equivalent to the GS-05 grade level in the Federal service, to include experience participating in analyzing data modeling concepts and reviewing data for trends from multiple systems OR A combination of education & experience GS-9: At least 2 years of progressively higher-level graduate education leading to a master's degree or master's or equivalent graduate degree OR At least 1 year of specialized experience, equivalent to the GS-07 grade level in the Federal service, to include experience analyzing and interpreting data modeling, algorithms, and coding data requirement; and analyzing and providing information from multiple systems to prepare data reports OR A combination of education & experience GS-11: At least 3 years of progressively higher-level graduate education leading to a Ph.D. degree or Ph.D. or equivalent doctoral degree OR At least 1 year of specialized experience, equivalent to the GS-09 grade level in the Federal service, to include experience applying and developing data adaptive algorithms, machine learning and other AI system; reviewing, analyzing, and providing information from multiple systems to prepare data reports; and using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation OR A combination of education & experience GS-12: At least 1 year of specialized experience, equivalent to the GS-11 grade level in the Federal service, to include experience identifying data required for use in the management and direction of programs; developing data adaptive algorithms, machine learning and other AI system; using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation; and applying statistical analyses to determine the fitness-for-use of new or combined data sources, machine learning outputs, and data science methods. GS-13: At least 1 year of specialized experience, equivalent to the GS-12 grade level in the Federal service, to include experience conducting research using public health data systems (i.e., survey data, health care facility data, syndromic surveillance data, electronic records, vital records, and non-traditional data sources); designing and developing data analytics/science related products using techniques such as machine learning, natural language processing, robotics process automation, and artificial intelligence; conducting analysis using software and/or programming languages; and using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation GS-14: At least 1 year of specialized experience, equivalent to the GS-13 grade level in the Federal service, to include experience designing and developing of data analytics/science related products using techniques such as machine learning, natural language processing, robotics process automation, and artificial intelligence; conducting analysis using software and/or programming languages; and identifying problematic issues and reporting discrepancies and providing appropriate recommendations to leadership GS-15: At least 1 year of specialized experience, equivalent to the GS-14 grade level in the Federal service, to include experience evaluating impacts of new policies and procedures to determine the effectiveness in meeting goals and objectives of a department or division; providing guidance for organizations information technology and negotiate on contracts providing information technology and services; planning, organizing, and presenting data science and data visualization techniques-based reports showcasing data-driven insights to organizational leadership and various program office; and guiding strategic planning for organizational structure, data management, information technology infrastructure, across an organization and with academic institutions and public health communities Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience. Promotion potential: Promotion to the next grade level is at management's discretion and is based on your meeting qualifications and time-in-grade requirements, demonstrated ability to perform the higher-level duties, the continuing need for the higher-level duties, and administrative approval. Promotion to the next grade level is not guaranteed and no promise of promotion is implied. The Centers for Disease Control and Prevention (CDC), a major operating component of the Department of Health and Human Services, is the nation's leading science-based, data-driven, service organization that protects the public's health. For more than 75 years, we have put science into action to help children stay healthy so they can grow and learn; to help families, businesses, and communities fight disease and stay strong; and to protect the public's health. In addition, CDC also has a critical preparedness and response mission: we protect the American people from health threats, research emerging diseases, and mobilize public health programs with domestic and international partners. CDC's 24/7 Emergency Operations Center (EOC) unites highly trained experts, well established processes, and state-of-the-art technology to coordinate resources and information as CDC responds to emergencies worldwide. Every CDC employee has a role in supporting public health emergency management, whether through temporary assignments to emergency responses or sustaining other CDC programs and activities while colleagues respond. CDC offers exciting and dynamic opportunities in Public Health with global impact. Examine how you can use your talent, training, and passion to help CDC continue as the world's premier public health organization. Please visit www.cdc.gov for more information.",
        "url": "https://www.linkedin.com/jobs/view/3970756927",
        "summary": "The Centers for Disease Control and Prevention (CDC) is seeking a Data Scientist to join their team. The position requires experience with data modeling, algorithms, coding data requirements, and machine learning. The ideal candidate will have a strong understanding of data analysis, statistical techniques, and public health data systems. The role involves designing and developing data analytics products using techniques such as machine learning, natural language processing, robotics process automation, and artificial intelligence. The candidate will conduct analysis using software and/or programming languages, and process large datasets into structured formats for matching, analysis, or estimation. The position also requires experience in identifying problematic issues, reporting discrepancies, and providing recommendations to leadership.  ",
        "industries": [
            "Public Health",
            "Healthcare",
            "Government"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Analytical Thinking",
            "Decision Making",
            "Critical Thinking",
            "Teamwork",
            "Leadership"
        ],
        "hard_skills": [
            "Data Modeling",
            "Algorithms",
            "Data Analysis",
            "Machine Learning",
            "Artificial Intelligence",
            "Statistical Analysis",
            "Data Visualization",
            "Data Management",
            "Programming Languages",
            "Software Development",
            "Data Science",
            "Data Analytics",
            "Natural Language Processing",
            "Robotics Process Automation"
        ],
        "tech_stack": [
            "Machine Learning",
            "Artificial Intelligence",
            "Natural Language Processing",
            "Robotics Process Automation",
            "Data Science",
            "Data Analytics"
        ],
        "programming_languages": [],
        "experience": 1,
        "education": {
            "min_degree": "Bachelor's",
            "fields": [
                "Mathematics",
                "Statistics",
                "Computer Science",
                "Data Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Virginia, United States",
        "job_id": 3831240809,
        "company": "Georgia IT, Inc.",
        "title": "Healthcare Data scientist  - Remote",
        "created_on": 1720588453.185903,
        "description": "Healthcare Date Datantist Location : Remote Job type: Contract US Citizen, Green Card, TN, GC EAD and H4 EAD only No Third-party agencies. Must-Have Qualities Masters Degree in Computer Science: The ideal candidate should hold a Masters degree in Computer Science, showcasing a strong academic foundation in relevant fields. 4 Years of Experience: We require at least 4 years of practical experience in data science , encompassing a strong track record of successful projects and contributions. ETL Pipeline Experience: The candidate should have a proven ability to design, build, and optimize ETL (Extract, Transform, Load) pipelines for efficient data processing and analysis. 4 . Python Proficiency: Profound expertise in Python is a crucial requirement, as the role heavily relies on Python for data analysis, modeling, and visualization. Nice-to-Have Qualities While not mandatory, the following qualities would be considered advantageous: Experience Deploying Client Models at Scale: Practical experience in deploying machine learning models at scale would be a significant asset, showcasing the ability to operationalize data science solutions effectively. Experience Evaluating LLM (Large Language Models): Familiarity with the evaluation of Large Language Models (LLM) and their applications in data science. Experience Building Healthcare Client Models: Experience in developing healthcare-focused machine learning models would be a strong plus. Soft Skills Analytical Mindset: We value individuals who can think critically, analyze data effectively, and draw actionable insights from complex datasets. Effective Communication: Strong communication skills are essential for collaborating with cross-functional teams and conveying data-driven findings.",
        "url": "https://www.linkedin.com/jobs/view/3831240809",
        "summary": "This is a contract position for a Healthcare Data Scientist. The ideal candidate will have a Masters degree in Computer Science, 4 years of experience in data science, and strong ETL pipeline experience. Proficiency in Python is a must. The role may involve deploying machine learning models at scale and evaluating Large Language Models (LLMs).",
        "industries": [
            "Healthcare",
            "Data Science"
        ],
        "soft_skills": [
            "Analytical Mindset",
            "Effective Communication"
        ],
        "hard_skills": [
            "ETL Pipeline",
            "Python"
        ],
        "tech_stack": [
            "ETL Pipeline",
            "Python"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 4,
        "education": {
            "min_degree": "Masters",
            "fields": [
                "Computer Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Nashville, TN",
        "job_id": 3970184188,
        "company": "ZipRecruiter",
        "title": "Sr Data Scientist",
        "created_on": 1720588462.1066349,
        "description": "Job Description Sr. Data Scientist Global Product Development Nashville, TN Why Asurion? Asurion is seeking for a Senior Manager to join our Data Science team. An individual in this role identifies and solves complex business problems, drives the creation of new data products and analytical capabilities embedded in multiple business applications. Leads a team of data scientists to gather and analyze large volumes of data, evaluates scenarios to make predictions on future outcomes and supports decision making. Role And Responsibilities Frame & communicate business problems as a Data Science/AI initiative in a collaborative way Work with a team of data scientists to build ML/AI solutions that drive business impact with minimal handholding Develop prototypes for new data product ideas Design and deploy complex, optimized, and large-scale machine learning algorithms and recommender systems to improve Asurion’s wireless & connected home experiences Analyze and interpret the results of product experiments Work closely with product managers and stakeholders to identify and answer important product questions that help improve outcomes Utilize Natural Processing, particularly Generative AI, to analyze speech and social data Communicate findings to product managers and development groups Drive the collection of new data and the refinement of existing data Regularly invents new and novel approaches to problems; takes initiative and breaks down barriers to solve problems; recognized within team as the source of solutions. Qualifications Master's or PhD preferably in an engineering, statistics, technology, or science role with at least 2 years’ work experience. Exceptional candidates with no previous work experience are welcome. Prior experience in leading, mentoring, and coaching data scientists is Prior experience in applying machine learning for customer experience & fraud detection use cases is a plus Prior experience in leveraging Generative AI to build useful and helpful solutions is a plus Comfortable in using advanced statistical data modeling techniques and tools Experience using Python and working with large scale systems Familiar with optimization techniques and underlying machine learning algorithms concepts Solid statistical knowledge; familiarity with hypothesis testing, experimental design and time series Familiarity with Linux/Unix/Shell environments Self-driven and able to ask and tackle the most important analytical questions with a view on driving product impact A strong passion for empirical research and for answering hard questions with data Result-driven and focused self-starters, great communicators that follows through on every initiative Love the responsibility of being individually empowered Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner About Asurion Simply put, Asurion helps people stay connected. As the global leader of connected life services, we provide over 290 million consumers around the world with simple, intuitive technology advice to help them get the most from their devices; support to fix their issues and connectivity crisis, and device protection to ensure they receive a replacement or repair. When a product is missing or simply doesn't work properly, Asurion’s 19,000 employees are focused on solving the problem with people and processes operating 24 hours a day, seven days a week, speaking six languages, and working across any device, platform, or provider. By partnering with leading retailers, mobile carriers and pay-tv providers, Asurion helps customers enhance their lives through their technology. For more information about Asurion Data Science Team, please visit www.datascience.asurion.com",
        "url": "https://www.linkedin.com/jobs/view/3970184188",
        "summary": "Asurion is looking for a Senior Data Scientist to join their Global Product Development team in Nashville, TN. This role focuses on identifying and solving complex business problems using data science and AI. You will lead a team of data scientists, develop ML/AI solutions, analyze data, and communicate findings to product managers and developers. The ideal candidate has a Master's or PhD in engineering, statistics, technology, or science with at least 2 years of experience (or exceptional candidates with no experience are welcome) and experience in leading data science teams, applying machine learning for customer experience and fraud detection, using Generative AI, working with Python and large-scale systems, and understanding optimization techniques and statistical methods. You will also need to be a strong communicator and able to translate complex analysis into actionable insights. ",
        "industries": [
            "Technology",
            "Data Science",
            "Machine Learning",
            "Artificial Intelligence",
            "Telecommunications",
            "Consumer Electronics",
            "Retail"
        ],
        "soft_skills": [
            "Communication",
            "Leadership",
            "Collaboration",
            "Problem Solving",
            "Analytical Thinking",
            "Decision Making",
            "Presentation Skills",
            "Project Management",
            "Teamwork",
            "Self-Motivation",
            "Passion for Data",
            "Result-Oriented"
        ],
        "hard_skills": [
            "Machine Learning",
            "Artificial Intelligence",
            "Python",
            "Data Modeling",
            "Statistical Analysis",
            "Hypothesis Testing",
            "Experimental Design",
            "Time Series Analysis",
            "Generative AI",
            "Natural Language Processing",
            "Recommender Systems",
            "Optimization Techniques",
            "Linux",
            "Unix",
            "Shell"
        ],
        "tech_stack": [
            "Python",
            "Machine Learning",
            "Artificial Intelligence",
            "Generative AI",
            "Natural Language Processing",
            "Recommender Systems",
            "Large Scale Systems",
            "Linux",
            "Unix",
            "Shell"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 2,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Engineering",
                "Statistics",
                "Technology",
                "Science"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "New York City Metropolitan Area",
        "job_id": 3961912806,
        "company": "Stealth Startup",
        "title": "Data Scientist - Series A Startup",
        "created_on": 1720588463.445895,
        "description": "We are one of the leading tech investment firms globally, with a track record of investing in some of the most valuable companies in the world. We are helping our early stage (Pre-Seed -> Series B) portfolio companies grow their teams. One of our portfolio companies is looking to hire a business-oriented data scientist to help accelerate their growth and product initiatives. They are focused on candidates with prior startup experience and run a hybrid work culture, so you will be expected to be in their NYC office 3 days a week. While being good at what you do are table stakes, we believe the following will make you successful in a startup: Optimistic individuals are persistent, determined, and unwilling to give up in the face of adversity. They keep working towards a goal or objective despite setbacks or failures. Optimism often involves a combination of perseverance, resilience, and determination. Growth-oriented individuals embrace challenges, persist in the face of setbacks, and see effort as a key to success. They are willing to take risks and push themselves outside of their comfort zones. Growth-oriented individuals are curious, see learning as a lifelong process, and embrace feedback. They are willing to try new things, and are not afraid to change direction if something isn’t working. Effective individuals collaborate well, work consistently and purposefully towards achieving their goals, efficiently manage their time, and are self-motivated. They are able to identify problems, analyze them critically, and develop effective solutions. At this time, we are looking for candidates with 3+ years of experience. As the company is an early stage startup, they are unable to sponsor visas of any kind.",
        "url": "https://www.linkedin.com/jobs/view/3961912806",
        "summary": "A leading tech investment firm is looking for a business-oriented data scientist with 3+ years of experience for one of their portfolio companies. The company is in the early stage (Pre-Seed -> Series B) and offers a hybrid work culture with 3 days a week in the NYC office. They are looking for optimistic, growth-oriented, and effective individuals with prior startup experience.",
        "industries": [
            "Technology",
            "Investment Banking",
            "Venture Capital",
            "Startups",
            "Data Science"
        ],
        "soft_skills": [
            "Optimistic",
            "Persistent",
            "Determined",
            "Growth-oriented",
            "Resilient",
            "Curious",
            "Learning",
            "Risk-taking",
            "Collaboration",
            "Goal-oriented",
            "Time Management",
            "Self-motivation",
            "Problem-solving",
            "Analytical",
            "Effective Communication"
        ],
        "hard_skills": [
            "Data Science"
        ],
        "tech_stack": [],
        "programming_languages": [],
        "experience": 3,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "ed8b9cbd14db458d9ead669ffa1a421c",
        "keyword": "Data Scientist",
        "location": "Tucson, AZ",
        "job_id": 3967650979,
        "company": "Energy Jobline",
        "title": "Data Scientist/Analytics Engineer",
        "created_on": 1720588472.305895,
        "description": "Job Title: Data Analyst Location: Tucson, AZ Contract: 12-month W2 contact (not available on C2C) Position Overview: We are seeking a talented and motivated Data Analyst to join our team in Tucson, AZ. The ideal candidate will have experience with Python, R programming, SQL scripting, and data visualization tools such as Tableau or Power BI. Additionally, familiarity with Snowflake or similar data warehousing platforms is highly desirable. Key Responsibilities Utilize Python or R programming to extract, clean, and analyze data from various sources. Write SQL scripts to query databases and manipulate data for analysis. Perform ETL (Extract, Transform, Load) processes to prepare data for analysis and reporting. Design and implement data models for analytics applications. Create interactive and insightful visualizations using Tableau, Power BI, or similar tools. Apply statistical and machine learning techniques, including regression, clustering, decision trees, and neural networks. Work with geospatial data and analytics, including GIS tools and techniques. Collaborate with cross-functional teams to understand data requirements and provide actionable insights. Conduct quality assessments on water quality data or other relevant datasets. Qualifications Bachelor's degree in Computer Science, Statistics, Mathematics, or related field. Proficiency in Python, R programming, and SQL scripting. Experience with data visualization tools such as Tableau, Power BI, or similar. Familiarity with Snowflake or other data warehousing platforms is a plus. Solid understanding of statistical and machine learning techniques. Proficient in data modeling for analytics applications. Strong problem-solving, critical thinking, and analytical skills. Excellent communication and collaboration abilities. Ability to work in a fast-paced, dynamic environment and handle multiple projects simultaneously.",
        "url": "https://www.linkedin.com/jobs/view/3967650979",
        "summary": "We are looking for a Data Analyst in Tucson, AZ to extract, clean, analyze data, write SQL scripts, perform ETL processes, design and implement data models, create visualizations, apply statistical and machine learning techniques, work with geospatial data, and collaborate with cross-functional teams.",
        "industries": [
            "Data Analysis",
            "Analytics",
            "Water Quality",
            "Environmental Science",
            "GIS",
            "Data Warehousing",
            "Machine Learning"
        ],
        "soft_skills": [
            "Problem Solving",
            "Critical Thinking",
            "Analytical Skills",
            "Communication",
            "Collaboration",
            "Teamwork",
            "Time Management"
        ],
        "hard_skills": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Power BI",
            "Snowflake",
            "ETL",
            "Data Modeling",
            "Regression",
            "Clustering",
            "Decision Trees",
            "Neural Networks",
            "Geospatial Data",
            "GIS"
        ],
        "tech_stack": [
            "Python",
            "R",
            "SQL",
            "Tableau",
            "Power BI",
            "Snowflake"
        ],
        "programming_languages": [
            "Python",
            "R",
            "SQL"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Statistics",
                "Mathematics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Ann Arbor, MI",
        "job_id": 3947134784,
        "company": "May Mobility",
        "title": "Senior Robotics Engineer - LIDAR",
        "created_on": 1720588483.9479105,
        "description": "May Mobility is transforming cities through autonomous technology to create a safer, greener, more accessible world. Based in Ann Arbor, Michigan, May develops and deploys autonomous vehicles (AVs) powered by our innovative Multi-Policy Decision Making (MPDM) technology that literally reimagines the way AVs think. Our vehicles do more than just drive themselves - they provide value to communities, bridge public transit gaps and move people where they need to go safely, easily and with a lot more fun. We’re building the world’s best autonomy system to reimagine transit by minimizing congestion, expanding access and encouraging better land use in order to foster more green, vibrant and livable spaces. Since our founding in 2017, we’ve given more than 300,000 autonomy-enabled rides to real people around the globe. And we’re just getting started. We’re hiring people who share our passion for building the future, today, solving real-world problems and seeing the impact of their work. Join us. Hybrid employees come into HQ or one of our sites on an agreed upon cadence set by their leader and based on the nature of the role. This role is a hybrid role, based out of Ann Arbor, Michigan. Job Summary May’s Lead Engineers are front-line problem solvers that get things done. May’s lead engineers have the initiative, experience, and technical skills to be able to solve problems delegated to them without oversight. Confidence backed by knowledge and experience is a must. As a Senior Robotics Engineer - LIDAR, you will lead the solution of challenging and complex problems facing vehicle autonomy. You will lead the design of future May autonomy systems and track down and solve the system’s most difficult issues. Autonomy system engineers are responsible for the integrated functioning of the autonomy system. Systems engineers interact with vision, LIDAR, RADAR, tracking, intent, decision-making, control, networking, health monitoring, computers, graphics cards, and power. System engineers drive forward architectural design and hardware/software design through collaboration across other engineering groups. You will be a go-to person for understanding how new features will fit in, how the system might fail, how to best evolve the system to be more effective or efficient, and how to keep the system working. As a leader, you will set an example of initiative, data-driven decision-making, design, and troubleshooting. You will also guide and mentor more junior autonomy engineers so that they can work more effectively with May’s systems. This position reports to the VP of Autonomy. Your Opportunity to Drive Success You will have an opportunity to independently impact our approach to solving the most interesting problems facing AV’s today, while operating live in the wild. Collaborate with other machine learning and robotics engineers to design, implement, test, and deploy robust, generalizable perception solutions for autonomous vehicles Work independently with cross-functional teams to develop software and system requirements Develop, test, and deploy software in C/C++/CUDA Lead team code quality activities including design and code reviews Track and Trend technical performance of the system in the field Provide technical guidance to Technical Support Team on issue diagnosis and resolution Required Qualifications A minimum of 3+ years of industry experience working on real-world robot perception systems (should have implemented at least two commercial projects working at a systems level, developing perception software as part of a larger robotics system) Masters' or PhD's degree in Robotics, Computer Vision, Machine Learning, Artificial Intelligence, Computer Science, or Computer Engineering, or a field that requires a strong mathematical and/or engineering foundation (e.g. physics, aerospace engineering) Object Detection/Segmentation/Tracking in Lidar, Vision, or LiDAR-Camera sensor fusion Solid experience on applying Machine Learning or Deep Learning Technologies to LiDAR Strong experiences on large-scale data driving and data analysis system to understand LiDAR, Vision, Sensor Fusion system Strong programming skills in C/C++ and experience with software development in a Linux environment Familiarity with standard development tools such as git, and CI/CD pipelines Experiences on fast ML development cycle Experiences on ML model optimization and deployment Desired Qualifications Strong background in one of the robot perception areas discussed above as demonstrated by developing and delivering to fielded robots multiple capabilities that solve critical problems in perception Demonstrated ability to mentor and support more junior engineers in learning and contributing to robotics development and testing Experience with python, machine learning software frameworks, and GPU programming in CUDA or related higher-level languages Benefits and Perks Competitive salary and benefits (medical / dental / vision / 401k) Meaningful stock incentives and equity refresh program Unlimited vacation / company paid holidays Paid parental leave Don’t meet every single requirement? Studies have shown that women and/or people of color are less likely to apply to a job unless they meet every qualification. At May Mobility, we’re committed to building a diverse, inclusive, and authentic workforce, so if you’re excited about this role but your previous experience doesn’t align perfectly with every qualification, we encourage you to apply anyway! You may be the perfect candidate for this or another role at May. Want to learn more about our culture & benefits? Check out our website! May Mobility is an equal opportunity employer. All applicants for employment will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, gender identity or expression, veteran status, genetics or any other legally protected basis. Below, you have the opportunity to share your preferred gender pronouns, gender, ethnicity, and veteran status with May Mobility to help us identify areas of improvement in our hiring and recruitment processes. Completion of these questions is entirely voluntary. Any information you choose to provide will be kept confidential, and will not impact the hiring decision in any way. If you believe that you will need any type of accommodation, please let us know. Note to Recruitment Agencies: May Mobility does not accept unsolicited agency resumes. Furthermore, May Mobility does not pay placement fees for candidates submitted by any agency other than its approved partners.",
        "url": "https://www.linkedin.com/jobs/view/3947134784",
        "summary": "May Mobility is seeking a Senior Robotics Engineer - LIDAR to lead the design and development of autonomy systems for autonomous vehicles. This role involves collaborating with machine learning and robotics engineers to implement perception solutions, developing software and system requirements, and leading code quality activities. The ideal candidate will have 3+ years of experience working on real-world robot perception systems, a Masters' or PhD's degree in a related field, and expertise in object detection, segmentation, tracking, and machine learning for LiDAR applications. This is a hybrid position based in Ann Arbor, Michigan.",
        "industries": [
            "Autonomous Vehicles",
            "Robotics",
            "Artificial Intelligence",
            "Machine Learning",
            "Transportation"
        ],
        "soft_skills": [
            "Problem Solving",
            "Initiative",
            "Leadership",
            "Communication",
            "Collaboration",
            "Decision-Making",
            "Mentorship",
            "Guidance"
        ],
        "hard_skills": [
            "C/C++",
            "CUDA",
            "Linux",
            "Git",
            "CI/CD Pipelines",
            "Machine Learning",
            "Deep Learning",
            "Object Detection",
            "Segmentation",
            "Tracking",
            "LiDAR",
            "Vision",
            "Sensor Fusion",
            "Data Analysis",
            "Python",
            "Software Development",
            "System Design",
            "Code Review",
            "Technical Support"
        ],
        "tech_stack": [
            "LiDAR",
            "Vision",
            "Sensor Fusion",
            "Machine Learning",
            "Deep Learning",
            "C/C++",
            "CUDA",
            "Linux",
            "Git",
            "CI/CD Pipelines",
            "Python"
        ],
        "programming_languages": [
            "C/C++",
            "CUDA",
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Master's",
            "fields": [
                "Robotics",
                "Computer Vision",
                "Machine Learning",
                "Artificial Intelligence",
                "Computer Science",
                "Computer Engineering",
                "Physics",
                "Aerospace Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "Benefits (medical, dental, vision, 401k)",
            "Stock incentives",
            "Equity refresh program",
            "Unlimited vacation",
            "Company paid holidays",
            "Paid parental leave"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Detroit, MI",
        "job_id": 3959422440,
        "company": "Google",
        "title": "Customer Engineer II, AI/ML, Google Cloud",
        "created_on": 1720588485.4355526,
        "description": "Note: Google’s hybrid workplace includes remote and in-office roles. By applying to this position you will have an opportunity to share your preferred working location from the following: In-office locations: Chicago, IL, USA; Austin, TX, USA; Addison, TX, USA; Detroit, MI, USA. Remote location(s): Michigan, USA; Minnesota, USA. Minimum qualifications: Bachelor's degree or equivalent practical experience. 6 years of experience as a sales engineer or technical consultant in a cloud computing environment or in a customer-facing role. Experience in virtualization or cloud native architectures in a support role. Experience with big data, machine learning, and numerical programming frameworks (e.g., TensorFlow, Python, MATLAB). Preferred qualifications: Master's degree in Computer Science or a related technical field. Experience building machine learning solutions and leveraging specific machine learning architectures (e.g., deep learning, LSTM, convolutional networks). Experience architecting and developing software or infrastructure for scalable distributed systems. Experience in data and information management as it relates to big data trends and issues within businesses. Ability to learn quickly, understand, and work with new emerging technologies, methodologies, and solutions in the cloud/IT technology space. About The Job When leading companies choose Google Cloud, it's a huge win for spreading the power of cloud computing globally. Once educational institutions, government agencies, and other businesses sign on to use Google Cloud products, you come in to facilitate making their work more productive, mobile, and collaborative. You listen and deliver what is most helpful for the customer. You assist fellow sales Googlers by problem-solving key technical issues for our customers. You liaise with the product marketing management and engineering teams to stay on top of industry trends and devise enhancements to Google Cloud products. As a Customer Engineer, you will work with Technical Sales teams as a machine learning subject matter expert to differentiate Google Cloud to our customers. In this role, you will help prospective customers and partners understand the power of Google Cloud, explaining technical features, helping customers design architectures, and problem-solving any potential roadblocks. Additionally, you will have the opportunity to help customers to leverage specialized Machine Learning (ML) hardware developed by Google (e.g. Tensor Processing Unit). You will also work closely with customers and product development to shape the TPU platform. Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems. The US base salary range for this full-time position is $122,000-$180,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google . Responsibilities Work with the team to identify and qualify business opportunities, understand key customer technical objections, and develop the strategy to resolve technical blockers. Work with customers to demonstrate and prototype Google Cloud product integrations in customer/partner environments. Recommend integration strategies, enterprise architectures, platforms, and application infrastructure to implement a complete solution using best practices on Google Cloud. Travel to customer sites, conferences, and other related events as needed. Provide in-depth machine learning expertise to support the technical relationship with Google’s customers including product and solution briefings, proof-of-concept work, and partner directly with product management to prioritize solutions impacting customer adoption to Google Cloud. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
        "url": "https://www.linkedin.com/jobs/view/3959422440",
        "summary": "Google Cloud Customer Engineer specializing in Machine Learning.  You will work with technical sales teams to differentiate Google Cloud to customers, help them understand its features, design architectures, and solve technical roadblocks. You'll also help customers leverage Google's specialized ML hardware (TPUs) and shape the TPU platform.",
        "industries": [
            "Cloud Computing",
            "Technology",
            "Software",
            "Machine Learning",
            "Artificial Intelligence",
            "Data Science",
            "Education",
            "Government"
        ],
        "soft_skills": [
            "Communication",
            "Problem Solving",
            "Technical Expertise",
            "Customer Focus",
            "Collaboration",
            "Presentation Skills",
            "Strategic Thinking",
            "Analytical Skills"
        ],
        "hard_skills": [
            "Cloud Computing",
            "Virtualization",
            "Cloud Native Architectures",
            "Big Data",
            "Machine Learning",
            "TensorFlow",
            "Python",
            "MATLAB",
            "Deep Learning",
            "LSTM",
            "Convolutional Networks",
            "Scalable Distributed Systems",
            "Data Management",
            "Emerging Technologies",
            "Google Cloud Platform",
            "Google Cloud Products",
            "Tensor Processing Unit (TPU)",
            "Integration Strategies",
            "Enterprise Architectures",
            "Application Infrastructure"
        ],
        "tech_stack": [
            "Google Cloud Platform",
            "TensorFlow",
            "Python",
            "MATLAB",
            "Deep Learning",
            "LSTM",
            "Convolutional Networks",
            "Tensor Processing Unit (TPU)"
        ],
        "programming_languages": [
            "Python",
            "MATLAB"
        ],
        "experience": 6,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Related Technical Field"
            ]
        },
        "salary": {
            "max": 180000,
            "min": 122000
        },
        "benefits": [
            "Bonus",
            "Equity"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Detroit Metropolitan Area",
        "job_id": 3954898539,
        "company": "Applied Resource Group",
        "title": "Senior Automation Engineer",
        "created_on": 1720588488.269952,
        "description": "Job Description: Principal Automation Engineer - Automotive Industry Travel: 25% Company Overview: Our company is a leader in providing advanced automation solutions to the automotive industry, partnering with Tier 1 automotive suppliers across various segments including automotive assembly, glass applications, press automation, powertrain, paint & sealer applications, body assembly, and tire & wheel systems. We specialize in enhancing manufacturing processes through cutting-edge robotics, artificial intelligence (AI), and machine learning (ML) technologies. Job Title: Principal Automation Engineer Location: Ability to travel to Automotive Customers. Job Type: Full-time Job Overview: As a Principal Automation Engineer specializing in the automotive industry, you will lead the design, development, and implementation of innovative automation solutions. Your expertise will be pivotal in driving efficiency, optimizing production, and accelerating time-to-market for our automotive manufacturing partners. You will leverage disruptive technologies to revolutionize decision-making processes within manufacturing plants, ensuring competitive advantage and operational excellence. Key Responsibilities: Solution Development: Design and develop automation solutions tailored to specific automotive manufacturing processes such as assembly, welding, paint applications, and more. Technology Integration: Integrate robotics, AI, and ML technologies to enhance production efficiency, quality assurance, and employee safety. Project Leadership: Lead cross-functional teams in executing automation projects from conception to deployment, ensuring adherence to timelines and budgetary constraints. Innovation and Optimization: Continuously innovate and optimize manufacturing processes through the adoption of advanced automation technologies and best practices. Collaboration: Collaborate closely with Tier 1 automotive suppliers and internal stakeholders to understand requirements, propose solutions, and drive consensus. Required Qualifications: Education: Bachelor’s degree in Mechanical Engineering, Electrical Engineering, Robotics, or a related field. Master’s degree preferred. Experience: Minimum of 7 years of hands-on experience in designing and implementing automation solutions within the automotive industry, with a focus on one or more of the following areas: assembly systems, welding, paint & sealer applications, or robotic systems integration. Technical Skills: Proficiency in robotics programming (e.g., Fanuc, ABB), PLC programming (e.g., Siemens, Allen-Bradley), and CAD software (e.g., SolidWorks, AutoCAD). Automotive Industry Technologies: Including but not limited to ABB, Fanuc, KUKA, Yaskawa, Siemens, Rockwell Automation, Allen-Bradley, Omron, Mitsubishi Electric, Universal Robots, and Denso Robotics Leadership: Proven track record of leading complex automation projects, managing teams, and driving results in a manufacturing environment. Communication: Excellent verbal and written communication skills, with the ability to effectively present technical information to diverse audiences. Preferred Qualifications: Experience with automotive manufacturing standards and practices (e.g., IATF 16949). Familiarity with Industry 4.0 principles and digital manufacturing technologies. Certification in Project Management (PMP) or Lean Six Sigma. Benefits: Competitive salary commensurate with experience. Comprehensive benefits package including health, dental, and vision insurance. Retirement savings plan (401k) with company match. Opportunities for professional development and advancement in a fast-growing industry.",
        "url": "https://www.linkedin.com/jobs/view/3954898539",
        "summary": "Lead the design, development, and implementation of innovative automation solutions for the automotive industry, integrating robotics, AI, and ML technologies to enhance production efficiency, quality assurance, and employee safety.",
        "industries": [
            "Automotive",
            "Manufacturing",
            "Robotics",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Leadership",
            "Communication",
            "Teamwork",
            "Problem-Solving",
            "Analytical",
            "Project Management",
            "Innovation",
            "Collaboration"
        ],
        "hard_skills": [
            "Robotics Programming",
            "PLC Programming",
            "CAD Software",
            "Project Management",
            "Lean Six Sigma"
        ],
        "tech_stack": [
            "Robotics",
            "AI",
            "ML",
            "Fanuc",
            "ABB",
            "Siemens",
            "Allen-Bradley",
            "SolidWorks",
            "AutoCAD",
            "KUKA",
            "Yaskawa",
            "Omron",
            "Mitsubishi Electric",
            "Universal Robots",
            "Denso Robotics"
        ],
        "programming_languages": [
            "PLC",
            "Robotics"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor’s degree",
            "fields": [
                "Mechanical Engineering",
                "Electrical Engineering",
                "Robotics"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Competitive salary",
            "Comprehensive benefits package",
            "Health insurance",
            "Dental insurance",
            "Vision insurance",
            "Retirement savings plan",
            "401k with company match",
            "Professional development opportunities",
            "Advancement opportunities"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Detroit Metropolitan Area",
        "job_id": 3963979907,
        "company": "Akkodis",
        "title": "Cloud Engineer",
        "created_on": 1720588489.8185647,
        "description": "Akkodis is currently accepting applications for a Cloud Software Engineer position for a client in the Metro Detroit Area. This position requires associates to work onsite in a hybrid capacity. As a Cloud Software Engineer you will be focused on building and driving the strategy forward for our internal AI/ML platform Salary/Pay: $60 per hour to $62 per hour (W2) Responsibilities: Work in a small, cross-functional teams. Collaborate directly and continuously with business partners, product managers and designers, and will release early and often. Supports ML Practitioners and Data Scientists Work closely with Tech Anchor, Product Manager and Product Owner to deliver machine learning use cases using Agile Methodology. Work with other Software and ML Engineers to tackle challenging AI problems. Participate in Pair Programming for cross training/upskilling, problem solving, and speed to delivery. Leverage latest ML and GCP technologies. Work with Architects to make technical decision on tools, integration, and other issues. Drive PoCs/Discoveries of new tools and technologies to support robust ML Platform Collaborate with other software engineers to understand platform vision, break out tasks and help them solve complex issues. Grow technical capabilities / expertise and provide guidance to other software engineers on the team. Qualifications: Bachelor’s degree in Computer Science or a related field of study 2+ years of experience in Python, Machine Learning Technologies or Deep Learning. 3+ years of work experience as a software engineer with exceptional software engineering knowledge. Experience working with Google Cloud Platform or other cloud experience. Experience with Python and has used Machine Learning tools (pytorch, tensorflow, xgboost etc). Experience using orchestration tools like Airflow. Good to have experience or knowledge of Deep Learning, LLM. Basic knowledge on React / Angular. Experience in supporting continuous improvement by investigating development alternatives. Experience in Software Craftsmanship such as Paired Programming, Test Driven Development, DevOps etc. Experience working with container technology, docker files, docker images, GitHub, CI/CD concepts. Experience applying Agile practices to solution delivery. Must be a self-starter to understand existing bottlenecks and come up with innovative solutions. Open to learning new technology. Strong communication and presentation skills, ability to share/teach others, work collaboratively with others. Good understanding of cloud design considerations and limitations and impact of pricing. If you are interested in this position, then please click APPLY NOW. For any questions regarding this position, please contact Stephen Pemberton at stephen.pemberton@akkodis.com. We are open to working with professionals eligible to work in the US with sponsorship *** Cannot work C2C *** Equal Opportunity Employer/Veterans/Disabled Benefit offerings include medical, dental, vision, term life insurance, short-term disability insurance, additional voluntary benefits, commuter benefits, and a 401K plan. Our program provides employees the flexibility to choose the type of coverage that meets their individual needs. Available paid leave may include Paid Sick Leave, where required by law; any other paid leave required by Federal, State, or local law; and Holiday pays upon meeting eligibility criteria. To read our Candidate Privacy Information Statement, which explains how we will use your information, please visit https://www.akkodis.com/en/privacy-policy. The Company will consider qualified applicants with arrest and conviction records.",
        "url": "https://www.linkedin.com/jobs/view/3963979907",
        "summary": "Akkodis is seeking a Cloud Software Engineer to join their team in the Metro Detroit Area. This hybrid role focuses on building and driving the strategy for an internal AI/ML platform. Responsibilities include collaborating with cross-functional teams, supporting ML Practitioners and Data Scientists, working with Google Cloud Platform, and driving PoCs for new technologies. The ideal candidate will have 2+ years of experience with Python, Machine Learning, and Deep Learning, and 3+ years of experience as a software engineer.  This is an onsite hybrid position with a salary range of $60-$62 per hour.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Presentation Skills",
            "Problem Solving",
            "Teamwork",
            "Self-Starter",
            "Open to Learning",
            "Technical Guidance"
        ],
        "hard_skills": [
            "Python",
            "Machine Learning",
            "Deep Learning",
            "Google Cloud Platform",
            "PyTorch",
            "TensorFlow",
            "XGBoost",
            "Airflow",
            "React",
            "Angular",
            "Docker",
            "GitHub",
            "CI/CD",
            "Agile",
            "Test Driven Development",
            "DevOps"
        ],
        "tech_stack": [
            "Google Cloud Platform",
            "Python",
            "PyTorch",
            "TensorFlow",
            "XGBoost",
            "Airflow",
            "React",
            "Angular",
            "Docker",
            "GitHub",
            "CI/CD"
        ],
        "programming_languages": [
            "Python"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Related Fields"
            ]
        },
        "salary": {
            "max": 62,
            "min": 60
        },
        "benefits": [
            "Medical",
            "Dental",
            "Vision",
            "Term Life Insurance",
            "Short-Term Disability Insurance",
            "Additional Voluntary Benefits",
            "Commuter Benefits",
            "401K Plan",
            "Paid Sick Leave",
            "Holiday Pay"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Warren, MI",
        "job_id": 3942393877,
        "company": "General Motors",
        "title": "EV Battery Analytics Staff Computer Scientist",
        "created_on": 1720588491.5115833,
        "description": "Job Description Remote: This role is categorized as remote. This means the successful candidate may be based anywhere in the United States and is not expected to report to a GM worksite unless directed by their manager. The Role: The EV Battery Analytics Staff Computer Scientist will lead a team of analytics engineers in designing the most capable analytics architecture for EV batteries in the automotive space. This individual will be tasked with expanding telemetry data to ensure Electric Vehicle batteries are performing in a safe and reliable fashion. He or she will be the owner of the data architecture strategy around EV battery data. What You’ll do: Work as a member of a cross-functional team to propose and implement high-impact data and analytic solutions that address business challenges across the EV battery industry. Manage the architecture of data tables, algorithms, and scripts for use in battery analytics standard work. Create dashboards for executive review in the Battery Thermal Runaway Governance Council Work with hardware, software, and analytics teams to characterize existing vehicle fleets in terms of battery performance, human behavior, and other dimensions. Be the technical lead for a cross-functional team to construct the data architecture standards and models for the battery analytics space. This position is a lead role and is across architectures and applications. Candidate must indirectly lead :10-20 other traction battery analytics engineers and many other engineers in a variety of disciplinary areas to create the most cost-competitive battery system that is both safe and reliable. Approve associate and senior battery analytic engineer approaches to algorithm, table creation, and dashboard development. Integrating battery cell and pack manufacturing data and OnStar streams into GM’s IT systems for ease of access by GM’s electrification teams (e.g. Design Release Engineers, Technical Specialists, and Calibrators, and more). Generate visually stunning, highly intelligible, and information-dense data visualizations for GM internal and GM external consumption. Coordinate requirements development with other analytics, information technology, propulsion, and vehicle engineers (establishing workgroups, meetings, etc.) and releasing those requirements through a controlled change management process. Manage key strategic interfaces within vehicle software and company information technology infrastructure to enable component reuse and adherence to best practices. Track and report issues as required by management. Manage project using timelines, deliverables, regular meetings and workgroups. Job may require some travel (Job may occasionally require early morning and late-night meetings to accommodate global schedules ( Additional Job Description Your Skills & Abilities (Required Qualifications) 10+ years of demonstrated technical experience in Predictive Analytics, Analytics, Computer Science, Data Science, Statistics, Mathematics, Engineering, or other quantitative field. Bachelor’s of Science degree in Predictive Analytics, Analytics, Computer Science, Data Science, Statistics, Mathematics, Engineering, or other quantitative field. Recognized experience (patents, publications, and/or work history) and knowledge of relevant technologies (e.g. propulsion battery systems, high voltage hardware, electric traction motors, power electronics, electric powertrains, etc.). Excellent experience with of relevant tools and programming languages… Machine Learning & Data Analysis Libraries: TensorFlow, Scikit-Learn, Spark ML, Pandas, or equivalent. Programming Languages: SQL, Python, R, , Big-Data Analysis Tools: Hadoop, PowerBI, Spark, Web-Scrapping Excellent experience with the following methods… Statistical Process Controls, Neural Networks, Machine Learning, Deep Learning Excellent user interface (UI) development capability Strong understanding of major automotive subsystems, battery cells, and big-data structure. Demonstrated excellent level of analytical ability, communication, and interpersonal skills required to build relationships with team members and customers to solve problems and resolve issues. Demonstrated ability to manage multiple and significantly complex projects with high level of autonomy and accountability for results. Demonstrates initiative by reaching beyond work assigned to improve output and/or help others. Ability to think broadly and reach out to other areas of a large organization to understand the cross-functional interactions between vehicle systems and/or IT systems. Proven ability in project management skills and ability to teach others. Excellent ability for follow change management techniques of digital content. What Will Give You A Competitive Edge (Preferred Skills) Master’s or Phd. degree in Predictive Analytics, Analytics, Statistics, Computer Science, or Engineering. 3+ years of demonstrated technical experience in product development of electrified vehicles, especially in the electric vehicle battery space. Professional Engineering License Highly experienced in artificial intelligence methods. Compensation: The compensation information is a good faith estimate only. It is based on what a successful applicant might be paid in accordance with applicable state laws. The compensation may not be representative for positions located outside of New York, Colorado, California, or Washington. The salary range for this role is $116,100 to $181,600. The actual base salary a successful candidate will be offered within this range will vary based on factors relevant to the position. About GM Our vision is a world with Zero Crashes, Zero Emissions and Zero Congestion and we embrace the responsibility to lead the change that will make our world better, safer and more equitable for all. Why Join Us We aspire to be the most inclusive company in the world. We believe we all must make a choice every day – individually and collectively – to drive meaningful change through our words, our deeds and our culture. Our Work Appropriately philosophy supports our foundation of inclusion and provides employees the flexibility to work where they can have the greatest impact on achieving our goals, dependent on role needs. Every day, we want every employee, no matter their background, ethnicity, preferences, or location, to feel they belong to one General Motors team. Benefits Overview The goal of the General Motors total rewards program is to support the health and well-being of you and your family. Our comprehensive compensation plan incudes, the following benefits, in addition to many others: Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents; Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family; Company and matching contributions to 401K savings plan to help you save for retirement; Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values; Tuition assistance and student loan refinancing; Discount on GM vehicles for you, your family and friends. Diversity Information General Motors is committed to being a workplace that is not only free of discrimination, but one that genuinely fosters inclusion and belonging. We strongly believe that workforce diversity creates an environment in which our employees can thrive and develop better products for our customers. We understand and embrace the variety through which people gain experiences whether through professional, personal, educational, or volunteer opportunities. GM is proud to be an equal opportunity employer. We encourage interested candidates to review the key responsibilities and qualifications and apply for any positions that match your skills and capabilities. Equal Employment Opportunity Statements GM is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. GM is committed to providing a work environment free from unlawful discrimination and advancing equal employment opportunities for all qualified individuals. As part of this commitment, all practices and decisions relating to terms and conditions of employment, including, but not limited to, recruiting, hiring, training, promotion, discipline, compensation, benefits, and termination of employment are made without regard to an individual's protected characteristics. For purposes of this policy, “protected characteristics\" include an individual's actual or perceived race, color, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth, lactation and related medical conditions), gender identity or gender expression, sexual orientation, weight, height, marital status, military service and veteran status, physical or mental disability, protected medical condition as defined by applicable state or local law, genetic information, or any other characteristic protected by applicable federal, state or local laws and ordinances. If you need a reasonable accommodation to assist with your job search or application for employment, email us at Careers.Accommodations@GM.com or call us at 800-865-7580. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.",
        "url": "https://www.linkedin.com/jobs/view/3942393877",
        "summary": "The EV Battery Analytics Staff Computer Scientist will lead a team of analytics engineers to design and implement an advanced data architecture for EV batteries. This role focuses on leveraging telemetry data to ensure the safe and reliable performance of EV batteries. The ideal candidate will have a strong background in analytics, computer science, and data science, along with expertise in battery technologies and relevant tools like TensorFlow, Scikit-Learn, SQL, Python, and Hadoop.",
        "industries": [
            "Automotive",
            "Electric Vehicle",
            "Battery Technology",
            "Data Science",
            "Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Interpersonal Skills",
            "Problem Solving",
            "Project Management",
            "Teamwork",
            "Leadership",
            "Initiative",
            "Autonomy",
            "Accountability",
            "Cross-Functional Collaboration",
            "Teaching"
        ],
        "hard_skills": [
            "Predictive Analytics",
            "Analytics",
            "Computer Science",
            "Data Science",
            "Statistics",
            "Mathematics",
            "Engineering",
            "Machine Learning",
            "Data Analysis",
            "TensorFlow",
            "Scikit-Learn",
            "Spark ML",
            "Pandas",
            "SQL",
            "Python",
            "R",
            "Hadoop",
            "PowerBI",
            "Spark",
            "Web-Scrapping",
            "Statistical Process Controls",
            "Neural Networks",
            "Deep Learning",
            "UI Development",
            "Battery Cells",
            "Big Data Structure",
            "Artificial Intelligence",
            "Product Development",
            "Electrified Vehicles",
            "Electric Vehicle Battery",
            "Project Management",
            "Change Management"
        ],
        "tech_stack": [
            "TensorFlow",
            "Scikit-Learn",
            "Spark ML",
            "Pandas",
            "SQL",
            "Python",
            "R",
            "Hadoop",
            "PowerBI",
            "Spark",
            "Web-Scrapping"
        ],
        "programming_languages": [
            "SQL",
            "Python",
            "R"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's of Science",
            "fields": [
                "Predictive Analytics",
                "Analytics",
                "Computer Science",
                "Data Science",
                "Statistics",
                "Mathematics",
                "Engineering"
            ]
        },
        "salary": {
            "max": 181600,
            "min": 116100
        },
        "benefits": [
            "Paid Time Off",
            "Parental Leave",
            "Health Insurance",
            "Dental Insurance",
            "Vision Insurance",
            "Life Insurance",
            "Health Savings Account",
            "Wellness Incentive",
            "401K",
            "Matching Contributions",
            "Recognition Program",
            "Tuition Assistance",
            "Student Loan Refinancing",
            "GM Vehicle Discount"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Jackson, MI",
        "job_id": 3938219872,
        "company": "Resource Logistics Inc.",
        "title": "Platform Engineer (Databricks - Azure)",
        "created_on": 1720588493.4857001,
        "description": "Platform Engineer (Databricks - Clienture) Location : Jackson Michigan.(Look for local resource) Contract Overview We are seeking a talented and motivated Platform Engineer to join our team. As a Platform Engineer, you will play a crucial role in designing, implementing, and maintaining our data platform using Databricks on the Microsoft Clienture cloud. Youll collaborate with cross-functional teams to ensure the scalability, reliability, and performance of our analytics and data solutions. Responsibilities Clienthitecture and Design: Provide input into the strategic technology direction for our data platform. Clienthitect scalable and efficient data solutions using Clienture Databricks. Data Pipelines And Integration Design, implement, and manage data pipelines. Ensure seamless data integration across various systems. Optimize data processing workflows. Infrastructure Automation Develop Terraform Infrastructure as Code (IaC) to automate Databricks environment deployments. Create a library of scripts for automating MLOps environments. Performance Monitoring And Tuning Monitor and analyze database performance. Fine-tune and optimize the data platform. Collaboration And Communication Work closely with interdisciplinary teams, including engineers, data scientists, and business stakeholders. Communicate effectively to ensure alignment with business goals. Qualifications Bachelors degree in Computer Science, Engineering, or related field. Proven experience as a Platform Engineer or similar role. Strong expertise in Databricks and Microsoft Clienture. Experience with Infrastructure as Code (IaC) and automation tools, preferably Terraform. Knowledge of data catalog tools (e.g., Microsoft Purview). Excellent problem-solving skills and ability to work in a collaborative environment",
        "url": "https://www.linkedin.com/jobs/view/3938219872",
        "summary": "We are looking for a Platform Engineer to design, implement, and maintain our data platform using Databricks on Microsoft Azure. This role involves architecting scalable data solutions, managing data pipelines, automating infrastructure with Terraform, and collaborating with cross-functional teams.",
        "industries": [
            "Data Engineering",
            "Software Engineering",
            "Technology",
            "Cloud Computing"
        ],
        "soft_skills": [
            "Collaboration",
            "Communication",
            "Problem-Solving",
            "Teamwork"
        ],
        "hard_skills": [
            "Databricks",
            "Azure",
            "Terraform",
            "Data Pipelines",
            "Data Integration",
            "Infrastructure as Code",
            "Performance Monitoring",
            "Performance Tuning"
        ],
        "tech_stack": [
            "Databricks",
            "Azure",
            "Terraform"
        ],
        "programming_languages": [],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Computer Science",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Superior, MI",
        "job_id": 3834966523,
        "company": "Hyundai America Technical Center, Inc. (HATCI)",
        "title": "Embedded SW Engineer (Engineer I or II)",
        "created_on": 1720588494.9778388,
        "description": "Hyundai America Technical Center, Inc. (HATCI) Is Currently Looking For An Embedded SW Engineer I/II For ADAS Sensor Fusion Within Our ADAS&AD Software Development Team At Our Superior Township, Michigan Facility The ADAS and Autonomous Driving (AD) Vehicle Software Development team in Hyundai America Technical Center, Inc. (HATCI) is an engineering and data science team that focuses on improving performance and expanding ADAS features and services of Hyundai/Kia/Genesis vehicles for the North American (NA) market. The team’s key roles and responsibilities are: New Technology Introduction to spearhead new technology conceptualization for future generation ADAS experiences for the NA market through in-house development as well as strategic partnerships with key technology hubs such as universities, startups and research labs Software Development to expand Hyundai/Kia/Genesis ADAS capabilities in coordination with the R&D Headquarters and other internal/external project partners Prototyping and Demonstration to develop prototypes and proof of concept demonstrations to various global teams within Hyundai Motor Group (HMG) for new ADAS/AD functions targeted for the NA market Software Strategy and Planning to identify market trends and customer needs for key ADAS experience themes and selection of new concept ideas Data Analysis for Production Applications to support requirements development and verification and software updates to improve product performance in the NA market. How You Will Drive Innovation As Embedded Sensor Fusion SW Engineer within our growing ADAS&AD Software Development team you will lead and support the following key activities: Key Activities Support advanced development and prototyping of new ADAS experiences specialized for the North American (NA) market in areas such as L2+/L3 automated driving, automated towing and hitching, automated parking, and automated path adjustment for collision avoidance features. Lead/support algorithm development to build, simulate and test perception algorithms, improve production software modules to enhance existing Hyundai/Kia/Genesis ADAS suite Work with senior engineers in the ADAS perception team to develop, debug and deploy raw sensor signal processing and sensor fusion algorithms in embedded platforms Lead/support AI/ML dataset creation, labeling, curation, formatting, model training, evaluation and deployment efforts with multiple sensor modalities Interface with technical experts and subject matter experts from the R&D Headquarters in South Korea to establish and maintain a collaborative relationship with our global partners Experience And Skills Basic Qualifications: B.S. in Electrical Engineering, Computer Science, Robotics, Computer Engineering or a similar engineering discipline Participation in relevant projects, internships or co-op experiences that demonstrate skills in embedded systems, sensor data handling, or ADAS technologies Proficiency in designing, programming, and debugging embedded systems, particularly experience with platforms like NVIDIA Jetson or similar Strong programming skills in Python and/or C/C++ Basic knowledge of signal processing techniques applicable to raw sensor data An understanding of sensor fusion principles and techniques, even if only at a theoretical level. Exposure to algorithms that combine data from multiple sensors. Experience with software development tools such as Git, and familiarity with Linux environments. A valid driver’s license with a satisfactory driving record Eagerness to learn new technologies and adapt to changes in technology and industry practices. Preferred Qualifications M.S. degree in Electrical Engineering, Computer Science, Robotics or a similar engineering discipline 2-3 years of industry experience developing and deploying algorithms for sensor data processing and sensor fusion applications is a plus Familiarity with various sensor modalities used in ADAS/AD, such as radar, cameras, ultrasonics and LiDAR, along with understanding of sensor characteristics and limitations Knowledge of CUDA for GPU programming on NVIDIA platforms is a plus Strong understanding and knowledge of signal processing and sensor fusion algorithms We believe in the unique contributions that individuals can bring to our team, so even if you don't meet every single requirement, we still encourage you to apply! We're looking for potential and passion as much as experience and expertise. Candidates applying for positions with Hyundai and KIA must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.",
        "url": "https://www.linkedin.com/jobs/view/3834966523",
        "summary": "Hyundai is seeking an Embedded SW Engineer I/II to work on advanced driver assistance systems (ADAS) sensor fusion. This role will involve developing and testing perception algorithms, working with raw sensor data, and building AI/ML datasets for ADAS features like automated driving, parking, and collision avoidance. The position requires embedded systems experience, strong programming skills in Python and C/C++, knowledge of sensor fusion and signal processing, and familiarity with development tools like Git and Linux.",
        "industries": [
            "Automotive",
            "Software Development",
            "Technology",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Analytical Skills",
            "Adaptability",
            "Teamwork",
            "Leadership",
            "Eagerness to Learn",
            "Attention to Detail"
        ],
        "hard_skills": [
            "Embedded Systems",
            "Sensor Data Handling",
            "ADAS Technologies",
            "Python",
            "C/C++",
            "Signal Processing",
            "Sensor Fusion",
            "Git",
            "Linux",
            "CUDA",
            "AI/ML",
            "Dataset Creation",
            "Data Labeling",
            "Model Training",
            "Model Evaluation",
            "Model Deployment",
            "NVIDIA Jetson"
        ],
        "tech_stack": [
            "NVIDIA Jetson",
            "Git",
            "Linux",
            "CUDA"
        ],
        "programming_languages": [
            "Python",
            "C",
            "C++"
        ],
        "experience": 2,
        "education": {
            "min_degree": "B.S.",
            "fields": [
                "Electrical Engineering",
                "Computer Science",
                "Robotics",
                "Computer Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Warren, MI",
        "job_id": 3919844857,
        "company": "Talascend - Where Opportunities Await.",
        "title": "Data Engineer - Digital Operations – Advanced Analytics",
        "created_on": 1720588496.39417,
        "description": "Talascend is currently seeking a Data Engineer - Digital Operations – Advanced Analytics for a contract opportunity in Warren, MI (Hybrid); Ability to work W2 Assignment JOB TITLE: Data Engineer - Digital Operations – Advanced Analytics DURATION: One year with possible extension LOCATION: Warren, MI (Hybrid); Ability to work W2 Assignment OVERVIEW: This assignment will be working on technical cases. Providing data for all escalated customer complaints and cases from the connected vehicle. On Star, my brand apps, anything the vehicle connects with and uses. Any issues that the first line cannot resolve this team takes that on. This role will include a lot of problem solving and Data. Connected Operations is a part of the larger Customer Experience organization and is at the forefront of the transition to a digital eco system where our interactions with our customers, our partners (dealers), now have more digital footprints. There are some major digital initiatives in the areas of NLP engines including speech to Text for IVR (Interactive Voice Response systems), transition to utilizing Intelligent Bots handling customer queries, using machine learning tools to improve our systems. We are also responsible to ensure the transactional performance of in-vehicle product services (OnStar services delivered using cellular connection CDMA/LTE such as OnStar Vehicle Diagnostics, Vehicle Health Alerts, Theft Alert Notification, Hands Free Calling, Smart Driver, Turn-by-turn navigation instructions, automatic crash response roadside assistance and Family Link) and analysis of real time data collected from the vehicles in rapport with research and development , quality control and manufacturing to ensure customer safety and ownership experience. The Individual would be leading the effort to develop “first in line” insights, Key Performance Indicators (KPIs) and effectiveness of the solutions that are being implemented. The individual is responsible for providing technical expertise to develop analytics driven solutions to help achieve our business goal. Individual will work as a member of a multi-disciplinary and cross organizational team of various experience levels that will be driving solution by designing, developing, and deploying analytic models to measure performance to support critical business areas. PRIMARY RESPONSIBILITIES: As a Data Engineer, the individual will work with a wide variety of data sources including Oracle, Teradata, Greenplum, Hadoop databases to extract information and integrate to help create “key performance indicators” - The KPI’s would serve as a benchmark of the critical program’s success . The KPI’s would cover the aspects of operational health, effectiveness, and pain points of the digital implementation. Effective gap analysis to understand the failure rates and the cause of the failures is also a key responsibility. The individual would also be responsible for implementation of Text Analytics /ML programs to better our understanding of business analytics, train models to act as better predictors of the conversational intents (Text parsing and topic modelling), volumetric trends towards specific lines of business and overall pain point understanding. With multiple initiatives going on, there would be holistic integration in the strategy employed to achieve a unified picture of all programs. Gather the data through mining computer data through software, to improve performance and reduce costs. Effectiveness of the solutions through a cost model would also be a critical responsibility that the individual would work with along with a broader team. Identify the right data across multiple data platforms and analyze the data in those respective data platforms. Integrate utilizing ETL techniques (Extract, Transform and Load) , all the different data points to common data lake to support the creation of Key performance indicators. Ability to drive insights out of structured, unstructured and semi structured data. Lead for advanced text analytics. Identify text splits/ Implement models like Bag of Words. Ability to create topic categories from text analytics. Help identify point pain points. Ability to handle large data volumes. Lead for analytics on Big Data Volumes. Ability to create systems from heavy duty vehicle data volumetric. Integration across multiple systems, Databases, technology types. Self-starter and ability to form initial impressions from ambiguous data. Synthesize trend data to support recommendations for action to improve performance. Work in a agile environment with a fast paced team to quickly Key Performance Indicators. Recommend and apply the right machine learning algorithms to satisfy the appropriate business requirements. Create tools or systems using databases, Shell scripting, Cognos, Tableau, Power BI, Spreadsheet, Hadoop, Hue, Kafka, Grafana, Python for output. Maintain and update the tools, dashboards, databases, and Recommend Improvements. Identify and monitor current performance and potential service failure modes in delivering digital products to customers using analytics. Maintain knowledge management article with model documents, templates, detailed process flow diagram, value stream mapping diagram, swim lane diagrams, playbook, and other reusable knowledge assets. Generate standard reports summarizing operational costs by working with a broader team. Meet and gather requirements with multiple business stakeholders across projects in the digital ecosystem. Perform Proof of concept on newer tools and technologies (within the approved list of software) to drive innovation. Draft and document the business cases where machine learning models would be used – The benefits and the rationale for selecting a model approach. Identify the right dependent and independent variables to train the machine learning model sets; Run sample model sets to derive outputs that establishes the relationships between the variables clearly. Communicate with leadership to determine the service level agreement for performance of information technology and our back office. Identify and lead adaption of new and innovative technological advances taking place rapidly in the field to remain competitive. Troubleshoot production issues caused due to production incidents by providing tactical and innovative solutions by working closely IT teams in resolving identified systemic issues affecting system performance. Monitor and supervise timely release of software updates, Product tuning cycles, infrastructure upgrades, to ensure deadlines, standards and performance targets are met. Big data performance tuning for data ingestion and data retrieval, with modeling tools like Erwin, Visio and advanced level expertise in performance optimization, data transformation methods with languages/tools like SQL, PL/SQL, NoSQL, Hive, Hadoop, Spark. Gap analysis in compliance with operational excellence program (lean six sigma principals) of the system to provide insights and improving system performance. Understand architectural tenets of Clouds ecosystems. Understand ETL methodologies across multiple product ecosystems. POSITION REQUIREMENTS: Bachelor’s degree in Computer Science or related field required. Expert in utilizing SQL across Oracle, Hadoop/Hive databases, systems. Expert in ETL systems – Via Batch SQL, Data Stage (awareness). Experience with extraction and loading into Hadoop/Hive. Business Intelligence and Data Analysis Software — IBM Cognos Impromptu; Tableau, Oracle Business Intelligence Enterprise Edition. Operating System Software — Bash, UNIX, Shell Script. Knowledge of IVR (Interactive Voice Response Systems). Knowledge and Expertise in Vehicle-based Telematics Architecture. Specialized knowledge of Vehicle based Health programs, High Speed Telematics ingestion and backend -Vehicle communication. Database Management System Software — Apache Hadoop/HDFS; Oracle PL/SQL; Teradata Database, Apache Cassandra, Apache Hive, NoSQL database. Advanced proficiency with using text Analytics utilizing Hive. Familiarly and experience with implementing Machine Learning Models (Create data sets, train models, explain correlations between dependent and independent variables). Familiarity with Statistics and ability to explain why a specific model was chosen. Familiarity with Object or Component-Oriented Development Software — Python. Presentation Software — Microsoft PowerPoint. Project Management Software —Microsoft Project; Microsoft SharePoint. Development Environment Software —Eclipse IDE; Microsoft Visual Studio. DESIRED QUALIFICATIONS: Knowledge of Data Lakes, Datawarehouse, Operational data stores as it relates to RDBMS and Big Data Technologies. Knowledge of Kafka Streaming Systems, Microservices architecture. Call-Center Telephony hardware/software integration to deliver critical Voice-based services. Knowledges of best CX practices for operational performance efficiencies – Determine right KPI’s, perform FMEA analysis, determine pain points, provide solutions for corrective actions. Understand Natural Language Processing. We thank all applicants for their interest. However, only those qualified individuals who closely meet the qualifications of the position will be contacted. The details of the position are only a summary, other duties may be assigned as necessary. Background Check and Drug Screen may be required. Talascend is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.",
        "url": "https://www.linkedin.com/jobs/view/3919844857",
        "summary": "This role is for a Data Engineer focusing on advanced analytics for digital operations within the automotive industry. The individual will work with large datasets from various sources, including vehicle telematics, customer interactions, and internal systems. Responsibilities include developing KPIs, conducting gap analysis, implementing text analytics and ML models, and building tools and dashboards to support business decision-making.",
        "industries": [
            "Automotive",
            "Telematics",
            "Customer Experience",
            "Data Analytics",
            "Machine Learning",
            "Software Engineering"
        ],
        "soft_skills": [
            "Problem Solving",
            "Analytical Skills",
            "Communication Skills",
            "Teamwork",
            "Self-starter",
            "Adaptability",
            "Critical Thinking",
            "Project Management",
            "Presentation Skills",
            "Time Management"
        ],
        "hard_skills": [
            "SQL",
            "ETL",
            "Hadoop",
            "Hive",
            "Oracle",
            "Teradata",
            "Greenplum",
            "Cognos",
            "Tableau",
            "Power BI",
            "Python",
            "Shell Scripting",
            "Kafka",
            "Grafana",
            "Text Analytics",
            "Machine Learning",
            "Natural Language Processing",
            "Statistics",
            "Data Warehousing",
            "Data Lakes",
            "Microservices",
            "Lean Six Sigma",
            "Cloud Computing",
            "Erwin",
            "Visio",
            "PL/SQL",
            "NoSQL",
            "Cassandra",
            "Bash",
            "UNIX"
        ],
        "tech_stack": [
            "Oracle",
            "Teradata",
            "Greenplum",
            "Hadoop",
            "Hive",
            "Cognos",
            "Tableau",
            "Power BI",
            "Python",
            "Shell Scripting",
            "Kafka",
            "Grafana",
            "Text Analytics",
            "Machine Learning",
            "Data Warehousing",
            "Data Lakes",
            "Microservices"
        ],
        "programming_languages": [
            "SQL",
            "Python"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Related Field"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "W2 Assignment",
            "Possible Extension",
            "Hybrid work"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Detroit, MI",
        "job_id": 3956227192,
        "company": "Atomic Industries",
        "title": "General Engineering Applicant",
        "created_on": 1720588497.7357812,
        "description": "Atomic currently offers a challenging environment for engineers from computational geometry/meshing/CFD, to physical HPC + ML problems. We're excited to break down barriers of traditional physics solvers using deep learning and other advanced methodologies. We're highly focused on a single application and value chain, so we're not recreating the wheel in terms of making broad platforms for users. We're actually doing the opposite, creating a computational API that places humans in the back seat. You'll be working on problems that fundamentally move the field of human creativity and design forward.",
        "url": "https://www.linkedin.com/jobs/view/3956227192",
        "summary": "Atomic is seeking engineers with expertise in computational geometry, meshing, CFD, physical HPC, and ML to revolutionize physics solvers using deep learning and advanced methodologies. The company focuses on a specific application and value chain, developing a computational API to automate complex calculations and empower human creativity and design.",
        "industries": [
            "Computer Software",
            "Engineering",
            "Research"
        ],
        "soft_skills": [
            "Problem Solving",
            "Creativity"
        ],
        "hard_skills": [
            "Computational Geometry",
            "Meshing",
            "CFD",
            "HPC",
            "Machine Learning",
            "Deep Learning"
        ],
        "tech_stack": [
            "Deep Learning",
            "Computational API"
        ],
        "programming_languages": [],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Detroit, MI",
        "job_id": 3954469339,
        "company": "ATC",
        "title": "Automation Engineer /QA Analyst - MI - Detroit",
        "created_on": 1720588498.9893098,
        "description": "About The Job Job Title: Automation Engineer /QA Analyst About ATC American Technology Consulting (ATC) is a next-gen technology firm committed to empowering enterprises through innovative solutions. ATC specializes in enterprise application development, cloud transformation, DevOps, robotic process automation, agile transformation, and more. We offer comprehensive services including AI/ML engineering, digital transformation, and mobile application development. Our design expertise spans UX/UI, branding, and product design. ATC also provides robust staffing solutions, dedicated retainer teams, and cybersecurity staffing. Join us to be part of a team driving digital transformation and excellence. Job Description Testing products, systems, and software to guarantee they are defect-free and fulfill the quality standards of an organization Developing and executing test plans to ensure that all objectives are met Implementing and monitoring test scripts to assess functionality, reliability, performance, and quality of the service or product Skills Required Proven experience executing functional, regression, and integration tests for Retail IT (Point of Sale, In-Store Payment), including on-premise and cloud services. Expertise in designing and documenting test cases (Qtest or similar tool) and clearly articulating bugs/defects in requirements management systems (Jira or similar tool). Experience reading, interpreting, and reviewing C# and XAML Other Additional Qualifications: Master’s Degree. We sponsor H1B / related work visas for eligible candidates. Individuals on F1/OPT are welcome to apply. Candidates require a US work authorization. We are an equal-opportunity employer.",
        "url": "https://www.linkedin.com/jobs/view/3954469339",
        "summary": "Automation Engineer /QA Analyst to test products, systems, and software for Retail IT (Point of Sale, In-Store Payment) including on-premise and cloud services.  Develop and execute test plans.  Implement and monitor test scripts.  Experience with functional, regression, and integration testing.  Expertise in designing and documenting test cases and articulating bugs/defects.  Experience reading, interpreting, and reviewing C# and XAML.",
        "industries": [
            "Technology",
            "IT",
            "Retail",
            "Software Development"
        ],
        "soft_skills": [
            "Problem Solving",
            "Analytical Thinking",
            "Communication",
            "Teamwork",
            "Detail-Oriented"
        ],
        "hard_skills": [
            "Functional Testing",
            "Regression Testing",
            "Integration Testing",
            "Test Planning",
            "Test Case Design",
            "Test Scripting",
            "Bug Reporting",
            "Requirements Management",
            "C#",
            "XAML",
            "Qtest",
            "Jira"
        ],
        "tech_stack": [
            "Qtest",
            "Jira",
            "C#",
            "XAML"
        ],
        "programming_languages": [
            "C#",
            "XAML"
        ],
        "experience": 0,
        "education": {
            "min_degree": "Master’s Degree",
            "fields": [
                "Computer Science",
                "Information Technology",
                "Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "H1B Sponsorship",
            "Visa Sponsorship",
            "F1/OPT Welcome",
            "Equal Opportunity Employer"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Dearborn, MI",
        "job_id": 3845988699,
        "company": "SmartIPlace",
        "title": "Software Engineer Senior(Hybrid)-W2",
        "created_on": 1720588503.0594146,
        "description": "Title- Software Engineer Senior Location- Dearborn, Michigan. Hybrid 2-3 days onsite. (Local would be ideal but will accept non local as well if they are ready to relocate from day 1) Visa- USC, GC Job Description This job request is for a Technical Lead position that would be responsible for SAP S4 Hana General ledger through working knowledge and configuration experience Skills Required Thorough working knowledge and configuration experience in S4 FI and CO modules: FI-GL, AP, AR, AA required. CO-PC, CO-CCA, CO-ML, CO-PA desirable. Experience working in a multi-company code, multi-currency environment required. Ability to perform in-depth hands-on configuration of required SAP FICO modules. Analyze problems and troubleshoot to find the root cause. Experience in multiple implementations of SAP ERP solutions with full life-cycle participation. Help with solution design and perform unit testing / integration testing and UAT. Skills Preferred Ability to read and debug ABAP code (but not perform any technical development). Good knowledge of integration with other S4 modules – Purchasing, Sales and Production Ability to read and debug ABAP code (but not perform any technical development) Development experience using various SAP development technologies including but not limited to the following: ABAP, Integration and UI tools. Experience Required 10+ years of experience in S4 FI and CO modules: FI-GL, AP, AR, AA required. CO-PC, CO-CCA, CO-ML, CO-PA desirable. Ability to perform in-depth hands-on configuration of required SAP FICO modules. Education Required Bachelor's Degree",
        "url": "https://www.linkedin.com/jobs/view/3845988699",
        "summary": "This position is for a Technical Lead responsible for configuring and managing SAP S4 Hana General Ledger, FI and CO modules, specifically FI-GL, AP, AR, AA. The ideal candidate will have 10+ years of experience with S4 FI and CO modules, including multi-company code and multi-currency environments, and experience in multiple SAP ERP implementations with full life-cycle participation. They should be comfortable analyzing and troubleshooting problems, performing in-depth configuration, unit and integration testing, and UAT.  Experience with ABAP code reading and debugging, as well as integration with other S4 modules such as Purchasing, Sales, and Production is preferred. ",
        "industries": [
            "Information Technology",
            "Software Development",
            "Consulting",
            "Accounting"
        ],
        "soft_skills": [
            "Problem Solving",
            "Troubleshooting",
            "Communication",
            "Teamwork",
            "Analytical Skills",
            "Detail-Oriented"
        ],
        "hard_skills": [
            "SAP S4 Hana",
            "General Ledger",
            "FI-GL",
            "AP",
            "AR",
            "AA",
            "CO-PC",
            "CO-CCA",
            "CO-ML",
            "CO-PA",
            "ABAP",
            "Integration",
            "Unit Testing",
            "Integration Testing",
            "UAT"
        ],
        "tech_stack": [
            "SAP S4 Hana",
            "ABAP"
        ],
        "programming_languages": [
            "ABAP"
        ],
        "experience": 10,
        "education": {
            "min_degree": "Bachelor's Degree",
            "fields": [
                "Information Technology",
                "Computer Science",
                "Accounting",
                "Finance"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Holland, MI",
        "job_id": 3965978068,
        "company": "Haworth",
        "title": "Data Quality Engineer",
        "created_on": 1720588504.5154948,
        "description": "Company Overview When you feel connected to your work, you feel more engaged. At Haworth, you can pursue a career that offers you ample opportunity to build your portfolio and expand your skillset in an exciting and inclusive environment. Join a company that values innovation, inspiration, and you! HAWORTH is a global leader in office furniture and architectural interiors. As a valued member of our team, you can make your mark on the world and reach your full potential within a culture of connectivity. Why Haworth? Find out here! Here at Haworth, our members enjoy benefits from their first day of employment including: 4 weeks paid time off and an option to purchase an additional week Priority Health Insurance Newly renovated on-site gym open 24 hours 401k Benefit - If you contribute 6% of your annual salary, Haworth will contribute up to 7% Annual bonus programs Company provided Short Term Disability, Long Term Disability & Life Insurance Tuition Reimbursement program 8 hours of paid volunteer time off Zero waste to landfill company which provides personal on-site recycling drop-off Job Overview We are currently looking for a Data Quality Engineer to join our team in Holland. As a Data Quality Engineer, You Will Haworth's Global Information Systems department is seeking a highly driven and effective professional to join the data ops team. As a Data Quality Engineer, you will leverage your expertise, experience, and passion to ensure we uphold the highest levels of data quality and excellence for our clients. You will be responsible for maintaining and enhancing the quality of our data. Working closely with our DataOps team members, Data Owners, and Data Stewards, you will develop, implement, and maintain data quality standards and processes. Additionally, you will identify and resolve data quality issues, ensuring that our data is accurate, complete, and reliable. Do you have these required qualifications? Bachelor’s degree in Computer Science, Computer Information Systems, Computer Engineering, or similar field of study with 7 years experience in related design, development, and support experience in respective technology stack OR Master’s Degree in Computer Science, Computer Information Systems, Computer Engineering, or similar field of study with 5 years experience related design, development, and support experience in respective technology stack Related experience includes : data ingestion automated testing of multi sources and multi-integration, writing SQL Queries and Stored Procedures, testing Data Warehousing and data modeling, automated testing of data security (RBAC, RLS, CLS, Data Masking), automated testing of 7×24 near real-time data ingestion and incremental change processing, programming experience with C#, JavaScript, and Python. (Combination of equivalent education and work experience will also be considered) In Addition To Current and continuing right to work in the United States without sponsorship The ability to work and commute daily on-site to our headquarters in Holland, MI without relocation assistance Job Responsibilities Lead the design, development, and automation of the testing framework for our Big Data infrastructure using various latest technologies from SAP and Azure, both on-premises and in the cloud. Lead API testing and automation of data pipelines, data services, cloud data warehouses, business intelligence, and machine learning platforms, with a focus on unified transactional data. Utilize programming languages and analytics tools/technologies to validate products, machine learning models, data pipelines, and data deliverables. Use data catalog tools like Collibra to define, document, and manage Data Quality Requirements and Data Quality Rules. Use ETL tools like SAP BODS, SAP SLT, SSIS, and SAP CPI to extract, transform, and load data. Lead data governance and data profiling efforts to ensure data quality and proper metadata documentation for data lineage. Create quality metrics to evaluate data pipelines, products, and customer deliverables. Develop automated testing solutions using statistical methods, models, and processes to validate predicted outcomes. Work within an iterative software development lifecycle under Agile development processes. Collaborate with other developers to design and implement data science features in support of established security and acceptance criteria. Apply common software engineering best practices, such as pairing, test-driven development (TDD), writing unit and integration tests, and participating in code reviews. Collaborate with engineers, designers, and analysts to deliver innovative AI/ML product feature Assist the QA team with feature and regression testing. Ideally, You Have Also Demonstrated The Following Expert in multiple phases of delivery lifecycle (Requirements Gathering and Analysis, Design, Development, Testing, Launch, and Post-Launch support) to ensure consistent, effective, and efficient delivery process. Understands and applies current development standards, techniques, and best practices within Haworth's defined Technical Stack to maintain and enhance existing applications and systems; expert in multiple layers of Haworth Technical Stack. Able to analyze/debug complex, cross-platform issues, enhance/fix them quickly, and mentor others to do same (i.e., performance issues, crashes, and/or unexpected results). Knowledge of customer service standards and procedures with ability to provide outstanding customer service. Strong team player with the ability to collaborate across all levels of the organization. Strong analytical and problem-solving skills with a high aptitude to learn. High level of attention to detail. Flexibility, adaptability, and willingness to assist in other areas as priorities shift. Ability to operate with minimal supervision while keeping leadership informed. Strong written and verbal communication skills. Haworth Values At Haworth, we have a strong set of values that guide our business and help us align with our customers. We listen to our Customers. We rely on our Members. We honor Integrity. We embrace Continuous Learning. We lead with Design. We create Value. We work to make the World better. Join the Haworth family. Apply for this job, or learn more about the many possibilities at Haworth, at https://Careers.Haworth.com.",
        "url": "https://www.linkedin.com/jobs/view/3965978068",
        "summary": "Haworth is seeking a Data Quality Engineer to join their team in Holland, MI. The role involves leading the design, development, and automation of testing frameworks for their Big Data infrastructure, utilizing SAP and Azure technologies. This individual will be responsible for API testing, data pipeline automation, data quality management, data governance, and collaborating with other engineers to deliver innovative AI/ML product features.",
        "industries": [
            "Furniture",
            "Office Furniture",
            "Interior Design",
            "Technology",
            "Data Analytics",
            "Software Development",
            "Big Data",
            "Cloud Computing",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "soft_skills": [
            "Highly Driven",
            "Effective",
            "Passionate",
            "Team Player",
            "Collaboration",
            "Analytical",
            "Problem-Solving",
            "Attention to Detail",
            "Flexibility",
            "Adaptability",
            "Communication",
            "Customer Service"
        ],
        "hard_skills": [
            "Data Quality",
            "Data Engineering",
            "DataOps",
            "Data Governance",
            "Data Profiling",
            "Data Lineage",
            "Data Security",
            "Data Modeling",
            "Data Warehousing",
            "ETL",
            "SQL",
            "Stored Procedures",
            "API Testing",
            "Automation",
            "Machine Learning",
            "Data Pipelines",
            "Cloud Data Warehouses",
            "Business Intelligence",
            "Agile Development",
            "Test-Driven Development",
            "Code Review",
            "Software Engineering"
        ],
        "tech_stack": [
            "SAP",
            "Azure",
            "Collibra",
            "SAP BODS",
            "SAP SLT",
            "SSIS",
            "SAP CPI",
            "C#",
            "JavaScript",
            "Python"
        ],
        "programming_languages": [
            "C#",
            "JavaScript",
            "Python",
            "SQL"
        ],
        "experience": 7,
        "education": {
            "min_degree": "Bachelor’s Degree",
            "fields": [
                "Computer Science",
                "Computer Information Systems",
                "Computer Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "4 weeks paid time off",
            "Option to purchase an additional week of paid time off",
            "Priority Health Insurance",
            "On-site gym",
            "401k Benefit",
            "Annual bonus programs",
            "Short Term Disability",
            "Long Term Disability",
            "Life Insurance",
            "Tuition Reimbursement program",
            "Paid volunteer time off",
            "Zero waste to landfill company with on-site recycling"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Detroit, MI",
        "job_id": 3960096767,
        "company": "Canonical",
        "title": "Distributed Systems Software Engineer, Python / Go",
        "created_on": 1720588506.0838637,
        "description": "We are seeking a software engineer with a passion for building and validating resilient distributed systems. At Canonical you can build a career and drive the success of those leveraging Canonical's Ubuntu and Juju to build multi-cloud deployable cloud applications. We see quality engineering as a first class engineering practice and are looking for people who can bring deep engineering insights and a data driven approach to test automation, reporting and data analytics. The Distributed Systems testing team at Canonical is responsible for ensuring the high quality of Canonical's Cloud solutions based on Juju, Terraform, OpenStack, Kubernetes when deployed under highly diverse conditions, from bare metal in customer data centers to public clouds like AWS, GCE, Azure. As a software engineer you will have the opportunity to develop CI pipelines which power Canonical's cloud integration testing and reporting. Upcoming initiatives you will have the opportunity to contribute to include expanding deployment capabilities to new clouds and developing AI/ML pipelines for automatic analysis of test results. A successful candidate is interested in tackling these problems, as well as imagining and leading new initiatives within the team and across Canonical. Location: this is a Globally remote role What your day will look like Create automated testing approaches and infrastructure for validating reliability, performance, and resilience of cloud orchestration tools and applications Enable engineering teams across Canonical to develop software with confidence by making distributed system testing tooling available across the company Enhance continuous integration pipelines for deploying and testing Canonical's cloud native products such as Kubeflow Deploy, manage, and debug highly distributed systems Monitor and report on automated testing efforts Collaborate daily with a globally distributed team What we are looking for in you Solid background in modern test processes and strategies Experience with Python or Go development Strong object oriented development skills Ability to develop and ship production grade modern web applications Working knowledge of continuous integration tools such as Jenkins, CircleCI, GitHub CI Knowledge of networking technologies and fundamentals Solid understanding of Linux system architecture A capacity for complex abstract thinking Capability for 2-4 weeks of international travel travel per year Additional skills that you might also bring Collecting and analyzing large multidimensional datasets Operating data platforms: key-value stores, relational or document databases, event buses Work with cloud technologies such as OpenStack, Kubernetes, Terraform and AWS Developing AI/ML pipelines What we offer you We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person - we've been working remotely since 2004! Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues from your team and others Priority Pass for travel and travel upgrades for long haul company events Canonical believes a diverse workforce enhances our ability to deliver world class software and services which meet the world's computing needs. We are committed to ensuring equal employment opportunities to all qualified individuals. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.",
        "url": "https://www.linkedin.com/jobs/view/3960096767",
        "summary": "Canonical is seeking a software engineer to join their Distributed Systems testing team. The role involves creating and maintaining automated testing infrastructure for cloud orchestration tools and applications, enabling engineering teams to develop software with confidence. The ideal candidate has experience with Python or Go development, object-oriented programming, CI tools like Jenkins, GitHub CI, and knowledge of networking, Linux system architecture.  This role is globally remote with opportunities for travel.  ",
        "industries": [
            "Software Development",
            "Cloud Computing",
            "Information Technology",
            "DevOps",
            "Data Analytics"
        ],
        "soft_skills": [
            "Communication",
            "Collaboration",
            "Problem Solving",
            "Teamwork",
            "Leadership",
            "Abstract Thinking"
        ],
        "hard_skills": [
            "Python",
            "Go",
            "Object Oriented Programming",
            "Web Application Development",
            "Jenkins",
            "CircleCI",
            "GitHub CI",
            "Networking",
            "Linux System Architecture",
            "Data Analysis",
            "AI/ML",
            "Terraform",
            "OpenStack",
            "Kubernetes",
            "AWS"
        ],
        "tech_stack": [
            "Python",
            "Go",
            "Jenkins",
            "CircleCI",
            "GitHub CI",
            "Terraform",
            "OpenStack",
            "Kubernetes",
            "AWS",
            "Kubeflow"
        ],
        "programming_languages": [
            "Python",
            "Go"
        ],
        "experience": 0,
        "education": {
            "min_degree": null,
            "fields": []
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": [
            "Remote Work",
            "Learning and Development Budget",
            "Annual Compensation Review",
            "Recognition Rewards",
            "Annual Holiday Leave",
            "Maternity and Paternity Leave",
            "Employee Assistance Programme",
            "Travel Opportunities",
            "Priority Pass"
        ]
    },
    {
        "task_id": "7d84f17e10d2468eb98348ea40360f2c",
        "keyword": "ML Engineer",
        "location": "Dearborn, MI",
        "job_id": 3964478175,
        "company": "V2Soft",
        "title": "Software Engineer Senior",
        "created_on": 1720588507.6156049,
        "description": "V2Soft ( www.v2soft.com ) is a global company, headquartered out of Bloomfield Hills, Michigan, with locations in Mexico, Italy, India, China and Germany. At V2Soft, our mission is to provide high performance technology solutions to solve real business problems. We become our customer’s true partner, enabling both parties to enjoy success. We are committed to promoting diversity in the workplace, and believe it has a positive effect on our company and the customers we serve. Description Position Responsibilities Work closely with Tech Anchor, Product Manager and Product Owner to deliver MLOPs platform and Gen AI solution in GCP using Python and other tools for the data scientists and business across the company. Work with software and ML engineers/Data Scientist to tackle challenging AIOps and Gen AI problems. Maintain and mange current CI/CD ecosystem and tools Find ways to automate and continually improve current CI/CD processes and release processes Examine, inspect codes / scripts and resolve issues Help innovate standardize machine learning development practices. Experiment, innovate and share knowledge with the team. Lead by example in use of Paired Programming for cross training/upskilling, problem solving, and speed to delivery. Leverage latest ML/Gen AI / GCP/AIOPs/Kubernetes technologies Skills Required: A Bachelor’s degree in Computer Science / Computer Engineering or similar technical discipline. 3+ years of work experience as a backend software engineer in Python with exceptional software engineering knowledge. 2+ years of experience with Cloud Engineering / Services Experience with ML workflow orchestration tools: Airflow, Kubeflow etc. Advanced working knowledge of object-oriented/object function programming languages: Python, C/C++ Experience/understanding in MLOPs and Gen AI is a big plus Experience in DevOps: Jenkins/Tekton etc. Experience with cloud services, preferably GCP Services like Vertex AI, Cloud Function, BigQuery etc. Experience in container management solution: Kubernetes, Docker Experience in scripting language: Bash, PowerShell etc. Experience with Infrastructure as code: Terraform etc. Skills Preferred: Master focused in Computer Science / Machine Learning or related field Experience working with Google Cloud platform(GCP) - specifically Google Kubernetes engine, Terraform, and infrastructure Experience in programming concepts such as Paired Programming, Test Driven Development, etc. Knowledge of coding and software craftsmanship practices. Must be a quick learner and open to learning new technology. Experience applying agile practices to solution delivery. Must be team-oriented and have excellent oral and written communication skills. Must be a self-starter to understand existing bottlenecks and come up with innovative solutions. Experience Required: A Bachelor’s degree in Computer Science / Computer Engineering or similar technical discipline. 3+ years of work experience as a backend software engineer in Python with exceptional software engineering knowledge. 2+ years of experience with Cloud Engineering / Services Experience with ML workflow orchestration tools: Airflow, Kubeflow etc. Advanced working knowledge of object-oriented/object function programming languages: Python, C/C++ Experience/understanding in MLOPs and Gen AI is a big plus Experience in DevOps: Jenkins/Tekton etc. Experience with cloud services, preferably GCP Services like Vertex AI, Cloud Function, BigQuery etc. Experience in container management solution: Kubernetes, Docker Experience in scripting language: Bash, PowerShell etc. Experience with Infrastructure as code: Terraform etc. Experience Preferred: Experience and good understanding of GCP, DevOPs, AI/ML and GEN AI Education Required: A Bachelor’s degree in Computer Science / Computer Engineering or similar technical discipline. V2Soft is an Equal Opportunity Employer ( EOE). https://www.v2soft.com/careers - to view all of our open opportunities and to learn more about our benefits.",
        "url": "https://www.linkedin.com/jobs/view/3964478175",
        "summary": "V2Soft is seeking a Backend Software Engineer to work on their MLOPs platform and Gen AI solutions in GCP using Python. This role involves collaborating with Tech Anchors, Product Managers, and Product Owners to develop and deploy solutions for data scientists and businesses across the company. Responsibilities include tackling challenging AIOps and Gen AI problems, maintaining and managing the CI/CD ecosystem, automating and improving processes, resolving issues, standardizing machine learning development practices, innovating and sharing knowledge, and leading by example in paired programming. The ideal candidate will have a strong background in Python, cloud engineering, ML workflow orchestration tools, and experience with GCP services like Vertex AI, Cloud Function, and BigQuery.",
        "industries": [
            "Information Technology",
            "Software Development",
            "Cloud Computing",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "soft_skills": [
            "Communication",
            "Teamwork",
            "Problem-Solving",
            "Leadership",
            "Innovation",
            "Learning",
            "Collaboration"
        ],
        "hard_skills": [
            "Python",
            "Cloud Engineering",
            "GCP",
            "Vertex AI",
            "Cloud Function",
            "BigQuery",
            "Airflow",
            "Kubeflow",
            "Jenkins",
            "Tekton",
            "Kubernetes",
            "Docker",
            "Bash",
            "PowerShell",
            "Terraform",
            "C/C++",
            "Object-Oriented Programming"
        ],
        "tech_stack": [
            "Python",
            "GCP",
            "Vertex AI",
            "Cloud Function",
            "BigQuery",
            "Airflow",
            "Kubeflow",
            "Jenkins",
            "Tekton",
            "Kubernetes",
            "Docker",
            "Terraform"
        ],
        "programming_languages": [
            "Python",
            "C/C++"
        ],
        "experience": 3,
        "education": {
            "min_degree": "Bachelor's degree",
            "fields": [
                "Computer Science",
                "Computer Engineering"
            ]
        },
        "salary": {
            "max": 0,
            "min": 0
        },
        "benefits": []
    }
]